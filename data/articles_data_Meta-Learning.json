[
    {
        "id": 17071,
        "title": "Meta-reinforcement learning",
        "authors": "Lan Zou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.00011-0"
    },
    {
        "id": 17072,
        "title": "Meta-learning for healthcare",
        "authors": "Lan Zou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.00007-9"
    },
    {
        "id": 17073,
        "title": "Meta-learning basics and background",
        "authors": "Lan Zou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.00010-9"
    },
    {
        "id": 17074,
        "title": "Metric-based meta-learning approaches",
        "authors": "Lan Zou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.00003-1"
    },
    {
        "id": 17075,
        "title": "Model-based meta-learning approaches",
        "authors": "Lan Zou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.00006-7"
    },
    {
        "id": 17076,
        "title": "Optimization-based meta-learning approaches",
        "authors": "Lan Zou",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.00001-8"
    },
    {
        "id": 17077,
        "title": "Meta-learning for computer vision",
        "authors": "Lan Zou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.00012-2"
    },
    {
        "id": 17078,
        "title": "Meta-learning for natural language processing",
        "authors": "Lan Zou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.00005-5"
    },
    {
        "id": 17079,
        "title": "Meta-Learning",
        "authors": "Wenwu Zhu, Xin Wang",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-88132-0_2"
    },
    {
        "id": 17080,
        "title": "Meta-Learning for Multimedia",
        "authors": "Wenwu Zhu, Xin Wang",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-88132-0_4"
    },
    {
        "id": 17081,
        "title": "Awesome-META+: Meta-Learning Research and Learning Platform",
        "authors": "Jingyao Wang, Chuyuan Zhang, Ye Ding, Yuxuan Yang",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p> Artificial intelligence technology has already had a profound impact in various fields such as economy, industry, and education, but still limited. Meta-learning, also known as \"learning to learn\", provides an opportunity for general artificial intelligence, which can break through the current AI bottleneck. However, meta learning started late and there are fewer projects compare with CV, NLP etc. Each deployment requires a lot of experience to configure the environment, debug code or even rewrite, and the frameworks are isolated. Moreover, there are currently few platforms that focus exclusively on meta-learning, or provide learning materials for novices, for which the threshold is relatively high. Based on this, Awesome-META+, a meta-learning framework integration and learning platform is proposed to solve the above problems and provide a complete and reliable meta-learning framework application and learning platform. The project aims to promote the development of meta-learning and the expansion of the community, including but not limited to the following functions: 1) Complete and reliable meta-learning framework, which can adapt to multi-field tasks such as target detection, image classification, and reinforcement learning. 2) Convenient and simple model deployment scheme which provide convenient meta-learning transfer methods and usage methods to lower the threshold of meta-learning and improve efficiency. 3) Comprehensive researches for learning. 4) Objective and credible performance analysis and thinking. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22688407"
    },
    {
        "id": 17082,
        "title": "Awesome-META+: Meta-Learning Research and Learning Platform",
        "authors": "Jingyao Wang, Chuyuan Zhang, Ye Ding, Yuxuan Yang",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p> Artificial intelligence technology has already had a profound impact in various fields such as economy, industry, and education, but still limited. Meta-learning, also known as \"learning to learn\", provides an opportunity for general artificial intelligence, which can break through the current AI bottleneck. However, meta learning started late and there are fewer projects compare with CV, NLP etc. Each deployment requires a lot of experience to configure the environment, debug code or even rewrite, and the frameworks are isolated. Moreover, there are currently few platforms that focus exclusively on meta-learning, or provide learning materials for novices, for which the threshold is relatively high. Based on this, Awesome-META+, a meta-learning framework integration and learning platform is proposed to solve the above problems and provide a complete and reliable meta-learning framework application and learning platform. The project aims to promote the development of meta-learning and the expansion of the community, including but not limited to the following functions: 1) Complete and reliable meta-learning framework, which can adapt to multi-field tasks such as target detection, image classification, and reinforcement learning. 2) Convenient and simple model deployment scheme which provide convenient meta-learning transfer methods and usage methods to lower the threshold of meta-learning and improve efficiency. 3) Comprehensive researches for learning. 4) Objective and credible performance analysis and thinking. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22688407.v1"
    },
    {
        "id": 17083,
        "title": "Metric learning algorithms for meta learning",
        "authors": "Pengyu Yuan, Hien Van Nguyen",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-399851-2.00010-7"
    },
    {
        "id": 17084,
        "title": "Meta Learning",
        "authors": "",
        "published": "2022-12-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009218276.024"
    },
    {
        "id": 17085,
        "title": "Meta learning for domain generalization",
        "authors": "Swami Sankaranarayanan, Yogesh Balaji",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-399851-2.00013-2"
    },
    {
        "id": 17086,
        "title": "Explaining Meta-Features Importance in Meta-Learning Through Shapley Values",
        "authors": "Moncef Garouani, Adeel Ahmad, Mourad Bouneffa",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011986600003467"
    },
    {
        "id": 17087,
        "title": "Meta learning by optimization",
        "authors": "Pengyu Yuan, Hien Van Nguyen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-399851-2.00011-9"
    },
    {
        "id": 17088,
        "title": "Introduction to meta learning",
        "authors": "Pengyu Yuan, Hien Van Nguyen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-399851-2.00009-0"
    },
    {
        "id": 17089,
        "title": "Model-based meta learning",
        "authors": "Pengyu Yuan, Hien Van Nguyen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-399851-2.00012-0"
    },
    {
        "id": 17090,
        "title": "Meta-Learning",
        "authors": "",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/c2020-0-03021-5"
    },
    {
        "id": 17091,
        "title": "Transfer Learning, Multi-task Learning, Continual Learning, and Meta-learning",
        "authors": "",
        "published": "2022-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009072205.018"
    },
    {
        "id": 17092,
        "title": "Meta learning in the big data regime",
        "authors": "Swami Sankaranarayanan, Yogesh Balaji",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-399851-2.00030-2"
    },
    {
        "id": 17093,
        "title": "Learning Meta-Learning (LML) dataset: Survey data of meta-learning parameters",
        "authors": "Sonia Corraya, Shamim Al Mamun, M. Shamim Kaiser",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.dib.2023.109777"
    },
    {
        "id": 17094,
        "title": "Meta-Learning",
        "authors": "Aske Plaat",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-0638-1_9"
    },
    {
        "id": 17095,
        "title": "Meta learning for adaptable lung nodule image analysis",
        "authors": "Aryan Mobiny, Hien Van Nguyen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-399851-2.00017-x"
    },
    {
        "id": 17096,
        "title": "Dedication",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.09997-1"
    },
    {
        "id": 17097,
        "title": "Copyright",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.09992-2"
    },
    {
        "id": 17098,
        "title": "Acknowledgments",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.09993-4"
    },
    {
        "id": 17099,
        "title": "Meta-analysis and criticisms of Visible Learning",
        "authors": "John Hattie",
        "published": "2023-2-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003380542-2"
    },
    {
        "id": 17100,
        "title": "Reinforcement meta-learning optimizes visuomotor learning",
        "authors": "Taisei Sugiyama, Nicolas Schweighofer, Jun Izawa",
        "published": "No Date",
        "citations": 3,
        "abstract": "AbstractReinforcement learning enables the brain to learn optimal action selection, such as go or not go, by forming state-action and action-outcome associations. Does this mechanism also optimize the brain’s willingness to learn, such as learn or not learn? Learning to learn by rewards, i.e., reinforcement meta-learning, is a crucial mechanism for machines to develop flexibility in learning, which is also considered in the brain without empirical examinations. Here, we show that humans learn to learn or not learn to maximize rewards in visuomotor learning tasks. We also show that this regulation of learning is not a motivational bias but is a result of an instrumental, active process, which takes into account the learning-outcome structure. Our results thus demonstrate the existence of reinforcement meta-learning in the human brain. Because motor learning is a process of minimizing sensory errors, our findings uncover an essential mechanism of interaction between reward and error.",
        "link": "http://dx.doi.org/10.1101/2020.01.19.912048"
    },
    {
        "id": 17101,
        "title": "Learning to acquire novel cognitive tasks with evolution, plasticity and meta-meta-learning",
        "authors": "Thomas Miconi",
        "published": "2022-7-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3520304.3533981"
    },
    {
        "id": 17102,
        "title": "Index",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.09990-9"
    },
    {
        "id": 17103,
        "title": "Meta-learning for emerging applications: Finance, building materials, graph neural networks, program synthesis, transportation, recommendation systems, and climate science",
        "authors": "Lan Zou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.00004-3"
    },
    {
        "id": 17104,
        "title": "Preface",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.09996-x"
    },
    {
        "id": 17105,
        "title": "AGILE - a meta learning framework for few-shot brain cell classification",
        "authors": "Pengyu Yuan, Hien Van Nguyen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-399851-2.00021-1"
    },
    {
        "id": 17106,
        "title": "Evaluar el modelo Flipped learning en un Ambiente de Aprendizaje E-learning",
        "authors": "Rennier Ligarretto Feo, Helio Alexander Hernández",
        "published": "2020-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22347/2175-2753v12i36.2575"
    },
    {
        "id": 17107,
        "title": "Meta-connective learning",
        "authors": "Neal Dreamson",
        "published": "2019-9-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429277528-2"
    },
    {
        "id": 17108,
        "title": "Automated Machine Learning and Meta-Learning for Multimedia",
        "authors": "Wenwu Zhu, Xin Wang",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-88132-0"
    },
    {
        "id": 17109,
        "title": "Meta-Baseline: Exploring Simple Meta-Learning for Few-Shot Learning",
        "authors": "Yinbo Chen, Zhuang Liu, Huijuan Xu, Trevor Darrell, Xiaolong Wang",
        "published": "2021-10",
        "citations": 139,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv48922.2021.00893"
    },
    {
        "id": 17110,
        "title": "Front Matter",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-89931-4.09988-0"
    },
    {
        "id": 17111,
        "title": "Meta-Analysis of Deep Learning Models for Machine Learning Chatbots",
        "authors": "Kyldo Jsowd",
        "published": "No Date",
        "citations": 0,
        "abstract": "This paper presents a comprehensive meta-analysis of deep learning models for machine learning chatbots. The rapid development of chatbot technology has led to a plethora of research studies exploring the use of deep learning techniques to enhance chatbot performance. However, there is a need for a systematic analysis to synthesize and evaluate the findings across these studies. In this study, we conduct a meta-analysis to identify the key trends, insights, and performance metrics associated with deep learning models in machine learning chatbots. The analysis includes a thorough examination of the various deep learning architectures, training methodologies, and evaluation metrics employed in the reviewed studies. Furthermore, we discuss the limitations and potential biases in the analyzed studies and provide recommendations for future research directions. The findings of this meta-analysis contribute to a better understanding of the effectiveness and challenges of deep learning models in machine learning chatbots, thereby guiding researchers and practitioners in the development and improvement of chatbot systems.",
        "link": "http://dx.doi.org/10.31219/osf.io/vz9hj"
    },
    {
        "id": 17112,
        "title": "Semi-supervised Meta-learning for Cross-domain Few-shot Intent Classification",
        "authors": "Yue Li, Jiong Zhang",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.metanlp-1.8"
    },
    {
        "id": 17113,
        "title": "Meta-Learning for Few-Shot Named Entity Recognition",
        "authors": "Cyprien de Lichy, Hadrien Glaude, William Campbell",
        "published": "2021",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.metanlp-1.6"
    },
    {
        "id": 17114,
        "title": "Automated Machine Learning",
        "authors": "Wenwu Zhu, Xin Wang",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-88132-0_1"
    },
    {
        "id": 17115,
        "title": "External Variables That Impact Mobile Learning (M-Learning) Acceptance: A Meta-Analysis",
        "authors": "Chenxi Liu",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3102/ip.22.1893430"
    },
    {
        "id": 17116,
        "title": "Meta-DRN: Meta-Learning for 1-Shot Image Segmentation",
        "authors": "Atmadeep Banerjee",
        "published": "2020-12-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/indicon49873.2020.9342070"
    },
    {
        "id": 17117,
        "title": "The Effect of Flipped Learning on Motivation: A Meta-Analysis",
        "authors": "Taha YAZAR, Özgür TUTAL",
        "published": "2023-4-29",
        "citations": 1,
        "abstract": "Ters-yüz öğrenme son yıllarda oldukça ilgi görmekte ve ters yüz öğrenmenin akademik başarı, derse yönelik tutum, kalıcılık, öz-yeterlik, eleştirel düşünme becerisi gibi farklı değişkenler üzerindeki etkisi gerçekleştirilen araştırmalarla incelenmektedir. Ters-yüz öğrenme yaklaşımının öğrenmeyi yönlendiren etkili bir güç olan motivasyon üzerindeki etkisini sınamak için de Türkiye ve yurtdışında çeşitli araştırmalar yapılmıştır. Ancak ters-yüz öğrenmenin etkililiğini inceleyen çalışmaların sonuçları farklılık göstermektedir. Kimi çalışmalar ters-yüz öğrenmenin öğrencilerin motivasyonu üzerindeki etkisinin pozitif olduğu sonucuna ulaşırken, kimi çalışmalar istatistiksel olarak anlamlı bir fark bulunmadığını, bazı çalışmalar ise negatif bir etkinin söz konusu olduğunu bildirmişlerdir. Bu araştırmanın amacı, ters-yüz öğrenmenin motivasyon üzerindeki etkisini inceleyen deneysel ve yarı deneysel çalışmaların sonuçlarını meta-analiz yöntemiyle analiz etmektir. Araştırmada yaklaşımla ilgili yurt içinde ve yurt dışında yapılmış deneysel ve yarı deneysel çalışmalara ulaşabilmek için alanyazın taraması yapılmıştır. Belirlenen anahtar kelimelere göre yapılan tarama sonucunda listelenen 4463 çalışmadan dâhil edilme ölçütlerine uyan 17 çalışma meta-analiz sürecine tabi tutulmuştur. Bu çalışmalardan 14’ü pozitif, üçü negatif etki büyüklüğüne sahiptir. Pozitif yönlü çalışmaların ikisi zayıf, beşi küçük, altısı orta ve biri güçlü etki büyüklüğü düzeyindedir. Gerçekleştirilen analiz sonucunda ters-yüz öğrenmenin genel etki büyüklüğü değeri rastgele etkiler modeli ile 0.077 ile 0.594 güven aralığında 0.336 olarak hesaplanmıştır (%95 CI, SE=0.132). Elde edilen bu sonuç, ters-yüz öğrenme yaklaşımının geleneksel eğitim süreçlerine kıyasla motivasyon üzerinde küçük düzeyde ve pozitif bir etkiye sahip olduğunu göstermektedir.",
        "link": "http://dx.doi.org/10.19171/uefad.1169794"
    },
    {
        "id": 17118,
        "title": "Knowledge-guided meta learning for disease prediction",
        "authors": "Qiuling Suo, Hyun Jae Cho, Jingyuan Chou, Stefan Bekiranov, Chongzhi Zang, Aidong Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-399851-2.00023-5"
    },
    {
        "id": 17119,
        "title": "Multi-Pair Text Style Transfer for Unbalanced Data via Task-Adaptive Meta-Learning",
        "authors": "Xing Han, Jessica Lundin",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.metanlp-1.4"
    },
    {
        "id": 17120,
        "title": "Optimizing Hyper Meta Learning Models",
        "authors": "G. Devika, Asha Gowda Karegowda",
        "published": "2023-9-28",
        "citations": 0,
        "abstract": "Optimizing hyper meta learning models is a critical task in the field of machine learning, as it can improve the performance, efficiency, and scalability of these models. In this chapter, the authors present an epic overview of the process of optimizing hyper meta learning models. They discuss the key steps involved in this process, including task selection, model architecture selection, hyperparameter optimization, model training, model evaluation, and deployment. They also explore the benefits of hyper meta learning models and their potential future applications in various fields. Finally, they highlight the challenges and limitations of hyper meta learning models and suggest future research directions to overcome these challenges and improve the effectiveness of these models.",
        "link": "http://dx.doi.org/10.4018/978-1-6684-7659-8.ch003"
    },
    {
        "id": 17121,
        "title": "Meta Q-network: a combination of reinforcement learning and meta learning",
        "authors": "Min Lu, Yi Wang, Wenfeng Wang",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijans.2022.125303"
    },
    {
        "id": 17122,
        "title": "Meta Q-network: a combination of reinforcement learning and meta learning",
        "authors": "Min Lu, Yi Wang, Wenfeng Wang",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijans.2022.10050329"
    },
    {
        "id": 17123,
        "title": "Toward a Meta-design Method for Learning Games",
        "authors": "Marne Bertrand, Muratet Mathieu, Sehaba Karim",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010530203700376"
    },
    {
        "id": 17124,
        "title": "Adversarial robustness in meta-learning and contrastive learning",
        "authors": "Pin-Yu Chen, Cho-Jui Hsieh",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00028-4"
    },
    {
        "id": 17125,
        "title": "Optimization Approaches in Meta-Learning Models",
        "authors": "Nidhi Arora, Ashok Sharma, Dinesh Kumar",
        "published": "2023-9-28",
        "citations": 0,
        "abstract": "This book chapter provides a comprehensive overview of optimization approaches in meta-learning, focusing on techniques and their applications. Meta-learning is a subfield of machine learning that emphasizes acquiring knowledge from previous tasks and applying the same to new tasks in order to develop the models with improved learning process. Optimization plays a crucial role in meta-learning models by enabling the effective acquisition and utilization of knowledge across tasks. This chapter provides an overview of various optimization approaches employed in meta-learning models which entail changing the model's input parameters or learning algorithms to facilitate effective learning across various tasks or domains. The methods tackle the problem of effective learning without compromising with accuracy and precision in performance focusing on the benefits of meta-learning frameworks in practical situations which may be considered as the real-world applications of these approaches.",
        "link": "http://dx.doi.org/10.4018/978-1-6684-7659-8.ch001"
    },
    {
        "id": 17126,
        "title": "Improving Generalization in Meta-Learning Via Meta-Gradient Augmentation",
        "authors": "Ren Wang, Haoliang Sun, Yuxiu Lin, Qi Wei, Yilong Yin",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4656379"
    },
    {
        "id": 17127,
        "title": "A Meta-Learning Reinforcement Training Method for Machine Learning Image-To-Image Optical Proximity Correction",
        "authors": "Albert Lin",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31224/3197"
    },
    {
        "id": 17128,
        "title": "Automated Machine Learning for Multimedia",
        "authors": "Wenwu Zhu, Xin Wang",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-88132-0_3"
    },
    {
        "id": 17129,
        "title": "Meta-Semi: A Meta-Learning Approach for Semi-Supervised Learning",
        "authors": "Yulin Wang, Jiayi Guo, Jiangshan Wang, Cheng Wu, Shiji Song, Gao Huang",
        "published": "2022-12",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26599/air.2022.9150011"
    },
    {
        "id": 17130,
        "title": "- Meta-Learning",
        "authors": "",
        "published": "2018-10-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b19011-16"
    },
    {
        "id": 17131,
        "title": "Probabilistic Adaptation for Meta-Learning",
        "authors": "Tameem Adel",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14428/esann/2023.es2023-48"
    },
    {
        "id": 17132,
        "title": "Meta-Learning in Computer Vision",
        "authors": "Wen-Feng Wang",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "Early machine learning was not end-to-end, that is, it did not directly input raw data at the input end, but based on human prior knowledge, preprocessed the raw data and used the extracted features as input. So early machine learning was also known as feature engineering. Due to the fact that the input raw data is manually processed before being used to train the model, it is impossible to avoid situations such as incorrect feature selection, inaccurate feature extraction, and even significant deviation in feature calculation results.  With the development of machine learning, especially the emergence of multi-layer neural networks, the end-to-end learning process has been achieved, marking the transition of machine learning from feature engineering to representation learning. Deep learning is further developed on this basis. Deep learning models have the ability to learn features. Because by configuring relevant parameters, multi-layer feedforward neural networks can approximate any function.  Metalearning belongs to the category of machine learning. The ultimate goal of machine learning algorithm research is to enable machines to have learning abilities that are close to those of humans. This is a very big challenge! The current mainstream machine learning methods, whether classical machine learning theories or more advanced deep learning models, cannot achieve this. The emergence of meta learning is precisely to enable machines to have learning abilities that are close to those of humans.  Machine learning theory is evolving from \"mechanical memory\" to \"active learning and application\", which is an inevitable trend. Just like a person's pursuit of a student career. At the beginning, we had relatively little consideration for learning methods, mainly relying on the matching of memory and knowledge to complete our preliminary understanding of the world. When the difficulty of knowledge increases, simple memory and matching can no longer meet the needs of learning, we have to start to pay attention to learning methods. This book will provide a learning-to-learn theory for the machine brain, which will help overcome the limitations of existing machine learning algorithms.",
        "link": "http://dx.doi.org/10.56157/etsl5404"
    },
    {
        "id": 17133,
        "title": "Explainable Artificial Intelligence (xAI) Approaches and Deep Meta-Learning Models",
        "authors": "Evren Dağlarli",
        "published": "2020-12-9",
        "citations": 19,
        "abstract": "The explainable artificial intelligence (xAI) is one of the interesting issues that has emerged recently. Many researchers are trying to deal with the subject with different dimensions and interesting results that have come out. However, we are still at the beginning of the way to understand these types of models. The forthcoming years are expected to be years in which the openness of deep learning models is discussed. In classical artificial intelligence approaches, we frequently encounter deep learning methods available today. These deep learning methods can yield highly effective results according to the data set size, data set quality, the methods used in feature extraction, the hyper parameter set used in deep learning models, the activation functions, and the optimization algorithms. However, there are important shortcomings that current deep learning models are currently inadequate. These artificial neural network-based models are black box models that generalize the data transmitted to it and learn from the data. Therefore, the relational link between input and output is not observable. This is an important open point in artificial neural networks and deep learning models. For these reasons, it is necessary to make serious efforts on the explainability and interpretability of black box models.",
        "link": "http://dx.doi.org/10.5772/intechopen.92172"
    },
    {
        "id": 17134,
        "title": "Domain generalization of deep networks for medical image segmentation via meta learning",
        "authors": "Quande Liu, Qi Dou, Cheng Chen, Pheng-Ann Heng",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-399851-2.00016-8"
    },
    {
        "id": 17135,
        "title": "Meta-federated learning",
        "authors": "Omid Aramoon, Pin-Yu Chen, Gang Qu, Yuan Tian",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-44-319037-7.00017-x"
    },
    {
        "id": 17136,
        "title": "Learning to Adapt: A Meta-learning Approach for Speaker Adaptation",
        "authors": "Ondřej Klejch, Joachim Fainberg, Peter Bell",
        "published": "2018-9-2",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2018-1244"
    },
    {
        "id": 17137,
        "title": "Rare disease classification via difficulty-aware meta learning",
        "authors": "Xiaomeng Li, Lequan Yu, Yueming Jin, Chi-Wing Fu, Lei Xing, Pheng-Ann Heng",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-399851-2.00026-0"
    },
    {
        "id": 17138,
        "title": "Meta Learning Improves Robustness and Performance in Machine Learning-Guided Protein Engineering",
        "authors": "Mason Minot, Sai T. Reddy",
        "published": "No Date",
        "citations": 2,
        "abstract": "AbstractMachine learning-guided protein engineering continues to rapidly progress, however, collecting large, well-labeled data sets remains time and resource intensive. Directed evolution and protein engineering studies often require extensive experimental processes to eliminate noise and fully label high-throughput protein sequence-function data. Meta learning methods established in other fields (e.g. computer vision and natural language processing) have proven effective in learning from noisy data, given the availability of a small data set with trusted labels and thus could be applied for protein engineering. Here, we generate yeast display antibody mutagenesis libraries and screen them for target antigen binding followed by deep sequencing. Meta learning approaches are able to learn under high synthetic and experimental noise as well as in under labeled data settings, typically outperforming baselines significantly and often requiring a fraction of the training data. Thus, we demonstrate meta learning may expedite and improve machine learning-guided protein engineering.Availability and implementationThe code used in this study is publicly available athttps://github.com/LSSI-ETH/meta-learning-for-protein-engineering.Graphical Abstract",
        "link": "http://dx.doi.org/10.1101/2023.01.30.526201"
    },
    {
        "id": 17139,
        "title": "Erratum to Meta-Semi: A Meta-Learning Approach for Semi-Supervised Learning",
        "authors": "Yulin Wang, Jiayi Guo, Jiangshan Wang, Cheng Wu, Shiji Song, Gao Huang",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26599/air.2023.9150017"
    },
    {
        "id": 17140,
        "title": "Meta-heuristics, Machine Learning, and Deep Learning Methods",
        "authors": "Hitoshi Iba",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-13-0200-8_2"
    },
    {
        "id": 17141,
        "title": "Meta-XNLG: A Meta-Learning Approach Based on Language Clustering for Zero-Shot Cross-Lingual Transfer and Generation: A Meta-Learning Approach Based on Language Clustering for Zero-Shot Cross-Lingual Transfer and Generation",
        "authors": "Kaushal Maurya, Maunendra Desarkar",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-acl.24"
    },
    {
        "id": 17142,
        "title": "Modified Model-Agnostic Meta-Learning",
        "authors": "Aashay Pawar",
        "published": "2020-12-20",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icmlant50963.2020.9355973"
    },
    {
        "id": 17143,
        "title": "Meta Learning With Medical Imaging and Health Informatics Applications",
        "authors": "",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/c2021-0-00060-2"
    },
    {
        "id": 17144,
        "title": "Soft Layer Selection with Meta-Learning for Zero-Shot Cross-Lingual Transfer",
        "authors": "Weijia Xu, Batool Haider, Jason Krone, Saab Mansour",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.metanlp-1.2"
    },
    {
        "id": 17145,
        "title": "Deep learning for robust meta-analytic estimation",
        "authors": "Evan C Carter",
        "published": "No Date",
        "citations": 1,
        "abstract": "Meta-analysis represents the promise of cumulative science--that each successive study brings us greater understanding of a given phenomenon. As such, meta-analyses are highly influential and gaining in popularity. However, there are well-known threats to the validity of meta-analytic results, such as processes like publication bias and questionable research practices which can cause researchers to massively overestimate the evidence in support of a claim. There are many statistical methods to correct for such bias, but no single method has been found to be robust in all realistic conditions. Here, I describe a method that merges statistical simulation and deep learning to achieve an unprecedented level of robust meta-analytic estimation in the face of numerous forms of bias and other historically problematic conditions. Furthermore, the resulting estimator, called DeepMA, has the unique property that it can easily evolve: As new conditions for which robustness is needed are identified, DeepMA can be re-trained to maintain high performance. Given the weaknesses that have been identified for meta-analysis, the current consensus is that it should serve as simply another data point, rather than residing at the top of the hierarchy of evidence. The novel approach I describe, however, holds the potential to eliminate these weaknesses, possibly solidifying meta-analysis as the platinum standard in scientific debate.",
        "link": "http://dx.doi.org/10.31234/osf.io/zad47"
    },
    {
        "id": 17146,
        "title": "Reinforcement learning and meta-decision making",
        "authors": "Pieter Verbeke, Tom Verguts",
        "published": "No Date",
        "citations": 0,
        "abstract": "A key aspect of cognitive flexibility is to efficiently make use of earlier experience to attain one’s goals. This requires learning, but also a modular, and more specifically hierarchical, structure. We hold that both are required but combining them leads to several computational challenges that brains and artificial agents (learn to) deal with. In a hierarchical structure, meta-decisions must be made, of which two types can be distinguished: First, a (meta-)decision may involve choosing which (lower-level) modules to select (module choice). Second, it may consist of choosing appropriate parameter settings within a module (parameter tuning). Further, prediction error monitoring may allow determining the right meta-decision (module choice or parameter tuning). We discuss computational challenges and empirical evidence relative to how these two meta-decisions may be implemented to support learning for cognitive flexibility.",
        "link": "http://dx.doi.org/10.31234/osf.io/uvfhe"
    },
    {
        "id": 17147,
        "title": "A Recent Publications Survey on Reinforcement Learning for Selecting Parameters of Meta-Heuristic and Machine Learning Algorithms",
        "authors": "Maria Chernigovskaya, Andrey Kharitonov, Klaus Turowski",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011954300003488"
    },
    {
        "id": 17148,
        "title": "Meta-Reinforcement Learning for Mastering Multiple Skills and Generalizing across Environments in Text-based Games",
        "authors": "Zhenjie Zhao, Mingfei Sun, Xiaojuan Ma",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.metanlp-1.1"
    },
    {
        "id": 17149,
        "title": "Metaclusterfl: Personalized Federated Learning on Non-Iid Data with Meta-Learning and Clustering",
        "authors": "Hui Zeng, Shiyu Xiong, Hongzhou Shi",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4656626"
    },
    {
        "id": 17150,
        "title": "Meta-Analysis to the Influence of 5E Teaching Model toward Students' Learning Outcomes",
        "authors": "Muhammad Fahrurrozi, A. Wahab Jufri, Haerul Muammar",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007297600050009"
    },
    {
        "id": 17151,
        "title": "MAML2: meta reinforcement learning via meta-learning for task categories",
        "authors": "Qiming Fu, Zhechao Wang, Nengwei Fang, Bin Xing, Xiao Zhang, Jianping Chen",
        "published": "2023-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11704-022-2037-1"
    },
    {
        "id": 17152,
        "title": "Smart task design for meta learning medical image analysis systems",
        "authors": "Cuong C. Nguyen, Youssef Dawoud, Thanh-Toan Do, Jacinto C. Nascimento, Vasileios Belagiannis, Gustavo Carneiro",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-399851-2.00019-3"
    },
    {
        "id": 17153,
        "title": "Future Research Directions",
        "authors": "Wenwu Zhu, Xin Wang",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-88132-0_5"
    },
    {
        "id": 17154,
        "title": "Meta-perspective on our learning journey",
        "authors": "Fiona Adamson, Jane Brendgen",
        "published": "2021-10-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781315161280-5"
    },
    {
        "id": 17155,
        "title": "Learning the Ropes- Meta-Analysis",
        "authors": "",
        "published": "2019-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.30824/1903-6"
    },
    {
        "id": 17156,
        "title": "Copyright",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-399851-2.00004-1"
    },
    {
        "id": 17157,
        "title": "General meta-learning paradigm based on prior-models, meta-model, meta-algorithm, and few-shot-base-model",
        "authors": "Eduardo Rivas-Posada, Mario I. Chacon-Murguia",
        "published": "2021-7-18",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn52387.2021.9533374"
    },
    {
        "id": 17158,
        "title": "Meta Reinforcement Learning with Hebbian Learning",
        "authors": "Di Wang",
        "published": "2022-10-26",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/uemcon54665.2022.9965711"
    },
    {
        "id": 17159,
        "title": "The Federated Meta-Learning with a Quartile Aggregation Method",
        "authors": "Lang Wu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4568337"
    },
    {
        "id": 17160,
        "title": "A Meta-Learning Approach for Software Refactoring",
        "authors": "Hanieh Khosravi, Abbas Rasoolzadegan",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4355385"
    },
    {
        "id": 17161,
        "title": "Learning With Nontraditional Engineering Labs: A Meta-Analysis",
        "authors": "Rachel Wong",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3102/ip.23.2009139"
    },
    {
        "id": 17162,
        "title": "5e Öğrenme Modelinin Öğrencilerin Öğrenme Ürünlerine Etkisi: Meta Analiz Çalışması",
        "authors": "Hakan SARAC",
        "published": "2017-7-15",
        "citations": 6,
        "abstract": "Araştırmada, 5E öğrenme modeli\nkullanımının öğrencilerin öğrenme ürünlerine etkisini belirlemek amacıyla meta\nanaliz çalışması yapılmıştır. 2007–2016 yılları arasında yapılmış araştırma\nproblemine uygun, meta analiz çalışmasına dahil edilebilecek istatistiksel\nverilere sahip doktora ve yüksek lisans tezleri Türkçe ve İngilizce anahtar\nkelimeler kullanılarak literatür taraması yapılmıştır. Tarama sonucunda, 5E\nöğrenme modeli kullanımının öğrencilerin öğrenme ürünlerine etkisine ilişkin\ntoplam 99 lisansüstü tez meta analize dahil edilmiş ve toplamda 186 etki\nbüyüklüğü değeri elde edilmiştir. Araştırma sonucunda derslerde 5E öğrenme\nmodeli kullanımının öğrencilerde öğrenme ürünlerine etkisinin pozitif yönde\nolduğu tespit edilmiş ve tespit edilen etki büyüklüğü değeri, rastgele etkiler\nmodeline göre 0.852 ile 1.073 güven aralığında 0.961 (% 95 CI, SE = .056)\nolarak bulunmuştur. Bu değer, Thalheimer ve Cook (2002) tarafından belirtilen\netki büyüklüğü sınıflandırmasına göre geniş düzeyde bir etki büyüklüğüdür. Araştırmada\nelde edilen 186 etki büyüklüğü değerinin 173’ü pozitif, 13’ü negatif’dir.\nAraştırmada öğrencilerin öğrenme ürünlerine, araştırmanın tez türüne,\naraştırmanın yapıldığı ders alanına ve araştırmaya katılan öğrencilerin öğrenim\ndüzeylerine göre moderatör analizler yapılmıştır. Yapılan analizler sonucunda,\nen yüksek etki büyüklüğü değerinin öğrenilen bilgilerin akılda kalıcılığında\n(ES = 1.274), doktora çalışmalarında (ES = .973), sosyal bilimler dersleri\nalanında (ES = 1.489) ve ilkokul öğrencilerinde (ES = 1.335) olduğu tespit\nedilmiştir.",
        "link": "http://dx.doi.org/10.29250/sead.306081"
    },
    {
        "id": 17163,
        "title": "Meta-combiner",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_536"
    },
    {
        "id": 17164,
        "title": "Meaningful Learning: towards a Meta-regulated Learning model in Hybrid Education",
        "authors": "Marybel Mollo-Flores, Angel Deroncele-Acosta",
        "published": "2021-10",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/laclo54177.2021.00066"
    },
    {
        "id": 17165,
        "title": "Meta-STMF: Meta-Learning Based Spatial Temporal Prediction Model Fusion Approach",
        "authors": "Liu Wei, Jia Suling",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2022.3186090"
    },
    {
        "id": 17166,
        "title": "Meta-learning for Classifying Previously Unseen Data Source into Previously Unseen Emotional Categories",
        "authors": "Gaël Guibon, Matthieu Labeau, Hélène Flamein, Luce Lefeuvre, Chloé Clavel",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.metanlp-1.9"
    },
    {
        "id": 17167,
        "title": "Understanding transfer learning and gradient-based meta-learning techniques",
        "authors": "Mike Huisman, Aske Plaat, Jan N. van Rijn",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "AbstractDeep neural networks can yield good performance on various tasks but often require large amounts of data to train them. Meta-learning received considerable attention as one approach to improve the generalization of these networks from a limited amount of data. Whilst meta-learning techniques have been observed to be successful at this in various scenarios, recent results suggest that when evaluated on tasks from a different data distribution than the one used for training, a baseline that simply finetunes a pre-trained network may be more effective than more complicated meta-learning techniques such as MAML, which is one of the most popular meta-learning techniques. This is surprising as the learning behaviour of MAML mimics that of finetuning: both rely on re-using learned features. We investigate the observed performance differences between finetuning, MAML, and another meta-learning technique called Reptile, and show that MAML and Reptile specialize for fast adaptation in low-data regimes of similar data distribution as the one used for training. Our findings show that both the output layer and the noisy training conditions induced by data scarcity play important roles in facilitating this specialization for MAML. Lastly, we show that the pre-trained features as obtained by the finetuning baseline are more diverse and discriminative than those learned by MAML and Reptile. Due to this lack of diversity and distribution specialization, MAML and Reptile may fail to generalize to out-of-distribution tasks whereas finetuning can fall back on the diversity of the learned features.",
        "link": "http://dx.doi.org/10.1007/s10994-023-06387-w"
    },
    {
        "id": 17168,
        "title": "Swarm Meta Learning",
        "authors": "Xiao Tian, Yuzhang Jiang, Hua Tianfield",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-11748-0_8"
    },
    {
        "id": 17169,
        "title": "Learning strategies",
        "authors": "John Hattie",
        "published": "2023-2-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003380542-12"
    },
    {
        "id": 17170,
        "title": "Meta-Learning Initialization vs Optimizer: Beyond 20 Ways Few-Shot Learning",
        "authors": "Aroof Aimen, Sahil Sidheekh, Hansin Ahuja, Narayanan  C. Krishnan",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4266883"
    }
]