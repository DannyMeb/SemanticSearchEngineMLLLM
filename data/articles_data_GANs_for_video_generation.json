[
    {
        "id": 20471,
        "title": "Bootstrapping Conditional GANs for Video Game Level Generation",
        "authors": "Ruben Rodriguez Torrado, Ahmed Khalifa, Michael Cerny Green, Niels Justesen, Sebastian Risi, Julian Togelius",
        "published": "2020-8",
        "citations": 23,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cog47356.2020.9231576"
    },
    {
        "id": 20472,
        "title": "Synthetic audio and video generation for language translation using GANs",
        "authors": "Quraishi Aynaan, Jethwa Jaydeep, Gupta Shiwani",
        "published": "2023",
        "citations": 0,
        "abstract": "Language barriers create a digital divide that prevents people from benefiting from the vast amount of content produced worldwide. In addition, content creators face challenges in producing content in multiple languages to reach a wider audience. To address this problem, this study proposed a solution through a survey that utilized Generative Adversarial Networks (GAN), Natural Language Processing (NPL), and Computer Vision. A Generative Adversarial Network (GAN) is a Machine Learning (ML) model in which two neural networks compete with each other by using deep learning methods to obtain more accurate predictions. The solution provided in this study can generate synthesized videos that are close to reality, ultimately bridging the language barrier and providing access to content.",
        "link": "http://dx.doi.org/10.26634/javr.1.1.19412"
    },
    {
        "id": 20473,
        "title": "Stream Generation: Markov Chains vs GANs",
        "authors": "Ricardo Jesus, Mário Antunes, Pétia Georgieva, Diogo Gomes, Rui Aguiar",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007766501770184"
    },
    {
        "id": 20474,
        "title": "G3AN++",
        "authors": "Sonam Gupta, Arti Keshari, Sukhendu Das",
        "published": "2021-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3490035.3490282"
    },
    {
        "id": 20475,
        "title": "GANs for Image Generation",
        "authors": "Xudong Mao, Qing Li",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-33-6048-8_2"
    },
    {
        "id": 20476,
        "title": "Generation of druglike molecules with generative adversarial networks (GANs)",
        "authors": "Beihong Ji, Matthew Brock",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1021/scimeetings.0c04751"
    },
    {
        "id": 20477,
        "title": "Generation of druglike molecules with generative adversarial networks (GANs)",
        "authors": "Beihong Ji, Matthew Brock",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1021/scimeetings.0c04750"
    },
    {
        "id": 20478,
        "title": "Guiding Gans: How to Control Non-Conditional Pre-Trained Gans for Conditional Image Generation",
        "authors": "Alejandro González, Manel Mateos, Felipe Perez-Stoppa, Ester Vidaña-Vila, Joan Navarro, Xavier Sevillano",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4560891"
    },
    {
        "id": 20479,
        "title": "Artifygan: Animated Face Image Generation Using Gans",
        "authors": "Iqra Bismi, Priya Khandelwal, Saniya Lande, Mohammad Masum",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4622124"
    },
    {
        "id": 20480,
        "title": "Feature Cycling Block for Improving Gans-Based Image Generation Performance",
        "authors": "Seung Park, Yong-Goo Shin",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4452070"
    },
    {
        "id": 20481,
        "title": "On Evaluating Video-based Generative Adversarial Networks (GANs)",
        "authors": "Nancy Ronquillo, Josh Harguess",
        "published": "2018-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aipr.2018.8707431"
    },
    {
        "id": 20482,
        "title": "NFT artwork generation using oscillatory activation functions in GANs",
        "authors": "Prith Sharma, Aditya Raj Sahoo, Sushant Sinha, Shubham Bharadwaj",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31224/2225"
    },
    {
        "id": 20483,
        "title": "Generative Adversarial Networks (GANs)",
        "authors": "Xudong Mao, Qing Li",
        "published": "2021",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-33-6048-8_1"
    },
    {
        "id": 20484,
        "title": "Housing GANs: Deep Generation of Housing Market Data",
        "authors": "Bilgi Yilmaz",
        "published": "2023-8-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10614-023-10456-6"
    },
    {
        "id": 20485,
        "title": "More Key Applications of GANs",
        "authors": "Xudong Mao, Qing Li",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-33-6048-8_3"
    },
    {
        "id": 20486,
        "title": "Synthetic Ultrasound Signal-Pairs Generation using Gans",
        "authors": "Mariam Fouad, Georg Schmitz",
        "published": "2023-4-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isbi53787.2023.10230481"
    },
    {
        "id": 20487,
        "title": "Text Description to Facial Sketch Generation using GANs",
        "authors": "Mohsin Tanveer, Usman Habib",
        "published": "2023-11-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icet59753.2023.10374885"
    },
    {
        "id": 20488,
        "title": "Keiki: Towards Realistic Danmaku Generation via Sequential GANs",
        "authors": "Ziqi Wang, Jialin Liu, Georgios N. Yannakakis",
        "published": "2021-8-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cog52621.2021.9619013"
    },
    {
        "id": 20489,
        "title": "Investigating Deep Convolution Conditional GANs for Electrocardiogram Generation",
        "authors": "Deepankar Nankani, Rashmi Dutta Baruah",
        "published": "2020-7",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn48605.2020.9207613"
    },
    {
        "id": 20490,
        "title": "Survey on Synthetic Data Generation, Evaluation Methods and GANs",
        "authors": "Alvaro Figueira, Bruno Vaz",
        "published": "2022-8-2",
        "citations": 55,
        "abstract": "Synthetic data consists of artificially generated data. When data are scarce, or of poor quality, synthetic data can be used, for example, to improve the performance of machine learning models. Generative adversarial networks (GANs) are a state-of-the-art deep generative models that can generate novel synthetic samples that follow the underlying data distribution of the original dataset. Reviews on synthetic data generation and on GANs have already been written. However, none in the relevant literature, to the best of our knowledge, has explicitly combined these two topics. This survey aims to fill this gap and provide useful material to new researchers in this field. That is, we aim to provide a survey that combines synthetic data generation and GANs, and that can act as a good and strong starting point for new researchers in the field, so that they have a general overview of the key contributions and useful references. We have conducted a review of the state-of-the-art by querying four major databases: Web of Sciences (WoS), Scopus, IEEE Xplore, and ACM Digital Library. This allowed us to gain insights into the most relevant authors, the most relevant scientific journals in the area, the most cited papers, the most significant research areas, the most important institutions, and the most relevant GAN architectures. GANs were thoroughly reviewed, as well as their most common training problems, their most important breakthroughs, and a focus on GAN architectures for tabular data. Further, the main algorithms for generating synthetic data, their applications and our thoughts on these methods are also expressed. Finally, we reviewed the main techniques for evaluating the quality of synthetic data (especially tabular data) and provided a schematic overview of the information presented in this paper.",
        "link": "http://dx.doi.org/10.3390/math10152733"
    },
    {
        "id": 20491,
        "title": "Generative Adversarial Networks (GANs): A Survey on Network Traffic Generation",
        "authors": "",
        "published": "2022-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18178/ijmlc.2022.12.6.1120"
    },
    {
        "id": 20492,
        "title": "MontageGAN: Generation and Assembly of Multiple Components by GANs",
        "authors": "Chean Fei Shee, Seiichi Uchida",
        "published": "2022-8-21",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icpr56361.2022.9956028"
    },
    {
        "id": 20493,
        "title": "Textile Design Generation Using GANs",
        "authors": "Raja Asim Fayyaz, Muaz Maqbool, Muhammad Hanif",
        "published": "2020-8-30",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ccece47787.2020.9255674"
    },
    {
        "id": 20494,
        "title": "I-GANs for Synthetical Infrared Images Generation",
        "authors": "Mohammad Mahdi Moradi, Reza Ghaderi",
        "published": "2022-2-23",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mvip53647.2022.9738551"
    },
    {
        "id": 20495,
        "title": "Unpaired Multi-Domain Image Generation via Regularized Conditional GANs",
        "authors": "Xudong Mao, Qing Li",
        "published": "2018-7",
        "citations": 5,
        "abstract": "In this paper, we study the problem of multi-domain image generation, the goal of which is to generate pairs of corresponding images from different domains. With the recent development in generative models, image generation has achieved great progress and has been applied to various computer vision tasks. However, multi-domain image generation may not achieve the desired performance due to the difficulty of learning the correspondence of different domain images, especially when the information of paired samples is not given. To tackle this problem, we propose Regularized Conditional GAN (RegCGAN) which is capable of learning to generate corresponding images in the absence of paired training data. RegCGAN is based on the conditional GAN, and we introduce two regularizers to guide the model to learn the corresponding semantics of different domains. We evaluate the proposed model on several tasks for which paired training data is not given, including the generation of edges and photos, the generation of faces with different attributes, etc. The experimental results show that our model can successfully generate corresponding images for all these tasks, while outperforms the baseline methods. We also introduce an approach of applying RegCGAN to unsupervised domain adaptation.",
        "link": "http://dx.doi.org/10.24963/ijcai.2018/354"
    },
    {
        "id": 20496,
        "title": "Unlimited Resolution Image Generation with R2D2-GANs",
        "authors": "Marija Jegorova, Antti Ilari Karjalainen, Jose Vazquez, Timothy M. Hospedales",
        "published": "2020-10-5",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ieeeconf38699.2020.9389260"
    },
    {
        "id": 20497,
        "title": "Attention-Aware Generative Adversarial Networks (ATA-GANs)",
        "authors": "Dimitris Kastaniotis, Ioanna Ntinou, Dimitrios Tsourounis, George Economou, Spiros Fotopoulos",
        "published": "2018-6",
        "citations": 23,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ivmspw.2018.8448850"
    },
    {
        "id": 20498,
        "title": "Quantitative Evaluation of Molecular Generation Performance of Graph-based GANs",
        "authors": "Jinli Zhang, Zhenbo Wang, Zongli Jiang, Man Wu, Chen Li, Yoshihiro Yamanishi",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nDeep generative models have been widely used in molecular generation tasks because they can save time and cost in drug development compared with traditional methods. Previous studies based on generative adversarial network (GAN) models typically employ reinforcement learning (RL) to constrain chemical properties, resulting in efficient and novel molecules. However, such models have poor performance in generating molecules due to instability in training. Therefore, quantitative evaluation of existing molecular generation models, especially GAN models, is necessary. This study aims to evaluate the performance of discrete GAN models using RL in molecular generation tasks and explore the impact of different factors on model performance. Through evaluation experiments on QM9 and ZINC datasets, the results show that noise sampling distributions, training epochs, and training data volumes can affect the performance of molecular generation. Finally, we provide strategies for stable training and improved performance for GAN models.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3431009/v1"
    },
    {
        "id": 20499,
        "title": "Conditional GANs for painting generation",
        "authors": "Adeel Mufti, Biagio Antonelli, Julius Monello",
        "published": "2020-1-31",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2556551"
    },
    {
        "id": 20500,
        "title": "Future Generation Wireless Video Communication Systems",
        "authors": "",
        "published": "2018-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781482290097-14"
    },
    {
        "id": 20501,
        "title": "Self-Attention Mechanism in GANs for Molecule Generation",
        "authors": "Sandeep Chinnareddy, Pranav Grandhi, Apurva Narayan",
        "published": "2021-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icmla52953.2021.00017"
    },
    {
        "id": 20502,
        "title": "Conditional Sig-Wasserstein GANs for Time Series Generation",
        "authors": "Hao Ni, Lukasz Szpruch, Magnus Wiese, Shujian Liao, Baoren Xiao",
        "published": "No Date",
        "citations": 42,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3623086"
    },
    {
        "id": 20503,
        "title": "A long video caption generation algorithm for big video data retrieval",
        "authors": "Songtao Ding, Shiru Qu, Yuling Xi, Shaohua Wan",
        "published": "2019-4",
        "citations": 112,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.future.2018.10.054"
    },
    {
        "id": 20504,
        "title": "CLIP2GAN: Towards Bridging Text with the Latent Space of GANs",
        "authors": "Yixuan Wang, Wengang Zhou, Jianmin Bao, Weilun Wang, Li Li, Houqiang Li",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tcsvt.2023.3294261"
    },
    {
        "id": 20505,
        "title": "Partial Label Learning via GANs With Multiclass SVMs and Information Maximization",
        "authors": "Jinfu Fan, Zhongjie Wang",
        "published": "2022-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tcsvt.2022.3192907"
    },
    {
        "id": 20506,
        "title": "VIVE3D: Viewpoint-Independent Video Editing using 3D-Aware GANs",
        "authors": "Anna Frühstück, Nikolaos Sarafianos, Yuanlu Xu, Peter Wonka, Tony Tung",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00432"
    },
    {
        "id": 20507,
        "title": "Improving Time Series Generation of GANs through Soft Dynamic Time Warping Loss",
        "authors": "Xiaozhuo Yu, Fakhri Karray",
        "published": "2022-10-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/smc53654.2022.9945231"
    },
    {
        "id": 20508,
        "title": "Spatio-temporal generation of morphological Plant features for yield prediction before harvest from Visual Image input using Progressively Growing GANs",
        "authors": "Dhruv Sheth",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/essoar.10509323.1"
    },
    {
        "id": 20509,
        "title": "Deformable GANs for Pose-Based Human Image Generation",
        "authors": "Aliaksandr Siarohin, Enver Sangineto, Stephane Lathuiliere, Nicu Sebe",
        "published": "2018-6",
        "citations": 302,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr.2018.00359"
    },
    {
        "id": 20510,
        "title": "Procedural Generation using Spatial GANs for Region-Specific Learning of Elevation Data",
        "authors": "Ryan J. Spick, Peter Cowling, James Alfred Walker",
        "published": "2019-8",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cig.2019.8848120"
    },
    {
        "id": 20511,
        "title": "Self-Supervised Video GANs: Learning for Appearance Consistency and Motion Coherency",
        "authors": "Sangeek Hyun, Jihwan Kim, Jae-Pil Heo",
        "published": "2021-6",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr46437.2021.01068"
    },
    {
        "id": 20512,
        "title": "Spatio-temporal generation of morphological Plant features for yield prediction before harvest from Visual Image input using Progressively Growing GANs",
        "authors": "Dhruv Sheth",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/essoar.10509323.2"
    },
    {
        "id": 20513,
        "title": "High-quality multispectral image generation using Conditional GANs",
        "authors": "Ayush Soni, Alexander Loui, Scott Brown, Carl Salvaggio",
        "published": "2020-1-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2352/issn.2470-1173.2020.8.imawm-086"
    },
    {
        "id": 20514,
        "title": "Fake Data Generation for Medical Image Augmentation using GANs",
        "authors": "Donghwan Kim, Jaehan Joo, Suk Chan Kim",
        "published": "2022-2-21",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icaiic54071.2022.9722700"
    },
    {
        "id": 20515,
        "title": "Naval Cybersecurity in the Age of AI: deceptive ISAR Images Generation with GANs",
        "authors": "Giulio Meucci, Bertan Karahoda, Amir Hossein Oveis, Francesco Mancuso, Edmond Jajaga, Alessandro Cantelli-Forti",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Navigational systems, the heart of maritime oper- ations, face escalating cybersecurity risks due to their system of systems nature and reliance on diverse suppliers. Amid concerns about supply chain attacks and insider threats, the potential for malicious radar image injections, including Inverse Synthetic Aperture Radar (ISAR) images, is emerging. Such manipulations can critically undermine navigational integrity through the generation of decoy targets, the strategic relocation of existing ones, and the effective concealment of additional targets. We have identified where an Advanced Persistent Threat (APT) could be concealed within the processing chain of a modern radar system. This study demonstrates the potential of APTs to exploit Generative Adversarial Networks (GANs) for the creation of deceptive ISAR images, thereby spotlighting this previously unexplored threat vector. Our findings offer novel insights into bolstering maritime cybersecurity in an increasingly AI-dominated landscape. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23709846.v2"
    },
    {
        "id": 20516,
        "title": "Noise Homogenization via Multi-Channel Wavelet Filtering for High-Fidelity Sample Generation in Gans",
        "authors": "Shaoning Zeng, Bob Zhang",
        "published": "2021-7-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icme51207.2021.9428452"
    },
    {
        "id": 20517,
        "title": "Naval Cybersecurity in the Age of AI: deceptive ISAR Images Generation with GANs",
        "authors": "Giulio Meucci, Bertan Karahoda, Amir Hossein Oveis, Francesco Mancuso, Edmond Jajaga, Alessandro Cantelli-Forti",
        "published": "No Date",
        "citations": 1,
        "abstract": "<p>Navigational systems, the heart of maritime oper- ations, face escalating cybersecurity risks due to their system of systems nature and reliance on diverse suppliers. Amid concerns about supply chain attacks and insider threats, the potential for malicious radar image injections, including Inverse Synthetic Aperture Radar (ISAR) images, is emerging. Such manipulations can critically undermine navigational integrity through the generation of decoy targets, the strategic relocation of existing ones, and the effective concealment of additional targets. We have identified where an Advanced Persistent Threat (APT) could be concealed within the processing chain of a modern radar system. This study demonstrates the potential of APTs to exploit Generative Adversarial Networks (GANs) for the creation of deceptive ISAR images, thereby spotlighting this previously unexplored threat vector. Our findings offer novel insights into bolstering maritime cybersecurity in an increasingly AI-dominated landscape. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23709846.v1"
    },
    {
        "id": 20518,
        "title": "Naval Cybersecurity in the Age of AI: deceptive ISAR Images Generation with GANs",
        "authors": "Giulio Meucci, Bertan Karahoda, Amir Hossein Oveis, Francesco Mancuso, Edmond Jajaga, Alessandro Cantelli-Forti",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Navigational systems, the heart of maritime oper- ations, face escalating cybersecurity risks due to their system of systems nature and reliance on diverse suppliers. Amid concerns about supply chain attacks and insider threats, the potential for malicious radar image injections, including Inverse Synthetic Aperture Radar (ISAR) images, is emerging. Such manipulations can critically undermine navigational integrity through the generation of decoy targets, the strategic relocation of existing ones, and the effective concealment of additional targets. We have identified where an Advanced Persistent Threat (APT) could be concealed within the processing chain of a modern radar system. This study demonstrates the potential of APTs to exploit Generative Adversarial Networks (GANs) for the creation of deceptive ISAR images, thereby spotlighting this previously unexplored threat vector. Our findings offer novel insights into bolstering maritime cybersecurity in an increasingly AI-dominated landscape. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23709846"
    },
    {
        "id": 20519,
        "title": "The impact of next-generation video on traditional media companies and industries",
        "authors": "Eli Noam",
        "published": "2021-1-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4337/9781800375048.00013"
    },
    {
        "id": 20520,
        "title": "Fast Video Quality Enhancement using GANs",
        "authors": "Leonardo Galteri, Lorenzo Seidenari, Marco Bertini, Tiberio Uricchio, Alberto Del Bimbo",
        "published": "2019-10-15",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3343031.3350592"
    },
    {
        "id": 20521,
        "title": "基于Transformer-GANs生成有风格调节的音乐",
        "authors": "Weining Wang, Jiahui Li, Yifan Li, Xiaofen Xing",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1631/fitee.2300359"
    },
    {
        "id": 20522,
        "title": "Spectral-GANs for High-Resolution 3D Point-cloud Generation",
        "authors": "Sameera Ramasinghe, Salman Khan, Nick Barnes, Stephen Gould",
        "published": "2020-10-24",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iros45743.2020.9341265"
    },
    {
        "id": 20523,
        "title": "Differentially private synthetic medical data generation using convolutional GANs",
        "authors": "Amirsina Torfi, Edward A. Fox, Chandan K. Reddy",
        "published": "2022-3",
        "citations": 31,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ins.2021.12.018"
    },
    {
        "id": 20524,
        "title": "Automatic Generation of Lymphoma Post-Treatment PETs using Conditional-GANs",
        "authors": "Gabriel Silva, Ines Domingues, Hugo Duarte, Joao A. M. Santos",
        "published": "2019-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dicta47822.2019.8945835"
    },
    {
        "id": 20525,
        "title": "Human trajectory prediction and generation using LSTM models and GANs",
        "authors": "Luca Rossi, Marina Paolanti, Roberto Pierdicca, Emanuele Frontoni",
        "published": "2021-12",
        "citations": 40,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patcog.2021.108136"
    },
    {
        "id": 20526,
        "title": "GANs, GANs, and More GANs",
        "authors": "Micheal Lanham",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-7092-9_4"
    },
    {
        "id": 20527,
        "title": "Synthetic and Private Smart Health Care Data Generation using GANs",
        "authors": "Sana Imtiaz, Muhammad Arsalan, Vladimir Vlassov, Ramin Sadre",
        "published": "2021-7",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icccn52240.2021.9522203"
    },
    {
        "id": 20528,
        "title": "Occlusion-aware Unsupervised Light Field Depth Estimation based on Muti-Scale GANs",
        "authors": "Wenbin Yan, Xiaogang Zhang, Hua Chen",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tcsvt.2024.3359661"
    },
    {
        "id": 20529,
        "title": "Context-Gan: Controllable Context Image Generation Using Gans",
        "authors": "Marc-Adrien Hostin, Vladimir Sivtsov, Shahram Attarian, David Bendahan, Marc-Emmanuel Bellemare",
        "published": "2023-4-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isbi53787.2023.10230602"
    },
    {
        "id": 20530,
        "title": "Appearance and Pose-Conditioned Human photograph generation using Deformable GANs",
        "authors": "Prof. Noshir Tarapore",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "In this study, we address the challenge of generating images of individuals based on pose and appearance data. Specifically, we take an image, xa, of an individual and a target pose, P (xb), extracted from another image, xb. We then generate a new image of the same individual in the target pose, P (xb), while preserving the visual details from xa. To manage pixel-to-pixel misalignments caused by pose differences between P (xa) and P (xb), we incorporate deformable skip connections in our Generative Adversarial Network’s generator. Additionally, we propose a nearest-neighbour loss as an alternative to the standard L1 and L2 losses to match the texture of the generated image with the target image. Our approach demonstrates competitive quantitative and qualitative results using standard datasets and protocols recently proposed for this task. We also carry out a comprehensive evaluation using off-the-shelf person-identification (Re-id) systems trained with person-generation-based augmented data, a key application for this task. Our experiments reveal that our Deformable GANs can significantly boost Re-id accuracy, surpassing data-augmentation techniques specifically trained using Re-identification losses. index Terms—Conditional GAN, Image Generation, Deformable Objects, Human Pose.",
        "link": "http://dx.doi.org/10.55041/ijsrem27604"
    },
    {
        "id": 20531,
        "title": "Keyphrase Generation with GANs in Low-Resources Scenarios",
        "authors": "Giuseppe Lancioni, Saida S.Mohamed, Beatrice Portelli, Giuseppe Serra, Carlo Tasso",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.sustainlp-1.12"
    },
    {
        "id": 20532,
        "title": "Image Generation with Gans-based Techniques: A Survey",
        "authors": "Shirin Nasr Esfahani, Shahram Latifi",
        "published": "2019-10-31",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5121/ijcsit.2019.11503"
    },
    {
        "id": 20533,
        "title": "Tackling the exponential scaling of signature-based GANs for high-dimensional financial time series generation",
        "authors": "Fernando De Meer, Peter Schwendner, Marcus Wunsch",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3942764"
    },
    {
        "id": 20534,
        "title": "Generation and Evaluation of Tabular Data in Different Domains Using Gans",
        "authors": "Persevearance Marecha, Lu Ye",
        "published": "2023-5-24",
        "citations": 0,
        "abstract": "Deep learning techniques like Generative Adversarial Networks (GANs) provide solutions in many domains where real data needs to be kept private. Synthesizing tabular data is difficult because of its high complexity. Tabular data usually contains a mixture of discrete and continuous data, which is not an easy model to build. The contributions made in this paper include training and generating data with the original Vanilla Gan, then CGan and WGan-Gp and WCGan-Gp which performs better than the former. The Adult Income Census dataset mainly focuses on predicting whether income exceeds 50,000 per year based on census data, then comparing the accuracy of machine learning models and calculating the F1 scores. Then the use of TimeGan on the stock dataset, comparing synthetic data vs real data. This paper will explore the use of GANs for generating and evaluating tabular data in different domains.",
        "link": "http://dx.doi.org/10.9734/ajrcos/2023/v16i1331"
    },
    {
        "id": 20535,
        "title": "Diverse Image Generation via Self-Conditioned GANs",
        "authors": "Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, Antonio Torralba",
        "published": "2020-6",
        "citations": 39,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr42600.2020.01429"
    },
    {
        "id": 20536,
        "title": "Vehicle trajectory prediction and generation using LSTM models and GANs",
        "authors": "Luca Rossi, Andrea Ajmar, Marina Paolanti, Roberto Pierdicca",
        "published": "2021-7-1",
        "citations": 13,
        "abstract": "Vehicles’ trajectory prediction is a topic with growing interest in recent years, as there are applications in several domains ranging from autonomous driving to traffic congestion prediction and urban planning. Predicting trajectories starting from Floating Car Data (FCD) is a complex task that comes with different challenges, namely Vehicle to Infrastructure (V2I) interaction, Vehicle to Vehicle (V2V) interaction, multimodality, and generalizability. These challenges, especially, have not been completely explored by state-of-the-art works. In particular, multimodality and generalizability have been neglected the most, and this work attempts to fill this gap by proposing and defining new datasets, metrics, and methods to help understand and predict vehicle trajectories. We propose and compare Deep Learning models based on Long Short-Term Memory and Generative Adversarial Network architectures; in particular, our GAN-3 model can be used to generate multiple predictions in multimodal scenarios. These approaches are evaluated with our newly proposed error metrics N-ADE and N-FDE, which normalize some biases in the standard Average Displacement Error (ADE) and Final Displacement Error (FDE) metrics. Experiments have been conducted using newly collected datasets in four large Italian cities (Rome, Milan, Naples, and Turin), considering different trajectory lengths to analyze error growth over a larger number of time-steps. The results prove that, although LSTM-based models are superior in unimodal scenarios, generative models perform best in those where the effects of multimodality are higher. Space-time and geographical analysis are performed, to prove the suitability of the proposed methodology for real cases and management services.",
        "link": "http://dx.doi.org/10.1371/journal.pone.0253868"
    },
    {
        "id": 20537,
        "title": "Video platforms",
        "authors": "Eli Noam",
        "published": "2021-1-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4337/9781800375048.00009"
    },
    {
        "id": 20538,
        "title": "GPR-GANs: Generation of Synthetic Ground Penetrating Radargrams Using Generative Adversarial Networks",
        "authors": "Ahtisham Fazeel, Jan Rottmayer, Rajat Mehta, Naim Bajcinca",
        "published": "2021-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iwagpr50767.2021.9843171"
    },
    {
        "id": 20539,
        "title": "Controlled time series generation for automotive software-in-the-loop testing using GANs",
        "authors": "Dhasarathy Parthasarathy, Karl Backstrom, Jens Henriksson, Solrun Einarsdottir",
        "published": "2020-8",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aitest49225.2020.00013"
    },
    {
        "id": 20540,
        "title": "Increasing Video Perceptual Quality with GANs and Semantic Coding",
        "authors": "Leonardo Galteri, Marco Bertini, Lorenzo Seidenari, Tiberio Uricchio, Alberto Del Bimbo",
        "published": "2020-10-12",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3394171.3413508"
    },
    {
        "id": 20541,
        "title": "Versatile Video Coding: a Next-generation Video Coding Standard",
        "authors": "Seishi Takamura",
        "published": "2019-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.53829/ntr201906gls"
    },
    {
        "id": 20542,
        "title": "Towards EEG Generation Using GANs for BCI Applications",
        "authors": "Fatemeh Fahimi, Zhuo Zhang, Wooi Boon Goh, Kai Keng Ang, Cuntai Guan",
        "published": "2019-5",
        "citations": 28,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bhi.2019.8834503"
    },
    {
        "id": 20543,
        "title": "Securing Federated GANs: Enabling Synthetic Data Generation for Health Registry Consortiums",
        "authors": "Narasimha Raghavan Veeraragavan, Jan Franz Nygård",
        "published": "2023-8-29",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3600160.3605041"
    },
    {
        "id": 20544,
        "title": "Utilizing GANs for Synthetic Well Logging Data Generation: a Step Towards Revolutionizing Near-Field Exploration",
        "authors": "A.A. Al-Fakih, S.I. Kaka, A. Koeshidayatullah",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3997/2214-4609.202471016"
    },
    {
        "id": 20545,
        "title": "SAR image generation using GANs with azimuth constraints for target classification",
        "authors": "Yann Giry-Fouquet, Alexandre Baussard, Cyrille Enderli, Tristan Porges",
        "published": "2021-9-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2599132"
    },
    {
        "id": 20546,
        "title": "Beyond Simple Images: Human Knowledge-Guided GANs for Clinical Data Generation",
        "authors": "Devendra Singh Dhami, Mayukh Das, Sriraam Natarajan",
        "published": "2021-9",
        "citations": 3,
        "abstract": "While Generative Adversarial Networks (GANs) have accelerated the use of generative modelling within the machine learning community, most of the adaptations of GANs are restricted to images. The use of GANs to generate clinical data has been rare due to the inability of GANs to faithfully capture the intrinsic relationships between features given a small amount of observational data. We hypothesize and verify that this challenge can be mitigated by incorporating rich domain knowledge in the form of expert advice in the generative process. Specifically, we propose human-allied GANs that uses correlation advice from humans to create synthetic clinical data. We construct a system that takes a symbolic representation of the expert advice and converts it into constraints on correlation of the features during the generative process. Our empirical evaluation demonstrates (a) the superiority of our approach over other GAN models, (b) the importance of incorporating advice over instance noise and (c) an initial framework for incorporation of privacy in our model while capturing the relationships between features.",
        "link": "http://dx.doi.org/10.24963/kr.2021/24"
    },
    {
        "id": 20547,
        "title": "Quant GANs: deep generation of financial time series",
        "authors": "Magnus Wiese, Robert Knobloch, Ralf Korn, Peter Kretschmer",
        "published": "2020-9-1",
        "citations": 107,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/14697688.2020.1730426"
    },
    {
        "id": 20548,
        "title": "Generative Adversarial Networks (GANs) Video Framework: A Systematic Literature Review",
        "authors": "Muhammad Hamza, Sibghat Ullah Bazai, Muhammad Imran Ghafoor, Shafi Ullah, Saira Akram, Muhammad Shahzeb Khan",
        "published": "2023-3-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icepecc57281.2023.10209475"
    },
    {
        "id": 20549,
        "title": "Video: Substrate contamination during withdrawal from a suspension",
        "authors": "Alban Sauret, Adrien Gans, Benedicte Colnet, Guillaume Saingier, Brian Dincau, Martin Bazant, Emilie Dressaire",
        "published": "2018-11-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1103/aps.dfd.2018.gfm.v0081"
    },
    {
        "id": 20550,
        "title": "GANs for generation of synthetic ultrasound images from small datasets",
        "authors": "Lennart Maack, Lennart Holstein, Alexander Schlaefer",
        "published": "2022-7-1",
        "citations": 3,
        "abstract": "Abstract\nThe task of medical image classification is increasingly supported by algorithms. Deep learning methods like convolutional neural networks (CNNs) show superior performance in medical image analysis but need a high-quality training dataset with a large number of annotated samples. Particularly in the medical domain, the availability of such datasets is rare due to data privacy or the lack of data sharing practices among institutes. Generative adversarial networks (GANs) are able to generate high quality synthetic images. This work investigates the capabilities of different state-of-the-art GAN architectures in generating realistic breast ultrasound images if only a small amount of training data is available. In a second step, these synthetic images are used to augment the real ultrasound image dataset utilized for training CNNs. The training of both GANs and CNNs is conducted with systematically reduced dataset sizes. The GAN architectures are capable of generating realistic ultrasound images. GANs using data augmentation techniques outperform the baseline Style- GAN2 with respect to the Frechet Inception distance by up to 64.2%. CNN models trained with additional synthetic data outperform the baseline CNN model using only real data for training by up to 15.3% with respect to the F1 score, especially for datasets containing less than 100 images. As a conclusion, GANs can successfully be used to generate synthetic ultrasound images of high quality and diversity, improve classification performance of CNNs and thus provide a benefit to computer-aided diagnostics.",
        "link": "http://dx.doi.org/10.1515/cdbme-2022-0005"
    },
    {
        "id": 20551,
        "title": "Analysis of Image Generation by different Generator in GANs",
        "authors": "Jiabei He, Yuzheng Nie, Ziwen Mao",
        "published": "2021-4-1",
        "citations": 0,
        "abstract": "Abstract\nGAN is very useful in the field of image generation. Many related GANs have been proposed for generating images from the description. However, the research about analysis of image generation by different Generator in GANs is still insufficient. In this paper, different methods such as CNN and Resnet are used as the Generator in GANs for image generation. The subjective evaluation is used to analyze the performance of different generators of GAN. The result shows that the CNN-based generator performs better than the Resnet-based generator. And the increase of the number of parameters in the model will change the image quality. The analysis of different methods as the generator in GAN has a great referential significance in the field of image generation.",
        "link": "http://dx.doi.org/10.1088/1742-6596/1903/1/012061"
    },
    {
        "id": 20552,
        "title": "Spatially Adaptive Losses for Video Super-resolution with GANs",
        "authors": "Xijun Wang, Alice Lucas, Santiago Lopez-Tapia, Xinyi Wu, Rafael Molina, Aggelos K. Katsaggelos",
        "published": "2019-5",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp.2019.8682742"
    },
    {
        "id": 20553,
        "title": "Sparse GANs for Thermal Infrared Image Generation From Optical Image",
        "authors": "Xiaoyan Qian, Miao Zhang, Feng Zhang",
        "published": "2020",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2020.3024576"
    },
    {
        "id": 20554,
        "title": "Market power in cloud video",
        "authors": "Eli Noam",
        "published": "2021-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4337/9781800375024.00010"
    },
    {
        "id": 20555,
        "title": "Synthetic Power Line Communications Channel Generation with Autoencoders and GANs",
        "authors": "Davide Righini, Nunzio A. Letizia, Andrea M. Tonello",
        "published": "2019-10",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/smartgridcomm.2019.8909700"
    },
    {
        "id": 20556,
        "title": "Anime face generation using DC-GANs",
        "authors": "Deepali Joshi, Shivam Sonawane, Tejas Bhat, Vedika Jumbad, Pallavi Wasade, Sakshi Zod",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/5.0182666"
    },
    {
        "id": 20557,
        "title": "Market power in cloud video",
        "authors": "Eli Noam",
        "published": "2021-1-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4337/9781800375048.00010"
    },
    {
        "id": 20558,
        "title": "Long-Term Video Generation with Evolving Residual Video Frames",
        "authors": "Nayoung Kim, Je-Won Kang",
        "published": "2018-10",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icip.2018.8451079"
    },
    {
        "id": 20559,
        "title": "Business models for video clouds",
        "authors": "Eli Noam",
        "published": "2021-1-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4337/9781800375048.00011"
    },
    {
        "id": 20560,
        "title": "Real-world evidence generation with David Thompson",
        "authors": "David Thompson",
        "published": "2020-1-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2217/vjbm-2020-0001"
    },
    {
        "id": 20561,
        "title": "CPPN2GAN",
        "authors": "Jacob Schrum, Vanessa Volz, Sebastian Risi",
        "published": "2020-6-25",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3377930.3389822"
    },
    {
        "id": 20562,
        "title": "Contextual RNN-GANs for Abstract Reasoning Diagram Generation",
        "authors": "Viveka Kulharia, Arnab Ghosh, Amitabha Mukerjee, Vinay Namboodiri, Mohit Bansal",
        "published": "2017-2-12",
        "citations": 3,
        "abstract": "\n      \n        Understanding object motions and transformations is a core problem in computer science. Modeling sequences of evolving images may provide better representations and models of motion and may ultimately be used for forecasting or simulation. Diagrammatic Abstract Reasoning is an avenue in which diagrams evolve in complex patterns and one needs to infer the underlying pattern sequence and generate the next image in the sequence. For this, we develop a novel Contextual Generative Adversarial Network based on Recurrent Neural Networks (Context-RNN-GANs), where both the generator and the discriminator modules are based on contextual history and the adversarial discriminator guides the generator to produce realistic images for the particular time step in the image sequence. We employ the Context-RNN-GAN model (and its variants) on a novel dataset of Diagrammatic Abstract Reasoning as well as perform initial evaluations on a next-frame prediction task of videos. Empirically, we show that our Context-RNN-GAN model performs competitively with 10th-grade human performance but there is still scope for interesting improvements as compared to college-grade human performance.\n      \n    ",
        "link": "http://dx.doi.org/10.1609/aaai.v31i1.10738"
    },
    {
        "id": 20563,
        "title": "The Applicability of Cycle GANs for Pupil and Eyelid Segmentation, Data Generation and Image Refinement",
        "authors": "Wolfgang Fuhl, David Geisler, Wolfgang Rosenstiel, Enkelejda Kasneci",
        "published": "2019-10",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccvw.2019.00541"
    },
    {
        "id": 20564,
        "title": "Audiovision and  Gesamtkunstwerk : The Aesthetics of First- and Second-Generation Industrial Music Video",
        "authors": "Michael Goddard",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5040/9781501313943.ch-015"
    },
    {
        "id": 20565,
        "title": "Video: Next Generation Science in Italy",
        "authors": "",
        "published": "2021-6-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/d43978-021-00078-7"
    },
    {
        "id": 20566,
        "title": "Synthetic demand data generation for individual electricity consumers : Generative Adversarial Networks (GANs)",
        "authors": "Bilgi Yilmaz, Ralf Korn",
        "published": "2022-8",
        "citations": 20,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.egyai.2022.100161"
    },
    {
        "id": 20567,
        "title": "Corneal endothelial image segmentation training data generation using GANs. Do experts need to annotate?",
        "authors": "Adrian Kucharski, Anna Fabijańska",
        "published": "2023-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.bspc.2023.104985"
    },
    {
        "id": 20568,
        "title": "Generation And Detection of Deepfakes using Generative Adversarial Networks (GANs) and Affine Transformation",
        "authors": "J. Vijaya, Amaan A. Kazi, Kishan G. Mishra, Avala Praveen",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10307811"
    },
    {
        "id": 20569,
        "title": "Enabling the Encoder-Empowered GAN-based Video Generators for Long Video Generation",
        "authors": "Jingbo Yang, Adrian G. Bors",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10222725"
    },
    {
        "id": 20570,
        "title": "SAR video generation of MIMO video SAR with beat frequency division FMCW",
        "authors": "Seok Kim",
        "published": "2017-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icspcs.2017.8270460"
    }
]