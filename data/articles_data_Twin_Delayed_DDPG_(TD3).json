[
    {
        "id": 16771,
        "title": "Improvement of the DDPG algorithm via twin delayed DDPG (TD3) on vertical rocket landing control system",
        "authors": "Faisal Amir Maz, Prawito Prajitno, Rika Andiarti, Rini Akmeliawati, Djati Handoko, Sastra Kusuma Wijaya, Larasmoyo Nugroho",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/5.0181658"
    },
    {
        "id": 16772,
        "title": "Maintaining the Frequency of AI-based Power System Model using Twin Delayed DDPG(TD3) Implementation",
        "authors": "Rohan Dubey, Renuka Loka, Alivelu Manga Parimi",
        "published": "2022-1-21",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/parc52418.2022.9726615"
    },
    {
        "id": 16773,
        "title": "Federated Transfer Learning for Authentication and Privacy Preservation Using Novel Supportive Twin Delayed DDPG (S-TD3) Algorithm for IIoT",
        "authors": "Arumugam K, Srimathi J, Sudhanshu Maurya, Senoj Joseph, Anju Asokan, Poongodi M, Abdullah A. Algethami, Mounir Hamdi, Hafiz Tayyab Rauf",
        "published": "2021-11-23",
        "citations": 29,
        "abstract": "The Industrial Internet of Things (IIoT) has led to the growth and expansion of various new opportunities in the new Industrial Transformation. There have been notable challenges regarding the security of data and challenges related to privacy when collecting real-time and automatic data while observing applications in the industry. This paper proposes an Federated Transfer Learning for Authentication and Privacy Preservation Using Novel Supportive Twin Delayed DDPG (S-TD3) Algorithm for IIoT. In FT-Block (Federated transfer learning blockchain), several blockchains are applied to preserve privacy and security for all types of industrial applications. Additionally, by introducing the authentication mechanism based on transfer learning, blockchains can enhance the preservation and security standards for industrial applications. Specifically, Novel Supportive Twin Delayed DDPG trains the user model to authenticate specific regions. As it is considered one of the most open and scalable interacting platforms of information, it successfully helps in the positive transfer of different kinds of data between devices in more significant and local operations of the industry. It is mainly due to a single authentication factor, and the poor adaptation to regular increases in the number of users and different requirements that make the current authentication mechanism suffer a lot in IIoT. As a result, it has been very clearly observed that the given solutions are very useful.",
        "link": "http://dx.doi.org/10.3390/s21237793"
    },
    {
        "id": 16774,
        "title": "Towards Safe and Efficient Modular Path Planning using Twin Delayed DDPG",
        "authors": "Marawan Azmy Hebaish, Ahmed Hussein, Amr El-Mougy",
        "published": "2022-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/vtc2022-spring54318.2022.9860536"
    },
    {
        "id": 16775,
        "title": "Continuous Multi-objective Zero-touch Network Slicing via Twin Delayed DDPG and OpenAI Gym",
        "authors": "Farhad Rezazadeh, Hatim Chergui, Luis Alonso, Christos Verikoukis",
        "published": "2020-12",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/globecom42002.2020.9322237"
    },
    {
        "id": 16776,
        "title": "Time-attenuating Twin Delayed DDPG for Quadrotor Tracking Control",
        "authors": "Boyuan Deng, Jian Sun, Zhuo Li, Gang Wang",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/ccc58697.2023.10241100"
    },
    {
        "id": 16777,
        "title": "Continuous control of seven-axis collaborative manipulator based on optimized twin delayed DDPG",
        "authors": "C. Xu, H. Yang, W. Liao, X. Zhang",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1049/icp.2022.1990"
    },
    {
        "id": 16778,
        "title": "A Dueling Twin Delayed DDPG Architecture for mobile robot navigation",
        "authors": "Haoge Jiang, Kong-Wah Wan, Han Wang, Xudong Jiang",
        "published": "2022-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icarcv57592.2022.10004320"
    },
    {
        "id": 16779,
        "title": "Research on the parking planning algorithm based on DDPG and TD3",
        "authors": "Miaozeng Du",
        "published": "2022-10-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2640901"
    },
    {
        "id": 16780,
        "title": "Low-Level Control of a Quadrotor using Twin Delayed Deep Deterministic Policy Gradient (TD3)",
        "authors": "Mazen Shehab, Ahmed Zaghloul, Ayman El-Badawy",
        "published": "2021-11-10",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cce53527.2021.9633086"
    },
    {
        "id": 16781,
        "title": "Constant Overpotential Fast Charging for Lithium-Ion Battery with Twin Delayed DDPG Algorithm",
        "authors": "Xiaofeng Yang, Zhongbao Wei, Liang Du",
        "published": "2022-6-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/itec53557.2022.9814023"
    },
    {
        "id": 16782,
        "title": "Twin Delayed DDPG based Dynamic Power Allocation for Mobility in IoRT",
        "authors": "Homayun Kabir, Mau-Luen Tham, Yoong Choon Chang",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.24138/jcomss-2022-0141"
    },
    {
        "id": 16783,
        "title": "Twin Delayed Deep Deterministic Policy Gradient (TD3) Based Virtual Inertia Control for Inverter-Interfacing DGs in Microgrids",
        "authors": "Osarodion Emmanuel Egbomwan, Shichao Liu, Hicham Chaoui",
        "published": "2023-6",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/jsyst.2022.3222262"
    },
    {
        "id": 16784,
        "title": "Neural Style Transfer with Twin-Delayed DDPG for Shared Control of Robotic Manipulators",
        "authors": "Raul Fernandez-Fernandez, Marco Aggravi, Paolo Robuffo Giordano, Juan G. Victores, Claudio Pacchierotti",
        "published": "2022-5-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icra46639.2022.9812245"
    },
    {
        "id": 16785,
        "title": "Comparison of MPPT based on Deep Reinforcement Learning by DQN, DDPG and TD3",
        "authors": "Jayandi Panggabean, Nana Sutisna, Infall Syafalni, Trio Adiono",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/apsipaasc58517.2023.10317341"
    },
    {
        "id": 16786,
        "title": "Twin Delayed DDPG based Dynamic Power Allocation for Internet of Robotic Things",
        "authors": "Homayun Kabir, Mau-Luen Tham, Yoong Choon Chang",
        "published": "2022-9-22",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/softcom55329.2022.9911277"
    },
    {
        "id": 16787,
        "title": "Twin-Delayed DDPG",
        "authors": "Stephen Dankwa, Wenfeng Zheng",
        "published": "2019-8-26",
        "citations": 60,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3387168.3387199"
    },
    {
        "id": 16788,
        "title": "Weighting Factor Design of FCS-MPC in Power Electronics Using DDPG and TD3: A Reinforcement Learning Approach",
        "authors": "Ignacio A. Acosta, César A. Silva",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/chilecon60335.2023.10418605"
    },
    {
        "id": 16789,
        "title": "Comparison of DDPG and TD3 Algorithms in a Walker2D Scenario",
        "authors": "Xinrui Shen",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2991/978-94-6463-370-2_17"
    },
    {
        "id": 16790,
        "title": "Towards a Dynamic Computation Offloading Mechanism with Twin Delayed DDPG in Edge Computing",
        "authors": "Aiichiro Oga, Bernady O. Apduhan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-37114-1_10"
    },
    {
        "id": 16791,
        "title": "An Evaluation of DDPG, TD3, SAC, and PPO: Deep Reinforcement Learning Algorithms for Controlling Continuous System",
        "authors": "Shijie Liu",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2991/978-94-6463-370-2_3"
    },
    {
        "id": 16792,
        "title": "Efficient Load Frequency Control of Renewable Integrated Power System: A Twin Delayed DDPG-Based Deep Reinforcement Learning Approach",
        "authors": "Junaid Khalid, Makbul A.M. Ramli, Muhammad Saud Khan, Taufal Hidayat",
        "published": "2022",
        "citations": 24,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2022.3174625"
    },
    {
        "id": 16793,
        "title": "Co-operative Multi-agent Twin Delayed DDPG for Robust Phase Duration Optimization of Large Road Networks",
        "authors": "Priya Shanmugasundaram, Shalabh Bhatnagar",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-22953-4_6"
    },
    {
        "id": 16794,
        "title": "Joint Optimization of IRS-assisted MU-MIMO Communication Systems through a DRL-based Twin Delayed DDPG Approach",
        "authors": "Dariel Pereira-Ruisanchez, Oscar Fresnedo, Darian Perez-Adan, Luis Castedo",
        "published": "2022-6-15",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bmsb55706.2022.9828652"
    },
    {
        "id": 16795,
        "title": "Memory-Enhanced Twin Delayed Deep Deterministic Policy Gradient (ME-TD3)-Based Unmanned Combat Aerial Vehicle Trajectory Planning for Avoiding Radar Detection Threats in Dynamic and Unknown Environments",
        "authors": "Jiantao Li, Tianxian Zhang, Kai Liu",
        "published": "2023-11-25",
        "citations": 0,
        "abstract": "Unmanned combat aerial vehicle (UCAV) trajectory planning to avoid radar detection threats is a complicated optimization problem that has been widely studied. The rapid changes in Radar Cross Sections (RCSs), the unknown cruise trajectory of airborne radar, and the uncertain distribution of radars exacerbate the complexity of this problem. In this paper, we propose a novel UCAV trajectory planning method based on deep reinforcement learning (DRL) technology to overcome the adverse impacts caused by the dynamics and randomness of environments. A predictive control model is constructed to describe the dynamic characteristics of the UCAV trajectory planning problem in detail. To improve the UCAV’s predictive ability, we propose a memory-enhanced twin delayed deep deterministic policy gradient (ME-TD3) algorithm that uses an attention mechanism to effectively extract environmental patterns from historical information. The simulation results show that the proposed method can successfully train UCAVs to carry out trajectory planning tasks in dynamic and unknown environments. Furthermore, the ME-TD3 algorithm outperforms other classical DRL algorithms in UCAV trajectory planning, exhibiting superior performance and adaptability.",
        "link": "http://dx.doi.org/10.3390/rs15235494"
    },
    {
        "id": 16796,
        "title": "Twin-Delayed Deep Deterministic Policy Gradient for altitude control of a flying-wing aircraft wi...",
        "authors": "",
        "published": "2023-1-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2514/6.2023-2678.vid"
    },
    {
        "id": 16797,
        "title": "A deep reinforcement learning algorithm based on modified Twin delay DDPG method for robotic applications",
        "authors": "Carlos Vasquez-Jalpa, Mariko Nakano-Miyatake, Enrique Escamilla-Hernandez",
        "published": "2021-10-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/iccas52745.2021.9649882"
    },
    {
        "id": 16798,
        "title": "Learn to Move Through a Combination of Policy Gradient Algorithms: DDPG, D4PG, and TD3",
        "authors": "Nicolas Bach, Andrew Melnik, Malte Schilling, Timo Korthals, Helge Ritter",
        "published": "2020",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-64580-9_52"
    },
    {
        "id": 16799,
        "title": "Twin Delayed Stochastic Actor-Critic",
        "authors": "Mohammad Asadolahi, Arash Sharifi, Touraj Banirostam",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIn both discrete and continuous domains, model-free reinforcement learning algorithms have been successfully applied to the vast majority of reinforcement learning problems and are the main solution to real world problems. In reinforcement learning problems with continuous action space, state-of-the-art algorithms are extremely sample-inefficient and need lots of training interactions to become proficient, which could be catastrophically expensive and infeasible in real-world problems. So far, frontier algorithms have not used well-defined methods to explore the decision space. Exploring new behaviors is a prerequisite to look for optimal policies. All of the leading algorithms in the field leverage a blind form of exploration added to agent decisions to search for better policies. Such solutions fail to mindfully explore the environment, disrupting the learning process. This makes these algorithms very prone to failing in specific domains. In this research, a novel stochastic Off-Policy Actor-Critic algorithm, TDS for short, is presented. Combining the policy gradient theorem with the deterministic policy gradient, the TDS algorithm can learn how to mindfully explore the environment. The proposed update method enables TDS to learn how to modify the decision stochasticity bonds for each state and action. This is done according to gradients information derived from learning feedbacks. Evaluations in MuJoCo and Box2D tasks show faster convergence or outperform the state-of-the-art algorithms including TD3, SAC, and DDPG in every environment tested.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3041837/v1"
    },
    {
        "id": 16800,
        "title": "Caecal volvulus in a twin pregnancy: dilemma of a delayed diagnosis",
        "authors": "Harjit Singh Dhaliwal",
        "published": "2020-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21276/obgyn.2020.6.2.16"
    },
    {
        "id": 16801,
        "title": "LSTM-TD3-Based Control for Delayed Drone Combat Strategies",
        "authors": "Bingyu Ji, Jun Wang, Hailin Zhang, Ya Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-6882-4_73"
    },
    {
        "id": 16802,
        "title": "Robust Traffic Signal Timing Control using Multiagent Twin Delayed Deep Deterministic Policy Gradients",
        "authors": "Priya Shanmugasundaram, Shalabh Bhatnagar",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010889300003116"
    },
    {
        "id": 16803,
        "title": "A case report of successful delayed interval delivery of one fetus in twin pregnancy",
        "authors": " jingzhang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThis report describes a case of twin pregnancy in which the first fetus was delivered at 18 weeks and 1 day, while the second fetus remained in utero for a further 147 days before vaginal delivery. Multiple pregnancies have a higher incidence of complications, preterm birth, and abortion compared with single pregnancies, and while the second fetus in twin pregnancies is typically delivered soon after the first, continued pregnancy can sometimes result in improved outcomes for the newborn. However, there are no guidelines for the management of delayed delivery in twin pregnancies. This case report describes a successful delayed delivery in our hospital.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2789885/v1"
    },
    {
        "id": 16804,
        "title": "DDPG in Code",
        "authors": "Mohit Sewak",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-13-8285-7_14"
    },
    {
        "id": 16805,
        "title": "Green Resource Allocation with DDPG for Knowledge Learning in Digital Twin-enabled Edges",
        "authors": "Xiaoming He, Yingchi Mao, Yinqiu Liu, Benteng Zhang, Yunzhe Jiang, Yan Hong",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/vtc2023-fall60731.2023.10333443"
    },
    {
        "id": 16806,
        "title": "Twin Delayed Hierarchical Actor-Critic",
        "authors": "Mihai Anca, Matthew Studley",
        "published": "2021-2-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icara51699.2021.9376459"
    },
    {
        "id": 16807,
        "title": "SiamTD: Siamese twin delayed deep deterministic policy gradient for rubust Object Tracking",
        "authors": "Yuzhu Wu, Baojie Fan",
        "published": "2021-10-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac53003.2021.9727975"
    },
    {
        "id": 16808,
        "title": "EC-DDPG: DDPG-Based Task Offloading Framework of Internet of Vehicle for Mission Critical Applications",
        "authors": "Hongbo Sun, Derui Ma, Hao She, Yongan Guo",
        "published": "2023-5-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccworkshops57953.2023.10283521"
    },
    {
        "id": 16809,
        "title": "Optimal Speed Limit Control for Network Mobility and Safety: A Twin-Delayed Deep Deterministic Policy Gradient Approach",
        "authors": "Fatima Afifah, Zhaomiao Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4760709"
    },
    {
        "id": 16810,
        "title": "Human Dizygotic Twinning: Evolutionary-Based Explanations/Twin Research Reviews: Conjoined Twins in a Triplet Pregnancy; Double Embryo Transfer; Health Anxiety; Delayed Delivery of the Second Twin/In the Media: Digital Marketing Twins; Bereaved Twin at March for Our Lives; Exchange of Places; Football Players Reunite as Patriots",
        "authors": "Nancy L. Segal",
        "published": "2018-8",
        "citations": 0,
        "abstract": "Human twinning poses a conundrum for researchers, given that the female uterus is optimally designed to carry a single fetus. Evolutionary explanations of dizygotic (DZ or fraternal) twinning provide insight and understanding of this reproductive event. This review is followed by summaries of recent twin research and reports concerning twins in a triplet pregnancy, double embryo transfer; a twin study of health anxiety, and delayed delivery of the second twin. Twin events reported in the media include a pair of digital marketing twins, a speech by a bereaved twin at the March for Our Lives in Washington, D.C., twins who exchanged places, and a same-team reunion of twin football players.",
        "link": "http://dx.doi.org/10.1017/thg.2018.38"
    },
    {
        "id": 16811,
        "title": "Obstetric and Neonatal Outcomes of Delayed Interval Delivery in a Twin Pregnancy: A Case Report",
        "authors": "",
        "published": "2019-4-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.12996/gmj.2019.48"
    },
    {
        "id": 16812,
        "title": "İki Ayaklı Robot Kontrolü için DDPG ve PPO Algoritmalarının Değerlendirilmesi",
        "authors": "Mustafa Can BINGOL",
        "published": "2022-7-18",
        "citations": 1,
        "abstract": "Legged robots are very popular topics in the robotic field owing to walking on hard terrain. In the current study, the walking of a bipedal robot that is legged robot was aimed. For this purpose, the system was examined and an artificial neural network was designed. After, the neural network was trained by using the Deep Deterministic Policy Gradient (DDPG) and the Proximal Policy Optimization (PPO) algorithms. After the training process, the PPO algorithm was formed better training performance than the DDPG algorithm. Also, the optimal noise standard deviation of the PPO algorithm was investigated. The results were shown that the best results were obtained by using 0.50. The system was tested by utilizing the artificial neural networks that trained the PPO algorithm which has got 0.50 noise standard deviation. According to the test result, the total reward was calculated as 274.334 and the walking task was achieved by purposed structure. As a result, the current study has formed the basis for controlling a bipedal robot and the PPO noise standard deviation selection.",
        "link": "http://dx.doi.org/10.47495/okufbed.1031976"
    },
    {
        "id": 16813,
        "title": "Hybrid DDPG Approach for Vehicle Motion Planning",
        "authors": "Árpád Fehér, Szilárd Aradi, Ferenc Hegedűs, Tamás Bécsi, Péter Gáspár",
        "published": "2019",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007955504220429"
    },
    {
        "id": 16814,
        "title": "Successfully delayed delivery of second twin after early second trimester rupture of membranes of the first twin: a case report",
        "authors": "Jadranka Georgievska, Igor Samardziski, Ana Daneva, Goran Kocoski",
        "published": "2020-7-16",
        "citations": 0,
        "abstract": "Twin pregnancies are high-risk pregnancies accompanied with multiple complications, such as: spontaneous abortion, preterm rupture of the membranes, preterm delivery, intrauterine death of one or both twins etc. There is no consensus about the management of twin  pregnancies complicated with preterm rupture of the membranes of one twin and risk of preterm delivery. These cases are rarely found in the literature. We present a case of a 35 years old patient, hospitalized in a tertiary level institution, because of a diamniotic dichorionic twin pregnancy complicated with preterm rupture of the membranes of the first twin at 19 weeks of gestation. She had one delivery with Caesarean section 16 years ago. In consultation with the patient induction of labor was done with delivery of the first twin, a death male fetus. After that, antibiotics and tocolytic therapy were administrated and the patient remained in the hospital about one week. The patient was discharged at home with regular control of her condition and condition of the fetus. The patient was again hospitalized at 33 weeks of gestation with uterine contractions on cardiotocography. After administration of corticosteroid therapy for fetal lung maturation she delivered spontaneously the second twin in a good condition and  she was discharged from hospital after 16 days. In twin pregnancies clinicians must think about delayed interval delivery of the second twin, after delivery of the first twin, with an aim to increase chances for survival, especially for pregnancies less than 30 weeks of gestation.",
        "link": "http://dx.doi.org/10.3889/aph.2020.5193"
    },
    {
        "id": 16815,
        "title": "Virtual Imitation Learning method based on TD3-GAIL for robot manipulator",
        "authors": "Seonghyeon Jo, Jongcheon Park, Sangmoon Lee",
        "published": "2021-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5370/kiee.2021.70.1.145"
    },
    {
        "id": 16816,
        "title": "A Weighted Critic Update Approach to Multi Agent Twin Delayed Deep Deterministic Algorithm",
        "authors": "Tamal Sarkar, Shobhanjana Kalita",
        "published": "2021-12-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/indicon52576.2021.9691489"
    },
    {
        "id": 16817,
        "title": "Video Task Offloading Algorithm Based on DDPG in MEC",
        "authors": "浩宇 程",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.12677/sea.2022.111011"
    },
    {
        "id": 16818,
        "title": "Inverted Pendulum Control using Twin Delayed Deep Deterministic Policy Gradient with a Novel Reward Function",
        "authors": "Manas Shil, G. N. Pillai",
        "published": "2022-2-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/delcon54057.2022.9752797"
    },
    {
        "id": 16819,
        "title": "Multi-AUV Charging Navigation Trajectory Planning Based on Twin Delayed Deep Deterministic Policy Gradient",
        "authors": "Jiaming Yu, Hao Sun, Qinglin Sun",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/ccc58697.2023.10240061"
    },
    {
        "id": 16820,
        "title": "Twin actor twin delayed deep deterministic policy gradient (TATD3) learning for batch process control",
        "authors": "Tanuja Joshi, Shikhar Makker, Hariprasad Kodamana, Harikumar Kandath",
        "published": "2021-12",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.compchemeng.2021.107527"
    },
    {
        "id": 16821,
        "title": "Delayed Cord Clamping in Twin Pregnancies: To Do or Not to Do?",
        "authors": "Stefano Ghirardello, Fabio Mosca",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1159/000497327"
    },
    {
        "id": 16822,
        "title": "DDPG Algoritmasında Bulunan Ornstein–Uhlenbeck Gürültüsünün Standart Sapmasının Araştırılması",
        "authors": "Mustafa Can BİNGOL",
        "published": "2021-6-27",
        "citations": 1,
        "abstract": "Reinforcement learning is a learning method that many creatures often unwittingly use to gain abilities such as eating and walking. Inspired by this learning method, machine learning researchers have reduced this learning method to subheadings as value learning and policy learning. In this study, the noise standard deviation of the deep deterministic policy gradient (DDPG) method, which is one of the policy learning algorithms, was examined to solve inverse kinematics of a 2 degrees-of-freedom planar robot. For this examination, 8 different functions were determined depending on the maximum value of the output of the action artificial neural network. Created artificial neural networks were trained by using these functions in 1000 iterations with 200 steps in each iteration. After the training, the statistical difference between the groups was examined and it was found that there was no statistical difference between the three best groups. For this reason, the best three groups were retrained 2500 iterations and 200 steps and tested for 100 different test scenarios after the training. After testing, the inverse kinematic equation of the 2 degrees-of-freedom planar robot with minimal errors was obtained with the help of artificial neural networks. In the light of the results, the importance of the choice of the standard deviation of noise and the correct range of selection was presented for researchers who will work in this field.",
        "link": "http://dx.doi.org/10.29109/gujsc.872646"
    },
    {
        "id": 16823,
        "title": "The Mysterious Case of the Delayed Twin: using research data to resolve linkage questions.",
        "authors": "Daniel Avery",
        "published": "2018-8-23",
        "citations": 0,
        "abstract": "IntroductionIn a large biobank of over half a million people, we have several pairs of participants who appear to share their genome. As more individuals are sequenced, more pairs are likely to be found. If these are twins then this is great news, but it isn’t quite that simple.\r\nObjectives and ApproachWhere 2 people share a genome we need to be able to confirm that these pairs are twins. However, there are a number of issues which could cause 2 people to appear to share a genome; for example being recruited twice, donating blood on another’s behalf, etc. We already identify and exclude participant data based on these conditions. We developed our methodology by looking at the first identified pair in great detail, looking for evidence which specifically ruled out possible alternate explanations, and then applying and refining the method on later pairs.\r\nResultsWe were able to demonstrate the pair were almost certainly twins using their biochemistry and family questionnaire data as principal sources. We also identified a number of variables which were useful in indicating the likelihood of a twin, and now form part of a methodology which we are still developing. Even more usefully, we identified a number of variables that seemed like useful measures but proved extremely misleading. To date we have 26 pairs of possible twins, with 9 confirmed as twins and the remainder looking likely to be twins but falling short of a threshold for confidence. We also have 75 pairs which confirm duplicate participants we have already excluded.\r\nConclusion/ImplicationsWe formed two lessons: even very simply linkages come with pitfalls, and you should gather more administrative data than you think. We’re proposing the collection of additional familial relationship data in our third resurvey. We are also looking into machine learning and statistical techniques to better identify twins and duplicates.",
        "link": "http://dx.doi.org/10.23889/ijpds.v3i4.643"
    },
    {
        "id": 16824,
        "title": "Use of Delayed Cord Clamping in Preterm Dichorionic Twin Gestations [27B]",
        "authors": "Lilly Liu, William Grobman, Lynn Yee",
        "published": "2017-5",
        "citations": 2,
        "abstract": "\nINTRODUCTION:\nDelayed cord clamping (DCC) for premature neonates has become standard of care in singleton gestations, but the outcomes after DCC in twin gestations are unclear. The aim of this study was to examine feasibility and outcomes associated with DCC in twins.\n\n\nMETHODS:\nThis is a retrospective cohort study of women delivering dichorionic-diamniotic twin gestations between 23-32 weeks gestation at a single center (2013-2015). In 6/2013, this institution introduced a DCC protocol for singleton neonates delivering < 32 weeks, with some dichorionic twins who also received DCC. Clinical characteristics and neonatal outcomes of twins receiving DCC were compared to those who did not. Bivariable assessments and fixed effects multivariable logistic and linear regression were utilized.\n\n\nRESULTS:\nOf 58 women delivering dichorionic twins < 32 weeks, 8 (13.8%) had both neonates receive DCC, resulting in 16 neonates who received DCC. DCC occurred both among those who were delivered vaginally (n=7), and by cesarean section (n=9). Neonates who received DCC, compared to those who did not, had similar umbilical artery pH, initial temperature, 5-minute Apgar score, and peak bilirubin. Additionally, there were no differences in neonatal intensive care unit length of stay, birth hematocrit, total number of blood transfusions or transfusions received in the first week, mechanical ventilation, need for pressors, death, or other adverse outcomes.\n\n\nCONCLUSION:\nPerformance of DCC in dichorionic twin gestations born < 32 weeks is feasible and not associated with worse neonatal outcomes in this small cohort. Further investigation of expansion of DCC protocols to dichorionic twin gestations appears worthy of exploration.\n",
        "link": "http://dx.doi.org/10.1097/01.aog.0000514297.19075.ea"
    },
    {
        "id": 16825,
        "title": "Delayed delivery of the second twin in a dichorionic diamniotic twin pregnancy for 136 days",
        "authors": "Nicola R. Solomon, Alexander E.P. Heazell",
        "published": "2020-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ejogrb.2020.07.056"
    },
    {
        "id": 16826,
        "title": "Delayed cord clamping  in newborn babies  from twin pregnancy",
        "authors": "Predescu (Mărăşescu) Ana Maria, Vlădăreanu Maria Irina, Simona Vlădăreanu",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26416/gine.33.3.2021.5317"
    },
    {
        "id": 16827,
        "title": "Twin-Delayed Deep Deterministic Policy Gradient Algorithm for Portfolio Selection",
        "authors": "Nicholas Baard, Terence L. van Zyl",
        "published": "2022-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cifer52523.2022.9776067"
    },
    {
        "id": 16828,
        "title": "HEV Energy Management Strategy Based on TD3 with Prioritized Exploration and Experience Replay",
        "authors": "Yu He, Youngki Kim",
        "published": "2023-5-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/acc55779.2023.10156220"
    },
    {
        "id": 16829,
        "title": "A Novel Entropy-Maximizing TD3-based Reinforcement Learning for Automatic PID Tuning",
        "authors": "Myisha A. Chowdhury, Qiugang Lu",
        "published": "2023-5-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/acc55779.2023.10156246"
    },
    {
        "id": 16830,
        "title": "Enhancing Twin Delayed Deep Deterministic Policy Gradient with Cross-Entropy Method",
        "authors": "Hieu Trung Nguyen, Khang Tran, Ngoc Hoang Luong",
        "published": "2021-12-21",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/nics54270.2021.9701549"
    },
    {
        "id": 16831,
        "title": "Twin Delayed DRL Approach for Resource Allocation in Multi-User NOMA Systems",
        "authors": "Ayman Rabee, Imad Barhumi",
        "published": "2023-10-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aict59525.2023.10313195"
    },
    {
        "id": 16832,
        "title": "Artificial Pancreas Control for Diabetes using TD3 Deep Reinforcement Learning",
        "authors": "Alan Mackey, Eoghan Furey",
        "published": "2022-6-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/issc55427.2022.9826219"
    },
    {
        "id": 16833,
        "title": "Quantitative Trading of Stocks Based on TD3 Algorithm",
        "authors": "Kaitian Yu",
        "published": "2023-7-25",
        "citations": 0,
        "abstract": "Intelligent and efficient stock analysis can help investors and institutions judge stock trends, improve investment returns, and avoid investment risks. The use of deep reinforcement learning methods to process stock data and provide investment recommendations has important research value. This question proposes to use the TD3 algorithm to implement a deep reinforcement learning model, introduce commonly used stock technical indicators, design reward and action functions, and use them to backtest recent stock trading data. Finally, comparing it with the moving average strategy and other deep reinforcement learning models, it was found that in the past decade of historical data, the annualized rate of the moving average strategy was 10% -15%, while the annualized rate of the TD3 algorithm was 23% -25%. This indicates that the TD3 algorithm can help investors or institutions make judgments and effectively improve investment returns.",
        "link": "http://dx.doi.org/10.54097/hset.v60i.10360"
    },
    {
        "id": 16834,
        "title": "A-TD3: An Adaptive Asynchronous Twin Delayed Deep Deterministic for Continuous Action Spaces",
        "authors": "Jiaolv Wu, Q. M. Jonathan Wu, Shuyue Chen, Farhad Pourpanah, Detian Huang",
        "published": "2022",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2022.3226446"
    },
    {
        "id": 16835,
        "title": "Improved Performance for PMSM Sensorless Control Based on LADRC Controller, ESO-type Observer, DO-type Observer, and RL-TD3 Agent",
        "authors": "Claudiu Ionel Nicola, Marcel Nicola",
        "published": "No Date",
        "citations": 1,
        "abstract": "Starting from the fact that in sensorless control systems of Permanent Magnet Synchronous Motor (PMSM) the load torque can have short and significant variations, this paper presents the sensorless control of a PMSM based on a Linear Adaptive Disturbance Rejection Controller (LADRC) type controller. Essentially, the successful operation of the LADRC controller to achieve PMSM rotor speed control performance depends on a good estimation of the disturbances acting on the system. Traditionally, an Extended State Observer (ESO) is used to make such an estimate. In this paper, it is proposed to use a Disturbance Observer (DO) to estimate the external disturbances, and after their rejection, the LADRC controller ensures an equivalent global behavior of the control system with an ideal double integrator, and thus increased ease in achieving the desired control performance. Control structures and Matlab/Simulink implementation of the sensorless PMSM control system based on LADRC controller with ESO/DO type observer are presented, as well as its use in tandem with a Reinforcement Learning Twin-Delayed Deep Deterministic Policy Gradient (RL-TD3) specially trained agent that provides correction signals for more accurate estimation of external disturbances and hence improved control performance. Qualitatively superior performance is achieved by using LADRC with the RL-TD3 agent control structure in terms of parametric robustness, response time, and steady-state error. Also, by calculating the fractal dimension (DF) of the controlled signal and the PMSM rotor speed, it is found that the higher the DF, the better the performance of the control system. The validation of the superiority of the proposed control structures is carried out by means of numerical simulations in the Matlab/Simulink environment.",
        "link": "http://dx.doi.org/10.20944/preprints202306.1258.v1"
    },
    {
        "id": 16836,
        "title": "D3-TD3: Deep Dense Dueling Architectures in TD3 Algorithm for Robot Path Planning Based on 3D Point Cloud",
        "authors": "Yuwan Gu, Zhitao Zhu, Yongtao Chu, Jidong Lv, Xueyuan Wang, Shoukun Xu",
        "published": "2023-12",
        "citations": 0,
        "abstract": " Twin delayed deep deterministic (TD3) policy gradient has several limitations when applied in planning a path in environment with a number of dilemmas according to our experiment, due to the complexity of the robot path planning task, the rate of convergence of TD3 algorithm is slow and the rate of collision is high. To address this problem, deep dense dueling twin delayed deep deterministic (D3-TD3) architecture is proposed, a method that preserves important information from cross-layer inputs through dense connections and divides the network into a value function and a dominance function, thus, allowing for faster convergence when solving complex tasks. Finally, a spatial model based on three-dimension (3D) point cloud is built, and simulation experimental results show that in static environment, the algorithm proposed in the paper has 40.6% fewer collisions compared to TD3, 30% fewer collisions compared to TD3-BC, 19.2% fewer collisions compared to Dueling TD3 and 17.4% fewer collisions compared to deep dense TD3. In dynamic and static environment, the algorithm proposed in the paper has 34.4% fewer collisions compared to TD3, 24% fewer collisions compared to TD3-BC, 6% fewer collisions compared to Dueling TD3 and 25% fewer collisions compared to deep dense TD3. ",
        "link": "http://dx.doi.org/10.1142/s021812662350305x"
    },
    {
        "id": 16837,
        "title": "Robot Trajectory Planning Optimization Algorithm Based on Improved TD3 Algorithm",
        "authors": "Xin Zhao, Sheng Zheng",
        "published": "2023-11-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icn60549.2023.10425941"
    },
    {
        "id": 16838,
        "title": "A Monte Carlo Transient Multilevel Implementation Applied to the C5G7-TD3 Benchmark",
        "authors": "Evan Gonzalez, Brian Kiedrowski",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.13182/physor22-37835"
    },
    {
        "id": 16839,
        "title": "Design and Analyses of a Transdermal Drug Delivery Device (TD3) †",
        "authors": "Jennifer García, Ismael Ríos, Faruk Fonthal Rico",
        "published": "2019-11-21",
        "citations": 10,
        "abstract": "In this paper, we introduce a novel type of transdermal drug delivery device (TD3) with a micro-electro-mechanical system (MEMS) design using computer-aided design (CAD) techniques as well as computational fluid dynamics (CFD) simulations regarding the fluid interaction inside the device during the actuation process. For the actuation principles of the chamber and microvalve, both thermopneumatic and piezoelectric principles are employed respectively, originating that the design perfectly integrates those principles through two different components, such as a micropump with integrated microvalves and a microneedle array. The TD3 has shown to be capable of delivering a volumetric flow of 2.92 × 10−5 cm3/s with a 6.6 Hz membrane stroke frequency. The device only needs 116 Pa to complete the suction process and 2560 Pa to complete the discharge process. A 38-microneedle array with 450 µm in length fulfills the function of permeating skin, allowing that the fluid reaches the desired destination and avoiding any possible pain during the insertion.",
        "link": "http://dx.doi.org/10.3390/s19235090"
    },
    {
        "id": 16840,
        "title": "Covertness-Aware Trajectory Design for UAV: A Multi-Step TD3-PER Solution",
        "authors": "Yuanjian Li, A. Hamid Aghvami",
        "published": "2022-5-16",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icc45855.2022.9839093"
    },
    {
        "id": 16841,
        "title": "Twin-Delayed Deep Deterministic Policy Gradient for Low-Frequency Oscillation Damping Control",
        "authors": "Qiushi Cui, Gyoungjae Kim, Yang Weng",
        "published": "2021-10-15",
        "citations": 4,
        "abstract": "Due to the large scale of power systems, latency uncertainty in communications can cause severe problems in wide-area measurement systems. To resolve this issue, a significant amount of past work focuses on using emerging technology, including machine learning methods such as Q-learning, for addressing latency issues in modern controls. Although the method can deal with the stochastic characteristics of communication latency, the Q-values can be overestimated in Q-learning methods, leading to high bias. To address the overestimation bias issue, we redesign the learning structure of the deep deterministic policy gradient (DDPG). Then we develop a damping control twin-delayed deep deterministic policy gradient method to handle the damping control issue under unknown latency in the power network. The purpose is to address the damping control issue under unknown latency in the power network. This paper will create a novel reward algorithm, taking into account the machine speed deviation, the episode termination prevention, and the feedback from action space. In this way, the system optimally damps down frequency oscillations while maintaining the system’s stability and reliable operation within defined limits. The simulation results verify the proposed algorithm in various perspectives, including the latency sensitivity analysis under high renewable energy penetration and the comparison with conventional and machine learning control algorithms. The proposed method shows a fast learning curve and good control performance under varying communication latency.",
        "link": "http://dx.doi.org/10.3390/en14206695"
    },
    {
        "id": 16842,
        "title": "SUCCESSFUL DELAYED‐INTERVAL DELIVERY IN MONOCHORIONIC DIAMNIOTIC TWIN PREGNANCY",
        "authors": "",
        "published": "2019-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/jpc.14410_19"
    },
    {
        "id": 16843,
        "title": "EP24.09: Selective laser ablation followed by a delayed Solomon technique for Twin–twin transfusion syndrome may improve dual survival",
        "authors": "C.L. Dinglas, J. Davis, C. Heiselman, M. Chavez, A. Vintzileos",
        "published": "2019-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/uog.21636"
    },
    {
        "id": 16844,
        "title": "Crystal structure of carboxyhemoglobin in complex with beta Cys93 modifying agent, TD3",
        "authors": "F.N. Musayev, R.M. Safo, M.K. Safo",
        "published": "2018-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2210/pdb6bwu/pdb"
    },
    {
        "id": 16845,
        "title": "Enhanced Mode-Locked Laser Control with Deep Reinforcement Learning: A Comparative Study with DDQN, TD3 and SAC Algorithms",
        "authors": "Gezhi Chen, Saiyu Luo, Li Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nDeep reinforcement learning algorithms, i.e. Double Deep Q Network (DDQN), Twin Delayed Deep Deterministic policy gradient (TD3), and Soft Actor-Critic (SAC), have recently found their applications in laser mode-locking. However, their performances have not yet been compared in detail. We show the implementation of the three AI algorithms on a simulated fiber laser mode-locked by nonlinear polarization rotation. The reward function is specifically designed to maximize the tendency of mode-locking by introducing kurtosis in frequency domain. The training curves indicate that TD3 and SAC outperform DDQN in multi-input context. DDQN has difficulty in handling multiple inputs and tends to have issues with convergence. While TD3 is most stable and efficient, SAC is more advantageous in searching various states. The simulation pulse evolution diagrams of these states are also listed to confirm the feasibility of training a mode-locked laser model through the three AI algorithms.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3675037/v1"
    },
    {
        "id": 16846,
        "title": "A QUOTA-DDPG Controller for Run-to-Run Control",
        "authors": "Zhu Ma, Tianhong Pan",
        "published": "2021-10-22",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac53003.2021.9728433"
    },
    {
        "id": 16847,
        "title": "Learning of Quadruped Robot Motor Skills Based on Policy Constrained TD3",
        "authors": "Xiaoyu Zhu, Xiaoqing Zhu, Jiangtao Chen, Siyuan Zhang, Borui Nan, Lanyue Bi",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac59555.2023.10451816"
    },
    {
        "id": 16848,
        "title": "Twin delayed deep deterministic reinforcement learning application in vehicle electrical suspension control",
        "authors": "Nong Zhang, Shilei Zhou, Daoyu Shen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijvp.2023.10055649"
    },
    {
        "id": 16849,
        "title": "Autonomous localized path planning algorithm for UAVs based on TD3 strategy",
        "authors": "Feiyu Zhao, Dayan Li, Zhengxu Wang, Jianlin Mao, Niya Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nAiming at the current local path planning methods for UAVs, the problem of weak portability due to the large influence of different controllers on its planning effect and the weak autonomous decision-making ability of UAV path planning, an autonomous local path planning algorithm for UAVs based on the TD3 policy update is proposed. On the basis of not changing the UAV's native controller, the decision-making model is designed to help the UAV realize local path planning work in unfamiliar environments based on environmental information. The model filters and extracts the UAV sensor, camera image information, and lidar information, inputs them into the reinforcement learning agent, outputs high-level command actions to the robot cooperative operating system, and transmits the movement commands from the operating system to the UAV, realizes the local path planning task of the UAV, and carries out the test experiments based on the training results. The test results show that the autonomous local path planning algorithm for UAVs based on deep reinforcement learning can effectively realize the autonomous local path planning task of UAVs, and the success rate reaches 93% under the interference of no obstacles, and 92% in the environment with obstacles. The success rate and portability of UAV implementation of path planning are improved.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3353928/v1"
    },
    {
        "id": 16850,
        "title": "Crystal structure of Deoxy Hemoglobin in complex with beta Cys93 modifying agent, TD3",
        "authors": "F.N. Musayev, R.M. Safo, M.K. Safo",
        "published": "2018-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2210/pdb6bwp/pdb"
    },
    {
        "id": 16851,
        "title": "Vector Control of PMSM Using TD3 Reinforcement Learning Algorithm",
        "authors": "Fengyuan Yin, Xiaoming Yuan, Zhiao Ma, Xinyu Xu",
        "published": "2023-8-24",
        "citations": 1,
        "abstract": "Permanent magnet synchronous motor (PMSM) drive systems are commonly utilized in mobile electric drive systems due to their high efficiency, high power density, and low maintenance cost. To reduce the tracking error of the permanent magnet synchronous motor, a reinforcement learning (RL) control algorithm based on double delay deterministic gradient algorithm (TD3) is proposed. The physical modeling of PMSM is carried out in Simulink, and the current controller controlling id-axis and iq-axis in the current loop is replaced by a reinforcement learning controller. The optimal control network parameters were obtained through simulation learning, and DDPG, BP, and LQG algorithms were simulated and compared under the same conditions. In the experiment part, the trained RL network was compiled into C code according to the workflow with the help of rapid prototyping control, and then downloaded to the controller for testing. The measured output signal is consistent with the simulation results, which shows that the algorithm can significantly reduce the tracking error under the variable speed of the motor, making the system have a fast response.",
        "link": "http://dx.doi.org/10.3390/a16090404"
    },
    {
        "id": 16852,
        "title": "Optimal Operation Strategy of Microgrid Based on TD3 Algorithm",
        "authors": "Chenyu Cui, Ze Dong",
        "published": "2022-9-23",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icpre55555.2022.9960559"
    },
    {
        "id": 16853,
        "title": "Twin delayed deep deterministic reinforcement learning application in vehicle electrical suspension control",
        "authors": "Daoyu Shen, Shilei Zhou, Nong Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijvp.2023.133852"
    },
    {
        "id": 16854,
        "title": "Twin Delayed Deep Deterministic Policy Gradient Based Energy Management Strategy for Fuel Cell/Battery/Ultracapacitor Hybrid Electric Vehicles Considering Unknown Terrain Information",
        "authors": "Fazhan Tao, Zhigao Fu, Huixian Gong, Baofeng Ji, Yao Zhou",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4523742"
    },
    {
        "id": 16855,
        "title": "Successful delayed-interval delivery in monochorionic diamniotic twin pregnancy: A case report",
        "authors": "Tanja Baltus, Maria Luisa Martin",
        "published": "2019-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.crwh.2018.e00093"
    },
    {
        "id": 16856,
        "title": "Delayed delivery of the second twin: Case report and literature review of diamniotic dichorionic twin pregnancy with very early preterm premature rupture of membranes",
        "authors": "A. Canu, A. Giannini, P. Ghirri, E. Malacarne, F. Pancetti, T. Simoncini, P. Mannella",
        "published": "2019-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.crwh.2019.e00104"
    },
    {
        "id": 16857,
        "title": "Learning industrial assembly by guided-DDPG",
        "authors": "Yongxiang Fan",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-390445-2.00018-0"
    },
    {
        "id": 16858,
        "title": "GRU-Attention based TD3 Network for Mobile Robot Navigation",
        "authors": "Jiayao Jia, Xiaowei Xing, Dong Eui Chang",
        "published": "2022-11-27",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/iccas55662.2022.10003950"
    },
    {
        "id": 16859,
        "title": "The LSTM-PER-TD3 Algorithm for Deep Reinforcement Learning in Continuous Control Tasks",
        "authors": "Qurui Zhang, Lirui Zhang, Qi Ma, Jing Xue",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac59555.2023.10450268"
    },
    {
        "id": 16860,
        "title": "Dynamic resource allocation in IRS-assisted UAV wideband cognitive radio networks: A DDQN-TD3 approach",
        "authors": "Hui Wei, Jingyi Lang",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.phycom.2024.102284"
    },
    {
        "id": 16861,
        "title": "Delayed interval twin delivery of a fetus with a favourable neonatal outcome after a preterm delivery of the first twin: a case report",
        "authors": "Nitin P. PaiDhungat, Tejaswi D. Kamble, Alka C. Bapat",
        "published": "2018-9-26",
        "citations": 0,
        "abstract": "Assisted reproductive techniques have proved to be a boon for infertile couples. With advent of newer techniques, the incidence of successful multiple pregnancies has also risen. Considering the emotional and financial aspects of the treatment and the risk of preterm delivery in such cases, our intent is not only to salvage one of the twins in case of unfortunate preterm delivery of the other but also to deliver a viable second twin with better chance of survival and favourable neonatal outcome. The current case describes a 34-year woman with previous 2 failed IVF conceptions, on external progesterone support, carrying a twin gestation in preterm labour. Upon the inadvertent delivery of the first twin, a cervical cerclage was done, and she was given conservative management, including bed rest and head low position in view of short cervix, with an aim to delay the delivery of the other. An interval of 66 days was achieved with surgical as well as medical management, following which a healthy second twin was born.",
        "link": "http://dx.doi.org/10.18203/2320-1770.ijrcog20184174"
    },
    {
        "id": 16862,
        "title": "Effect of delayed cord clamping on maternal and neonatal outcome in twin pregnancies",
        "authors": "Suin Yoon, Yookyung Jin, Yejin Kim, Ji-Hee Sung, Suk-Joo Choi, Soo-young Oh, Cheong-Rae Roh",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe objective of this study was to compare the maternal and neonatal outcomes following delayed cord clamping (DCC) versus immediate cord clamping (ICC) in twin pregnancies. This was a retrospective cohort study of 705 twin pregnancies who delivered at ≥ 24 weeks of gestation. Maternal and neonatal hemoglobin levels, blood transfusion, and neonatal outcomes were compared between DCC (n = 225) and ICC (n = 480) groups. Mean maternal predelivery and postpartum hemoglobin levels and the rate of postpartum hemoglobin drop ≥ 20% or maternal blood transfusion were comparable between the two groups. The DCC group had a significantly higher mean neonatal hemoglobin level (DCC vs. ICC: 17.4 ± 3.5 vs. 16.6 ± 2.7 g/dl, P = 0.010) but significantly lower rates of neonatal blood transfusion (DCC vs. ICC: 3.3% vs. 8.8%, P < 0.001) and respiratory distress syndrome (DCC vs. ICC: 6.7% vs. 15.2%, P < 0.001) than the ICC group. In conclusion, DCC compared with ICC in twin pregnancy was not associated with an increase of maternal postpartum bleeding complications, but it was associated with higher neonatal hemoglobin level and lower risks of neonatal blood transfusion and respiratory distress syndrome.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3133760/v1"
    },
    {
        "id": 16863,
        "title": "Deep Deterministic Policy Gradient (DDPG) Agent-Based Sliding Mode Control for Quadrotor Attitudes",
        "authors": "Wenjun Hu, Yueneng Yang, Zhiyang Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "A novel reinforcement learning deep deterministic policy gradient agent-based sliding mode control (DDPG-SMC) approach is proposed to suppress the chattering phenomenon in the attitude control for quadrotors, in the presence of external disturbances. First, the attitude dynamics model of the studied quadrotor is derived and the attitude control problem is described by formulas. Second, a sliding mode controller including its sliding mode surface and reaching law is selected for the nonlinear dynamic system, and the stability of the designed SMC system is supported by Lyapunov stability theorem. Third, a reinforcement learning (RL) agent based on deep deterministic policy gradient (DDPG) is trained to adjust the switching control gain adaptively. During the training process, the input signals of agent are the actual and desired attitude angles, and the output action is the time-varying control gain. Finally, the above trained agent is applied to the SMC as a parameter regulator, to implement the adaptive adjustment of the switching control gain related to reaching law, and the simulation results verify the robustness and effectiveness of the proposed DDPG-SMC method.",
        "link": "http://dx.doi.org/10.20944/preprints202401.1213.v1"
    },
    {
        "id": 16864,
        "title": "Path Planning of Mobile Robot Based on Improved TD3 Algorithm in Dynamic Environment",
        "authors": "Peng Li, Donghui Chen, Yuchen Wang, Lanyong Zhang, Shiquan Zhao",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4727758"
    },
    {
        "id": 16865,
        "title": "Augmented-Ensemble TD3: Overcoming the Shackles of Constant Action Delay",
        "authors": "Jongsoo Lee, Soohee Han",
        "published": "2023-10-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/iccas59377.2023.10316794"
    },
    {
        "id": 16866,
        "title": "Reply to the Letter to the Editor “Delayed Cord Clamping in Twin Pregnancies: to Do or Not to Do?”",
        "authors": "Chayatat Ruangkit, Pracha Nuntnarumit",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1159/000497329"
    },
    {
        "id": 16867,
        "title": "Novel TD3 Based AUV Path Tracking Control",
        "authors": "Yue Zhang, Ru Li, Yibin Li, Tianze Zhang, Yinghao Zhuang, Yan Song",
        "published": "2021-10-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac53003.2021.9727467"
    },
    {
        "id": 16868,
        "title": "Twin delayed deep deterministic policy gradient-based intelligent computation offloading for IoT",
        "authors": "Siguang Chen, Bei Tang, Kun Wang",
        "published": "2023-8",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.dcan.2022.06.008"
    },
    {
        "id": 16869,
        "title": "Swap Softmax Twin Delayed Deep Deterministic Policy Gradient",
        "authors": "Chaohu Liu, Yunbo Zhao",
        "published": "2023-6-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isas59543.2023.10164333"
    },
    {
        "id": 16870,
        "title": "Efficient DDPG via the Self-Supervised Method",
        "authors": "Guanghao Zhang, Hongliang Chen, Jianxun Li",
        "published": "2020-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ccdc49329.2020.9164668"
    }
]