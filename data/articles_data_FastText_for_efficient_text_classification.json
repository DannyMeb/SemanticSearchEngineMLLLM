[
    {
        "id": 21905,
        "title": "Text classification framework for short text based on TFIDF-FastText",
        "authors": "Shrutika Chawla, Ravreet Kaur, Preeti Aggarwal",
        "published": "2023-11",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-15211-5"
    },
    {
        "id": 21906,
        "title": "Research on Text Classification of Anonymous Data Based on FastText Model",
        "authors": "美瑶 朱",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.12677/sa.2023.122060"
    },
    {
        "id": 21907,
        "title": "Text Classification of Climate Change Tweets using Artificial Neural Networks, FastText Word Embeddings, and Latent Dirichlet Allocation",
        "authors": "John Daves S. Baguio, Billy A. Lu, Christine F. Peña",
        "published": "2023-6-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/apsit58554.2023.10201782"
    },
    {
        "id": 21908,
        "title": "Security bug reports classification using fasttext",
        "authors": "Sultan S. Alqahtani",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10207-023-00793-w"
    },
    {
        "id": 21909,
        "title": "CNN-FastText Multi-Input (CFMI) Neural Networks for Social Media Clickbait Classification",
        "authors": "Chirag Sharma, Gurneet Singh, Pratibha Singh Muttum, Shubham Mahajan",
        "published": "2024-1-25",
        "citations": 0,
        "abstract": "\nIntroduction:\nUser-generated video portals, such as YouTube, are facing the chal-lenge of Clickbait. These are used to lure viewers and gain traffic on specific content. The real content inside the video deviates from its title. and a thumbnail. The consequence of this is poor user experience on the platform.\n\n\nbackground:\nThe method employs a self-developed convolutional model, combined with different other video metadata. The thumbnail of any video plays a vital role in gathering user attention; hence, it should also be addressed. Moreover, we believe that word embeddings can help in determining the words that can attract viewers.\n\n\nMethods:\nThe existing identification techniques either use pre-trained models or are restricted to text only. Other video metadata is not considered. To tackle this situation of clickbait, we propose a CNN-Fast Text Multi-Input (CFMI) Neural Network. The method employs a self-developed convolutional model, combined with different other video metadata. The thumbnail of any video plays a vital role in gathering user attention; hence, it should also be addressed. With greater expressiveness, it depicts and captures the parallels between the title and thumb-nail and the video content.\n\n\nobjective:\nThis research also compares the proposed system with the previous works on various parameters. With the usage of the proposed network, the platforms can easily analyze the videos during the uploading stage. In Industry 4.0, every data bit is crucial and must be preserved carefully.\n\n\nResults:\nThis research also compares the proposed system with the previous works on various parameters. With the usage of the proposed network, the platforms can easily analyze the vide-os during the uploading stage. The future belongs to Post Quantum Cryptography (PWC), we reviewed various encryption standards in this paper.\n\n\nConclusion:\nIn Industry 4.0, every data bit is crucial and must be preserved carefully. This in-dustry will surely benefit from the model as it will eliminate false and misleading videos from the platform.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.2174/0126662558283914231221065437"
    },
    {
        "id": 21910,
        "title": "Classification of Bulughul Maraam Categories: Prohibitions, Recommendations, and Information Using Extreme Learning Machine and Fasttext",
        "authors": "Rissa Handayani, Ina Najiyah, Dirga Wisnuwardana",
        "published": "2023-12-28",
        "citations": 0,
        "abstract": "Hadith is the second source of Islamic law after the Quran. After the hadiths were compiled, Imam of Hadith created collections of hadiths, one of which is Imam Bukhari who compiled the book Bulughul Maraam, which is considered to have the highest level of authenticity. Digital collections of hadiths can now be found in the form of e-books and web pages, which help in the search for hadiths. The classification of hadiths is necessary to organize them by category, making it easier to search for hadiths based on their categories. Text mining is needed to classify hadiths because it can identify patterns in unstructured text. This research aims to improve the accuracy of classifying recommended, prohibited, and informational hadiths using a dataset of 7008 hadiths, which consists of primary data taken from the book Bulughul Maraam in the Indonesian language. Previously, similar research was conducted in 2017 that classified recommended, prohibited, and obligatory hadiths with an accuracy of 85%, but only for Sahih Bukhari hadiths. In this research, the same classification categories will be examined, proposing a different method, namely the Extreme Learning Machine method and Word2vec Fasttext for text representation with a larger dataset. The results of this research show a model accuracy of 86.31%, 86% precision, and 87% recall, indicating that the proposed model performs well in classifying hadiths.",
        "keywords": "",
        "link": "http://dx.doi.org/10.15575/join.v8i2.1205"
    },
    {
        "id": 21911,
        "title": "Automating Service Classification for Victims of Violence in Indonesia through Deep Learning Using Gated Recurrent Unit and fastText",
        "authors": "Dedy Arisandi, Rossy Nurhasanah, Suci Khairiah",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/elticom61905.2023.10443196"
    },
    {
        "id": 21912,
        "title": "Topic Classification Using the Long Short-Term Memory (LSTM) Method with FastText Feature Expansion on Twitter",
        "authors": "Bella Adriani Putri, Erwin Budi Setiawan",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icodsa58501.2023.10277033"
    },
    {
        "id": 21913,
        "title": "Disaster Event Classification on Twitter: A Comparison of LSTM and GRU Algorithms using Word Embedding FastText and GloVe",
        "authors": "Ade Febrian, Arif Dwi Laksito",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iwaiip58158.2023.10462842"
    },
    {
        "id": 21914,
        "title": "Machine learning for text document classification-efficient classification approach",
        "authors": "Sura I. Mohammed Ali, Marwah Nihad, Hussien Mohamed Sharaf, Haitham Farouk",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "<p>Numerous alternative methods for text classification have been created because of the increase in the amount of online text information available. The cosine similarity classifier is the most extensively utilized simple and efficient approach. It improves text classification performance. It is combined with estimated values provided by conventional classifiers such as Multinomial Naive Bayesian (MNB). Consequently, combining the similarity between a test document and a category with the estimated value for the category enhances the performance of the classifier. This approach provides a text document categorization method that is both efficient and effective. In addition, methods for determining the proper relationship between a set of words in a document and its document categorization is also obtained.</p>",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijai.v13.i1.pp703-710"
    },
    {
        "id": 21915,
        "title": "Multi-label Classification of Indonesian Al-Quran Translation based CNN, BiLSTM, and FastText",
        "authors": "Ahmad Rofiqul Muslikh, Ismail Akbar, De Rosal Ignatius Moses Setiadi, Hussain Md Mehedul Islam",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "Studying the Qur'an is a pivotal act of worship in Islam, which necessitates a structured understanding of its verses to facilitate learning and referencing. Reflecting this complexity, each Quranic verse is rich with unique thematic elements and can be classified into a range of distinct categories. This study explores the enhancement of a multi-label classification model through the integration of FastText. Employing a CNN+Bi-LSTM architecture, the research undertakes the classification of Quranic translations across categories such as Tauhid, Ibadah, Akhlak, and Sejarah. Based on model evaluation using F1-Score, it shows significant differences between the CNN+Bi-LSTM model without FastText, with the highest result being 68.70% in the 80:20 testing configuration. Conversely, the CNN+Bi-LSTM+FastText model, combining embedding size and epoch parameters, achieves a result of 73.30% with an embedding size of 200, epoch of 100, and a 90:10 testing configuration. These findings underscore the significant impact of FastText on model optimization, with an enhancement margin of 4.6% over the base model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.62411/tc.v23i1.9925"
    },
    {
        "id": 21916,
        "title": "TOPIC GROUPING BASED ON DESCRIPTION TEXT IN MICROSOFT RESEARCH VIDEO DESCRIPTION CORPUS DATA USING FASTTEXT, PCA AND K-MEANS CLUSTERING",
        "authors": "Ahmad Hafidh Ayatullah, Nanik Suciati",
        "published": "2023-2-28",
        "citations": 0,
        "abstract": "Video data retrieval can be done based on voice, image, or text data that represents video content. Searching for videos using text data can be done by calculating the similarity between the text descriptions provided by the user and the text descriptions of all the video data in the database. Only video data with a certain level of similarity will be provided to the user as a fetch result. Determining the similarity of the description text can be based on the clustering results of the feature representation of the description text with the word embedding used. This research groups topics of the Microsoft Research Video Description Corpus (MRVDC) based on text descriptions of Indonesian language dataset. The Microsoft Research Video Description Corpus (MRVDC) is a video dataset developed by Microsoft Research, which contains paraphrased event expressions in English and other languages. The results of grouping these topics show how the patterns of similarity and interrelationships between text descriptions from different video data, which will be useful for the topic-based video retrieval. The topic grouping process is based on text descriptions using fastText as word embedding, PCA as features reduction method and K[1]means as the clustering method. The experiment on 1959 videos with 43753 text descriptions to vary the number of k and with/without PCA result that the optimal clustering number is 180 with silhouette coefficient of 0.123115. The optimal clustering results in this study can be used for video data retrieval systems in the Indonesian language MRVDC dataset.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33795/jip.v9i2.1271"
    },
    {
        "id": 21917,
        "title": "MatchXML: An Efficient Text-label Matching Framework for Extreme Multi-label Text Classification",
        "authors": "Hui Ye, Rajshekhar Sunderraman, Shihao Ji",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tkde.2024.3374750"
    },
    {
        "id": 21918,
        "title": "A Novel Efficient and Effective Preprocessing Algorithm for Text Classification",
        "authors": "Lijie Zhu, Difan Luo",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.4236/jcc.2023.113001"
    },
    {
        "id": 21919,
        "title": "Comparison of Fasttext and Word2Vec Weighting Techniques for Classification of Multiclass Emotions Using the Conv-LSTM Method",
        "authors": "Salwa Ziada Salsabiila, Helena Nurramdhani Irmanda, Artika Arista",
        "published": "2023-11-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icimcis60089.2023.10349034"
    },
    {
        "id": 21920,
        "title": "Hybrid Model for Efficient Assamese Text Classification using CNN-LSTM",
        "authors": "Chayanika Talukdar, Shikhar Kr. Sarma",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.12785/ijcds/140191"
    },
    {
        "id": 21921,
        "title": "the_linguists at BLP-2023 Task 1: A Novel Informal Bangla Fasttext Embedding for Violence Inciting Text Detection",
        "authors": "Md. Tariquzzaman, Md Wasif Kader, Audwit Anam, Naimul Haque, Mohsinul Kabir, Hasan Mahmud, Md Kamrul Hasan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.banglalp-1.26"
    },
    {
        "id": 21922,
        "title": "A Novel Approach to Efficient Multilabel Text Classification: BERT-Federated Learning Fusion",
        "authors": "Arefin Abu Isha Md. Sadot, Mitu Maliha Mehjabin, Aziz Mahafuz",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccit60459.2023.10441264"
    },
    {
        "id": 21923,
        "title": "An efficient consolidation of word embedding and deep learning techniques for classifying anticancer peptides: FastText+BiLSTM",
        "authors": "Onur Karakaya, Zeynep Hilal Kilimci",
        "published": "2024-2-20",
        "citations": 0,
        "abstract": "Anticancer peptides (ACPs) are a group of peptides that exhibit antineoplastic properties. The utilization of ACPs in cancer prevention can present a viable substitute for conventional cancer therapeutics, as they possess a higher degree of selectivity and safety. Recent scientific advancements generate an interest in peptide-based therapies which offer the advantage of efficiently treating intended cells without negatively impacting normal cells. However, as the number of peptide sequences continues to increase rapidly, developing a reliable and precise prediction model becomes a challenging task. In this work, our motivation is to advance an efficient model for categorizing anticancer peptides employing the consolidation of word embedding and deep learning models. First, Word2Vec, GloVe, FastText, One-Hot-Encoding approaches are evaluated as embedding techniques for the purpose of extracting peptide sequences. Then, the output of embedding models are fed into deep learning approaches CNN, LSTM, BiLSTM. To demonstrate the contribution of proposed framework, extensive experiments are carried on widely-used datasets in the literature, ACPs250 and independent. Experiment results show the usage of proposed model enhances classification accuracy when compared to the state-of-the-art studies. The proposed combination, FastText+BiLSTM, exhibits 92.50% of accuracy for ACPs250 dataset, and 96.15% of accuracy for the Independent dataset, thence determining new state-of-the-art.",
        "keywords": "",
        "link": "http://dx.doi.org/10.7717/peerj-cs.1831"
    },
    {
        "id": 21924,
        "title": "Efficient Classification of Hallmark of Cancer Using Embedding-Based Support Vector Machine for Multilabel Text",
        "authors": "Shikha Verma, Aditi Sharan, Nidhi Malik",
        "published": "2024-3-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00354-024-00248-3"
    },
    {
        "id": 21925,
        "title": "An Efficient Text based Classification using Neural Networks and Long Short-Term Memory",
        "authors": "Settipalli Shanmukha Sai Srinivas, Devata Sai Harshith, Venubabu Rachapudi",
        "published": "2023-2-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icais56108.2023.10073886"
    },
    {
        "id": 21926,
        "title": "FastPacket: Towards Pre-trained Packets Embedding based on FastText for nextgeneration NIDS",
        "authors": "",
        "published": "2023-2-27",
        "citations": 0,
        "abstract": "New Attacks are increasingly used by attackers everyday but many of them are not detected by Intrusion Detection Systems as most IDS ignore raw packet information and only care about some basic statistical information extracted from PCAP files. Using networking programs to extract fixed statistical features from packets is good, but may not enough to detect nowadays challenges. We think that it is time to utilize big data and deep learning for automatic dynamic feature extraction from packets. It is time to get inspired by deep learning pre-trained models in computer vision and natural language processing, so security deep learning solutions will have its pre-trained models on big datasets to be used in future researches. In this paper, we proposed a new approach for embedding packets based on character-level embeddings, inspired by FastText success on text data. We called this approach FastPacket. Results are measured on subsets of CIC-IDS-2017 dataset, but we expect promising results on big data pre-trained models. We suggest building pre-trained FastPacket on MAWI big dataset and make it available to community, similar to FastText. To be able to outperform currently used NIDS, to start a new era of packet-level NIDS that can better detect complex attacks.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33140/jctcsr.02.01.07"
    },
    {
        "id": 21927,
        "title": "Few-Shot Text Classification with an Efficient Prompt Tuning Method in Meta-Learning Framework",
        "authors": "Xiaobao Lv",
        "published": "2024-4-1",
        "citations": 0,
        "abstract": " Meta-learning stands as a prevalent framework utilized in few-shot learning methods. Nonetheless, its efficacy hinges on substantial data availability during meta-training. Recent work adeptly tackled this hurdle by synergizing prompt tuning with the meta-learning paradigm, consequently attaining unparalleled performance on four benchmarks (FewRel, HuffPost, Reuters and Amazon). Nonetheless, the implementation efficacy of the previous method leaves room for enhancement, which is especially crucial when tuning larger language models. To this end, we introduce another expedited prompt tuning approach nested within the meta-learning framework. The novel approach normalizes the label information and sample information and uses the regression method to obtain the closed-form solution of each few-shot task, which significantly enhances inference speed, achieving a twofold improvement, while concurrently elevating average accuracy by [Formula: see text]% on the same benchmarks. Moreover, it demonstrates enhanced stability when faced with limited meta-training data, which is more applicable in many real scenarios where parallel data is rare. The source code is available to reproduce the results ( http://github.com/Dr-Lv/EMPT ). ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1142/s0218001424510066"
    },
    {
        "id": 21928,
        "title": "Depression Intensity Classification from Tweets Using FastText Based Weighted Soft Voting Ensemble",
        "authors": "Muhammad Rizwan, Muhammad Faheem Mushtaq, Maryam Rafiq, Arif Mehmood, Isabel de la Torre Diez, Monica Gracia Villar, Helena Garay, Imran Ashraf",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/cmc.2024.037347"
    },
    {
        "id": 21929,
        "title": "Word Embedding for Text Classification: Efficient CNN and Bi-GRU Fusion Multi Attention Mechanism",
        "authors": "Yalamanchili Salini, Poluru Eswaraiah, M. Veera Brahmam, Uddagiri Sirisha",
        "published": "2023-9-26",
        "citations": 0,
        "abstract": "The proposed methodology for the task of text classification involves the utilization of a deep learning algorithm that integrates the characteristics of a fusion model. The present model is comprised of several attention-based Convolutional Neural Networks (CNNs) and Gate Recurrent Units (GRUs) that are organized in a cyclic neural network. The Efficient CNN and Bi-GRU Fusion Multi Attention Mechanism is a method that integrates convolutional neural networks (CNNs) and bidirectional Gated Recurrent Units (Bi-GRUs) with multi-attention mechanisms in order to enhance the efficacy of word embedding for the purpose of text classification. The proposed design facilitates the extraction of both local and global features of textual feature words and employs an attention mechanism to compute the significance of words in text classification. The fusion model endeavors to enhance the performance of text classification tasks by effectively representing text documents through the combination of CNNs, Bi-GRUs, and multi-attention mechanisms. This approach aims to capture both local and global contextual information, thereby improving the model’s ability to process and analyze textual data. Moreover, the amalgamation of diverse models can potentially augment the precision of text categorization. The study involved conducting experiments on various data sets, including the IMDB film review data set and the THUCNews data set. The results of the study demonstrate that the proposed model exhibits superior performance compared to previous models that relied solely on CNN, LSTM, or fusion models that integrated these architectures. This superiority is evident in terms of accuracy, recall rate, and F1 score.",
        "keywords": "",
        "link": "http://dx.doi.org/10.4108/eetsis.3992"
    },
    {
        "id": 21930,
        "title": "Efficient Shapley Values Estimation by Amortization for Text Classification",
        "authors": "Chenghao Yang, Fan Yin, He He, Kai-Wei Chang, Xiaofei Ma, Bing Xiang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.483"
    },
    {
        "id": 21931,
        "title": "A Communication-Efficient Federated Text Classification Method Based on Parameter Pruning",
        "authors": "Zheng Huo, Yilin Fan, Yaxin Huang",
        "published": "2023-6-21",
        "citations": 0,
        "abstract": "Text classification is an important application of machine learning. This paper proposes a communication-efficient federated text classification method based on parameter pruning. In the federated learning architecture, the data distribution of different participants is not independent and identically distributed; a federated word embedding model FedW2V is proposed. Then the TextCNN model is extended to the federated architecture. To reduce the communication cost of the federated TextCNN model, a parameter pruning algorithm called FedInitPrune is proposed, which reduces the amount of communication data both in the uplink and downlink during the parameter transmission phase. The algorithms are tested on real-world datasets. The experimental results show that when the text classification model accuracy reduces by less than 2%, the amount of federated learning communication parameters can be reduced by 74.26%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math11132804"
    },
    {
        "id": 21932,
        "title": "Analyzing BERT’s Performance Compared to Traditional Text Classification Models",
        "authors": "Bihi Sabiri, Amal Khtira, Bouchra El Asri, Maryem Rhanoui",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011983100003467"
    },
    {
        "id": 21933,
        "title": "Why Do We Need Domain-Experts for End-to-End Text Classification? An Overview",
        "authors": "Jakob Andersen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011605900003393"
    },
    {
        "id": 21934,
        "title": "Nanoscale Text Classification with Bi-LSTM: Enhancing Precision",
        "authors": "",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17756/nwj.2023-s4-070"
    },
    {
        "id": 21935,
        "title": "Efficient Use of Large Language Models for Analysis of Text Corpora",
        "authors": "David Adamczyk, Jan Hůla",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012349800003654"
    },
    {
        "id": 21936,
        "title": "Classification and Textual Function of Conclusions in Text and Paragraphs",
        "authors": "Biyu Wu, Jiayao Fan, Hui Sun",
        "published": "2023-4",
        "citations": 0,
        "abstract": "Text and paragraph are two forms of discourse. Their conclusions are similar in structure and semantics. There are three types of conclusion sentence in paragraphs: closing sentence, comment sentence, concluding sentence. The closing sentence is the restatement of the theme of the paragraph and generally has a discourse marker indicating a summary; The comment sentence is the remark on the topic of the paragraph; The concluding sentence is the ending of the paragraph with both summary and comment. When the conclusion sentence is in the thesis paragraph, it is also the thesis statement of the text. There are two types of paragraphs in the conclusion part of the text: the transitional paragraph and the conclusion paragraph. The latter is a summary and comment on the topic of the text. Usually, the topic sentence of the conclusion paragraph, often accompanied by discourse markers indicating the general conclusion, is the closing sentence of the text, which forms a circulation in viewpoint with the thesis statement of the text through lexical cohesion of keyword repetition. The conclusion sentence of the conclusion paragraph is the comment sentence of the text, which forms an emotional echo with the title of the text and realizes the sublimation of the theme.",
        "keywords": "",
        "link": "http://dx.doi.org/10.18178/ijlll.2023.9.2.397"
    },
    {
        "id": 21937,
        "title": "Analogical Text Mining: Application to Arabic Text Summarization and Classification",
        "authors": "Bilel Elayeb, Amina Chouigui, Myriam Bounhas",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aiccsa59173.2023.10479304"
    },
    {
        "id": 21938,
        "title": "Towards Low-Budget Real-Time Active Learning for Text Classification via Proxy-Based Data Selection",
        "authors": "Jakob Andersen, Olaf Zukunft",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011606000003393"
    },
    {
        "id": 21939,
        "title": "Randout-KD: Finetuning Foundation Models for Text Classification via Random Noise and Knowledge Distillation",
        "authors": "Pervaiz Khan, Andreas Dengel, Sheraz Ahmed",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011687800003393"
    },
    {
        "id": 21940,
        "title": "Feature-enhanced text-inception model for Chinese long text classification",
        "authors": "Guo Yang, Yan Jiayu, Xu Dongdong, Guo Zelin, Huan Hai",
        "published": "2023-2-6",
        "citations": 2,
        "abstract": "AbstractTo solve the problem regarding unbalanced distribution of multi-category Chinese long texts and improve the classification accuracy thereof, a data enhancement method was proposed. Combined with this method, a feature-enhanced text-inception model for Chinese long text classification was proposed. First, the model used a novel text-inception module to extract important shallow features of the text. Meanwhile, the bidirectional gated recurrent unit (Bi-GRU) and the capsule neural network were employed to form a deep feature extraction module to understand the semantic information in the text; K-MaxPooling was then used to reduce the dimension of its shallow and deep features and enhance the overall features. Finally, the Softmax function was used for classification. By comparing the classification effects with a variety of models, the results show that the model can significantly improve the accuracy of long Chinese text classification and has a strong ability to recognize long Chinese text features. The accuracy of the model is 93.97% when applied to an experimental dataset.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-023-29013-0"
    },
    {
        "id": 21941,
        "title": "Performance analysis of token-based text augmentation techniques on text classification tasks in Indic languages",
        "authors": "Rishabh Shirke, Anupam Agrawal",
        "published": "2023-8-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icscc59169.2023.10335009"
    },
    {
        "id": 21942,
        "title": "Efficient Adaptive Convolutional Model Based on Label Embedding for Text Classification Using Low Resource Languages",
        "authors": "Victor Kwaku Agbesi, Chen Wenyu, Abush S. Ameneshewa, Emmanuel Odame, Koffi Dumor, Judith Ayekai Browne",
        "published": "2023-4-23",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3596947.3596962"
    },
    {
        "id": 21943,
        "title": "Emotion Detection from Text: Classification and Prediction of Moods in Real-Time Streaming Text",
        "authors": "Prachi Juyal, Amit Kundalya",
        "published": "2023-8-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icirca57980.2023.10220607"
    },
    {
        "id": 21944,
        "title": "FastText Embedding and LSTM for Sentiment Analysis: An Empirical Study on Algerian Tweets",
        "authors": "Lamia Ouchene, Sadik Bessou",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icit58056.2023.10226060"
    },
    {
        "id": 21945,
        "title": "Text Classification using LSTM",
        "authors": "",
        "published": "2023-7-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets43078"
    },
    {
        "id": 21946,
        "title": "Ensemble-Based Text Classification for Spam Detection",
        "authors": "Meng Zhang",
        "published": "2024-4-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.31449/inf.v48i6.5246"
    },
    {
        "id": 21947,
        "title": "Efficient Long-Text Understanding with Short-Text Models",
        "authors": "Maor Ivgi, Uri Shaham, Jonathan Berant",
        "published": "2023-3-22",
        "citations": 6,
        "abstract": "AbstractTransformer-based pretrained language models (LMs) are ubiquitous across natural language understanding, but cannot be applied to long sequences such as stories, scientific articles, and long documents due to their quadratic complexity. While a myriad of efficient transformer variants have been proposed, they are typically based on custom implementations that require expensive pretraining from scratch. In this work, we propose SLED: SLiding-Encoder and Decoder, a simple approach for processing long sequences that re-uses and leverages battle-tested short-text pretrained LMs. Specifically, we partition the input into overlapping chunks, encode each with a short-text LM encoder and use the pretrained decoder to fuse information across chunks (fusion-in-decoder). We illustrate through controlled experiments that SLED offers a viable strategy for long text understanding and evaluate our approach on SCROLLS, a benchmark with seven datasets across a wide range of language understanding tasks. We find that SLED is competitive with specialized models that are up to 50x larger and require a dedicated and expensive pretraining step.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1162/tacl_a_00547"
    },
    {
        "id": 21948,
        "title": "MEGClass: Extremely Weakly Supervised Text Classification via Mutually-Enhancing Text Granularities",
        "authors": "Priyanka Kargupta, Tanay Komarlu, Susik Yoon, Xuan Wang, Jiawei Han",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.708"
    },
    {
        "id": 21949,
        "title": "Multi-lingual text classification models to detect hate and offensive text",
        "authors": "Pranav Kumar, Pranav Garg, Mansi Chitkara, Gulshan Dhillon",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0177435"
    },
    {
        "id": 21950,
        "title": "SF-CNN: Deep Text Classification and Retrieval for Text Documents",
        "authors": "R. Sarasu, K. K. Thyagharajan, N. R. Shanker",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/iasc.2023.027429"
    },
    {
        "id": 21951,
        "title": "Core sentence vector text matching algorithm based on text classification dataset",
        "authors": "Zhenyu Qin, Junmin Wu",
        "published": "2023-5-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2674769"
    },
    {
        "id": 21952,
        "title": "Image and Text: Fighting the same Battle? Super Resolution Learning for Imbalanced Text Classification",
        "authors": "Romain Meunier, Benamara Farah, Véronique Moriceau, Patricia Stolf",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.718"
    },
    {
        "id": 21953,
        "title": "Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification using Graph Neural Networks?",
        "authors": "Margarita Bugueño, Gerard de Melo",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.600"
    },
    {
        "id": 21954,
        "title": "Semantic Text Compression for Classification",
        "authors": "Emrecan Kutay, Aylin Yener",
        "published": "2023-5-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccworkshops57953.2023.10283705"
    },
    {
        "id": 21955,
        "title": "A COMPARATIVE ANALYSIS OF TEXT CLASSIFICATION ALGORITHMS FOR POS AMBIGUITY USING WEKA",
        "authors": "",
        "published": "2023-5-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.48047/ecb/2023.12.si6.036"
    },
    {
        "id": 21956,
        "title": "Contrastive classification: A label-independent generalization model for text classification",
        "authors": "Yi Liang, Turdi Tohti, Askar Hamdulla",
        "published": "2024-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.123130"
    },
    {
        "id": 21957,
        "title": "Text VQA with Token Classification of Recognized Text and Rule-Based Numerical Reasoning",
        "authors": "V. O. Surkov,  , D. A. Evseev",
        "published": "2023-6-19",
        "citations": 0,
        "abstract": "In this paper, we describe a question answering system on document images which is capable of numerical reasoning over extracted structured data. The system performs optical character recognition, detection of key attributes in text, generation of a numerical reasoning program, and its execution with the values of key attributes as operands. OCR includes the steps of bounding boxes detection and recognition of text from bounding boxes. The extraction of key attributes, such as quantity and price of goods, total etc., is based on the BERT token classification model. For expression generation we investigated the rule-based approach and the T5-base model and found that T5 is capable of generalization to expression types unseen in the training set. The proposed architecture of the question answering system utilizes the structure of independent blocks, each of which can be enhanced or replaced while keeping other components unchanged. The proposed model was evaluated in the Receipt-AVQA competition and on FUNSD dataset.",
        "keywords": "",
        "link": "http://dx.doi.org/10.28995/2075-7182-2023-22-486-496"
    },
    {
        "id": 21958,
        "title": "mLongT5: A Multilingual and Efficient Text-To-Text Transformer for Longer Sequences",
        "authors": "David Uthus, Santiago Ontanon, Joshua Ainslie, Mandy Guo",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.628"
    },
    {
        "id": 21959,
        "title": "Evaluating Gender Bias in Pre-trained Filipino FastText Embeddings",
        "authors": "Lance Calvin Gamboa, Maria Regina Justina Estuar",
        "published": "2023-3-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/itikd56332.2023.10100022"
    },
    {
        "id": 21960,
        "title": "BiLSTM Text Classification Incorporating Attentional Mechanisms",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25236/ajcis.2023.061314"
    },
    {
        "id": 21961,
        "title": "Automatic Text Classification Model Based on Machine Learning",
        "authors": "",
        "published": "2023-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.38007/ml.2023.040106"
    },
    {
        "id": 21962,
        "title": "An Efficient Information Extraction Mechanism with Page Ranking and a Classification Strategy based on Similarity Learning of Web Text Documents",
        "authors": "Sunil Kumar Thota, G V S Raj Kumar, B. Raja Koti, K. Naveen Kumar",
        "published": "2023-9-20",
        "citations": 0,
        "abstract": "Users have recently had more access to information thanks to the growth of the www information system. In these situations, search engines have developed into an essential tool for consumers to find information in a big space. The difficulty of handling this wealth of knowledge grows more difficult every day. Although search engines are crucial for information gathering, many of the results they offer are not required by the user because they are ranked according on user string matches. As a result, there were semantic disparities between the terms used in the user inquiry and the importance of catch phrases in the results. The problem of grouping relevant information into categories of related topics hasn't been solved. A Ranking Based Similarity Learning Approach and SVM based classification frame work of web text to estimate the semantic comparison between words to improve extraction of information is proposed in the work. The results of the experiment suggest improvisation in order to obtain better results by retrieving more relevant results.",
        "keywords": "",
        "link": "http://dx.doi.org/10.17762/ijritcc.v11i8.7948"
    },
    {
        "id": 21963,
        "title": "A Text Block Refinement Framework For Text Classification and Object Recognition From Academic Articles",
        "authors": "Li Jinghong, Ota Koichi, Gu Wen, Hasegawa Shinobu",
        "published": "2023-9-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/inista59065.2023.10310320"
    },
    {
        "id": 21964,
        "title": "Efficient Deep Learning Ensemble for Skin Lesion Classification",
        "authors": "David Gaviria, Md Saker, Petia Radeva",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011816100003417"
    },
    {
        "id": 21965,
        "title": "An Effective, Efficient, and Scalable Confidence-based Instance Selection Framework for Transformer-Based Text Classification",
        "authors": "Washington Cunha, Celso França, Guilherme Fonseca, Leonardo Rocha, Marcos André Gonçalves",
        "published": "2023-7-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3539618.3591638"
    },
    {
        "id": 21966,
        "title": "Text2Topic: Multi-Label Text Classification System for Efficient Topic Detection in User Generated Content with Zero-Shot Capabilities",
        "authors": "Fengjun Wang, Moran Beladev, Ofri Kleinfeld, Elina Frayerman, Tal Shachar, Eran Fainman, Karen Lastmann Assaraf, Sarai Mizrachi, Benjamin Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-industry.10"
    },
    {
        "id": 21967,
        "title": "“Low-Resource” Text Classification: A Parameter-Free Classification Method with Compressors",
        "authors": "Zhiying Jiang, Matthew Yang, Mikhail Tsirlin, Raphael Tang, Yiqin Dai, Jimmy Lin",
        "published": "2023",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.426"
    },
    {
        "id": 21968,
        "title": "Topic Classification of Key Audit Matters in Japanese Audit Reports by Zero-shot Text Classification",
        "authors": "Nobushige Doi, Yusuke Nobuta, Takeshi Mizuno",
        "published": "2023-7-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iiai-aai59060.2023.00108"
    },
    {
        "id": 21969,
        "title": "Text length considered adaptive bagging ensemble learning algorithm for text classification",
        "authors": "Youwei Wang, Jiangchun Liu, Lizhou Feng",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-14578-9"
    },
    {
        "id": 21970,
        "title": "Natural Language Processing Approach for Classification of Archetypes Using Text on Business Environments",
        "authors": "Richard Mariano, Ana Conceição de Jesus, Alessandro Vieira, Jessica Almeida de Lima, Giulia Zanon de Castro, Wladmir Brandão",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011856200003467"
    },
    {
        "id": 21971,
        "title": "Label Hierarchy Alignment for Improved Hierarchical Text Classification",
        "authors": "Ashish Kumar, Durga Toshniwal",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386495"
    },
    {
        "id": 21972,
        "title": "PyPatentAlice: Text-based classification of patents after Alice",
        "authors": "Dominik Jurek",
        "published": "2024-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.simpa.2023.100611"
    },
    {
        "id": 21973,
        "title": "An Enhanced and Efficient approach towards text detection and extracting text in multi-oriented images",
        "authors": "Ashutosh Shankhdhar, Lakshya Daga, Gargi Jadaun",
        "published": "2023-1-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aisc56616.2023.10085454"
    },
    {
        "id": 21974,
        "title": "Small-Text: Active Learning for Text Classification in Python",
        "authors": "Christopher Schröder, Lydia Müller, Andreas Niekler, Martin Potthast",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.eacl-demo.11"
    },
    {
        "id": 21975,
        "title": "Image and Text Feature Based Multimodal Learning for Multi-Label Classification of Radiology Images in Biomedical Literature",
        "authors": "Md. Hasan, Md Jani, Md Rahman",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012438400003657"
    },
    {
        "id": 21976,
        "title": "An Unseen Features Enhanced Text Classification Approach",
        "authors": "Nesar Ahmad Wasi, Muhammad Abulaish",
        "published": "2023-6-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191857"
    },
    {
        "id": 21977,
        "title": "Deep Learning Based Text Classification Methods",
        "authors": "Zhaoguo Wang",
        "published": "2023-2-28",
        "citations": 1,
        "abstract": "Text classification tasks are indispensable in natural language processing. With the development of Internet technology, the way people transmit information has changed from letters to the Internet. With the increase in the amount of information, manual data annotation is inefficient. After 2010, the emergence of deep learning methods has brought text classification into an epoch-making stage. ReNN-> MLP-> RNN-> CNN-> Attention -> Transformer-> GNN and other text classification methods are gradually being developed and known by everyone, which also shows that text classification is developing towards a text feature that does not rely on manually acquired text features and is directly learning from the text content and modelling. This paper will start with basic knowledge, first let everyone understand the nature, application and historical background of text classification, will briefly introduce shallow learning, then enter deep learning, Select the classic model from the six classification methods from ReNN to Transformer for brief analysis, briefly analyse the model from the principle of the model, what problems it is good at solving, problems or shortcomings that it is not good at solving. Finally, the paper describes the performance of these models on the dataset.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v34i.5478"
    },
    {
        "id": 21978,
        "title": "Research on Text Classification Method Based on NLP",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23977/acss.2023.070213"
    },
    {
        "id": 21979,
        "title": "A Branch-and-Bound Approach to Efficient Classification and Retrieval of Documents",
        "authors": "Kotaro Ii, Hiroto Saigo, Yasuo Tabei",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012310600003654"
    },
    {
        "id": 21980,
        "title": "Learning Word Embeddings for Ukrainian: A Comparative Study of FastText Hyperparameters",
        "authors": "Nataliia Romanyshyn, Dmytro Chaplynskyi, Kyrylo Zakharov",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.unlp-1.3"
    },
    {
        "id": 21981,
        "title": "Active Learning Based on Transfer Learning Techniques for Text Classification",
        "authors": "Daniela Onita",
        "published": "2023",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3260771"
    },
    {
        "id": 21982,
        "title": "ANALYSIS OF ALGORITHMS FOR TEXT CLASSIFICATION",
        "authors": "Tatiana Logunova, Lidiia Shcherbakova, Vasilii Vasiukov, Viacheslav Shimkun",
        "published": "2023-2-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32743/unitech.2023.107.2.15064"
    },
    {
        "id": 21983,
        "title": "Text Sentiment Classification Method Based on Bilstm",
        "authors": "Wenliang Wang",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "In the booming age of digital communication and natural language processing(NLP), understanding user sentiments expressed in texts has become increasingly vital. This research addresses the challenge of classifying text sentiments into three distinct categories: positive, neutral, and negative. Recognizing the nuances of human emotion in textual content is paramount for enhancing user experiences and tailoring personalized digital interactions. This study trains a BiLSTM model, supplemented with optimization strategies to adaptively learn from a diverse dataset. Additionally, a large number of baseline experiments were conducted to compare its efficacy with traditional algorithms such as Logistic Regression. The BiLSTM model demonstrated a good accuracy of 78.21% on the test set. Conclusively, while the proposed model shows significant potential, further refinements could be made, emphasizing data augmentation and model regularization to achieve optimal performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hbem.v21i.14737"
    },
    {
        "id": 21984,
        "title": "Hierarchical Label Text Classification Method with Deep-Level Label-Assisted Classification",
        "authors": "Cao Yu-kun, Wei Zi-yue, Tang Yi-jia, Jin Cheng-kun",
        "published": "2023-5-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ddcls58216.2023.10166293"
    },
    {
        "id": 21985,
        "title": "Utilization of relative context for text non-text region classification in offline documents using multi-scale dilated convolutional neural network",
        "authors": "Showmik Bhowmik",
        "published": "2023-9-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-16546-9"
    },
    {
        "id": 21986,
        "title": "Depression and Suicide Risk Detection on Social Media using fastText Embedding and XGBoost Classifier",
        "authors": "Sayani Ghosal, Amita Jain",
        "published": "2023",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.procs.2023.01.141"
    },
    {
        "id": 21987,
        "title": "Research on sensitive text classification detection and classification based on improved artificial neural network",
        "authors": "Haisheng Gu, Qing Li, Duanming Shen",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10878-023-01085-8"
    },
    {
        "id": 21988,
        "title": "Handwritten Text Classification Based on Convolutional Neural Network",
        "authors": "Aldyn Chen",
        "published": "2023-2-28",
        "citations": 0,
        "abstract": "The convolutional neural network (CNN) is a popular and highly effective deep learning technique for image classification. As the popularity of CNNs grew, the model has become popular in several machine learning problems. This paper utilizes a CNN model and the popular LeNet-5 transfer learned model to classify texts after the words are preprocessed and segmented from an image. The EMNIST database is used to train the models. The paper achieves an 89.36% validation accuracy on the EMNIST Balanced dataset and an 86.64% on the EMNIST By_Class dataset for the CNN model of four convolutional layers and one dense layer. Similarly, the LeNet-5 model obtained a validation accuracy of 85.88% on the EMNIST Balanced dataset and 85.01% accuracy on the EMNIST By_Class dataset. However, despite a higher accuracy in the EMNIST Balanced dataset, the EMNIST By_Class dataset achieves better results in real-world handwritten texts.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v34i.5372"
    },
    {
        "id": 21989,
        "title": "Evaluation of Healthprompt for Zero-shot Clinical Text Classification",
        "authors": "Sonish Sivarajkumar, Yanshan Wang",
        "published": "2023-6-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ichi57859.2023.00081"
    },
    {
        "id": 21990,
        "title": "Detecting textual adversarial examples through text modification on text classification systems",
        "authors": "Hyun Kwon, Sanghyun Lee",
        "published": "2023-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10489-022-03313-w"
    },
    {
        "id": 21991,
        "title": "Neural Architecture Search for Text Classification With Limited Computing Resources Using Efficient Cartesian Genetic Programming",
        "authors": "Xuan Wu, Di Wang, Huanhuan Chen, Lele Yan, Yubin Xiao, Chunyan Miao, Hongwei Ge, Dong Xu, Yanchun Liang, Kangping Wang, Chunguo Wu, You Zhou",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tevc.2023.3346969"
    },
    {
        "id": 21992,
        "title": "Learning under Label Proportions for Text Classification",
        "authors": "Jatin Chauhan, Xiaoxuan Wang, Wei Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.817"
    },
    {
        "id": 21993,
        "title": "A Comprehensive Review on Transformers Models For Text Classification",
        "authors": "Rania Kora, Ammar Mohammed",
        "published": "2023-9-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/miucc58832.2023.10278387"
    },
    {
        "id": 21994,
        "title": "Text classification algorithms exploration on sentiment analysis",
        "authors": "Xupeng Zhang",
        "published": "2023-6-14",
        "citations": 1,
        "abstract": "Internet provides us with an abundance of useful tools and data. However, it also generates a vast quantity of data that may bewilder us. There must be a technique for automatically processing these data. Here, text classification becomes useful. Text classification is the algorithm-based process of categorizing data inputs into distinct labels. For instance, email software utilizes it to assess if an email should be filtered into the spam folder, social media forums use it to classify postings into labels that are relevant to the topic, etc. Text categorization is utilized in a variety of businesses, including search engines, sentiment analysis, emergency response systems, chatbots, etc. Review websites have emerged in recent years where customers may share their opinions on a business or a product. The review is extremely emotive but crucial to the company. It is possible to accurately assess the reviews for the sentiment they present through text classification. This paper compares the efficacy of various text classification algorithms for sentiment analysis.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/5/20230541"
    },
    {
        "id": 21995,
        "title": "A Turkish Text Classification Based Feature Selection and Density Peaks Clustering",
        "authors": "Ezgi Zorarpaci",
        "published": "2023-7-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/siu59756.2023.10223750"
    },
    {
        "id": 21996,
        "title": "Augmentation in a Binary Text Classification Task",
        "authors": "Bohdan Pavlyshenko, Mykola Stasiuk",
        "published": "2023-9-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/elit61488.2023.10311045"
    },
    {
        "id": 21997,
        "title": "Fine-Tuning Fasttext Using Bayesian Optimization for Movie Review Sentiment Analysis",
        "authors": "Rico Halim, Abba Suganda Girsang, Mohammad Faisal Riftiarrasyid",
        "published": "2023-12-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icteca60133.2023.10490756"
    },
    {
        "id": 21998,
        "title": "Short Text Sentiment Classification Using Bayesian and Deep Neural Networks",
        "authors": "Zhan Shi, Chongjun Fan",
        "published": "2023-3-28",
        "citations": 0,
        "abstract": "The previous multi-layer learning network is easy to fall into local extreme points in supervised learning. If the training samples sufficiently cover future samples, the learned multi-layer weights can be well used to predict new test samples. This paper mainly studies the research and analysis of machine short text sentiment classification based on Bayesian network and deep neural network algorithm. It first introduces Bayesian network and deep neural network algorithms, and analyzes the comments of various social software such as Twitter, Weibo, and other popular emotional communication platforms. Using modeling technology popular reviews are designed to conduct classification research on unigrams, bigrams, parts of speech, dependency labels, and triplet dependencies. The results show that the range of its classification accuracy is the smallest as 0.8116 and the largest as 0.87. These values are obtained when the input nodes of the triple dependency feature are 12,000, and the reconstruction error range of the Boltzmann machine is limited between 7.3175 and 26.5429, and the average classification accuracy is 0.8301. The advantages of triplet dependency features for text representation in text sentiment classification tasks are illustrated. It shows that Bayesian and deep neural network show good advantages in short text emotion classification.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12071589"
    },
    {
        "id": 21999,
        "title": "N-Gram-Based Serbian Text Classification",
        "authors": "Petar Prvulović, Nemanja Radosavljević, Dušan Vujošević, Dhinaharan Nagamalai, Jelena Vasiljević",
        "published": "2023-9-16",
        "citations": 0,
        "abstract": "Natural language processing is an active area of research which finds many applications in variety of fields. Low-resource languages are a challenge as they lack curated datasets, stemmers and other elements used in text processing. Statistical approach is an alternative which can be used to bypass lack of rule-based implementations. The paper presents a model for classification of unstructured text in Serbian language. The model uses n-gram-based stemming to create document attributes vectors. Vectors are created on 3-, 4- and 5-grams. Vector reduction is tested on two criteria: n-gram entropy and number of occurrences, and two lengths: 1000 and 2000 n-grams. The support vector machine is used to classify documents. The model is trained and tested on a dataset collected from a Serbian news portal. Classification accuracy of over 80% is achieved. The presented model provides a good basis for range of applications in business decision automation for low-resource languages.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5121/csit.2023.131613"
    },
    {
        "id": 22000,
        "title": "Few-shot Text Classification Method Based on Feature Optimization",
        "authors": "Jing Peng, Shuquan Huo",
        "published": "2023-7-3",
        "citations": 0,
        "abstract": "For the poor effect of few-shot text classification caused by insufficient data for feature representation, this paper combines wide and deep attention bidirectional long short time memory (WDAB-LSTM) and a prototypical network to optimize text features for better classification performance. With this proposed algorithm, text enhancement and preprocessing are firstly adopted to solve the problem of insufficient samples and WDAB-LSTM is used to increase word attention to get output vectors containing important context-related information. Then the prototypical network is added to optimize the distance measurement module in the model for a better effect on feature extraction and sample representation. To test the performance of this algorithm, Amazon Review Sentiment Classification (ARSC), Text Retrieval Conference (TREC), and Kaggle are selected. Compared with the Siamese network and the prototypical network, the proposed algorithm with feature optimization has a relatively higher accuracy rate, precision rate, recall rate, and F1 value.",
        "keywords": "",
        "link": "http://dx.doi.org/10.13052/jwe1540-9589.2235"
    },
    {
        "id": 22001,
        "title": "IndoBERT Based Data Augmentation for Indonesian Text Classification",
        "authors": "Fuad Muftie, Muhammad Haris",
        "published": "2023-8-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icitri59340.2023.10250061"
    },
    {
        "id": 22002,
        "title": "Named Entity Recognition Utilized to Enhance Text Classification While Preserving Privacy",
        "authors": "Mohammed Kutbi",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3325895"
    },
    {
        "id": 22003,
        "title": "Multilingual Text Classification Based On Deep Learning Models",
        "authors": "Lanxin Lin",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/itaic58329.2023.10409100"
    },
    {
        "id": 22004,
        "title": "Enhancing Arabic Text Classification with a Hybrid Word Embedding Method",
        "authors": "Eman Aljohani",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dese60595.2023.10468772"
    },
    {
        "id": 22005,
        "title": "Text classification based on <scp>PEGCN</scp>: Graph convolution classification using location information and edge features",
        "authors": "Ruidong Zhang, Zelin Guo, Hai Huan",
        "published": "2024-3",
        "citations": 0,
        "abstract": "AbstractThe purpose of text classification is to label the text with known labels. In recent years, the method based on graph neural network (GNN) has achieved good results. However, the existing methods based on GNN only regard the text as the set of co‐occurring words, without considering the position information of each word in the statement. At the same time, the method mainly extracts the node features in the graph, and the edge features between the nodes are not used enough. To solve these problems, a new text classification method, graph convolutional network using positions and edges, is proposed. In the word embedding section, a positional encoding input representation is employed to enable the neural network to learn the relative positional information among words. Meanwhile, the dimension of the adjacency matrix is increased to extract the multi‐dimensional edge features. Through experiments on multiple text classification datasets, the proposed method is shown to be superior to the traditional text classification method, and has achieved a maximum improvement of more than 4%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1111/exsy.13511"
    },
    {
        "id": 22006,
        "title": "EFFICIENT SUMMERIZATION OF TEXT THROUGH EXTRACTIVE METHODS",
        "authors": "",
        "published": "2023-5-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets38099"
    },
    {
        "id": 22007,
        "title": "On Enhancement of Text Classification and Analysis of Text Emotions Using Graph Machine Learning and Ensemble Learning Methods on Non-English Datasets",
        "authors": "Fatemeh Gholami, Zahed Rahmati, Alireza Mofidi, Mostafa Abbaszadeh",
        "published": "2023-10-4",
        "citations": 0,
        "abstract": "In recent years, machine learning approaches, in particular graph learning methods, have achieved great results in the field of natural language processing, in particular text classification tasks. However, many of such models have shown limited generalization on datasets in different languages. In this research, we investigate and elaborate graph machine learning methods on non-English datasets (such as the Persian Digikala dataset), which consists of users’ opinions for the task of text classification. More specifically, we investigate different combinations of (Pars) BERT with various graph neural network (GNN) architectures (such as GCN, GAT, and GIN) as well as use ensemble learning methods in order to tackle the text classification task on certain well-known non-English datasets. Our analysis and results demonstrate how applying GNN models helps in achieving good scores on the task of text classification by better capturing the topological information between textual data. Additionally, our experiments show how models employing language-specific pre-trained models (like ParsBERT, instead of BERT) capture better information about the data, resulting in better accuracies.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/a16100470"
    },
    {
        "id": 22008,
        "title": "Text Classification System Using Text Mining with XGBoost Method",
        "authors": "Ni Kadek Dwi Rusjayanthi, Anak Agung Kompiang Oka Sudana, I Nyoman Prayana Trisna",
        "published": "2023-8-21",
        "citations": 0,
        "abstract": "Large data nowadays can be used for analysis; thus, it can obtain important/valuable knowledge in various domains. Text analysis can be carried out by utilizing text mining using computational methods so that knowledge extraction can be carried out on large text data, including processing related to unstructured text data, which is written in natural language. Classification in text mining is a type of work with the searching process for a set of models or functions that describe and differentiate text data classes with the aim that the model can be used to predict the class of an object (text data) whose class is unknown. Text mining was carried out in this research to analyze text data through the Text Classification System using a classification method, namely the XGBoost (eXtreme Gradient Boosting) Method. A text classification system was developed to classify text in the form of articles. The highest accuracy obtained from the test is 77%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.24843/jim.2023.v11.i02.p01"
    },
    {
        "id": 22009,
        "title": "TextNetTopics Pro, a topic model-based text classification for short text by integration of semantic and document-topic distribution information",
        "authors": "Daniel Voskergian, Burcu Bakir-Gungor, Malik Yousef",
        "published": "2023-10-5",
        "citations": 0,
        "abstract": "With the exponential growth in the daily publication of scientific articles, automatic classification and categorization can assist in assigning articles to a predefined category. Article titles are concise descriptions of the articles’ content with valuable information that can be useful in document classification and categorization. However, shortness, data sparseness, limited word occurrences, and the inadequate contextual information of scientific document titles hinder the direct application of conventional text mining and machine learning algorithms on these short texts, making their classification a challenging task. This study firstly explores the performance of our earlier study, TextNetTopics on the short text. Secondly, here we propose an advanced version called TextNetTopics Pro, which is a novel short-text classification framework that utilizes a promising combination of lexical features organized in topics of words and topic distribution extracted by a topic model to alleviate the data-sparseness problem when classifying short texts. We evaluate our proposed approach using nine state-of-the-art short-text topic models on two publicly available datasets of scientific article titles as short-text documents. The first dataset is related to the Biomedical field, and the other one is related to Computer Science publications. Additionally, we comparatively evaluate the predictive performance of the models generated with and without using the abstracts. Finally, we demonstrate the robustness and effectiveness of the proposed approach in handling the imbalanced data, particularly in the classification of Drug-Induced Liver Injury articles as part of the CAMDA challenge. Taking advantage of the semantic information detected by topic models proved to be a reliable way to improve the overall performance of ML classifiers.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fgene.2023.1243874"
    },
    {
        "id": 22010,
        "title": "Multi-dimensional Semantic-based Text Classification Model",
        "authors": "Xiaoyan Gongye, Chongxu Hu, Xiaohu Zhang, Shuang Liu",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191647"
    },
    {
        "id": 22011,
        "title": "Long Text Classification using Transformers with Paragraph Selection Strategies",
        "authors": "Mohit Tuteja, Daniel González Juclà",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.nllp-1.3"
    },
    {
        "id": 22012,
        "title": "A review and analysis for the text-based classification",
        "authors": "",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.19101/ijacr.2023.1362008"
    },
    {
        "id": 22013,
        "title": "Enhancing the Generalization for Text Classification through Fusion of Backward Features",
        "authors": "Dewen Seng, Xin Wu",
        "published": "2023-1-23",
        "citations": 3,
        "abstract": "Generalization has always been a keyword in deep learning. Pretrained models and domain adaptation technology have received widespread attention in solving the problem of generalization. They are all focused on finding features in data to improve the generalization ability and to prevent overfitting. Although they have achieved good results in various tasks, those models are unstable when classifying a sentence whose label is positive but still contains negative phrases. In this article, we analyzed the attention heat map of the benchmarks and found that previous models pay more attention to the phrase rather than to the semantic information of the whole sentence. Moreover, we proposed a method to scatter the attention away from opposite sentiment words to avoid a one-sided judgment. We designed a two-stream network and stacked the gradient reversal layer and feature projection layer within the auxiliary network. The gradient reversal layer can reverse the gradient of features in the training stage so that the parameters are optimized following the reversed gradient in the backpropagation stage. We utilized an auxiliary network to extract the backward features and then fed them into the main network to merge them with normal features extracted by the main network. We applied this method to the three baselines of TextCNN, BERT, and RoBERTa using sentiment analysis and sarcasm detection datasets. The results show that our method can improve the sentiment analysis datasets by 0.5% and the sarcasm detection datasets by 2.1%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23031287"
    },
    {
        "id": 22014,
        "title": "BERT-based Classification of Four Major Dementias using Twitter Text Data",
        "authors": "Kazuki Utsunomiya, Ryohei Banno",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tencon58879.2023.10322384"
    },
    {
        "id": 22015,
        "title": "Distance-Based Meta-Features for Arabic Text Classification",
        "authors": "Maroua Louail, Chafia Kara-Mohamed alias Hamdi-Cherif",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/imsa58542.2023.10217428"
    },
    {
        "id": 22016,
        "title": "Text classification by BERT-Capsules",
        "authors": "Minghui Guo",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "This paper presents a model that integrates a BERT encoder with a Capsule network, eliminating the traditional fully connected layer designed for downstream classification tasks in BERT in favor of a capsule layer. This capsule layer consists of three main modules: the representation module, the probability module, and the reconstruction module. It transforms the final hidden layer output of BERT into the final activation capsule probabilities to classify the text. By applying the model to sentiment analysis and text classification tasks, and comparing the test results with various BERT variants, the performance across all metrics was found to be superior. Observing the model’s handling of multiple entities and complex relationships, sentences with high ambiguity were extracted to observe the probability distribution of all capsules and compared with RNN-Capsule. It was found that the activation capsule probabilities for BERT-Capsule were significantly higher than the rest, and more pronounced than RNN-Capsule, indicating the model’s exceptional ability to process ambiguous information.",
        "keywords": "",
        "link": "http://dx.doi.org/10.61173/wcg0nf17"
    },
    {
        "id": 22017,
        "title": "Text Classification Based on Neural Network Fusion",
        "authors": "Deageon Kim",
        "published": "2023-7-19",
        "citations": 0,
        "abstract": "The goal of text classification is to identify the category to which the text belongs. Text categorization is widely used in email detection, sentiment analysis, topic marking and other fields. However, good text representation is the point to improve the capability of NLP tasks. Traditional text representation adopts bag-of-words model or vector space model, which loses the context information of the text and faces the problems of high latitude and high sparsity,. In recent years, with the increase of data and the improvement of computing performance, the use of deep learning technology to represent and classify texts has attracted great attention. Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) and RNN with attention mechanism are used to represent the text, and then to classify the text and other NLP tasks, all of which have better performance than the traditional methods. In this paper, we design two sentence-level models based on the deep network and the details are as follows: (1) Text representation and classification model based on bidirectional RNN and CNN (BRCNN). BRCNN’s input is the word vector corresponding to each word in the sentence; after using RNN to extract word order information in sentences, CNN is used to extract higher-level features of sentences. After convolution, the maximum pool operation is used to obtain sentence vectors. At last, softmax classifier is used for classification. RNN can capture the word order information in sentences, while CNN can extract useful features. Experiments on eight text classification tasks show that BRCNN model can get better text feature representation, and the classification accuracy rate is equal to or higher than that of the prior art. (2) Attention mechanism and CNN (ACNN) model uses the RNN with attention mechanism to obtain the context vector; Then CNN is used to extract more advanced feature information. The maximum pool operation is adopted to obtain a sentence vector; At last, the softmax classifier is used to classify the text. Experiments on eight text classification benchmark data sets show that ACNN improves the stability of model convergence, and can converge to an optimal or local optimal solution better than BRCNN.",
        "keywords": "",
        "link": "http://dx.doi.org/10.31803/tg-20221228154330"
    },
    {
        "id": 22018,
        "title": "Classification of broadband network devices using text mining technique",
        "authors": "Mahasak Ketcham, Thittaporn Ganokratanaa, Nattapat Sridoung",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mex.2023.102346"
    },
    {
        "id": 22019,
        "title": "Research on text classification based on neural networks",
        "authors": "Mingshi Zheng",
        "published": "2024-2-22",
        "citations": 0,
        "abstract": "With the rapid development of information technology, the processing of massive text data has become increasingly important. As a common computer information processing task, text classification has attracted a wide range of research interests. This paper aims to explore the text classification method based on neural network and analyze the key technologies. In order to solve the problem of text time series data classification, this paper uses the text time series data of occupancy detection and applies these neural network models in deep learning, including recurrent neural network, long short-term memory and gated recurrent unit, and trains the neural network through supervised learning. Inputting the room attribute data to these trained neural network models and judging the occupancy of the room. At the same time, observing the experimental results of these neural network models, including training loss, test loss and accuracy, to further study the performance of neural network in processing text time series data classification. This papers experiment aims to evaluate the performance of neural network in text classification and makes a detailed analysis through the experimental results. The goal of the research is to find an effective solution based on neural networks for the classification of text sequence data. Through the analysis of the experimental results, it can be concluded that the method based on neural network is feasible and effective in text sequence data classification. These analysis results will help to further promote the development of text classification technology and provide guidance and reference for practical application. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/41/20230768"
    },
    {
        "id": 22020,
        "title": "DATA AUGMENTATION IN TEXT CLASSIFICATION WITH MULTIPLE CATEGORIES",
        "authors": "B. Pavlyshenko, M. Stasiuk",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.30970/eli.25.6"
    },
    {
        "id": 22021,
        "title": "Content Retrieval dengan Fasttext Word Embedding pada Learning Management System Olimpiade",
        "authors": "Rochana Prih Hastuti, Vellya Riona, Margareta Hardiyanti",
        "published": "2023-5-31",
        "citations": 0,
        "abstract": "Learning Management System (LMS) merupakan jenis media pembelajaran daring yang digunakan siswa di berbagai tingkat. Penggunaannya pada keperluan kompetisi, secara khusus olimpiade, memiliki karakteristik tersendiri dibanding LMS  untuk keperluan pembelajaran sehari-hari. Salah satunya adalah kemampuan sistem mengelola bank soal dan menyajikan kategori yang relevan kepada user. User pada LMS Olimpiade tersegmentasi sesuai bidang ilmu yang ingin ditekuni. Meski begitu, tiap bidang memiliki topik pembelajaran yang beragam jenisnya dan bahkan cenderung berkembang seiring waktu. Manajemen bank soal dengan anotasi topik di awal memerlukan tenaga ahli dan memakan waktu. Sedangkan fitur pencarian tanpa menggunakan informasi metadata tersebut tentu juga sulit dilakukan. Fitur pencarian semantik menjadi penting pada sistem seperti ini. Dibutuhkan skema pencarian berdasarkan konten yang mampu mengembalikan soal-soal yang relevan dengan topik di masing-masing bidang. Fitur pencarian dibangun menggunakan skema information retrieval yakni vector space model. Hasil eksperimen dan evaluasi responden menunjukkan representasi word embedding dengan performa pencarian terbaik adalah FastText word embedding. Efisiensi ukuran model dilakukan dengan menggunakan compressed version. Representasi ini selain dapat mengakomodasi hasil pencarian sesuai konteks kueri juga dapat mengatasi permasalahan out-of-vocabulary.",
        "keywords": "",
        "link": "http://dx.doi.org/10.22146/jise.v4i1.6766"
    },
    {
        "id": 22022,
        "title": "A Brief Survey of Text Classification Methods",
        "authors": "Qilu Jiao",
        "published": "2023-5-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciba56860.2023.10165621"
    },
    {
        "id": 22023,
        "title": "Multi-label Text Classification using GloVe and Neural Network Models",
        "authors": "Hongren Wang",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eiect60552.2023.10442284"
    },
    {
        "id": 22024,
        "title": "Application of Unsupervised Machine Learning Algorithm in Patent Text Classification",
        "authors": "JiaHong Ma, HaiYing Li",
        "published": "2023-6-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icise60366.2023.00087"
    },
    {
        "id": 22025,
        "title": "Fuzzy text/non-text classification of document images based on morphological operator, wavelet transform, and strong feature vector",
        "authors": "Mobina Ranjbar Malidareh, Amir Masoud Molaei",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijcvr.2023.10056059"
    },
    {
        "id": 22026,
        "title": "A transformer-based generative adversarial learning to detect sarcasm from Bengali text with correct classification of confusing text",
        "authors": "Sanzana Karim Lora, Ishrat Jahan, Rahad Hussain, Rifat Shahriyar, A.B.M. Alim Al Islam",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.heliyon.2023.e22531"
    },
    {
        "id": 22027,
        "title": "Efficient and Interpretable Compressive Text Summarisation with Unsupervised Dual-Agent Reinforcement Learning",
        "authors": "Peggy Tang, Junbin Gao, Lei Zhang, Zhiyong Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.sustainlp-1.17"
    },
    {
        "id": 22028,
        "title": "A Multilabel Text Classifier of Cancer Literature at the Publication Level: Methods Study of Medical Text Classification",
        "authors": "Ying Zhang, Xiaoying Li, Yi Liu, Aihua Li, Xuemei Yang, Xiaoli Tang",
        "published": "2023-10-5",
        "citations": 0,
        "abstract": "\nBackground\nGiven the threat posed by cancer to human health, there is a rapid growth in the volume of data in the cancer field and interdisciplinary and collaborative research is becoming increasingly important for fine-grained classification. The low-resolution classifier of reported studies at the journal level fails to satisfy advanced searching demands, and a single label does not adequately characterize the literature originated from interdisciplinary research results. There is thus a need to establish a multilabel classifier with higher resolution to support literature retrieval for cancer research and reduce the burden of screening papers for clinical relevance.\n\n\nObjective\nThe primary objective of this research was to address the low-resolution issue of cancer literature classification due to the ambiguity of the existing journal-level classifier in order to support gaining high-relevance evidence for clinical consideration and all-sided results for literature retrieval.\n\n\nMethods\nWe trained a multilabel classifier with scalability for classifying the literature on cancer research directly at the publication level to assign proper content-derived labels based on the “Bidirectional Encoder Representation from Transformers (BERT) + X” model and obtain the best option for X. First, a corpus of 70,599 cancer publications retrieved from the Dimensions database was divided into a training and a testing set in a ratio of 7:3. Second, using the classification terminology of International Cancer Research Partnership cancer types, we compared the performance of classifiers developed using BERT and 5 classical deep learning models, such as the text recurrent neural network (TextRNN) and FastText, followed by metrics analysis.\n\n\nResults\nAfter comparing various combined deep learning models, we obtained a classifier based on the optimal combination “BERT + TextRNN,” with a precision of 93.09%, a recall of 87.75%, and an F1-score of 90.34%. Moreover, we quantified the distinctive characteristics in the text structure and multilabel distribution in order to generalize the model to other fields with similar characteristics.\n\n\nConclusions\nThe “BERT + TextRNN” model was trained for high-resolution classification of cancer literature at the publication level to support accurate retrieval and academic statistics. The model automatically assigns 1 or more labels to each cancer paper, as required. Quantitative comparison verified that the “BERT + TextRNN” model is the best fit for multilabel classification of cancer literature compared to other models. More data from diverse fields will be collected to testify the scalability and extensibility of the proposed model in the future.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.2196/44892"
    },
    {
        "id": 22029,
        "title": "Finite State Automata on Multi-Word Units for Efficient Text-Mining",
        "authors": "Alberto Postiglione",
        "published": "2024-2-6",
        "citations": 1,
        "abstract": "Text mining is crucial for analyzing unstructured and semi-structured textual documents. This paper introduces a fast and precise text mining method based on a finite automaton to extract knowledge domains. Unlike simple words, multi-word units (such as credit card) are emphasized for their efficiency in identifying specific semantic areas due to their predominantly monosemic nature, their limited number and their distinctiveness. The method focuses on identifying multi-word units within terminological ontologies, where each multi-word unit is associated with a sub-domain of ontology knowledge. The algorithm, designed to handle the challenges posed by very long multi-word units composed of a variable number of simple words, integrates user-selected ontologies into a single finite automaton during a fast pre-processing step. At runtime, the automaton reads input text character by character, efficiently locating multi-word units even if they overlap. This approach is efficient for both short and long documents, requiring no prior training. Ontologies can be updated without additional computational costs. An early system prototype, tested on 100 short and medium-length documents, recognized the knowledge domains for the vast majority of texts (over 90%) analyzed. The authors suggest that this method could be a valuable semantic-based knowledge domain extraction technique in unstructured documents.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math12040506"
    },
    {
        "id": 22030,
        "title": "Parameter-Efficient Learning for Text-to-Speech Accent Adaptation",
        "authors": "Li-Jen Yang, Chao-Han Huck Yang, Jen-Tzung Chien",
        "published": "2023-8-20",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1212"
    },
    {
        "id": 22031,
        "title": "Efficient Spoken Language Recognition via Multilabel Classification",
        "authors": "Oriol Nieto, Zeyu Jin, Franck Dernoncourt, Justin Salamon",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1986"
    },
    {
        "id": 22032,
        "title": "Combining Metric Learning and Attention Heads for Accurate and Efficient Multilabel Image Classification",
        "authors": "Kirill Prokofiev, Vladislav Sovrasov",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011603700003417"
    },
    {
        "id": 22033,
        "title": "PhishDetect: A BiLSTM based phishing URL detection framework using FastText embeddings",
        "authors": "Kumar Mangalam, Basant Subba",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/comsnets59351.2024.10427067"
    },
    {
        "id": 22034,
        "title": "LSTM and Bidirectional GRU Comparison for Text Classification",
        "authors": "Hannan Asrawi, Ema Utami, Ainul Yaqin",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "Although the phrases machine learning and AI are frequently used interchangeably and are frequently discussed together, they do not have the same meanings. While all artificial intelligence (AI) is machine learning, not all AI is machine learning, which is a key distinction. In the beginning, machine learning and natural language processing (NLP) are related since machine learning is frequently employed as a tool for NLP tasks. The advantage of NLP is that it can perform analysis, and examine a lot of data, including comments on social media accounts and hundreds of online customer evaluations. Text classification is essentially what needs to be done. This study compares Bidirectional GRU and LSTM as text classification algorithms using 20,000 newsgroup documents from 20 newsgroups from The UCI KDD Archive.\r\nAfter using the suggested model, we compare it to the long short-term memory and bidirectional GRU models for accuracy and validation. The results of the two comparisons show that the bidirectional GRU model performs better than the long short-term memory model. And this is a successful classification of text using a deep learning algorithm that uses a bidirectional GRU.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33395/sinkron.v8i4.12899"
    },
    {
        "id": 22035,
        "title": "Double-Channel Short Text Classification With Fused Enhanced Features",
        "authors": "Xiaochi Luo, Ningjia Qiu",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icise-ie60962.2023.10456399"
    },
    {
        "id": 22036,
        "title": "Hierarchical Label Generation for Text Classification",
        "authors": "Jingun Kwon, Hidetaka Kamigaito, Young-In Song, Manabu Okumura",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-eacl.46"
    },
    {
        "id": 22037,
        "title": "Granular computing-based deep learning for text classification",
        "authors": "Rashid Behzadidoost, Farnaz Mahan, Habib Izadkhah",
        "published": "2024-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ins.2023.119746"
    },
    {
        "id": 22038,
        "title": "A Submodular Optimization Framework for Imbalanced Text Classification With Data Augmentation",
        "authors": "Eyor Alemayehu, Yi Fang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3267669"
    },
    {
        "id": 22039,
        "title": "A Novel Text Classification Model Combining Time Correlation Principle and Rough Set Theory",
        "authors": "Dejun Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3332909"
    },
    {
        "id": 22040,
        "title": "A Text Classification Model Based on BERT and Attention",
        "authors": "Binglin Zhu, Wei Pan",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cait59945.2023.10469363"
    },
    {
        "id": 22041,
        "title": "KLASIFIKASI SENTIMEN VAKSIN COVID-19 MENGGUNAKAN K-NEAREST NEIGHBOR BERDASARKAN WORD EMBEDDINGS FASTTEXT PADA TWITTER",
        "authors": "Afri Naldi, Surya Agustian",
        "published": "2023-6-16",
        "citations": 0,
        "abstract": "Pada akhir 2019 muncul penyakit semacam flu yang menginfeksi paru-paru di kota Wuhan. Diduga penyakit tersebut diduga berasal dari kelelawar. WHO memberi nama penyakit ini dengan nama Covid-19 dan virus ini tersebar ke seluruh dunia sehingga menyebabkan pandemi. Pemerintah mengambil indakan vaksinasi untuk mengatasi virus ini, namun mendapat respon pro dan kontra dari masyarakat. Ada banyak penelitian yang membahas sentimen masyarakat terhadap vaksinasi salah satunya adalah klasifikasi sentimen. Penelitian ini membahas klasifikasi sentimen terhadap vaksin covid-19 menggunakan algoritma K-Nearest Neighbor dan Fasttext pada twitter. Data diperoleh dengan cara crawling menggunakan bahasa pemograman pyton dan Twitter API. Pelabelan data dilakukan dengan teknik crowdsourcing dan majority voting. Data yang digunakan setelah proses penyeimbangan adalah 6000 data training, 778 data development dan 400 data test. Hasil pengujian setelah berbagai eksperimen dan feature engineering mendapatkan hasil terbaik dengan nilai akurasi 69% dan f1-score 60%. Hasil ini merupakan hasil terbaik dibanding penelitian sebelumnya dengan dataset yang sama.",
        "keywords": "",
        "link": "http://dx.doi.org/10.31849/zn.v5i2.12548"
    },
    {
        "id": 22042,
        "title": "Towards Distribution-shift Robust Text Classification of Emotional Content",
        "authors": "Luana Bulla, Aldo Gangemi, Misael Mongiovi’",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.524"
    },
    {
        "id": 22043,
        "title": "Classification Algorithm of Network Public Opinion Text Information Based on BP Neural Network",
        "authors": "Hongpeng Lao",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icnetic59568.2023.00120"
    },
    {
        "id": 22044,
        "title": "KNN Text Classification Algorithm Based on Chaotic Particle Swarm Optimization",
        "authors": "Shiyong Xiong, Qian Gong",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icc59986.2023.10421154"
    },
    {
        "id": 22045,
        "title": "Enabling Digital Transformation through Business Text Classification with Small Datasets",
        "authors": "Muhammad Arslan, Christophe Cruz",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iit59782.2023.10366487"
    },
    {
        "id": 22046,
        "title": "Deep Convolutional Neural Network for Knowledge-Infused Text Classification",
        "authors": "Sonika Malik, Sarika Jain",
        "published": "2024-3-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00354-024-00245-6"
    },
    {
        "id": 22047,
        "title": "Instance Discrimination for Improving Chinese Text Classification",
        "authors": "He Hu, Yujue Chen",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3650215.3650220"
    },
    {
        "id": 22048,
        "title": "Multi-Class Text Classification using Machine Learning &amp; Deep Learning",
        "authors": "Arul Keswani, Tarun Jain, Bibek Sharma",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/incoft60753.2023.10425423"
    },
    {
        "id": 22049,
        "title": "Towards a classification of text features highly indicative of context-appropriate L2 writing competence",
        "authors": "Nikola Dobrić",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.system.2023.103155"
    },
    {
        "id": 22050,
        "title": "Iterative pseudo-labelling with SoftMax probability in text classification",
        "authors": "Jiyu Wang",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "Semi-supervised learning is one of the potential research fields in text classification. In this paper, semi-supervised pseudo-label training experiments are conducted using the BERT model that has been pre-trained as a baseline. Only 20% of the original dataset is used for the new training set after segmenting the training set. The raw corpus used for pseudo-label training consists of the remaining 80% of data after labels are removed, while the original test set is still utilized. The results indicate that the key to the semi-supervised pseudo-labelling method is the performance of the original model and reasonable data filtering techniques. Even though the SoftMax value used for data filtering is not precisely equivalent to model prediction accuracy, experimental results show it can somewhat reduce the error propagation problem of the model. This is consistent with earlier research. However, using SoftMax as the threshold for data screening can't bring enough benefits to the model training and make it surpass the training performance of the original data set. As a result, future studies will focus on improving the accuracy of pseudo-labelling with a more suitable data selection method to better the model's performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/6/20230738"
    },
    {
        "id": 22051,
        "title": "Weakly supervised text classification method based on transformer",
        "authors": "ling gan, aijun yi",
        "published": "2023-3-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2672391"
    },
    {
        "id": 22052,
        "title": "Effects of Preprocessing on Text Classification in Balanced and Imbalanced Datasets",
        "authors": "",
        "published": "2024-3-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3837/tiis.2024.03.004"
    },
    {
        "id": 22053,
        "title": "The Text Classification Active Learning Using Transfer Learning Methods",
        "authors": "Ashu Katyal",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smartgencon60755.2023.10441969"
    },
    {
        "id": 22054,
        "title": "Depression Classification from Thai Text Twitter Post based on NLP-generated Corpus",
        "authors": "Vorraya Suttiprapa, Surapong Uttama",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/incit60207.2023.10413094"
    },
    {
        "id": 22055,
        "title": "Contrastive learning with text augmentation for text classification",
        "authors": "Ouyang Jia, Huimin Huang, Jiaxin Ren, Luodi Xie, Yinyin Xiao",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10489-023-04453-3"
    },
    {
        "id": 22056,
        "title": "A Comparison of Text Classification Methods: Naïve Bayes and Support Vector Machine for E-Commerce Item Classification",
        "authors": "Arnold Pramudita, Raphael Wijaya, Steven Cokro, Ghinaa Zain Nabiilah,  Rojali",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icitacee58587.2023.10276728"
    },
    {
        "id": 22057,
        "title": "Exploration on the Effect of Text Preprocessing Based on Inflection Morphology and Attachment Morphology Restoration in Tibetan Text Classification",
        "authors": "Jie Yang, Nima Tashi, Sanke Deng, Dawa Dolma, Tshering Dondrub",
        "published": "2023-8-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/prml59573.2023.10348251"
    },
    {
        "id": 22058,
        "title": "Advancing Legal Citation Text Classification A Conv1D-Based Approach for Multi-Class Classification",
        "authors": "Ying Xie, Zhengning Li, Yibo Yin, Zibu Wei, Guokun Xu, Yang Luo",
        "published": "2024-2-28",
        "citations": 0,
        "abstract": "The escalating volume and intricacy of legal documents necessitate advanced techniques for automated text classification in the legal domain. Our proposed approach leverages Convolutional Neural Networks (Conv1D), a neural network architecture adept at capturing hierarchical features in sequential data. The incorporation of max-pooling facilitates the extraction of salient features, while softmax activation enables the model to handle the multi-class nature of legal citation categorization. By addressing the limitations identified in previous studies, our model aims to advance the state-of-the-art in legal citation text classification, offering a robust and efficient solution for automated categorization in the legal domain. Our research contributes to the ongoing evolution of NLP applications in the legal field, promising enhanced accuracy and adaptability in the automated analysis of legal texts.",
        "keywords": "",
        "link": "http://dx.doi.org/10.53469/jtpes.2024.04(02).03"
    },
    {
        "id": 22059,
        "title": "ELMo Layer Embedding Comparision with Short Text Classification",
        "authors": "JRKC Jayakody, VGTN Vidanagama, Indika Perera, HMLK Herath",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/asiancon58793.2023.10270646"
    },
    {
        "id": 22060,
        "title": "Zero-Shot Learning For Text Classification: Extending Classifiability Beyond Conventional Techniques",
        "authors": "Muthu Palaniappan M, Adithya Vedhamani, Sundharakumar K B",
        "published": "2023-9-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tensymp55890.2023.10223610"
    },
    {
        "id": 22061,
        "title": "Classification Research Based on Quantitative Expansion of Short Text Feature Correlation",
        "authors": "Jun Zhu",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/raiic59453.2023.10280844"
    },
    {
        "id": 22062,
        "title": "Text Classification using Improved IWO-HAN",
        "authors": "Gunjan Singh, Arpita Nagpal, Vijendra Singh",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.procs.2023.01.097"
    },
    {
        "id": 22063,
        "title": "Text Classification of National Anthem using Agglomerative Hierarchical Clustering",
        "authors": "Prajwal Rai, Nirdosh Bista, Kumar Prasun, Gajendra Sharma",
        "published": "2024-3-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.47119/ijrp1001461420246269"
    },
    {
        "id": 22064,
        "title": "Cross-task Knowledge Transfer for Extremely Weakly Supervised Text Classification",
        "authors": "Seongmin Park, Kyungho Kim, Jihwa Lee",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.328"
    },
    {
        "id": 22065,
        "title": "BERT-Enhanced Graph Convolutional Network for News Text Classification",
        "authors": "Li Li, Yushui Geng",
        "published": "2023-8-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/swc57546.2023.10448791"
    },
    {
        "id": 22066,
        "title": "Research on Chinese Text Classification Based on Improved RNN",
        "authors": "Tiantian Fu, Haizhong Liu",
        "published": "2023-5-26",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icetci57876.2023.10176780"
    },
    {
        "id": 22067,
        "title": "Comparative Analysis of Text Classification using SVM, Naïve Bayes, and KNN Models",
        "authors": "Anubhav Bhalla",
        "published": "2023-8-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icirca57980.2023.10220728"
    },
    {
        "id": 22068,
        "title": "Classification of Text, Image and Audio Messages Used for Cyberbulling on Social Medias",
        "authors": "Ermira Idrizi, Mentor Hamiti",
        "published": "2023-5-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/mipro57284.2023.10159835"
    },
    {
        "id": 22069,
        "title": "Review On Text Classification Using Improved Deep Learning Models",
        "authors": "Rajni Gaikwad, Mona Mulchandani, Reena Thakur",
        "published": "2024-2-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ic457434.2024.10486233"
    },
    {
        "id": 22070,
        "title": "Text classification and gradation in Arabic textbooks",
        "authors": "Salwa Mohamed",
        "published": "2023-5-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/09571736.2023.2213695"
    },
    {
        "id": 22071,
        "title": "Retrieval-Augmented Few-shot Text Classification",
        "authors": "Guoxin Yu, Lemao Liu, Haiyun Jiang, Shuming Shi, Xiang Ao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.447"
    },
    {
        "id": 22072,
        "title": "Implementation of Bidirectional Gated Recurrent Units for Text Classification",
        "authors": "Hannan Asrawi, Andi Sunyoto, Bayu Setiaji",
        "published": "2023-11-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icoiact59844.2023.10455822"
    },
    {
        "id": 22073,
        "title": "Data-free Distillation with Evolutionary Pseudo Data for Text Classification",
        "authors": "Zongshuai Qi, Yiyang Xiong",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bmsb58369.2023.10211458"
    },
    {
        "id": 22074,
        "title": "Long Text Multi-label Classification",
        "authors": "Miao Zang, Siyi Niu, Yang Gao, Xi Chen",
        "published": "2023-2-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nnice58320.2023.10105696"
    },
    {
        "id": 22075,
        "title": "LexiFuse+: A Unified One-Class Solution for Imbalanced Short-Text Classification",
        "authors": "Saugata Bose, Guoxin Su",
        "published": "2023-10-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/e-science58273.2023.10254896"
    },
    {
        "id": 22076,
        "title": "Comparison of Classifiers for Text Classification in an E-commerce Service",
        "authors": "Çağdaş Doğan, Sinan Sarıca",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eleco60389.2023.10415941"
    },
    {
        "id": 22077,
        "title": "Text Classification for Newsgroup using Deep Learning",
        "authors": "Mr.Ch.Mani Kanta Kalyan Mr.Ch.Mani Kanta Kalyan",
        "published": "2023-10-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.46243/jst.2023.v8.i04.pp53-59"
    },
    {
        "id": 22078,
        "title": "A novel redistribution-based feature selection for text classification",
        "authors": "Murat Okkalioglu",
        "published": "2024-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.123119"
    },
    {
        "id": 22079,
        "title": "An improved text mining-based space mission risk classification approach",
        "authors": "Nikolaos Sapountzoglou, Nikos Andrikos",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.actaastro.2023.03.028"
    },
    {
        "id": 22080,
        "title": "Towards Improving Text Classification Tasks Based on Knowledge Graphs for Limited Labeled Data",
        "authors": "Hongzhi Zhang, Omair Shafiq",
        "published": "2023-6-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21428/594757db.62395a61"
    },
    {
        "id": 22081,
        "title": "Regularized Conditional Alignment for Multi-Domain Text Classification",
        "authors": "Juntao Hu, Yuan Wu",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10448406"
    },
    {
        "id": 22082,
        "title": "An Empirical Study on Active Learning for Multi-label Text Classification",
        "authors": "Mengqi Wang, Ming Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.insights-1.12"
    },
    {
        "id": 22083,
        "title": "An Exploration of the Effectiveness of Machine Learning Algorithms for Text Classification",
        "authors": "Meena Desai, Suriya Prakash J",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/incoft60753.2023.10425568"
    },
    {
        "id": 22084,
        "title": "Multi-layer GCNs for Travel Text Aspect-level Sentiment Classification",
        "authors": "Min Wang, Ming Yang",
        "published": "2023-12-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mlcr61158.2023.00022"
    },
    {
        "id": 22085,
        "title": "Detection of Fake Data in Medical News Using Text Classification Methods",
        "authors": "Vladimir A. Lovtsov, Mark E. Khabarov, Maria Skvortsova",
        "published": "2023-9-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/rusautocon58002.2023.10272852"
    },
    {
        "id": 22086,
        "title": "Genetic algorithm and support vector machine application in English text classification for intelligent teaching",
        "authors": "Qiao Jin",
        "published": "2023-8-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00500-023-09084-x"
    },
    {
        "id": 22087,
        "title": "A Voting classification approach for Sentiment Extraction from Bengali text",
        "authors": "",
        "published": "2023-5-15",
        "citations": 0,
        "abstract": "Sentiment extraction is one of the most challenging tasks in Natural Language Processing (NLP). It is essential for analysing consumer and user feedback on social media sites and in the commercial world. Finding sentiments or emotions in raw text data and identifying their polarity, or whether they are positive or negative, is the main objective of sentiment extraction. This area has been the focus of various research projects for English and other significant natural languages. In this article, we offer a voting classification method that uses a variety of machine learning classifiers to extract sentiment from Bengali language text. We explored Logistic Regression, Decision Tree Classifier, Random Forest Classifier, Support Vector Classifier, Multinomial Nave Base and Ridge Classifier, and lastly, we used a voting classification strategy to extract sentiments from social media comments.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30534/ijeter/2023/021152023"
    },
    {
        "id": 22088,
        "title": "Toward a Dual Attention Model for Image-Text Sentiment Classification",
        "authors": "Soukaina Fatimi, Wafae Sabbar, Abdelkrim Bekkhoucha",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/amcai59331.2023.10431498"
    },
    {
        "id": 22089,
        "title": "Supervised term-category feature weighting for improved text classification",
        "authors": "Joseph Attieh, Joe Tekli",
        "published": "2023-2",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2022.110215"
    },
    {
        "id": 22090,
        "title": "Dual-channel Text Classification Based on the Attention Mechanism",
        "authors": "Yaqi Yu, Lin Zhang",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdsca59871.2023.10392379"
    },
    {
        "id": 22091,
        "title": "Synthetic-MixUp: A Simple Framework for Imbalanced Text classification",
        "authors": "Rakha Asyrofi, Reza Fauzan",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/gcce59613.2023.10315313"
    },
    {
        "id": 22092,
        "title": "An Efficient Machine Learning-Based Malware Prediction and Classification Architecture: A Cybersecurity Case Study",
        "authors": "",
        "published": "2023-4-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.48047/nq.2022.20.19.nq99297"
    },
    {
        "id": 22093,
        "title": "Memory-Based Invariance Learning for Out-of-Domain Text Classification",
        "authors": "Chen Jia, Yue Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.101"
    },
    {
        "id": 22094,
        "title": "COMPARATIVE STUDY AND EVALUATION OF TEXT CLASSIFICATION APPROACHES IN NLP USING DIFFERENT ALGORITHMS",
        "authors": "",
        "published": "2023-3-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets33939"
    },
    {
        "id": 22095,
        "title": "Effect of Stemming on Hindi Text Classification",
        "authors": "Dr. Anjusha Pimpalshende, PREETY SINGH, Dr. Archana Potnurwar",
        "published": "2023-2-15",
        "citations": 0,
        "abstract": "Abstract.  Text classification is very useful to search large amount of textual data available online by dividing it into smaller relevant units. Now a day’s large amount of digital documents are available in Indian languages. Designing text classifiers in Indian languages is one of the research areas so that people can search and read required documents in their local languages. In proposed work tried to design Text classifier for Hindi text documents and tried to show how stemmer affects the performance of Hindi text classifiers. Stemming is a process to convert words in any language to its base or root words. Stemmers are used for written documents not for spoken languages. Performance of many applications such as text summarization, Information Retrieval (IR) system,text classification systems, syntactic parsing can be improved by applying stemmers. Stemmer eliminates suffix or prefix of the word and form original root word. These root words helps in the preprocessing step required in many algorithms. We applied various stemmers on Hindi text classification models. Experiments and results show that performance of the classifiers is improved by applying stemmers.",
        "keywords": "",
        "link": "http://dx.doi.org/10.47164/ijngc.v14i1.1063"
    },
    {
        "id": 22096,
        "title": "MLRNet: A Meta-Loss Reweighting Network for Biased Data on Text Classification",
        "authors": "Hao Yu, Xinfu Li",
        "published": "2023-12-24",
        "citations": 0,
        "abstract": "Artificially generated datasets often exhibit biases, leading conventional deep neural networks to overfit. Typically, a weighted function adjusts sample impact during model updates using weighted loss. Meta-neural networks, trained with meta-learning principles, generalize well across tasks, acquiring generalized weights. This enables the self-generation of tailored weighted functions for data biases. However, datasets may simultaneously exhibit imbalanced classes and corrupted labels, posing a challenge for current meta-models. To address this, this paper presents Meta-Loss Reweighting Network (MLRNet) with fusion attention features. MLRNet continually evolves sample loss values, integrating them with sample features from self-attention layers in a semantic space. This enhances discriminative power for biased samples. By employing minimal unbiased meta-data for guidance, mutual optimization between the classifier and the meta-model is conducted, endowing biased samples with more reasonable weights. Experiments on English and Chinese benchmark datasets including artificial and real-world biased data show MLRNet’s superior performance under biased data conditions.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app14010164"
    },
    {
        "id": 22097,
        "title": "Enhancing Text Classification Models with Generative AI-aided Data Augmentation",
        "authors": "Huanhuan Zhao, Haihua Chen, Hong-Jun Yoon",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aitest58265.2023.00030"
    },
    {
        "id": 22098,
        "title": "Enhanced text classification through an improved discrete laying chicken algorithm",
        "authors": "Fatemeh Daneshfar, Mohammad Javad Aghajani",
        "published": "2024-1-25",
        "citations": 0,
        "abstract": "AbstractThe exponential growth of digital text documents presents a significant challenge for text classification algorithms, as the vast number of words in each document can hinder their efficiency. Feature selection (FS) is a crucial technique that aims to eliminate irrelevant features and enhance classification accuracy. In this study, we propose an improved version of the discrete laying chicken algorithm (IDLCA) that utilizes noun‐based filtering to reduce the number of features and improve text classification performance. Although LCA is a newly proposed algorithm, it has not been systematically applied to discrete problems before. Our enhanced version of LCA employs different operators to improve both exploration and exploitation of this algorithm to find better solutions in discrete mode. To evaluate the effectiveness of the proposed method, we compared it with some conventional nature‐inspired feature selection methods using various learning models such as decision trees (DT), K‐nearest neighbor (KNN), Naive Bayes (NB), and support vector machine (SVM) on five benchmark datasets with three different evaluation metrics. The experimental results demonstrate the effectiveness of the proposed algorithm in comparison to the existing one. The code is available at https://github.com/m0javad/Improved-Discrete-Laying-Chicken-Algorithm.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1111/exsy.13553"
    },
    {
        "id": 22099,
        "title": "$$\\mathcal {B}\\text {rain}{\\mathcal{M}\\mathcal{N}}\\text {et}$$: a unified neural network architecture for brain image classification",
        "authors": "Sudip Ghosh,  Deepti, Shivam Gupta",
        "published": "2024-3-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13721-024-00443-8"
    },
    {
        "id": 22100,
        "title": "Application of natural language processing technology in text classification",
        "authors": "tian Li",
        "published": "2023-2-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2661012"
    },
    {
        "id": 22101,
        "title": "Using High Dimensional Computing on Arabic Language Speech to Text Classification",
        "authors": "",
        "published": "2023-3-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18576/isl/120306"
    },
    {
        "id": 22102,
        "title": "Text Classification of Mixed Model Based on Deep Learning",
        "authors": "Sang-Hwa Lee",
        "published": "2023-7-19",
        "citations": 0,
        "abstract": "At present, deep learning has been widely used many fields, but the research on text classification is still relatively few. This paper makes full use of the good learning characteristics of deep learning, proposes a hybrid model based on deep learning, and designs a text classifier based on the hybrid model. This hybrid model uses two common deep learning models, sparse automatic encoder and deep confidence network, to mix. The hybrid model is mainly composed of three parts, the first two layers are constructed by sparse automatic encoder, the middle layer is a three-layer depth Convolutional Neural Network (CNN), and finally Softmax regression is used as the classification layer. In order to test the classification performance of the classifier based on deep learning hybrid model, relevant experiments were conducted on English data set 20Newsgroup and Chinese data set Fudan University Chinese Corpus. In the English text classification experiment, the classifier based on deep learning hybrid model is used to classify, and a high classification accuracy rate is obtained. In order to further verify the superiority of its performance, a comparative experiment with naive Bayes classifier, K-Nearest Neighbor (KNN) classifier and Support Vector Machine (SVM) classifier demonstrates that the classification effect of the classifier based on deep learning hybrid model is better than that of naive Bayes classifier, KNN classifier and support vector machine classifier. In the experiment of Chinese text classification, the Chinese corpus of Fudan University is tested, and a good classification effect is obtained. The influence of different parameter settings on the classification accuracy is discussed.",
        "keywords": "",
        "link": "http://dx.doi.org/10.31803/tg-20221228180808"
    },
    {
        "id": 22103,
        "title": "Gene Disease Classification from Biomedical Text via Ensemble Machine Learning",
        "authors": "Rabea F. Ghazi, Dhafar Hamed Abd",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dese60595.2023.10469108"
    },
    {
        "id": 22104,
        "title": "Government affairs message text classification based on RoBerta and TextCNN",
        "authors": "Yan Lai, Lin Zhang",
        "published": "2023-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cisce58541.2023.10142573"
    }
]