[
    {
        "id": 10705,
        "title": "Spatial–temporal recurrent reinforcement learning for autonomous ships",
        "authors": "Martin Waltz, Ostap Okhrin",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.06.015"
    },
    {
        "id": 10706,
        "title": "Traffic forecasting with graph spatial–temporal position recurrent network",
        "authors": "Yibi Chen, Kenli Li, Chai Kiat Yeo, Keqin Li",
        "published": "2023-5",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.03.009"
    },
    {
        "id": 10707,
        "title": "ENHANCING SEQUENCE LEARNING WITH MASKING IN RECURRENT NEURAL NETWORKS",
        "authors": "",
        "published": "2024-1-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets48489"
    },
    {
        "id": 10708,
        "title": "Continual learning with attentive recurrent neural networks for temporal data classification",
        "authors": "Shao-Yu Yin, Yu Huang, Tien-Yu Chang, Shih-Fang Chang, Vincent S. Tseng",
        "published": "2023-1",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2022.10.031"
    },
    {
        "id": 10709,
        "title": "Origin of the efficiency of spike timing-based neural computation for processing temporal information",
        "authors": "Zhiwei Jiang, Jiaming Xu, Tielin Zhang, Mu-ming Poo, Bo Xu",
        "published": "2023-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2022.12.017"
    },
    {
        "id": 10710,
        "title": "iR6mA-RNN: Identifying N6-Methyladenosine Sites in Eukaryotic Transcriptomes using Recurrent Neural Networks and Sequence-embedded Features",
        "authors": "Binh P. Nguyen, Thanh-Hoang Nguyen-Vo, Loc Nguyen, Quang H. Trinh, Chalinor Baliuag, Trang T. T. Do, Susanto Rahardja",
        "published": "2023-7-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ssp53291.2023.10207989"
    },
    {
        "id": 10711,
        "title": "Structural health monitoring of steel moment frame buildings via sequence-based recurrent neural networks",
        "authors": "Khashayar Heydarpour, Doeun Choe, Kyungyong Chung",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cai54212.2023.00154"
    },
    {
        "id": 10712,
        "title": "Exploring Spatio-Temporal Context with Recurrent Neural Networks for Medical Image Analysis",
        "authors": "Bhuvana J, Vaibhav Srivastav, Sunil Kumar",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470687"
    },
    {
        "id": 10713,
        "title": "Attractor Properties of Spatiotemporal Memory in Effective Sequence Processing Task",
        "authors": "P. Kuderov, E. Dzhivelikian, A. I. Panov",
        "published": "2023-12",
        "citations": 0,
        "abstract": "\nAbstract\nFor autonomous AI systems, it is important to process spatiotemporal information to encode and memorize it and extract and reuse abstractions effectively. What is natural for natural intelligence is still a challenge for AI systems. In this paper, we propose a biologically plausible model of spatiotemporal memory with an attractor module and study its ability to encode sequences and efficiently extract and reuse repetitive patterns. The results of experiments on synthetic and textual data and data from DVS cameras demonstrate a qualitative improvement in the properties of the model when using the attractor module.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.3103/s1060992x23060097"
    },
    {
        "id": 10714,
        "title": "Motion Prediction Of Traffic Agents With Hybrid Recurrent-Convolutional Neural Networks",
        "authors": "Vasileios Lagoutaris, Konstantinos Moustakas",
        "published": "2023-6-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dsp58604.2023.10167941"
    },
    {
        "id": 10715,
        "title": "Prediction of Deep Ice Layer Thickness Using Adaptive Recurrent Graph Neural Networks",
        "authors": "Benjamin Zalatan, Maryam Rahnemoonfar",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10222391"
    },
    {
        "id": 10716,
        "title": "Sequence Modeling with Recurrent Neural Networks (RNNs) for Student Learning Behavior Pattern Recognition in a Flipped Classroom",
        "authors": "Guangheng Tang",
        "published": "2024-4-4",
        "citations": 0,
        "abstract": "The flipped classroom model has become increasingly popular in education, altering the traditional methods of teaching. It is important to understand and acknowledge how students learn within this framework in order to optimize instructional strategies and promote personalized learning. This study investigates the use of Sequence Modeling with Recurrent Neural Networks (RNNs) to identify patterns in student learning behavior within a flipped classroom setting. The proposed deep learning architecture utilizes RNNs to analyze sequential patterns in students' interactions with the flipped classroom materials, while also incorporating attention mechanisms to better detect important patterns and temporal dynamics in the learning process. Multimodal learning techniques are also employed, combining data from various sources to gain a comprehensive understanding of student behavior. Additionally, clustering techniques using autoencoders are explored to group students with similar learning behaviors. Predictive models, such as RNN or LSTM networks, are developed to forecast future learning behaviors and provide insights into potential challenges or successes for individual students. The effectiveness of this framework is evaluated using real-world data from flipped classroom implementations, with performance metrics like recall, precision, and accuracy used to assess the success of the sequence modeling approach in recognizing and predicting student behavior patterns. Overall, the application of deep learning methods, specifically sequence modeling with RNNs, demonstrates potential for improving personalized learning experiences and facilitating proactive interventions to support diverse student needs.",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/jes.1306"
    },
    {
        "id": 10717,
        "title": "Employing Recursive Neural Networks in Voice Question-Answering Systems: A Novel Approach for Sequence Processing",
        "authors": "Lin Ning, Zuo Yue",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icipca59209.2023.10257880"
    },
    {
        "id": 10718,
        "title": "Active Hypothesis Testing in Unknown Environments Using Recurrent Neural Networks and Model Free Reinforcement Learning",
        "authors": "George Stamatelis, Nicholas Kalouptsidis",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/eusipco58844.2023.10289731"
    },
    {
        "id": 10719,
        "title": "Fading memory as inductive bias in residual recurrent networks",
        "authors": "Igor Dubinin, Felix Effenberger",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2024.106179"
    },
    {
        "id": 10720,
        "title": "Two-timescale recurrent neural networks for distributed minimax optimization",
        "authors": "Zicong Xia, Yang Liu, Jiasen Wang, Jun Wang",
        "published": "2023-8",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.06.003"
    },
    {
        "id": 10721,
        "title": "Improved Recurrent Neural Networks for Text Classification and Dynamic Sylvester Equation Solving",
        "authors": "Weijie Chen, Jie Jin, Dimitrios Gerontitis, Lixin Qiu, Jingcan Zhu",
        "published": "2023-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-023-11176-6"
    },
    {
        "id": 10722,
        "title": "ODRNN: optimized deep recurrent neural networks for automatic detection of leukaemia",
        "authors": "K. Dhana Shree, S. Logeswari",
        "published": "2024-3-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11760-024-03062-y"
    },
    {
        "id": 10723,
        "title": "Multi-view stereo with recurrent neural networks for spatio-temporal consistent depth maps",
        "authors": "Hosung Son, Suk-ju Kang",
        "published": "2023-2-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceic57457.2023.10049937"
    },
    {
        "id": 10724,
        "title": "Multi-temporal Processing Quality Prediction Based on Graph Neural Networks and Transfer Learning",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18178/wcse.2023.06.020"
    },
    {
        "id": 10725,
        "title": "Convolutional Spiking Neural Networks for Spatio-Temporal Feature Extraction",
        "authors": "Ali Samadzadeh, Fatemeh Sadat Tabatabaei Far, Ali Javadi, Ahmad Nickabadi, Morteza Haghir Chehreghani",
        "published": "2023-12",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-023-11247-8"
    },
    {
        "id": 10726,
        "title": "A Study of Temporal and Recurrent Neural Networks for CO2 Emission Forecasting",
        "authors": "Oleg Rudenko, Oleksandr Bezsonov, Nataliia Serdiuk, Kateryna Pasichnyk",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32782/cmis/3392-10"
    },
    {
        "id": 10727,
        "title": "An automated patient-specific ECG beat classification using LSTM-based recurrent neural networks",
        "authors": "Somaraju Boda, Manjunatha Mahadevappa, Pranab Kumar Dutta",
        "published": "2023-7",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.bspc.2023.104756"
    },
    {
        "id": 10728,
        "title": "Safe Model-based Control from Signal Temporal Logic Specifications Using Recurrent Neural Networks",
        "authors": "Wenliang Liu, Mirai Nishioka, Calin Belta",
        "published": "2023-5-29",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icra48891.2023.10161201"
    },
    {
        "id": 10729,
        "title": "DyVGRNN: DYnamic mixture Variational Graph Recurrent Neural Networks",
        "authors": "Ghazaleh Niknam, Soheila Molaei, Hadi Zare, Shirui Pan, Mahdi Jalili, Tingting Zhu, David Clifton",
        "published": "2023-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.05.048"
    },
    {
        "id": 10730,
        "title": "User Re-Authentication via Mouse Movements and Recurrent Neural Networks",
        "authors": "Paul Houssel, Luis Leiva",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012296600003648"
    },
    {
        "id": 10731,
        "title": "Linear and Non-Linear Spatio-Temporal Input Selection In Wireless Traffic Networks Prediction using Recurrent Neural Networks",
        "authors": " Ahmad Saikhu,  Agung Teguh Setyadi,  Victor Hariadi",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "For the optimization of computer networks with high bandwidth requirements, it is necessary to predict the traffic of the wireless network. Its goal is to reduce maintenance costs and improve internet services. Feature selection is a major issue in multivariate time series (MTS) spatio-temporal modeling. Another problem is the dependency between input features, time lags, and spatial factors, so an appropriate model is needed. This study aims to provide solutions to two problems. The first is to improve a feature extraction and selection process in spatio-temporal MTS data for relevant features using Detrended Partial Cross-Correlation Analysis (DPPCA) and nonredundant features associated with linear using Pearson's correlation (PC) filters and non-linear associations using Symmetrical Uncertainty (SU) and a combination of both PCSUF. The second is to develop a spatiotemporal framework model using recurrent neural networks (RNNs) to get better performance than the traditional model. These methods are combined and tested using a data set of cellular networks with one hour intervals during November in three locations. Testing the effectiveness of the feature selection technique showed that 27.6% of the total extracted features were. The forecasting model with the DPCCA-SU-RNN combination method is the best performance by having RMSE = 380.7, R2 = 97% and MAPE = 10%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.29207/resti.v7i6.5296"
    },
    {
        "id": 10732,
        "title": "Transductive Support Vector Machines (TSVM) With Hybrid Recurrent Neural Networks For Medical Image Filtering",
        "authors": "Ravi Kumar",
        "published": "2023-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ihcsp56702.2023.10127184"
    },
    {
        "id": 10733,
        "title": "A novel locally connected recurrent neural network for identification of nonlinear dynamical system",
        "authors": "R Shobana., Rajesh Kumar, Bhavnesh Jaint",
        "published": "2023-3-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/spin57001.2023.10117315"
    },
    {
        "id": 10734,
        "title": "Novel criteria of sampled-data synchronization controller design for gated recurrent unit neural networks under mismatched parameters",
        "authors": "Seungyong Han, Suneel Kumar Kommuri, Yongsik Jin",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.12.035"
    },
    {
        "id": 10735,
        "title": "Explainability Insights to Cellular Simultaneous Recurrent Neural Networks for Classical Planning",
        "authors": "Michaela Urbanovská, Antonín Komenda",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012375800003636"
    },
    {
        "id": 10736,
        "title": "Warming up recurrent neural networks to maximise reachable multistability greatly improves learning",
        "authors": "Gaspard Lambrechts, Florent De Geeter, Nicolas Vecoven, Damien Ernst, Guillaume Drion",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.07.023"
    },
    {
        "id": 10737,
        "title": "Generalisation of Feed-Forward Neural Networks and  Recurrent Neural Networks",
        "authors": "Rui Wang",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "This paper presents an in-depth analysis of Feed-Forward Neural Networks (FNNs) and Recurrent Neural Networks (RNNs), two powerful models in the field of artificial intelligence. Understanding these models and their applications is crucial for harnessing their potential. The study addresses the need to comprehend the unique characteristics and architectures of FNNs and RNNs. These models excel at processing sequential and temporal data, making them indispensable in tasks. Furthermore, the paper emphasises the importance of variables in FNNs and proposes a novel method to rank the importance of independent variables in predicting the output variable. By understanding the relationship between inputs and outputs, valuable insights can be gained into the underlying patterns and mechanisms driving the system being modelled. Additionally, the research explores the impact of initial weights on model performance. Contrary to conventional beliefs, the study provides evidence that neural networks with random weights can achieve competitive performance, particularly in situations with limited training datasets. This finding challenges the traditional notion that careful initialization is necessary for neural networks to perform well. In summary, this paper provides a comprehensive analysis of FNNs and RNNs while highlighting the importance of understanding the relationship between variables and the impact of initial weights on model performance. By shedding light on these crucial aspects, this research contributes to the advancement and effective utilisation of neural networks, paving the way for improved predictions and insights in various domains.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/40/20230659"
    },
    {
        "id": 10738,
        "title": "Performability of Deep Recurrent Neural Networks for Molecular Sequence data",
        "authors": "Roshan R. Kotkondawar, Sanjay R. Sutar, Arvind W. Kiwelekar, Hansaraj S. Wankhede",
        "published": "2023-5-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.12785/ijcds/1301107"
    },
    {
        "id": 10739,
        "title": "Time series prediction and anomaly detection with recurrent spiking neural networks",
        "authors": "Yann Cherdo, Benoit Miramond, Alain Pegatoquet",
        "published": "2023-6-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191614"
    },
    {
        "id": 10740,
        "title": "Rectified Attention Gate Unit in Recurrent Neural Networks for Effective Attention Computation",
        "authors": "Manh-Hung Ha, Oscal Tzyh-Chiang Chen",
        "published": "2023-7-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ssp53291.2023.10207931"
    },
    {
        "id": 10741,
        "title": "ProductGraphSleepNet: Sleep staging using product spatio-temporal graph learning with attentive temporal aggregation",
        "authors": "Aref Einizade, Samaneh Nasiri, Sepideh Hajipour Sardouie, Gari D. Clifford",
        "published": "2023-7",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.05.016"
    },
    {
        "id": 10742,
        "title": "Quantum recurrent neural networks for sequential learning",
        "authors": "Yanan Li, Zhimin Wang, Rongbing Han, Shangshang Shi, Jiaxin Li, Ruimin Shang, Haiyong Zheng, Guoqiang Zhong, Yongjian Gu",
        "published": "2023-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.07.003"
    },
    {
        "id": 10743,
        "title": "Cascade Prediction with Recurrent Neural Networks and Diffusion Depth Distributions",
        "authors": "Shao Huang, Wangyang Yu",
        "published": "2023-2-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nnice58320.2023.10105676"
    },
    {
        "id": 10744,
        "title": "Face Expression Recognition using Recurrent Neural Networks",
        "authors": "Marcos Sanchez-Ruiz, Jonathan Flores-Monroy, Mariko Nakano-Miyatake, Enrique Escamilla-Hernandez, Hector Perez-Meana",
        "published": "2023-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tsp59544.2023.10197740"
    },
    {
        "id": 10745,
        "title": "Higher-Order Spatio-Temporal Neural Networks for Covid-19 Forecasting",
        "authors": "Yuzhou Chen, Sotiris Batsakis, H. Vincent Poor",
        "published": "2023-6-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10095012"
    },
    {
        "id": 10746,
        "title": "Dynamic Analysis and an Eigen Initializer for Recurrent Neural Networks",
        "authors": "Ran Dou, Jose Principe",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191986"
    },
    {
        "id": 10747,
        "title": "Cascaded Convolutional Recurrent Neural Networks for EEG Emotion Recognition Based on Temporal–Frequency–Spatial Features",
        "authors": "Yuan Luo, Changbo Wu, Caiyun Lv",
        "published": "2023-6-2",
        "citations": 1,
        "abstract": "Emotion recognition is a research area that spans multiple disciplines, including computational science, neuroscience, and cognitive psychology. The use of electroencephalogram (EEG) signals in emotion recognition is particularly promising due to their objective and nonartefactual nature. To effectively leverage the spatial information between electrodes, the temporal correlation of EEG sequences, and the various sub-bands of information corresponding to different emotions, we construct a 4D matrix comprising temporal–frequency–spatial features as the input to our proposed hybrid model. This model incorporates a residual network based on depthwise convolution (DC) and pointwise convolution (PC), which not only extracts the spatial–frequency information in the input signal, but also reduces the training parameters. To further improve performance, we apply frequency channel attention networks (FcaNet) to distribute weights to different channel features. Finally, we use a bidirectional long short-term memory network (Bi-LSTM) to learn the temporal information in the sequence in both directions. To highlight the temporal importance of the frame window in the sample, we choose the weighted sum of the hidden layer states at all frame moments as the input to softmax. Our experimental results demonstrate that the proposed method achieves excellent recognition performance. We experimentally validated all proposed methods on the DEAP dataset, which has authoritative status in the EEG emotion recognition domain. The average accuracy achieved was 97.84% for the four binary classifications of valence, arousal, dominance, and liking and 88.46% for the four classifications of high and low valence–arousal recognition.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app13116761"
    },
    {
        "id": 10748,
        "title": "Methodology for multi-temporal prediction of crop rotations using recurrent neural networks",
        "authors": "Ambre Dupuis, Camélia Dadouchi, Bruno Agard",
        "published": "2023-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.atech.2022.100152"
    },
    {
        "id": 10749,
        "title": "Multi-lingual character recognition and extraction using recurrent neural networks",
        "authors": "Varipally Vishwanath Neerugatti, K. Manjunathachari, Prasad K. Satya",
        "published": "2023",
        "citations": 0,
        "abstract": "In recent years, segmentation and recognition of multilingual languages have attracted the attention of many researchers. Multilingual Optical Character Recognition (OCR) technology uses tools like PyTesseract, OpenCV and Recurrent Neural Networks (RNN) to transform text in English, Telugu, Hindi, Tamil and Kannada. Converting text to digital format transforms communication and supports cultural understanding. The system supports multiple languages and can handle different languages. PyTesseract and OpenCV are used for accurate behavior recognition, while RNN improves language understanding. To ensure accuracy, the system uses advanced techniques to overcome problems such as noise and distortion in data input. This technology, combined with advanced OCR algorithms, improves text recognition and makes it adaptable to multilingual environments. This study highlights the importance of multilingual OCR in preserving language, supporting international cooperation, and encouraging participation in the digital age. The research explores ways to use cross-language grammar, fonts, and document layouts using previously implemented techniques to create informative content. RNN further improves the OCR process by capturing complex words. The userfriendly interface and integration with various platforms increase accessibility, allowing users to easily engage with multilingual content. Therefore, multilingual OCR, which combines PyTesseract, OpenCV, RNN, and other advanced techniques, is used to overcome speech problems, handle various grammars and input data, and have a positive impact on the development of OCR technology. This research helps create a globally connected society where knowledge is transmitted across language boundaries, fostering cultural exchange and fostering growth, while ensuring a good and accurate understanding of literature.",
        "keywords": "",
        "link": "http://dx.doi.org/10.26634/jip.10.4.20293"
    },
    {
        "id": 10750,
        "title": "Named Entity Recognition using Multiple Smaller LSTM in Parallel Recurrent Neural Networks",
        "authors": "P Suhas Reddy, Dheeraj Sai Madhalam, Pavan Kumar Kundeti",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iconscept57958.2023.10170554"
    },
    {
        "id": 10751,
        "title": "A novel method for distinction heart rate variability during meditation using LSTM recurrent neural networks based on visibility graph",
        "authors": "Mahda Nasrolahzadeh, Zeynab Mohammadpoory, Javad Haddadnia",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.bspc.2023.105822"
    },
    {
        "id": 10752,
        "title": "DRRNets: Dynamic Recurrent Routing via Low-Rank Regularization in Recurrent Neural Networks",
        "authors": "Dongjing Shan, Yong Luo, Xiongwei Zhang, Chao Zhang",
        "published": "2023-4",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2021.3105818"
    },
    {
        "id": 10753,
        "title": "Sentiment Analysis With Lipschitz Recurrent Neural Networks",
        "authors": "Mahmudul Hasan, Sachin Shetty",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isncc58260.2023.10323619"
    },
    {
        "id": 10754,
        "title": "Different Types of Neural Networks and Applications: Evidence from Feedforward, Convolutional and Recurrent Neural Networks",
        "authors": "Yumin Pan",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "Neural networks have achieved great process in the 90 years since they were officially introduced in 1943. Because of its wide application and huge research and development potential, this technology attracts more and more scientific and technological workers to the research of neural networks. Neural network technology is an essential component of AI development, and it is a significant indicator of a country's overall strength. In this paper, this study will demonstrate Feedforward Neural Network, Convolution Neural Network and Recurrent Neural networks and evaluate them through datasets from kaggle.com. and CSDN (China IT community). Through this paper, readers can have a better outlook and understanding of the operating principles of each type of neural network as well as their specific jobs (what kind of jobs they specialized in) and each application of these neural networks. So that this paper can promote readers' thoughts and help them start learning neural networks or be a supplement or reference for future scholars. In the end, this paper will present the outcome, which is the evaluation of the accuracy, loss curve, and accuracy curve of neural networks.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/6rn1wd81"
    },
    {
        "id": 10755,
        "title": "Modeling Batch Tasks Using Recurrent Neural Networks in Co-Located Alibaba Workloads",
        "authors": "Hifza Khalid, Arunselvan Ramaswamy, Simone Ferlin, Alva Couch",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012392700003654"
    },
    {
        "id": 10756,
        "title": "Classification of DBS microelectrode recordings using a residual neural network with attention in the temporal domain",
        "authors": "K.A. Ciecierski, T. Mandat",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.11.021"
    },
    {
        "id": 10757,
        "title": "Facial micro-expression recognition using deep spatio-temporal neural networks",
        "authors": "Yufeng Zheng, Erik P. Blasch",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2665189"
    },
    {
        "id": 10758,
        "title": "Research on assembly sequence planning method based on artificial neural networks",
        "authors": "Jing Zhang, Shaowei Feng, Kai Chai",
        "published": "2024-3-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3026725"
    },
    {
        "id": 10759,
        "title": "Efficient Protein Structural Class Prediction Via Chaos Game Representation and Recurrent Neural Networks",
        "authors": "Michaela Areti Zervou, Effrosyni Doutsi, Panagiotis Tsakalides",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10094877"
    },
    {
        "id": 10760,
        "title": "Leveraging Sparsity with Spiking Recurrent Neural Networks for Energy-Efficient Keyword Spotting",
        "authors": "Manon Dampfhoffer, Thomas Mesquida, Emmanuel Hardy, Alexandre Valentian, Lorena Anghel",
        "published": "2023-6-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10097174"
    },
    {
        "id": 10761,
        "title": "Dynamical Hyperspectral Unmixing With Variational Recurrent Neural Networks",
        "authors": "Ricardo A. Borsoi, Tales Imbiriba, Pau Closas",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tip.2023.3266660"
    },
    {
        "id": 10762,
        "title": "Exploring crude oil price movements as a complex time series using recurrent neural networks",
        "authors": "Rida El Abassi, Mohamed Oubraime, Jaafar Idrais, Abderrahim Sabour",
        "published": "2023-5-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3607720.3607731"
    },
    {
        "id": 10763,
        "title": "Expressivity of Hidden Markov Chains vs. Recurrent Neural Networks From a System Theoretic Viewpoint",
        "authors": "François Desbouvries, Yohan Petetin, Achille Salaün",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tsp.2023.3328108"
    },
    {
        "id": 10764,
        "title": "MODELING VISUAL MOTION PROCESSING DURING SMOOTH PURSUIT EYE MOVEMENTS USING RECURRENT NEURAL NETWORKS",
        "authors": "Min Ki Kim, Joonyeol Lee, Sung-Phil Kim, Jeong-Woo Sohn",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ibneur.2023.08.1650"
    },
    {
        "id": 10765,
        "title": "Least Redundant Gated Recurrent Neural Network",
        "authors": "Łukasz Neumann, Łukasz Lepak, Paweł Wawrzyński",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191895"
    },
    {
        "id": 10766,
        "title": "RECURRENT QUANTUM NEURAL NETWORKS: A REVIEW",
        "authors": "Gleydson Fernandes de Jesus, Valéria Loureiro da Silva",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5151/siintec2023-306159"
    },
    {
        "id": 10767,
        "title": "Investigating Temporal Features of Carotid Intima-Media Thickness from Ultrasound Imaging with Recurrent Neural Networks",
        "authors": "Min Jing, Kathryn Owen, Brian Mac Namee, Iab B. A. Menown, James McLaughlin",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/embc40787.2023.10340661"
    },
    {
        "id": 10768,
        "title": "STTRE: A Spatio-Temporal Transformer with Relative Embeddings for multivariate time series forecasting",
        "authors": "Azad Deihim, Eduardo Alonso, Dimitra Apostolopoulou",
        "published": "2023-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.09.039"
    },
    {
        "id": 10769,
        "title": "Predicting Opinions in Social Networks Using Recurrent Neural Networks",
        "authors": "Mohamed N. Zareer, Rastko R. Selmic",
        "published": "2023-6-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/med59994.2023.10185814"
    },
    {
        "id": 10770,
        "title": "Adaptive pseudo-Siamese policy network for temporal knowledge prediction",
        "authors": "Pengpeng Shao, Tong Liu, Feihu Che, Dawei Zhang, Jianhua Tao",
        "published": "2023-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.01.004"
    },
    {
        "id": 10771,
        "title": "An Inexact Sequential Quadratic Programming Method for Learning and Control of Recurrent Neural Networks",
        "authors": "Adeyemi D. Adeoye, Alberto Bemporad",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2024.3354855"
    },
    {
        "id": 10772,
        "title": "SSR-TA: Sequence-to-Sequence-based expert recurrent recommendation for ticket automation",
        "authors": "Chenhan Cao, Xiaoyu Fang, Bingqing Luo, Bin Xia",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00521-023-09152-1"
    },
    {
        "id": 10773,
        "title": "Quasi-Recurrent Neural Networks with Embedded Variable Selection Module for Data Sequence Modeling in Dynamic Industrial Processes",
        "authors": "Yiyin Tang, Yalin Wang, Chenliang Liu, Xiaofeng Yuan, Kai Wang",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciea58696.2023.10241509"
    },
    {
        "id": 10774,
        "title": "Ensemble Recurrent Graph Neural Networks for Availability Prediction in Cellular Networks",
        "authors": "Ming-Yen Wu",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ickii58656.2023.10332614"
    },
    {
        "id": 10775,
        "title": "TransformerG2G: Adaptive time-stepping for learning temporal graph embeddings using transformers",
        "authors": "Alan John Varghese, Aniruddha Bora, Mengjia Xu, George Em Karniadakis",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.12.040"
    },
    {
        "id": 10776,
        "title": "Few-shot link prediction for temporal knowledge graphs based on time-aware translation and attention mechanism",
        "authors": "Han Zhang, Luyi Bai",
        "published": "2023-4",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.01.043"
    },
    {
        "id": 10777,
        "title": "Heterogeneous recurrent spiking neural network for spatio-temporal classification",
        "authors": "Biswadeep Chakraborty, Saibal Mukhopadhyay",
        "published": "2023-1-30",
        "citations": 5,
        "abstract": "Spiking Neural Networks are often touted as brain-inspired learning models for the third wave of Artificial Intelligence. Although recent SNNs trained with supervised backpropagation show classification accuracy comparable to deep networks, the performance of unsupervised learning-based SNNs remains much lower. This paper presents a heterogeneous recurrent spiking neural network (HRSNN) with unsupervised learning for spatio-temporal classification of video activity recognition tasks on RGB (KTH, UCF11, UCF101) and event-based datasets (DVS128 Gesture). We observed an accuracy of 94.32% for the KTH dataset, 79.58% and 77.53% for the UCF11 and UCF101 datasets, respectively, and an accuracy of 96.54% on the event-based DVS Gesture dataset using the novel unsupervised HRSNN model. The key novelty of the HRSNN is that the recurrent layer in HRSNN consists of heterogeneous neurons with varying firing/relaxation dynamics, and they are trained via heterogeneous spike-time-dependent-plasticity (STDP) with varying learning dynamics for each synapse. We show that this novel combination of heterogeneity in architecture and learning method outperforms current homogeneous spiking neural networks. We further show that HRSNN can achieve similar performance to state-of-the-art backpropagation trained supervised SNN, but with less computation (fewer neurons and sparse connection) and less training data.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fnins.2023.994517"
    },
    {
        "id": 10778,
        "title": "On the Quantization of Recurrent Neural Networks for Smiles Generation",
        "authors": "Adriano Durao, Joel P. Arrais, Bernardete Ribeiro, Gabriel Falcao",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10095354"
    },
    {
        "id": 10779,
        "title": "Learning spatial-spectral-temporal EEG representations with dual-stream neural networks for motor imagery",
        "authors": "Weijian Mai, Fengjie Wu, Xiaoting Mai",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.bspc.2024.106003"
    },
    {
        "id": 10780,
        "title": "Learning dynamic spatial-temporal regularized correlation filter tracking with response deviation suppression via multi-feature fusion",
        "authors": "Sathishkumar Moorthy, Young Hoon Joo",
        "published": "2023-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.08.019"
    },
    {
        "id": 10781,
        "title": "Semantically Layered Representation for Planning Problems and Its Usage for Heuristic Computation Using Cellular Simultaneous Recurrent Neural Networks",
        "authors": "Michaela Urbanovská, Antonín Komenda",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011691000003393"
    },
    {
        "id": 10782,
        "title": "Fog-cloud based intrusion detection system using Recurrent Neural Networks and feature selection for IoT networks",
        "authors": "Naeem Firdous Syed, Mengmeng Ge, Zubair Baig",
        "published": "2023-4",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.comnet.2023.109662"
    },
    {
        "id": 10783,
        "title": "Design of continuous-time recurrent neural networks with piecewise-linear activation function for generation of prescribed sequences of bipolar vectors",
        "authors": "Norikazu Takahashi, Tsuyoshi Yamakawa, Yasuhiro Minetoma, Tetsuo Nishi, Tsuyoshi Migita",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.05.013"
    },
    {
        "id": 10784,
        "title": "Correction: Recurrent neural networks for enhanced joint channel estimation and interference cancellation in FBMC and OFDM systems: unveiling the potential for 5G networks",
        "authors": "Rasha M. Al‑Makhlasawy, Mayada Khairy, Walid El‑Shafai",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s13634-023-01090-3"
    },
    {
        "id": 10785,
        "title": "Adversarial Attacks with Defense Mechanisms on Convolutional Neural Networks and Recurrent Neural Networks for Malware Classification",
        "authors": "Sharoug Alzaidy, Hamad Binsalleeh",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "In the field of behavioral detection, deep learning has been extensively utilized. For example, deep learning models have been utilized to detect and classify malware. Deep learning, however, has vulnerabilities that can be exploited with crafted inputs, resulting in malicious files being misclassified. Cyber-Physical Systems (CPS) may be compromised by malicious files, which can have catastrophic consequences. This paper presents a method for classifying Windows portable executables (PEs) using Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs). To generate malware executable adversarial examples of PE, we conduct two white-box attacks, Jacobian-based Saliency Map Attack (JSMA) and Carlini and Wagner attack (C&W). An adversarial payload was injected into the DOS header, and a section was added to the file to preserve the PE functionality. The attacks successfully evaded the CNN model with a 91% evasion rate, whereas the RNN model evaded attacks at an 84.6% rate. Two defense mechanisms based on distillation and training techniques are examined in this study for overcoming adversarial example challenges. Distillation and training against JSMA resulted in the highest reductions in the evasion rates of 48.1% and 41.49%, respectively. Distillation and training against C&W resulted in the highest decrease in evasion rates, at 48.1% and 49.9%, respectively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app14041673"
    },
    {
        "id": 10786,
        "title": "Exploring Neural Network Structure through Sparse Recurrent Neural Networks: A Recasting and Distillation of Neural Network Hyperparameters",
        "authors": "Quincy Hershey, Randy Paffenroth, Harsh Pathak",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00026"
    },
    {
        "id": 10787,
        "title": "Ensemble recurrent neural network with whale optimization algorithm-based DNA sequence classification for medical applications",
        "authors": "Abdulaziz Alshammari",
        "published": "2023-5-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00500-023-08435-y"
    },
    {
        "id": 10788,
        "title": "Weakly supervised temporal action localization with actionness-guided false positive suppression",
        "authors": "Zhilin Li, Zilei Wang, Qinying Liu",
        "published": "2024-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2024.106307"
    },
    {
        "id": 10789,
        "title": "Advantages and Disadvantages of Spiking Neural Networks Compared to Classical Artificial Neural Networks",
        "authors": "Igor Semenov, Dmitry Nikitin",
        "published": "2023-11-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icp60417.2023.10397433"
    },
    {
        "id": 10790,
        "title": "Differentiating brain states via multi-clip random fragment strategy-based interactive bidirectional recurrent neural network",
        "authors": "Shu Zhang, Enze Shi, Lin Wu, Ruoyang Wang, Sigang Yu, Zhengliang Liu, Shaochen Xu, Tianming Liu, Shijie Zhao",
        "published": "2023-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.06.040"
    },
    {
        "id": 10791,
        "title": "Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction",
        "authors": "Cam Van Thi Nguyen, Tuan Mai, Son The, Dang Kieu, Duc-Trong Le",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.937"
    },
    {
        "id": 10792,
        "title": "Next Word Prediction using Recurrent Neural Networks",
        "authors": "",
        "published": "2023-11-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.58257/ijprems32232"
    },
    {
        "id": 10793,
        "title": "Image Captioning System Using Merge Conventional and Recurrent Neural Networks",
        "authors": "Rasha Talib Gdeeb",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "Image captioning system is that operation where we create a group of captions defines the image content and depends specially on deep learning. This technology is used for a wide range in recent time because it can help as example the blind people by telling them about all the objects around them which Nvidia company has the lead of it. Many searches were done in this subject and may be the most important one that search done by Andrej Karpathy leader of artificial intelligent in Tesla company depending on Flicker database which gives a special result used by next researches. ICS (Image Captioning Systems) are end-to-end Sequence-to-Sequence systems where we can convert a series of image pixels descriptions into a series of words. For images objects recognition we can use conventional neural networks (CNN) and for the words recognition and text build we will use recurrent neural network",
        "keywords": "",
        "link": "http://dx.doi.org/10.47832/minarcongress9-17"
    },
    {
        "id": 10794,
        "title": "DESIGN AND DEVELOPMENT OF EFFICIENT WATER QUALITY PREDICTION MODELS USING VARIANTS OF RECURRENT NEURAL NETWORKS",
        "authors": "",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.48047/ecb/2023.12.si5.0143"
    },
    {
        "id": 10795,
        "title": "Optimizing the Spatial-Temporal Extent of Environmental Factors in Forecasting El Niño and La Niña Using Recurrent Neural Network",
        "authors": "Jahnavi Jonnalagadda, Mahdi Hashemi",
        "published": "2023-6-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/engproc2023039010"
    },
    {
        "id": 10796,
        "title": "Soil Nutrient Evaluation System Based on Improved Recurrent Neural Network",
        "authors": "Yingbo Bu, Xinjie Yu, Yao Yang",
        "published": "2023-2-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nnice58320.2023.10105705"
    },
    {
        "id": 10797,
        "title": "Convolutional Recurrent Neural Networks for the Classification of Cetacean Bioacoustic Patterns",
        "authors": "Dimitris N. Makropoulos, Antigoni Tsiami, Aristides Prospathopoulos, Dimitris Kassis, Alexandros Frantzis, Emmanuel Skarsoulis, George Piperakis, Petros Maragos",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10096422"
    },
    {
        "id": 10798,
        "title": "SGORNN: Combining scalar gates and orthogonal constraints in recurrent networks",
        "authors": "Will Taylor-Melanson, Martha Dais Ferreira, Stan Matwin",
        "published": "2023-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2022.11.028"
    },
    {
        "id": 10799,
        "title": "Exploring a Basis Set of Intrinsic Functions Underlying Neural Computation by Symbolically Programming Recurrent Neural Networks.",
        "authors": "Daniel Calbick, Ilker Yildirim, Jason Kim",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32470/ccn.2023.1692-0"
    },
    {
        "id": 10800,
        "title": "DRGNN - Dilated recurrent graph neural network framework incorporating spatial and temporal features signifying social relationships in IoT network based traffic prediction",
        "authors": "Jegatheesan Divya, Arumugam Chandrasekar",
        "published": "2023",
        "citations": 0,
        "abstract": "The intelligent transportation system seeks to reduce traffic and improve the driving experience. They give us a lot of data that we can use to improve services for both the public and transportation officials by feeding it into machine learning systems. Most importantly, Traffic environment refers to everything that might have an impact on how much traffic is moving down the road, including traffic signals, accidents, protests, and even road repairs that might result in a backup. A motorist or rider can make an informed choice if they have previous knowledge that is very close to approximate all the above and many more real-world circumstances that can affect traffic. Additionally, it aids in the development of driverless vehicles. Traffic data have been growing dramatically in recent decades, and we are moving toward big data concepts for transportation. The current approaches for predicting traffic flow use some traffic prediction models, however they are still inadequate to handle practical situations. We thus aimed to focus on the traffic flow forecast problem using the traffic data and prediction models. The proposed model called DRGNN, a dilated recurrent graph neural network framework aims to effectively analyze and predict the traffic pattern by considering the spatial (space) and temporal (time) aspects of the real-time traffic data considering social relationships between internet of vehicles which indeed produced accurate and valuable insights that could help in deploying the model in any suitable real-time traffic monitoring and prediction system.",
        "keywords": "",
        "link": "http://dx.doi.org/10.14311/nnw.2023.33.026"
    },
    {
        "id": 10801,
        "title": "Recurrent neural networks for enhanced joint channel estimation and interference cancellation in FBMC and OFDM systems: unveiling the potential for 5G networks",
        "authors": "Rasha M. Al-Makhlasawy, Mayada Khairy, Walid El-Shafai",
        "published": "2023-11-24",
        "citations": 1,
        "abstract": "AbstractFBMC is a pivotal system in 5G, serving as a cornerstone for efficient use of available bandwidth while simultaneously meeting stringent requirements for high spectral efficiency. Notably, FBMC harnesses the power of multicarrier modulation (MC), a good alternative to orthogonal frequency division multiplexing (OFDM) technology that supports fourth-generation (4G) systems. The wireless communications field is full of challenges, the most important of which are channel estimation and interference cancellation, both of which deserve comprehensive study to increase the efficiency of data transmission. In this paper, our investigation takes a deliberate step towards the convergence of two prominent modulation models: OFDM and FBMC. We specifically contrast these modulation techniques with the intricate field of joint channel estimation and interference cancellation (JCEIC). In this research study, we take advantage of recurrent neural networks' (RNNs') efficiency as a vehicular channel to perform precise channel estimation and recovery of uncorrupted transmitted signals, thereby lowering the bit error rate (BER). Our channel estimation for a dual selective channel is based on the thoughtful placement of pilots scattered over the temporal and frequency dimensions, and is further improved by the interference cancellation method of low complexity that was selected. Our JCEIC proposal aims to integrate RNNs carefully, using the output sequences of JCEIC algorithms as useful inputs to this neural architecture. By clearly demonstrating a decrease in BER as compared to traditional approaches, it is evident that the performance of the novel approach is near to that of a perfect channel. Additionally, a comparison of the performance of FBMC and OFDM systems at various signal-to-noise ratios reveals a clear performance divide that favors the former in terms of system efficiency. The BER is restricted by FBMC to a commendable threshold of less than 0.1 at a modest 5 dB, continuing the higher trend started by its improved RNN-based channel estimate. The accuracy of channel estimation is clearly improved by this paradigm shift, and the computing complexity typical of 5G networks is also clearly reduced.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s13634-023-01077-0"
    },
    {
        "id": 10802,
        "title": "Temporal shuffling for defending deep action recognition models against adversarial attacks",
        "authors": "Jaehui Hwang, Huan Zhang, Jun-Ho Choi, Cho-Jui Hsieh, Jong-Seok Lee",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.10.033"
    },
    {
        "id": 10803,
        "title": "Merging of Neural Networks",
        "authors": "Martin Pašen, Vladimír Boža",
        "published": "2024-2-6",
        "citations": 0,
        "abstract": "AbstractWe propose a simple scheme for merging two neural networks trained with different starting initialization into a single one with the same size as the original ones. We do this by carefully selecting channels from each input network. Our procedure might be used as a finalization step after one tries multiple starting seeds to avoid an unlucky one. We also show that training two networks and merging them leads to better performance than training a single network for an extended period of time.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-024-11445-y"
    },
    {
        "id": 10804,
        "title": "Recurrent segmentation meets block models in temporal networks",
        "authors": "Chamalee Wickrama Arachchi, Nikolaj Tatti",
        "published": "2024-1-30",
        "citations": 0,
        "abstract": "AbstractA popular approach to model interactions is to represent them as a network with nodes being the agents and the interactions being the edges. Interactions are often timestamped, which leads to having timestamped edges. Many real-world temporal networks have a recurrent or possibly cyclic behaviour. In this paper, our main interest is to model recurrent activity in such temporal networks. As a starting point we use stochastic block model, a popular choice for modelling static networks, where nodes are split into R groups. We extend the block model to temporal networks by modelling the edges with a Poisson process. We make the parameters of the process dependent on time by segmenting the time line into K segments. We require that only $$H \\le K$$\n\nH\n≤\nK\n\n different set of parameters can be used. If $$H < K$$\n\nH\n<\nK\n\n, then several, not necessarily consecutive, segments must share their parameters, modelling repeating behaviour. We propose two variants where a group membership of a node is fixed over the course of entire time line and group memberships are allowed to vary from segment to segment. We prove that searching for optimal groups and segmentation in both variants is NP-hard. Consequently, we split the problem into 3 subproblems where we optimize groups, model parameters, and segmentation in turn while keeping the remaining structures fixed. We propose an iterative algorithm that requires $$\\mathcal {O} \\left( KHm + Rn + R^2\\,H\\right)$$\n\nO\n\nK\nH\nm\n+\nR\nn\n+\n\nR\n2\n\n\nH\n\n\n time per iteration, where n and m are the number of nodes and edges in the network. We demonstrate experimentally that the number of required iterations is typically low, the algorithm is able to discover the ground truth from synthetic datasets, and show that certain real-world networks exhibit recurrent behaviour as the likelihood does not deteriorate when H is lowered.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10994-023-06507-6"
    },
    {
        "id": 10805,
        "title": "Integrating Explicit Contexts with Recurrent Neural Networks for Improving Prognostic Models",
        "authors": "Rashmi Dutta Baruah, Mario Muñoz Organero",
        "published": "2023-3-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aero55745.2023.10115751"
    },
    {
        "id": 10806,
        "title": "Data-driven learning of chaotic dynamical systems using Discrete-Temporal Sobolev Networks",
        "authors": "Connor Kennedy, Trace Crowdis, Haoran Hu, Sankaran Vaidyanathan, Hong-Kun Zhang",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2024.106152"
    },
    {
        "id": 10807,
        "title": "Cross-patient automatic epileptic seizure detection using patient-adversarial neural networks with spatio-temporal EEG augmentation",
        "authors": "Zongpeng Zhang, Taoyun Ji, Mingqing Xiao, Wen Wang, Guojing Yu, Tong Lin, Yuwu Jiang, Xiaohua Zhou, Zhouchen Lin",
        "published": "2024-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.bspc.2023.105664"
    },
    {
        "id": 10808,
        "title": "A direct discretization recurrent neurodynamics method for time-variant nonlinear optimization with redundant robot manipulators",
        "authors": "Yang Shi, Wangrong Sheng, Shuai Li, Bin Li, Xiaobing Sun, Dimitrios K. Gerontitis",
        "published": "2023-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.04.040"
    },
    {
        "id": 10809,
        "title": "Gated Recurrent Fusion UNet for Depth Completion",
        "authors": "Tao Li, Xiucheng Dong, Hongwei Lin",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-023-11334-w"
    },
    {
        "id": 10810,
        "title": "Graph Representation for Weakly-Supervised Spatio-Temporal Action Detection",
        "authors": "Dinesh Singh",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10192033"
    },
    {
        "id": 10811,
        "title": "Characterizing functional brain networks via Spatio-Temporal Attention 4D Convolutional Neural Networks (STA-4DCNNs)",
        "authors": "Xi Jiang, Jiadong Yan, Yu Zhao, Mingxin Jiang, Yuzhong Chen, Jingchao Zhou, Zhenxiang Xiao, Zifan Wang, Rong Zhang, Benjamin Becker, Dajiang Zhu, Keith M. Kendrick, Tianming Liu",
        "published": "2023-1",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2022.11.004"
    },
    {
        "id": 10812,
        "title": "DuReSE: Rewriting Incomplete Utterances via Neural Sequence Editing",
        "authors": "Wenhui Jiang, Xiaodong Gu, Yuting Chen, Beijun Shen",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-023-11174-8"
    },
    {
        "id": 10813,
        "title": "Characterising representation dynamics in recurrent neural networks for object recognition",
        "authors": "Sushrut Thorat, Adrien Doerig, Tim Kietzmann",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32470/ccn.2023.1088-0"
    },
    {
        "id": 10814,
        "title": "The Application of Generating API Call Sequence Code for Android Driven by Neural Network",
        "authors": "Jingbo Yang, Wenjun Wu, Jian Ren",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191527"
    },
    {
        "id": 10815,
        "title": "An advanced spatio-temporal convolutional recurrent neural network for storm surge predictions",
        "authors": "Ehsan Adeli, Luning Sun, Jianxun Wang, Alexandros A. Taflanidis",
        "published": "2023-9",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00521-023-08719-2"
    },
    {
        "id": 10816,
        "title": "Deep Temporal Contrastive Clustering",
        "authors": "Ying Zhong, Dong Huang, Chang-Dong Wang",
        "published": "2023-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-023-11287-0"
    },
    {
        "id": 10817,
        "title": "Advancing Recurrent Neural Networks and Generative Adversarial Networks: A Technical Framework for Enhanced Effectiveness Evaluation",
        "authors": "Xia Yu",
        "published": "2023-9-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciscae59047.2023.10393296"
    },
    {
        "id": 10818,
        "title": "Multi-branch spatial-temporal-spectral convolutional neural networks for multi-task motor imagery EEG classification",
        "authors": "Zikun Cai, Tian-jian Luo, Xuan Cao",
        "published": "2024-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.bspc.2024.106156"
    },
    {
        "id": 10819,
        "title": "Deep neural networks for the detection of temporal-lobe epileptiform discharges from scalp electroencephalograms",
        "authors": "Hsiao-Lung Chan, Yuan Ouyang, Po-Jung Huang, Han-Tao Li, Chun-Wei Chang, Bao-Luen Chang, Wen-Yen Hsu, Tony Wu",
        "published": "2023-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.bspc.2023.104698"
    },
    {
        "id": 10820,
        "title": "Stability and Limit Cycles of Fuzzy Inferences in a Recurrent Petri-like Neural Network",
        "authors": "Lidia Ghosh, Dipanjan Konar, Amit Konar, Atulya K. Nagar",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191279"
    },
    {
        "id": 10821,
        "title": "Neural Networks with Dependent Inputs",
        "authors": "Mostafa Boskabadi, Mahdi Doostparast",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-023-11263-8"
    },
    {
        "id": 10822,
        "title": "Extended dissipative criteria for delayed semi-discretized competitive neural networks",
        "authors": "B. Adhira, G. Nagamani",
        "published": "2024-3-25",
        "citations": 0,
        "abstract": "AbstractThis brief investigates the extended dissipativity performance of semi-discretized competitive neural networks (CNNs) with time-varying delays. Inspired by the computational efficiency and feasibility of implementing the networks, we formulate a discrete counterpart to the continuous-time CNNs. By employing an appropriate Lyapunov–Krasovskii functional (LKF) and a relaxed summation inequality, sufficient conditions ensure the extended dissipative criteria of discretized CNNs are obtained in the linear matrix inequality framework. Finally, to refine our prediction, two numerical examples are provided to demonstrate the sustainability and merits of the theoretical results.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-024-11583-3"
    },
    {
        "id": 10823,
        "title": "Decoding self-motion from visual image sequence predicts distinctive features of reflexive motor responses to visual motion",
        "authors": "Daiki Nakamura, Hiroaki Gomi",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.03.020"
    },
    {
        "id": 10824,
        "title": "Emotion Recognition in Reddit Comments Using Recurrent Neural\nNetworks",
        "authors": "Mahdi Rezapour",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "\nBackground:\nReddit comments are a valuable source of natural language data\nwhere emotion plays a key role in human communication. However, emotion recognition is a\ndifficult task that requires understanding the context and sentiment of the texts. In this paper,\nwe aim to compare the effectiveness of four recurrent neural network (RNN) models for classifying the emotions of Reddit comments.\n\n\nMethods:\nWe use a small dataset of 4,922 comments labeled with four emotions: approval,\ndisapproval, love, and annoyance. We also use pre-trained Glove.840B.300d embeddings as\nthe input representation for all models. The models we compare are SimpleRNN, Long ShortTerm Memory (LSTM), bidirectional LSTM, and Gated Recurrent Unit (GRU). We experiment with different text preprocessing steps, such as removing stopwords and applying stemming, removing negation from stopwords, and the effect of setting the embedding layer as\ntrainable on the models.\n\n\nResults:\nWe find that GRU outperforms all other models, achieving an accuracy of 74%. Bidirectional LSTM and LSTM are close behind, while SimpleRNN performs the worst. We observe that the low accuracy is likely due to the presence of sarcasm, irony, and complexity in\nthe texts. We also notice that setting the embedding layer as trainable improves the performance of LSTM but increases the computational cost and training time significantly. We analyze some examples of misclassified texts by GRU and identify the challenges and limitations\nof the dataset and the models\n\n\nConclusion:\nIn our study GRU was found to be the best model for emotion classification of\nReddit comments among the four RNN models we compared. We also discuss some future directions for research to improve the emotion recognition task on Reddit comments. Furthermore, we provide an extensive discussion of the applications and methods behind each technique in the context of the paper.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.2174/0126662558273325231201051141"
    },
    {
        "id": 10825,
        "title": "Memory capacity of recurrent neural networks with matrix representation",
        "authors": "Animesh Renanse, Alok Sharma, Rohitash Chandra",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neucom.2023.126824"
    },
    {
        "id": 10826,
        "title": "Recurrent Neural Networks With More Flexible Memory: Better Predictions Than Rough Volatility",
        "authors": "Damien Challet, Vincent Ragel",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4514331"
    },
    {
        "id": 10827,
        "title": "Trajectory-Based State-of-Charge Prediction Using LSTM Recurrent Neural Networks",
        "authors": "Adan Ernesto Vela",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dasc58513.2023.10311254"
    },
    {
        "id": 10828,
        "title": "Recurrent Neural Networks for Forecasting Social Processes",
        "authors": "Angelin Lalev, Alexandrina Alexandrova",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bdkcse59280.2023.10339767"
    },
    {
        "id": 10829,
        "title": "ST-GIN: An Uncertainty Quantification Approach in Traffic Data Imputation with Spatio-Temporal Graph Attention and Bidirectional Recurrent United Neural Networks",
        "authors": "Zepu Wang, Dingyi Zhuang, Yankai Li, Jinhua Zhao, Peng Sun, Shenhao Wang, Yulin Hu",
        "published": "2023-9-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/itsc57777.2023.10422526"
    },
    {
        "id": 10830,
        "title": "Spatial-Temporal Recurrent Graph Neural Networks for Fault Diagnostics in Power Distribution Systems",
        "authors": "Bang L. H. Nguyen, Tuyen V. Vu, Thai-Thanh Nguyen, Mayank Panwar, Rob Hovsapian",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3273292"
    },
    {
        "id": 10831,
        "title": "‘Seeing’ the Future: Improving Macroeconomic Forecasts with Spatial Data Using Recurrent Convolutional Neural Networks",
        "authors": "Jonathan Leslie",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4350048"
    },
    {
        "id": 10832,
        "title": "Load Margin Assessment of Power Systems Using Recurrent Neural Networks",
        "authors": "Murilo E. C. Bento",
        "published": "2023-11-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/induscon58041.2023.10374951"
    },
    {
        "id": 10833,
        "title": "Learning of Cognitive Control during Task Switching in Recurrent Neural Networks",
        "authors": "Shengjie Xu, Tom Verguts, Senne Braem",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32470/ccn.2023.1253-0"
    },
    {
        "id": 10834,
        "title": "Phish-armour: phishing detection using deep recurrent neural networks",
        "authors": "P. Dhanavanthini, S. Sibi Chakkravarthy",
        "published": "2023-3-27",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00500-023-07962-y"
    },
    {
        "id": 10835,
        "title": "Spectro-Temporal Recurrent Neural Network for Robotic Slip Detection with Piezoelectric Tactile Sensor",
        "authors": "Théo Ayral, Saifeddine Aloui, Mathieu Grossard",
        "published": "2023-6-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aim46323.2023.10196263"
    },
    {
        "id": 10836,
        "title": "Human Activity Recognition Based on Deep-Temporal Learning Using Convolution Neural Networks Features and Bidirectional Gated Recurrent Unit With Features Selection",
        "authors": "Tariq Ahmad, Jinsong Wu, Hathal Salamah Alwageed, Faheem Khan, Jawad Khan, Youngmoon Lee",
        "published": "2023",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3263155"
    },
    {
        "id": 10837,
        "title": "Retracted: Note Detection in Music Teaching Based on Intelligent Bidirectional Recurrent Neural Network",
        "authors": "",
        "published": "2023-8-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9850239"
    },
    {
        "id": 10838,
        "title": "End-to-End Classification of Cell-Cycle Stages with Center-Cell Focus Tracker Using Recurrent Neural Networks",
        "authors": "Abin Jose, Rijo Roy, Dennis Eschweiler, Ina Laube, Reza Azad, Daniel Moreno-Andrés, Johannes Stegmaier",
        "published": "2023-6-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10095221"
    },
    {
        "id": 10839,
        "title": "Data-driven recurrent neural networks modeling of cyanobacteria growth in bubble columns reactors under sparging with CO2-enriched Air",
        "authors": "Karen Joselyne Avilez-Cuahquentzi, Antonio Flores-Tlacuahuac, Diana Ramírez-Gamboa, Roberto Parra-Saldivar",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cep.2023.109653"
    },
    {
        "id": 10840,
        "title": "Quantifying and Maximizing the Information Flux in Recurrent Neural Networks",
        "authors": "Claus Metzner, Marius E. Yamakou, Dennis Voelkl, Achim Schilling, Patrick Krauss",
        "published": "2024-2-16",
        "citations": 1,
        "abstract": "Abstract\nFree-running recurrent neural networks (RNNs), especially probabilistic models, generate an ongoing information flux that can be quantified with the mutual information I[x→(t),x→(t+1)] between subsequent system states x→. Although previous studies have shown that I depends on the statistics of the network’s connection weights, it is unclear how to maximize I systematically and how to quantify the flux in large systems where computing the mutual information becomes intractable. Here, we address these questions using Boltzmann machines as model systems. We find that in networks with moderately strong connections, the mutual information I is approximately a monotonic transformation of the root-mean-square averaged Pearson correlations between neuron pairs, a quantity that can be efficiently computed even in large systems. Furthermore, evolutionary maximization of I[x→(t),x→(t+1)] reveals a general design principle for the weight matrices enabling the systematic construction of systems with a high spontaneous information flux. Finally, we simultaneously maximize information flux and the mean period length of cyclic attractors in the state-space of these dynamical networks. Our results are potentially useful for the construction of RNNs that serve as short-time memories or pattern generators.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1162/neco_a_01651"
    },
    {
        "id": 10841,
        "title": "GT-LSTM: A spatio-temporal ensemble network for traffic flow prediction",
        "authors": "Yong Luo, Jianying Zheng, Xiang Wang, Yanyun Tao, Xingxing Jiang",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.12.016"
    },
    {
        "id": 10842,
        "title": "Bayesian hypernetwork collaborates with time-difference evolutional network for temporal knowledge prediction",
        "authors": "Pengpeng Shao, Yang Wen, Jianhua Tao",
        "published": "2024-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2024.106146"
    },
    {
        "id": 10843,
        "title": "Convolutional Recurrent Neural Networks for Medical Image Recognition",
        "authors": "Pankaj Saraswat, Rohaila Naaz, Kavitha R",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470932"
    },
    {
        "id": 10844,
        "title": "Attention-Based Deep Spiking Neural Networks for Temporal Credit Assignment Problems",
        "authors": "Lang Qin, Ziming Wang, Rui Yan, Huajin Tang",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2023.3240176"
    },
    {
        "id": 10845,
        "title": "Fracture Estimation Based on Deformation History with Recurrent Neural Networks",
        "authors": "Muhammed Adil Yatkin, Mihkel Kõrgesaar",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00152"
    },
    {
        "id": 10846,
        "title": "Algorithm for Mobile Robot Localization Based on Recurrent Convolutional Neural Networks",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18178/wcse.2023.06.029"
    },
    {
        "id": 10847,
        "title": "A Sequence Tagging based Framework for Few-Shot Relation Extraction",
        "authors": "Xukun Luo, Ping Wang",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191604"
    },
    {
        "id": 10848,
        "title": "Comparisons of Stock Prediction Methods Based on Recurrent Neural Networks",
        "authors": "George Shao",
        "published": "2023-2-28",
        "citations": 0,
        "abstract": "These instructions give you guidelines for preparing papers for DRP. Use this document as a template if you are using Microsoft Word 6.0 or later. Otherwise, use this document as an instruction set. The electronic file of your paper will be formatted further at DRP. Paper titles should be written in uppercase and lowercase letters, not all uppercase. Avoid writing long formulas with subscripts in the title; short formulas that identify the elements are fine (e.g., \"Nd-Fe-B\"). Do not write “(Invited)” in the title. Full names of authors are preferred in the author field, but are not required. Put a space between authors’ initials. The abstract must be a concise yet comprehensive reflection of what is in your article. In particular, the abstract must be self-contained, without abbreviations, footnotes, or references. It should be a microcosm of the full article. The abstract must be between 100 - 300 words. Be sure that you adhere to these limits; otherwise, you will need to edit your abstract accordingly. The abstract must be written as one paragraph, and should not contain displayed mathematical equations or tabular material. The abstract should include three or four different keywords or phrases, as this will help readers to find it. It is important to avoid over-repetition of such phrases as this can result in a page being rejected by search engines. Ensure that your abstract reads well and is grammatically correct.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v34i.5376"
    },
    {
        "id": 10849,
        "title": "Investigating the Use of Spatial Transformer Networks and Recurrent Neural Networks for Medical Image Segmentation",
        "authors": "Vineet Saxena, M N Nachappa, Ritu Shree",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470837"
    },
    {
        "id": 10850,
        "title": "Universal Recurrent Event Memories for Streaming Data",
        "authors": "Ran Dou, Jose Principe",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191277"
    },
    {
        "id": 10851,
        "title": "Dynamic Rumor Control in Social Networks Using Temporal Graph Neural Networks",
        "authors": "Jonson Manurung, Poltak Sihombing, Mohammad Andri Budiman,  Sawaluddin",
        "published": "2023-11-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icosnikom60230.2023.10364382"
    },
    {
        "id": 10852,
        "title": "A Combined Model Based on Recurrent Neural Networks and Graph Convolutional Networks for Financial Time Series Forecasting",
        "authors": "Ana Lazcano, Pedro Javier Herrera, Manuel Monge",
        "published": "2023-1-2",
        "citations": 22,
        "abstract": "Accurate and real-time forecasting of the price of oil plays an important role in the world economy. Research interest in forecasting this type of time series has increased considerably in recent decades, since, due to the characteristics of the time series, it was a complicated task with inaccurate results. Concretely, deep learning models such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) have appeared in this field with promising results compared to traditional approaches. To improve the performance of existing networks in time series forecasting, in this work two types of neural networks are brought together, combining the characteristics of a Graph Convolutional Network (GCN) and a Bidirectional Long Short-Term Memory (BiLSTM) network. This is a novel evolution that improves existing results in the literature and provides new possibilities in the analysis of time series. The results confirm a better performance of the combined BiLSTM-GCN approach compared to the BiLSTM and GCN models separately, as well as to the traditional models, with a lower error in all the error metrics used: the Root Mean Squared Error (RMSE), the Mean Squared Error (MSE), the Mean Absolute Percentage Error (MAPE) and the R-squared (R2). These results represent a smaller difference between the result returned by the model and the real value and, therefore, a greater precision in the predictions of this model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math11010224"
    },
    {
        "id": 10853,
        "title": "Global Asymptotic Stability of Anti-Periodic Solutions of Time-Delayed Fractional Bam Neural Networks",
        "authors": "Münevver Tuz",
        "published": "2024-3-30",
        "citations": 0,
        "abstract": "AbstractIn this study, bidirectional fractional-order BAM neural networks with time-varying delays are examined. Time delay is an important phenomenon in the implementation of a signal or effect passing through neural network. Signal transmission in neural networks can generally be described as an anti-periodic process. Our aim is to show global asymptotic stability and the uniqueness of the equilibrium point for such neural networks in the problem with antiperiodic solution.For this purpose, the proof was made using differential inequality theory, basic analysis information, and the Lyapunov functional method. In addition, a numerical example is presented to verify the theoretical results.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-024-11561-9"
    },
    {
        "id": 10854,
        "title": "A Hybrid Approch for Noise Suppression Based on Recurrent Neural Network",
        "authors": "Mingyuan Zhong",
        "published": "2023-4-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsp58490.2023.10248570"
    },
    {
        "id": 10855,
        "title": "SpikeSEE: An energy-efficient dynamic scenes processing framework for retinal prostheses",
        "authors": "Chuanqing Wang, Chaoming Fang, Yong Zou, Jie Yang, Mohamad Sawan",
        "published": "2023-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.05.002"
    },
    {
        "id": 10856,
        "title": "PIPER: A logic-driven deep contrastive optimization pipeline for event temporal reasoning",
        "authors": "Beibei Zhang, Lishuang Li",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.04.020"
    },
    {
        "id": 10857,
        "title": "Temporal Spatial Decomposition and Fusion Network for Time Series Forecasting*",
        "authors": "Liwang Zhou, Jing Gao",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191934"
    },
    {
        "id": 10858,
        "title": "Artificial intelligence-based Medicine Recognition System using faster Recurrent Convolutional Neural Networks",
        "authors": "P.Ranjith Kumar, Tarun Jaiswal, Satyabrata Jena",
        "published": "2023",
        "citations": 0,
        "abstract": "Recently, chronic patients are taking multiple medications incorrectly and taking the wrong medications due to similarity of drugs.It is possible that taking the improper medication can result in hazardous interactions with other medications or they will counteract the intended benefits of the medications, resulting in extra severe repercussions such as acute complications. The conventional methods are failed to provide the maximum efficiency. Therefore, this article is focused on implementation of faster recurrent convolutional neural networks (FR-CNN), which is capable of extracting the features from images. FR-CNN mainly used to analyze the patterns of the medicines and extracts the deep features. Further, classification of medicines is carried out by comparing with ground truth labels. The simulation results shows that the proposed system resulted in superior performance as compared to state of art approaches.",
        "keywords": "",
        "link": "http://dx.doi.org/10.58599/ijsmien.2023.1105"
    },
    {
        "id": 10859,
        "title": "Temporal Inconsistency-Based Intrinsic Reward for Multi-Agent Reinforcement Learning",
        "authors": "Shaoqi Sun, Kele Xu",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191420"
    },
    {
        "id": 10860,
        "title": "Reconstructing computational system dynamics from neural data with recurrent neural networks",
        "authors": "Daniel Durstewitz, Georgia Koppe, Max Ingo Thurm",
        "published": "2023-11",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41583-023-00740-7"
    },
    {
        "id": 10861,
        "title": "Uncertainty-Aware QoT Forecasting in Optical Networks with Bayesian Recurrent Neural Networks",
        "authors": "Nicola Di Cicco, Jacopo Talpini, Mëmëdhe Ibrahimi, Marco Savi, Massimo Tornatore",
        "published": "2023-5-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icc45041.2023.10278767"
    },
    {
        "id": 10862,
        "title": "Performing decision-making tasks through dynamics of recurrent neural networks trained with reinforcement learning",
        "authors": "Roman Kononov, Oleg Maslennikov",
        "published": "2023-9-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dcna59899.2023.10290321"
    },
    {
        "id": 10863,
        "title": "Recurrent Neural Networks (RNNs) to improve EEG-based person identification",
        "authors": "Youssef Mohamed, Ahmed M. Anter, Ahmed B. Zaky",
        "published": "2023-7-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/imsa58542.2023.10217750"
    },
    {
        "id": 10864,
        "title": "Session-based Recommendation with Temporal Graph Neural Network and Contrastive Learning",
        "authors": "Xiaolong Li, Xiaoru Wang, Haoxiang Zhang, Jiabin Zhang",
        "published": "2023-2-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nnice58320.2023.10105727"
    },
    {
        "id": 10865,
        "title": "Fraud Detection using Recurrent Neural Networks for Digital Wallet Security",
        "authors": "Can Iscan, Fatma Patlar Akbulut",
        "published": "2023-9-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ubmk59864.2023.10286651"
    },
    {
        "id": 10866,
        "title": "Automating Medical Image Segmentation with Recurrent Neural Networks",
        "authors": "Neeraj Das, Ajay Kumar Upadhyay, Deepak Mehta",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470816"
    },
    {
        "id": 10867,
        "title": "STACoRe: Spatio-temporal and action-based contrastive representations for reinforcement learning in Atari",
        "authors": "Young Jae Lee, Jaehoon Kim, Mingu Kwak, Young Joon Park, Seoung Bum Kim",
        "published": "2023-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2022.12.018"
    },
    {
        "id": 10868,
        "title": "Improving Wind Speed Uncertainty Forecasts Using Recurrent Neural Networks",
        "authors": "Juri Backes, Wolfgang Renz",
        "published": "2023-1-23",
        "citations": 0,
        "abstract": "For integration of growing amounts of volatile renewable energy in the European electricity system, reliable weather prognosis gains importance. But, depending on weather conditions, forecast reliability of wind speed for predicting wind power can vary drastically with time. Thus, relevance of risk-aware system operation strategies is increasing based on wind speed uncertainty a measure of which is provided by the standard deviations of ensemble forecasts of the German Weather Service. However, lacking validity of this measure is known as a long-standing problem.Therefore, this work investigates how machine learning based on a suitably selected set of physical quantities of weather ensemble data as well as historic wind data allows for a more realistic uncertainty quantification. A recurrent neural network (RNN) based sequence-to-sequence architecture is implemented and probabilistic wind speed forecasts are generated for a region in northern Germany.The results are evaluated and compared with the forecasts of the German Weather Service thereby revealing improved validity of such deep-learning based uncertainty measures.",
        "keywords": "",
        "link": "http://dx.doi.org/10.7557/18.6806"
    },
    {
        "id": 10869,
        "title": "Graph Generation with Recurrent and Graph Neural Networks",
        "authors": "Xikun Huang, Yangyang Li, Chaoqun Fei, Chuanqing Wang",
        "published": "2023-11-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/medai59581.2023.00033"
    },
    {
        "id": 10870,
        "title": "Recurrent Neural Networks for Improved Medical Image Classification",
        "authors": "Umesh Kumar Singh, Kavitha R, Pankaj Saraswat",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470908"
    },
    {
        "id": 10871,
        "title": "A novel hardware-efficient ergodic sequential logic spiking neural network and reproductions of biologically plausible spatio-temporal phenomena towards development of neural prosthetic device",
        "authors": "Yuta Shiomi, Hiroyuki Torikai",
        "published": "2023-6-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191905"
    },
    {
        "id": 10872,
        "title": "Guest editorial: Special issue on advances in deep learning based speech processing",
        "authors": "Xiao-Lei Zhang, Lei Xie, Eric Fosler-Lussier, Emmanuel Vincent",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2022.11.033"
    },
    {
        "id": 10873,
        "title": "A Comparative Study of Convolutional Neural Networks and Recurrent Neural Networks for Chord Recognition",
        "authors": "Hania Nawaz Khan, Sibghatullah Bazai, Zubair Zaland, Sibghatullah Durrani, Saad Aslam, Angela Amphawan, Fatima Ali, Tse-Kian Neo",
        "published": "2023-9-5",
        "citations": 0,
        "abstract": "Using Mel-spectrograms, this study evaluates the effectiveness of Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNNs). Mel-spectrograms are justified by their non- linearity and similarity to the human hearing system. This study uses over 200 tracks by The Beatles and Queen collected through the Music Information Retrieval Evaluation Exchange. Data augmentation approaches are used to increase accuracy on unusual chords. This paper presents a 3-layer 2D CNN model trained on major and minor chords and then expanded to different types of chords. The dataset demonstrates that both models can recognize musical chords across various genres. We compare the proposed results to the existing literature and demonstrate the effectiveness of the proposed methodology. As a result of our analysis, we found that the CNN and RNN models were 79% and 76% accurate, respectively. The presented findings suggest that CNNs and RNNs are suitable models for chord recognition using Mel-spectrograms. Data augmentation can be an effective technique for improving accuracy on rare chords.",
        "keywords": "",
        "link": "http://dx.doi.org/10.15379/ijmst.v10i2.1837"
    },
    {
        "id": 10874,
        "title": "Hopf Bifurcation of General Fractional Delayed TdBAM Neural Networks",
        "authors": "M. Rakshana, P. Balasubramaniam",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-023-11302-4"
    },
    {
        "id": 10875,
        "title": "FBN-TCN: Temporal convolutional neural network based on spatial domain fusion brain networks for affective brain–computer interfaces",
        "authors": "Jinying Bi, Fei Wang, Jingyu Ping, Gangguo Qu, Fangzhou Hu, Hao Li, Shuai Han",
        "published": "2024-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.bspc.2024.106323"
    },
    {
        "id": 10876,
        "title": "Combining recurrent and Graph Neural Networks to predict the next place’s category",
        "authors": "Cláudio G.S. Capanema, Guilherme S. de Oliveira, Fabrício A. Silva, Thais R.M.B. Silva, Antonio A.F. Loureiro",
        "published": "2023-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.adhoc.2022.103016"
    },
    {
        "id": 10877,
        "title": "Recurrent Neural Language Models as Probabilistic Finite-state Automata",
        "authors": "Anej Svete, Ryan Cotterell",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.502"
    },
    {
        "id": 10878,
        "title": "Special Issue on Neural Networks for Early Cancer Detection",
        "authors": "Shiping Wen, R. Dhanasekaran",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-023-11299-w"
    },
    {
        "id": 10879,
        "title": "Multi-Level Node Authorization using Recurrent Neural Networks for Secure Health Monitoring System",
        "authors": "V. Lakshman Narayana, P. Syamalatha, P. Vatsalya, V. SriCharitha, V. Akhila",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icscna58489.2023.10370543"
    },
    {
        "id": 10880,
        "title": "Multi-Label Temporal Evidential Neural Networks for Early Event Detection",
        "authors": "Xujiang Zhao, Xuchao Zhang, Chen Zhao, Jin-Hee Cho, Lance Kaplan, Dong Hyun Jeong, Audun Jøsang, Haifeng Chen, Feng Chen",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10096305"
    },
    {
        "id": 10881,
        "title": "Detecting Cyber Attacks in Industrial Control Systems Using Spatio-Temporal Autoencoder",
        "authors": "Bin Lan, Shunzheng Yu",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191873"
    },
    {
        "id": 10882,
        "title": "Real-Time MRI Video Synthesis from Time Aligned Phonemes with Sequence-to-Sequence Networks",
        "authors": "Sathvik Udupa, Prasanta Kumar Ghosh",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10094797"
    },
    {
        "id": 10883,
        "title": "Efficient Extraction and Automated Thyroid Prediction with an Optimized Gated Recurrent Unit in Recurrent Neural Networks",
        "authors": "Et al. Nagavali Saka",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "Computer-aided tools are becoming increasingly important in medical diagnostics. This paper introduces the Efficient Feature Extraction Based Recurrent Neural Network (FERNN) for computer-aided thyroid disease prediction. The FERNN model uses a Gated Recurrent Unit Recurrent Neural Network (GRU-RNN) optimized with the COOT Optimization Algorithm.The study begins by gathering data from an open-source system and preprocessing it using min-max normalization to address missing values. The preprocessed data undergoes a two-level feature extraction (TLFE) procedure. In the first level, a ranked filter feature set technique is used to prioritize features based on medical expert recommendations. In the second level, a variety of metrics, including information gain, gain ratio, chi-square, and relief, are used to rank and select features. A composite measure guided by fuzzy logic is then used to select a judicious subset of features. The FERNN model uses the GRU-RNN to classify thyroid diseases in the databases. To optimise, the COOT optimization method is employed. The model's weights. The FERNN model was put into practise in MATLAB and assessed with a variety of statistical metrics, including kappa, accuracy, precision, recall, sensitivity, specificity, and the F-measure. The proposed methodology was benchmarked against traditional techniques, including the deep belief neural network (DBN), artificial neural network (ANN), and support vector machine (SVM).",
        "keywords": "",
        "link": "http://dx.doi.org/10.17762/ijritcc.v11i9.9607"
    },
    {
        "id": 10884,
        "title": "Sequence-to-Sequence Recurrent Graph Convolutional Networks for Traffic Estimation and Prediction Using Connected Probe Vehicle Data",
        "authors": "Amr Abdelraouf, Mohamed Abdel-Aty, Nada Mahmoud",
        "published": "2023-1",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tits.2022.3168865"
    },
    {
        "id": 10885,
        "title": "pymodconn: A python package for developing modular sequence-to-sequence control-oriented deep neural networks",
        "authors": "Gaurav Chaudhary, Hicham Johra, Laurent Georges, Bjørn Austbø",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.softx.2023.101599"
    },
    {
        "id": 10886,
        "title": "Sequential Learning Network With Residual Blocks: Incorporating Temporal Convolutional Information Into Recurrent Neural Networks",
        "authors": "Dongjing Shan, Kun Yao, Xiongwei Zhang",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tcds.2023.3325358"
    },
    {
        "id": 10887,
        "title": "Exploring weight initialization, diversity of solutions, and degradation in recurrent neural networks trained for temporal and decision-making tasks",
        "authors": "Cecilia Jarne, Rodrigo Laje",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10827-023-00857-9"
    },
    {
        "id": 10888,
        "title": "Multi-Branch Spatial-Temporal Decoupling Neural Network for Traffic Forecasting",
        "authors": "Hui Zheng, Yi Qian, Ruoxuan Zhu, Xing Wang, Junlan Feng, Lin Zhu, Chao Deng",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191710"
    },
    {
        "id": 10889,
        "title": "Methane Concentration Forecasting Based on Sentinel-5P Products and Recurrent Neural Networks",
        "authors": "Theofani Psomouli, Ioannis Kansizoglou, Antonios Gasteratos",
        "published": "2023-6-16",
        "citations": 0,
        "abstract": "The increase in the concentration of geological gas emissions in the atmosphere and particularly the increase of methane is considered by the majority of the scientific community as the main cause of global climate change. The main reasons that place methane at the center of interest, lie in its high global warming potential (GWP) and its lifetime in the atmosphere. Anthropogenic processes, like engineering geology ones, highly affect the daily profile of gasses in the atmosphere. Should direct measures be taken to reduce emissions of methane, immediate global warming mitigation could be achieved. Due to its significance, methane has been monitored by many space missions over the years and as of 2017 by the Sentinel-5P mission. Considering the above, we conclude that monitoring and predicting future methane concentration based on past data is of vital importance for the course of climate change over the next decades. To that end, we introduce a method exploiting state-of-the-art recurrent neural networks (RNNs), which have been proven particularly effective in regression problems, such as time-series forecasting. Aligned with the green artificial intelligence (AI) initiative, the paper at hand investigates the ability of different RNN architectures to predict future methane concentration in the most active regions of Texas, Pennsylvania and West Virginia, by using Sentinel-5P methane data and focusing on computational and complexity efficiency. We conduct several empirical studies and utilize the obtained results to conclude the most effective architecture for the specific use case, establishing a competitive prediction performance that reaches up to a 0.7578 mean squared error on the evaluation set. Yet, taking into consideration the overall efficiency of the investigated models, we conclude that the exploitation of RNN architectures with less number of layers and a restricted number of units, i.e., one recurrent layer with 8 neurons, is able to better compensate for competitive prediction performance, meanwhile sustaining lower computational complexity and execution time. Finally, we compare RNN models against deep neural networks along with the well-established support vector regression, clearly highlighting the supremacy of the recurrent ones, as well as discuss future extensions of the introduced work.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/geosciences13060183"
    },
    {
        "id": 10890,
        "title": "Optimal Energy Forecasting Using Hybrid Recurrent Neural Networks",
        "authors": "Elumalaivasan Poongavanam, Padmanathan Kasinathan, Kulothungan Kanagasabai",
        "published": "2023",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/iasc.2023.030101"
    },
    {
        "id": 10891,
        "title": "The Smart Intuitive Natural Language Understanding with Recurrent Neural Networks",
        "authors": "R Raghavendra, Megha Pandeya, Deepak Kumar",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470796"
    },
    {
        "id": 10892,
        "title": "Location Estimation of Moving Targets by Passive Sonobuoy and Recurrent Deep Neural Network",
        "authors": "Hooshang Abbaspour, Ghazal Najafi",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isncc58260.2023.10323838"
    },
    {
        "id": 10893,
        "title": "Deep Learning for Marginal Bayesian Posterior Inference with Recurrent Neural Networks",
        "authors": "Thayer Fisher, Alex Luedtke, Marco Carone, Noah Simon",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5705/ss.202020.0348"
    },
    {
        "id": 10894,
        "title": "Recurrent Neural Networks for Solving Photovoltaic System Dynamics",
        "authors": "Md Rifat Hossain, Sumit Paudyal, Tuyen Vu",
        "published": "2023-11-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isgt-la56058.2023.10328292"
    },
    {
        "id": 10895,
        "title": "The Smart Improving of Translation Models Using Recurrent Neural Networks",
        "authors": "Anjali Singh, Mayur Agarwal, Gowrishankar J",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470485"
    },
    {
        "id": 10896,
        "title": "Explaining deep neural networks processing raw diagnostic signals",
        "authors": "Nico Herwig, Pietro Borghesani",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ymssp.2023.110584"
    },
    {
        "id": 10897,
        "title": "Spectro Temporal Fusion with CLSTM-Autoencoder based approach for Anomalous Sound Detection",
        "authors": "S. Chandrakala, Akhilandeswari Pidikiti, P. V. N. Sai Mahathi",
        "published": "2024-2-15",
        "citations": 0,
        "abstract": "AbstractDeep learning models are proved efficient for complex learning tasks. Anomalous sound detection is one such complex task for which self-supervised deep architectures are emerging in recent days. Self-supervised deep models efficiently capture the underlying structure of data. Self-supervised anomalous sound detection attempts to distinguish between normal sounds and unidentified anomalous sounds. With the use of appropriate autoencoders, reconstruction error based decision making is effective for anomaly detection in domains such as computer vision. Auditory image (Spectrogram) based representation of sound signals are commonly used in sound event detection. We propose convolutional long short-term memory (CLSTM) Auto Encoder based approach for anomalous sound detection. In this approach, we explore fusion of spectral and temporal features to model characteristics of normal sounds with noises. The proposed approach is evaluated using MIMII dataset and the DCASE Challenge (2020) Task 2—Anomalous sound detection dataset. Experiments on proposed approach reveal significant improvement over the state-of-the-art approaches.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-024-11485-4"
    },
    {
        "id": 10898,
        "title": "The Convergence of Incremental Neural Networks",
        "authors": "Lei Chen, Yilin Wang, Lixiao Zhang, Wei Chen",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-023-11429-4"
    },
    {
        "id": 10899,
        "title": "Online Spatio-Temporal Learning in Deep Neural Networks",
        "authors": "Thomas Bohnstingl, Stanisław Woźniak, Angeliki Pantazi, Evangelos Eleftheriou",
        "published": "2023-11",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2022.3153985"
    },
    {
        "id": 10900,
        "title": "Data-Driven Tabulation for Chemistry Integration Using Recurrent Neural Networks",
        "authors": "Yu Zhang, Qingguo Lin, Wenli Du, Feng Qian",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2022.3175301"
    },
    {
        "id": 10901,
        "title": "Temporal group-aware graph diffusion networks for dynamic link prediction",
        "authors": "Da Huang, Fangyuan Lei",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ipm.2023.103292"
    },
    {
        "id": 10902,
        "title": "Stability Analysis of Recurrent Neural Networks With Time-Varying Delay by Flexible Terminal Interpolation Method",
        "authors": "Zhanshan Wang, Yufeng Tian",
        "published": "2024-2",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2022.3188161"
    },
    {
        "id": 10903,
        "title": "Daily Prediction Model of Photovoltaic Power Generation Using a Hybrid Architecture of Recurrent Neural Networks and Shallow Neural Networks",
        "authors": "Wilson Castillo-Rojas, Juan Bekios-Calfa, César Hernández",
        "published": "2023-4-18",
        "citations": 0,
        "abstract": "In recent years, photovoltaic energy has become one of the most implemented electricity generation options to help reduce environmental pollution suffered by the planet. Accuracy in this photovoltaic energy forecasting is essential to increase the amount of renewable energy that can be introduced to existing electrical grid systems. The objective of this work is based on developing various computational models capable of making short-term forecasting about the generation of photovoltaic energy that is generated in a solar plant. For the implementation of these models, a hybrid architecture based on recurrent neural networks (RNN) with long short-term memory (LSTM) or gated recurrent units (GRU) structure, combined with shallow artificial neural networks (ANN) with multilayer perceptron (MLP) structure, is established. RNN models have a particular configuration that makes them efficient for processing ordered data in time series. The results of this work have been obtained through controlled experiments with different configurations of its hyperparameters for hybrid RNN-ANN models. From these, the three models with the best performance are selected, and after a comparative analysis between them, the forecasting of photovoltaic energy production for the next few hours can be determined with a determination coefficient of 0.97 and root mean square error (RMSE) of 0.17. It is concluded that the proposed and implemented models are functional and capable of predicting with a high level of accuracy the photovoltaic energy production of the solar plant, based on historical data on photovoltaic energy production.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/2592405"
    },
    {
        "id": 10904,
        "title": "Exponential Stability of Stochastic Time-Delay Neural Networks with Random Delayed Impulses",
        "authors": "Yueli Huang, Ailong Wu, Jin-E Zhang",
        "published": "2024-2-15",
        "citations": 0,
        "abstract": "AbstractThe mean square exponential stability of stochastic time-delay neural networks (STDNNs) with random delayed impulses (RDIs) is addressed in this paper. Focusing on the variable delays in impulses, the notion of average random delay is adopted to consider these delays as a whole, and the stability criterion of STDNNs with RDIs is developed by using stochastic analysis idea and the Lyapunov method. Taking into account the impulsive effect, interference function and stabilization function of delayed impulses are explored independently. The results demonstrate that delayed impulses with random properties take a crucial role in dynamics of STDNNs, not only making stable STDNNs unstable, but also stabilizing unstable STDNNs. Our conclusions, specifically, allow for delays in both impulsive dynamics and continuous subsystems that surpass length of impulsive interval, which alleviates certain severe limitations, such as presence of upper bound for impulsive delays or requirement that impulsive delays can only exist between two impulsive events. Finally, feasibility of the theoretical results is verified through three simulation examples.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-024-11521-3"
    }
]