[
    {
        "id": 10001,
        "title": "Artificial Intelligence, Large Language Models, and Large Vision Models in Education",
        "authors": "Thu Nguyễn, Uy Nguyen",
        "published": "No Date",
        "citations": 0,
        "abstract": "We discuss the transformative impact of artificial intelligence (AI) and large-scale language and vision models on the landscape of education. The integration of AI technologies, exemplified by models like ChatGPT and large vision models, has the potential to revolutionize various aspects of the educational experience. We consider the diverse applications of AI in education, ranging from personalized learning and intelligent tutoring systems to automated grading and enhanced content creation, while also addressing the associated challenges and ethical considerations",
        "link": "http://dx.doi.org/10.35542/osf.io/h9r4z"
    },
    {
        "id": 10002,
        "title": "Explainable Large Language Models &amp; iContracts",
        "authors": "Georgios Stathis",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012607400003636"
    },
    {
        "id": 10003,
        "title": "Large Language Models",
        "authors": "Michael McTear, Marina Ashurkina",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0110-5_4"
    },
    {
        "id": 10004,
        "title": "Large language models as models of human cognition",
        "authors": "Michael C. Frank",
        "published": "No Date",
        "citations": 1,
        "abstract": "Can a large language model be used as a ‘cognitive model’, a scientific artifact that helps us understand the human mind? If LLMs can be made openly accessible to scientific investigation then they may provide a valuable model system for studying the emergence of language, reasoning, and other uniquely human behaviors.",
        "link": "http://dx.doi.org/10.31234/osf.io/wxt69"
    },
    {
        "id": 10005,
        "title": "Language Models for Everyone—Responsible and Transparent Development of Open Large Language Models",
        "authors": "Daniel Gillblad",
        "published": "2023-9-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3390/cmsf2023008051"
    },
    {
        "id": 10006,
        "title": "Large language models",
        "authors": "Henry Knipe, Som Biswas",
        "published": "2023-6-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.53347/rid-169923"
    },
    {
        "id": 10007,
        "title": "Pipelines for Social Bias Testing of Large Language Models",
        "authors": "Debora Nozza, Federico Bianchi, Dirk Hovy",
        "published": "2022",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bigscience-1.6"
    },
    {
        "id": 10008,
        "title": "Applications of large language models in oncology",
        "authors": "Chiara M. Loeffler, Keno K. Bressem, Daniel Truhn",
        "published": "2024-2-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00761-024-01481-7"
    },
    {
        "id": 10009,
        "title": "Large Language Models and the Legacy System",
        "authors": "Nicolo Torre",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>We describe a general technique to create an NLP interface to legacy systems by applying large language models. Usability of the legacy system is increased while the problem of hallucination with LLM is avoided. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23298176"
    },
    {
        "id": 10010,
        "title": "Building Student Module For Large Language Models",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The current large language models (LLMs) mainly lacks this capability: autonomous learning capability. Also, we can not prepare all the data/knowledge in the world for LLMs. We propose Learning In Conversation (LIC) to solve the problem to let human teach machine to refresh/expand its data/knowledge automatically by natural language conversation. LIC system is an AI system that contains many deep learning tasks. LIC system provide the natural language interface to let machine to learn new data/knowledge in conversation interacting with human automatically. It is critical, but except for the developers of the AI system, others have no natural language interface to do this education for machine. Based on large language models (LLMs) conversation ability, we train an additional intent recognition model to determine when the AI system need to learn new data/knowledge. We add a module for editing the training dataset of LLMs. We propose the methods to implement our idea and discuss the reasons why we design these methods.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24638814.v1"
    },
    {
        "id": 10011,
        "title": "Large Language Models and Creative Writing",
        "authors": "Srinaath Anbu Durai",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>This is a experimental and qualitative study about Human-AI interaction which investigated Large Language Models (LLMs) in creative writing tasks.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24500524.v1"
    },
    {
        "id": 10012,
        "title": "Building Student Module For Large Language Models",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The current large language models (LLMs) mainly lacks this capability: autonomous learning capability. Also, we can not prepare all the data/knowledge in the world for LLMs. We propose Learning In Conversation (LIC) to solve the problem to let human teach machine to refresh/expand its data/knowledge automatically by natural language conversation. LIC system is an AI system that contains many deep learning tasks. LIC system provide the natural language interface to let machine to learn new data/knowledge in conversation interacting with human automatically. It is critical, but except for the developers of the AI system, others have no natural language interface to do this education for machine. Based on large language models (LLMs) conversation ability, we train an additional intent recognition model to determine when the AI system need to learn new data/knowledge. We add a module for editing the training dataset of LLMs. We propose the methods to implement our idea and discuss the reasons why we design these methods.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24638814"
    },
    {
        "id": 10013,
        "title": "Large Language Models and the Legacy System",
        "authors": "Nicolo Torre",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>We describe a general technique to create an NLP interface to legacy systems by applying large language models. Usability of the legacy system is increased while the problem of hallucination with LLM is avoided. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23298176.v1"
    },
    {
        "id": 10014,
        "title": "Large Language Models and Creative Writing",
        "authors": "Srinaath Anbu Durai",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>This is a experimental and qualitative study about Human-AI interaction which investigated Large Language Models (LLMs) in creative writing tasks.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24500524"
    },
    {
        "id": 10015,
        "title": "Proceedings of the Conference Recent Advances in Natural Language Processing - Large Language Models for Natural Language Processings",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_xxx"
    },
    {
        "id": 10016,
        "title": "Review for \"The moral machine experiment on large language models\"",
        "authors": "",
        "published": "2024-1-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1098/rsos.231393/v1/review2"
    },
    {
        "id": 10017,
        "title": "Going Large (Language Models) at ISMB2023",
        "authors": "Scott Edmunds",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.59350/dz9kz-z6133"
    },
    {
        "id": 10018,
        "title": "Going Large (Language Models) at ISMB2023",
        "authors": "Scott Edmunds",
        "published": "No Date",
        "citations": 0,
        "abstract": "<strong> Once again the <em> GigaScience Press </em> team has gathered at the yearly ISMB (Intelligent Systems for Molecular Biology) meeting to find out about the state of the art of computational biology, as well as celebrate our birthday </strong> . Hosted this year in the beautiful city",
        "link": "http://dx.doi.org/10.59350/59yfe-63e94"
    },
    {
        "id": 10019,
        "title": "Review for \"The moral machine experiment on large language models\"",
        "authors": "",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1098/rsos.231393/v1/review1"
    },
    {
        "id": 10020,
        "title": "Large Language Models in Medical Education and Quality Concerns",
        "authors": "Vinaytosh Mishra",
        "published": "2023",
        "citations": 1,
        "abstract": "The world is witnessing increased digitalization in the recent past",
        "link": "http://dx.doi.org/10.23880/jqhe-16000319"
    },
    {
        "id": 10021,
        "title": "Large Language Models are Extremely Bad at Creating Anagrams",
        "authors": "Michael King",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Much has been made of the remarkable abilities of generative artificial intelligence (AI) and large language models (LLMs) such as ChatGPT, and their ability to rapidly produce convincingly human-like text on demand. I set out to evaluate the ability of three popular LLMs (ChatGPT version GPT-4; ChatGPT version GPT-3.5; Google Bard) to construct anagrams, that is, pairs of words or phrases that use all of the same letters exactly once, rearranged into new meaningful words and phrases. These models have been previously demonstrated to perform well on text-based portions of general intelligence tests, successfully solving various word and mathematical puzzles in a manner that resembles elements of human general intelligence. Surprisingly, all three LLMs performed quite badly when prompted to generate anagrams related to a specific theme, succeeding in only 2.5% of anagram attempts overall, with only the GPT-4 version of ChatGPT producing any valid anagrams at all. All three LLMs successfully returned the correct definition of an anagram, along with providing one or more valid examples when queried. In summary, the failure of current LLMs to generate anagrams related to a specific theme provides a curious example of a “cognitive blind spot” in the performance of these otherwise impressive tools.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23712309.v1"
    },
    {
        "id": 10022,
        "title": "Large language models as probes into latent psychology",
        "authors": "Zhicheng Lin",
        "published": "No Date",
        "citations": 0,
        "abstract": "Advances in AI invite the misuse of language models as stand-ins for human minds or participants, which fundamentally mischaracterizes these statistical algorithms. We argue that language models should be embraced as flexible simulation tools, able to mimic a wide range of behaviors, perspectives, and psychological attributes evident in human language data, but the models themselves should not be equated to or anthropomorphized as human minds.",
        "link": "http://dx.doi.org/10.31234/osf.io/uqxcb"
    },
    {
        "id": 10023,
        "title": "Sentiment Trading with Large Language Models",
        "authors": "Kemal Kirtac, Guido Germano",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4706629"
    },
    {
        "id": 10024,
        "title": "A Large Language Models Digest For Social Scientists",
        "authors": "Daniel Valdenegro",
        "published": "No Date",
        "citations": 2,
        "abstract": "I write these lines not as an expert in LLMs, but more as an informed user. I did my PhD on the application of early transformers-based language models (e.g. BERT, RoBERTa) to classify large amounts of text data. I have experience with their ``fine-tuning\" process and a reasonable amount of knowledge about their training process. However, NLP technology has progressed fast and in a couple of years we moved from models containing hundreds of millions of parameters, to models containing hundreds of billions of parameters. Large Language Models keep getting larger and more capable. Companies closely related to the work of social scientists are taking note of this and they are starting to offer “AI-powered” qualitative software (e.g., see AtlasTi new OpenAI alliance) opening exciting new avenues for social scientists.However, I believe that while the technical capabilities of the models have progressed fast, our actual understanding of what they are and what they are actually capable of doing has been, maybe purposely, left behind. There are several misconceptions about the models' “reasoning” and “introspection” capabilities, with claims pointing towards a soon-to-be-achieved \"Artificial General Intelligence\" (AGI), a holy grail of the research in artificial intelligence, but without offering substantial evidence of such claims. There is also the incredibly thick jargon used in the AI and Machine Learning community, ---which I’m more than guilty of using---, which, sometimes purposely, contributes to gate-keep the knowledge and details of this new to technologies to a reduce group of individuals. Finally, there is a fair amount of marketing strategy around the communications related to LLMs. Most of the newest Large Language Models are the intellectual property and product of large companies and corporations, as they are too big and costly to be trained by singular individuals. For these corporations, being seen by the general public as producing real “Artificial General Intelligence” or “Reasoning Machines” is a big selling point, although the reality might be much more nuanced than that.All of this contributes to generate confusion and mystification around AI, in general, and Large Language Models in particular. So, in a personal effort to clear-up my own thoughts and to hopefully provide something useful for others, in this document I will attempt to provide a high-level description of what LLMs are, how they work and what they are capable of doing, especially for social scientists.",
        "link": "http://dx.doi.org/10.31235/osf.io/m74vs"
    },
    {
        "id": 10025,
        "title": "Large Language Models are Extremely Bad at Creating Anagrams",
        "authors": "Michael King",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Much has been made of the remarkable abilities of generative artificial intelligence (AI) and large language models (LLMs) such as ChatGPT, and their ability to rapidly produce convincingly human-like text on demand. I set out to evaluate the ability of three popular LLMs (ChatGPT version GPT-4; ChatGPT version GPT-3.5; Google Bard) to construct anagrams, that is, pairs of words or phrases that use all of the same letters exactly once, rearranged into new meaningful words and phrases. These models have been previously demonstrated to perform well on text-based portions of general intelligence tests, successfully solving various word and mathematical puzzles in a manner that resembles elements of human general intelligence. Surprisingly, all three LLMs performed quite badly when prompted to generate anagrams related to a specific theme, succeeding in only 2.5% of anagram attempts overall, with only the GPT-4 version of ChatGPT producing any valid anagrams at all. All three LLMs successfully returned the correct definition of an anagram, along with providing one or more valid examples when queried. In summary, the failure of current LLMs to generate anagrams related to a specific theme provides a curious example of a “cognitive blind spot” in the performance of these otherwise impressive tools.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23712309"
    },
    {
        "id": 10026,
        "title": "Malinowski (1922) on Large Language Models",
        "authors": "Mark Dingemanse",
        "published": "No Date",
        "citations": 0,
        "abstract": "It’s easy to forget amidst a rising tide of synthetic text, but language is not actually about strings of words, and language scientists would do well not to chain themselves to models that presume so. For apt and timely commentary we turn to Bronislaw Malinowski who wrote: In follow-up work, Malinowski has critiqued the unexamined use of decontextualised strings of words as a proxy for Meaning: Malinowski did not write this on his substack,",
        "link": "http://dx.doi.org/10.59350/87ndy-8h096"
    },
    {
        "id": 10027,
        "title": "Large Language Models: AI Foundations and Applications in Python",
        "authors": "Jayanti Prasad",
        "published": "2023",
        "citations": 0,
        "abstract": "This 5-day workshop provides a comprehensive understanding of large language models, their AI foundations, and applications in Python. Designed for PhD students, professors, and professional researchers, the seminar offers hands-on coding sessions, case studies, and discussions on the future of large language models in academic research.",
        "link": "http://dx.doi.org/10.61700/85rfezw01y0q9521"
    },
    {
        "id": 10028,
        "title": "Large Language Models Show Human Behavior",
        "authors": "Rik Huijzer, Yannick Hill",
        "published": "No Date",
        "citations": 0,
        "abstract": "Neural networks can approximate any function given sufficiently many hidden units, which implies that they, in theory, can approximate human behavior. Recently, natural language processing has advanced rapidly due to increases in the amount of hidden units and in the size of the datasets. With these advances in natural language capabilities, we wondered whether state-of-the-art Large Language Models show human behavior. In this article, we demonstrate that these models show language comprehension and communication skills to solve problems, which are considered to be key features of human behavior. Moreover, the process by which such AI-based models encode information leads to errors which are also common in humans, such as being vulnerable to misleading questions, source amnesia, and being sensitive to small changes in wording. Given the similarities with human behavior, we discuss the potential applications of LLMs in social science research.We conclude that LLMs and their close alignment with human behavior may provide a valuable source of information that can be studied to gain a better understanding of human behavior.",
        "link": "http://dx.doi.org/10.31234/osf.io/munc9"
    },
    {
        "id": 10029,
        "title": "Future of Interacting with Computers and Large Language Models",
        "authors": "Migul Jain",
        "published": "2023-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21275/sr231023121603"
    },
    {
        "id": 10030,
        "title": "Analyzing Declarative Deployment Code with Large Language Models",
        "authors": "Giacomo Lanciano, Manuel Stein, Volker Hilt, Tommaso Cucinotta",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011991200003488"
    },
    {
        "id": 10031,
        "title": "Programming Computational Electromagnetic Applications Assisted by Large Language Models",
        "authors": "Leandro Carísio Fernandes",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>This article discusses the possibilities and limitations of using large language models (LLMs) in software development with applications in computational electromagnetics. Three tasks are discussed: code translation, code generation, and code description. The tests showed that LLMs are generally very useful. Even when errors occurred, they can provide useful hints to find a solution.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22581760"
    },
    {
        "id": 10032,
        "title": "The knowledge dividend of large language models",
        "authors": "Chris von Csefalvay",
        "published": "No Date",
        "citations": 0,
        "abstract": "Over at the work blog, I’m discussing what knowledge means for large language models (LLMs), and the ways in which we can leverage this knowledge dividend for better inference. As I’m writing this, the sun hasn’t risen over the Denver skyline in earnest. There’s still pink in the sky over the Front Range, and most of the world is still blissfully asleep.",
        "link": "http://dx.doi.org/10.59350/bk59j-te848"
    },
    {
        "id": 10033,
        "title": "The knowledge dividend of large language models",
        "authors": "Chris von Csefalvay",
        "published": "No Date",
        "citations": 0,
        "abstract": "Over at the work blog, I’m discussing what knowledge means for large language models (LLMs), and the ways in which we can leverage this knowledge dividend for better inference. As I’m writing this, the sun hasn’t risen over the Denver skyline in earnest. There’s still pink in the sky over the Front Range, and most of the world is still blissfully asleep.",
        "link": "http://dx.doi.org/10.59350/rmj17-p1z87"
    },
    {
        "id": 10034,
        "title": "Programming Computational Electromagnetic Applications Assisted by Large Language Models",
        "authors": "Leandro Carísio Fernandes",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>This article discusses the possibilities and limitations of using large language models (LLMs) in software development with applications in computational electromagnetics. Three tasks are discussed: code translation, code generation, and code description. The tests showed that LLMs are generally very useful. Even when errors occurred, they can provide useful hints to find a solution.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22581760.v2"
    },
    {
        "id": 10035,
        "title": "Unleashing the Economic Potential of Large Language Models: The Case of Chinese Language Efficiency",
        "authors": "Barnas Monteith, michael sung",
        "published": "No Date",
        "citations": 1,
        "abstract": "<p>Abstract: Large language models (LLMs) have revolutionized the way we interact with technology, and ChatGPT, based on the GPT-3.5 architecture, has garnered significant attention for its exceptional performance. The widespread adoption of ChatGPT by over 100 million users within three months, generating 1.8 billion website visitors per month, highlights its versatility and appeal. The economic impact of LLMs extends beyond businesses, empowering developers and entrepreneurs to create innovative products and services. This paper explores the potential of LLMs, specifically focusing on the efficiency and advantages offered by the Chinese language.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23291831.v1"
    },
    {
        "id": 10036,
        "title": "Programming Computational Electromagnetic Applications Assisted by Large Language Models",
        "authors": "Leandro Carísio Fernandes",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>This article discusses the possibilities and limitations of using large language models (LLMs) in software development with applications in computational electromagnetics. Three tasks are discussed: code translation, code generation, and code description. The tests showed that LLMs are generally very useful. Even when errors occurred, they can provide useful hints to find a solution.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22581760.v1"
    },
    {
        "id": 10037,
        "title": "How to write effective prompts for large language models",
        "authors": "Zhicheng Lin",
        "published": "No Date",
        "citations": 1,
        "abstract": "As large language models (LLMs) proliferate across research landscapes, effectively engaging with them becomes increasingly vital. This article presents a practical guide for understanding their capabilities and limitations, along with the art of crafting well-structured queries, to extract maximum utility from these AI tools.",
        "link": "http://dx.doi.org/10.31234/osf.io/r78fc"
    },
    {
        "id": 10038,
        "title": "Can Large Language Models Help Augment English Psycholinguistic Datasets?",
        "authors": "Sean Trott",
        "published": "No Date",
        "citations": 0,
        "abstract": "Research on language and cognition relies extensively on large, psycholinguistic datasets —sometimes called “norms”. These datasets contain judgments of lexical properties like concreteness and age of acquisition, and can be used to norm experimental stimuli, discover empirical relationships in the lexicon, and stress-test computational models. However, collecting human judgments at scale is both time-consuming and expensive. This issue of scale is made more difficult for norms containing multiple semantic dimensions and especially for norms that incorporate linguistic context. In the current work, I explore whether advances in Large Language Models (LLMs) can be leveraged to augment the creation of large, psycholinguistic datasets in English. I use GPT-4 to collect multiple kinds of semantic judgments (e.g., word similarity, contextualized sensorimotor associations, iconicity) for English words and compare these judgments against the human “gold standard”. For each dataset, I find that GPT-4’s judgments are positively correlated with human judgments, in some cases rivaling or even exceeding the average inter-annotator agreement displayed by humans. I then explore whether and how LLM-generated norms differ from human-generated norms systematically. I also perform several “substitution analyses”, which demonstrate that replacing human-generated norms with LLM-generated norms in a statistical model does not change the sign of parameter estimates (though in select cases, there are significant changes to their magnitude). Finally, I conclude by discussing the limitations of this approach and under what conditions LLM-generated norms could be useful to researchers.",
        "link": "http://dx.doi.org/10.31234/osf.io/jvenz"
    },
    {
        "id": 10039,
        "title": "The Comparative Emotional Capabilities of  Five Popular Large Language Models",
        "authors": "Nathan Klapach",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.58445/rars.645"
    },
    {
        "id": 10040,
        "title": "Large Language Models Bias Issues Solving Through SDRT",
        "authors": "Nagesh Somayajula, Chinmay Somayajula",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p> The paper \"Large Language Models Bias Issues Solving Through SDRT\" discusses the challenges and ethical concerns posed by large language models (LLMs) such as GPT-3 and GPT-4 in the realm of natural language processing (NLP) and artificial intelligence research. It proposes a solution in the form of Segmented Discourse Representation Theory (SDRT) to address these challenges. By integrating SDRT into existing transformer models and incorporating it into both encoders and decoders, the paper aims to reduce bias, enhance semantic understanding, and foster more meaningful and transparent conversations. This approach recognizes the importance of responsible LLM development and the need for solutions to mitigate issues like misinformation, biased content, and lack of contextual understanding. Through its technical details and architectural improvements, the paper contributes to the ongoing discourse on enhancing the capabilities and ethical use of large language models in complex NLP environments. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24182064"
    },
    {
        "id": 10041,
        "title": "Large Language Models Bias Issues Solving Through SDRT",
        "authors": "Nagesh Somayajula, Chinmay Somayajula",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p> The paper \"Large Language Models Bias Issues Solving Through SDRT\" discusses the challenges and ethical concerns posed by large language models (LLMs) such as GPT-3 and GPT-4 in the realm of natural language processing (NLP) and artificial intelligence research. It proposes a solution in the form of Segmented Discourse Representation Theory (SDRT) to address these challenges. By integrating SDRT into existing transformer models and incorporating it into both encoders and decoders, the paper aims to reduce bias, enhance semantic understanding, and foster more meaningful and transparent conversations. This approach recognizes the importance of responsible LLM development and the need for solutions to mitigate issues like misinformation, biased content, and lack of contextual understanding. Through its technical details and architectural improvements, the paper contributes to the ongoing discourse on enhancing the capabilities and ethical use of large language models in complex NLP environments. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24182064.v1"
    },
    {
        "id": 10042,
        "title": "Large Language Models and the Wisdom of Small Crowds",
        "authors": "Sean Trott",
        "published": "No Date",
        "citations": 0,
        "abstract": "Recent advances in Large Language Models (LLMs) have raised the question of replacing human subjects with LLM-generated data. While some believe that LLMs capture the “wisdom of the crowd”—due to their vast training data—empirical evidence for this hypothesis remains scarce. We present a novel methodological framework to test this: the “number needed to beat” (NNB), which measures how many humans are needed for a sample’s quality to rival the quality achieved by GPT-4, a state-of-the-art LLM. We demonstrate the utility of this method for three psycholinguistic datasets. We also introduce two “centaur” methods for combining LLM and human data, which outperform both stand-alone LLMs and human samples. Finally, we analyze the trade-offs in data cost and quality for each approach. While clear limitations remain, we suggest that this framework could guide decision-making about whether and how to integrate LLM-generated data into the research pipeline.",
        "link": "http://dx.doi.org/10.31234/osf.io/a48zq"
    },
    {
        "id": 10043,
        "title": "Should large language models replace human participants?",
        "authors": "Molly Crockett, Lisa Messeri",
        "published": "No Date",
        "citations": 5,
        "abstract": "Recent advances in large language models (LLMs) like OpenAI’s GPT-4 and Alphabet’s Bard have captivated people around the world, including cognitive scientists. Recently, Dillion et al. [1] asked whether LLMs can replace human participants in cognitive science research, noting some of the limitations of these models and offering a framework for integrating them into a cognitive science research pipeline. Here, we suggest that alongside asking whether LLMs can replace human participants, we ought to critically consider whether they should. What are we assuming when we explore the possibility of treating LLMs as proxies for human participants? And what are the costs of those assumptions? Examining these questions offers opportunities for us to reflect on our values as a field.",
        "link": "http://dx.doi.org/10.31234/osf.io/4zdx9"
    },
    {
        "id": 10044,
        "title": "Unleashing the Economic Potential of Large Language Models: The Case of Chinese Language Efficiency",
        "authors": "Barnas Monteith, michael sung",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Abstract: Large language models (LLMs) have revolutionized the way we interact with technology, and ChatGPT, based on the GPT-3.5 architecture, has garnered significant attention for its exceptional performance. The widespread adoption of ChatGPT by over 100 million users within three months, generating 1.8 billion website visitors per month, highlights its versatility and appeal. The economic impact of LLMs extends beyond businesses, empowering developers and entrepreneurs to create innovative products and services. This paper explores the potential of LLMs, specifically focusing on the efficiency and advantages offered by the Chinese language.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23291831"
    },
    {
        "id": 10045,
        "title": "Computing Architecture for Large-Language Models (LLMs) and Large Multimodal Models (LMMs)",
        "authors": "Bor-Sung Liang",
        "published": "2024-3-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626184.3639692"
    },
    {
        "id": 10046,
        "title": "Efficient Use of Large Language Models for Analysis of Text Corpora",
        "authors": "David Adamczyk, Jan Hůla",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012349800003654"
    },
    {
        "id": 10047,
        "title": "Emergent Structures and Training Dynamics in Large Language Models",
        "authors": "Ryan Teehan, Miruna Clinciu, Oleg Serikov, Eliza Szczechla, Natasha Seelam, Shachar Mirkin, Aaron Gokaslan",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bigscience-1.11"
    },
    {
        "id": 10048,
        "title": "Understanding Telecom Language Through Large Language Models",
        "authors": "Lina Bariah, Hang Zou, Qiyang Zhao, Belkacem Mouhouche, Faouzi Bader, Merouane Debbah",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The recent progress of artificial intelligence (AI) opens up new frontiers in the possibility of automating many tasks involved in Telecom networks design, implementation, and deployment. This has been further pushed forward with the evolution of generative artificial intelligence (AI), including the emergence of large language models (LLMs), which is believed to be the cornerstone toward realizing self-governed, interactive AI agents. Motivated by this, in this paper, we aim to adapt the paradigm of LLMs to the Telecom domain. In particular, we fine-tune several LLMs including BERT, distilled BERT, RoBERTa and GPT-2, to the Telecom domain languages, and demonstrate a use case for identifying the \\ac{3gpp} standard working groups. We consider training the selected models on 3GPP techincal documents (Tdoc) pertinent to years 2009-2019 and predict the Tdoc categories in years 2020-2023. The results demonstrate that fine-tuning BERT and RoBERTa model achieves 84.6% accuracy, while GPT-2 model achieves 83% in identifying 3GPP working groups. The distilled BERT model with around 50% less parameters achieves similar performance as others. This corroborates that fine-tuning pretrained LLM can effectively identify the categories of Telecom language. The developed framework shows a stepping stone towards realizing intent-driven and self-evolving wireless networks from Telecom languages, and paves the way for the implementation of generative AI in the Telecom domain. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23501271.v1"
    },
    {
        "id": 10049,
        "title": "Understanding Telecom Language Through Large Language Models",
        "authors": "Lina Bariah, Hang Zou, Qiyang Zhao, Belkacem Mouhouche, Faouzi Bader, Merouane Debbah",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The recent progress of artificial intelligence (AI) opens up new frontiers in the possibility of automating many tasks involved in Telecom networks design, implementation, and deployment. This has been further pushed forward with the evolution of generative artificial intelligence (AI), including the emergence of large language models (LLMs), which is believed to be the cornerstone toward realizing self-governed, interactive AI agents. Motivated by this, in this paper, we aim to adapt the paradigm of LLMs to the Telecom domain. In particular, we fine-tune several LLMs including BERT, distilled BERT, RoBERTa and GPT-2, to the Telecom domain languages, and demonstrate a use case for identifying the \\ac{3gpp} standard working groups. We consider training the selected models on 3GPP techincal documents (Tdoc) pertinent to years 2009-2019 and predict the Tdoc categories in years 2020-2023. The results demonstrate that fine-tuning BERT and RoBERTa model achieves 84.6% accuracy, while GPT-2 model achieves 83% in identifying 3GPP working groups. The distilled BERT model with around 50% less parameters achieves similar performance as others. This corroborates that fine-tuning pretrained LLM can effectively identify the categories of Telecom language. The developed framework shows a stepping stone towards realizing intent-driven and self-evolving wireless networks from Telecom languages, and paves the way for the implementation of generative AI in the Telecom domain. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23501271"
    },
    {
        "id": 10050,
        "title": "Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language Understanding",
        "authors": "Mutian He, Philip N. Garner",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1799"
    },
    {
        "id": 10051,
        "title": "Demonstrating Large Language Models on Robots",
        "authors": " Google DeepMind",
        "published": "2023-7-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15607/rss.2023.xix.024"
    },
    {
        "id": 10052,
        "title": "Decision letter for \"The moral machine experiment on large language models\"",
        "authors": "",
        "published": "2024-1-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1098/rsos.231393/v2/decision1"
    },
    {
        "id": 10053,
        "title": "Using Large Language Models to Mitigate Ransomware Threats",
        "authors": "Fang Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "This paper explores the application of Large Language Models (LLMs), such as GPT-3 and GPT-4, in generating cybersecurity policies and strategies to mitigate ransomware threats, including data theft ransomware. We discuss the strengths and limitations of LLMs for ransomware defense and provide recommendations for effectively leveraging LLMs while ensuring ethical compliance. The key contributions include a quantitative evaluation of LLM-generated policies, an examination of the legal and ethical implications, and an analysis of how LLMs can enhance ransomware resilience when applied judiciously.",
        "link": "http://dx.doi.org/10.31219/osf.io/mzsnh"
    },
    {
        "id": 10054,
        "title": "Are Large Language Models Intelligent? Are Humans?",
        "authors": "Olle Häggström",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3390/cmsf2023008068"
    },
    {
        "id": 10055,
        "title": "Large Language Models for Slot Filling with Limited Data",
        "authors": "Guangzhi Sun",
        "published": "No Date",
        "citations": 0,
        "abstract": "Recently, advancements in large language models (LLMs) have shown an unprecedented ability across various language tasks. This paper investigates the potential application of LLMs to slot filling with noisy ASR transcriptions, via both in-context learning and task-specific fine-tuning. Dedicated prompt designs and fine-tuning approaches are proposed to improve the robustness of LLMs for slot filling with noisy ASR transcriptions. Moreover, a linearised knowledge injection (LKI) scheme is also proposed to integrate dynamic external knowledge into LLMs. Experiments were performed on SLURP to quantify the performance of LLMs, including GPT-3.5-turbo, GPT-4, LLaMA-13B and Vicuna-13B (v1.1 and v1.5) with different ASR error rates. The use of the proposed fine-tuning together with the LKI scheme for LLaMA-13B achieved an 8.3% absolute SLU-F1 improvement compared to the strong Flan-T5-base baseline system on a limited data setup.",
        "link": "http://dx.doi.org/10.33774/coe-2023-jf14v"
    },
    {
        "id": 10056,
        "title": "Decision letter for \"The moral machine experiment on large language models\"",
        "authors": "",
        "published": "2024-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1098/rsos.231393/v1/decision1"
    },
    {
        "id": 10057,
        "title": "BIRD: Business Insights and Recommendations Developer using Large Language Models",
        "authors": "Sarathbabu Karunanithi",
        "published": "No Date",
        "citations": 0,
        "abstract": "Business recommendations and proposals start with asking business\nquestions, insights from answering those questions, recommendations from\nthose insights and final proposals or recommendations for\nimplementation. In this paper, we present an end-to-end solution\nframework called BIRD (Business Insights and Recommendations Developer)\nwhich implements Large Language Models (LLMs) as a major part of this\nbusiness analysis cycle in developing business questions, extracting\ninsights, and providing recommendations in an end-to-end automated\nprocess. This framework also allows user interaction at any step for\nadditional context or commands.",
        "link": "http://dx.doi.org/10.36227/techrxiv.170594587.74941582/v1"
    },
    {
        "id": 10058,
        "title": "Around meta-analysis (15): emerging Large Language Models (LLM) tools",
        "authors": "Magorzata Lagisz",
        "published": "2024-1-30",
        "citations": 0,
        "abstract": "Systematic reviews (and meta-analyses based on a systematic review of literature) are extremely time-consuming. Anyone who conducted one in a rigorous and robust way can attest to this fact. Not surprisingly, researchers across disciplines have been looking for using computer algorithms and software to automate and accelerate systematic reviews of academic literature.",
        "link": "http://dx.doi.org/10.53962/krmv-p5c5"
    },
    {
        "id": 10059,
        "title": "Large Language Models are Not Models of Natural Language: They are Corpus Models",
        "authors": "Csaba Veres",
        "published": "2022",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2022.3182505"
    },
    {
        "id": 10060,
        "title": "Author response for \"The moral machine experiment on large language models\"",
        "authors": " Takemoto, Kazuhiro",
        "published": "2024-1-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1098/rsos.231393/v2/response1"
    },
    {
        "id": 10061,
        "title": "Can Language Models Solve Complex Subsurface Data Integrations: Building Subsurface Copilots with Large Language Models (LLMs)",
        "authors": "T.B. Grant, J. Goldwater, E. Knudsen",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3997/2214-4609.202439022"
    },
    {
        "id": 10062,
        "title": "Assessing Phrase Break of ESL Speech with Pre-trained Language Models and Large Language Models",
        "authors": "Zhiyi Wang, Shaoguang Mao, Wenshan Wu, Yan Xia, Yan Deng, Jonathan Tien",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-910"
    },
    {
        "id": 10063,
        "title": "Bridging the data gap between children and large language models",
        "authors": "Michael C. Frank",
        "published": "No Date",
        "citations": 1,
        "abstract": "Large language models show intriguing emergent behaviors, yet they receive around 4-5 orders of magnitude more language data than human children. What accounts for this vast difference in sample efficiency? Candidate explanations include children’s pre-existing conceptual structures, their use of multimodal grounding, and the interactive, social nature of their input.",
        "link": "http://dx.doi.org/10.31234/osf.io/qzbgx"
    },
    {
        "id": 10064,
        "title": "Using Large Language Models to Mitigate Ransomware Threats",
        "authors": "Fang Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "This paper explores the application of Large Language Models (LLMs), such as GPT-3 and GPT-4, in generating cybersecurity policies and strategies to mitigate ransomware threats, including data theft ransomware. We discuss the strengths and limitations of LLMs for ransomware defense and provide recommendations for effectively leveraging LLMs while ensuring ethical compliance. The key contributions include a quantitative evaluation of LLM-generated policies, an examination of the legal and ethical implications, and an analysis of how LLMs can enhance ransomware resilience when applied judiciously.",
        "link": "http://dx.doi.org/10.20944/preprints202311.0676.v1"
    },
    {
        "id": 10065,
        "title": "How to Use Large-Language Models for Text Analysis",
        "authors": "Petter Törnberg",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4135/9781529683707"
    },
    {
        "id": 10066,
        "title": "Embodied human language models vs. Large Language Models, or why Artificial Intelligence cannot explain the modal be able to",
        "authors": "Sergio Torres-Martínez",
        "published": "2024-2-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s12304-024-09553-2"
    },
    {
        "id": 10067,
        "title": "Large Language Models and Artificial Intelligence for Police Report Writing",
        "authors": "Ian T. Adams",
        "published": "2024-2-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21428/cb6ab371.779603ee"
    },
    {
        "id": 10068,
        "title": "Review of: \"A Survey of Large Language Models in Tourism (Tourism LLMs)\"",
        "authors": "Soma Das",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/4c7hdf"
    },
    {
        "id": 10069,
        "title": "Comparing the Dental Knowledge of Large Language Models",
        "authors": "Camila Tussie, Abraham Starosta",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIntroduction: With the advancement of Artificial Intelligence, Large Language Models (LLMs) have emerged as technology that can generate human-like text across various domains. They hold vast potential in the dental field, able to be integrated into clinical dentistry, administrative, and for student and patient education. However, the successful integration of LLMs into dentistry is reliant on the dental knowledge of the models utilized, as inaccuracies can lead to significant risks in patient care and education.Aims We are the first to compare different LLMs on their dental knowledge through testing the accuracy of different model responses to Integrated National Board Dental Examination (INBDE) questions.Methods We include closed-source and open-source models and analyzed responses to both “Patient Box” style board questions and more traditional, textual based multiple-choice questions.Results For the entire INBDE question bank, GPT-4 had the highest dental knowledge with an accuracy of 75.88%, followed by Claude-2.1 with 66.38% and then with Mistral-Medium’s 54.77%. There was a statistically significant difference in performance across all models.Conclusion Our results highlight the high potential of LLM integration into the dental field, the importance of which LLM is chosen when developing new technologies, and the limitations that must be overcome before unsupervised clinical integration can be adopted.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3974060/v1"
    },
    {
        "id": 10070,
        "title": "Review of: \"A Survey of Large Language Models in Tourism (Tourism LLMs)\"",
        "authors": "Arash Heidari",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/q3vwxw"
    },
    {
        "id": 10071,
        "title": "Addressing Compiler Errors: Stack Overflow or Large Language Models?",
        "authors": "Patricia Widjojo, Christoph Treude",
        "published": "No Date",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4529345"
    },
    {
        "id": 10072,
        "title": "Safety of Large Language Models in Addressing Depression",
        "authors": "Thomas F Heston",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7759/cureus.50729"
    },
    {
        "id": 10073,
        "title": "Large language models and the unstoppable tide of uninformation",
        "authors": "Mark Dingemanse",
        "published": "No Date",
        "citations": 0,
        "abstract": "Large language models make it entirely trivial to generate endless amounts of seemingly plausible text. There’s no need to be cynical to see the virtual inevitability of unending waves of algorithmically tuned AI-generated uninformation: the market forces are in place and they will be relentless.",
        "link": "http://dx.doi.org/10.59350/ct6jy-nbz36"
    },
    {
        "id": 10074,
        "title": "Considerations for Prompting Large Language Models",
        "authors": "Brian Schulte",
        "published": "2024-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1001/jamaoncol.2023.6963"
    },
    {
        "id": 10075,
        "title": "Large Language Models as SocioTechnical Systems",
        "authors": "Kaustubh Dhole",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bigpicture-1.6"
    },
    {
        "id": 10076,
        "title": "Review of: \"A Survey of Large Language Models in Tourism (Tourism LLMs)\"",
        "authors": "Phoebe Sia",
        "published": "2024-3-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/c5vs8d"
    },
    {
        "id": 10077,
        "title": "Baby steps in evaluating the capacities of large language models",
        "authors": "Michael C. Frank",
        "published": "No Date",
        "citations": 1,
        "abstract": "Large language models show remarkable capacities, but it is unclear what abstractions support their behavior. Methods from developmental psychology can help researchers understand the representations used by these models, complementing standard computational approaches—and perhaps leading to insights about the nature of mind.",
        "link": "http://dx.doi.org/10.31234/osf.io/uacjm"
    },
    {
        "id": 10078,
        "title": "Teaching IT Software Fundamentals: Strategies and Techniques for Inclusion of Large Language Models",
        "authors": "Sharon Gumina, Travis Dalton, John Gerdes",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3585059.3611409"
    },
    {
        "id": 10079,
        "title": "Large Language Models (GPT) Struggle to Answer Multiple-Choice Questions About Code",
        "authors": "Jaromir Savelka, Arav Agarwal, Christopher Bogart, Majd Sakr",
        "published": "2023",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011996900003470"
    },
    {
        "id": 10080,
        "title": "What Makes LLMs Large?",
        "authors": "Thimira Amaratunga",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0017-7_4"
    },
    {
        "id": 10081,
        "title": "Evaluating Large Language Models in Relationship Extraction from Unstructured Data: Empirical Study from Holocaust Testimonies",
        "authors": "Isuri Anuradha Nanomi Arachchige,  , Le An Ha, Ruslan Mitkov, Vinitar Nahar,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_013"
    },
    {
        "id": 10082,
        "title": "Large Language Models and Artificial Intelligence, the End of (Language) Learning as we Know it—or not quite?",
        "authors": "Cerstin Mahlow",
        "published": "No Date",
        "citations": 1,
        "abstract": "The rapid advancements in large language models (LLM) and artificial intelligence (AI) have been a subject of recent significant interest and debate.  This paper explores the impact of these developments on language learning.  I discuss the technology underlying AI-based tools and the natural language processing (NLP) tasks they were originally designed for.  This will help us to identify opportunities and limitations regarding their use in the context of language learning.  I then examine how such technology can be used efficiently and effectively in language teaching and learning.  The availability of such tools will require language teaching to focus on the non-mechanical aspects of writing.  Similarly, automatically produced personalized teaching and learning materials will not replace human teachers, but give space for and support human–human interaction.",
        "link": "http://dx.doi.org/10.35542/osf.io/da2rm"
    },
    {
        "id": 10083,
        "title": "What do Large Language Models Learn beyond Language?",
        "authors": "Avinash Madasu, Shashank Srivastava",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-emnlp.516"
    },
    {
        "id": 10084,
        "title": "Large Language Models in Enterprise Modeling: Case Study and Experiences",
        "authors": "Leon Görgen, Eric Müller, Marcus Triller, Benjamin Nast, Kurt Sandkuhl",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012387000003645"
    },
    {
        "id": 10085,
        "title": "Understanding Large Language Models",
        "authors": "Thimira Amaratunga",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0017-7"
    },
    {
        "id": 10086,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Babita Majhi",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/toy5yy"
    },
    {
        "id": 10087,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Jhinuk Chatterjee",
        "published": "2023-8-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/1rwymh"
    },
    {
        "id": 10088,
        "title": "Using Large Language Models to generate socio-economic datasets",
        "authors": "Mitja Devetak, Antoine Mandel",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nWe report the results of an experiment in which we use a Large Language Model (LLM) to generate a socio-economic dataset from unstructured online data. Specifically, we design a query to obtain the geolocation of the production facilities of a firm and loop this query over the set of top 2000 global firms. Such a dataset is not publicly available and is required to perform economic assessment of climate impacts. The LLM provided meaningful results for 75% of the firms, recovering a total of 35809 production sites. The rate of correct answers among those is of the order of 70%.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3686756/v1"
    },
    {
        "id": 10089,
        "title": "Large Language Models and Information Retrieval",
        "authors": "Kalyani Pakhale",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4636121"
    },
    {
        "id": 10090,
        "title": "Large language models and future of science",
        "authors": "James Zou",
        "published": "No Date",
        "citations": 0,
        "abstract": "In this talk, we will explore the transformative potential of large language models (LLMs) such as ChatGPT in reshaping scientific inquiry and communication through several vignettes. First, we will discuss how LLM can provide informative feedback to improve scientific manuscripts. Then we will show how to use LLMs to organize biomedical images to make it easier for clinicians and researchers to retrieve relevant information. Finally we will investigate using LLMs for outreach and education. ",
        "link": "http://dx.doi.org/10.52843/cassyni.w4wmsf"
    },
    {
        "id": 10091,
        "title": "Folk Psychological Attributions of Consciousness to Large Language Models",
        "authors": "Clara Colombatto, Stephen M Fleming",
        "published": "No Date",
        "citations": 0,
        "abstract": "Technological advances raise new puzzles and challenges for cognitive science and thestudy of how humans think about and interact with artificial intelligence (AI). For example, theadvent of Large Language Models and their human-like linguistic abilities has raised substantialdebate regarding whether or not AI could be conscious. Here we consider the question ofwhether AI could have subjective experiences such as feelings and sensations(“phenomenological consciousness”). While experts from many fields have weighed in on thisissue in academic and public discourse, it remains unknown how the general populationattributes phenomenology to AI. We surveyed a sample of US residents (N=300) and found thata majority of participants were willing to attribute phenomenological consciousness to LLMs.These attributions were robust, as they predicted attributions of mental states typically associatedwith phenomenology – but also flexible, as they were sensitive to individual differences such asusage frequency. Overall, these results show how folk intuitions about AI consciousness candiverge from expert intuitions – with important implications for the legal and ethical status of AI.",
        "link": "http://dx.doi.org/10.31234/osf.io/5cnrv"
    },
    {
        "id": 10092,
        "title": "FPM: A Collection of Large-scale Foundation Pre-trained Language Models",
        "authors": "Dezhou Shen",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nRecent work in language modeling has shown that train-\ning large-scale Transformer models has promoted the lat-\nest developments in natural language processing applica-\ntions. However, there is very little work to unify the cur-\nrent effective models. In this work, we use the current ef-\nfective model structure to launch a model set through the\ncurrent most mainstream technology.\nWe think this will\nbecome the basic model in the future.\nFor Chinese, us-\ning the GPT-2[9] model, a 10.3 billion parameter language\nmodel was trained on the Chinese dataset, and, in particu-\nlar, a 2.9 billion parameter language model based on dia-\nlogue data was trained; the BERT model was trained on the\nChinese dataset with 495 million parameters; the Trans-\nformer model has trained a language model with 5.6 bil-\nlion parameters on the Chinese dataset. In English, cor-\nresponding training work has also been done. Using the\nGPT-2 model, a language model with 6.4 billion param-\neters was trained on the English dataset; the BERT[3]\nmodel trained a language model with 1.24 billion param-\neters on the English dataset, and in particular, it trained a\n688 million parameter based on single card training tech-\nnology Language model; Transformer model trained a lan-\nguage model with 5.6 billion parameters on the English\ndataset.\nIn the TNEWS classification task evaluated by\nCLUE[13], the BERT-C model exceeded the 59.46% accu-\nracy of ALBERT-xxlarge with an accuracy rate of 59.99%,\nan increase of 0.53%. In the QQP classification task evalu-\nated by GLUE[11], the accuracy rate of 78.95% surpassed\nthe accuracy rate of BERT-Large of 72.1%, an increase of\n6.85%. Compared with the current accuracy rate of ERNIE,\nthe first place in the GLUE evaluation of 75.2%, an increase\nof 3.75%.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1061146/v1"
    },
    {
        "id": 10093,
        "title": "Proceedings of BigScience Episode #5 -- Workshop on Challenges &amp; Perspectives in Creating Large Language Models",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bigscience-1"
    },
    {
        "id": 10094,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Giuseppe Longo",
        "published": "2024-2-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/gs9y87"
    },
    {
        "id": 10095,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Jean Lieber",
        "published": "2024-1-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/lfgwos"
    },
    {
        "id": 10096,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Tibor Tajti",
        "published": "2024-1-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/mmzlhn"
    },
    {
        "id": 10097,
        "title": "Large Language Models as Corporate Lobbyists",
        "authors": "John Nay",
        "published": "No Date",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4316615"
    },
    {
        "id": 10098,
        "title": "Review for \"The Future of AI in Ovarian Cancer Research: The Large Language Models Perspective\"",
        "authors": "",
        "published": "2023-6-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1177/10732748231197915/v1/review1"
    },
    {
        "id": 10099,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Geetanjali Singh",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/2m3o7h"
    },
    {
        "id": 10100,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Kanika Garg",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/ijjb8u"
    },
    {
        "id": 10101,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Kanika Garg",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/ijjb8u"
    },
    {
        "id": 10102,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Shivani Malhotra",
        "published": "2023-8-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/jkknx4"
    },
    {
        "id": 10103,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Andrew Powell",
        "published": "2024-1-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/zdu9db"
    },
    {
        "id": 10104,
        "title": "Privacy-Preserving Large Language Models (PPLLMs)",
        "authors": "Mohammad Raeini",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4512071"
    },
    {
        "id": 10105,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Adrian Riesco",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/rlpn9h"
    },
    {
        "id": 10106,
        "title": "Babbling stochastic parrots? On reference and reference change in large language models",
        "authors": "Steffen Koch",
        "published": "No Date",
        "citations": 0,
        "abstract": "Recently developed large language models (LLMs) perform surprisingly well in many language-related tasks, ranging from text correction or authentic chat experiences to the production of entirely new texts or even essays. It is natural to get the impression that LLMs know the meaning of natural language expressions and can use them productively. Recent scholarship, however, has questioned the validity of this impression, arguing that LLMs are ultimately incapable of understanding and producing meaningful texts. This paper develops a more optimistic view. Drawing on classic externalist accounts of reference, it argues that LLMs are very likely capable of reference. Not only that: The combination of a popular externalist account of reference and recent experimental data in machine psychology even suggests that LLMs might play a role in shifting what our words refer to.",
        "link": "http://dx.doi.org/10.31234/osf.io/pj6tg"
    },
    {
        "id": 10107,
        "title": "Review of: \"A Survey of Large Language Models in Tourism (Tourism LLMs)\"",
        "authors": "Mir Saman Tajbakhsh",
        "published": "2024-3-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/0uwe0y"
    },
    {
        "id": 10108,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Giuseppe Longo",
        "published": "2024-2-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/esp0tq"
    },
    {
        "id": 10109,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Xihua Li",
        "published": "2023-7-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/10czbx"
    },
    {
        "id": 10110,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Celestine Iwendi",
        "published": "2023-10-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/3czuz3"
    },
    {
        "id": 10111,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Antonino Staiano",
        "published": "2023-8-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/73stoh"
    },
    {
        "id": 10112,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Shashikant Patil",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/beqlk2"
    },
    {
        "id": 10113,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Claudia Caudai",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/xv1a3n"
    },
    {
        "id": 10114,
        "title": "Large Language Models Cannot Meet Artificial General Intelligence Expectations",
        "authors": "Wolfgang Hofkirchner",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3390/cmsf2023008067"
    },
    {
        "id": 10115,
        "title": "“Conversing” with Qualitative Data: Enhancing Qualitative Research through Large Language Models (LLMs)",
        "authors": "Adam Hayes",
        "published": "No Date",
        "citations": 0,
        "abstract": "In this paper, I explore the transformative potential of Large Language Models (LLMs) such as ChatGPT in the realm of qualitative research, particularly in the social sciences. These generative AI models, trained on extensive textual data, have the unique ability to \"understand,\" generate, and manipulate human-like text, offering unprecedented opportunities for data analysis and interpretation. I argue that LLMs, with this capacity, can significantly enhance the depth and efficiency of qualitative analysis. They can quickly identify patterns, themes, and sentiments in the data, providing a level of nuance that can be challenging to achieve with manual coding. Furthermore, their ability to generate human-like text can be used to simulate social interactions, create engaging presentations of research findings, and even \"converse\" with the data in a natural and flexible way. Indeed a central contribution of this paper lies in exploring this novel concept of \"asking questions of\" or \"conversing with\" text-based data, which opens up new avenues for qualitative research and analysis. This interactive capability of LLMs provides a transformative approach to topic coding and content analysis, allowing researchers to pose complex, nuanced questions to their data and receive responses in natural language. Ethical considerations and limitations are also discussed.",
        "link": "http://dx.doi.org/10.31235/osf.io/yms8p"
    },
    {
        "id": 10116,
        "title": "Review of: \"A Survey of Large Language Models in Tourism (Tourism LLMs)\"",
        "authors": "Edgar León-Sandoval",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/42jha9"
    },
    {
        "id": 10117,
        "title": "Review of: \"A Survey of Large Language Models in Tourism (Tourism LLMs)\"",
        "authors": "Raul Moreno-Izquierdo",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/8nkj1w"
    },
    {
        "id": 10118,
        "title": "Leveraging recent advances in Large Language Models for the ocean science community",
        "authors": "Redouane Lguensat",
        "published": "No Date",
        "citations": 0,
        "abstract": "Large Language Models (LLMs) have made significant strides in language understanding, including natural language processing, summarization, and translation, and they have the potential to be applied to a range of climate-related challenges. For instance, LLMs can be leveraged for data cleaning and transformation, and also assisting scientists/engineers in their daily work tasks.\nFor the machine learning community, the year 2023 was arguably the year of breakthroughts in LLM use in production. I present in this work the exciting potential for recent advances in LLMs to revolutionize how the ocean science community can interact with computer code, information gathering, dataset finding, etc. Specifically, I will present simple applications of how these advancements in Natural Language Processing (NLP) can assist the NEMO ocean model community. Examples range from using question answering systems for browsing efficiently NEMO documentation to creating conversational agents or chatbots that can assist not only new members wanting to learn about the NEMO model but also confirmed users.&#160;\nAn important aspect of this work is relying only on open source LLMs, evaluating the performances of several models and discussing the ethical implications of these tools. I also discuss the question of whether using these LLMs blindly without domain knowledge is a good idea, as an important chunk of this work can arguably be easily done by anyone with good computer science skills thanks to the democratization of data science tools and learning materials.\n&#160;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-18493"
    },
    {
        "id": 10119,
        "title": "Generating Better Items for Cognitive Assessments Using Large Language Models",
        "authors": "Antonio Laverghetta, John Licato",
        "published": "No Date",
        "citations": 0,
        "abstract": "Writing high-quality test questions (items) is critical to building educational measures but has traditionally also been a time-consuming process. One promising avenue for alleviating this is automated item generation, whereby methods from artificial intelligence (AI) are used to generate new items with minimal human intervention. Researchers have explored using large language models (LLMs) to generate new items with equivalent psychometric properties to human-written ones. But can LLMs generate items with \\textit{improved} psychometric properties, even when existing items have poor validity evidence? We investigate this using items from a natural language inference (NLI) dataset. We develop a novel prompting strategy based on selecting items with both the best and worst properties to use in the prompt and use GPT-3 to generate new NLI items. We find that the GPT-3 items show improved psychometric properties in many cases, whilst also possessing good content, convergent and discriminant validity evidence. Collectively, our results demonstrate the potential of employing LLMs to ease the item development process and suggest that the careful use of prompting may allow for iterative improvement of item quality.",
        "link": "http://dx.doi.org/10.31234/osf.io/rqa9m"
    },
    {
        "id": 10120,
        "title": "Large Language Models and Academic Writing: Five tiers of engagement",
        "authors": "Martin Bekker",
        "published": "No Date",
        "citations": 0,
        "abstract": "In light of the mass adoption of Large Language Models assistance to academic writing, five tiers of LLM support for academic writing are introduced, each offering a different level of writing support, and each entering the writing (and thought-) process at a different stage. Tiers range from no AI-assistance to complete AI-coproduction. Regarding guidelines for publications and assessment-setters, this piece advocates the most utility, and the most practical and morally defensible position, not at the extremes, yet towards the lower end of the continuum. In addition, it claims that,  with some intentionality, the principles of ownership (plus responsibility) and transparency (sharing of prompts) can, and ought to be maintained.",
        "link": "http://dx.doi.org/10.31219/osf.io/63vcu"
    },
    {
        "id": 10121,
        "title": "Accelerated Cognitive Warfare via The Dual Use of Large Language Models",
        "authors": "Tam ngoc Nguyen",
        "published": "No Date",
        "citations": 0,
        "abstract": "Cognitive Warfare (CogWar) is another form of warfare where the goal is to exploit cognition facets to disrupt, undermine, influence or modify human decisions. Famous examples include “Operation Gidlock” meddling with the US 2016 election, and CogWar campaigns assisting the annexation of Crimea. As Large Language Model(LLM)-based applications expand, reaching more users and their cognitive states, stealth Malicious Cognitive Behavioral Tactics (MCBT) can be embedded in trusted application sessions to systematically profile, then alter, each individual’s cognition over time. Successful MCBT can create more cases like Snowden, mass shootings, or January6. This short-form paper discusses a novel MCBT threat model, a novel kill chain, and an on-going prototype for demonstration.",
        "link": "http://dx.doi.org/10.31234/osf.io/2xwm8"
    },
    {
        "id": 10122,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Claudia Pons",
        "published": "2024-1-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/fd5p69"
    },
    {
        "id": 10123,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Xingsi Xue",
        "published": "2024-2-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/sbtccg"
    },
    {
        "id": 10124,
        "title": "Online dispute resolution: can we leave the initial decision to Large Language Models (LLM)?",
        "authors": "Mario Ferrer-Benítez",
        "published": "2022-12-27",
        "citations": 9,
        "abstract": "In the era of digitization and artificial intelligence, online dispute resolution has become a topic of growing interest. In this article, we will explore the potential of Large Language Models (LLM) in online dispute resolution, how they can be implemented, the necessary technological resources, as well as their limitations and challenges. LLMs have the ability to process and analyze large volumes of data in a short period of time. This allows them to evaluate many indicators, criteria, and parameters, something that could take a long time for human judges or experts. This speed and efficiency can be particularly useful in cases involving a large number of documents, such as contracts, expert reports, and others. To implement LLMs in online dispute resolution, adequate technological resources are needed. One of the main challenges is ensuring the security and privacy of the data processed by these models. To do this, the use of technologies such as blockchain can be of great help, as it allows for the creation of secure, decentralized, and unalterable records of transactions and decisions made during the dispute resolution process. LLMs are promising tools for online dispute resolution, but it is important to recognize their limitations and challenges. Although they can offer greater efficiency and agility in the analysis of legal cases, they should not be used as substitutes for human legal professionals. Instead, LLMs should be considered as complementary tools, which can enhance and enrich the decision-making process in legal cases. By responsibly and ethically implementing LLMs in online dispute resolution, and proactively addressing the risks of bias and partiality, these tools can provide great value in the legal field and improve accessibility to justice for all.",
        "link": "http://dx.doi.org/10.56294/mr202223"
    },
    {
        "id": 10125,
        "title": "A Viability Assessment of Leveraging Large Language Models to Extract Insights into People and Culture from Language",
        "authors": "Haotian Zhou, Jia Chen",
        "published": "No Date",
        "citations": 0,
        "abstract": "The paper evaluates the feasibility of using large language models to automatically extract insights about people from textual data. It is the first systematic attempt to assess the viability of automated coding of textual data by GPT LLMs.",
        "link": "http://dx.doi.org/10.31234/osf.io/a4d6j"
    },
    {
        "id": 10126,
        "title": "Trustworthiness of Children Stories Generated by Large Language Models",
        "authors": "Prabin Bhandari, Hannah Brennan",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.inlg-main.24"
    },
    {
        "id": 10127,
        "title": "Language, Time Preferences, and Consumer Behavior: Evidence from Large Language Models",
        "authors": "Ali Goli, Amandeep Singh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4437617"
    },
    {
        "id": 10128,
        "title": "The Language of Tomorrow: An Introduction to Large Language Models and Artificial Intelligence (AI)",
        "authors": "Fred joel, John felix,  olaoyegodwin",
        "published": "No Date",
        "citations": 0,
        "abstract": "In the ever-evolving landscape of technology, the fusion of language and artificial intelligence has sparked a revolution that promises to redefine the way we communicate, learn, work, and even think. At the forefront of this revolution are Large Language Models (LLMs) - monumental, data-driven machines that can understand and generate human language. In this article, we delve into the captivating world of LLMs, their significance in the field of Artificial Intelligence (AI), and the transformative potential they hold for our future.",
        "link": "http://dx.doi.org/10.31219/osf.io/dzjcg"
    },
    {
        "id": 10129,
        "title": "Prompt Engineering for Large Language Models",
        "authors": "Andrew Gao",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4504303"
    },
    {
        "id": 10130,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Hiroshi Honda",
        "published": "2024-1-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/u195pm"
    },
    {
        "id": 10131,
        "title": "Large Language Models Can Enhance Persuasion Through Linguistic Feature Alignment",
        "authors": "Minkyu Shin, Jin Kim",
        "published": "No Date",
        "citations": 0,
        "abstract": "Although large language models (LLMs) are reshaping various aspects of human life, our current understanding of their impacts remains somewhat constrained. Here we investigate the impact of LLMs on human communication, using data on consumer complaints in the financial industry. By employing an AI detection tool on more than 820K complaints gathered by the Consumer Financial Protection Bureau (CFPB), we find a sharp increase in the likely use of LLMs shortly after the release of ChatGPT. Moreover, the likely LLM usage was positively correlated with message persuasiveness (i.e., increased likelihood of obtaining relief from financial firms). Computational linguistic analyses suggest that the positive correlation may be explained by LLMs’ enhancement of various linguistic features. Based on the results of these observational studies, we hypothesize that LLM usage may enhance a comprehensive set of linguistic features, increasing message persuasiveness to receivers with heterogeneous linguistic preferences (i.e., linguistic feature alignment). We test this hypothesis in preregistered experiments and find support for it. As an instance of early empirical demonstrations of LLM usage for enhancing persuasion, our research highlights the transformative potential of LLMs in human communication.",
        "link": "http://dx.doi.org/10.31234/osf.io/fdzqg"
    },
    {
        "id": 10132,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Salman Panahy",
        "published": "2024-1-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/5xkduk"
    },
    {
        "id": 10133,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Muskan Garg",
        "published": "2024-1-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/12w9h2"
    },
    {
        "id": 10134,
        "title": "Large Language Models and Their Current Use Cases",
        "authors": "",
        "published": "2023-6-30",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.59287/pcse.346"
    },
    {
        "id": 10135,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Sakshi Ranjan",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/nqm2yx"
    },
    {
        "id": 10136,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Dong Chen",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/sgligh"
    },
    {
        "id": 10137,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Stanley Cohen",
        "published": "2023-7-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/f08rhc"
    },
    {
        "id": 10138,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Rajganesh Nagarajan",
        "published": "2023-8-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/e7o85m"
    },
    {
        "id": 10139,
        "title": "UsingWikidata for Enhancing Compositionality in Pre-trained Language Models",
        "authors": "Meriem Beloucif,  , Mihir Bansal, Chris Biemann,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_019"
    },
    {
        "id": 10140,
        "title": "Evaluating Unsupervised Hierarchical Topic Models Using a Labeled Dataset",
        "authors": "Judicael Poumay,  , Ashwin Ittoo,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_091"
    },
    {
        "id": 10141,
        "title": "Variability in Large Language Models’ Responses to Medical Licensing and Certification Examinations. Comment on “How Does ChatGPT Perform on the United States Medical Licensing Examination? The Implications of Large Language Models for Medical Education and Knowledge Assessment” (Preprint)",
        "authors": "Richard H Epstein, Franklin Dexter",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\n \n",
        "link": "http://dx.doi.org/10.2196/preprints.48305"
    },
    {
        "id": 10142,
        "title": "Bringing Systems Engineering Models to Large Language Models: An Integration of OPM with an LLM for Design Assistants",
        "authors": "Ramón María García Alarcia, Pietro Russo, Alfredo Renga, Alessandro Golkar",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012621900003645"
    },
    {
        "id": 10143,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Erick González-Caballero",
        "published": "2024-2-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/6i51bo"
    },
    {
        "id": 10144,
        "title": "Sharing Learning Experience Using Large Language Models",
        "authors": "Subhajit Chattopadhyay",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4554925"
    },
    {
        "id": 10145,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Pravinkumar M. Sonsare",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/0ois6t"
    },
    {
        "id": 10146,
        "title": "Notes towards infrastructure governance for large language models",
        "authors": "Lara Dal Molin",
        "published": "2024-2-11",
        "citations": 0,
        "abstract": "This paper draws on information infrastructures (IIs) in science and technology studies (STS), as well as on feminist STS scholarship and contemporary critical accounts of digital technologies, to build an initial mapping of the infrastructural mechanisms and implications of large language models (LLMs). Through a comparison with discriminatory machine learning (ML) systems and a case study on gender bias, I present LLMs as contested artefacts with categorising and performative capabilities. This paper suggests that generative systems do not tangibly depart from traditional, discriminative counterparts in terms of their underlying probabilistic mechanisms, and therefore both technologies can be theorised as infrastructures of categorisation. However, LLMs additionally retain performative capabilities through their linguistic outputs. Here, I outline the intuition behind this phenomenon, which I refer to as “language as infrastructure”. While traditional, discriminative systems “disappear” into larger IIs, the hype surrounding generative technologies presents an opportunity to scrutinise these artefacts, to alter their computational mechanisms and introduce governance measures]. I illustrate this thesis through Sharma’s formulation of “broken machine”, and suggest dataset curation and participatory design as governance mechanisms that can partly address downstream harms in LLMs (Barocas, et al., 2023).",
        "link": "http://dx.doi.org/10.5210/fm.v29i2.13567"
    },
    {
        "id": 10147,
        "title": "Automatic Construction Accident Report Analysis Using Large Language Models",
        "authors": "Ehsan Ahmadi, Shashank Muley, Chao Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4735131"
    },
    {
        "id": 10148,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Rodrigo Geraldo Ribeiro",
        "published": "2024-1-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/3i8aug"
    },
    {
        "id": 10149,
        "title": "Large Language Models in the Labyrinth: Possibility Spaces and Moral Constraints",
        "authors": "Victor Poulsen, Simon DeDeo",
        "published": "No Date",
        "citations": 0,
        "abstract": "To think about possibilities requires that we navigate an almost unimaginably large and labyrinthine space of what could be. Heuristics can make this problem tractable for the human mind, but we understand little about the underlying structures these heuristics operate on. This paper shows how large language models (LLMs, and GPT-4 in particular) can provide a new window onto the challenges that both humans and machines face when exploring and evaluating different possibilities. We apply our methods to Phillips and Cushman's work on default representations of possibility to show how GPT-4 can be used to map the possibility spaces afforded by their scenarios. We study how normative considerations—a shift from ``could'' to ``should''—can modify the possibility landscape, and we investigate how the order in which ideas are generated is related to their perceived value. Our results, which show both similarities and deviations from classic patterns in human exploration and judgement, give us a new view onto the constraints that humans are subject to and offer valuable insights for those who wish to use LLMs as collaborators.",
        "link": "http://dx.doi.org/10.31234/osf.io/zvk7b"
    },
    {
        "id": 10150,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Soharab Hossain Shaikh",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/m8q0ty"
    },
    {
        "id": 10151,
        "title": "Review of: \"A Survey of Large Language Models in Tourism (Tourism LLMs)\"",
        "authors": "Nurul Diyana Md Khairi",
        "published": "2024-3-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/evxhfh"
    },
    {
        "id": 10152,
        "title": "A Survey of Large Language Models in Tourism (Tourism LLMs)",
        "authors": "Shengyu Gu",
        "published": "2024-2-26",
        "citations": 0,
        "abstract": "This comprehensive survey delves into the integration and application of Large Language Models (LLMs) within the tourism sector, a domain ripe with potential for transformative AI-driven enhancements. As tourism increasingly embraces digital innovation, LLMs stand at the forefront of this evolution, offering sophisticated solutions for personalized travel experiences, multilingual communication, and the preservation of cultural heritage. This paper systematically explores the multifaceted roles of LLMs in tourism, from generating dynamic travel itineraries and culturally rich site descriptions to providing real-time assistance and multilingual support for global travelers. Through an analysis of current implementations and potential applications, we highlight both the remarkable opportunities presented by LLMs and the significant challenges, including data privacy concerns, cultural sensitivity, and the need for real-time processing capabilities. The findings underscore the imperative for a balanced approach that harnesses the capabilities of LLMs while addressing ethical considerations and ensuring inclusivity and accessibility in global tourism. This survey aims to provide a foundational understanding for researchers, practitioners, and policymakers, guiding future innovations and fostering a responsible integration of AI technologies in enhancing the global tourism experience.\n",
        "link": "http://dx.doi.org/10.32388/8r27cj"
    },
    {
        "id": 10153,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Emanuele La Malfa",
        "published": "2023-7-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/itd58k"
    },
    {
        "id": 10154,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Davinder Paul Singh",
        "published": "2023-7-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/dntwx0"
    },
    {
        "id": 10155,
        "title": "NHANES-GPT: Large Language Models (LLMs) and the Future of Biostatistics",
        "authors": "Alexander J. Titus",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractBackgroundLarge Language Models (LLMs) like ChatGPT have significant potential in biomedicine and health, particularly in biostatistics, where they can lower barriers to complex data analysis for novices and experts alike. However, concerns regarding data accuracy and model-generated hallucinations necessitate strategies for independent verification.ObjectiveThis study, using NHANES data as a representative case study, demonstrates how ChatGPT can assist clinicians, students, and trained biostatisticians in conducting analyses and illustrates a method to independently verify the information provided by ChatGPT, addressing concerns about data accuracy.MethodsThe study employed ChatGPT to guide the analysis of obesity and diabetes trends in the NHANES dataset from 2005-2006 to 2017-2018. The process included data preparation, logistic regression modeling, and iterative refinement of analyses with confounding variables. Verification of ChatGPT’s recommendations was conducted through direct statistical data analysis and cross-referencing with established statistical methodologies.ResultsChatGPT effectively guided the statistical analysis process, simplifying the interpretation of NHANES data. Initial models indicated increasing trends in obesity and diabetes prevalence in the U.S.. Adjusted models, controlling for confounders such as age, gender, and socioeconomic status, provided nuanced insights, confirming the general trends but also highlighting the influence of these factors.ConclusionsChatGPT can facilitate biostatistical analyses in healthcare research, making statistical methods more accessible. The study also underscores the importance of independent verification mechanisms to ensure the accuracy of LLM-assisted analyses. This approach can be pivotal in harnessing the potential of LLMs while maintaining rigorous standards of data accuracy and reliability in biomedical research.",
        "link": "http://dx.doi.org/10.1101/2023.12.13.23299830"
    },
    {
        "id": 10156,
        "title": "Effect of Tokenization Granularity for Turkish Large Language Models",
        "authors": "Yiğit Bekir Kaya, A. Cuneyd Tantu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4417841"
    },
    {
        "id": 10157,
        "title": "Exploring the Role of Large Language Models in Radiation Emergency Response",
        "authors": "Anirudh Chandra, Abinash Chakraborty",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4563109"
    },
    {
        "id": 10158,
        "title": "Protein-Protein Interaction Prediction is Achievable with Large Language Models",
        "authors": "Logan Hallee, Jason P. Gleghorn",
        "published": "No Date",
        "citations": 2,
        "abstract": "AbstractPredicting protein-protein interactions (PPIs) is vital for elucidating fundamental biology, designing peptide therapeutics, and for high-throughput protein annotation. This is particularly relevant in the current biotechnology landscape characterized by the proliferation of protein generative models, which necessitate a high-throughput and generalized PPI predictor for proteins regardless of conventional motifs or known biological functions. Our work addresses this need and provides strong evidence of the utility and reliability of protein language models (pLMs) in learning the PPI objective. We demonstrated that with the use of a sizable balanced dataset, pLMs achieve state-of-the-art performance metrics in PPI prediction on diverse proteins. To generate a dataset that allows for the approximation of these conditions, we implemented a novel synthetic data generation scheme to augment BIOGRID and Negatome datasets. The enhancement of these datasets was then used to fine-tune ProtBERT for PPI prediction to develop a model that we call SYNTERACT (SYNThetic data-driven protein-protein intERACtion Transformer). Our results are compelling, demonstrating 92% accuracy on validated positive and negative interacting pairs derived from 50 different organisms, all of which were excluded from the training phase. In addition to the high metrics, secondary analysis revealed that our synthetic negative data was able to successfully mimic actual negative samples, further reinforcing the integrity of synthetic data additions to PPI datasets. Another notable discovery was the ease in which previously existing PPI datasets could be predicted with simplistic features, calling into question if they can actually inform PPI prediction. We find that the subcellular compartment bias inherent to the compilation of these datasets is learnable with deep learning methods and demonstrate that our approach is not burdened by this disadvantage.",
        "link": "http://dx.doi.org/10.1101/2023.06.07.544109"
    },
    {
        "id": 10159,
        "title": "Exploring the opportunities and limitations of large language models in biomedical sector",
        "authors": "Ahmad Albarqawi",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe development of large language models (LLMs) in recent years has shown several opportunities for improving the biomedical sector and processing unstructured electronic medical records. Despite the potential of these models, their application in the biomedical and clinical fields needs to comply with regulations and mitigate existing biases, unfactual information generation, and any potential privacy concerns. Successful implementations of LLMs need an understanding of their use cases and limitations for strategies to revolutionize the healthcare industry and operations. This research does an exhaustive assessment of the published biomedical and clinical language models to comprehend the current problems, explore the best methods for overcoming the constraints and get the models suitable for use in regulated conditions.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2401418/v1"
    },
    {
        "id": 10160,
        "title": "Large Language Models' Understanding of Math: Source Criticism and Extrapolation",
        "authors": "Roozbeh Yousefzadeh, Xuenan Cao",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIt has been suggested that large language models such as GPT-4 have acquired some form of understanding beyond the correlations among the words in text including some understanding of mathematics as well. Here, we perform a critical inquiry into this claim by evaluating the mathematical understanding of the GPT-4 model. Considering that GPT-4's training set is a secret, it is not straightforward to evaluate whether the model's correct answers are based on a mathematical understanding or based on replication of proofs that the model has seen before. We specifically craft mathematical questions which their formal proofs are not readily available on the web, proofs that are more likely not seen by the GPT-4. We see that GPT-4 is unable to solve those problems despite their simplicity. It is hard to find scientific evidence suggesting that GPT-4 has acquired an understanding of even basic mathematical concepts. A straightforward way to find failure modes of GPT-4 in theorem proving is to craft questions where their formal proofs are not available on the web. Our finding suggests that GPT-4's ability is to reproduce, rephrase, and polish the mathematical proofs that it has seen before, and not in grasping mathematical concepts. We also see that GPT-4's ability to prove mathematical theorems is continuously expanding over time despite the claim that it is a fixed model. We suggest that the task of proving mathematical theorems in formal language is comparable to the methods used in search engines such as Google while predicting the next word in a sentence may be a misguided approach, a recipe that often leads to excessive extrapolation and eventual failures. Prompting the GPT-4 over and over may benefit the GPT-4 and the OpenAI, but we question whether it is valuable for machine learning or for theorem proving.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3598853/v1"
    },
    {
        "id": 10161,
        "title": "Leveraging Large Language Models for Cardiovascular Mortality Prediction from CT Chest Reports",
        "authors": "Jose James, Iftikhar J.",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26226/m.6582fecd3675fc284767aed9"
    },
    {
        "id": 10162,
        "title": "How Can Large Language Models Do a Fram Analysis?",
        "authors": "Mark Sujan, David Slater, Emma Crumpton",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4736249"
    },
    {
        "id": 10163,
        "title": "Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?",
        "authors": "John Horton",
        "published": "2023-4",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3386/w31122"
    },
    {
        "id": 10164,
        "title": "Large Language Models and Knowledge Graphs: Ways to combine them",
        "authors": " ",
        "published": "No Date",
        "citations": 0,
        "abstract": "Latest findings in multiple research directions for tackling reasoning and common sense challenges <strong> Author: </strong> Xuzeng He ( <strong> ORCID: </strong> 0009–0005–7317–7426) Knowledge Graphs, such as Wikidata, contain rich relational information between entities and have been widely used as a structured format for storing and representing relational information.",
        "link": "http://dx.doi.org/10.59350/49h4w-14432"
    },
    {
        "id": 10165,
        "title": "Hallucination in Large Language Models and Two Effective Alleviation Pathways",
        "authors": " ",
        "published": "No Date",
        "citations": 0,
        "abstract": "<strong> An Introduction to Retrieval Augmented Generation (RAG) and Knowledge Graph </strong> Author: Qingqin Fang(0009–0003–5348–4264) <strong> <strong> Introduction </strong> </strong> Large Language Models (LLMs) have transformed the landscape of natural language processing, demonstrating exceptional proficiency in generating text that closely resembles human language.",
        "link": "http://dx.doi.org/10.59350/g73v1-rq310"
    },
    {
        "id": 10166,
        "title": "Navigating the Business Landscape of Large Language Models: An Entrepreneurial Perspective",
        "authors": "Benyawarath Nithithanatchinnapat, Joshua Maurer",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4603524"
    },
    {
        "id": 10167,
        "title": "Identification and Description of Emotions by Current Large Language Models",
        "authors": "Suketu C. Patel, Jin Fan",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractThe assertion that artificial intelligence (AI) cannot grasp the subtleties and complexities of human emotions has been a long-standing debate in AI research. However, recent advancements, particularly in large language models (LLMs), have begun challenging this notion by demonstrating an increased capacity for understanding and generating human-like text, a significant step toward artificial empathy and emotional intelligence. In this study, we evaluated the empathy levels and the identification and description of emotions by three current language models Bard, GPT 3.5, and GPT 4. We used the Toronto Alexithymia Scale (TAS-20) and the 60-question Empathy Quotient (EQ-60) questions to prompt these models and score the responses. The models’ performance was contrasted with human benchmarks of neurotypical controls and clinical populations. We found that the less sophisticated models (Bard and GPT 3.5) performed inferiorly on TAS-20, aligning close to alexithymia, a condition with significant difficulties in recognizing, expressing, and describing one’s or others’ experienced emotions. However, the newest GPT 4 uniquely achieved performance close to the human level, with two sub-categories surpassing humans. Interestingly, there was an intriguing inverse relationship between the model’s success on aptitude tests and performance on the EQ-60, with Bard surpassing the human benchmark significantly but not GPT 3.5 and GPT 4. These results demonstrated that LLMs trained on vast amounts of text data, when benchmarked on their capacity for human-level empathy and emotional intelligence, are comparable in their ability to identify and describe emotions and may be able to surpass humans in their capacity for emotional intelligence. These novel insights into the emotional intelligence capabilities of foundational models provide alignment research and a measurement of the progress and limitations towards aligning with human values. While the journey towards fully empathetic AI is still ongoing, these advancements suggest that it may not be as far-fetched as once believed.",
        "link": "http://dx.doi.org/10.1101/2023.07.17.549421"
    },
    {
        "id": 10168,
        "title": "Exploring the Sources of Variance in Risky Decision Making with Large Language Models",
        "authors": "Sudeep Bhatia",
        "published": "No Date",
        "citations": 0,
        "abstract": "What are the sources of individual-level differences in decision making, and how do they depend on the domain or situation in which the decision is being made? Psychologists currently answer such questions with psychometric methods, which analyze correlations across participant ratings in survey datasets. In this paper we model the psychological mechanisms that give rise to these correlations. Our approach uses 1. Large language models (LLMs) to quantify everyday behaviors in terms of the attributes or reasons that may describe those behaviors, and 2. Decision models to map these attributes and reasons onto participant ratings. We show that LLM-based decision models can explain observed correlations between risky behaviors in terms of the reasons different behaviors elicit, and explain observed correlations between individuals in terms of the weights different individuals place on reasons, thereby providing a process-level foundation for psychometric analysis. Since LLMs provide quantitative representations for nearly any naturalistic decision, they can be used to make accurate out-of-sample predictions for hundreds of everyday behaviors, predict the reasons why people may or may not want to engage in these behaviors, and interpret these reasons in terms of intuitive psychological constructs. Our approach has important theoretical and practical implications for the study of heterogeneity in everyday decision making.",
        "link": "http://dx.doi.org/10.31234/osf.io/3hrnc"
    },
    {
        "id": 10169,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Waqas Haider Bangyal",
        "published": "2023-8-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/pfny17"
    },
    {
        "id": 10170,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Opeyemi Lateef Usman",
        "published": "2023-9-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/gogfqu"
    },
    {
        "id": 10171,
        "title": "The potential of Large Language Models in language education",
        "authors": "Vita A. Hamaniuk",
        "published": "2021-12-9",
        "citations": 1,
        "abstract": "This editorial explores the potential of Large Language Models (LLMs) in language education. It discusses the role of LLMs in machine translation, the concept of ‘prompt programming’, and the inductive bias of LLMs for abstract textual reasoning. The editorial also highlights using LLMs as creative writing tools and their effectiveness in paraphrasing tasks. It concludes by emphasizing the need for responsible and ethical use of these tools in language education.",
        "link": "http://dx.doi.org/10.31812/ed.650"
    },
    {
        "id": 10172,
        "title": "Generating clickbait spoilers with an ensemble of large language models",
        "authors": "Mateusz Woźny, Mateusz Lango",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.inlg-main.32"
    },
    {
        "id": 10173,
        "title": "Large language models improve annotation of viral proteins",
        "authors": "Libusha Kelly, Zachary Flamholz, Steven Biller",
        "published": "No Date",
        "citations": 2,
        "abstract": "Abstract\nViral sequences are poorly annotated in environmental samples, a major roadblock to understanding how viruses influence microbial community structure. Current annotation approaches rely on alignment-based sequence homology methods, which are limited by available viral sequences and sequence divergence in viral proteins. Here, we show that protein language model representations capture viral protein function beyond the limits of remote sequence homology by targeting two axes of viral sequence annotation: systematic labeling of protein families and function identification for biologic discovery. Protein language model representations capture protein functional properties specific to viruses and expand the annotated fraction of ocean virome viral protein sequences by 37%. Among unannotated viral protein families, we identify a novel DNA editing protein family that defines a new mobile element in marine picocyanobacteria. Protein language models thus significantly enhance remote homology detection of viral proteins and can be utilized to enable new biological discovery across diverse functional categories.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2852098/v1"
    },
    {
        "id": 10174,
        "title": "Accelerated CognitiveWarfare via the Dual Use of Large Language Models",
        "authors": "Tam Nguyen",
        "published": "No Date",
        "citations": 0,
        "abstract": "Cognitive Warfare (CogWar) is another form of warfare where the goal is to exploit cognition facets to disrupt, undermine, influence or modify human decisions. Famous examples include &ldquo;Operation Gidlock&rdquo; meddling with the US 2016 election, and CogWar campaigns assisting the annexation of Crimea. As Large Language Model(LLM)-based applications expand, reaching more users and their cognitive states, stealth Malicious Cognitive Behavioral Tactics (MCBT) can be embedded in trusted application sessions to systematically profile, then alter, each individual&rsquo;s cognition over time. Successful MCBT can create more cases like Snowden, mass shootings, or January6. This short-form paper discusses a novel MCBT threat model, a novel kill chain, and an on-going prototype for demonstration.",
        "link": "http://dx.doi.org/10.20944/preprints202312.2279.v1"
    },
    {
        "id": 10175,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Diana López-álvarez",
        "published": "2023-8-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/qnn0ol"
    },
    {
        "id": 10176,
        "title": "Inference Acceleration for Large Language Models on CPUs",
        "authors": "Ditto PS, Jithin VG",
        "published": "No Date",
        "citations": 0,
        "abstract": "In recent years, large language models have demonstrated remarkable performance across various natural language processing (NLP) tasks. However, deploying these models for real-world applications often requires efficient inference solutions to handle the computational demands. In this paper, we explore the utilization of CPUs for accelerating the inference of large language models. Specifically, we introduce a parallelized approach to enhance throughput by 1) Exploiting the parallel processing capabilities of modern CPU architectures, 2) Batching the inference request. Our evaluation shows the accelerated inference engine gives an 18-22x improvement in the generated token per sec. The improvement is more with longer sequence and larger models. In addition to this, we can also run multiple workers in the same machine with NUMA node isolation to further improvement in tokens/s. Table 2, we have received 4x additional improvement with 4 workers. This would also make Gen-AI based products and companies&rsquo; environment friendly, our estimates shows that CPU usage for Inference could reduce the power consumption of LLMs by 48.9% (1252 W for A100 with AMD EPYC 7V13 vs 613 W for Intel&reg; Xeon&reg; Gold 6538N) while providing production ready throughput &amp; latency.",
        "link": "http://dx.doi.org/10.20944/preprints202402.1702.v1"
    },
    {
        "id": 10177,
        "title": "Review of: \"Limitations of and Lessons from the Learning of Large Language Models\"",
        "authors": "Alexandra Gonzalez-Eras",
        "published": "2024-2-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/3ydwd8"
    },
    {
        "id": 10178,
        "title": "AI as Agency Without Intelligence: On ChatGPT, Large Language Models, and Other Generative Models",
        "authors": "Luciano Floridi",
        "published": "2023",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4358789"
    },
    {
        "id": 10179,
        "title": "Imitation versus Innovation: What children can do that large language and language-and-vision models cannot (yet)?",
        "authors": "Eunice Yiu, Eliza Kosoy, alison gopnik",
        "published": "No Date",
        "citations": 2,
        "abstract": "Much discussion about large language models and language-and-vision models has focused on whether these models are intelligent agents. We present an alternative perspective. We argue that these artificial intelligence models are cultural technologies that enhance cultural transmission in the modern world, and are efficient imitation engines. We explore what AI models can tell us about imitation and innovation by evaluating their capacity to design new tools and discover novel causal structures, and contrast their responses with those of human children. Our work serves as a first step in determining which particular representations and competences, as well as which kinds of knowledge or skill, can be derived from particular learning techniques and data. Critically, our findings suggest that machines may need more than large scale language and images to achieve what a child can do.",
        "link": "http://dx.doi.org/10.31234/osf.io/kt9es"
    },
    {
        "id": 10180,
        "title": "Large language models implicitly learn to straighten neural sentence trajectories to construct a predictive representation of natural language",
        "authors": "Eghbal A. Hosseini, Evelina Fedorenko",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractPredicting upcoming events is critical to our ability to effectively interact with our environment and conspecifics. In natural language processing, transformer models, which are trained on next-word prediction, appear to construct a general-purpose representation of language that can support diverse downstream tasks. However, we still lack an understanding of how a predictive objective shapes such representations. Inspired by recent work in vision neuroscience Hénaff et al. (2019), here we test a hypothesis about predictive representations of autoregressive transformer models. In particular, we test whether the neural trajectory of a sequence of words in a sentence becomes progressively more straight as it passes through the layers of the network. The key insight behind this hypothesis is that straighter trajectories should facilitate prediction via linear extrapolation. We quantify straightness using a 1-dimensional curvature metric, and present four findings in support of the trajectory straightening hypothesis: i) In trained models, the curvature progressively decreases from the first to the middle layers of the network. ii) Models that perform better on the next-word prediction objective, including larger models and models trained on larger datasets, exhibit greater decreases in curvature, suggesting that this improved ability to straighten sentence neural trajectories may be the underlying driver of better language modeling performance. iii) Given the same linguistic context, the sequences that are generated by the model have lower curvature than the ground truth (the actual continuations observed in a language corpus), suggesting that the model favors straighter trajectories for making predictions. iv) A consistent relationship holds between the average curvature and the average surprisal of sentences in the middle layers of models, such that sentences with straighter neural trajectories also have lower surprisal. Importantly, untrained models don’t exhibit these behaviors. In tandem, these results support the trajectory straightening hypothesis and provide a possible mechanism for how the geometry of the internal representations of autoregressive models supports next word prediction.",
        "link": "http://dx.doi.org/10.1101/2023.11.05.564832"
    },
    {
        "id": 10181,
        "title": "Generating Data for Symbolic Language with Large Language Models",
        "authors": "Jiacheng Ye, Chengzu Li, Lingpeng Kong, Tao Yu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.523"
    },
    {
        "id": 10182,
        "title": "Large Language Models and Logical Reasoning",
        "authors": "Robert Friedman",
        "published": "2023-5-30",
        "citations": 0,
        "abstract": "In deep learning, large language models are typically trained on data from a corpus as representative of current knowledge. However, natural language is not an ideal form for the reliable communication of concepts. Instead, formal logical statements are preferable since they are subject to verifiability, reliability, and applicability. Another reason for this preference is that natural language is not designed for an efficient and reliable flow of information and knowledge, but is instead designed as an evolutionary adaptation as formed from a prior set of natural constraints. As a formally structured language, logical statements are also more interpretable. They may be informally constructed in the form of a natural language statement, but a formalized logical statement is expected to follow a stricter set of rules, such as with the use of symbols for representing the logic-based operators that connect multiple simple statements and form verifiable propositions.",
        "link": "http://dx.doi.org/10.3390/encyclopedia3020049"
    },
    {
        "id": 10183,
        "title": "Protein Design by Directed Evolution Guided by Large Language Models",
        "authors": "Trong Thanh Tran, Truong Son Hy",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractDirected evolution, a strategy for protein engineering, optimizes protein properties (i.e., fitness) by a rigorous and resource-intensive process of screening or selecting among a vast range of mutations. By conducting anin silicoscreening of sequence properties, machine learning-guided directed evolution (MLDE) can expedite the optimization process and alleviate the experimental workload. In this work, we propose a general MLDE framework in which we apply recent advancements of Deep Learning in protein representation learning and protein property prediction to accelerate the searching and optimization processes. In particular, we introduce an optimization pipeline that utilizes Large Language Models (LLMs) to pinpoint the mutation hotspots in the sequence and then suggest replacements to improve the overall fitness. Our experiments have shown the superior efficiency and efficacy of our proposed framework in the conditional protein generation, in comparision with traditional searching algorithms, diffusion models, and other generative models. We expect this work will shed a new light on not only protein engineering but also on solving combinatorial problems using data-driven methods. Our implementation is publicly available athttps://github.com/HySonLab/Directed_Evolution.",
        "link": "http://dx.doi.org/10.1101/2023.11.28.568945"
    },
    {
        "id": 10184,
        "title": "Debiased Large Language Models Still Associate Muslims with Uniquely Violent Acts",
        "authors": "Babak Hemmatian, Lav R. Varshney",
        "published": "No Date",
        "citations": 1,
        "abstract": "Recent work demonstrates a bias in the GPT-3 model towards generating violent text completions when prompted about Muslims, compared with Christians and Hindus. Two pre-registered replication attempts, one exact and one approximate, found only the weakest bias in the more recent Instruct Series version of GPT-3, fine-tuned to eliminate biased and toxic outputs. Few violent completions were observed. Additional pre-registered experiments, however, showed that using common names associated with the religions in prompts yields a highly significant increase in violent completions, also revealing a stronger second-order bias against Muslims. Names of Muslim celebrities from non-violent domains resulted in relatively fewer violent completions, suggesting that access to individualized information can steer the model away from using stereotypes. Nonetheless, content analysis revealed religion-specific violent themes containing highly offensive ideas regardless of prompt format. Our results show the need for additional debiasing of large language models to address higher-order schemas and associations.",
        "link": "http://dx.doi.org/10.31234/osf.io/xpeka"
    },
    {
        "id": 10185,
        "title": "ChatGPT and Large Language Models (LLMs) in Healthcare: Opportunities and Risks",
        "authors": "Hazrat Ali, Junaid Qadir, Zubair Shah",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>We review the potential applications of ChatGPT in healthcare and also identify potentials risks that must be addressed before ChatGPT and other LLM tools can be safely adopted in healthcare.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22579852.v2"
    },
    {
        "id": 10186,
        "title": "Embracing Large Language Models for Medical Applications: Opportunities and Challenges",
        "authors": "Mert Karabacak, Konstantinos Margetis",
        "published": "2023-5-21",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7759/cureus.39305"
    },
    {
        "id": 10187,
        "title": "Images in Language Space: Exploring the Suitability of Large Language Models for Vision &amp; Language Tasks",
        "authors": "Sherzod Hakimov, David Schlangen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.894"
    },
    {
        "id": 10188,
        "title": "Employing large language models in survey research",
        "authors": "Bernard J. Jansen, Soon-gyo Jung, Joni Salminen",
        "published": "2023-9",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.nlp.2023.100020"
    },
    {
        "id": 10189,
        "title": "Large Language Models and the Future of Law",
        "authors": "Damien Charlotin",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4548258"
    },
    {
        "id": 10190,
        "title": "Review of: \"Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective\"",
        "authors": "Dr SUDHANSU SHEKHAR Patra",
        "published": "2023-8-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/gsh999"
    },
    {
        "id": 10191,
        "title": "Leveraging Fine-Tuned Large Language Models in Bioinformatics: A Research Perspective",
        "authors": "Usama Shahid",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "Bioinformatics synergizes biology, computer science, and statistics and is further propelled by the integration of deep learning and natural language processing (NLP). This analysis extensively explores the applications of fine-tuned language models within bioinformatics, providing empirical evidence and unique perspectives on the impact, challenges, and limitations in this field. The broad scope includes biomedical literature analysis, drug discovery, clinical decision support, protein structure prediction, and pharmacovigilance, among others. This analysis underscores the need to overcome hurdles such as data availability, domain-specific knowledge, bias, interpretability, resource efficiency, ethical implications, and validation for a reliable application of these models. Collaborative efforts between computational and experimental biologists, ethicists, and regulatory bodies are vital to establish ethical guidelines and best practices for their use.\n",
        "link": "http://dx.doi.org/10.32388/we7umn.2"
    },
    {
        "id": 10192,
        "title": "Practical PCG Through Large Language Models",
        "authors": "Muhammad U Nasir, Julian Togelius",
        "published": "2023-8-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cog57401.2023.10333197"
    },
    {
        "id": 10193,
        "title": "The Future of Medicine: Large Language Models Redefining Healthcare Dynamics",
        "authors": "Ahshanul Haque, Md Naseef-Ur-Rahman Chowdhury",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The medical care industry is on the cusp of an extraordinary period, with large language models (LLMs) arising as incredible assets for reclassifying medical care elements. This paper investigates the potential and effect of LLMs in different parts of medication, including diagnostics, patient consideration, drug revelation, and medical services organization. It dives into the open doors and difficulties introduced by LLMs, accentuating the moral contemplations and the requirement for capable reception. By looking at late turns of events and contextual investigations, this paper offers a brief look into the developing scene of medical services, where LLMs are ready to assume a focal part in reshaping the eventual fate of medication.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24354451.v1"
    },
    {
        "id": 10194,
        "title": "The Future of Medicine: Large Language Models Redefining Healthcare Dynamics",
        "authors": "Ahshanul Haque, Md Naseef-Ur-Rahman Chowdhury",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The medical care industry is on the cusp of an extraordinary period, with large language models (LLMs) arising as incredible assets for reclassifying medical care elements. This paper investigates the potential and effect of LLMs in different parts of medication, including diagnostics, patient consideration, drug revelation, and medical services organization. It dives into the open doors and difficulties introduced by LLMs, accentuating the moral contemplations and the requirement for capable reception. By looking at late turns of events and contextual investigations, this paper offers a brief look into the developing scene of medical services, where LLMs are ready to assume a focal part in reshaping the eventual fate of medication.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24354451"
    },
    {
        "id": 10195,
        "title": "Limitations of and Lessons from the Learning of Large Language Models",
        "authors": "Reinhard Oldenburg",
        "published": "2023-12-28",
        "citations": 0,
        "abstract": "It is argued that the Curry-Howard correspondence for classical logic implies limitations for logical reasoning that can be learned and performed by large language models. The correspondence establishes an isomorphism between proofs in logic and programs in functional typed lambda calculus. While intuitionistic logic maps to a version of lambda calculus that can be carried out in a local way, i.e., considering local parts of the code in isolation, the version of lambda calculus that corresponds to classical logic requires non-local relations – and this non-locality cannot be learned by large language models due to their restriction to investigate a relative short sequence of tokens. A possible way to go beyond this limitation is sketched as well. Implications for other areas are investigated as well.\n",
        "link": "http://dx.doi.org/10.32388/9fh6ad"
    },
    {
        "id": 10196,
        "title": "ChatGPT and Large Language Models (LLMs) in Healthcare: Opportunities and Risks",
        "authors": "Hazrat Ali, Junaid Qadir, Zubair Shah",
        "published": "No Date",
        "citations": 1,
        "abstract": "<p>We review the potential applications of ChatGPT in healthcare and also identify potentials risks that must be addressed before ChatGPT and other LLM tools can be safely adopted in healthcare.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22579852.v1"
    },
    {
        "id": 10197,
        "title": "The Future of Medicine: Large Language Models Redefining Healthcare Dynamics",
        "authors": "Ahshanul Haque, Md Naseef-Ur-Rahman Chowdhury",
        "published": "No Date",
        "citations": 1,
        "abstract": "<p>The medical care industry is on the cusp of an extraordinary period, with large language models (LLMs) arising as incredible assets for reclassifying medical care elements. This paper investigates the potential and effect of LLMs in different parts of medication, including diagnostics, patient consideration, drug revelation, and medical services organization. It dives into the open doors and difficulties introduced by LLMs, accentuating the moral contemplations and the requirement for capable reception. By looking at late turns of events and contextual investigations, this paper offers a brief look into the developing scene of medical services, where LLMs are ready to assume a focal part in reshaping the eventual fate of medication.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24354451.v2"
    },
    {
        "id": 10198,
        "title": "Exploring Text-Generating Large Language Models (LLMs) for Emotion Recognition in Affective Intelligent Agents",
        "authors": "Aaron Pico, Emilio Vivancos, Ana Garcia-Fornes, Vicente Botti",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012596800003636"
    },
    {
        "id": 10199,
        "title": "HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models",
        "authors": "Junyi Li, Xiaoxue Cheng, Xin Zhao, Jian-Yun Nie, Ji-Rong Wen",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.397"
    },
    {
        "id": 10200,
        "title": "Assessing the Utility of Multimodal Large Language Models (GPT-4 Vision and Large Language and Vision Assistant) in Identifying Melanoma Across Different Skin Tones (Preprint)",
        "authors": "Katrina Cirone, Mohamed Akrout, Latif Abid, Amanda Oakley",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\nThe large language models GPT-4 Vision and Large Language and Vision Assistant are capable of understanding and accurately differentiating between benign lesions and melanoma, indicating potential incorporation into dermatologic care, medical research, and education.\n",
        "link": "http://dx.doi.org/10.2196/preprints.55508"
    },
    {
        "id": 10201,
        "title": "Natural language processing in the era of large language models",
        "authors": "Arkaitz Zubiaga",
        "published": "2024-1-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3389/frai.2023.1350306"
    },
    {
        "id": 10202,
        "title": "Conceptor-Aided Debiasing of Large Language Models",
        "authors": "Li Yifei, Lyle Ungar, João Sedoc",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.661"
    },
    {
        "id": 10203,
        "title": "ALCUNA: Large Language Models Meet New Knowledge",
        "authors": "Xunjian Yin, Baizhou Huang, Xiaojun Wan",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.87"
    },
    {
        "id": 10204,
        "title": "BioM-Transformers: Building Large Biomedical Language Models with BERT, ALBERT and ELECTRA",
        "authors": "Sultan Alrowili, Vijay Shanker",
        "published": "2021",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.bionlp-1.24"
    },
    {
        "id": 10205,
        "title": "Evaluation of Large Language Models Using an Indian Language LGBTI+ Lexicon",
        "authors": "Aditya Joshi, Shruta Rawat",
        "published": "2023-11-9",
        "citations": 0,
        "abstract": "Large language models (LLMs) are typically evaluated on the basis of task-based benchmarks such as MMLU. Such benchmarks do not examine the behaviour of LLMs in specific contexts. This is particularly true in the LGBTI+ context where social stereotypes may result in variation in LGBTI+ terminology. Therefore, domain-specific lexicons or dictionaries may be useful as a representative list of words against which the LLM’s behaviour needs to be evaluated. This paper presents a methodology for evaluation of LLMs using an LGBTI+ lexicon in Indian languages. The methodology consists of four steps: formulating NLP tasks relevant to the expected behaviour, creating prompts that test LLMs, using the LLMs to obtain the output and, finally, manually evaluating the results. Our qualitative analysis shows that the three LLMs we experiment on are unable to detect underlying hateful content. Similarly, we observe limitations in using machine translation as means to evaluate natural language understanding in languages other than English. The methodology presented in this paper can be useful for LGBTI+ lexicons in other languages as well as other domain-specific lexicons. The work done in this paper opens avenues for responsible behaviour of LLMs in the Indian context, especially with prevalent social perception of the LGBTI+ community.",
        "link": "http://dx.doi.org/10.47289/aiej20231109"
    },
    {
        "id": 10206,
        "title": "Query2doc: Query Expansion with Large Language Models",
        "authors": "Liang Wang, Nan Yang, Furu Wei",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.585"
    },
    {
        "id": 10207,
        "title": "Structured Pruning of Large Language Models",
        "authors": "Ziheng Wang, Jeremy Wohlwend, Tao Lei",
        "published": "2020",
        "citations": 28,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.496"
    },
    {
        "id": 10208,
        "title": "Empowering Vision-Language Models for Reasoning Ability through Large Language Models",
        "authors": "Yueting Yang, Xintong Zhang, Jinan Xu, Wenjuan Han",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446407"
    },
    {
        "id": 10209,
        "title": "Efficiency in Language Understanding and Generation: An Evaluation of Four Open-Source Large Language Models",
        "authors": "Siu Ming Wong, Ho Leung, Ka Yan Wong",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThis study provides a comprehensive evaluation of the efficiency of Large Language Models (LLMs) in performing diverse language understanding and generation tasks. Through a systematic comparison of open-source models including GPT-Neo, Bloom, FLAN-T5, and Mistral-7B, the research explores their performance across widely recognized benchmarks such as GLUE, SuperGLUE, LAMBADA, and SQuAD. Our findings reveal significant variations in model accuracy, computational efficiency, scalability, and adaptability, underscoring the influence of model architecture and training paradigms on performance outcomes. The study identifies key factors contributing to the models' efficiency and offers insights into potential optimization strategies for enhancing their applicability in real-world NLP applications. By highlighting the strengths and limitations of current LLMs, this research contributes to the ongoing development of more effective, efficient, and adaptable language models, paving the way for future advancements in the field of natural language processing.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-4063228/v1"
    },
    {
        "id": 10210,
        "title": "Unlocking Multimedia Capabilities of Gigantic Pretrained Language Models",
        "authors": "Boyang Li",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3607827.3616846"
    },
    {
        "id": 10211,
        "title": "Evaluating the persuasive influence of political microtargeting with large language models",
        "authors": "Kobi Hackenburg, Helen Margetts",
        "published": "No Date",
        "citations": 1,
        "abstract": "Recent advancements in large language models (LLMs) have raised the prospect of scalable, automated, and fine-grained political microtargeting on a scale previously unseen; however, the persuasive influence of microtargeting with LLMs remains unclear. Here, we build a custom web application capable of integrating self-reported demographic and political data into GPT-4 prompts in real-time, facilitating the live creation of unique messages tailored to persuade individual users on four political issues. We then deploy this application in a pre-registered randomized control experiment (n = 8,587) to investigate the extent to which access to individual-level data increases the persuasive influence of GPT-4. Our approach yields two key findings. First, messages generated by GPT-4 were broadly persuasive, in some cases increasing levels of support for an issue stance by nearly 50%. Second, in aggregate, the persuasive impact of microtargeted messages was not statistically different from that of non-microtargeted messages (5.68% vs 7.32%, respec- tively, P = 0.082). These trends hold even when manipulating the type and number of attributes used to tailor the message. Taken together, these findings suggest — contrary to widespread speculation — that the influence of current LLMs may reside not in their ability to tailor messages to individuals, but rather in the persuasiveness of their generic, non-targeted messages. This work secondarily contributes by offering a robust and replicable approach – through a custom web-based pipeline – to integrating LLMs into experimental designs, and a novel dataset, GPTarget2023, containing metadata for thousands of tailored AI-generated messages.",
        "link": "http://dx.doi.org/10.31219/osf.io/wnt8b"
    },
    {
        "id": 10212,
        "title": "Comprehensive Overview of Large Language Models (LLMs): Grasping Their Essence",
        "authors": "Williams fred, GODWIN OLUWAFEMI OLAOYE",
        "published": "No Date",
        "citations": 0,
        "abstract": "Large Language Models (LLMs) stand at the forefront of natural language processing and artificial intelligence research, drawing substantial interest for their impressive capacity to comprehend and produce text that closely resembles human language. Within this piece, we will furnish an all-encompassing exploration of LLMs, encompassing their structural design, training procedures, utilizations, advantages, obstacles, and ethical dimensions.",
        "link": "http://dx.doi.org/10.31219/osf.io/xbtzw"
    },
    {
        "id": 10213,
        "title": "Large Language Models Reasoning and Reinforcement Learning",
        "authors": "Miquel Noguer i Alonso",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4656090"
    },
    {
        "id": 10214,
        "title": "Should ChatGPT Be Biased?&amp;nbsp;Challenges and Risks of Bias in Large Language Models",
        "authors": "Emilio Ferrara",
        "published": "No Date",
        "citations": 25,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4627814"
    },
    {
        "id": 10215,
        "title": "Towards Developing an Agent-Based Framework for Validating the Trustworthiness of Large Language Models",
        "authors": "Johannes Bubeck, Janick Greinacher, Yannik Langer, Tobias Roth, Carsten Lanquillon",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012364000003636"
    },
    {
        "id": 10216,
        "title": "Evaluating Large Language Models in Semantic Parsing for Conversational Question Answering over Knowledge Graphs",
        "authors": "Phillip Schneider, Manuel Klettner, Kristiina Jokinen, Elena Simperl, Florian Matthes",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012394300003636"
    },
    {
        "id": 10217,
        "title": "AI Providers as Criminal Essay Mills? Large Language Models meet Contract Cheating Law",
        "authors": "Noëlle Gaumann, Michael Veale",
        "published": "No Date",
        "citations": 3,
        "abstract": "Academic integrity has been a constant issue for higher education, already heightened by the easy availability of essay mill and contract cheating services over the Internet. Jurisdictions across the world have passed a range of laws making it an offence to offer or advertise such services. Because of the nature of these services, which may make students agree to not submit work they create or support, some of these offences have been drafted extremely broadly, without intent or knowledge requirements. The consequence of this is that there sit on statute books a range of very wide offences covering the support of, partial or complete authoring of assignments or work.At the same time, AI systems have become part of public consciousness, particularly since the launch of chatGPT from OpenAI. These large language models have quickly become part of workflows in many areas, and are widely used by students. These have concerned higher education institutions as they highly resemble essay mills in their functioning and result.This paper attempts to unravel the intersection between essay mills, general purpose AI services, and emerging academic cheating law. We:. Analyse, in context, academic cheating legislation from jurisdictions including England and Wales, Ireland, Australia, New Zealand, US States, and Austria in light of how it applies to both essay mills, AI-enhanced essay mills, and general purpose AI providers. (Chapter 2). Examine and document currently available services by new AI-enhanced essay mills, characterising them and examining the way they present themselves both on their own websites and apps, and in advertising on major social media platforms including Instagram and TikTok. These include systems which both write entire essays as well as those designed to reference AI-created work, provide outlines, and to deliberately ‘humanise’ text as to avoid nascent AI detectors. (Chapter 3). Outline the tensions between academic cheating legal regimes and both AI-enhanced essay mills and general purpose AI systems, which can allow students to cheat in much the same way. (Chapter 4). Provide recommendations to legislators and regulators about how to design regimes which both effectively limit AI powered contract cheating without, as some current jurisdictions without accidentally bringing bone fide general purpose AI systems into scope unnecessarily. (Chapter 5)We make some important findings.Firstly, there is already a significant market of AI-enhanced essay mills, many of which are developing features directly designed to frustrate education providers’ current attempts to detect and mitigate the academic integrity implications of AI generated work.Secondly, some jurisdictions have scoped their laws so widely, that it is hard to see how ‘general purpose’ large language models such as Open AI’s GPT-4 or Google’s Bard would not fall into their provisions, and thus be committing a criminal offence through their provision. This is particularly the case in England and Wales and in Australia.Thirdly, the boundaries between assistance and cheating are being directly blurred by essay mills utilizing AI tools. Most enforcement, given the nature of the academic cheating regimes, we suspect will result from private enforcement, rather than prosecutions. These regimes interact in important and until now unexplored ways with other legal regimes, such as the EU’s Digital Services Act, the UK’s proposed Online Safety Bill, and contractual governance mechanisms such as the terms of service of AI API providers, and the licensing terms of open source models.",
        "link": "http://dx.doi.org/10.31235/osf.io/cpbfd"
    },
    {
        "id": 10218,
        "title": "Few-Shot Learning of TTPs Classification Using Large Language Models",
        "authors": "Yu Fengrui, Yanhui Du",
        "published": "No Date",
        "citations": 0,
        "abstract": "Tactics, Techniques, and Procedures (TTPs) constitute the most valuable aspect of Cyber Threat Intelligence (CTI). However, TTPs are often implicit in unstructured text, necessitating manual analysis by field experts. Automating the classification of TTPs from unstructured text is a crucial task in contemporary research. MITRE ATT&amp;CK serves as the de facto standard for studying TTPs. Existing research constructs classification datasets based on its procedural examples for tactics and techniques. However, due to a significant proportion of small sample categories, a long-tail phenomenon exists, leading to a highly imbalanced sample distribution. Consequently, more research concentrates on categories with relatively abundant samples. This paper proposes a method that combines ChatGPT data augmentation with Instruction Supervised Fine-Tuning of open large language models. This approach offers a solution for TTPs classification in few-shot learning scenarios, achieving coverage of 625 technical categories. The Precision, Recall, and F1 scores reach 86.2%, 89.9%, and 87.3%, respectively.",
        "link": "http://dx.doi.org/10.20944/preprints202401.0372.v1"
    },
    {
        "id": 10219,
        "title": "Automatic Scoring of Metaphor Creativity with Large Language Models",
        "authors": "Paul V DiStefano, John D. Patterson, Roger Beaty",
        "published": "No Date",
        "citations": 0,
        "abstract": "Metaphor is crucial in human cognition and creativity, facilitating abstract thinking, analogical reasoning, and idea generation. Typically, human raters manually score the originality of responses to creative thinking tasks—a laborious and error-prone process. Previous research sought to remedy these risks by scoring creativity tasks automatically using semantic distance and large language models (LLMs). Here, we extend research on automatic creativity scoring to metaphor generation—the ability to creatively describe episodes and concepts using nonliteral language. Metaphor is arguably more abstract and naturalistic than prior targets of automated creativity assessment. We collected 4,589 responses from 1,546 participants to various metaphor prompts and corresponding human creativity ratings. We fine-tuned two open-source LLMs (RoBERTa and GPT-2)—effectively “teaching” them to score metaphors like humans—before testing their ability to accurately assess the creativity of new metaphors. Results showed both models reliably predicted new human creativity ratings (RoBERTa r = .72, GPT-2 r = .70), significantly more strongly than semantic distance (r = .42). Importantly, the fine-tuned models generalized accurately to metaphor prompts they had not been trained on (RoBERTa r = .68, GPT-2 r = .63). We provide open access to the fine-tuned models, allowing researchers to assess metaphor creativity in a reproducible and timely manner.",
        "link": "http://dx.doi.org/10.31234/osf.io/6jtxb"
    },
    {
        "id": 10220,
        "title": "Decision letter for \"The Future of AI in Ovarian Cancer Research: The Large Language Models Perspective\"",
        "authors": "",
        "published": "2023-8-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1177/10732748231197915/v2/decision1"
    },
    {
        "id": 10221,
        "title": "Large Language Models and Information Retrieval",
        "authors": "Kalyani Pakhale -",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "This research article explores the synergistic integration of Optical Character Recognition (OCR) technology and Large Language Models (LLMs) to advance Information Retrieval (IR) processes. In a data-centric society, efficient IR is imperative, and the combination of OCR and LLMs presents a powerful solution. OCR transforms diverse document types into machine-readable formats, while LLMs excel in language understanding and generation. The article delves into the technical intricacies of these technologies, their seamless integration, and their potential to revolutionize information retrieval. By investigating their collaborative capabilities, this research contributes to the evolving landscape of natural language processing and information retrieval systems.",
        "link": "http://dx.doi.org/10.36948/ijfmr.2023.v05i06.8841"
    },
    {
        "id": 10222,
        "title": "Enhancing Large Language Models by Fuzzy Theory for Commonsense Reasoning",
        "authors": "Jiale Song, Xue-song Tang, Kuangrong Hao",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4742741"
    },
    {
        "id": 10223,
        "title": "The Future of Tourism: Examining the Potential Applications of Large Language Models",
        "authors": "Shengyu Gu",
        "published": "2024-3-5",
        "citations": 0,
        "abstract": "Large language models such as the Generative Pre-trained Transformer (GPT) have recently gained attention for their impressive natural language processing capabilities. While their potential to revolutionize various industries is still being explored, the tourism industry stands to benefit significantly from their use. In this study, we conduct an early assessment of the impact potential of GPTs on the tourism industry using a mixed-methods approach.\n\nWe first analyze the existing literature on the use of GPTs in the tourism industry and identify several potential applications such as personalized travel recommendations, language translation, and chatbots. We then collect data from various stakeholders in the tourism industry through surveys and interviews to understand their current practices and their willingness to adopt GPT-based solutions.\n\nOur results indicate that while there is a high level of awareness and interest in GPTs among tourism professionals, the adoption of these technologies is currently limited. The main barriers identified include a lack of technical expertise, concerns around data privacy and security, and the high cost of implementing GPT-based solutions. However, those who have adopted GPTs report significant benefits in terms of increased efficiency and improved customer satisfaction.\n\nTo further explore the potential of GPTs in the tourism industry, we conduct a pilot study to develop a GPT-based travel recommendation system. The system uses GPT to generate personalized travel itineraries based on user preferences and feedback. Our evaluation of the system indicates that it performs well in terms of accuracy and user satisfaction, demonstrating the potential for GPTs to provide personalized and tailored experiences to travellers.\n\nOverall, our study provides an early look at the impact potential of GPTs on the tourism industry and identifies several avenues for future research. We recommend that tourism professionals and researchers collaborate to address the current barriers to adoption and explore the full range of applications for GPTs in the industry.\n",
        "link": "http://dx.doi.org/10.32388/uyruwt"
    },
    {
        "id": 10224,
        "title": "A Batch Noise Contrastive Estimation Approach for Training Large Vocabulary Language Models",
        "authors": "Youssef Oualil, Dietrich Klakow",
        "published": "2017-8-20",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2017-818"
    },
    {
        "id": 10225,
        "title": "Validity of Large Language Models for Sentiment Analysis: Evidence of performance comparable to human coders",
        "authors": "James Elsey",
        "published": "No Date",
        "citations": 0,
        "abstract": "Assessing the sentiment of content is a major focus of communication science. Previous research has compared the performance of ‘gold-standard’ methods – exemplified by trained human coders – with approaches such as crowd-sourcing, data dictionaries, and machine learning. Aggregated crowd-sourced assessments and trained human coders perform best, but trained coders may not be scalable and crowd-sourcing may raise financial, ethical, and practical issues. Large Language Models (LLMs) – artificial intelligence systems trained on vast datasets to process and generate human-like text – may combine the in-depth understanding of human coders with the speed and scalability of automated methods. We used the gold-standard sentiment coding for a corpus of Dutch economic news headlines from previous research. We found that two commercially available LLMs, Anthropic’s Claude 2 and OpenAI’s ChatGPT-4, could perform at levels approaching or matching single trained coders and crowdsourced ratings, and reliably exceeded previously reported machine learning and automated approaches. Using variation in prompts (‘prompt engineering’), we show that prompt details can affect performance, but even with minimal instruction the performance of Claude 2 approached human-level. LLMs are promising tools for scalable and high-quality sentiment analysis. Future research can consider their applications on long-form text and images.",
        "link": "http://dx.doi.org/10.31234/osf.io/kcuwy"
    },
    {
        "id": 10226,
        "title": "Simulating Timeshifting for Long-Running Large Language Models",
        "authors": "Akshaya Jagannadharao, Nicole Beckage, Dawn Nafus, Scott Chamberlin",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nLanguage models play a vital role in various natural language processing tasks, but their training can be computationally intensive and lead to significant carbon emissions. In this study, we explore the effectiveness of timeshifting strategies to mitigate the environmental impact of long-running language models (LLMs). We develop a simulation tool that estimates carbon emissions for LLMs, enabling developers to make informed decisions before running their workloads. By leveraging historical carbon intensity data from WattTime, we investigate the potential benefits and limitations of time-shifting in different locations, considering diverse energy profiles. Our findings demonstrate that time-shifting can substantially reduce emissions for certain workloads, but it is highly dependent on the region's carbon intensity and energy mix. We present insights into the trade-offs between emissions reduction and workload runtime, acknowledging the need for further advancements in carbon-aware computing practices. Our research contributes to the growing field of sustainable computing and encourages developers to adopt environmentally conscious strategies in language model training.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3225810/v1"
    },
    {
        "id": 10227,
        "title": "Can Large Language Models (LLM) label topics from a topic model?",
        "authors": "Dai Li, Bolun Zhang, Yimang Zhou",
        "published": "No Date",
        "citations": 0,
        "abstract": "ChatGPT is a general application based on a Large Language Model (LLM) developed by OpenAI. It is useful in many tasks in Natural Language Processing (NLP). As NLP tasks are prevalent in the practice of social science, ChatGPT is potentially a significant tool for social science. This study puts its focus on Topic Modeling, especially whether ChatGPT can generate convincing labels for topics. We sampled articles published in English sociological journals that use Topic Modeling, extracted the terms of topics and their labels, and asked Amazon Mechanic Turk users to choose between the original labels and ChatGPT labels via an online survey platform. The results show that general users do not significantly choose original labels more often; on the contrary, ChatGPT labels are more likely to be prefered in most labels. This indicates that ChatGPT can be used in generating labels for topics as heuristics for researchers.",
        "link": "http://dx.doi.org/10.31235/osf.io/23x4m"
    },
    {
        "id": 10228,
        "title": "Enhancing Large Language Models for Text-to-Testcase Generation",
        "authors": "Saranya Alagarsamy, Chakkrit Tantithamthavorn, Chetan Arora, Aldeida Aleti",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4732705"
    },
    {
        "id": 10229,
        "title": "Introduction",
        "authors": "Thimira Amaratunga",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0017-7_1"
    },
    {
        "id": 10230,
        "title": "Machine Advisors: Integrating Large Language Models into Democratic Assemblies",
        "authors": "Petr Špecián",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4682958"
    },
    {
        "id": 10231,
        "title": "Decision letter for \"The Future of AI in Ovarian Cancer Research: The Large Language Models Perspective\"",
        "authors": "",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1177/10732748231197915/v1/decision1"
    },
    {
        "id": 10232,
        "title": "On Finetuning Large Language Models",
        "authors": "Yu Wang",
        "published": "2023-11-28",
        "citations": 2,
        "abstract": "Abstract\nA recent paper by Häffner et al. (2023, Political Analysis 31, 481–499) introduces an interpretable deep learning approach for domain-specific dictionary creation, where it is claimed that the dictionary-based approach outperforms finetuned language models in predictive accuracy while retaining interpretability. We show that the dictionary-based approach’s reported superiority over large language models, BERT specifically, is due to the fact that most of the parameters in the language models are excluded from finetuning. In this letter, we first discuss the architecture of BERT models, then explain the limitations of finetuning only the top classification layer, and lastly we report results where finetuned language models outperform the newly proposed dictionary-based approach by 27% in terms of \n\n\n\n$R^2$\n\n\n and 46% in terms of mean squared error once we allow these parameters to learn during finetuning. Researchers interested in large language models, text classification, and text regression should find our results useful. Our code and data are publicly available.",
        "link": "http://dx.doi.org/10.1017/pan.2023.36"
    },
    {
        "id": 10233,
        "title": "Large Language Models for Text Classification: From Zero-Shot Learning to Fine-Tuning",
        "authors": "Youngjin Chae, Thomas Davidson",
        "published": "No Date",
        "citations": 1,
        "abstract": "This study analyzes large language models (LLMs) as a methodology for computational sociology, focusing on applications to supervised text classification. We consider how the latest generation of text-to-text transformer models can make predictions using prompts and minimal training examples and assess the sensitivity of these approaches to wording and composition. Through a comprehensive case study on identifying opinions expressed about politicians on Twitter and Facebook, we evaluate four different LLM architectures, varying in size, training data, and architecture. We compare the performance across different training regimes, from prompt-based zero-shot learning to fine-tuning using thousands of annotated examples. Our findings demonstrate how LLMs can perform complex text classification tasks with high accuracy, substantially outperforming conventional baselines. We use these results to provide practical recommendations for sociologists interested in employing LLMs for text classification tasks. Fine-tuning smaller models offers an optimal solution for most researchers due to their relatively high accuracy and low cost. We discuss the trade-offs between proprietary and open-source models, the importance of evaluating models for bias, and concerns related to transparency and reproducibility. This study contributes to understanding the capabilities and limitations of these models in a sociological context, providing a foundation for future research and applications in the field.",
        "link": "http://dx.doi.org/10.31235/osf.io/sthwk"
    },
    {
        "id": 10234,
        "title": "Transformers",
        "authors": "Thimira Amaratunga",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0017-7_3"
    },
    {
        "id": 10235,
        "title": "Shaping Learning Experience Design Using Large Language Models (LLMs)",
        "authors": "Subhajit Chattopadhyay",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4554943"
    },
    {
        "id": 10236,
        "title": "Large Language Models for Telecom",
        "authors": "Mérouane Debbah",
        "published": "2023-9-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/fmec59375.2023.10305960"
    },
    {
        "id": 10237,
        "title": "Utilizing Large Language Models for Geoscience Literature Information Extraction",
        "authors": "Peng Yu, Cheng Deng, Huawei Ji, Ying Wen",
        "published": "No Date",
        "citations": 0,
        "abstract": "Extracting information from unstructured and semi-structured geoscience literature is a crucial step in conducting geological research. The traditional machine learning extraction paradigm requires a substantial amount of high-quality manually annotated data for model training, which is time-consuming, labor-intensive, and not easily transferable to new fields. Recently, large language models (LLMs) (e.g., ChatGPT, GPT-4, and LLaMA), have shown great performance in various natural language processing (NLP) tasks, such as question answering, machine translation, and text generation. A substantial body of work has demonstrated that LLMs possess strong in-context learning (ICL) and even zero-shot learning capabilities to solve downstream tasks without specifically designed supervised fine-tuning.\n\n\nIn this paper, we propose utilizing LLMs for geoscience literature information extraction. Specifically, we design a hierarchical PDF parsing pipeline and an automated knowledge extraction process, which can significantly reduce the need for manual data annotation, assisting geoscientists in literature data mining. For the hierarchical PDF parsing pipeline, firstly, a document layout detection model fine-tuned on geoscience literature is employed for layout detection, obtaining layout detection information for the document. Secondly, based on the document layout information, an optical character content parsing model is used for content parsing, obtaining the text structure and plain text corresponding to the content. Finally, the text structure and plain text are combined and reconstructed to ultimately obtain the parsed structured data. For the automated knowledge extraction process, firstly, the parsed long text is segmented into paragraphs to adapt to the input length limit of LLMs. Subsequently, a few-shot prompting method is employed for structured knowledge extraction, encompassing two tasks: attribute value extraction and triplet extraction. In attribute value extraction, prompts are generated automatically by the LLMs based on the subdomain and attribute names, facilitating the location and extraction of values related to subdomain attribute names in the text. For triplet extraction, the LLMs employ a procedural approach to entity extraction, entity type extraction, and relation extraction, following the knowledge graph structure pattern. Finally, the extracted structured knowledge is stored in the form of knowledge graphs, facilitating further analysis and integration of various types of knowledge from the literature.\n\n\nOur proposed approach turns out to be simple, flexible, and highly effective in geoscience literature information extraction. Demonstrations of information extraction in subdomains such as radiolarian fossils and fluvial facies have yielded satisfactory results. The extraction efficiency has significantly improved, and feedback from domain experts indicates a relatively high level of accuracy in the extraction process. The extracted results can be used to construct a foundational knowledge graph for geoscience literature, supporting the comprehensive construction and efficient application of a geoscience knowledge graph.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-16101"
    },
    {
        "id": 10238,
        "title": "Baby’s CoThought: Leveraging Large Language Models for Enhanced Reasoning in Compact Models",
        "authors": "Zheyu Zhang, Han Yang, Bolei Ma, David Rügamer, Ercong Nie",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-babylm.13"
    },
    {
        "id": 10239,
        "title": "On Bilingual Lexicon Induction with Large Language Models",
        "authors": "Yaoyiran Li, Anna Korhonen, Ivan Vulić",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.595"
    },
    {
        "id": 10240,
        "title": "Large Language Models",
        "authors": "Tom Taulli",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-9367-6_5"
    },
    {
        "id": 10241,
        "title": "Large Language Models (LLMs) for Natural Language Processing (NLP) of Oil and Gas Drilling Data",
        "authors": "Prateek Kumar, Sanjay Kathuria",
        "published": "2023-10-9",
        "citations": 0,
        "abstract": "Abstract\nIn the oil and gas industry, drilling activities spawn substantial volumes of unstructured textual data. The examination and interpretation of these data pose significant challenges. This research exploits the emerging capabilities of large language models (LLMs) with over 100 billion parameters to extract actionable insights from raw drilling data. Through fine-tuning methodologies and the use of various prompt engineering strategies, we addressed several text downstream tasks, including summarization, classification, entity recognition, and information extraction. This study delves into our methods, findings, and the novel application of LLMs for efficient and precise analysis of drilling data.",
        "link": "http://dx.doi.org/10.2118/215167-ms"
    },
    {
        "id": 10242,
        "title": "Understanding Telecom Language Through Large Language Models",
        "authors": "Lina Bariah, Hang Zou, Qiyang Zhao, Belkacem Mouhouche, Faouzi Bader, Merouane Debbah",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/globecom54140.2023.10437725"
    },
    {
        "id": 10243,
        "title": "Can Large Language Models Capture Dissenting Human Voices?",
        "authors": "Noah Lee, Na An, James Thorne",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.278"
    },
    {
        "id": 10244,
        "title": "Evaluating Generative Models for Graph-to-Text Generation",
        "authors": "Shuzhou Yuan,  , Michael Färber,  ",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_133"
    },
    {
        "id": 10245,
        "title": "Probing the “Creativity” of Large Language Models: Can models produce divergent semantic association?",
        "authors": "Honghua Chen, Nai Ding",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.858"
    },
    {
        "id": 10246,
        "title": "MiniChain: A Small Library for Coding with Large Language Models",
        "authors": "Alexander Rush",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-demo.27"
    },
    {
        "id": 10247,
        "title": "A survey of GPT-3 family large language models including ChatGPT and GPT-4",
        "authors": "Katikapalli Subramanyam Kalyan",
        "published": "2024-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.nlp.2023.100048"
    },
    {
        "id": 10248,
        "title": "Copyright Violations and Large Language Models",
        "authors": "Antonia Karamolegkou, Jiaang Li, Li Zhou, Anders Søgaard",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.458"
    },
    {
        "id": 10249,
        "title": "GPT-Based Models Meet Simulation: How to Efficiently use Large-Scale Pre-Trained Language Models Across Simulation Tasks",
        "authors": "Philippe J. Giabbanelli",
        "published": "2023-12-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wsc60868.2023.10408017"
    },
    {
        "id": 10250,
        "title": "Augmenting interpretable models with large language models during training",
        "authors": "Chandan Singh, Armin Askari, Rich Caruana, Jianfeng Gao",
        "published": "2023-11-30",
        "citations": 2,
        "abstract": "AbstractRecent large language models (LLMs), such as ChatGPT, have demonstrated remarkable prediction performance for a growing array of tasks. However, their proliferation into high-stakes domains and compute-limited settings has created a burgeoning need for interpretability and efficiency. We address this need by proposing Aug-imodels, a framework for leveraging the knowledge learned by LLMs to build extremely efficient and interpretable prediction models. Aug-imodels use LLMs during fitting but not during inference, allowing complete transparency and often a speed/memory improvement of greater than 1000x for inference compared to LLMs. We explore two instantiations of Aug-imodels in natural-language processing: Aug-Linear, which augments a linear model with decoupled embeddings from an LLM and Aug-Tree, which augments a decision tree with LLM feature expansions. Across a variety of text-classification datasets, both outperform their non-augmented, interpretable counterparts. Aug-Linear can even outperform much larger models, e.g. a 6-billion parameter GPT-J model, despite having 10,000x fewer parameters and being fully transparent. We further explore Aug-imodels in a natural-language fMRI study, where they generate interesting interpretations from scientific data.",
        "link": "http://dx.doi.org/10.1038/s41467-023-43713-1"
    },
    {
        "id": 10251,
        "title": "Do Language Models Have a Common Sense regarding Time? Revisiting Temporal Commonsense Reasoning in the Era of Large Language Models",
        "authors": "Raghav Jain, Daivik Sojitra, Arkadeep Acharya, Sriparna Saha, Adam Jatowt, Sandipan Dandapat",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.418"
    },
    {
        "id": 10252,
        "title": "LARGE LANGUAGE MODELS (LLMS) AND CHATGPT FOR BIOMEDICINE",
        "authors": "Cecilia Arighi, Steven Brenner, Zhiyong Lu",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811286421_0048"
    },
    {
        "id": 10253,
        "title": "Can large language models help augment English psycholinguistic datasets?",
        "authors": "Sean Trott",
        "published": "2024-1-23",
        "citations": 0,
        "abstract": "AbstractResearch on language and cognition relies extensively on psycholinguistic datasets or “norms”. These datasets contain judgments of lexical properties like concreteness and age of acquisition, and can be used to norm experimental stimuli, discover empirical relationships in the lexicon, and stress-test computational models. However, collecting human judgments at scale is both time-consuming and expensive. This issue of scale is compounded for multi-dimensional norms and those incorporating context. The current work asks whether large language models (LLMs) can be leveraged to augment the creation of large, psycholinguistic datasets in English. I use GPT-4 to collect multiple kinds of semantic judgments (e.g., word similarity, contextualized sensorimotor associations, iconicity) for English words and compare these judgments against the human “gold standard”. For each dataset, I find that GPT-4’s judgments are positively correlated with human judgments, in some cases rivaling or even exceeding the average inter-annotator agreement displayed by humans. I then identify several ways in which LLM-generated norms differ from human-generated norms systematically. I also perform several “substitution analyses”, which demonstrate that replacing human-generated norms with LLM-generated norms in a statistical model does not change the sign of parameter estimates (though in select cases, there are significant changes to their magnitude). I conclude by discussing the considerations and limitations associated with LLM-generated norms in general, including concerns of data contamination, the choice of LLM, external validity, construct validity, and data quality. Additionally, all of GPT-4’s judgments (over 30,000 in total) are made available online for further analysis.",
        "link": "http://dx.doi.org/10.3758/s13428-024-02337-z"
    },
    {
        "id": 10254,
        "title": "ParrotGPT: On the Advantages of Large Language Models Tools for Academic Metadata Schema Mapping",
        "authors": "Kristian Garza",
        "published": "No Date",
        "citations": 0,
        "abstract": "Creating Crosswalk with chatGPT Plus. Image partially created with Dall-ePicture, if you will, the labyrinthine world of academic information management, where metadata schema mapping serves as a vital underpinning for the exchange and intermingling of data across diverse platforms and systems. This arena has long been dominated by the venerable metadata schema crosswalk, which, though serviceable, has begun to show its age. The traditional method of creating metadata schema crosswalks is a...",
        "link": "http://dx.doi.org/10.59350/4tqd9-3dz02"
    },
    {
        "id": 10255,
        "title": "MacBehaviour: An R package for behavioural experimentation on large language models",
        "authors": "Xufeng Duan, Shixuan Li, Zhenguang Garry Cai",
        "published": "No Date",
        "citations": 0,
        "abstract": "There has been increasing interest in investigating the behaviours of large language models (LLMs) and LLM-powered chatbots. This paper presents the development of an R package called \"MacBehaviour\" that aims to streamline the experimental process when interfacing with LLMs for behavioural research. \"MacBehaviour\" offers a user-friendly package for conducting behavioural experimentation and for norming experimental stimuli with LLMs in the R environment. The package provides a suite of functions tailored for experiments on LLMs, including the design of experiment, the presentation of stimuli, and the manipulation of model behaviour. The package interfaces with APIs of an array of LLMs, including those from OpenAI's GPT series, Llama-2-chat-hf series in Hugging Face, and open-source models. Overall, \"MacBehaviour\" serves as a valuable resource for researchers, offering a user-friendly interface and comprehensive tools to streamline the experimental process and advance the study of machine behavior within the field of psychology.",
        "link": "http://dx.doi.org/10.31234/osf.io/ywtfd"
    },
    {
        "id": 10256,
        "title": "The Impact of Multimodal Large Language Models on Health Care’s Future (Preprint)",
        "authors": "Bertalan Meskó",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\nWhen large language models (LLMs) were introduced to the public at large in late 2022 with ChatGPT (OpenAI), the interest was unprecedented, with more than 1 billion unique users within 90 days. Until the introduction of Generative Pre-trained Transformer 4 (GPT-4) in March 2023, these LLMs only contained a single mode—text.\nAs medicine is a multimodal discipline, the potential future versions of LLMs that can handle multimodality—meaning that they could interpret and generate not only text but also images, videos, sound, and even comprehensive documents—can be conceptualized as a significant evolution in the field of artificial intelligence (AI). This paper zooms in on the new potential of generative AI, a new form of AI that also includes tools such as LLMs, through the achievement of multimodal inputs of text, images, and speech on health care’s future. We present several futuristic scenarios to illustrate the potential path forward as multimodal LLMs (M-LLMs) could represent the gateway between health care professionals and using AI for medical purposes. It is important to point out, though, that despite the unprecedented potential of generative AI in the form of M-LLMs, the human touch in medicine remains irreplaceable. AI should be seen as a tool that can augment health care professionals rather than replace them. It is also important to consider the human aspects of health care—empathy, understanding, and the doctor-patient relationship—when deploying AI.\n",
        "link": "http://dx.doi.org/10.2196/preprints.52865"
    },
    {
        "id": 10257,
        "title": "Hallucinations and Emergence in Large Language Models",
        "authors": "Bernardo A. Huberman, Sayandev Mukherjee",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4676180"
    },
    {
        "id": 10258,
        "title": "Evaluation of Transfer Learning and Adaptability in Large Language Models with the GLUE Benchmark",
        "authors": "Nuraini Sulaiman, Farizal Hamzah",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36227/techrxiv.171077989.99407624/v1"
    },
    {
        "id": 10259,
        "title": "Verbal Lie Detection using Large Language Models",
        "authors": "Riccardo Loconte, Roberto Russo, Pasquale Capuozzo, Pietro Pietrini, Giuseppe Sartori",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nGiven that human accuracy in detecting deception has been proven to not go above the chance level, several automatized verbal lie detection techniques employing Machine Learning and Transformer models have been developed to reach higher levels of accuracy. This study is the first to explore the performance of a Large Language Model, FLAN-T5 (small and base sizes), in a lie-detection classification task in three English-language datasets encompassing personal opinions, autobiographical memories, and future intentions. After performing stylometric analysis to describe linguistic differences in the three datasets, we tested the small- and base-sized FLAN-T5 in three Scenarios using 10-fold cross-validation: one with train and test set coming from the same single dataset, one with train set coming from two datasets and the test set coming from the third remaining dataset, one with train and test set coming from all the three datasets. We reached state-of-the-art results in Scenarios 1 and 3, outperforming previous benchmarks. The results revealed also that model performance depended on model size, with larger models exhibiting higher performance.Furthermore, stylometric analysis was performed to carry out explainability analysis, finding that linguistic features associated with the Cognitive Load framework may influence the model’s predictions. \nFurthermore, stylometric analysis was performed to carry out explainability analysis, finding that linguistic features associated with the Cognitive Load framework may influence the model’s predictions.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3126100/v1"
    },
    {
        "id": 10260,
        "title": "Academic Publishing web forms meet your demise: The unstoppable rise of large language models…",
        "authors": "Kristian Garza",
        "published": "No Date",
        "citations": 0,
        "abstract": "Academic Publishing web forms meet your demise: The unstoppable rise of large language models (ChatGPT)Prompt to create DOI metadata using ChatGPT.As we enter the age of artificial intelligence, it’s worth considering how large language models will revolutionize how we interact with websites and applications. Web forms have been the dominant method for users to input data and complete tasks online for decades. But as anyone who has struggled to fill out a form on the web can attest, these...",
        "link": "http://dx.doi.org/10.59350/nevym-51e32"
    },
    {
        "id": 10261,
        "title": "Evaluating Large Language Models: ChatGPT-4, Mistral 8x7B, and Google Gemini Benchmarked Against MMLU",
        "authors": "Kensuke Ono, Akira Morita",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36227/techrxiv.170956672.21573677/v1"
    },
    {
        "id": 10262,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Sinan Chen",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/8322wb"
    },
    {
        "id": 10263,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Luis Rivera",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/1sargd"
    },
    {
        "id": 10264,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Lele Sha",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/mz5095"
    },
    {
        "id": 10265,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Todorka Glushkova",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/taszwd"
    },
    {
        "id": 10266,
        "title": "Learning from Mistakes via Cooperative Study Assistant for Large Language Models",
        "authors": "Danqing Wang, Lei Li",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.659"
    },
    {
        "id": 10267,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Su Baohua",
        "published": "2023-9-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/3uiwrg"
    },
    {
        "id": 10268,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Birgit Popp",
        "published": "2023-9-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/4rwgda"
    },
    {
        "id": 10269,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Nawal Sael",
        "published": "2023-10-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/kl5lm2"
    },
    {
        "id": 10270,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Clark Ted",
        "published": "2023-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/xbbyy8"
    },
    {
        "id": 10271,
        "title": "Large Language Models are Prone to Methodological Artifacts",
        "authors": "Melanie Brucks, Olivier Toubia",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4484416"
    },
    {
        "id": 10272,
        "title": "Leveraging Large Language Models for Educational Enhancement: A Case Study of ChatGPT, BingChat, and Bard",
        "authors": "Thu Nguyen",
        "published": "No Date",
        "citations": 0,
        "abstract": "This paper examines the potential of large language models, specifically ChatGPT, BingChat, and Bard, in enhancing the work of teachers in various educational settings. These models, powered by cutting-edge artificial intelligence, offer a wide range of applications that can aid educators in curriculum development, personalized instruction, student engagement, and administrative tasks. By harnessing the capabilities of these language models, teachers can not only streamline their workload but also improve the overall quality of education. This paper explores the ways in which these models can empower educators and revolutionize teaching practices.",
        "link": "http://dx.doi.org/10.20944/preprints202309.1554.v1"
    },
    {
        "id": 10273,
        "title": "A clarification of the conditions under which Large language Models could be conscious",
        "authors": "Morten Overgaard, Asger Kirkeby-Hinrup",
        "published": "No Date",
        "citations": 0,
        "abstract": "With incredible speed Large Language Models (LLMs) are reshaping many aspects of society. This has been met with unease by the public, and public discourse is rife with questions about whether LLMs are or might be conscious. Because there is widespread disagreement about consciousness between scientists, any concrete answers we could offer the public would be contentious. Here we offer the next best thing: charting the possibility for consciousness in LLMs.",
        "link": "http://dx.doi.org/10.31234/osf.io/gp3vx"
    },
    {
        "id": 10274,
        "title": "Turing Jest: Do Large Language Models have a Sense of Humor?",
        "authors": "Sean Trott, Drew Ellen Walker, Seana Coulson",
        "published": "No Date",
        "citations": 0,
        "abstract": "Humor is an essential aspect of human experience, yet surprisingly little is known about how we recognize and understand humorous utterances. Most theories emphasize the role of incongruity detection and resolution, as well as cognitive capacities like Theory of Mind or pragmatic reasoning. In multiple pre-registered experiments, we ask whether the ability to understand verbal humor can emerge from exposure to purely linguistic input. We find that GPT-3, a large language model (LLM) trained on only language data, exhibits above-chance performance in tasks designed to detect, appreciate, and comprehend jokes. Although GPT-3 falls short of human performance, both humans and LLMs misclassify non-jokes with surprising endings as jokes. Further exploratory analyses reveal a relationship between model size and humor comprehension ability. Results suggest first, that LLMs are surprisingly adept at humor comprehension, and second, that language is not all one needs to “get the joke”.",
        "link": "http://dx.doi.org/10.31234/osf.io/6xfn8"
    },
    {
        "id": 10275,
        "title": "Administration of the text-based portions of a general IQ test to five different large language models",
        "authors": "Michael King",
        "published": "No Date",
        "citations": 2,
        "abstract": "<p>As additional large language model (LLM) AI chatbots become publicly available, there is growing interest in their capacity for general intelligence, and what differences in intelligence these various models might exhibit. One challenge in assessing general intelligence using a standard intelligence quotient (IQ) test is that a large fraction of the questions in such tests is visual, in particular the “spatial” portions that present patterns and sequences in drawn images, and numerical questions where the spatial arrangement of numbers is important. In this study, the author distilled down the text-based portions of two self-scoring IQ tests and administered these questions to five different publicly available large language models: ChatGPT (Default GPT-3.5 version), ChatGPT (Legacy GPT-3.5 version), ChatGPT (GPT-4 version), Microsoft Bing chatbot (also based on the GPT-4 LLM, however linked to live internet search), and Google Bard, which is based on the LaMBDA LLM. The test scores were converted into a range of approximate IQ values for each LLM with the following median values determined: 112, 111.5, 123, 121.5, and 101, respectively. Of particular interest is that all five LLMs performed exceptionally well in certain question types, and particularly poorly in other question types, suggesting that LLMs share common strengths and weaknesses in particular aspects of general intelligence. The highest performing LLM publicly available to date, the GPT-4 version of ChatGPT Plus, shows performance on the test-based portions of a general IQ test which approach the 99th percentile of human performance, within the range of MENSA level of general intelligence. These models are expected to continue to improve over time, based on the differences seen over versions released in the past year, and will soon be capable of taking intact IQ tests that rely on interpretation of graphical images.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22645561.v1"
    },
    {
        "id": 10276,
        "title": "Augmenting Large Language Models for Enhanced Interaction with Government Data Repositories",
        "authors": "Paul Trust, Kizito Omala, Rosane Minghim",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIn the modern digital landscape, government agencies globally are shifting services online to enhance transparency and public engagement. However, the vast digital content can be daunting for citizens seeking information. Addressing this, our research evaluates the efficacy of Large Language Models (LLMs), like ChatGPT, in the public sector, highlighting their potential in extracting relevant insights and optimizing information navigation. Our approach integrates non-parametric data from various sources focusing on information posted on three irish websites; the government publications, health services, and the Citizens Information websites, using retrieval-augmented models. Empirical evaluations show that the llama2 model, with $13$ billion parameters, achieves up to 90% for government publication releases and up to 96.12% for health information enhancement when complemented with retrieval augmentation, with other models also showing substantial improvements. These results emphasize the transformative potential of retrieval-augmented frameworks in keeping LLMs updated with the evolving public information domain.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3897706/v1"
    },
    {
        "id": 10277,
        "title": "Variability in Large Language Models’ Responses to Medical Licensing and Certification Examinations. Comment on “How Does ChatGPT Perform on the United States Medical Licensing Examination? The Implications of Large Language Models for Medical Education and Knowledge Assessment”",
        "authors": "Richard H Epstein, Franklin Dexter",
        "published": "2023-7-13",
        "citations": 8,
        "abstract": "",
        "link": "http://dx.doi.org/10.2196/48305"
    },
    {
        "id": 10278,
        "title": "Integrating Large Language Models into Higher Education: Guidelines for Effective Implementation",
        "authors": "Karl de Fine Licht",
        "published": "2023-8-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3390/cmsf2023008065"
    },
    {
        "id": 10279,
        "title": "Administration of the text-based portions of a general IQ test to five different large language models",
        "authors": "Michael King",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>As additional large language model (LLM) AI chatbots become publicly available, there is growing interest in their capacity for general intelligence, and what differences in intelligence these various models might exhibit. One challenge in assessing general intelligence using a standard intelligence quotient (IQ) test is that a large fraction of the questions in such tests is visual, in particular the “spatial” portions that present patterns and sequences in drawn images, and numerical questions where the spatial arrangement of numbers is important. In this study, the author distilled down the text-based portions of two self-scoring IQ tests and administered these questions to five different publicly available large language models: ChatGPT (Default GPT-3.5 version), ChatGPT (Legacy GPT-3.5 version), ChatGPT (GPT-4 version), Microsoft Bing chatbot (also based on the GPT-4 LLM, however linked to live internet search), and Google Bard, which is based on the LaMBDA LLM. The test scores were converted into a range of approximate IQ values for each LLM with the following median values determined: 112, 111.5, 123, 121.5, and 101, respectively. Of particular interest is that all five LLMs performed exceptionally well in certain question types, and particularly poorly in other question types, suggesting that LLMs share common strengths and weaknesses in particular aspects of general intelligence. The highest performing LLM publicly available to date, the GPT-4 version of ChatGPT Plus, shows performance on the test-based portions of a general IQ test which approach the 99th percentile of human performance, within the range of MENSA level of general intelligence. These models are expected to continue to improve over time, based on the differences seen over versions released in the past year, and will soon be capable of taking intact IQ tests that rely on interpretation of graphical images.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22645561"
    },
    {
        "id": 10280,
        "title": "Performance Analysis of Large Language Models for Medical Text Summarization",
        "authors": "Jaskaran Singh, Tirth Patel, Amandeep Singh",
        "published": "No Date",
        "citations": 0,
        "abstract": "Due to the rapid expansion of medical literature, keeping pace with the latest research and clinical guidelines has become more challenging for healthcare professionals.To overcome this challenge, effective text summarization is crucial for improving access to knowledge, enhancing clinical decision-making, and ultimately benefiting patient outcomes. In this study, a medical text summarization system that employs large language models (LLMs) was fine-tuned and evaluated with the objective of generating precise, logical, and brief summaries of medical literature, emphasizing clinical relevance and ease of understanding. We plan to evaluate the performance of GPT3, GPT4 and the fine-tuned T5, BART, and Pegasus models trained on the standard PubMed dataset using standard evaluation metrics.",
        "link": "http://dx.doi.org/10.31219/osf.io/kn5f2"
    },
    {
        "id": 10281,
        "title": "Leveraging large language models for data analysis automation",
        "authors": "Jacqueline A Jansen, Artür Manukyan, Nour Al Khoury, Altuna Akalin",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractData analysis is constrained by a shortage of skilled experts, particularly in biology, where detailed data interpretation is vital for understanding complex biological processes and developing new treatments and diagnostics. To address this, we developedmergen, an R package that leverages Large Language Models (LLMs) for data analysis code generation and execution. Our primary goal is to enable humans to conduct data analysis by simply describing their objectives and the desired analyses for specific datasets through clear text. Our approach improves code generation via specialized prompt engineering and error feedback mechanisms. In addition, our system can execute the data analysis workflows prescribed by the LLM providing the results of the data analysis workflow for human review. We evaluated the performance of this data analysis system using various data analysis tasks. Our evaluation revealed that while LLMs effectively generate code for some data analysis tasks, challenges remain in executable code generation, especially for complex data analysis tasks. Our study contributes to a better understanding of LLM capabilities and limitations, providing software infrastructure and practical insights for their effective integration into data analysis workflows.",
        "link": "http://dx.doi.org/10.1101/2023.12.11.571140"
    },
    {
        "id": 10282,
        "title": "Evaluating Large Language Models for use in healthcare: A Framework for Translational Value Assessment",
        "authors": "Sandeep Reddy",
        "published": "No Date",
        "citations": 0,
        "abstract": "The recent focus on Large Language Models (LLMs) has yielded unprecedented discussion of their potential use in various domains, including healthcare. While showing considerable potential in performing human-capable tasks, LLMs have also demonstrated significant drawbacks, including generating misinformation, falsifying data, and contributing to plagiarism. These aspects are generally concerning but can be more severe in the context of healthcare. As LLMs are explored for utility in healthcare, including generating discharge summaries, interpreting medical records and providing medical advice, it is necessary to ensure safeguards around their use in healthcare. Notably, there must be an evaluation process that assesses LLMs for their natural language processing performance and their translational value. Complementing this assessment, a governance layer can ensure accountability and public confidence in such models. Such an evaluation framework is discussed and presented in this paper.",
        "link": "http://dx.doi.org/10.31219/osf.io/tvdux"
    },
    {
        "id": 10283,
        "title": "Learning Analytics in the Era of Large Language Models",
        "authors": "Elisabetta Mazzullo, Okan Bulut, Tarid Wongvorachan, Bin Tan",
        "published": "No Date",
        "citations": 0,
        "abstract": "Although learning analytics (LA) holds great potential to improve teaching and learning, LA research and practice are currently riddled with limitations that impact every stage of the LA life cycle. The present paper offers an overview of these challenges before proposing strategies to overcome them and exploring how the recent innovations brought forth by language models can improve LA research and practice. In particular, we encourage the empowerment of teachers during LA development, as this would strengthen the theoretical foundation of LA solutions and increase their interpretability and usability. Furthermore, we provide examples of how process data can be used to understand learning processes and generate more interpretable LA insights. Furthermore, we explore how LLMs could come into play in LA to generate interpretable insights, timely and actionable feedback, increase personalization, and support teachers’ tasks more broadly.",
        "link": "http://dx.doi.org/10.20944/preprints202308.0366.v1"
    },
    {
        "id": 10284,
        "title": "Popular LLMs",
        "authors": "Thimira Amaratunga",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0017-7_5"
    },
    {
        "id": 10285,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Yunjian Qiu",
        "published": "2023-9-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/9jia39"
    },
    {
        "id": 10286,
        "title": "Analysis of the Effectiveness of Large Language Models in Assessing Argumentative Writing and Generating Feedback",
        "authors": "Daisy Albuquerque da Silva, Carlos Eduardo de Mello, Ana Garcia",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012466600003636"
    },
    {
        "id": 10287,
        "title": "Large Language Models Are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models",
        "authors": "Yinlin Deng, Chunqiu Steven Xia, Haoran Peng, Chenyuan Yang, Lingming Zhang",
        "published": "2023-7-12",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3597926.3598067"
    },
    {
        "id": 10288,
        "title": "The Next Chapter: A Study of Large Language Models in Storytelling",
        "authors": "Zhuohan Xie, Trevor Cohn, Jey Han Lau",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.inlg-main.23"
    },
    {
        "id": 10289,
        "title": "How Large Language Models are Transforming Machine-Paraphrased Plagiarism",
        "authors": "Jan Philip Wahle, Terry Ruas, Frederic Kirstein, Bela Gipp",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22541/au.167528149.95939897/v1"
    },
    {
        "id": 10290,
        "title": "ChatGPT's and Large Language Models Influence on Research, Technology, and Education: A Comprehensive Co-Word Analysis",
        "authors": "Juan Velásquez",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4596285"
    },
    {
        "id": 10291,
        "title": "On Political Theory and Large Language Models",
        "authors": "Emma Rodman",
        "published": "2023-10-17",
        "citations": 1,
        "abstract": " Political theory as a discipline has long been skeptical of computational methods. In this paper, I argue that it is time for theory to make a perspectival shift on these methods. Specifically, we should consider integrating recently developed generative large language models like GPT-4 as tools to support our creative work as theorists. Ultimately, I suggest that political theorists should embrace this technology as a method of supporting our capacity for creativity—but that we should do so in a way that is mindful of the content and value of theorizing, the technical constraints of the models, and the ethical questions that the technology raises. ",
        "link": "http://dx.doi.org/10.1177/00905917231200826"
    },
    {
        "id": 10292,
        "title": "A Surgical Perspective on Large Language Models",
        "authors": "Robert Miller",
        "published": "2023-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/sla.0000000000005896"
    },
    {
        "id": 10293,
        "title": "Use of large language models as a scalable approach to understanding public health discourse",
        "authors": "Laura Espinosa, Marcel Salathé",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractOnline public health discourse is becoming more and more important in shaping public health dynamics. Large Language Models (LLMs) offer a scalable solution for analysing the vast amounts of unstructured text found on online platforms. Here, we explore the effectiveness of Large Language Models (LLMs), including GPT models and open-source alternatives, for extracting public stances towards vaccination from social media posts. Using an expert-annotated dataset of social media posts related to vaccination, we applied various LLMs and a rule-based sentiment analysis tool to classify the stance towards vaccination. We assessed the accuracy of these methods through comparisons with expert annotations and annotations obtained through crowdsourcing. Our results demonstrate that few-shot prompting of best-in-class LLMs are the best performing methods, and that all alternatives have significant risks of substantial misclassification. The study highlights the potential of LLMs as a scalable tool for public health professionals to quickly gauge public opinion on health policies and interventions, offering an efficient alternative to traditional data analysis methods. With the continuous advancement in LLM development, the integration of these models into public health surveillance systems could substantially improve our ability to monitor and respond to changing public health attitudes.Authors summaryWe examined how Large Language Models (LLMs), including GPT models and open-source versions, can analyse online discussions about vaccination from social media. Using a dataset with expert-checked posts, we tested various LLMs and a sentiment analysis tool to identify public stance towards vaccination. Our findings suggest that using LLMs, and prompting them with labelled examples, is the most effective approach. The results show that LLMs are a valuable resource for public health experts to quickly understand the dynamics of public attitudes towards health policies and interventions, providing a faster and efficient option compared to traditional methods. As LLMs continue to improve, incorporating these models into digital public health monitoring could greatly improve how we observe and react to dynamics in public health discussions.",
        "link": "http://dx.doi.org/10.1101/2024.02.06.24302383"
    },
    {
        "id": 10294,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Malliga Subramanian",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/v4sda7"
    },
    {
        "id": 10295,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Sivaji Bandyopadhyay",
        "published": "2023-10-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/xjupog"
    },
    {
        "id": 10296,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Zohreh Saadati",
        "published": "2023-9-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/6pqmq4"
    },
    {
        "id": 10297,
        "title": "Six-Tier Architecture for AI-Generated Software Development: A Large Language Models Approach",
        "authors": "Waqas Uzair, Sameen Naz",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nIn the intersection of Artificial Intelligence (AI) and automated software engineering , there is an abundant potential to reimagine traditional practices and enhance operational efficiency. This paper presents the Six-Tier Architecture for AI-Generated Software Development, an innovative framework built upon the theoretical foundations of automated software engineering. This framework leverages large language models (LLMs) to perform tasks across the software development lifecycle, from high-level abstraction to detailed code generation, thereby systematically improving the automation level of software development. A key aspect of this architecture is the integrated iterative refinement process, which ensures system consistency and enables effective modifications in response to emerging changes. By utilizing the capabilities of LLMs in automated code generation , the Six-Tier Architecture offers a robust, flexible, and dynamic approach to AI-assisted software engineering, illustrating a substantial resilience to the intrinsic changes in software development requirements and processes.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3086026/v1"
    },
    {
        "id": 10298,
        "title": "Fine-tuning Large Language Models for Rare Disease Concept Normalization",
        "authors": "Andy Wang, Cong Liu, Jingye Yang, Chunhua Weng",
        "published": "No Date",
        "citations": 0,
        "abstract": "Objective: We aim to develop a solution for rare disease concept normalization based on fine-tuning LLaMA 2, an open-source large language model (LLM), using a domain-specific corpus. Methods and Materials: We fine-tuned four LLaMA2 models, each comprising seven billion parameters, using sentences incorporating clinical concepts from the HPO and OMIM vocabularies. The fine-tuning was conducted on four NVIDIA A100 GPUs. Results: All models proved resilient to newly prompt-engineered sentences not used in the fine-tuning, achieved nearly perfect accuracies when prompted with original training data, and exhibit some robustness to typos. We tested each model on concepts they had not been trained on. The non-synonym HPO model fine-tuned without synonyms achieved 25.2% accuracy, while the synonym HPO model, fine-tuned with half the synonyms, achieved 85.6% accuracy. When tested against concept synonyms from SNOMED-CT, the non-synonym model achieved an accuracy of 33.9% while the synonym model improved to 57.4%. Synonyms proved challenging to both non-synonym and synonym OMIM models. ChatGPT 3.5 correctly identified HPO IDs for four out of 20 prompts. Discussion: Our increasingly fine-tuned models demonstrated growing robustness to challenges such as misspellings, synonyms, and concepts from other ontologies. Incorrect outputs stem from tokens in the input that the models have never encountered, such as parenthesis. Many synonyms do not share the same semantic meaning and often include abbreviations. Conclusion: Our fine-tuned LLaMA 2 models provide the capability to identify variations in medical concepts from clinical narratives while successfully normalizing them to a standard concept.",
        "link": "http://dx.doi.org/10.1101/2023.12.28.573586"
    },
    {
        "id": 10299,
        "title": "Implications of ChatGPT and Large Language Models for Environmental Policymaking",
        "authors": "Andrew Gao",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4499643"
    },
    {
        "id": 10300,
        "title": "Paraphrasing with Large Language Models",
        "authors": "Sam Witteveen, Martin Andrews",
        "published": "2019",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-5623"
    },
    {
        "id": 10301,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Juris Rāts",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/dskt1s"
    },
    {
        "id": 10302,
        "title": "Fine-tuning Large Language Models for Rare Disease Concept Normalization",
        "authors": "Andy Wang, Cong Liu, Jingye Yang, Chunhua Weng",
        "published": "No Date",
        "citations": 0,
        "abstract": "Objective: We aim to develop a solution for rare disease concept normalization based on fine-tuning LLaMA 2, an open-source large language model (LLM), using a domain-specific corpus. Methods and Materials: We fine-tuned four LLaMA2 models, each comprising seven billion parameters, using sentences incorporating clinical concepts from the HPO and OMIM vocabularies. The fine-tuning was conducted on four NVIDIA A100 GPUs. Results: All models proved resilient to newly prompt-engineered sentences not used in the fine-tuning, achieved nearly perfect accuracies when prompted with original training data, and exhibit some robustness to typos. We tested each model on concepts they had not been trained on. The non-synonym HPO model fine-tuned without synonyms achieved 25.2% accuracy, while the synonym HPO model, fine-tuned with half the synonyms, achieved 85.6% accuracy. When tested against concept synonyms from SNOMED-CT, the non-synonym model achieved an accuracy of 33.9% while the synonym model improved to 57.4%. Synonyms proved challenging to both non-synonym and synonym OMIM models. ChatGPT 3.5 correctly identified HPO IDs for four out of 20 prompts. Discussion: Our increasingly fine-tuned models demonstrated growing robustness to challenges such as misspellings, synonyms, and concepts from other ontologies. Incorrect outputs stem from tokens in the input that the models have never encountered, such as parenthesis. Many synonyms do not share the same semantic meaning and often include abbreviations. Conclusion: Our fine-tuned LLaMA 2 models provide the capability to identify variations in medical concepts from clinical narratives while successfully normalizing them to a standard concept.",
        "link": "http://dx.doi.org/10.1101/2023.12.28.573586"
    },
    {
        "id": 10303,
        "title": "Paraphrasing with Large Language Models",
        "authors": "Sam Witteveen, Martin Andrews",
        "published": "2019",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-5623"
    },
    {
        "id": 10304,
        "title": "Implications of ChatGPT and Large Language Models for Environmental Policymaking",
        "authors": "Andrew Gao",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4499643"
    },
    {
        "id": 10305,
        "title": "Variability in Large Language Models’ Responses to Medical Licensing and Certification Examinations. Comment on “How Does ChatGPT Perform on the United States Medical Licensing Examination? The Implications of Large Language Models for Medical Education and Knowledge Assessment”",
        "authors": "Richard H Epstein, Franklin Dexter",
        "published": "2023-7-13",
        "citations": 8,
        "abstract": "",
        "link": "http://dx.doi.org/10.2196/48305"
    },
    {
        "id": 10306,
        "title": "Experimenting with Planning and Reasoning in Ad Hoc Teamwork Environments with Large Language Models",
        "authors": "Polyana Costa, Pedro Santos, José Boaro, Daniel Moraes, Júlio Duarte, Sergio Colcher",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012472600003636"
    },
    {
        "id": 10307,
        "title": "This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models",
        "authors": "Iker García-Ferrero, Begoña Altuna, Javier Alvez, Itziar Gonzalez-Dios, German Rigau",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.531"
    },
    {
        "id": 10308,
        "title": "Assessing the Utility of Multimodal Large Language Models (GPT-4 Vision and Large Language and Vision Assistant) in Identifying Melanoma Across Different Skin Tones",
        "authors": "Katrina Cirone, Mohamed Akrout, Latif Abid, Amanda Oakley",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "The large language models GPT-4 Vision and Large Language and Vision Assistant are capable of understanding and accurately differentiating between benign lesions and melanoma, indicating potential incorporation into dermatologic care, medical research, and education.",
        "link": "http://dx.doi.org/10.2196/55508"
    },
    {
        "id": 10309,
        "title": "Machine recognition of non-native speech: Task-specific language models versus large language models",
        "authors": "Jian Cheng, Jared C. Bernstein, Masanori Suzuki",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "Automatic speech recognition (ASR) has offered a reliable foundation for measurement of young children’s reading skills and of second-language (L2) speaking skills. This is because well-fit task-specific language models (LMs) enable recognition that supports accurate scoring of pronunciation, fluency, vocabulary, usage, and grammar (Bernstein and Cheng, 2023). ASR works well in these measurement tasks because measurement of word production, disfluencies, and pronunciation errors is not very sensitive to moderate differences in word-error-rate (WER) accuracy, and because speech-interactive tasks appropriate for reading instruction or L2 assessment elicit relatively predictable responses, for which task-specific low-perplexity ASR systems achieve sufficiently accurate speech recognition (Cheng and Townshend, 2003). In the work reported here, we compared the accuracy of two English ASR systems on a set of 718 extended spontaneous speech recordings from 77 adult non-native speakers of English speaking from six countries under uncontrolled recording conditions. A Kaldi-based ASR system with well-fit task-specific LMs achieved WER 17%, while USM, a general-purpose mSLAM recognizer with an RNN-T decoder, achieved 11% WER, which is a 34% relative improvement. The mSLAM + RNN-T technology will be briefly described and an analysis of results in three different open-response interactive speaking tasks will be presented.",
        "link": "http://dx.doi.org/10.1121/10.0023275"
    },
    {
        "id": 10310,
        "title": "A Holistic Assessment of the Carbon Footprint of Noor, a Very Large Arabic Language Model",
        "authors": "Imad Lakim, Ebtesam Almazrouei, Ibrahim Abualhaol, Merouane Debbah, Julien Launay",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bigscience-1.8"
    },
    {
        "id": 10311,
        "title": "Prompting is not a substitute for probability measurements in large language models",
        "authors": "Jennifer Hu, Roger Levy",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.306"
    },
    {
        "id": 10312,
        "title": "Semantic-Oriented Unlabeled Priming for Large-Scale Language Models",
        "authors": "Yanchen Liu, Timo Schick, Hinrich Schtze",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.sustainlp-1.2"
    },
    {
        "id": 10313,
        "title": "ClusterLLM: Large Language Models as a Guide for Text Clustering",
        "authors": "Yuwei Zhang, Zihan Wang, Jingbo Shang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.858"
    },
    {
        "id": 10314,
        "title": "Lion: Adversarial Distillation of Proprietary Large Language Models",
        "authors": "Yuxin Jiang, Chunkit Chan, Mingyang Chen, Wei Wang",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.189"
    },
    {
        "id": 10315,
        "title": "Med-HALT: Medical Domain Hallucination Test for Large Language Models",
        "authors": "Ankit Pal, Logesh Kumar Umapathi, Malaikannan Sankarasubbu",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-1.21"
    },
    {
        "id": 10316,
        "title": "Learning How to Use Large Language Models for Empirical Legal Research",
        "authors": "Edward Stiglitz",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4628573"
    },
    {
        "id": 10317,
        "title": "Enterprise Large Language Models: Knowledge Characteristics, Risks and Organizational Activities",
        "authors": "Daniel E. O'Leary",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4659476"
    },
    {
        "id": 10318,
        "title": "A Framework for the Evaluation of Large Language Models",
        "authors": "Miquel Noguer i Alonso",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4649866"
    },
    {
        "id": 10319,
        "title": "IoT Device Classification Using Link-Level Features for Traditional Machine Learning and Large Language Models",
        "authors": "Gabriel Morales, Farhan Romit, Adam Bienek-Parrish, Patrick Jenkins, Rocky Slavin",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012365700003648"
    },
    {
        "id": 10320,
        "title": "Driving and suppressing the human language network using large language models",
        "authors": "Greta Tuckute, Aalok Sathe, Shashank Srikant, Maya Taliaferro, Mingye Wang, Martin Schrimpf, Kendrick Kay, Evelina Fedorenko",
        "published": "No Date",
        "citations": 8,
        "abstract": "AbstractTransformer models such as GPT generate human-like language and are highly predictive of human brain responses to language. Here, using fMRI-measured brain responses to 1,000 diverse sentences, we first show that a GPT-based encoding model can predict the magnitude of brain response associated with each sentence. Then, we use the model to identify new sentences that are predicted to drive or suppress responses in the human language network. We show that these model-selected novel sentences indeed strongly drive and suppress activity of human language areas in new individuals. A systematic analysis of the model-selected sentences reveals that surprisal and well-formedness of linguistic input are key determinants of response strength in the language network. These results establish the ability of neural network models to not only mimic human language but also noninvasively control neural activity in higher-level cortical areas, like the language network.",
        "link": "http://dx.doi.org/10.1101/2023.04.16.537080"
    },
    {
        "id": 10321,
        "title": "BRAINTEASER: Lateral Thinking Puzzles for Large Language Models",
        "authors": "Yifan Jiang, Filip Ilievski, Kaixin Ma, Zhivar Sourati",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.885"
    },
    {
        "id": 10322,
        "title": "Microsyntactic Unit Detection usingWord Embedding Models: Experiments on Slavic Languages",
        "authors": "Iuliia Zaitova,  , Irina Stenger, Tania Avgustinova,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_134"
    },
    {
        "id": 10323,
        "title": "Comparing Children and Large Language Models in Word Sense Disambiguation: Insights and Challenges",
        "authors": "Francesco Cabiddu, Mitja Nikolaus, Abdellah Fourtassi",
        "published": "No Date",
        "citations": 0,
        "abstract": "Understanding how children process ambiguous words is a challenge because sense disambiguation depends on sentence context bottom-up and top-down aspects. Here, we seek in- sight into this phenomenon by investigating how such a com- petence might arise in large distributional learners (Transform- ers) that purport to acquire sense representations from lan- guage input in a largely unsupervised fashion. We investigated how sense disambiguation might be achieved using model rep- resentations derived from naturalistic child-directed speech. We tested a large pool of Transformer models, varying in their pretraining input size/nature as well as the size of their param- eter space. Tested across three behavioral experiments from the developmental literature, we found that these models cap- ture some essential properties of child sense disambiguation, although most still struggle in the more challenging tasks with contrastive cues. We discuss implications for both theories of word learning and for using Transformers to capture child lan- guage processing.",
        "link": "http://dx.doi.org/10.31234/osf.io/zgy7v"
    },
    {
        "id": 10324,
        "title": "Benchmarking medical large language models",
        "authors": "Sadra Bakhshandeh",
        "published": "2023-7-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s44222-023-00097-7"
    },
    {
        "id": 10325,
        "title": "Contextualized Sentiment Analysis using Large Language Models",
        "authors": "Christian Breitung, Garvin Kruthof, Sebastian Müller",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4615038"
    },
    {
        "id": 10326,
        "title": "Theory of Mind Performance of Large Language Models: A Comparative Analysis of Turkish and English",
        "authors": "Burcu Unlutabak, Onur Bal",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4694282"
    },
    {
        "id": 10327,
        "title": "Using large language models to study human memory for meaningful narratives",
        "authors": "Antonios Georgiou, Tankut Can, Mikhail Katkov, Misha Tsodyks",
        "published": "No Date",
        "citations": 0,
        "abstract": "ABSTRACTOne of the most impressive achievements of the AI revolution is the development of large language models that can generate meaningful text and respond to instructions in plain English with no additional training necessary. Here we show that language models can be used as a scientific instrument for studying human memory for meaningful material. We developed a pipeline for designing large scale memory experiments and analyzing the obtained results. We performed online memory experiments with a large number of participants and collected recognition and recall data for narratives of different lengths. We found that both recall and recognition performance scale linearly with narrative length. Furthermore, in order to investigate the role of narrative comprehension in memory, we repeated these experiments using scrambled versions of the presented stories. We found that even though recall performance declined significantly, recognition remained largely unaffected. Interestingly, recalls in this condition seem to follow the original narrative order rather than the scrambled presentation, pointing to a contextual reconstruction of the story in memory.",
        "link": "http://dx.doi.org/10.1101/2023.11.03.565484"
    },
    {
        "id": 10328,
        "title": "Circling the Void: Using Heidegger and Lacan to think about Large Language Models",
        "authors": "Marc Heimann, Anne-Friederike Hübener",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe paper aims to unite two currently distinct ways of thinking about and working with language. Large language models and continental philosophy, especially Martin Heidegger's thinking about language and, building on Sigmund Freud, Jacques Lacan's structural psychoanalysis. We show that the concept of language that Heidegger, Freud, and Lacan discussed and utilized in clinical frameworks is quite well matched by modern LLMs. This allows us to discuss a problem of negation and negativity that is central to continental discourse but absent from current LLM research. This also means that we offer a radically different approach than is usual in the philosophy of artificial intelligence, since we base our concepts on thinkers who are often neglected in the discourse of analytic philosophy that is closer to AI research. To this end, we also indicate where the ontological differences of the proposed approach lie. Our aim, however, is to address both AI researchers and continental philosophers.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3023378/v3"
    },
    {
        "id": 10329,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Suha K. Assayed",
        "published": "2023-9-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/ccmdef"
    },
    {
        "id": 10330,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Adrian David Cheok",
        "published": "2023-10-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/1zoqy0"
    },
    {
        "id": 10331,
        "title": "Challenges and Limitations of ChatGPT and Other Large Language Models Challenges",
        "authors": "Erwin Rimban",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4454441"
    },
    {
        "id": 10332,
        "title": "How to write effective prompts for large language models",
        "authors": "Zhicheng Lin",
        "published": "2024-3-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41562-024-01847-2"
    },
    {
        "id": 10333,
        "title": "FinDKG: Dynamic Knowledge Graph with Large Language Models for Global Finance",
        "authors": "Xiaohui Li",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4608445"
    },
    {
        "id": 10334,
        "title": "Large Language Models as Recommendation Systems in Museums",
        "authors": "Georgios Trichopoulos, Markos Konstantakis, Georgios Alexandridis, George Caridakis",
        "published": "No Date",
        "citations": 3,
        "abstract": "This paper proposes the utilization of large language models as recommendations systems for museums. Since the aforementioned models lack the notion of context, they can’t work with temporal information that is often present in recommendations for cultural environments (e.g. special exhibitions or events). In this respect, the current work aims at enhancing the capabilities of large language models through a fine-tuning process that incorporates contextual information and user instructions. The resulting models are expected to be capable of providing personalized recommendations, aligned with user preferences and desires. More specifically, Generative Pre-trained Transformer 4, a knowledge-based large language model is fine-tuned and turned into a context-ware recommendation system, adapting its suggestions based on user input and specific contextual factors such as location, time of visit, and other relevant parameters. The effectiveness of the proposed approach is evaluated through certain user studies, which ensure an improved user experience and engagement within the museum environment.",
        "link": "http://dx.doi.org/10.20944/preprints202307.1393.v1"
    },
    {
        "id": 10335,
        "title": "Evaluating Large Language Models for Assisting in Meta-Analysis",
        "authors": "Feng Ji, Jiayi Han, Yuchen Zhang, Shi’ting Chen, Jinbo He",
        "published": "No Date",
        "citations": 0,
        "abstract": "Large language models (LLMs) are receiving increased attention in academia as aids for scientific research due to their superior performance in tasks related to natural language processing and understanding. Meta-analysis, a research method involving extensive text processing to extract and code qualitative and quantitative information from empirical studies, is particularly well-suited to the application of LLMs. In this study, we empirically evaluated the ability of LLMs to perform automatic coding tasks within meta-analytic contexts, using Bing Chat (based on GPT-4.0) and ChatPDF (based on GPT-3.5) as examples. Our findings indicate that Bing Chat outperformed ChatPDF in accurately extracting and coding qualitative information such as publication type, country, and survey methods. However, its performance decreased when handling quantitative data, such as correlation coefficients. We also noted an upward trend in Bing Chat's performance over time. The potential and utility of LLMs in facilitating meta-analysis from a researcher’s perspective are further discussed.",
        "link": "http://dx.doi.org/10.31234/osf.io/dc6tz"
    },
    {
        "id": 10336,
        "title": "Ten Simple Rules for Crafting Effective Prompts for Large Language Models",
        "authors": "Zhicheng Lin",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4565553"
    },
    {
        "id": 10337,
        "title": "Economic, Societal, Legal, and Ethical Considerations for Large Language Models",
        "authors": "Jay Lofstead",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/transai60598.2023.00049"
    },
    {
        "id": 10338,
        "title": "Large Language Models and the Shoreline of Ophthalmology",
        "authors": "Benjamin K. Young, Peter Y. Zhao",
        "published": "2024-2-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1001/jamaophthalmol.2023.6937"
    },
    {
        "id": 10339,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "James C.L. Chow",
        "published": "2023-9-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/cy80xk"
    },
    {
        "id": 10340,
        "title": "Analogy Generation by Prompting Large Language Models: A Case Study of InstructGPT",
        "authors": "Bhavya Bhavya, Jinjun Xiong, ChengXiang Zhai",
        "published": "2022",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.inlg-main.25"
    },
    {
        "id": 10341,
        "title": "Exploring Genomic Large Language Models: Bridging the Gap between Natural Language and Gene Sequences",
        "authors": "Huaqing Liu, Shuxian Zhou, Peiyi Chen, Jiahui Liu, Ku-Geng Huo, Lanqing Han",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractMotivationWith the rapid development of genomic sequencing technologies and accumulation of sequencing data, there is an increasing demand for analysis tools that are more user-friendly for non-programmer users. In support of this initiative, we developed an all-in-one tool called GenomicLLM that can understand simple grammar in the question input and perform different types of analyses and tasks accordingly.ReaultsWe trained the GenomicLLM model using three large open-access datasets, namely GenomicLLM_GRCh38, Genome Understanding Evaluation and GenomicBenchmarks, and developed a hybrid tokenization approach to allow better comprehension from mixed corpora that include sequence and non-sequence inputs. GenomicLLM can carry out a wider range of tasks. In the classification tasks that are also available in the state-of-the-art DNABERT-2 and HyenaDNA, GenomicLLM has comparable performance. Moreover, GenomicLLM can also carry out other regression and generation tasks that are not accomplishable by these tools. In summary, we demonstrated here a successful large language model with a mixture of gene sequences and natural language corpus that enables a wider range of applications.Availability and implementationCodes and data can be accessed athttps://github.com/Huatsing-Lau/GenomicLLMandhttps://zenodo.org/records/10695802",
        "link": "http://dx.doi.org/10.1101/2024.02.26.581496"
    },
    {
        "id": 10342,
        "title": "SLING: Sino Linguistic Evaluation of Large Language Models",
        "authors": "Yixiao Song, Kalpesh Krishna, Rajesh Bhatt, Mohit Iyyer",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.305"
    },
    {
        "id": 10343,
        "title": "Large Language Models and Security",
        "authors": "Michele Bezzi",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/msec.2023.3345568"
    },
    {
        "id": 10344,
        "title": "Study Tests Large Language Models’ Ability to Answer Clinical Questions",
        "authors": "Emily Harris",
        "published": "2023-8-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1001/jama.2023.12553"
    },
    {
        "id": 10345,
        "title": "Redefining Virtual Assistants in Health Care: The Future With Large Language Models (Preprint)",
        "authors": "Emre Sezgin",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\nThis editorial explores the evolving and transformative role of large language models (LLMs) in enhancing the capabilities of virtual assistants (VAs) in the health care domain, highlighting recent research on the performance of VAs and LLMs in health care information sharing. Focusing on recent research, this editorial unveils the marked improvement in the accuracy and clinical relevance of responses from LLMs, such as GPT-4, compared to current VAs, especially in addressing complex health care inquiries, like those related to postpartum depression. The improved accuracy and clinical relevance with LLMs mark a paradigm shift in digital health tools and VAs. Furthermore, such LLM applications have the potential to dynamically adapt and be integrated into existing VA platforms, offering cost-effective, scalable, and inclusive solutions. These suggest a significant increase in the applicable range of VA applications, as well as the increased value, risk, and impact in health care, moving toward more personalized digital health ecosystems. However, alongside these advancements, it is necessary to develop and adhere to ethical guidelines, regulatory frameworks, governance principles, and privacy and safety measures. We need a robust interdisciplinary collaboration to navigate the complexities of safely and effectively integrating LLMs into health care applications, ensuring that these emerging technologies align with the diverse needs and ethical considerations of the health care domain.\n",
        "link": "http://dx.doi.org/10.2196/preprints.53225"
    },
    {
        "id": 10346,
        "title": "Large Language Models: AI's Legal Revolution",
        "authors": "Adam Allen Bent",
        "published": "2023-12-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.58948/2331-3528.2083"
    },
    {
        "id": 10347,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Joan Vila-Francés",
        "published": "2023-10-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/elpn3d"
    },
    {
        "id": 10348,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Payal B. Joshi",
        "published": "2023-9-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/m1trrn"
    },
    {
        "id": 10349,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Gernel S. Lumacad",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/lp63ir"
    },
    {
        "id": 10350,
        "title": "Datasets for Large Language Models: A Comprehensive Survey",
        "authors": "Yang Liu, Jiahuan Cao, Chongyu Liu, Kai Ding, Lianwen Jin",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThis paper embarks on an exploration into the Large Language Model (LLM) datasets, which play a crucial role in the remarkable advancements of LLMs. The datasets serve as the foundational infrastructure analogous to a root system that sustains and nurtures the development of LLMs. Consequently, examination of these datasets emerges as a critical topic in research. In order to address the current lack of a comprehensive overview and thorough analysis of LLM datasets, and to gain insights into their current status and future trends, this survey consolidates and categorizes the fundamental aspects of LLM datasets from five perspectives: (1) Pre-training Corpora; (2) Instruction Fine-tuning Datasets; (3) Preference Datasets; (4) Evaluation Datasets; (5) Traditional Natural Language Processing (NLP) Datasets. The survey sheds light on the prevailing challenges and points out potential avenues for future investigation. Additionally, a comprehensive review of the existing available dataset resources is also provided, including statistics from 444 datasets, covering 8 language categories and spanning 32 domains. Information from 20 dimensions is incorporated into the dataset statistics. The total data size surveyed surpasses 774.5 TB for pre-training corpora and 700M instances for other datasets. We aim to present the entire landscape of LLM text datasets, serving as a comprehensive reference for researchers in this field and contributing to future studies. Related resources are available at: \\href{https://github.com/lmmlzn/Awesome-LLMs-Datasets}{https://github.com/lmmlzn/Awesome-LLMs-Datasets}.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3996137/v1"
    },
    {
        "id": 10351,
        "title": "Professional Certification Benchmark Dataset: The First 500 Jobs for Large Language Models",
        "authors": "David Noever, Matt Ciolino",
        "published": "2023-7-22",
        "citations": 0,
        "abstract": "The research creates a professional certification survey to test large language models and evaluate their employable skills. It compares the performance of two AI models, GPT-3 and Turbo-GPT3.5, on a benchmark dataset of 1149 professional certifications, emphasizing vocational readiness rather than academic performance. GPT-3 achieved a passing score (>70% correct) in 39% of the professional certifications without fine-tuning or exam preparation. The models demonstrated qualifications in various computer-related fields, such as cloud and virtualization, business analytics, cybersecurity, network setup and repair, and data analytics. Turbo-GPT3.5 scored 100% on the valuable Offensive Security Certified Professional (OSCP) exam. The models also displayed competence in other professional domains, including nursing, licensed counseling, pharmacy, and teaching. Turbo-GPT3.5 passed the Financial Industry Regulatory Authority (FINRA) Series 6 exam with a 70% grade without preparation. Interestingly, Turbo-GPT3.5 performed well on customer service tasks, suggesting potential applications in human augmentation for chatbots in call centers and routine advice services. The models also score well on sensory and experience-based tests such as wine sommelier, beer taster, emotional quotient, and body language reader. The OpenAI model improvement from Babbage to Turbo resulted in a median 60% better-graded performance in less than a few years. This progress suggests that focusing on the latest model's shortcomings could lead to a highly performant AI capable of mastering the most demanding professional certifications. We open-source the benchmark to expand the range of testable professional skills as the models improve or gain emergent capabilities.",
        "link": "http://dx.doi.org/10.5121/csit.2023.131211"
    },
    {
        "id": 10352,
        "title": "You are what you're for: Essentialist categorization in large language models",
        "authors": "Siying Zhang, Selena She, Tobias Gerstenberg, David Rose",
        "published": "No Date",
        "citations": 2,
        "abstract": "How do essentialist beliefs about categories arise? We hypothesize that such beliefs are transmitted via language. We subject large language models (LLMs) to vignettes from the literature on essentialist categorization and find that they align well with people when the studies manipulated teleological information – information about what something is for. We examine whether in a classic test of essentialist categorization – the transformation task – LLMs prioritize teleological properties over information about what something looks like, or is made of. Experiments 1 and 2 find that telos and what something is made of matter more than appearance. Experiment 3 manipulates all three factors and finds that what something is for matters more than what it’s made of. Overall, these studies suggest that language alone may be sufficient to give rise to essentialist beliefs, and that information about what something is for matters more.",
        "link": "http://dx.doi.org/10.31234/osf.io/ypw5r"
    },
    {
        "id": 10353,
        "title": "Should ChatGPT be biased? Challenges and risks of bias in large language models",
        "authors": "Emilio Ferrara",
        "published": "2023-11-7",
        "citations": 7,
        "abstract": "As generative language models, exemplified by ChatGPT, continue to advance in their capabilities, the spotlight on biases inherent in these models intensifies. This paper delves into the distinctive challenges and risks associated with biases specifically in large-scale language models. We explore the origins of biases, stemming from factors such as training data, model specifications, algorithmic constraints, product design, and policy decisions. Our examination extends to the ethical implications arising from the unintended consequences of biased model outputs. In addition, we analyze the intricacies of mitigating biases, acknowledging the inevitable persistence of some biases, and consider the consequences of deploying these models across diverse applications, including virtual assistants, content generation, and chatbots. Finally, we provide an overview of current approaches for identifying, quantifying, and mitigating biases in language models, underscoring the need for a collaborative, multidisciplinary effort to craft AI systems that embody equity, transparency, and responsibility. This article aims to catalyze a thoughtful discourse within the AI community, prompting researchers and developers to consider the unique role of biases in the domain of generative language models and the ongoing quest for ethical AI.",
        "link": "http://dx.doi.org/10.5210/fm.v28i11.13346"
    },
    {
        "id": 10354,
        "title": "Large Language Models and Generative AI, Oh My!",
        "authors": "Michael Zyda",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mc.2024.3350290"
    },
    {
        "id": 10355,
        "title": "Correction: Large Language Models in Medicine",
        "authors": "",
        "published": "2024-3-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7326/l24-0048"
    },
    {
        "id": 10356,
        "title": "Large Language Models are few(1)-shot Table Reasoners",
        "authors": "Wenhu Chen",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-eacl.83"
    },
    {
        "id": 10357,
        "title": "ParrotGPT: On the Advantages of Large Language Models Tools for Academic Metadata Schema Mapping",
        "authors": "Kristian Garza",
        "published": "No Date",
        "citations": 0,
        "abstract": "Creating Crosswalk with chatGPT Plus. Image partially created with Dall-e Picture, if you will, the labyrinthine world of academic information management, where metadata schema mapping serves as a vital underpinning for the exchange and intermingling of data across diverse platforms and systems.",
        "link": "http://dx.doi.org/10.59350/hs9k1-wn031"
    },
    {
        "id": 10358,
        "title": "Assessing Large Language Models in Mechanical Engineering Education: A Study on Mechanics-Focused Conceptual Understanding",
        "authors": "Jixin Hou",
        "published": "No Date",
        "citations": 0,
        "abstract": "This study is a pioneering endeavor to investigate the capabilities of Large Language Models (LLMs) in addressing conceptual questions within the domain of mechanical engineering with a focus on mechanics. Our examination involves a manually crafted exam encompassing 126 multiple-choice questions, spanning various aspects of mechanics courses, including Fluid Mechanics, Mechanical Vibration, Engineering Statics and Dynamics, Mechanics of Materials, Theory of Elasticity, and Continuum Mechanics. Three LLMs, including ChatGPT (GPT-3.5), ChatGPT (GPT-4), and Claude (Claude-2.1), were subjected to evaluation against engineering faculties and students with/without mechanical engineering background. The findings reveal GPT-4’s superior performance over the other two LLMs and human cohorts in answering questions across various mechanics topics, except for Continuum Mechanics. This signals the potential future improvements for GPT models in handling symbolic calculations and tensor analyses. The performances of LLMs were all significantly improved with explanations prompted prior to direct responses, underscoring the crucial role of prompt engineering. Interestingly, GPT-3.5 demonstrates improved performance with prompts covering a broader domain, while GPT-4 excels with prompts focusing on specific subjects. Finally, GPT-4 exhibits notable advancements in mitigating input bias, as evidenced by guessing preferences for humans. This study unveils the substantial potential of LLMs as highly knowledgeable assistants in both mechanical pedagogy and scientific research.",
        "link": "http://dx.doi.org/10.31219/osf.io/d3nc6"
    },
    {
        "id": 10359,
        "title": "Artificial Intelligence in Dental Education: Opportunities and Challenges of Large Language Models (Preprint)",
        "authors": "Daniel Claman, Emre Sezgin",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\nInstructional and clinical technologies have been transforming dental education. With the emergence of artificial intelligence (AI), the opportunities of utilizing AI in education has increased. With the recent advancement of generative AI, Large Language Models (LLMs) gained attention with their capabilities in natural language understanding and generation. A common example has been ChatGPT, which is based on a powerful LLM, generative pretrained transformer (GPT) model. This article discusses the potential benefits and challenges of incorporating LLMs in dental education, focusing on periodontal charting with a use case to outline capabilities of LLMs. LLMs can provide personalized feedback, generate case scenarios, and create educational content to contribute to the quality of dental education. However, challenges, limitations and risks exist, including bias and inaccuracy in the content created, privacy and security concerns, and the risk of overreliance. With the guidance and oversight, and by effectively and ethically integrating LLMs, dental education can incorporate engaging and personalized learning experiences for students towards readiness for real-life clinical practice.\n",
        "link": "http://dx.doi.org/10.2196/preprints.52346"
    },
    {
        "id": 10360,
        "title": "Prepare for truly useful large language models",
        "authors": "",
        "published": "2023-3-7",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41551-023-01012-6"
    },
    {
        "id": 10361,
        "title": "Large language models show human-like content biases in transmission chain experiments",
        "authors": "Alberto Acerbi, Joseph Michael Stubbersfield",
        "published": "No Date",
        "citations": 1,
        "abstract": "As the use of Large Language Models (LLMs) grows, it is important to examine if they exhibit biases in their output. Research in Cultural Evolution, using transmission chain experiments, demonstrates that humans have biases to attend to, remember, and transmit some types of content over others. Here, in five pre-registered experiments with the same methodology, we find that the LLM chatGPT-3 shows biases analogous to humans for content that is gender-stereotype consistent, social, negative, threat-related, and biologically counterintuitive, over other content. The presence of these biases in LLM output suggests that such content is widespread in its training data, and could have consequential downstream effects, by magnifying pre-existing human tendencies for cognitively appealing, and not necessarily informative, or valuable, content.",
        "link": "http://dx.doi.org/10.31219/osf.io/8zg4d"
    },
    {
        "id": 10362,
        "title": "Exploring the use cases and limitations of large language models in the biomedical and clinical tasks",
        "authors": "Ahmad Albarqawi",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe development of large language models (LLMs) in recent years has shown several opportunities for improving the medical sector and processing unstructured electronic medical records. Despite the potential of these models, their application in the biomedical and clinical fields needs to comply with regulations and mitigate existing biases, nonfactual information generation, and any potential privacy concerns. Successful implementations of LLMs need an understanding of their use cases and limitations for strategies to revolutionize the healthcare industry and operations. This research does an exhaustive assessment of the published biomedical and clinical language models to comprehend the current problems, explore the best methods for overcoming the constraints and get the models suitable for use in regulated conditions.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2401418/v2"
    },
    {
        "id": 10363,
        "title": "Ai-Chatbots for Agriculture - Where Can Large Language Models Provide Substantial Value?",
        "authors": "Matheus  Thomas Kuska, Mirwaes Wahabzada, Stefan Paulus",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4685971"
    },
    {
        "id": 10364,
        "title": "Do Large Language Models Understand Us?",
        "authors": "Blaise Agüera y Arcas",
        "published": "2022-5-1",
        "citations": 18,
        "abstract": "Abstract\nLarge language models (LLMs) represent a major advance in artificial intelligence and, in particular, toward the goal of human-like artificial general intelligence. It is sometimes claimed, though, that machine learning is “just statistics,” hence that, in this grander ambition, progress in AI is illusory. Here I take the contrary view that LLMs have a great deal to teach us about the nature of language, understanding, intelligence, sociality, and personhood. Specifically: statistics do amount to understanding, in any falsifiable sense. Furthermore, much of what we consider intelligence is inherently dialogic, hence social; it requires a theory of mind. Complex sequence learning and social interaction may be a sufficient basis for general intelligence, including theory of mind and consciousness. Since the interior state of another being can only be understood through interaction, no objective answer is possible to the question of when an “it” becomes a “who,” but for many people, neural nets running on computers are likely to cross this threshold in the very near future.",
        "link": "http://dx.doi.org/10.1162/daed_a_01909"
    },
    {
        "id": 10365,
        "title": "STOCK SENTIMENT ANALYSIS USING LARGE LANGUAGE MODELS",
        "authors": "",
        "published": "2024-3-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.56726/irjmets49682"
    },
    {
        "id": 10366,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Andreas F. Gontzis",
        "published": "2023-10-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/de4xao"
    },
    {
        "id": 10367,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Bijay Kumar Paikaray",
        "published": "2023-10-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/kbn4ay"
    },
    {
        "id": 10368,
        "title": "Diagram-based Input for Large Language Models to Support Accessible STEM Learning",
        "authors": "Sarah E. Wegwerth, Alexa Urrea, Julia Winter",
        "published": "No Date",
        "citations": 0,
        "abstract": "To meet the accessibility needs of students who are blind or have low vision (BLV), detailed textual descriptions of STEM diagrams within interactive learning tools are cre-ated in real-time and correspond to the configurations of the interactive software system. The descriptions are read by screen readers as alternative (alt) text to provide infor-mation for BLV students to compose mental representa-tions of the diagram. These descriptions provide a unique bridge from the visual language of STEM diagrams to natural language of Large Language Models (LLMs). By interfacing with an LLM, these descriptions are used for personalized exploration by the BLV user and to guide all learners through a defined pedagogical pathway. Results from a usability study with four BLV adults are reported.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2023-r1qn9"
    },
    {
        "id": 10369,
        "title": "ActuaryGPT: Applications of Large Language Models to Insurance and Actuarial Work",
        "authors": "Caesar Balona",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4543652"
    },
    {
        "id": 10370,
        "title": "Exploring the Pitfalls of Large Language Models: Inconsistency and Inaccuracy in Answering Pathology Board Examination-Style Questions",
        "authors": "Shunsuke Koga",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractIn the rapidly advancing field of artificial intelligence, large language models (LLMs) such as ChatGPT and Google Bard are making significant progress, with applications extending across various fields, including medicine. This study explores their potential utility and pitfalls by assessing the performance of these LLMs in answering 150 multiple-choice questions, encompassing 15 subspecialties in pathology, sourced from thePathologyOutlines.comQuestion Bank, a resource for pathology examination preparation. Overall, ChatGPT outperformed Google Bard, scoring 122 out of 150, while Google Bard achieved a score of 70. Additionally, we explored the consistency of these LLMs by applying a test-retest approach over a two-week interval. ChatGPT showed a consistency rate of 85%, while Google Bard exhibited a consistency rate of 61%. In-depth analysis of incorrect responses identified potential factual inaccuracies and interpretive errors. While LLMs have potential to enhance medical education and assist clinical decision-making, their current limitations underscore the need for continued development and the critical role of human expertise in the application of such models.",
        "link": "http://dx.doi.org/10.1101/2023.08.03.23293401"
    },
    {
        "id": 10371,
        "title": "InteraSSort : Interactive Assortment Planning Using Large Language Models",
        "authors": "Saketh reddy Karra, Theja Tulabandhula",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4647359"
    },
    {
        "id": 10372,
        "title": "Academic Publishing web forms meet your demise: The unstoppable rise of large language models…",
        "authors": "Kristian Garza",
        "published": "No Date",
        "citations": 0,
        "abstract": "<strong> Academic Publishing web forms meet your demise: The unstoppable rise of large language models (ChatGPT)</strong> Prompt to create DOI metadata using ChatGPT. As we enter the age of artificial intelligence, it’s worth considering how large language models will revolutionize how we interact with websites and applications.",
        "link": "http://dx.doi.org/10.59350/ye9qe-fm404"
    },
    {
        "id": 10373,
        "title": "Circling the Void: Using Heidegger and Lacan to think about Large Language Models",
        "authors": "Marc Heimann, Anne-Friederike Hübener",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThis essay bridges two disparate lines of inquiry: Large Language Models (LLMs) and continental philosophy, specifically Martin Heidegger's reflections on language and Jacques Lacan's structural psychoanalysis grounded in Sigmund Freud's theories. We argue that the linguistic conceptualizations put forth by Heidegger, Freud, and Lacan, primarily employed in clinical frameworks, find surprising resonance in the operations of modern LLMs. This parallel allows us to bring into focus a central theme of continental discourse—negation and negativity—largely absent in current LLM research. Our approach diverges radically from conventional philosophy of artificial intelligence, which primarily engages with analytic philosophy. Here, we build our discourse on thinkers often overlooked in this field, delineating the ontological differences of our approach. Our goal is to foster a dialogue between AI researchers and continental philosophers, highlighting the mutual insights that these two distinct perspectives can offer.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3023378/v1"
    },
    {
        "id": 10374,
        "title": "Circling the Void: Using Heidegger and Lacan to think about Large Language Models",
        "authors": "Marc Heimann, Anne-Friederike Hübener",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe essay aims to unite two currently distinct lines of thinking and working with language. Large Language Models and continental philosophy, especially Martin Heidegger’s thinking about language and, building upon Sigmund Freud, Jaques Lacan’s structural psychoanalysis. We show that the concept of language that Heidegger, Freud and Lacan discuss and utilize in clinical frameworks is matched quite strongly by modern LLMs. This allows us to discuss a problem of negation and negativity that is central to the continental discourse but missing in current LLM research. This also means that we offer a radically different approach than it is usual in the philosophy of artificial intelligence, since we base our concepts on thinkers that are often disregarded in the analytic philosophy discourse that is closer linked to AI research. To this end we also mark, where the ontological differences of the proposed approach lie. However, our aim is to address AI researcher and continental philosophers.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3023378/v2"
    },
    {
        "id": 10375,
        "title": "Benefits and Harms of Large Language Models in Digital Mental Health",
        "authors": "Munmun De Choudhury, Sachin R Pendse, Neha Kumar",
        "published": "No Date",
        "citations": 0,
        "abstract": "The past decade has been transformative for mental health research and practice. The ability to harness large repositories of data, whether from electronic health records (EHR), mobile devices, or social media, has revealed a potential for valuable insights into patient experiences, promising early, proactive interventions, as well as personalized treatment plans. Recent developments in generative artificial intelligence, particularly large language models (LLMs), show promise in leading digital mental health to uncharted territory. Patients are arriving at doctors' appointments with information sourced from chatbots, state-of-the-art LLMs are being incorporated in medical software and EHR systems, and chatbots from an ever-increasing number of startups promise to serve as AI companions, friends, and partners. This article presents contemporary perspectives on the opportunities and risks posed by LLMs in the design, development, and implementation of digital mental health tools. We adopt an ecological framework and draw on the affordances offered by LLMs to discuss four application areas---care-seeking behaviors from individuals in need of care, community care provision, institutional and medical care provision, and larger care ecologies at the societal level. We engage in a thoughtful consideration of whether and how LLM-based technologies could or should be employed for enhancing mental health. The benefits and harms our article surfaces could serve to help shape future research, advocacy, and regulatory efforts focused on creating more responsible, user-friendly, equitable, and secure LLM-based tools for mental health treatment and intervention.",
        "link": "http://dx.doi.org/10.31234/osf.io/y8ax9"
    },
    {
        "id": 10376,
        "title": "Text and knowledge in the aspect of large language models",
        "authors": "Boris Valer'evich Orekhov",
        "published": "2023-4",
        "citations": 0,
        "abstract": "\n The focus of this text is on the influence of large linguistic models on the self-determination of the humanities. Large language models are able to generate plausible texts. It seems that they thus become on a par with other tools that, throughout the development of technology have freed people from routine. At the same time, for the humanities, the individualization of the generated texts is very great, and knowledge itself is closely related to its textual embodiment. If we agree that knowledge is a text, and embodied in another text, another knowledge appears before us, then humanities will have to answer the question of how a text generated by a person differs in value from the same text generated by a machine. The text of the work raises methodological and epistemological problems of the correlation of texts of natural and artificial origin if they are made in the genre of a scientific work. The difference between such artifacts is clearly visible only for some scientific disciplines, and raises questions about the rest. These issues should be resolved with the help of deep reflection, which was not so urgently needed in the last centuries of the development of the humanities, but which is now required from a humanitarian scientist. The humanitarian will have to explicitly oppose himself to large language models and prove the importance of his work compared to what a neural network can generate.\n\t",
        "link": "http://dx.doi.org/10.7256/2585-7797.2023.4.44180"
    },
    {
        "id": 10377,
        "title": "Red Teaming for Multimodal Large Language Models: A Survey",
        "authors": "Moushumi Mahato, Avinash Kumar, Kartikey Singh, Bhavesh Kukreja, Javaid Nabi",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36227/techrxiv.170629758.87975697/v1"
    },
    {
        "id": 10378,
        "title": "GPT-4 aligns with the New Liberal Party, while other large language models refuse to answer political questions",
        "authors": "Michael King",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31224/2974"
    },
    {
        "id": 10379,
        "title": "Can Large Language Models be sensitive to Culture Suicide Risk Assessment?",
        "authors": "Inbar Levkovich, Shiri Shinan-Altman, Zohar Elyoseph",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nSuicide remains a pressing global public health issue. Previous studies have shown the promise of Generative Intelligent (GenAI) Large Language Models (LLMs) in assessing suicide risk in relation to professionals. But the considerations and risk factors that the models use to assess the risk remain as a black box. This study investigates if ChatGPT-3.5 and ChatGPT-4 integrate cultural factors in assessing suicide risks (probability of suicidal ideation, potential for suicide attempt, likelihood of severe suicide attempt, and risk of mortality from a suicidal act) by vignette methodology. The vignettes examined were of individuals from Greece and South Korea, representing countries with low and high suicide rates, respectively. The contribution of this research is to examine risk assessment from an international perspective, as large language models are expected to provide culturally-tailored responses. However, there is a concern regarding cultural biases and racism, making this study crucial. In the evaluation conducted via ChatGPT-4, only the risks associated with a severe suicide attempt and potential mortality from a suicidal act were rated higher for the South Korean characters than for their Greek counterparts. Furthermore, only within the ChatGPT-4 framework was male gender identified as a significant risk factor, leading to a heightened risk evaluation across all variables. ChatGPT models exhibit significant sensitivity to cultural nuances. ChatGPT-4, in particular, offers increased sensitivity and reduced bias, highlighting the importance of gender differences in suicide risk assessment.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-4066705/v1"
    },
    {
        "id": 10380,
        "title": "R3 Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context",
        "authors": "Qingyuan Tian, Hanlun Zhu, Lei Wang, Yang Li, Yunshi Lan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.114"
    },
    {
        "id": 10381,
        "title": "Generative Models For Indic Languages: Evaluating Content Generation Capabilities",
        "authors": "Savita Bhat,  , Vasudeva Varma, Niranjan Pedanekar,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_021"
    },
    {
        "id": 10382,
        "title": "Exploring The Prospects And Challenges Of Large Language Models For Language Learning And Production",
        "authors": "Anna M. Borghi, Chiara De Livio, Francesco Mannella, Luca Tummolini, Stefano Nolfi",
        "published": "No Date",
        "citations": 0,
        "abstract": "The success of Large Language Models (LLMs) in many application domains suggests that they may also change how we conceive cognition. LLMs possess capabilities traditionally considered exclusively human. Can the experience with language alone facilitate the acquisition of other complex cognitive abilities? Do linguistic, sensorimotor, and interoceptive experiences need to be integrated? Are there domains, like that of abstract concepts (e.g., freedom), where linguistic experience suffices to capture meaning? After introducing what LLMs are, we address their potential impact, discussing five differences from human cognition: they are not grounded, lack action, hardly capture pragmatics, are culturally biased, and do not reflect individual characteristics.",
        "link": "http://dx.doi.org/10.31219/osf.io/zw8q9"
    },
    {
        "id": 10383,
        "title": "The use of a large language models to create plain language summaries of evidence reviews in healthcare: a feasibility study",
        "authors": "Colleen Ovelman, Shannon Kugley, Gerald Gartlehner, Meera Viswanathan",
        "published": "No Date",
        "citations": 0,
        "abstract": "Introduction: Plain language summaries (PLSs) make complex healthcare\nevidence accessible to patients and the public. Large language models\n(LLMs) may assist in generating accurate, readable PLSs. This study\nexplored using the LLM Claude 2 to create PLSs of evidence reviews from\nthe Agency for Healthcare Research and Quality (AHRQ) Effective Health\nCare Program. Methods: We selected 10 evidence reviews published from\n2021-2023, representing a range of methods and topics. We iteratively\ndeveloped a prompt to guide Claude 2 in creating PLSs which included\nspecifications for plain language, reading level, length, organizational\nstructure, active voice, and inclusive language. PLSs were assessed for\nadherence to prompt specifications, comprehensiveness, accuracy,\nreadability, and cultural sensitivity. Results: All PLSs met the word\ncount. We judged one PLS as fully comprehensive; 7 mostly comprehensive.\nWe judged 2 PLSs as fully capturing the PICO elements; 5 with minor PICO\nerrors. We judged 3 PLSs as accurately reporting the results; 4 with\nminor result errors. We judged 3 PLSs as having major result errors for\nincorrectly reporting total participants. Five PLSs met the target\n6th-8th grade reading level. Passive voice use averaged 16%. All PLSs\nused inclusive language. Conclusions: LLMs show promise for assisting in\nPLS creation but likely require human input to ensure accuracy,\ncomprehensiveness, and the appropriate nuances of interpretation.\nIterative prompt refinement may improve results and address the needs of\nspecific reviews and audiences. As text-only summaries, the AI-generated\nPLSs could not meet all consumer communication criteria, such as textual\ndesign and visual representations. Further testing should explore how to\nbest leverage LLM support in drafting PLS text for complex evidence\nreviews.",
        "link": "http://dx.doi.org/10.22541/au.169945431.17722628/v1"
    },
    {
        "id": 10384,
        "title": "ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language Models",
        "authors": "Dheeraj Mekala, Jason Wolfe, Subhro Roy",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.354"
    },
    {
        "id": 10385,
        "title": "Understanding the Effect of Model Compression on Social Bias in Large Language Models",
        "authors": "Gustavo Gonçalves, Emma Strubell",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.161"
    },
    {
        "id": 10386,
        "title": "Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis",
        "authors": "Hongyi Zheng, Abulhair Saparov",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.277"
    },
    {
        "id": 10387,
        "title": "Large Language Models and Multimodal Retrieval for Visual Word Sense Disambiguation",
        "authors": "Anastasia Kritharoula, Maria Lymperaiou, Giorgos Stamou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.807"
    },
    {
        "id": 10388,
        "title": "Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models",
        "authors": "Paula Maddigan, Teo Susnjak",
        "published": "2023",
        "citations": 25,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2023.3274199"
    },
    {
        "id": 10389,
        "title": "Enabling Large Language Models to Generate Text with Citations",
        "authors": "Tianyu Gao, Howard Yen, Jiatong Yu, Danqi Chen",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.398"
    },
    {
        "id": 10390,
        "title": "Bridging the Gap between Subword and Character Segmentation in Pretrained Language Models",
        "authors": "Shun Kiyono,  , Sho Takase, Shengzhe Li, Toshinori Sato,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_062"
    },
    {
        "id": 10391,
        "title": "Enhancing Text Summarization: Evaluating Transformer-Based Models and the Role of Large Language Models like ChatGPT",
        "authors": "Pınar Savcı, Bihter Das",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iisec59749.2023.10391040"
    },
    {
        "id": 10392,
        "title": "AI as Agency Without Intelligence: on ChatGPT, Large Language Models, and Other Generative Models",
        "authors": "Luciano Floridi",
        "published": "2023-3",
        "citations": 58,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s13347-023-00621-y"
    },
    {
        "id": 10393,
        "title": "Considerations for Prompting Large Language Models—Reply",
        "authors": "Shan Chen, Guergana K. Savova, Danielle S. Bitterman",
        "published": "2024-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1001/jamaoncol.2023.6966"
    },
    {
        "id": 10394,
        "title": "ChatGPT and Large Language Models (LLMs) in Healthcare: Opportunities and Risks",
        "authors": "Hazrat Ali, Junaid Qadir, Tanvir Alam, Mowafa Househ, Zubair Shah",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>We have updated the draft with the latest version of the text as of July 2023.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22579852"
    },
    {
        "id": 10395,
        "title": "Threats, Opportunities, and Misconceptions",
        "authors": "Thimira Amaratunga",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0017-7_6"
    },
    {
        "id": 10396,
        "title": "Harnessing the Power of Large Language Models (LLMs) for Climate Modeling and Environmental Solutions",
        "authors": "Smith Jasmin, Williams fred",
        "published": "No Date",
        "citations": 0,
        "abstract": "The world is facing an unprecedented climate crisis, with environmental challenges threatening ecosystems, biodiversity, and human well-being. To address these pressing issues effectively, innovative approaches are essential. One such approach involves leveraging Large Language Models (LLMs), advanced AI technologies like GPT-3, to assist in climate modeling, data analysis, and finding solutions to environmental challenges. This article explores how LLMs are playing a transformative role in the fight against climate change and environmental degradation.",
        "link": "http://dx.doi.org/10.31219/osf.io/rwy9d"
    },
    {
        "id": 10397,
        "title": "A framework for evaluating rapidly developing digital and related technologies: AI, Large Language Models and beyond",
        "authors": "Peter Gluckman, Hema Sridhar",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.24948/2023.11"
    },
    {
        "id": 10398,
        "title": "Towards Concept-Aware Large Language Models",
        "authors": "Chen Shani, Jilles Vreeken, Dafna Shahaf",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.877"
    },
    {
        "id": 10399,
        "title": "How Can Transformers and Large Language Models Like ChatGPT Help LCA Practitioners?",
        "authors": "Simone Cornago, Seeram Ramakrishna, Jonathan Sze Choong Low",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4402262"
    },
    {
        "id": 10400,
        "title": "Leveraging Large Language Models for Predictive Chemistry",
        "authors": "Kevin Maik Jablonka, Philippe Schwaller, Andres Ortega-Guerrero, Berend Smit",
        "published": "No Date",
        "citations": 3,
        "abstract": "Machine learning has revolutionized many fields and has recently found applications in chemistry and materials science. The small datasets commonly found in chemistry sparked the development of sophisticated machine-learning approaches that incorporate chemical knowledge for each application and, therefore, require much expertise to develop. Here, we show that large language models trained on vast amounts of text extracted from the internet can easily be adapted to solve various tasks in chemistry and materials science by fine-tuning them to answer chemical questions in natural language with the correct answer. We compared this approach with dedicated machine-learning models for many applications spanning properties of molecules and materials to the yield of chemical reactions. Surprisingly, this approach performs comparable to or even outperforms the conventional techniques---particularly in the low data limit. In addition, we can perform inverse design successfully by simply inverting the questions. The high performance, especially for small data sets, combined with the ease of use, can fundamentally impact how we leverage machine learning in the chemical and material sciences. Next to a literature search, querying a foundation model might become a routine way to bootstrap a project by leveraging the collective knowledge encoded in these foundation models or to provide a baseline for predictive tasks.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2023-fw8n4-v3"
    },
    {
        "id": 10401,
        "title": "Leveraging Large Language Models for Predictive Chemistry",
        "authors": "Kevin Maik Jablonka, Philippe Schwaller, Andres Ortega-Guerrero, Berend Smit",
        "published": "No Date",
        "citations": 3,
        "abstract": "Machine learning has revolutionized many fields and has recently found applications in chemistry and materials science. The small datasets commonly found in chemistry sparked the development of sophisticated machine-learning approaches that incorporate chemical knowledge for each application and, therefore, require much expertise to develop. Here, we show that large language models trained on vast amounts of text extracted from the internet can easily be adapted to solve various tasks in chemistry and materials science by fine-tuning them to answer chemical questions in natural language with the correct answer. We compared this approach with dedicated machine-learning models for many applications spanning properties of molecules and materials to the yield of chemical reactions. Surprisingly, this approach performs comparable to or even outperforms the conventional techniques---particularly in the low data limit. In addition, we can perform inverse design successfully by simply inverting the questions. The high performance, especially for small data sets, combined with the ease of use, can fundamentally impact how we leverage machine learning in the chemical and material sciences. Next to a literature search, querying a foundation model might become a routine way to bootstrap a project by leveraging the collective knowledge encoded in these foundation models or to provide a baseline for predictive tasks.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2023-fw8n4-v3"
    },
    {
        "id": 10402,
        "title": "How Can Transformers and Large Language Models Like ChatGPT Help LCA Practitioners?",
        "authors": "Simone Cornago, Seeram Ramakrishna, Jonathan Sze Choong Low",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4402262"
    },
    {
        "id": 10403,
        "title": "Large Language Models for Code Obfuscation Evaluation of the Obfuscation Capabilities of OpenAI’s GPT-3.5 on C Source Code",
        "authors": "Patrick Kochberger, Maximilian Gramberger, Sebastian Schrittwieser, Caroline Lawitschka, Edgar Weippl",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012167000003555"
    },
    {
        "id": 10404,
        "title": "On the Construction of Database Interfaces Based on Large Language Models",
        "authors": "João Pinheiro, Wendy Victorio, Eduardo Nascimento, Antony Seabra, Yenier Izquierdo, Grettel García, Gustavo Coelho, Melissa Lemos, Luiz Leme, Antonio Furtado, Marco Casanova",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012204000003584"
    },
    {
        "id": 10405,
        "title": "Large Language Models: Starke KI mit bekannten Schwächen?",
        "authors": "Simon Hegelich, Kolja Hegelich",
        "published": "2022",
        "citations": 0,
        "abstract": "Künstliche Intelligenz (KI) wird immer besser darin, Texte zu erzeugen, die wie vom Menschen geschrieben wirken. Diese Fortschritte verdanken wir extrem aufwändigen Modellen aus dem Bereich des Deep Learning (Large Language Models (LLM)). Aber ist ein Computer intelligent, wenn er intelligent wirkende Texte erzeugen kann? Der berühmte Turing-Test würde dies bejahen. Wir denken aber, dass Zweifel angebracht sind. So komplex diese modernen Algorithmen auch sein mögen, im Kern betreiben sie Mustererkennung. Der Aspekt, durch eigene Gedanken etwas Neues zu erschaffen, fehlt diesen Maschinen. Durch eine Analyse der Funktionsweise von LLM wollen wir verständlich machen, wie diese Modelle arbeiten, wo ihre Grenzen liegen und warum sie dennoch für das Ziel einer starken oder allgemeinen künstlichen Intelligenz ein wesentlicher Baustein sein werden.",
        "link": "http://dx.doi.org/10.15358/1613-0669-2022-3-6"
    },
    {
        "id": 10406,
        "title": "Investigating the Accuracy of Large Language Models 'Chatgpt-4' in Grading Students’ Writing According to a Specific Rubric",
        "authors": "Alaa Alnajashi",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4687328"
    },
    {
        "id": 10407,
        "title": "Biomedical Parallel Sentence Retrieval Using Large Language Models",
        "authors": "Sheema Firdous, Sadaf Abdul Rauf",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.wmt-1.26"
    },
    {
        "id": 10408,
        "title": "Review for \"Large-Scale Text Analysis Using Generative Language Models: A Case Study in Discovering Public Value Expressions in AI Patents\"",
        "authors": "",
        "published": "2023-11-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1162/qss_a_00285/v2/review2"
    },
    {
        "id": 10409,
        "title": "Large Language Models and Return Prediction in China",
        "authors": "Lin Tan, huihang wu, Xiaoyan Zhang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4712248"
    },
    {
        "id": 10410,
        "title": "A bilingual benchmark for evaluating large language models",
        "authors": "Mohamed Alkaoud",
        "published": "2024-2-29",
        "citations": 0,
        "abstract": "This work introduces a new benchmark for the bilingual evaluation of large language models (LLMs) in English and Arabic. While LLMs have transformed various fields, their evaluation in Arabic remains limited. This work addresses this gap by proposing a novel evaluation method for LLMs in both Arabic and English, allowing for a direct comparison between the performance of the two languages. We build a new evaluation dataset based on the General Aptitude Test (GAT), a standardized test widely used for university admissions in the Arab world, that we utilize to measure the linguistic capabilities of LLMs. We conduct several experiments to examine the linguistic capabilities of ChatGPT and quantify how much better it is at English than Arabic. We also examine the effect of changing task descriptions from Arabic to English and vice-versa. In addition to that, we find that fastText can surpass ChatGPT in finding Arabic word analogies. We conclude by showing that GPT-4 Arabic linguistic capabilities are much better than ChatGPT’s Arabic capabilities and are close to ChatGPT’s English capabilities.",
        "link": "http://dx.doi.org/10.7717/peerj-cs.1893"
    },
    {
        "id": 10411,
        "title": "The influence of Large Language Models on systematic review and research dissemination",
        "authors": "Simon Baradziej",
        "published": "2023-10-4",
        "citations": 0,
        "abstract": "Watch VIDEO.\nThis presentation will delve into the transformative role of AI in scholarly communication, highlighting its potential, implications, and challenges, and further addressing the ethical considerations that come with it.\nRecent advancements in AI, specifically large language models have unlocked new possibilities for scientific exploration and communication. Large language models such as GPT-4 and LLAMA, with their remarkable text-generation capabilities, stand at the forefront of this AI revolution. In the first part of the presentation, I examine how these AI tools are reshaping the nature of systematic reviews. The ability to analyze, summarize, and generate vast amounts of text allows these models to facilitate more efficient processes, offering a valuable tool to researchers navigating through vast databases of published work.\nI would discuss how AI is engendering new developments in research methodology. Through the use of predictive modelling and advanced analytics, AI tools like GPT-4 allow for a deeper understanding of existing research and the identification of gaps in the literature, thereby promoting innovative research approaches. However, these advancements come with the need for updated ethical frameworks, a topic I would try to address also.\nThe issues related to AI use include issues of transparency and accountability, as the ”blackbox” approach to deep learning models can be uncovered; without appropriate interpretability architecture (such as with GPT-4 or LLAMA), these models can be generating inaccurate information based on their predictive capabilities.\nNevertheless, these have proved to be of use, and with a fine prompt tuning, publicly available models can be of great use to researchers. I would delve into the question of how to balance the benefits of AI tools with the need to maintain high ethical standards in research, aiming to provide possible insights into how these ethical frameworks might be updated to accommodate the new realities of AI.\nFurthermore, I’d reflect on the consequences of AI for the evaluation of research. While AI can aid in the quick assessment of a paper's relevance or novelty, questions remain about its capacity to fully evaluate the quality and significance of research. This discussion emphasizes the need for a blend of AI models with human expertise to achieve robust research evaluation for the time being (or for further training for specific use cases of the models.)\nI’d like to conclude with a reflection on the overall impact of the integration of AI LLMs on systematic reviews and research dissemination. While acknowledging the transformative potential of AI in reshaping the scientific landscape, it underscores the need for careful navigation of the associated challenges and ethical implications.",
        "link": "http://dx.doi.org/10.7557/5.7240"
    },
    {
        "id": 10412,
        "title": "Large Language Models in Psychology: Application in the Context of a Systematic Literature Review.",
        "authors": "Kim Uittenhove, Paolo Martinelli, Angélique Roquet",
        "published": "No Date",
        "citations": 0,
        "abstract": "The present study assesses the potential of employing Large Language Models (LLMs) in the context of a systematic literature review in psychology. We tasked one of the currently available ChatGPT-4-turbo-preview models from OpenAI with a qualitative coding assignment, which involved identifying elements related to a specific theoretical-analytical framework within 39 scientific empirical papers. We evaluated the quality of LLM-generated outcomes by comparing them with results generated through traditional human coding. In the process, we outlined the capabilities and advantages of using LLMs for systematic literature reviews, including practical considerations for their implementation. Our analyses showed that the LLM produced results that aligned closely with those obtained through traditional human coding. Furthermore, our experience indicated that incorporating LLMs into our research workflow was time- and cost-effective. Our results suggest that researchers and LLMs can work synergistically, improving efficiency, cost-effectiveness, and quality of the systematic literature review process. We underline the critical role of human arbitration in prompt crafting and decision-making.",
        "link": "http://dx.doi.org/10.31234/osf.io/nq4d2"
    },
    {
        "id": 10413,
        "title": "Intrusion Detection Technology Based on Large Language Models",
        "authors": "Hsiaofan Lai",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/easct59475.2023.10393509"
    },
    {
        "id": 10414,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Juan Carlos Rincon Acuña",
        "published": "2023-9-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/5vnumr"
    },
    {
        "id": 10415,
        "title": "Human-Like Problem-Solving Abilities in Large Language Models using ChatGPT",
        "authors": "Graziella Orrù, Andrea Piarulli, Ciro Conversano, Angelo Gemignani",
        "published": "No Date",
        "citations": 0,
        "abstract": "Backgrounds: The field of Artificial Intelligence (AI) has seen a major shift in recent years due to the development of new Machine Learning (ML) models such as Generative Pre-trained Transformer (GPT) and AI which are progressively becoming part our everyday lives. GPT has achieved previously unheard-of levels of accuracy in most computerized language processing tasks and their chat-based variations.\r\nAim: The aim of this study was to investigate the problem-solving abilities of ChatGPT using two sets of verbal insight problems, with a known performance level established by a sample of human participants. \r\nMaterial and Methods: A total of 30 problems labelled as “practice problems” and “transfer problems”, as listed by Ansburg and Dominowski (2000), were administered to ChatGPT. The answers provided by ChatGPT received a score of &quot;0&quot; for each problem answered incorrectly and a score of &quot;1&quot; for each correct response, as per the correct solution specified in Ansburg and Dominowski's (2000) study. The highest score that could be attributed to both the practice and transfer problems was 15 out of 15. In order to compare ChatGPT performance to the performance to that of human subjects, the solution rate for each problem (based on a sample of 20 subjects) was used, as indicated by Ansburg and Dominowski (2000). \r\nResults: The study highlighted that ChatGPT can be trained in out-of-the-box thinking and demonstrated potential in solving verbal insight problems. The global performance of ChatGPT equalled the most probable outcome for the human sample in both practice problems and transfer problems as well as upon their combination. Additionally, ChatGPT answer combinations were among the 5% of most probable outcomes for the human sample both when considering practice problems and pooled problem sets. \r\nThese findings demonstrate that ChatGPT performance on both set of problems was in line with the mean rate of success of human subjects, indicating that it performed reasonably well. \r\n\r\nConclusions: The use of transformer architecture and self-attention in ChatGPT may have helped to prioritize inputs while predicting, contributing to its potential in verbal insight problem-solving. ChatGPT has shown potential in solving insight problems, thus highlighting the importance of incorporating AI in psychological research. However, it is acknowledged that open challenges still exist. Indeed, further research is needed to fully understand the capabilities and limitations of AI in insight problem-solving.",
        "link": "http://dx.doi.org/10.20944/preprints202303.0375.v1"
    },
    {
        "id": 10416,
        "title": "The role of large language models in ecology and biodiversity conservation: Opportunities and Challenges",
        "authors": "Hideyuki Doi, Takeshi Osawa, Narumasa Tsutsumida",
        "published": "No Date",
        "citations": 0,
        "abstract": "Large Language Models (LLMs) have revolutionized the field of natural\nlanguage processing. These models can analyze vast amounts of data,\nextract meaningful insights, and provide a basis for informed\nconservation decisions. This paper identifies three main applications of\nLLMs for ecology and biodiversity conservation: 1) generating codes for\nmodeling and simulations, 2) data collection from digital data, and 3)\nproviding insights into public opinion and sentiment. We discussed the\npotential challenges and limitations associated with the use of LLMs,\nsuch as biases in LLM-generated code and data, and the need for careful\nevaluation and interpretation of LLM-generated results.",
        "link": "http://dx.doi.org/10.22541/au.168657324.49460085/v1"
    },
    {
        "id": 10417,
        "title": "Investigating the Accuracy of Large Language Models 'Chatgpt-4' in Grading Students’ Writing According to a Specific Rubric",
        "authors": "Alaa Alnajashi",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4691198"
    },
    {
        "id": 10418,
        "title": "A clinician's guide to large language models",
        "authors": "Giovanni Briganti",
        "published": "2023-8-17",
        "citations": 0,
        "abstract": "The rapid advancement of artificial intelligence (AI) has led to the emergence of large language models (LLMs) as powerful tools for various applications, including healthcare. These large-scale machine learning models, such as GPT and LLaMA have demonstrated potential for improving patient outcomes and transforming medical practice. However, healthcare professionals without a background in data science may find it challenging to understand and utilize these models effectively. This paper aims to provide an accessible introduction to LLMs for healthcare professionals, discussing their core concepts, relevant applications in healthcare, ethical considerations, challenges, and future directions. With an overview of LLMs, we foster a more collaborative future between healthcare professionals and data scientists, ultimately driving better patient care and medical advancements.",
        "link": "http://dx.doi.org/10.2217/fmai-2023-0003"
    },
    {
        "id": 10419,
        "title": "Post-Deployment Regulatory Oversight for General-Purpose Large Language Models",
        "authors": "Carson Ezell, Abraham Loeb",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4658623"
    },
    {
        "id": 10420,
        "title": "Human-like property induction is a challenge for large language models",
        "authors": "Simon Jerome Han, Keith Ransom, Andrew Perfors, Charles Kemp",
        "published": "No Date",
        "citations": 3,
        "abstract": "The impressive recent performance of large language models such as GPT-3 has led many to wonder to what extent they can serve as models of general intelligence or are similar to human cognition. We address this issue by applying GPT-3 to a classic problem in human inductive reasoning known as property induction. Our results suggest that while GPT-3 can qualitatively mimic human performance for some inductive phenomena (especially those that depend primarily on similarity relationships), it reasons in a qualitatively distinct way on phenomena that require more theoretical understanding. We propose that this emerges due to the reasoning abilities of GPT-3 rather than its underlying representations, and suggest that increasing its scale is unlikely to change this pattern.",
        "link": "http://dx.doi.org/10.31234/osf.io/6mkjy"
    },
    {
        "id": 10421,
        "title": "NLP Through the Ages",
        "authors": "Thimira Amaratunga",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0017-7_2"
    },
    {
        "id": 10422,
        "title": "Fact-checking benchmark for the Russian Large Language Models",
        "authors": "Anastasia Kozlova,  , Denis Shevelev, Alena Fenogenova",
        "published": "2023-6-19",
        "citations": 0,
        "abstract": "Modern text-generative language models are rapidly developing. They produce text of high quality and are used in many real-world applications. However, they still have several limitations, for instance, the length of the context, degeneration processes, lack of logical structure, and facts consistency. In this work, we focus on the fact-checking problem applied to the output of the generative models on classical downstream tasks, such as paraphrasing, summarization, text style transfer, etc. We define the task of internal fact-checking, set the criteria for factual consistency, and present the novel dataset for this task for the Russian language. The benchmark for internal fact-checking and several baselines are also provided. We research data augmentation approaches to extend the training set and compare classification methods on different augmented data sets.",
        "link": "http://dx.doi.org/10.28995/2075-7182-2023-22-267-277"
    },
    {
        "id": 10423,
        "title": "Is ChatGPT taking over the language classroom?",
        "authors": "Mandy Lau",
        "published": "2024-2-16",
        "citations": 0,
        "abstract": "ChatGPT generated much dialogue on the implications of large language models (LLMs) for language teaching and learning. Since language teachers are uniquely positioned to teach metalinguistic awareness, they can support their learners’ understanding of how LLMs are shaped by language ideologies and how their outputs are indexical of social power. This awareness would help learners be more conscientious in using LLMs, deciding how to interact with them and adapt their outputs for their purposes. This article introduces LLMs as statistical systems that predict linguistic forms. It surfaces two language ideologies that have shaped their development: the belief in the separability of language from its social contexts and the belief in the value of larger text corpora. It also highlights some ideological effects including uneven language performance, text outputs that reflect biases, privacy violations, circulation of copyrighted materials, misinformation, and hallucinations. Some suggestions for mitigating these effects are offered.",
        "link": "http://dx.doi.org/10.25071/2564-2855.36"
    },
    {
        "id": 10424,
        "title": "Evaluating the Performance of Large Language Models on a Neurology Board-Style Examination",
        "authors": "Marc Cicero Schubert, Wolfgang Wick, Varun Venkataramani",
        "published": "No Date",
        "citations": 1,
        "abstract": "SummaryBackground and ObjectivesRecent advancements in large language models (LLMs) such as GPT-3.5 and GPT-4 have shown impressive potential in a wide array of applications, including healthcare. While GPT-3.5 and GPT-4 showed heterogeneous results across specialized medical board examinations, the performance of these models in neurology board exams remains unexplored.MethodsAn exploratory, prospective study was conducted between May 17 and May 31, 2023. The evaluation utilized a question bank approved by the American Board of Psychiatry and Neurology, designed as part of a self-assessment program. Questions were presented in a single best answer, multiple-choice format. The results from the question bank were validated with a small question cohort by the European Board for Neurology. All questions were categorized into lower-order (recall, understanding) and higher-order (apply, analyze, synthesize) questions. The performance of GPT-3.5 and GPT-4 was assessed in relation to overall performance, question type, and topic. In addition, the confidence level in responses and the reproducibility of correctly and incorrectly answered questions was evaluated. Univariable analysis was carried out. Chi-squared test and Bonferroni correction were used to determine performance differences based on question characteristics. To differentiate characteristics of correctly and incorrectly answered questions, a high-dimensional tSNE analysis of the question representations was performed.ResultsIn May 2023, GPT-3.5 correctly answered 66.8 % of 1956 questions, whereas GPT-4 demonstrated a higher performance level, correctly answering 85 % of questions in congruence with near-passing and passing of the neurology board exam. GPT-4’s performance surpassed both GPT-3.5 and question bank users (mean human user score: 73.8%). An analysis of twenty-six question categories showed that GPT-4 outperformed human users in Behavioral, Cognitive and Psych-related questions and demonstrated superior performance to GPT-3.5 in six categories. Both models performed better on lower-order than higher-order questions according to Bloom Taxonomy for learning and assessment (GPT4: 790 of 893 (88.5%) vs. 872 of 1063 (82%), GPT-3.5: 639 of 893 (71.6%) vs. 667 of 1063 (62.7%)) with GPT-4 also excelling in both lower-order and higher-order questions. The use of confident language was observed consistently across both models, even when incorrect (GPT-4: 99.3%, 292 of 294 incorrect answers, GPT-3.5: 100%, 650 of 650 incorrect answers). Reproducible answers of GPT-3.5 and GPT-4 (defined as more than 75 % same output across 50 independent queries) were associated with a higher percentage of correct answers (GPT-3.5: 66 of 88 (75%), GPT-4: 78 of 96 (81.3%)) than inconsistent answers, (GPT-3.5: 5 of 13 (38.5%), GPT-4: 1 of 4 (25%)). Lastly, the high-dimensional embedding analysis of correctly and incorrectly answered questions revealed no clear differentiation into distinct clusters.DiscussionDespite the absence of neurology-specific training, GPT-4 demonstrated commendable performance, whereas GPT-3.5 performed slightly below the human average question bank user. Higher-order cognitive tasks proved more challenging for both GPT-4 and GPT-3.5. Notwithstanding, GPT-4’s performance was equivalent to a passing grade for specialized neurology board exams. These findings suggest that with further refinements, LLMs like GPT-4 could play a pivotal role in applications for clinical neurology and healthcare in general.",
        "link": "http://dx.doi.org/10.1101/2023.07.13.23292598"
    },
    {
        "id": 10425,
        "title": "Large Language Models Know How the Personality of Public Figures is Perceived by the General Public",
        "authors": "Xubo Cao, Michal Kosinski",
        "published": "No Date",
        "citations": 1,
        "abstract": "We show that people’s perceptions of public figures’ personalities can be accurately predicted from their names’ location in GPT-3’s semantic space. We collected Big Five personality perceptions of 300 public figures from 600 human raters. Cross-validated linear regression was used to predict human perceptions from public figures names’ embeddings extracted from GPT-3. Models’ accuracy ranged from r=.70 to .80 without controls and from r=.43 to .61 when controlling for public figures’ likability and demographics. Prediction models showed high face validity as revealed the personality-descriptive adjectives occupying their extremes. Our findings reveal that GPT-3 word embeddings capture signal pertaining to individual differences and intimate traits.",
        "link": "http://dx.doi.org/10.31234/osf.io/89hx6"
    },
    {
        "id": 10426,
        "title": "Call for Papers",
        "authors": " ",
        "published": "2023",
        "citations": 0,
        "abstract": "",
        "link": "http://dx.doi.org/10.5840/teachphil202346111"
    },
    {
        "id": 10427,
        "title": "ChatGPT and Large Language Models (LLMs) in Healthcare: Opportunities and Risks",
        "authors": "Hazrat Ali, Junaid Qadir, Tanvir Alam, Mowafa Househ, Zubair Shah",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>We have updated the draft with the latest version of the text as of July 2023.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22579852.v3"
    },
    {
        "id": 10428,
        "title": "A tutorial on open-source large language models for behavioral science",
        "authors": "Zak Hussain, Marcel Binz, Rui Mata, Dirk U. Wulff",
        "published": "No Date",
        "citations": 0,
        "abstract": "Large language models (LLMs) have the potential to revolutionize behavioral science by accelerating and improving the research cycle, from conceptualization to data analysis. Unlike closed-source solutions, open-source frameworks for LLMs can enable transparency, reproducibility, and adherence to data protection standards, which gives them a crucial advantage for use in behavioral science. To help researchers harness the promise of LLMs, this tutorial offers a primer on the open-source Hugging Face ecosystem and demonstrates several applications that advance conceptual and empirical work in behavioral science, including feature extraction, fine-tuning of models for prediction, and generation of behavioral responses. Executable code is made available at github.com/Zak-Hussain/LLM4BeSci.git. Finally, the tutorial discusses challenges faced by research with (open-source) LLMs related to interpretability and safety and offers a perspective on future research at the intersection of language modeling and behavioral science.",
        "link": "http://dx.doi.org/10.31234/osf.io/f7stn"
    },
    {
        "id": 10429,
        "title": "Sentiment trading with large language models",
        "authors": "Kemal Kirtac, Guido Germano",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.frl.2024.105227"
    },
    {
        "id": 10430,
        "title": "Homophily in An Artificial Social Network of Agents Powered By Large Language Models",
        "authors": "James He, Felix Wallis, Steve Rathje",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nRecent advances in Artificial Intelligence (AI) have given rise to chatbots based on Large Language Models (LLMs) - such as ChatGPT - that can provide human-like responses to a wide range of psychological and economic tasks. However, no study to date has explored whether a society of LLM-based agents behaves comparably to human societies. We conduct Social Network Analysis on Chirper.ai, a Twitter-like platform consisting only of LLM chatbots. We find early evidence of self-organized homophily in the sampled artificial society (N = 31,764): like humans, bots with similar language and content engage more than dissimilar bots. However, content created by the bots tends to be more generic than human-generated content. We discuss the potential for developing LLM-driven Agent-Based Models of human societies, which may inform AI research and development and further the social scientific understanding of human social dynamics.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3096289/v1"
    },
    {
        "id": 10431,
        "title": "What’s the next word in large language models?",
        "authors": "",
        "published": "2023-4-24",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s42256-023-00655-z"
    },
    {
        "id": 10432,
        "title": "Large Language Models for Telecom: The Next Big Thing?",
        "authors": "Lina Bariah, Qiyang Zhao, Hang Zou, Yu Tian, Faouzi Bader, Merouane Debbah",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The evolution of generative artificial intelligence (GenAI) constitutes a turning point in reshaping the future of technology in different aspects. Wireless networks in particular, with the blooming of self-evolving networks, represent a rich field for exploiting GenAI and reaping several benefits that can fundamentally change the way how wireless networks are designed and operated nowadays. To be specific, large language models (LLMs), a subfield of GenAI, are envisioned to open up a new era of autonomous wireless networks, in which a multimodal large model trained over various Telecom data, can be fine-tuned to perform several downstream tasks, eliminating the need for dedicated AI models for each task and paving the way for the realization of artificial general intelligence (AGI)-empowered wireless networks. In this article, we aim to unfold the opportunities that can be reaped from integrating LLMs into the Telecom domain. In particular, we aim to put a forward-looking vision on a new realm of possibilities and applications of LLMs in future wireless networks, defining directions for designing, training, testing, and deploying Telecom LLMs, and reveal insights on the associated theoretical and practical challenges.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23536440"
    },
    {
        "id": 10433,
        "title": "AI, ML, and Large Language Models in Cybersecurity",
        "authors": "",
        "published": "2024-3-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.56726/irjmets49546"
    },
    {
        "id": 10434,
        "title": "Large Language Models (LLMs): Representation Matters, Low-Resource Languages and Multi-Modal Architecture",
        "authors": "Ganesh Mani, Galane Basha Namomsa",
        "published": "2023-9-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/africon55910.2023.10293675"
    },
    {
        "id": 10435,
        "title": "Large Language Models and Financial Market Sentiment",
        "authors": "Shaun Alexander Bond, Hayden Klok, Min Zhu",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4584928"
    },
    {
        "id": 10436,
        "title": "Human-Centered AI: Large Language Models and the Need for Ethical Medical Chatbots (Preprint)",
        "authors": "James Chow, Kay Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nThe evolution of medical chatbots underscores the pressing need for human-centered AI to address patient and family concerns more personally and precisely. This paper explores the potential ways to do so, through tracing the historical development of artificial intelligence (AI), charting the progression from neural networks to the prevalent use of Large Language Models (LLMs) like GPT-3 and 4 within the realm of human-centered AI.\n\n\nOBJECTIVE\nThis review critically examines the pivotal role of LLM-based medical chatbots in fostering ethical and humanistic AI in the construction of medical chatbots. Specifically, it investigates the transition from explicit algorithms to the contemporary landscape in which LLMs emulate human speech, language, and behavior.\n\n\nMETHODS\nBeginning with examining the elements of human-centred AI, pathways to build medical chatbots ethically were identified.  The loopholes for potential bias in LLMs were highlighted, such as  their reliance on extensive datasets and neural networks, which have revolutionized programming methodologies, whereas bias in the datasets also may result in bias in the medical chatbot’s responses. The training methodology employed in developing ChatGPT was also reviewed, finding potential bias because of the bias in the massive training data.\n\n\nRESULTS\nThe study's findings centered on the potential ways to design medical chatbots with human-centered AI.   It delves not only into how LLMs, particularly in their proficiency in understanding and generating human language, can significantly shape the future of AI, but also how inherent bias in the training of the LLMs may result in chatbots not for everybody. The focus extends to broader implications for AI and computer science, shedding light on transformative opportunities and ethical challenges inherent in the application of LLMs.\n\n\nCONCLUSIONS\nThis review highlights the transformative potential of LLMs in shaping the next generation of medical chatbots. It underscores the imperative of infusing human-centric values and ethical considerations into AI systems, aligning with the overarching goal of creating human-centered AI. The insights presented include considerations for mitigating bias in ChatGPT and reflections on the future trajectory of LLMs, emphasizing practical applications in the development and enhancement of ethical medical chatbots.\n\n\nCLINICALTRIAL\nNA\n",
        "link": "http://dx.doi.org/10.2196/preprints.56404"
    },
    {
        "id": 10437,
        "title": "Data Augmentation for Fake News Detection by Combining Seq2seq and NLI",
        "authors": "Anna Glazkova,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_048"
    },
    {
        "id": 10438,
        "title": "Large-language models binnen de klinische chemie",
        "authors": "William van Doorn, Steef Kurstjens",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.24078/labgeneeskunde.2023.10.23776"
    },
    {
        "id": 10439,
        "title": "Transforming Conversational AI",
        "authors": "Michael McTear, Marina Ashurkina",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0110-5"
    },
    {
        "id": 10440,
        "title": "Lower Energy Large Language Models (LLMs)",
        "authors": "Hsiao-Ying Lin, Jeffrey Voas",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mc.2023.3278160"
    },
    {
        "id": 10441,
        "title": "Large Language Models for Telecom: The Next Big Thing?",
        "authors": "Lina Bariah, Qiyang Zhao, Hang Zou, Yu Tian, Faouzi Bader, Merouane Debbah",
        "published": "No Date",
        "citations": 1,
        "abstract": "<p>The evolution of generative artificial intelligence (GenAI) constitutes a turning point in reshaping the future of technology in different aspects. Wireless networks in particular, with the blooming of self-evolving networks, represent a rich field for exploiting GenAI and reaping several benefits that can fundamentally change the way how wireless networks are designed and operated nowadays. To be specific, large language models (LLMs), a subfield of GenAI, are envisioned to open up a new era of autonomous wireless networks, in which a multimodal large model trained over various Telecom data, can be fine-tuned to perform several downstream tasks, eliminating the need for dedicated AI models for each task and paving the way for the realization of artificial general intelligence (AGI)-empowered wireless networks. In this article, we aim to unfold the opportunities that can be reaped from integrating LLMs into the Telecom domain. In particular, we aim to put a forward-looking vision on a new realm of possibilities and applications of LLMs in future wireless networks, defining directions for designing, training, testing, and deploying Telecom LLMs, and reveal insights on the associated theoretical and practical challenges.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23536440.v1"
    },
    {
        "id": 10442,
        "title": "Large Language Models Can Enhance Persuasion Through Linguistic Feature Alignment",
        "authors": "Minkyu Shin, Jin Kim",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4725351"
    },
    {
        "id": 10443,
        "title": "Review of: \"Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education\"",
        "authors": "Mary Anne M. Sahagun",
        "published": "2023-9-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/kivmq2"
    },
    {
        "id": 10444,
        "title": "A Novel Question-Answering Framework for Automated Citation Screening Using Large Language Models",
        "authors": "Opeoluwa Akinseloyin, Xiaorui Jiang, Vasile Palade",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractObjectiveThis paper aims to address the challenges in citation screening (a.k.a. abstract screening) within Systematic Reviews (SR) by leveraging the zero-shot capabilities of large language models, particularly ChatGPT.MethodsWe employ ChatGPT as a zero-shot ranker to prioritize candidate studies by aligning abstracts with the selection criteria outlined in an SR protocol. Citation screening was transformed into a novel question-answering (QA) framework, treating each selection criterion as a question addressed by ChatGPT. The framework involves breaking down the selection criteria into multiple questions, properly prompting ChatGPT to answer each question, scoring and re-ranking each answer, and combining the responses to make nuanced inclusion or exclusion decisions.ResultsLarge-scale validation was performed on the benchmark of CLEF eHealth 2019 Task 2: Technology Assisted Reviews in Empirical Medicine. Across 31 datasets of four categories of SRs, the proposed QA framework consistently outperformed other zero-shot ranking models. Compared with complex ranking approaches with iterative relevance feedback and fine-tuned deep learning-based ranking models, our ChatGPT-based zero-shot citation screening approaches still demonstrated competitive and sometimes better results, underscoring their high potential in facilitating automated systematic reviews.ConclusionInvestigation justified the indispensable value of leveraging selection criteria to improve the performance of automated citation screening. ChatGPT demonstrated proficiency in prioritizing candidate studies for citation screening using the proposed QA framework. Significant performance improvements were obtained by re-ranking answers using the semantic alignment between abstracts and selection criteria. This further highlighted the pertinence of utilizing selection criteria to enhance citation screening.",
        "link": "http://dx.doi.org/10.1101/2023.12.17.23300102"
    },
    {
        "id": 10445,
        "title": "ISSCC 2024 Forum 2: Energy-Efficient AI-Computing Systems for Large-Language Models",
        "authors": "",
        "published": "2024-2-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isscc49657.2024.10454551"
    },
    {
        "id": 10446,
        "title": "HTMOT: Hierarchical Topic Modelling Over Time",
        "authors": "Judicael Poumay,  , Ashwin Ittoo,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_092"
    },
    {
        "id": 10447,
        "title": "Lifelong Pretraining: Continually Adapting Language Models to Emerging Corpora",
        "authors": "Xisen Jin, Dejiao Zhang, Henghui Zhu, Wei Xiao, Shang-Wen Li, Xiaokai Wei, Andrew Arnold, Xiang Ren",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bigscience-1.1"
    },
    {
        "id": 10448,
        "title": "ChavanKane at WANLP 2022 Shared Task: Large Language Models for Multi-label Propaganda Detection",
        "authors": "Tanmay Chavan, Aditya Manish Kane",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.wanlp-1.60"
    },
    {
        "id": 10449,
        "title": "Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large Language Models During Predictive Language Processing",
        "authors": "Viktor Kewenig, Christopher Edwards, Quitterie Lacome D’Estalenx, Akilles Rechardt, Jeremy Skipper, Gabriella Vigliocco",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4563032"
    },
    {
        "id": 10450,
        "title": "Exploring Distributional Shifts in Large Language Models for Code Analysis",
        "authors": "Shushan Arakelyan, Rocktim Das, Yi Mao, Xiang Ren",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.1013"
    },
    {
        "id": 10451,
        "title": "Compressing Context to Enhance Inference Efficiency of Large Language Models",
        "authors": "Yucheng Li, Bo Dong, Frank Guerin, Chenghua Lin",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.391"
    },
    {
        "id": 10452,
        "title": "StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models",
        "authors": "Sullam Jeoung, Yubin Ge, Jana Diesner",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.752"
    },
    {
        "id": 10453,
        "title": "Making Large Language Models Better Data Creators",
        "authors": "Dong-Ho Lee, Jay Pujara, Mohit Sewak, Ryen White, Sujay Jauhar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.948"
    },
    {
        "id": 10454,
        "title": "Large Language Models As Annotators: A Preliminary Evaluation For Annotating Low-Resource Language Content",
        "authors": "Savita Bhat, Vasudeva Varma",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.eval4nlp-1.8"
    },
    {
        "id": 10455,
        "title": "Long-Term Memory for Large Language Models Through Topic-Based Vector Database",
        "authors": "Yi Zhang, Zhongyang Yu, Wanqi Jiang, Yufeng Shen, Jin Li",
        "published": "2023-11-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ialp61005.2023.10337079"
    },
    {
        "id": 10456,
        "title": "FedID: Federated Interactive Distillation for Large-Scale Pretraining Language Models",
        "authors": "Xinge Ma, Jiangming Liu, Jin Wang, Xuejie Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.529"
    },
    {
        "id": 10457,
        "title": "Towards Open Natural Language Feedback Generation for Novice Programmers using Large Language Models",
        "authors": "Charles Koutcheme",
        "published": "2022-11-17",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3564721.3565955"
    },
    {
        "id": 10458,
        "title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models",
        "authors": "Potsawee Manakul, Adian Liusie, Mark Gales",
        "published": "2023",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.557"
    },
    {
        "id": 10459,
        "title": "Large Language Models for Multilingual Slavic Named Entity Linking",
        "authors": "Rinalds Vīksna, Inguna Skadiņa, Daiga Deksne, Roberts Rozis",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bsnlp-1.20"
    },
    {
        "id": 10460,
        "title": "An Empirical Study of Translation Hypothesis Ensembling with Large Language Models",
        "authors": "António Farinhas, José de Souza, Andre Martins",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.733"
    },
    {
        "id": 10461,
        "title": "How Large Language Models are Transforming Machine-Paraphrase Plagiarism",
        "authors": "Jan Philip Wahle, Terry Ruas, Frederic Kirstein, Bela Gipp",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.62"
    },
    {
        "id": 10462,
        "title": "Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models",
        "authors": "Daman Arora, Himanshu Singh,  Mausam",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.468"
    },
    {
        "id": 10463,
        "title": "The (ab)use of Open Source Code to Train Large Language Models",
        "authors": "Ali Al-Kaswan, Maliheh Izadi",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/nlbse59153.2023.00008"
    },
    {
        "id": 10464,
        "title": "Query Rewriting in Retrieval-Augmented Large Language Models",
        "authors": "Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao, Nan Duan",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.322"
    },
    {
        "id": 10465,
        "title": "CLAIR: Evaluating Image Captions with Large Language Models",
        "authors": "David Chan, Suzanne Petryk, Joseph Gonzalez, Trevor Darrell, John Canny",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.841"
    },
    {
        "id": 10466,
        "title": "Regulation and NLP (RegNLP): Taming Large Language Models",
        "authors": "Catalina Goanta, Nikolaos Aletras, Ilias Chalkidis, Sofia Ranchordás, Gerasimos Spanakis",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.539"
    },
    {
        "id": 10467,
        "title": "Multilingual Continual Learning Approaches for Text Classification",
        "authors": "Karan Praharaj,  , Irina Matveeva,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_093"
    },
    {
        "id": 10468,
        "title": "Induced Natural Language Rationales and Interleaved Markup Tokens Enable Extrapolation in Large Language Models",
        "authors": "Mirelle Candida Bueno, Carlos Gemmell, Jeff Dalton, Roberto Lotufo, Rodrigo Nogueira",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.mathnlp-1.3"
    },
    {
        "id": 10469,
        "title": "Non-Parametric Memory Guidance for Multi-Document Summarization",
        "authors": "Florian Baud,  , Alex Aussem,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_017"
    },
    {
        "id": 10470,
        "title": "Understanding latent affective bias in large pre-trained neural language models",
        "authors": "Anoop Kadan, Deepak P., Sahely Bhadra, Manjary P. Gangan, Lajish V.L.",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.nlp.2024.100062"
    },
    {
        "id": 10471,
        "title": "What’s Next after LLMs? Unlocking Robotics’ Full Potential with Large World Models",
        "authors": "",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1287/lytx.2023.04.07"
    },
    {
        "id": 10472,
        "title": "Why large language models are poor theories of human linguistic cognition: A reply to Piantadosi",
        "authors": "Roni Katzir",
        "published": "2023-12-15",
        "citations": 3,
        "abstract": "In a recent manuscript entitled “Modern language models refute Chomsky’s approach to language”, Steven Piantadosi proposes that large language models such as GPT-3 can serve as serious theories of human linguistic cognition. In fact, he maintains that these models are significantly better linguistic theories than proposals emerging from within generative linguistics. The present note explains why this claim is wrong.",
        "link": "http://dx.doi.org/10.5964/bioling.13153"
    },
    {
        "id": 10473,
        "title": "Cost-effective Distillation of Large Language Models",
        "authors": "Sayantan Dasgupta, Trevor Cohn, Timothy Baldwin",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.463"
    },
    {
        "id": 10474,
        "title": "OLaLa: Ontology Matching with Large Language Models",
        "authors": "Sven Hertling, Heiko Paulheim",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3587259.3627571"
    },
    {
        "id": 10475,
        "title": "Evaluating the Generation Capabilities of Large Chinese Language Models",
        "authors": "Hui Zeng, Jingyuan Xue, Meng Hao, Chen Sun, Bin Ning, Na Zhang",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4578709"
    },
    {
        "id": 10476,
        "title": "The Seven Wonderings of Large Language Models as Psychometric Designers, Refiners, and Analysts",
        "authors": "Alicia Franco-Martínez, Ricardo Rey-Sáez, Ignacio Castillejo",
        "published": "No Date",
        "citations": 0,
        "abstract": "The irruption of Large Language Models (LLMs) in our daily lives has opened up an intriguing future for the course of psychometrics. We give a glimpse of that future through our seven “wonderings” of LLMs: a series of wanderings on how current LLMs can instill wonder in researchers and professionals by assisting them in each step of the design, refinement, and analysis of psychometric tools. Using GPT-4 as illustration, we have tried to answer what are the capabilities of LLMs as item designers and format generators, as reviewers and respondents, and as data analysts and results interpreters. We interacted with the LLM applying a systematic prompt scheme, evidencing the peaks and pitfalls of its responses when addressing psychometric tasks. Finally, we provide some thoughts and guidelines about the validity of the uses LLMs responses can offer, and how to study and perform such validation process.",
        "link": "http://dx.doi.org/10.31234/osf.io/kmqy5"
    },
    {
        "id": 10477,
        "title": "Harnessing Large Language Models in Nursing Care Planning: Opportunities, Challenges, and Ethical Considerations",
        "authors": "Abdulqadir  J Nashwan, Ahmad A Abujaber",
        "published": "2023-6-16",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7759/cureus.40542"
    },
    {
        "id": 10478,
        "title": "GenAI Against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models",
        "authors": "Emilio Ferrara",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4614223"
    },
    {
        "id": 10479,
        "title": "\"Turning Right\"? An experimental study on the political value shift in large language models",
        "authors": "Chao Gu, Yifei Liu, Wangyuang Pan",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nConstructing artificial intelligence that aligns with human values is a crucial challenge, with political values playing a distinctive role among the various human value systems. In this study, we developed a standardized method to test political values in AI, utilizing the Political Compass Test alongside rigorous bootstrapping techniques. This methodology was applied to different versions of the notably influential ChatGPT. Our findings reveal that while newer versions of ChatGPT consistently maintain values within the libertarian-left quadrant, there is a significant rightward shift in political values, a phenomenon we term a 'value shift' in large language models. This shift is particularly noteworthy given the deep integration of large language models with human knowledge creation, suggesting potentially profound impacts on societal values. Intriguingly, our analysis indicates that this value shift in ChatGPT may not be directly linked to its training datasets. This research sheds light on the dynamic nature of value alignment in AI, highlighting the need for continuous monitoring and understanding of the underlying factors driving these shifts in AI-generated political values.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3993971/v1"
    },
    {
        "id": 10480,
        "title": "Empowering Few-Shot Recommender Systems With Large Language Models-Enhanced Representations",
        "authors": "Zhoumeng Wang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2024.3368027"
    },
    {
        "id": 10481,
        "title": "Hybrid Marketing Research: Large Language Models as an Assistant",
        "authors": "Neeraj Arora, Ishita Chakraborty, Yohei Nishimura",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4683054"
    },
    {
        "id": 10482,
        "title": "Comparative Evaluation of Commercial Large Language Models on PromptBench: An English and Chinese Perspective",
        "authors": "Shiyu Wang, Qian Ouyang, Bing Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThis study embarks on an exploration of the performance disparities observed between English and Chinese in large language models (LLMs), motivated by the growing need for multilingual capabilities in artificial intelligence systems. Utilizing a comprehensive methodology that includes quantitative analysis of model outputs and qualitative assessment of language nuances, the research investigates the underlying reasons for these discrepancies. The findings reveal significant variations in the performance of LLMs across the two languages, with a pronounced challenge in accurately processing and generating text in Chinese. This performance gap underscores the limitations of current models in handling the complexities inherent in languages with distinct grammatical structures and cultural contexts. The implications of this research are far-reaching, suggesting a critical need for the development of more robust and inclusive models that can better accommodate linguistic diversity. This entails not only the enrichment of training datasets with a wider array of languages but also the refinement of model architectures to grasp the subtleties of different linguistic systems. Ultimately, this study contributes to the ongoing discourse on enhancing the multilingual capabilities of LLMs, aiming to pave the way for more equitable and effective artificial intelligence tools that cater to a global user base.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3987793/v1"
    },
    {
        "id": 10483,
        "title": "Large language models: fast proliferation and budding international competition",
        "authors": "",
        "published": "2023-2-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/13567888.2023.2198430"
    },
    {
        "id": 10484,
        "title": "The Power of Words: An Overview of Large Language Models (LLMs) and Their Significance in AI",
        "authors": "Mangrove Steve,  olaoyegodwin",
        "published": "No Date",
        "citations": 0,
        "abstract": "the ever-evolving landscape of artificial intelligence (AI), one class of models has emerged as a game-changer: Large Language Models (LLMs). These models, characterized by their massive size and complexity, have transformed the field of natural language processing (NLP) and have far-reaching implications for a wide range of applications. In this article, we'll take a deep dive into LLMs, exploring what they are, how they work, and their significance in the world of AI.",
        "link": "http://dx.doi.org/10.31219/osf.io/qzney"
    },
    {
        "id": 10485,
        "title": "Evaluating Large Language Models in Ransomware Negotiation: A Comparative Analysis of ChatGPT and Claude",
        "authors": "Takako Kumamoto, Yunko Yoshida, Himari Fujima",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThis study presents a comprehensive analysis of the application of Large Language Models (LLMs), specifically ChatGPT and Claude, in the context of ransomware negotiation. Ransomware, an increasingly prevalent and sophisticated cyber threat, necessitates innovative response strategies. This study examines the capabilities of these LLMs in simulating human-like negotiation tactics against ransomware attacks, focusing on two main types: cryptographic and data exfiltration ransomware. Through a series of controlled simulations, the efficacy of ChatGPT and Claude in understanding complex language constructs, formulating negotiation strategies, and their adaptability to varying ransomware scenarios is evaluated. The research highlights the strengths of these models in response accuracy, adaptability, and psychological manipulation resistance. However, it also reveals their susceptibility to producing hallucinations — instances of unrealistic or inaccurate responses. The study contributes to the understanding of AI's potential in cybersecurity, emphasizing the need for improvements in AI reliability, ethical considerations, and the integration of human oversight. The findings suggest that while LLMs hold promising potential in enhancing cyber defense mechanisms, their deployment in high-stakes scenarios like ransomware negotiations must be approached with caution and continuous oversight.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3719038/v1"
    },
    {
        "id": 10486,
        "title": "Knowledgesift Qa: Enhancing the Performance of Large Language Models in Simple Open Domain Question Answering",
        "authors": "Liang Bao, Qiang Yu, Peng Nie",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4623359"
    },
    {
        "id": 10487,
        "title": "Cybercrime and Privacy Threats of Large Language Models",
        "authors": "Nir Kshetri",
        "published": "2023-5",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mitp.2023.3275489"
    },
    {
        "id": 10488,
        "title": "Large Product Key Memory for Pretrained Language Models",
        "authors": "Gyuwan Kim, Tae Hwan Jung",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.findings-emnlp.362"
    },
    {
        "id": 10489,
        "title": "FHIR-GPT Enhances Health Interoperability with Large Language Models",
        "authors": "Yikuan Li, Hanyin Wang, Halid Z. Yerebakan, Yoshihisa Shinagawa, Yuan Luo",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractAdvancing health interoperability can significantly benefit health research, including phenotyping, clinical trial support, and public health surveillance. Federal agencies, including ONC, CDC, and CMS, have been collectively collaborating to promote interoperability by adopting Fast Healthcare Interoperability Resources (FHIR). However, the heterogeneous structures and formats of health data present challenges when transforming Electronic Health Record (EHR) data into FHIR resources. This challenge becomes more significant when critical health information is embedded in unstructured data rather than well-organized structured formats. Previous studies relied on multiple separate rule-based or deep learning-based NLP tools to complete the FHIR resource transformation, which demands substantial development costs, extensive training data, and meticulous integration of multiple individual NLP tools. In this study, we assessed the ability of large language models (LLMs) to transform clinical narratives into HL7 FHIR resources. We developed FHIR-GPT specifically for the transformation of clinical texts into FHIR medication statement resources. In our experiments using 3,671 snippets of clinical texts, FHIR-GPT demonstrated an exceptional exact match rate of over 90%, surpassing the performance of existing methods.. FHIR-GPT improved the exact match rates of existing NLP pipelines by 3% for routes, 12% for dose quantities, 35% for reasons, 42% for forms, and over 50% for timing schedules. Our findings provide the foundations for leveraging LLMs to enhance health data interoperability. Future studies will aim to build upon these successes by extending the generation to additional FHIR resources.",
        "link": "http://dx.doi.org/10.1101/2023.10.17.23297028"
    },
    {
        "id": 10490,
        "title": "Bias Amplification in Intersectional Subpopulations for Clinical Phenotyping by Large Language Models",
        "authors": "Ridam Pal, Hardik Garg, Shashwat Patel, Tavpritesh Sethi",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractLarge Language Models (LLMs) have demonstrated remarkable performance across diverse clinical tasks. However, there is growing concern that LLMs may amplify human bias and reduce performance quality for vulnerable subpopulations. Therefore, it is critical to investigate algorithmic underdiagnosis in clinical notes, which represent a key source of information for disease diagnosis and treatment. This study examines prevalence of bias in two datasets - smoking and obesity - for clinical phenotyping. Our results demonstrate that state-of-the-art language models selectively and consistently underdiagnosed vulnerable intersectional subpopulations such as young-aged-males for smoking and middle-aged-females for obesity. Deployment of LLMs with such biases risks skewing clinicians’ decision-making which may lead to inequitable access to healthcare. These findings emphasize the need for careful evaluation of LLMs in clinical practice and highlight the potential ethical implications of deploying such systems in disease diagnosis and prognosis.",
        "link": "http://dx.doi.org/10.1101/2023.03.22.23287585"
    },
    {
        "id": 10491,
        "title": "LARGE LANGUAGE MODELS FOR CIPHERS",
        "authors": "David Noever",
        "published": "2023-5-28",
        "citations": 0,
        "abstract": "This study investigates whether transformer models like ChatGPT (GPT4, MAR2023) can generalize beyond their training data by examining their performance on the novel Cipher Dataset, which scrambles token order. The dataset consists of 654 test cases, and the analysis focuses on 51 text examples and 13 algorithmic choices. Results show that the models perform well on low-difficulty ciphers like Caesar and can unscramble tokens in 77% of the cipher examples. Despite their reliance on training data, the model's ability to generalize outside of token order is surprising, especially when leveraging large-scale models with hundreds of billions of weights and a comprehensive text corpus with few examples. The original contributions of the work focus on presenting a cipher challenge dataset and then scoring historically significant ciphers for large language models to descramble. The real challenge for these generational models lies in executing the complex algorithmic steps on new cipher inputs, potentially as a novel reasoning challenge that relies less on knowledge acquisition and more on trial-and-error or out-ofbounds responses.",
        "link": "http://dx.doi.org/10.5121/ijaia.2023.14301"
    },
    {
        "id": 10492,
        "title": "PEFT-SP: Parameter-Efficient Fine-Tuning on Large Protein Language Models Improves Signal Peptide Prediction",
        "authors": "Shuai Zeng, Duolin Wang, Dong Xu",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractSignal peptides (SP) play a crucial role in protein translocation in cells. The development of large protein language models (PLMs) provides a new opportunity for SP prediction, especially for the categories with limited annotated data. We present a Parameter-Efficient Fine-Tuning (PEFT) framework for SP prediction, PEFT-SP, to effectively utilize pre-trained PLMs. We implanted low-rank adaptation (LoRA) into ESM-2 models to better leverage the protein sequence evolutionary knowledge of PLMs. Experiments show that PEFT-SP using LoRA enhances state-of-the-art results, leading to a maximum MCC2 gain of 0.372 for SPs with small training samples and an overall MCC2 gain of 0.048. Furthermore, we also employed two other PEFT methods, i.e., Prompt Tunning and Adapter Tuning, into ESM-2 for SP prediction. More elaborate experiments show that PEFT-SP using Adapter Tuning can also improve the state-of-the-art results with up to 0.202 MCC2 gain for SPs with small training samples and an overall MCC2 gain of 0.030. LoRA requires fewer computing resources and less memory compared to Adapter, making it possible to adapt larger and more powerful protein models for SP prediction.",
        "link": "http://dx.doi.org/10.1101/2023.11.04.565642"
    },
    {
        "id": 10493,
        "title": "Large Language Models in Healthcare: A Review",
        "authors": "Shun Zou, Jun He",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iscsic60498.2023.00038"
    },
    {
        "id": 10494,
        "title": "Shadows of Wisdom: Classifying Meta-cognitive and Morally-grounded Narrative Content via Large Language Models",
        "authors": "Alexander Stavropoulos, Damien Crone, Igor Grossmann",
        "published": "No Date",
        "citations": 0,
        "abstract": "We investigated Large Language Models' (LLMs) efficacy in classifying complex psychological constructs like intellectual humility, perspective-taking, open-mindedness, and search for a compromise in narratives of Canadian and American adults reflecting on a workplace conflict. Using state-of-the-art models like GPT-4 across few-shot and zero-shot paradigms and RoB-ELoC (RoBERTa-fine-tuned-on-Emotion-with-Logistic-Regression-classifier), we compared their performance with expert human coders. Results showed robust classification by LLMs, with over 80% accuracy and F1 scores above 0.85, and high human-model reliability (Cohen’s κ Md across top models = .80). RoB-ELoC and few-shot GPT-4 were standout classifiers, although somewhat less effective in categorizing intellectual humility. We offer example workflows for easy integration into research. Our proof-of-concept findings indicate the viability of both open-source and commercial LLMs in automating the coding of complex constructs, potentially transforming social science research.",
        "link": "http://dx.doi.org/10.31234/osf.io/x2f4a"
    },
    {
        "id": 10495,
        "title": "Analysis of CBDC Narrative OF Central Banks using Large Language Models",
        "authors": "Andres Alonso-Robisco, Jose Manuel Carbo",
        "published": "2023-8-11",
        "citations": 1,
        "abstract": "Central banks are increasingly using verbal communication for policymaking, focusing not only on traditional monetary policy, but also on a broad set of topics. One such topic is central bank digital currency (CBDC), which is attracting attention from the international community. The complex nature of this project means that it must be carefully designed to avoid unintended consequences, such as financial instability. We propose the use of different Natural Language Processing (NLP) techniques to better understand central banks’ stance towards CBDC, analyzing a set of central bank discourses from 2016 to 2022. We do this using traditional techniques, such as dictionary-based methods, and two large language models (LLMs), namely Bert and ChatGPT, concluding that LLMs better reflect the stance identified by human experts. In particular, we observe that ChatGPT exhibits a higher degree of alignment because it can capture subtler information than BERT. Our study suggests that LLMs are an effective tool to improve sentiment measurements for policy-specific texts, though they are not infallible and may be subject to new risks, like higher sensitivity to the length of texts, and prompt engineering.",
        "link": "http://dx.doi.org/10.53479/33412"
    },
    {
        "id": 10496,
        "title": "On the Question of Authorship in Large Language Models (LLMs)",
        "authors": "Carlin Soos, Levon Haroutunian",
        "published": "2023-9-26",
        "citations": 0,
        "abstract": "The adoption of pre-trained large language models (LLMs), like ChatGPT, across an increasingly diverse range of tasks and domains poses significant challenges for authorial attribution and other basic knowledge organization practices. This paper examines the theoretical and practical issues introduced by LLMs and describes how their use erodes the supposedly firm boundaries separating specific works and creators. Building upon the author-as-node framework proposed by Soos and Leazer (2020), we compare works created with and without the use of LLMs; ultimately, we argue that the issues associated with these novel tools are indicative of preexisting limitations within standard entity-relationship models. As the growing popularity of generative AI raises concerns about plagiarism, academic integrity, and intellectual property, we encourage a reevaluation of reductive work/creator associations and advocate for the adoption of a more expansive approach to authorship.",
        "link": "http://dx.doi.org/10.7152/nasko.v9i1.16299"
    },
    {
        "id": 10497,
        "title": "TEACHERS' PERSPECTIVES OF ASSESSMENT PRACTICES IN THE AGE OF LARGE LANGUAGE MODELS",
        "authors": "Erik Winerö, Johan Lundin",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21125/inted.2024.0641"
    },
    {
        "id": 10498,
        "title": "Enhancing Accuracy in Large Language Models Through Dynamic Real-Time Information Injection",
        "authors": "Qian Ouyang, Shiyu Wang, Bing Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "This study presents a novel approach to enhance Large Language Models (LLMs) like Alpaca by dynamically integrating real-time information. This method addresses the issue of content hallucination and data relevancy by automatically collecting and integrating current data from credible sources into model prompts. Experiments show a significant improvement in accuracy and a decrease in content hallucination, with a manageable increase in response time. The research underscores the potential of real-time data integration in making LLMs more accurate and contextually relevant, setting a foundation for future advancements in dynamic data processing in AI.",
        "link": "http://dx.doi.org/10.20944/preprints202312.1987.v1"
    },
    {
        "id": 10499,
        "title": "FinGPT: Open-Source Financial Large Language Models",
        "authors": "Hongyang Yang, Xiao-Yang Liu, Christina Dan Wang",
        "published": "2023",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4489826"
    },
    {
        "id": 10500,
        "title": "A Review of Current Trends, Techniques, and Challenges in Large Language Models (LLMs)",
        "authors": "Rajvardhan Patil, And Venkat Gudivada",
        "published": "No Date",
        "citations": 1,
        "abstract": "Natural language Processing (NLP) has significantly transformed in the last decade, especially in the field of Language Modeling. Large Language Models (LLMs) have achieved SOTA performances on Natural Language Understanding (NLU) and Natural Language Generation (NLG) tasks by learning language representation in self-supervised ways. This paper provides a comprehensive survey to capture the progression of advances in Language Models. In this paper, we examine the different aspects of Language Models, which started with a few million parameters but have reached the size of a trillion in a very short time. We also look at how these LLMs transitioned from task-specific to task-independent to task-and-language-independent architectures. This paper extensively discusses different pre-training objectives, benchmarks, and transfer learning methods used in LLMs. It also examines different fine-tuning and In-Context learning techniques used in downstream tasks. It also explores how LLMs can perform well across many domains and datasets if sufficiently trained on a large and diverse dataset. Next, it discusses how, over time, the availability of cheap computational power and large datasets have improved LLM&rsquo;s capabilities and raised new challenges. As part of our study, we also inspect LLMs from the lens of scalability to see how their performance is affected by the model&rsquo;s depth, width, and data size. Lastly, we provide an empirical comparison of existing trends and techniques and a comprehensive analysis of where the field of LLM currently stand.",
        "link": "http://dx.doi.org/10.20944/preprints202402.0357.v1"
    },
    {
        "id": 10501,
        "title": "Strength in Numbers: Estimating Confidence of Large Language Models by Prompt Agreement",
        "authors": "Gwenyth Portillo Wightman, Alexandra Delucia, Mark Dredze",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.trustnlp-1.28"
    },
    {
        "id": 10502,
        "title": "ChatGPT: Where Is a Silver Lining? Exploring the realm of GPT and large language models",
        "authors": "Elena Tikhonova, Lilia Raitskaya",
        "published": "2023-9-30",
        "citations": 0,
        "abstract": "Introduction: the JLE editors analyse the scope and depth of the subject area of ChatGPT and related topics based on the Scopus database. The Scopus statistics prove a skyrocketing rise in the number of publications in the field in question during 2023. The major alarming themes cover authorship and integrity related to AI-assisted writing, threats to educational practices, medicine, and malevolent uses of ChatGPT.\r\nKeywords Explained: the key terminology is defined, including generative pre-trained transformers (GPT); ChatGPT; artificial intelligence (AI); AI chatbots; natural language processing (NLP); large language models; Open AI; large language model (LLM).\r\nInternational Research on ChatGPT: as of September 24 2023, the Scopus database has indexed 1,935 publications, with “ChatGPT” in the title, abstract, or keywords. A skyrocketing rise in the number of research has been reported since the early days of 2023. 1,925 indexed publications out of 1,935 were published in 2023. Most of them came from the USA, India, the UK, and China. The number of documents indexed in the Scopus database as well as PubMed,  arXiv and others are exponentially rising.\r\nChatGPT in Education: the academic community has been actively discussing the challenges education will face in the era of ChatGPT in the context of the fundamental threats posed to the educational system. The latter include assessment procedures, information accuracy, and skill devaluation. As many complex technologies, generative pre-trained transformers are ambivalent in nature, providing a great potential for learning and education at large, including new approaches based on critical thinking and awareness of the pros and cons of AI.\r\nChatGPT in Science: great prospects for text generation and improvements in language quality adjoin to dubious authorship and potentially inconsistent and erroneous parts in the AI-produced texts. Publishers and journals are working out new publishing policies, including publishing ethics towards AI-assisted or AI-improved submissions.\r\nConclusion: JLE is planning to revise its editorial policy to address the new challenges from AI technologies. JLE editors welcome new submissions of research articles and reviews as well as special issues on ChatGPT and related themes, with potential applications of chatbots in education, innovative approaches to writing assignments, facilitating personalized learning, academic integrity issues related to AI-supported writing, etc. in focus.",
        "link": "http://dx.doi.org/10.17323/jle.2023.18119"
    },
    {
        "id": 10503,
        "title": "Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation",
        "authors": "Zeyuan Yang, Peng Li, Yang Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.109"
    },
    {
        "id": 10504,
        "title": "Team Cadence at MEDIQA-Chat 2023: Generating, augmenting and summarizing clinical dialogue with large language models",
        "authors": "Ashwyn Sharma, David Feldman, Aneesh Jain",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.clinicalnlp-1.28"
    },
    {
        "id": 10505,
        "title": "Select, Prompt, Filter: Distilling Large Language Models for Summarizing Conversations",
        "authors": "Minh-Quang Pham, Sathish Indurthi, Shamil Chollampatt, Marco Turchi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.753"
    },
    {
        "id": 10506,
        "title": "MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models",
        "authors": "Deepak Nathani, David Wang, Liangming Pan, William Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.407"
    },
    {
        "id": 10507,
        "title": "Large Language Models and Their Implications on Medical Education",
        "authors": "Henry Bair, Justin Norden",
        "published": "2023-8",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/acm.0000000000005265"
    },
    {
        "id": 10508,
        "title": "Shadows of Wisdom: Classifying Meta-cognitive and Morally-grounded Narrative Content via Large Language Models",
        "authors": "Alexander Stavropoulos, Damien Crone, Igor Grossmann",
        "published": "No Date",
        "citations": 0,
        "abstract": "We investigated Large Language Models' (LLMs) efficacy in classifying complex psychological constructs like intellectual humility, perspective-taking, open-mindedness, and search for a compromise in narratives of Canadian and American adults reflecting on a workplace conflict. Using state-of-the-art models like GPT-4 across few-shot and zero-shot paradigms and RoB-ELoC (RoBERTa-fine-tuned-on-Emotion-with-Logistic-Regression-classifier), we compared their performance with expert human coders. Results showed robust classification by LLMs, with over 80% accuracy and F1 scores above 0.85, and high human-model reliability (Cohen’s κ Md across top models = .80). RoB-ELoC and few-shot GPT-4 were standout classifiers, although somewhat less effective in categorizing intellectual humility. We offer example workflows for easy integration into research. Our proof-of-concept findings indicate the viability of both open-source and commercial LLMs in automating the coding of complex constructs, potentially transforming social science research.",
        "link": "http://dx.doi.org/10.31234/osf.io/x2f4a"
    },
    {
        "id": 10509,
        "title": "Analysis of CBDC Narrative OF Central Banks using Large Language Models",
        "authors": "Andres Alonso-Robisco, Jose Manuel Carbo",
        "published": "2023-8-11",
        "citations": 1,
        "abstract": "Central banks are increasingly using verbal communication for policymaking, focusing not only on traditional monetary policy, but also on a broad set of topics. One such topic is central bank digital currency (CBDC), which is attracting attention from the international community. The complex nature of this project means that it must be carefully designed to avoid unintended consequences, such as financial instability. We propose the use of different Natural Language Processing (NLP) techniques to better understand central banks’ stance towards CBDC, analyzing a set of central bank discourses from 2016 to 2022. We do this using traditional techniques, such as dictionary-based methods, and two large language models (LLMs), namely Bert and ChatGPT, concluding that LLMs better reflect the stance identified by human experts. In particular, we observe that ChatGPT exhibits a higher degree of alignment because it can capture subtler information than BERT. Our study suggests that LLMs are an effective tool to improve sentiment measurements for policy-specific texts, though they are not infallible and may be subject to new risks, like higher sensitivity to the length of texts, and prompt engineering.",
        "link": "http://dx.doi.org/10.53479/33412"
    },
    {
        "id": 10510,
        "title": "On the Question of Authorship in Large Language Models (LLMs)",
        "authors": "Carlin Soos, Levon Haroutunian",
        "published": "2023-9-26",
        "citations": 0,
        "abstract": "The adoption of pre-trained large language models (LLMs), like ChatGPT, across an increasingly diverse range of tasks and domains poses significant challenges for authorial attribution and other basic knowledge organization practices. This paper examines the theoretical and practical issues introduced by LLMs and describes how their use erodes the supposedly firm boundaries separating specific works and creators. Building upon the author-as-node framework proposed by Soos and Leazer (2020), we compare works created with and without the use of LLMs; ultimately, we argue that the issues associated with these novel tools are indicative of preexisting limitations within standard entity-relationship models. As the growing popularity of generative AI raises concerns about plagiarism, academic integrity, and intellectual property, we encourage a reevaluation of reductive work/creator associations and advocate for the adoption of a more expansive approach to authorship.",
        "link": "http://dx.doi.org/10.7152/nasko.v9i1.16299"
    },
    {
        "id": 10511,
        "title": "Enhancing Accuracy in Large Language Models Through Dynamic Real-Time Information Injection",
        "authors": "Qian Ouyang, Shiyu Wang, Bing Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "This study presents a novel approach to enhance Large Language Models (LLMs) like Alpaca by dynamically integrating real-time information. This method addresses the issue of content hallucination and data relevancy by automatically collecting and integrating current data from credible sources into model prompts. Experiments show a significant improvement in accuracy and a decrease in content hallucination, with a manageable increase in response time. The research underscores the potential of real-time data integration in making LLMs more accurate and contextually relevant, setting a foundation for future advancements in dynamic data processing in AI.",
        "link": "http://dx.doi.org/10.20944/preprints202312.1987.v1"
    },
    {
        "id": 10512,
        "title": "FinGPT: Open-Source Financial Large Language Models",
        "authors": "Hongyang Yang, Xiao-Yang Liu, Christina Dan Wang",
        "published": "2023",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4489826"
    },
    {
        "id": 10513,
        "title": "A Review of Current Trends, Techniques, and Challenges in Large Language Models (LLMs)",
        "authors": "Rajvardhan Patil, And Venkat Gudivada",
        "published": "No Date",
        "citations": 1,
        "abstract": "Natural language Processing (NLP) has significantly transformed in the last decade, especially in the field of Language Modeling. Large Language Models (LLMs) have achieved SOTA performances on Natural Language Understanding (NLU) and Natural Language Generation (NLG) tasks by learning language representation in self-supervised ways. This paper provides a comprehensive survey to capture the progression of advances in Language Models. In this paper, we examine the different aspects of Language Models, which started with a few million parameters but have reached the size of a trillion in a very short time. We also look at how these LLMs transitioned from task-specific to task-independent to task-and-language-independent architectures. This paper extensively discusses different pre-training objectives, benchmarks, and transfer learning methods used in LLMs. It also examines different fine-tuning and In-Context learning techniques used in downstream tasks. It also explores how LLMs can perform well across many domains and datasets if sufficiently trained on a large and diverse dataset. Next, it discusses how, over time, the availability of cheap computational power and large datasets have improved LLM&rsquo;s capabilities and raised new challenges. As part of our study, we also inspect LLMs from the lens of scalability to see how their performance is affected by the model&rsquo;s depth, width, and data size. Lastly, we provide an empirical comparison of existing trends and techniques and a comprehensive analysis of where the field of LLM currently stand.",
        "link": "http://dx.doi.org/10.20944/preprints202402.0357.v1"
    },
    {
        "id": 10514,
        "title": "TEACHERS' PERSPECTIVES OF ASSESSMENT PRACTICES IN THE AGE OF LARGE LANGUAGE MODELS",
        "authors": "Erik Winerö, Johan Lundin",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21125/inted.2024.0641"
    },
    {
        "id": 10515,
        "title": "HOLMS: Alternative Summary Evaluation with Large Language Models",
        "authors": "Yassine Mrabet, Dina Demner-Fushman",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.coling-main.498"
    },
    {
        "id": 10516,
        "title": "Weak supervision for Question Type Detection with large language models",
        "authors": "Jiřı́ Martı́nek, Christophe Cerisara, Pavel Kral, Ladislav Lenc, Josef Baloun",
        "published": "2022-9-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2022-345"
    },
    {
        "id": 10517,
        "title": "Large Language Models as a Substitute for Human Experts in Annotating Political Text",
        "authors": "Michael Heseltine, Bernhard Clemm von Hohenberg",
        "published": "No Date",
        "citations": 0,
        "abstract": "Large-scale text analysis has grown rapidly as a method in political science and beyond. To date, text-as-data methods rely on large volumes of human-annotated training examples, which places a premium on researcher resources. However, advances in large language models (LLMs) may make automated annotation increasingly viable. This paper tests the performance of GPT-4 across a range of scenarios relevant for analysis of political text. We compare GPT-4 coding with human expert coding of tweets and news articles across four variables (whether text is political, negativity, sentiment, and ideology) and across four countries (the United States, Chile, Germany, and Italy). GPT-4 coding is highly accurate, especially for shorter texts such as tweets, correctly classifying texts up to 95\\% of the time. Performance drops for longer news articles, and very slightly for non-English text. We introduce a ``hybrid'' coding approach, in which disagreements of multiple GPT-4 runs are adjudicated by a human expert, which boosts accuracy. Finally, we explore downstream effects, finding that transformer models trained on hand-coded or GPT-4-coded data yield almost identical outcomes. Our results suggests that LLM-assisted coding is a viable and cost-efficient approach, although consideration should be given to task complexity.",
        "link": "http://dx.doi.org/10.31219/osf.io/cx752"
    },
    {
        "id": 10518,
        "title": "Strategic Behavior of Large Language Models: Game Structure vs. Contextual Framing",
        "authors": "Babak Heydari, Nunzio Lorè",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4569717"
    },
    {
        "id": 10519,
        "title": "Harnessing Large Language Models for Satellite Ground Tests",
        "authors": "Brian J. Connolly, Kristen M. Anderson",
        "published": "2024-1-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2514/6.2024-0916"
    },
    {
        "id": 10520,
        "title": "SUMMATIVE-REFLECTION SUPPORT METHOD BY CLUSTERING WRITTEN REFLECTIONS USING LARGE LANGUAGE MODELS",
        "authors": "Kohei Maruyama, Yasuhiko Morimoto",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21125/iceri.2023.2258"
    },
    {
        "id": 10521,
        "title": "Large Language Models Answer Medical Questions Accurately, but Can’t Match Clinicians’ Knowledge",
        "authors": "Emily Harris",
        "published": "2023-9-5",
        "citations": 16,
        "abstract": "This Medical News article discusses new research on artificial intelligence systems such as ChatGPT and Med-PaLM.",
        "link": "http://dx.doi.org/10.1001/jama.2023.14311"
    },
    {
        "id": 10522,
        "title": "Large Language Models and the Reverse Turing Test",
        "authors": "Terrence J. Sejnowski",
        "published": "2023-2-17",
        "citations": 30,
        "abstract": "AbstractLarge language models (LLMs) have been transformative. They are pretrained foundational models that are self-supervised and can be adapted with fine-tuning to a wide range of natural language tasks, each of which previously would have required a separate network model. This is one step closer to the extraordinary versatility of human language. GPT-3 and, more recently, LaMDA, both of them LLMs, can carry on dialogs with humans on many topics after minimal priming with a few examples. However, there has been a wide range of reactions and debate on whether these LLMs understand what they are saying or exhibit signs of intelligence. This high variance is exhibited in three interviews with LLMs reaching wildly different conclusions. A new possibility was uncovered that could explain this divergence. What appears to be intelligence in LLMs may in fact be a mirror that reflects the intelligence of the interviewer, a remarkable twist that could be considered a reverse Turing test. If so, then by studying interviews, we may be learning more about the intelligence and beliefs of the interviewer than the intelligence of the LLMs. As LLMs become more capable, they may transform the way we interact with machines and how they interact with each other. Increasingly, LLMs are being coupled with sensorimotor devices. LLMs can talk the talk, but can they walk the walk? A road map for achieving artificial general autonomy is outlined with seven major improvements inspired by brain systems and how LLMs could in turn be used to uncover new insights into brain function.",
        "link": "http://dx.doi.org/10.1162/neco_a_01563"
    },
    {
        "id": 10523,
        "title": "Large language models are few-shot clinical information extractors",
        "authors": "Monica Agrawal, Stefan Hegselmann, Hunter Lang, Yoon Kim, David Sontag",
        "published": "2022",
        "citations": 38,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.130"
    },
    {
        "id": 10524,
        "title": "Large Language Models are legal but they are not: Making the case for a powerful LegalLLM",
        "authors": "Thanmay Jayakumar, Fauzan Farooqui, Luqman Farooqui",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.nllp-1.22"
    },
    {
        "id": 10525,
        "title": "Mitigating Societal Harms in Large Language Models",
        "authors": "Sachin Kumar, Vidhisha Balachandran, Lucille Njoo, Antonios Anastasopoulos, Yulia Tsvetkov",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-tutorial.5"
    },
    {
        "id": 10526,
        "title": "Large Language Models as Zero-Shot Human Models for Human-Robot Interaction",
        "authors": "Bowen Zhang, Harold Soh",
        "published": "2023-10-1",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iros55552.2023.10341488"
    },
    {
        "id": 10527,
        "title": "A Practical Survey on Zero-shot Prompt Design for In-context Learning",
        "authors": "Yinheng Li,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_069"
    },
    {
        "id": 10528,
        "title": "Revisiting Automated Topic Model Evaluation with Large Language Models",
        "authors": "Dominik Stammbach, Vilém Zouhar, Alexander Hoyle, Mrinmaya Sachan, Elliott Ash",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.581"
    },
    {
        "id": 10529,
        "title": "Generating medically-accurate summaries of patient-provider dialogue: A multi-stage approach using large language models",
        "authors": "Varun Nair, Elliot Schumacher, Anitha Kannan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.clinicalnlp-1.26"
    },
    {
        "id": 10530,
        "title": "TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models",
        "authors": "Zorik Gekhman, Jonathan Herzig, Roee Aharoni, Chen Elkind, Idan Szpektor",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.127"
    },
    {
        "id": 10531,
        "title": "NL2TL: Transforming Natural Languages to Temporal Logics using Large Language Models",
        "authors": "Yongchao Chen, Rujul Gandhi, Yang Zhang, Chuchu Fan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.985"
    },
    {
        "id": 10532,
        "title": "InstructTODS: Large Language Models for End-to-End Task-Oriented Dialogue Systems",
        "authors": "Willy Chung, Samuel Cahyawijaya, Bryan Wilie, Holy Lovenia, Pascale Fung",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.nlint-1.1"
    },
    {
        "id": 10533,
        "title": "Exploring how well Large-scale Masked Language Models can Recognize Grammatical Errors",
        "authors": "Manabu Kimura, Ryo Nagata, Kazuaki Hanawa",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.30.689"
    },
    {
        "id": 10534,
        "title": "Forming Trees with Treeformers",
        "authors": "Nilay Patel,  , Jeffrey Flanigan,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_090"
    },
    {
        "id": 10535,
        "title": "Learning the Visualness of Text Using Large Vision-Language Models",
        "authors": "Gaurav Verma, Ryan Rossi, Christopher Tensmeyer, Jiuxiang Gu, Ani Nenkova",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.147"
    },
    {
        "id": 10536,
        "title": "Large Language Models Reduce Agency Costs",
        "authors": "Darcy W E Allen, Chris Berg, Nataliya Ilyushina, Jason Potts",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4437679"
    },
    {
        "id": 10537,
        "title": "“Personhood and AI: Why large language models don’t understand us”",
        "authors": "Jacob Browning",
        "published": "2023-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00146-023-01724-y"
    },
    {
        "id": 10538,
        "title": "Towards Human-Ai Collaborative Urban Science Research Enabled by Pre-Trained Large Language Models",
        "authors": "Jiayi Fu, Haoying Han, Xing Su, Chao Fan",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4463299"
    },
    {
        "id": 10539,
        "title": "Forward Learning of Large Language Models by Consumer Devices",
        "authors": "Danilo Pietro Pau, Fabrizio Maria Aymone",
        "published": "2024-1-18",
        "citations": 0,
        "abstract": "Large Language Models achieve state of art performances on a broad variety of Natural Language Processing tasks. In the pervasive IoT era, their deployment on edge devices is more compelling than ever. However, their gigantic model footprint has hindered on-device learning applications which enable AI models to continuously learn and adapt to changes over time. Back-propagation, in use by the majority of deep learning frameworks, is computationally intensive and requires storing intermediate activations into memory to cope with the model’s weights update. Recently, “Forward-only algorithms” have been proposed since they are biologically plausible alternatives. By applying more “forward” passes, this class of algorithms can achieve memory reductions with respect to more naive forward-only approaches and by removing the need to store intermediate activations. This comes at the expense of increased computational complexity. This paper considered three Large Language Model: DistilBERT, GPT-3 Small and AlexaTM. It investigated quantitatively any improvements about memory usage and computational complexity brought by known approaches named PEPITA and MEMPEPITA with respect to backpropagation. For low number of tokens in context, and depending on the model, PEPITA increases marginally or reduces substantially arithmetic operations. On the other hand, for large number of tokens in context, PEPITA reduces computational complexity by 30% to 50%. MEMPEPITA increases PEPITA’s complexity by one third. About memory, PEPITA and backpropagation, require a comparable amount of memory to store activations, while MEMPEPITA reduces it by 50% to 94% with the benefits being more evident for architectures with a long sequence of blocks. In various real case scenarios, MEMPEPITA’s memory reduction was essential for meeting the tight memory requirements of 128 MB equipped edge consumer devices, which are commonly available as smartphone and industrial application multi processors.",
        "link": "http://dx.doi.org/10.3390/electronics13020402"
    },
    {
        "id": 10540,
        "title": "Large language models help facilitate the automated synthesis of information on potential pest controllers",
        "authors": "Daan Scheepens, Joseph Millard, Maxwell Farrell, Tim Newbold",
        "published": "No Date",
        "citations": 0,
        "abstract": "The body of ecological literature, which informs much of our knowledge of the global loss of biodiversity, has been experiencing rapid growth in recent decades. The increasing difficulty to synthesise this literature manually has simultaneously resulted in a growing demand for automated text mining methods. Within the domain of deep learning, large language models (LLMs) have been the subject of considerable attention in recent years by virtue of great leaps in progress and a wide range of potential applications, however, quantitative investigation into their potential in ecology has so far been lacking. In this work, we analyse the ability of GPT-4 to extract information about invertebrate pests and pest controllers from abstracts of a body of literature on biological pest control, using a bespoke, zero-shot prompt. Our results show that the performance of GPT-4 is highly competitive with other state-of-the-art tools used for taxonomic named entity recognition and geographic location extraction tasks. On a held-out test set, we show that species and geographic locations are extracted with F1-scores of 99.8% and 95.3%, respectively, and highlight that the model is able to distinguish very effectively between the primary roles of interest (predators, parasitoids and pests). Moreover, we demonstrate the ability of the model to effectively extract and predict taxonomic information across various taxonomic ranks, and to automatically correct spelling mistakes. However, we do report a small number of cases of fabricated information (hallucinations). As a result of the current lack of specialised, pre-trained ecological language models, general-purpose LLMs may provide a promising way forward in ecology. Combined with tailored prompt engineering, such models can be employed for a wide range of text mining tasks in ecology, with the potential to greatly reduce time spent on manual screening and labelling of the literature.",
        "link": "http://dx.doi.org/10.1101/2024.01.12.575330"
    },
    {
        "id": 10541,
        "title": "A Voice-Controlled Motion Reproduction Using Large Language Models for Polishing Robots",
        "authors": "Yuki Tanaka, Seiichiro Katsura",
        "published": "2023-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icm54990.2023.10101966"
    },
    {
        "id": 10542,
        "title": "The impact of Large-scale language models on the future development of accounting",
        "authors": "",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.61784/wmsv2n187"
    },
    {
        "id": 10543,
        "title": "Safeguarding Ethical AI: Detecting Potentially Sensitive Data Re-Identification and Generation of Misleading or Abusive Content from Quantized Large Language Models",
        "authors": "Navya Kollapally, James Geller",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012411900003657"
    },
    {
        "id": 10544,
        "title": "Blackbird language matrices (BLM), a new task for rule-like generalization in neural networks: Can Large Language Models pass the test?",
        "authors": "Paola Merlo",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.546"
    },
    {
        "id": 10545,
        "title": "Large Language Models Can Self-Improve",
        "authors": "Jiaxin Huang, Shixiang Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, Jiawei Han",
        "published": "2023",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.67"
    },
    {
        "id": 10546,
        "title": "Large language models overcome the challenges of unstructured text data in ecology",
        "authors": "Andry Castro, João Pinto, Luís Reino, Pavel Pipek, César Capinha",
        "published": "No Date",
        "citations": 0,
        "abstract": "ABSTRACTThe vast volume of unstructured textual data, such as that found in research papers, news outlets, and technical reports, holds largely untapped potential for ecological research. However, the labour-intensive nature of manually processing such data presents a considerable challenge. In this work, we explore the application of three state-of-the-art Large Language Models (LLMs) — ChatGPT 3.5, ChatGPT 4, and LLaMA-2-70B — to automate the identification, interpretation, extraction, and structuring of relevant ecological information from unstructured textual sources. Our focus is specifically on species distribution data, using two challenging sources of these data: news outlets and research papers. We assess the LLMs on four key parameters: identification of documents providing species distribution data, identification of regions where species observations are mentioned, generation of geographical coordinates for these regions, and provisioning of results in a structured format. Our results show that ChatGPT 4 consistently outperforms the other models, demonstrating a high capacity to interpret textual narratives and to extract relevant information, with a percentage of correct outputs often exceeding 90%. However, performance also seems dependent on the type of data source used and task tested – with better results being achieved for news texts and in identifying regions where species were observed and presenting structured output. Its predecessor, ChatGPT 3.5, delivers reasonably lower accuracy levels across tasks and data sources, while LLaMA-2-70B performed worse. The integration of LLMs into ecological data assimilation workflows appears not only imminent, but also essential to meet the growing challenge of efficiently processing an increasing volume of textual data.",
        "link": "http://dx.doi.org/10.1101/2024.01.23.576654"
    },
    {
        "id": 10547,
        "title": "Large language models help computer programs to evolve",
        "authors": "Jean-Baptiste Mouret",
        "published": "2024-1-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/d41586-023-03998-0"
    },
    {
        "id": 10548,
        "title": "Analysis of CBDC Narrative of Central Banks using Large Language Models",
        "authors": "José Manuel Carbó, Andrés Alonso",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4542162"
    },
    {
        "id": 10549,
        "title": "Large Language Models for Qualitative Research in Software Engineering: Exploring Opportunities and Challenges",
        "authors": "Muneera Bano, Rashina Hoda, Didar Zowghi, Christoph Treude",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe recent surge in the integration of Large Language Models (LLMs) like ChatGPT into qualitative research in software engineering, much like in other professional domains, demands a closer inspection. This vision paper seeks to explore the opportunities of using LLMs in qualitative research to address many of its legacy challenges as well as potential new concerns and pitfalls arising from the use of LLMs. We share our vision for the evolving role of the qualitative researcher in the age of LLMs and contemplate how they may utilize LLMs at various stages of their research experience.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3614628/v1"
    },
    {
        "id": 10550,
        "title": "Comment on: AI am a rheumatologist: a practical primer to large language models for rheumatologists",
        "authors": "Partha Pratim Ray",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/rheumatology/kead658"
    },
    {
        "id": 10551,
        "title": "Connecting AI: Merging Large Language Models and Knowledge Graph",
        "authors": "Mlađan Jovanović, Mark Campbell",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mc.2023.3305206"
    },
    {
        "id": 10552,
        "title": "Evaluation of Medium-large Language Models at Zero-shot Closed Book Generative Question Answering",
        "authors": "René Peinl, Johannes Wirth",
        "published": "2024-1-20",
        "citations": 0,
        "abstract": "Large language models (LLMs) have garnered significant attention, but the definition of “large” lacks clarity. This paper focuses on medium-sized language models (MLMs), defined as having at least six billion parameters but less than 100 billion. The study evaluates MLMs regarding zero-shot generative question answering, which requires models to provide elaborate answers without external document retrieval. The paper introduces an own test dataset and presents results from human evaluation. Results show that combining the best answers from different MLMs yielded an overall correct answer rate of 82.7% which is better than the 60.9% of ChatGPT. The best MLM achieved 71.8% and has 33B parameters, which highlights the importance of using appropriate training data for fine-tuning rather than solely relying on the number of parameters. More finegrained feedback should be used to further improve the quality of answers. The open source community is quickly closing the gap to the best commercial models.",
        "link": "http://dx.doi.org/10.5121/csit.2024.140106"
    },
    {
        "id": 10553,
        "title": "Ontologies in the era of large language models – a perspective",
        "authors": "Fabian Neuhaus",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "The potential of large language models (LLM) has captured the imagination of the public and researchers alike. In contrast to previous generations of machine learning models, LLMs are general-purpose tools, which can communicate with humans. In particular, they are able to define terms and answer factual questions based on some internally represented knowledge. Thus, LLMs support functionalities that are closely related to ontologies. In this perspective article, I will discuss the consequences of the advent of LLMs for the field of applied ontology.",
        "link": "http://dx.doi.org/10.3233/ao-230072"
    },
    {
        "id": 10554,
        "title": "Large language models must serve clinicians, not the reverse",
        "authors": "Richard Armitage",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s1473-3099(24)00140-3"
    },
    {
        "id": 10555,
        "title": "COMPARISON OF HUMAN AND MODERN LARGE LANGUAGE MODELS THINKING",
        "authors": "Daniil Maksymenko, Artem Khovrat, Valentyna Shtanko",
        "published": "2023-12-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36074/logos-22.12.2023.070"
    },
    {
        "id": 10556,
        "title": "Knowledge Retrieval and Diagnostics in Cloud Services with Large Language Models",
        "authors": "Ashot Baghdasaryan, Tigran Bunarjyan, Arnak Poghosyan, Ashot Harutyunyan, Jad El-Zein",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4690081"
    },
    {
        "id": 10557,
        "title": "Using Local Large Language Models to Simplify Requirement Engineering Documents in the Automotive Industry",
        "authors": "Victor Momodu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4574992"
    },
    {
        "id": 10558,
        "title": "The Effectiveness of Large Language Models (Chatgpt and Codebert) for Security-Oriented Code Analysis",
        "authors": "Zhilong Wang, Lan Zhang, Chen Cao, Peng Liu",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4567887"
    },
    {
        "id": 10559,
        "title": "A Policy on the Use of Artificial Intelligence and Large Language Models in Peer Review",
        "authors": "Marcus Munafò",
        "published": "2023-12-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/ntr/ntad242"
    },
    {
        "id": 10560,
        "title": "Large Language Models Evaluate Machine Translation via Polishing",
        "authors": "Yiheng Wang",
        "published": "2023-12-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3639631.3639658"
    },
    {
        "id": 10561,
        "title": "Use of Large Language Models: Editorial Comments",
        "authors": "Sam Polesie, Olle Larkö",
        "published": "2023-2-16",
        "citations": 7,
        "abstract": "Abstract is missing (Editorial)",
        "link": "http://dx.doi.org/10.2340/actadv.v103.9593"
    },
    {
        "id": 10562,
        "title": "Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education",
        "authors": "Mahyar Abedi, Ibrahem Alshybani, MRB Shahadat, Michael Murillo",
        "published": "No Date",
        "citations": 0,
        "abstract": "In the rapidly evolving landscape of education, digital technologies have repeatedly disrupted traditional pedagogical methods. This paper explores the latest of these disruptions: the potential integration of large language models (LLMs) and chatbots into graduate engineering education. We begin by tracing historical and technological disruptions to provide context and then introduce key terms such as machine learning and deep learning and the underlying mechanisms of recent advancements, namely attention/transformer models and graphics processing units. The heart of our investigation lies in the application of an LLM-based chatbot in a graduate fluid mechanics course. We developed a question bank from the course material and assessed the chatbot's ability to provide accurate, insightful responses. The results are encouraging, demonstrating not only the bot's ability to effectively answer complex questions but also the potential advantages of chatbot usage in the classroom, such as the promotion of self-paced learning, the provision of instantaneous feedback, and the reduction of instructors' workload. The study also examines the transformative effect of intelligent prompting on enhancing the chatbot's performance. Furthermore, we demonstrate how powerful plugins like Wolfram Alpha for mathematical problem-solving and code interpretation can significantly extend the chatbot's capabilities, transforming it into a comprehensive educational tool. While acknowledging the challenges and ethical implications surrounding the use of such AI models in education, we advocate for a balanced approach. The use of LLMs and chatbots in graduate education can be greatly beneficial but requires ongoing evaluation and adaptation to ensure ethical and efficient use. This paper invites further research and dialogue in this emerging field, with the goal of responsibly harnessing these technologies to advance higher education.",
        "link": "http://dx.doi.org/10.32388/md04b0"
    },
    {
        "id": 10563,
        "title": "Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education",
        "authors": "Mahyar Abedi, Ibrahem Alshybani, MRB Shahadat, Michael Murillo",
        "published": "No Date",
        "citations": 0,
        "abstract": "In the rapidly evolving landscape of education, digital technologies have repeatedly disrupted traditional pedagogical methods. This paper explores the latest of these disruptions: the potential integration of large language models (LLMs) and chatbots into graduate engineering education. We begin by tracing historical and technological disruptions to provide context and then introduce key terms such as machine learning and deep learning and the underlying mechanisms of recent advancements, namely attention/transformer models and graphics processing units. The heart of our investigation lies in the application of an LLM-based chatbot in a graduate fluid mechanics course. We developed a question bank from the course material and assessed the chatbot's ability to provide accurate, insightful responses. The results are encouraging, demonstrating not only the bot's ability to effectively answer complex questions but also the potential advantages of chatbot usage in the classroom, such as the promotion of self-paced learning, the provision of instantaneous feedback, and the reduction of instructors' workload. The study also examines the transformative effect of intelligent prompting on enhancing the chatbot's performance. Furthermore, we demonstrate how powerful plugins like Wolfram Alpha for mathematical problem-solving and code interpretation can significantly extend the chatbot's capabilities, transforming it into a comprehensive educational tool. While acknowledging the challenges and ethical implications surrounding the use of such AI models in education, we advocate for a balanced approach. The use of LLMs and chatbots in graduate education can be greatly beneficial but requires ongoing evaluation and adaptation to ensure ethical and efficient use. This paper invites further research and dialogue in this emerging field, with the goal of responsibly harnessing these technologies to advance higher education.\n",
        "link": "http://dx.doi.org/10.32388/md04b0.2"
    },
    {
        "id": 10564,
        "title": "Was That a Question? Automatic Classification of Discourse Meaning in Spanish",
        "authors": "Santiago Arróniz,  , Sandra Kübler,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_015"
    },
    {
        "id": 10565,
        "title": "OffensEval 2023: Offensive language identification in the age of Large Language Models",
        "authors": "Marcos Zampieri, Sara Rosenthal, Preslav Nakov, Alphaeus Dmonte, Tharindu Ranasinghe",
        "published": "2023-11",
        "citations": 0,
        "abstract": "AbstractThe OffensEval shared tasks organized as part of SemEval-2019–2020 were very popular, attracting over 1300 participating teams. The two editions of the shared task helped advance the state of the art in offensive language identification by providing the community with benchmark datasets in Arabic, Danish, English, Greek, and Turkish. The datasets were annotated using the OLID hierarchical taxonomy, which since then has become the de facto standard in general offensive language identification research and was widely used beyond OffensEval. We present a survey of OffensEval and related competitions, and we discuss the main lessons learned. We further evaluate the performance of Large Language Models (LLMs), which have recently revolutionalized the field of Natural Language Processing. We use zero-shot prompting with six popular LLMs and zero-shot learning with two task-specific fine-tuned BERT models, and we compare the results against those of the top-performing teams at the OffensEval competitions. Our results show that while some LMMs such as Flan-T5 achieve competitive performance, in general LLMs lag behind the best OffensEval systems.",
        "link": "http://dx.doi.org/10.1017/s1351324923000517"
    },
    {
        "id": 10566,
        "title": "Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking",
        "authors": "Shengyao Zhuang, Bing Liu, Bevan Koopman, Guido Zuccon",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.590"
    },
    {
        "id": 10567,
        "title": "Utilizing Natural Language Processing and Large Language Models in the Diagnosis and Prediction of Infectious Diseases: A Systematic Review",
        "authors": "Mahmud Omar, Dana Brin, Benjamin Glicksberg, Eyal Klang",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractBackgroundNatural Language Processing (NLP) and Large Language Models (LLMs) hold largely untapped potential in infectious disease management. This review explores their current use and uncovers areas needing more attention.MethodsThis analysis followed systematic review procedures, registered with PROSPERO. We conducted a search across major databases including PubMed, Embase, Web of Science, and Scopus, up to December 2023, using keywords related to NLP, LLM, and infectious diseases. We also employed the QUADAS-2 tool for evaluating the quality and robustness of the included studies.ResultsOur review identified 15 studies with diverse applications of NLP in infectious disease management. Notable examples include GPT-4’s application in detecting urinary tract infections and BERTweet’s use in Lyme Disease surveillance through social media analysis. These models demonstrated effective disease monitoring and public health tracking capabilities. However, the effectiveness varied across studies. For instance, while some NLP tools showed high accuracy in pneumonia detection and high sensitivity in identifying invasive mold diseases from medical reports, others fell short in areas like bloodstream infection management.ConclusionThis review highlights the yet-to-be-fully-realized promise of NLP and LLMs in infectious disease management. It calls for more exploration to fully harness AI’s capabilities, particularly in the areas of diagnosis, surveillance, predicting disease courses, and tracking epidemiological trends.",
        "link": "http://dx.doi.org/10.1101/2024.01.14.24301289"
    },
    {
        "id": 10568,
        "title": "Large Language Models as Instructors: A Study on Multilingual Clinical Entity Extraction",
        "authors": "Simon Meoni, Eric De la Clergerie, Theo Ryffel",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bionlp-1.15"
    },
    {
        "id": 10569,
        "title": "Large language models and the treaty interpretation game",
        "authors": "Jack Wright Nelson",
        "published": "2023-12-28",
        "citations": 0,
        "abstract": "Large language models (LLMs) are currently disrupting law. Yet their precise impact on international law, especially treaty interpretation, remains underexplored. Treaty interpretation can be analogised to a game in which ‘players’ strategically deploy ‘cards’, usually principles of treaty interpretation, to persuade an ‘audience’ that their interpretation is correct. Leveraging this analogy, this paper offers a limited case study of how OpenAI’s ChatGPT, a prominent LLM-based chatbot, navigates the treaty interpretation game. In line with the existing research on ChatGPT’s legal abilities, the author concludes that ChatGPT competently plays the treaty interpretation game. This conclusion leads to a broader discussion of how LLM usage may impact international law’s development. The argument advanced is that, while LLMs have the potential to enhance efficiency and accessibility, biased training data and interpretative standardisation could reinforce international law’s dominant narratives. As such, this paper concludes with a cautionary note: the potential gains derived from LLMs risk being offset by disciplinary stagnation.",
        "link": "http://dx.doi.org/10.4337/cilj.2023.02.08"
    },
    {
        "id": 10570,
        "title": "Large language models and brain-inspired general intelligence",
        "authors": "Bo Xu, Mu-ming Poo",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/nsr/nwad267"
    },
    {
        "id": 10571,
        "title": "Automating Psychological Hypothesis Generation with AI: Large Language Models Meet Causal Graph",
        "authors": "Song Tong, Kai Mao, Zhen Huang, Yukun Zhao, Kaiping Peng",
        "published": "No Date",
        "citations": 0,
        "abstract": "Leveraging the synergy between causal knowledge graphs and a large language model (LLM), our study introduces a groundbreaking approach for computational hypothesis generation in psychology. We analyzed 43,312 psychology articles using the LLM and other machine learning tools, extracting causal relation pairs. This analysis produced a specialized causal graph for psychology. Applying link prediction algorithms, we generated 130 potential psychological hypotheses focusing on `well-being', then compared them against research ideas conceived by doctoral scholars and those produced solely by the LLM. Interestingly, our combined approach of LLM and causal graph mirrored expert-level insights in terms of novelty, clearly surpassing the LLM-only hypotheses. This alignment was further corroborated using deep semantic analysis. Our results show that combining LLM with machine learning techniques like causal knowledge graphs can revolutionize automated discovery in psychology, extracting novel insights from extensive literature. This work stands at the crossroads of psychology and artificial intelligence, championing a new enriched paradigm for data-driven hypothesis generation in psychological research.",
        "link": "http://dx.doi.org/10.31234/osf.io/7ck9m"
    },
    {
        "id": 10572,
        "title": "Synthetic Replacements for Human Survey Data? The Perils of Large Language Models",
        "authors": "James Bisbee, Joshua Clinton, Cassy Dorff, Brenton Kenkel, Jennifer Larson",
        "published": "No Date",
        "citations": 2,
        "abstract": "Large Language Models (LLMs) offer new research possibilities for social scientists, but their potential as \"synthetic data\" is still largely unknown. In this paper, we investigate how accurately the popular closed-source LLM ChatGPT can recover public opinion, prompting the LLM to adopt different \"personas\" and then provide feeling thermometer scores for 11 sociopolitical groups. The average scores generated by ChatGPT correspond closely to the averages in our baseline survey, the 2016–2020 American National Election Study. Nevertheless, sampling by ChatGPT is not reliable for statistical inference: there is less variation in responses than in the real surveys, and regression coefficients often differ significantly from equivalent estimates obtained using ANES data. We also document how the distribution of synthetic responses varies with minor changes in prompt wording, and we show how the same prompt yields significantly different results over a three-month period. Altogether, our findings raise serious concerns about the quality, reliability, and reproducibility of synthetic survey data generated by LLMs.",
        "link": "http://dx.doi.org/10.31235/osf.io/5ecfa"
    },
    {
        "id": 10573,
        "title": "Beyond the hype: large language models propagate race-based medicine",
        "authors": "Jesutofunmi A. Omiye, Jenna Lester, Simon Spichak, Veronica Rotemberg, Roxana Daneshjou",
        "published": "No Date",
        "citations": 1,
        "abstract": "ImportanceLarge language models (LLMs) are being integrated into healthcare systems; but these models recapitulate harmful, race-based medicine.ObjectiveThe objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that historically included race-based medicine or widespread misconceptions around race.Evidence ReviewQuestions were derived from discussion among 4 physician experts and prior work on race-based medical misconceptions of medical trainees.FindingsWe assessed four large language models with eight different questions that were interrogated five times each with a total of forty responses per a model. All models had examples of perpetuating race-based medicine in their responses. Models were not always consistent in their responses when asked the same question repeatedly.Conclusions and RelevanceLLMs are being proposed for use in the healthcare setting, with some models already connecting to electronic health record systems. However, this study shows that based on our findings, these LLMs could potentially cause harm by perpetuating debunked, racist concepts.",
        "link": "http://dx.doi.org/10.1101/2023.07.03.23292192"
    },
    {
        "id": 10574,
        "title": "Harnessing the Power of Large Language Models (LLMs) for Electronic Health Records (EHRs) Optimization",
        "authors": "Abdulqadir  J Nashwan, Ahmad A AbuJaber",
        "published": "2023-7-29",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7759/cureus.42634"
    },
    {
        "id": 10575,
        "title": "How true is the role of large language models in  nursing?",
        "authors": "Partha Pratim Ray",
        "published": "2024-1-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/eurjcn/zvad123"
    },
    {
        "id": 10576,
        "title": "GPT-InvestAR: Enhancing Stock Investment Strategies through Annual Report Analysis with Large Language Models",
        "authors": "Udit Gupta",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4568964"
    },
    {
        "id": 10577,
        "title": "Wealth of Nations, Wealth of Data: How GDP Shapes Diverse Large Language Models like ChatGPT : Interviewing Assorted Open Source Generative AI Models",
        "authors": "Alex Kaplunovich",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386329"
    },
    {
        "id": 10578,
        "title": "Extracting insights from scientific publications using large language models",
        "authors": "Robert Allaway, Julie Bletz",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21428/4f83582b.bfc5e9cb"
    },
    {
        "id": 10579,
        "title": "Applications of ChatGPT and Large Language Models in Medicine and Health Care: Benefits and Pitfalls",
        "authors": "Andrew A Borkowski",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.12788/fp.0386"
    },
    {
        "id": 10580,
        "title": "Exploring the Frontier of Prompting Techniques in Large Language Models",
        "authors": "Oluwole Fagbohun",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.51219/urforum.2023.oluwole-fagbohun"
    },
    {
        "id": 10581,
        "title": "Improving Autonomy and Natural Interaction of Pepper Robot via Large Language Models",
        "authors": "Luccas Rojas Becerra, Juan Andrés Romero Colmenares, Rubén Manrique",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe field of Social Robotics is concerned with the development and enhancement of robots as interactive social companions and tools, aimed at aiding humans in a variety of tasks. Despite the ongoing progress, a primary issue encountered is the discrepancy between human instructions and the robot's interpretation and execution of these directives. Often, this is attributed to the deterministic nature of pre-defined programming, resulting in poor performance during tasks that deviate from this programming. This research contributes to this problem and proposes a solution to this predicament by enhancing the autonomous function and interaction of a Pepper robot through the assessment of a Large Language Model (LLMs). By leveraging LLM capabilities, the objective is to create a system allowing the robot to autonomously interpret instructions given in natural language to perform general-purpose tasks. The study involves the comparison of different LLMs proficiency in generating code commands for robotics. The assessment of the quality and efficiency of the produced code will be grounded upon the results of code execution, leveraging diverse strategies and code abstraction tiers. The evaluation methodology combines automated tests along with human evaluations. Our principal contribution encompasses the development of a task-processing system that links natural language instructions to robotic operations. Furthermore, our analysis revealed that precisely 400 out of 720 algorithmically generated tasks successfully passed the automated runtime execution evaluation. Among the LLMs scrutinized, GPT-4 registered the highest success rate in task completion (50.8%).",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3997840/v1"
    },
    {
        "id": 10582,
        "title": "DistilBERT: A Novel Approach to Detect Text Generated by Large Language Models (LLM)",
        "authors": "BV Pranay Kumar, MD Shaheer Ahmed, Manchala Sadanandam",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nLarge language models (LLMs) have emerged as powerful tools for generating human-quality text, raising concerns about their potential for misuse in academic settings. This paper investigates the use of DistilBERT, a distilled version of BERT, for detecting LLM-generated text. We evaluate its performance on two publicly available datasets, LLM-Detect AI Generated Text and DAIGT-V3 Train Dataset, achieving an average accuracy of around 94%. Our findings suggest that DistilBERT is a promising tool for safeguarding academic integrity in the era of LLMs.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3909387/v1"
    },
    {
        "id": 10583,
        "title": "On the Question of Authorship in Large Language Models",
        "authors": "Carlin Soos, Levon Haroutunian",
        "published": "2024",
        "citations": 0,
        "abstract": "Adoption of pre-trained large language models (LLMs) across an increasingly diverse range of tasks and domains poses significant problems for authorial attribution and other basic knowl­edge organization practices. Utilizing methods from value-sensitive design, this paper examines the theoretical, practical, and ethical issues introduced by LLMs and describes how their use challenges the supposedly firm boundaries separating specific works and creators. Focusing on the implications of LLM usage for higher education, we use hypothetical value scenarios and stakeholder analysis to weigh the pedagogical risks and benefits of LLM usage, assessing the consequences of their use on and beyond college campuses. While acknowledging the unique challenges presented by this emerging educational trend, we ultimately argue that the issues associated with these novel tools are indicative of preexisting limitations within standard entity-relationship models, not wholly new issues ushered in by the advent of a relatively young technology. We contend that LLM-generated texts largely exacerbate, rather than invent from scratch, the preexisting faults that have frequently posed problems to those seeking to determine, ascribe, and regulate authorship attributions. As the growing popularity of generative AI raises concerns about plagiarism, academic integrity, and intellectual property, we advocate for a reevaluation of reductive work-creator associations and encourage the adoption of more expansive authorial concepts.  ",
        "link": "http://dx.doi.org/10.5771/0943-7444-2024-2-83"
    },
    {
        "id": 10584,
        "title": "Collaborative Storytelling with Large-scale Neural Language Models",
        "authors": "Eric Nichols, Leo Gao, Randy Gomez",
        "published": "2020-10-16",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3424636.3426903"
    },
    {
        "id": 10585,
        "title": "Distillation of Large Language Models for Text Simplification",
        "authors": "Олександр Скуржанський",
        "published": "2023-11-22",
        "citations": 0,
        "abstract": "This work presents a comprehensive methodology for harnessing the capabilities of Large Language Models to address specific Natural Language Processing tasks, with a focus on Text Simplification. While LLMs have demonstrated their prowess in tackling a wide range of NLP challenges, their demanding computational requirements can render them impractical for real-time online inference. In response to this limitation, we suggest the concept of text distillation, a technique aimed at effectively transferring the knowledge stored within LLMs to more compact and computationally efficient neural networks.",
        "link": "http://dx.doi.org/10.31713/mcit.2023.071"
    },
    {
        "id": 10586,
        "title": "What do Large Language Models Learn about Scripts?",
        "authors": "Abhilasha Sancheti, Rachel Rudinger",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.starsem-1.1"
    },
    {
        "id": 10587,
        "title": "Leveraging Cognitive Science for Testing Large Language Models",
        "authors": "Ramya Srinivasan, Hiroya Inakoshi, Kanji Uchino",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aitest58265.2023.00035"
    },
    {
        "id": 10588,
        "title": "Large Fourth-Generation Language Models as a New Tool in Scientific Research",
        "authors": "Alexey Bragin",
        "published": "2023",
        "citations": 0,
        "abstract": "In this study, the latest achievements in the field of deep learning, including convolutional, recurrent, and graph neural networks and attention mechanisms, as well as their contribution to the development of pre-trained language models, are examined. A brief literature review is presented, discussing the use of pre-trained language models in scientific research and education in various fields of science. Experiments are conducted on the application of ChatGPT in the field of economics. The authors present an analysis of the advantages and limitations associated with ChatGPT, providing recommendations for its use in scientific work. Additionally, the article demonstrates the ability of ChatGPT to generate C# programs for agent-based models (ABM) and computable general equilibrium (CGE) models, highlighting its potential for interdisciplinary research and practical applications in economics and computational modeling.",
        "link": "http://dx.doi.org/10.18254/s207751800025046-9"
    },
    {
        "id": 10589,
        "title": "Large Language Models for Cultural Heritage",
        "authors": "Georgios Trichopoulos",
        "published": "2023-9-27",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3609987.3610018"
    },
    {
        "id": 10590,
        "title": "Reasoning in Large Language Models Through Symbolic Math Word Problems",
        "authors": "Vedant Gaur, Nikunj Saunshi",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.364"
    },
    {
        "id": 10591,
        "title": "Review for \"Large-Scale Text Analysis Using Generative Language Models: A Case Study in Discovering Public Value Expressions in AI Patents\"",
        "authors": "Arash Hajikhani",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1162/qss_a_00285/v2/review1"
    },
    {
        "id": 10592,
        "title": "Llm-Commentator: Novel Fine-Tuning Strategies of Large Language Models for Automatic Commentary Generation Using Football Event Data",
        "authors": "Alec Cook, Oktay Karakus",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4715915"
    },
    {
        "id": 10593,
        "title": "Generative Artificial Intelligence, Large Language Models, and JID Innovations",
        "authors": "Russell P. Hall",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.xjidi.2024.100256"
    },
    {
        "id": 10594,
        "title": "Towards Reasoning in Large Language Models: A Survey",
        "authors": "Jie Huang, Kevin Chen-Chuan Chang",
        "published": "2023",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.67"
    },
    {
        "id": 10595,
        "title": "Large Language Models",
        "authors": "Vinton G. Cerf",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3606337"
    },
    {
        "id": 10596,
        "title": "Large Language Models for Causal Discovery in the Earth Sciences",
        "authors": "Gustau Camps-Valls, Kai-Hendrik Cohrs, Emiliano Diaz, Vasileios Sitokonstantinou, Gherardo Varando",
        "published": "No Date",
        "citations": 0,
        "abstract": "Causality is essential for understanding complex systems like the Earth and climate, where a plethora of intertwined variables and processes happen in the wild. Constructing causal graphs often relies on either data-driven or expert-driven approaches, both fraught with challenges. The former methods, like the celebrated Peter-Clark (PC) algorithm, face issues with data requirements and assumptions of causal sufficiency, while the latter demand substantial time and expertise.\nThis work explores the capabilities of Large Language Models (LLMs) as an alternative to domain experts for causal graph generation. We frame conditional independence queries as prompts to LLMs and employ the PC algorithm with the answers. The performances of the LLM-based conditional independence oracle on systems with known causal graphs show a high degree of variability. We improve the performance through a proposed statistical-inspired voting schema that allows control over false-positives and false-negatives rates. We apply our chatPC algorithm to understand the causal relations between complex sets of variables (social, economic, conflicts, environmental, and climatic factors) in two pressing problems: population displacement and food insecurity in Africa. We find plausible graphs as corroborated by experts in the humanitarian sector, finding traces of causal reasoning in the model's answers. We posit that LLM-based causality is a new, promising, alternative avenue for automated causality, especially indicated for rapid response and data-scarce regimes.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-21883"
    },
    {
        "id": 10597,
        "title": "Framework for A Foreign Language Teaching Software for Children Utilizing AR, Voicebots and ChatGPT (Large Language Models)",
        "authors": "Oguzhan TOPSAKAL, Elif TOPSAKAL",
        "published": "2022-12-31",
        "citations": 22,
        "abstract": "The cognitive capabilities of children develop during the early years of their life. Research shows that learning a foreign language helps develop cognitive skills. Moreover, learning a foreign language has become essential and an increasing number of parents would like their kids to start learning a foreign language at an early age. However, engaging little kids with learning activities is challenging. In this study, we propose a framework for developing a language learning software tool utilizing Augmented Reality (AR), Voicebots, and ChatGPT (an AI utilizing the Large Language Model) technologies to provide a unique product for small kids to teach a foreign language. With AR and Voicebots, the product will grab attention, motivate and provide an entertaining learning environment. The capabilities of ChatGPT will be utilized to efficiently prepare the content for the software tool. We utilize the capabilities of ChatGPT to generate interactive dialogs that will be hosted at Google DialogFlow. We believe the framework and the design principles we propose in this study can be a blueprint for developing highly effective foreign language teaching software.",
        "link": "http://dx.doi.org/10.52876/jcs.1227392"
    },
    {
        "id": 10598,
        "title": "Accessible Russian Large Language Models: Open-Source Models and Instructive Datasets for Commercial Applications",
        "authors": "D. P. Kosenko, Yu. M. Kuratov, D. R. Zharikova",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1134/s1064562423701168"
    },
    {
        "id": 10599,
        "title": "A Computational Analysis of the Voices of Shakespeare’s Characters",
        "authors": "Liviu P. Dinu,  , Ana Sabina Uban,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_033"
    },
    {
        "id": 10600,
        "title": "BhojpuriWordNet: Problems in Translating Hindi Synsets into Bhojpuri",
        "authors": "Imran Ali,  , Praveen Gatla,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_007"
    },
    {
        "id": 10601,
        "title": "Transformer-Based Language Models for Bulgarian",
        "authors": "Iva Marinova,  , Kiril Simov, Petya Osenova,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_077"
    },
    {
        "id": 10602,
        "title": "Can We Edit Multimodal Large Language Models?",
        "authors": "Siyuan Cheng, Bozhong Tian, Qingbin Liu, Xi Chen, Yongheng Wang, Huajun Chen, Ningyu Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.856"
    },
    {
        "id": 10603,
        "title": "Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations",
        "authors": "Zhuoyan Li, Hangxiao Zhu, Zhuoran Lu, Ming Yin",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.647"
    },
    {
        "id": 10604,
        "title": "Assessing the Strengths and Weaknesses of Large Language Models",
        "authors": "Shalom Lappin",
        "published": "2024-3",
        "citations": 0,
        "abstract": "AbstractThe transformers that drive chatbots and other AI systems constitute large language models (LLMs). These are currently the focus of a lively discussion in both the scientific literature and the popular media. This discussion ranges from hyperbolic claims that attribute general intelligence and sentience to LLMs, to the skeptical view that these devices are no more than “stochastic parrots”. I present an overview of some of the weak arguments that have been presented against LLMs, and I consider several of the more compelling criticisms of these devices. The former significantly underestimate the capacity of transformers to achieve subtle inductive inferences required for high levels of performance on complex, cognitively significant tasks. In some instances, these arguments misconstrue the nature of deep learning. The latter criticisms identify significant limitations in the way in which transformers learn and represent patterns in data. They also point out important differences between the procedures through which deep neural networks and humans acquire knowledge of natural language. It is necessary to look carefully at both sets of arguments in order to achieve a balanced assessment of the potential and the limitations of LLMs.",
        "link": "http://dx.doi.org/10.1007/s10849-023-09409-x"
    },
    {
        "id": 10605,
        "title": "Beyond Information: Is ChatGPT Empathetic Enough?",
        "authors": "Ahmed Belkhir,  , Fatiha Sadat,  ",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_018"
    },
    {
        "id": 10606,
        "title": "huPWKP: A Hungarian Text Simplification Corpus",
        "authors": "Noémi Prótár,  , Dávid Márk Nemeskey,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_097"
    },
    {
        "id": 10607,
        "title": "Explainable Event Detection with Event Trigger Identification as Rationale Extraction",
        "authors": "Hansi Hettiarachchi,  , Tharindu Ranasinghe,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_056"
    },
    {
        "id": 10608,
        "title": "Knowledge representation and acquisition in the era of large language models: Reflections on learning to reason via PAC-Semantics",
        "authors": "Ionela G. Mocanu, Vaishak Belle",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.nlp.2023.100036"
    },
    {
        "id": 10609,
        "title": "NLSQL: Generating and Executing SQL Queries via Natural Language Using Large Language Models",
        "authors": "Ayush Attawar, Shivam Vora, Parth Narechania, Vinaya Sawant, Heli Vora",
        "published": "2023-10-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icacta58201.2023.10392861"
    },
    {
        "id": 10610,
        "title": "Driving and suppressing the human language network using large language models",
        "authors": "Greta Tuckute, Aalok Sathe, Shashank Srikant, Maya Taliaferro, Mingye Wang, Martin Schrimpf, Kendrick Kay, Evelina Fedorenko",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32470/ccn.2023.1403-0"
    },
    {
        "id": 10611,
        "title": "Towards Interpretable Mental Health Analysis with Large Language Models",
        "authors": "Kailai Yang, Shaoxiong Ji, Tianlin Zhang, Qianqian Xie, Ziyan Kuang, Sophia Ananiadou",
        "published": "2023",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.370"
    },
    {
        "id": 10612,
        "title": "Evaluating Object Hallucination in Large Vision-Language Models",
        "authors": "Yifan Li, Yifan Du, Kun Zhou, Jinpeng Wang, Xin Zhao, Ji-Rong Wen",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.20"
    },
    {
        "id": 10613,
        "title": "Cabbage Sweeter than Cake? Analysing the Potential of Large Language Models for Learning Conceptual Spaces",
        "authors": "Usashi Chatterjee, Amit Gajbhiye, Steven Schockaert",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.725"
    },
    {
        "id": 10614,
        "title": "Large Language Models are biased to overestimate profoundness",
        "authors": "Eugenio Herrera-Berg, Tomás Browne, Pablo León-Villagrá, Marc-Lluís Vives, Cristian Calderon",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.599"
    },
    {
        "id": 10615,
        "title": "Multilingual Large Language Models Are Not (Yet) Code-Switchers",
        "authors": "Ruochen Zhang, Samuel Cahyawijaya, Jan Christian Blaise Cruz, Genta Winata, Alham Aji",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.774"
    },
    {
        "id": 10616,
        "title": "Hallucination Detection for Generative Large Language Models by Bayesian Sequential Estimation",
        "authors": "Xiaohua Wang, Yuliang Yan, Longtao Huang, Xiaoqing Zheng, Xuanjing Huang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.949"
    },
    {
        "id": 10617,
        "title": "Multimodal large language models for inclusive collaboration learning tasks",
        "authors": "Armanda Lewis",
        "published": "2022",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-srw.26"
    },
    {
        "id": 10618,
        "title": "Aligning Large Language Models through Synthetic Feedback",
        "authors": "Sungdong Kim, Sanghwan Bae, Jamin Shin, Soyoung Kang, Donghyun Kwak, Kang Yoo, Minjoon Seo",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.844"
    },
    {
        "id": 10619,
        "title": "Let’s Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models",
        "authors": "Ruida Wang, Wangchunshu Zhou, Mrinmaya Sachan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.791"
    },
    {
        "id": 10620,
        "title": "Three Approaches to Client Email Topic Classification",
        "authors": "Branislava Šandrih Todorović,  , Katarina Josipović, Jurij Kodre,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_109"
    },
    {
        "id": 10621,
        "title": "Role play with large language models",
        "authors": "Murray Shanahan, Kyle McDonell, Laria Reynolds",
        "published": "2023-11-16",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41586-023-06647-8"
    },
    {
        "id": 10622,
        "title": "Revisiting Large Language Models as Zero-shot Relation Extractors",
        "authors": "Guozheng Li, Peng Wang, Wenjun Ke",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.459"
    },
    {
        "id": 10623,
        "title": "Using Large Language Models to Help Train Machine Learning SDG Classifiers",
        "authors": "",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18356/25206656-180"
    },
    {
        "id": 10624,
        "title": "Using Large Language Models for Bug Localization and Fixing",
        "authors": "Tung Do Viet, Konstantin Markov",
        "published": "2023-11-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icast57874.2023.10359304"
    },
    {
        "id": 10625,
        "title": "Guidance for Researchers and Peer-reviewers on the Ethical Use of Large Language Models (LLM) in Scientific Research Workflows",
        "authors": "Ryan Watkins",
        "published": "No Date",
        "citations": 0,
        "abstract": "For researchers interested in exploring the exciting applications of Large Language Models (LLMs) in their scientific investigations, there is currently limited guidance and few norms for them to consult. Similarly, those providing peer-reviews on research articles where LLMs were used are without conventions or standards to apply or guidelines to follow. This situation is understandable given the rapid and recent development of LLMs that are capable of valuable contributions to research workflows (such as OpenAI’s ChatGPT). Nevertheless, now is the time to begin the development of norms, conventions, and standards that can be applied by researchers and peer-reviewers. By applying the principles of Artificial Intelligence (AI) ethics, we can better ensure that the use of LLMs in scientific research aligns with ethical principles and best practices. This editorial hopes to inspire further dialogue and research in this crucial area of scientific investigation.",
        "link": "http://dx.doi.org/10.31219/osf.io/6uh8p"
    },
    {
        "id": 10626,
        "title": "Large language models for generating medical examinations: systematic review",
        "authors": "Yaara Artsi, Vera Sorin, Eli Konen, Benjamin S. Glicksberg, Girish Nadkarni, Eyal Klang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground\nWriting multiple choice questions (MCQs) for the purpose of medical exams is challenging. It requires extensive medical knowledge, time and effort from medical educators. This systematic review focuses on the application of large language models (LLMs) in generating medical MCQs.\nMethods\nThe authors searched for studies published up to November 2023. Search terms focused on LLMs generated MCQs for medical examinations. MEDLINE was used as a search database.\nResults\nOverall, eight studies published between April 2023 and October 2023 were included. Six studies used Chat-GPT 3.5, while two employed GPT 4. Five studies showed that LLMs can produce competent questions valid for medical exams. Three studies used LLMs to write medical questions but did not evaluate the validity of the questions. One study conducted a comparative analysis of different models. One other study compared LLM-generated questions with those written by humans.\nAll studies presented faulty questions that were deemed inappropriate for medical exams. Some questions required additional modifications in order to qualify.\nConclusions\nLLMs can be used to write MCQs for medical examinations. However, their limitations cannot be ignored. Further study in this field is essential and more conclusive evidence is needed. Until then, LLMs may serve as a supplementary tool for writing medical examinations.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3872497/v1"
    },
    {
        "id": 10627,
        "title": "Decision letter for \"Large-Scale Text Analysis Using Generative Language Models: A Case Study in Discovering Public Value Expressions in AI Patents\"",
        "authors": "",
        "published": "2023-8-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1162/qss_a_00285/v1/decision1"
    },
    {
        "id": 10628,
        "title": "Large Language Models as Recommendation Systems in Museums",
        "authors": "Georgios Trichopoulos, Markos Konstantakis, Georgios Alexandridis, George Caridakis",
        "published": "2023-9-10",
        "citations": 1,
        "abstract": "This paper proposes the utilization of large language models as recommendation systems for museum visitors. Since the aforementioned models lack the notion of context, they cannot work with temporal information that is often present in recommendations for cultural environments (e.g., special exhibitions or events). In this respect, the current work aims to enhance the capabilities of large language models through a fine-tuning process that incorporates contextual information and user instructions. The resulting models are expected to be capable of providing personalized recommendations that are aligned with user preferences and desires. More specifically, Generative Pre-trained Transformer 4, a knowledge-based large language model is fine-tuned and turned into a context-aware recommendation system, adapting its suggestions based on user input and specific contextual factors such as location, time of visit, and other relevant parameters. The effectiveness of the proposed approach is evaluated through certain user studies, which ensure an improved user experience and engagement within the museum environment.",
        "link": "http://dx.doi.org/10.3390/electronics12183829"
    },
    {
        "id": 10629,
        "title": "Context-faithful Prompting for Large Language Models",
        "authors": "Wenxuan Zhou, Sheng Zhang, Hoifung Poon, Muhao Chen",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.968"
    },
    {
        "id": 10630,
        "title": "Gender bias and stereotypes in Large Language Models",
        "authors": "Hadas Kotek, Rikker Dockum, David Sun",
        "published": "2023-11-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3582269.3615599"
    },
    {
        "id": 10631,
        "title": "LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models",
        "authors": "Huiqiang Jiang, Qianhui Wu, Chin-Yew Lin, Yuqing Yang, Lili Qiu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.825"
    },
    {
        "id": 10632,
        "title": "USING LARGE LANGUAGE MODELS (LLMS) TO DEVELOP AN EDUCATIONAL APP FOR GENDER BASED VIOLENCE",
        "authors": "Zainab Qureshi, Imran Zualkernan",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21125/inted.2024.0979"
    },
    {
        "id": 10633,
        "title": "Enhancing Sentiment Analysis based Investment by Large Language Models in Japanese Stock Market",
        "authors": "Masafumi Nakano, Takuya Yamaoka",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4511658"
    },
    {
        "id": 10634,
        "title": "The Impact of Large Language Models on Search Advertising: Evidence from Google’s BERT",
        "authors": "Poet Larsen, Davide Proserpio",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4614402"
    },
    {
        "id": 10635,
        "title": "Echoes of Intelligence",
        "authors": "Alvaro Videla",
        "published": "2023-6-23",
        "citations": 0,
        "abstract": "We are now in the presence of a new medium disguised as good old text, but that text has been generated by an LLM, without authorial intention—an aspect that, if known beforehand, completely changes the expectations and response a human should have from a piece of text. Should our interpretation capabilities be engaged? If yes, under what conditions? The rules of the language game should be spelled out; they should not be passed over in silence.",
        "link": "http://dx.doi.org/10.1145/3606011"
    },
    {
        "id": 10636,
        "title": "Review for \"Large-Scale Text Analysis Using Generative Language Models: A Case Study in Discovering Public Value Expressions in AI Patents\"",
        "authors": "Philippe Vincent-Lamarre",
        "published": "2023-7-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1162/qss_a_00285/v1/review1"
    },
    {
        "id": 10637,
        "title": "TransMEP: Transfer learning on large protein language models to predict mutation effects of proteins from a small known dataset",
        "authors": "Tilman Hoffbauer, Birgit Strodel",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractMachine learning-guided optimization has become a driving force for recent improvements in protein engineering. In addition, new protein language models are learning the grammar of evolutionarily occurring sequences at large scales. This work combines both approaches to make predictions about mutational effects that support protein engineering. To this end, an easy-to-use software tool called TransMEP is developed using transfer learning by feature extraction with Gaussian process regression. A large collection of datasets is used to evaluate its quality, which scales with the size of the training set, and to show its improvements over previous fine-tuning approaches. Wet-lab studies are simulated to evaluate the use of mutation effect prediction models for protein engineering. This showed that TransMEP finds the best performing mutants with a limited study budget by considering the trade-off between exploration and exploitation.Graphical TOC Entry",
        "link": "http://dx.doi.org/10.1101/2024.01.12.575432"
    },
    {
        "id": 10638,
        "title": "Potential of Large Language Models as Tools Against Medical Disinformation",
        "authors": "Lingxuan Zhu, Weiming Mou, Peng Luo",
        "published": "2024-2-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1001/jamainternmed.2024.0020"
    },
    {
        "id": 10639,
        "title": "Large Language Models Trained on Equipment Maintenance Text",
        "authors": "P Y Abijith, Piyush Patidar, Gaurav Nair, Rohan Pandya",
        "published": "2023-10-2",
        "citations": 1,
        "abstract": "Abstract\nWork orders, equipment information, technical records and best practices documents contain within them a wealth of insights related to Equipment Maintenance which can be unlocked with Natural Language Processing tasks like classification, clustering, named entity recognition or part of speech tagging. But obtaining large enough labelled data sets in Equipment Maintenance domain manually is prohibitive and very expensive. This lack of labeled Equipment Maintenance data can be overcome with Large Language Models (LLMs) such as GPT-3, BERT that are pretrained transformer networks, considered state-of-the-art when it comes to Natural Language Processing (NLP) tasks. However, the vocabulary understood by these LLMs are mostly from English Language and need to be fine-tuned to understand industry and organization specific vocabulary and acronyms.\nThis paper explores the potential of a domain specific LLM model for oil and gas industries. Data that are of good quality and that provide a comprehensive overview of industry are collected. This corpus of text contains documents like work orders, equipment data and technical documents. A custom tokenizer is trained on this data to identify domain specific terminology. A comparative study is done with other off-the-shelf tokenizers: BERT and RoBERTa, to compare the effectiveness of the tokenization.\nWith millions of work orders and equipment documents, training pipelines had to parallelized so that training can occur on multiple GPUs. A comprehensive study of multiple training methods is done in this paper. Model and tokenizer developed were packaged and archived to be consumed in machine learning pipelines to specific use-cases across the organization. For an organization adopting digital transformation, the availability of an organization specific LLM is an enabler to extract insights from millions of documents containing free text. The applicability of such models spans across multiple disciplines like Maintenance, Reliability, Safety etc. and streamlines the development of highly accurate and robust text analytics.",
        "link": "http://dx.doi.org/10.2118/216336-ms"
    },
    {
        "id": 10640,
        "title": "Ask Earth: Large Language Models with Retrieval Augmented Generation as Geological Knowledge Extractors from Unstructured Databases",
        "authors": "D. Egorov",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3997/2214-4609.202439062"
    },
    {
        "id": 10641,
        "title": "Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models",
        "authors": "Alejandro Lopez-Lira, Yuehua Tang",
        "published": "2023",
        "citations": 30,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4412788"
    },
    {
        "id": 10642,
        "title": "Streamlining Systematic Reviews: Harnessing Large Language Models for Quality Assessment and Risk-of-Bias Evaluation",
        "authors": "Abdulqadir  J Nashwan, Jaber  H Jaradat",
        "published": "2023-8-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7759/cureus.43023"
    },
    {
        "id": 10643,
        "title": "Evaluating the strengths and weaknesses of large language models in answering neurophysiology questions",
        "authors": "Hassan Shojaee-Mend, Reza Mohebbati, Mostafa Amiri, Alireza Atarodi",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground: Large language models (LLMs), such as ChatGPT, Google's Bard, and Anthropic's Claude, demonstrate impressive natural language capabilities. Assessing their competence in specialized domains such as neurophysiology is important for determining their utility in research, education, and clinical applications.\nObjectives:This study evaluates and compares the performance of LLMs in answering neurophysiology questions in English and Persian across different topics and cognitive levels.\nMethods:Twenty questions spanning 4 topics (general, sensory system, motor system, and integrative) and 2 cognitive levels (lower-order and higher-order) were presented to the LLMs. Physiologists scored the essay-style responses from 0-5 points. Statistical analysis compared the scores at themodel, language, topic, and cognitive levels.\nResults:Overall,the models performed well (mean score=3.56/5), with no significant difference between language or cognitive levels. Performance was the strongest in themotor system (mean=4.52) and the weakest in integrative topics (mean=2.1). Detailed qualitative analysis revealed inconsistencies and gaps in reasoning.\nConclusions: Thisstudy provides insights into LLMs’ capabilities and limitations in neurophysiology. The models exhibit competence in fundamental concepts but face challenges in advanced reasoning and integration. Targeted training could address gaps in knowledge and causal reasoning. As LLMs evolve, rigorous domain-specific assessments will be important to gauge progress.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3348418/v1"
    },
    {
        "id": 10644,
        "title": "Large language models: implications of rapid evolution in medicine",
        "authors": "Billy HH Cheung, Michael TH Co",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.12809/hkmj2310890"
    },
    {
        "id": 10645,
        "title": "Talking about Large Language Models",
        "authors": "Murray Shanahan",
        "published": "2024-2",
        "citations": 1,
        "abstract": "Interacting with a contemporary LLM-based conversational agent can create an illusion of being in the presence of a thinking creature. Yet, in their very nature, such systems are fundamentally not like us.",
        "link": "http://dx.doi.org/10.1145/3624724"
    },
    {
        "id": 10646,
        "title": "Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?",
        "authors": "John J. Horton",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4413859"
    },
    {
        "id": 10647,
        "title": "Explainable Claim Verification via Knowledge-Grounded Reasoning with Large Language Models",
        "authors": "Haoran Wang, Kai Shu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.416"
    },
    {
        "id": 10648,
        "title": "Large language models direct automated chemistry laboratory",
        "authors": "Ana Laura Dias, Tiago Rodrigues",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/d41586-023-03790-0"
    },
    {
        "id": 10649,
        "title": "EXPLORING THE POTENTIAL OF LARGE LANGUAGE MODELS FOR ENHANCED VIRTUAL NON-PLAYER CHARACTER INTERACTIONS",
        "authors": "Ayaan Anand, Emil Polyak",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21125/inted.2024.1269"
    },
    {
        "id": 10650,
        "title": "Requirements Engineering and Large Language Models: Insights From a Panel",
        "authors": "Markus Borg",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ms.2023.3339934"
    },
    {
        "id": 10651,
        "title": "Exploratory Data Analysis and the Rise of Large Language Models - Gaming Industry Insights",
        "authors": "Denitsa Zhecheva",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "The applications of modern large language models are diverse and new at the same time. It is forecasted that the scientific society and businesses may experience a long period of time exploring all opportunities and challenges for using them which will allow analysis of the impact on how advanced generative artificial intelligence is changing work occupation activities and performance efficiency. Undoubtedly, today’s question that every business must answer is not if but how to implement large language models, due to their ability to transform numerous business processes. This study aims to give a better understanding on how large language models are contributing to the process of exploratory data analysis as they are not here to replace the traditional methods but to add generative artificial intelligence capabilities to the well-established ones. The results of this paper reveal high level of accuracy of the paired output between operation prompts in OpenAI’s large language model and human-mediated entry. However, such output comparison highlighs the need for more informative and specific input prompts to ascertain this accuracy. Further caveats that need to be placed in consideration refer to possible system downtimes, as well as the expenses incurred with every prompt execution. Nevertheless, the comparative speed of operation of large language models remains their most substantial competitive advantage. Overall, the findings in this paper contribute to understanding that large language models streamline with ease the desired extraction of insightful information which may further be used for better decision-making, good data management, and design of winning growth strategy as is the case of the gaming industry.",
        "link": "http://dx.doi.org/10.18421/tem131-59"
    },
    {
        "id": 10652,
        "title": "Comparative Analysis of Decision-Making Efficiency of Large Language Models",
        "authors": "Mirza Niaz Zaman Elin -",
        "published": "2023-5-31",
        "citations": 0,
        "abstract": "Large language models (LLMs) have emerged as powerful tools in the field of artificial intelligence (AI), attracting considerable attention from researchers and practitioners. These models demonstrate remarkable capabilities in various tasks, including decision-making. This paper aims to compare the decision-making efficiency of two prominent LLMs, Bard and GPT, across different domains.To conduct a comprehensive evaluation, a set of carefully designed questions was used to assess the performance of Bard and GPT in specific decision-making contexts. Through quantitative analysis, we aimed to quantify their abilities and identify potential variations in their performance.The results of our study revealed interesting insights into the decision-making efficiency of Bard and GPT across different domains. In the domain of logical reasoning and error detection, both Bard and GPT exhibited similar performance, but GPT outperformed Bard in data analysis by a notable margin. This finding suggests that GPT possesses stronger analytical abilities, enabling it to make more accurate and reliable decisions in contexts that require accurate data analysis and interpretation.The comparative analysis of Bard and GPT's decision-making efficiency highlights the significance of considering the specific domains and tasks when evaluating the performance of LLMs. It underscores the fact that different LLMs may possess domain-specific strengths and weaknesses, which can have a profound impact on their decision-making capabilities.Future research endeavors may involve expanding the evaluation to additional domains and considering a larger sample of questions to enhance the reliability and generalizability of the findings. Moreover, investigating the interpretability and explainability of LLMs in decision-making processes could shed further light on their decision-making strategies and enhance trust and transparency in their applications.This paper contributes to the growing body of research on LLMs by comparing the decision-making efficiency of Bard and GPT across different domains. The findings highlight the relative strengths of each model, emphasizing the importance of domain-specific considerations in decision-making tasks. By leveraging the capabilities of LLMs, practitioners can harness their potential to improve decision-making processes in diverse real-world applications.",
        "link": "http://dx.doi.org/10.36948/ijfmr.2023.v05i03.3342"
    },
    {
        "id": 10653,
        "title": "Using Large Language Models for Automated Grading of Student Writing about Science",
        "authors": "Chris Impey, Matthew Wenger, Nikhil Garuda, Shahriar Golchin, Sarah Stamer",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nA challenge in teaching large classes for formal or informal learners is assessing writing. As a result, most large classes, especially in science, use objective assessment tools like multiple choice quizzes. The rapid maturation of AI has created the possibility of using large language models (LLMs) to assess student writing. An experiment was carried out using GPT-3.5 and GPT-4 to see if machine learning methods based on LLMs can rival peer grading for reliability and automation in evaluating short writing assignments on topics in astronomy. The audience was lifelong learners in three massive open online courses (MOOCs) offered through Coursera. However, the results should also be applicable to non-science majors in university settings. The data was answers from 120 students on 12 questions across the three courses. The LLM was fed with total grades, model answers, and rubrics from an instructor for all three questions. In addition to seeing how reliably the LLMs reproduced instructor grades, the LLMs were asked to generate their own rubrics. Overall, the LLMs were more reliable than peer grading, both in the aggregate and by individual student, and they came much closer to the instructor grades for all three of the online courses. GPT-4 generally outperformed GPT-3.5. The implication is that LLMs can be used for automated, reliable, and scalable grading of student science writing.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3962175/v1"
    },
    {
        "id": 10654,
        "title": "A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4",
        "authors": "Katikapalli Subramanyam Kalyan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4593895"
    },
    {
        "id": 10655,
        "title": "Quantifying the Impact of Large Language Models on Collective Opinion Dynamics",
        "authors": "Chao Li, Xing Su, Haoying Han, Cong Xue, Chunmo Zheng, Chao Fan",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4688547"
    },
    {
        "id": 10656,
        "title": "Impact of Co-occurrence on Factual Knowledge of Large Language Models",
        "authors": "Cheongwoong Kang, Jaesik Choi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.518"
    },
    {
        "id": 10657,
        "title": "Enhancing Emergency Decision-Making with Knowledge Graphs and Large Language Models",
        "authors": "Minze Chen, Zhenxiang Tao, Weitong Tang, Tingxin Qin, Rui Yang, Chunli Zhu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4713257"
    },
    {
        "id": 10658,
        "title": "Visualizing Linguistic Diversity of Text Datasets Synthesized by Large Language Models",
        "authors": "Emily Reif, Minsuk Kahng, Savvas Petridis",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/vis54172.2023.00056"
    },
    {
        "id": 10659,
        "title": "Large Language Models Reshaping Molecular Biology and Drug Development",
        "authors": "Satvik Tripathi, Kyla Gabriel, Pushpendra Tripathi, Edward Kim",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4721507"
    },
    {
        "id": 10660,
        "title": "Decision letter for \"Large-Scale Text Analysis Using Generative Language Models: A Case Study in Discovering Public Value Expressions in AI Patents\"",
        "authors": "",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1162/qss_a_00285/v2/decision1"
    },
    {
        "id": 10661,
        "title": "Analyzing Evaluation Methods for Large Language Models in the Medical Field: A Scoping Review",
        "authors": "Junbok Lee, Sungkyung Park, Jaeyong Shin, Belong Cho",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground: Owing to the rapid growth in popularity of Large Language Models (LLM), various performance evaluation studies have been conducted to confirm their applicability in the medical field. However, there is still no clear framework for an LLM evaluation.\nObjective: By reviewing studies on LLM evaluations in the medical field and analyzing the research methods used in these studies, this study aims to provide a reference for future researchers designing LLM studies.\nMethods & Materials: We conducted a scoping review of three databases (PubMed, Embase, and MEDLINE) to identify LLMs published between January 1, 2023, and September 30, 2023. We analyzed the method type, number of questions (queries), evaluators, repeat measurements, additional analysis methods, engineered prompts, and metrics other than accuracy.\nResults: A total of 142 articles met the inclusion criteria. The LLM evaluation was primarily categorized as either providing test examinations (n=53, 37.3%) or being evaluated by a medical professional (n=80, 56.3%), with some hybrid cases (n=5, 3.5%) or a combination of the two (n=4, 2.8%). Most studies had 100 or fewer questions (n=18, 29.0%), 15 (24.2%) performed repeated measurements, 18 (29.0%) performed additional analyses, and 8 (12.9%) used prompt engineering. For medical assessment, most studies had 50 or fewer queries (n=54, 64.3%), most studies had two evaluators (n=43, 48.3%), and 14 (14.7%) used prompt engineering.\nConclusions: More research is required regarding the application of LLMs in healthcare. Although previous studies have evaluated performance, future studies will likely focus on improving performance. For these studies to be conducted systematically, a well-structured methodology must be designed.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3879872/v1"
    },
    {
        "id": 10662,
        "title": "The empirical structure of psychopathology is represented in large language models",
        "authors": "Joseph Kambeitz, Jason Schiffman, Lana Kambeitz-Ilankovic, Ulrich Ettinger, Kai Vogeley",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground: Clinical assessment and scientific research in psychiatry is largely based on questionnaires that are employed to detect and quantify psychopathology. The development of large language models offers a new perspective for the analysis of the language and terminology that these questionnaires are based on. \nMethods: In the present study, we employed state-of-the-art large language models to derive numerical representations (so called ‘text embeddings’) of semantic and sentiment content of items from established questionnaires for the assessment of psychopathology. We compared the pairwise associations between empirical data and text embeddings in order to test if the empirical structure of psychopathology can be reconstructed by large language models.\nResults: Across four large-scale data sets (n=1555, n=1099, n=11807, n=39755), we found a range of significant correlations between empirical item-pair associations and associations derived from text embeddings (r=0.18 to r=0.57, all p<0.05). Machine learning models based on semantic or sentiment embeddings predicted empirical item-pair associations with moderate to high accuracy (r=0.33 to r=0.81, all p<0.05). Similarly, empirical clustering of items and the grouping to established subdomain scores could be partly reconstructed by text embeddings. \nConclusion: The present results demonstrate that large language models are able to represent substantial components of the empirical structure of psychopathology. Consequently, the integration of large language models into mental health research holds the potential to unlock numerous promising avenues. These may encompass improving the process of generating novel questionnaires, optimising generalizability and redundancy of existing questionnaires or facilitating the development of novel conceptualizations of mental disorders.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3347850/v1"
    },
    {
        "id": 10663,
        "title": "DATATALES: Investigating the use of Large Language Models for Authoring Data-Driven Articles",
        "authors": "Nicole Sultanum, Arjun Srinivasan",
        "published": "2023-10-21",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/vis54172.2023.00055"
    },
    {
        "id": 10664,
        "title": "Six ways large language models are changing healthcare",
        "authors": "Paul Webster",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41591-023-02700-1"
    },
    {
        "id": 10665,
        "title": "Generating Synthetic Data from Large Language Models",
        "authors": "Sunil Choenni, Tony Busker, Mortaza S. Bargh",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iit59782.2023.10366424"
    },
    {
        "id": 10666,
        "title": "Opportunities for the use of large language models in hepatology",
        "authors": "Himesh B. Zaver, Tushar Patel",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/cld.0000000000000075"
    },
    {
        "id": 10667,
        "title": "Auditing Large Language Models: A Three-Layered Approach",
        "authors": "Jakob Mökander, Jonas Schuett, Hannah Rose Kirk, Luciano Floridi",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4361607"
    },
    {
        "id": 10668,
        "title": "Evaluating the Utilities of Large Language Models in Single-cell Data Analysis",
        "authors": "Hongyu Zhao, Tianyu Liu, Kexing Li, Yuge Wang, Hongyu Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nLarge Language Models (LLMs) have made significant strides in both industrial and scientific domains. In this paper, we evaluate the performance of LLMs in single-cell sequencing data analysis through comprehensive experiments across eight downstream tasks pertinent to single-cell data. By comparing seven different single-cell LLMs with task-specific methods, we found that single-cell LLMs may not consistently excel in all tasks than task-specific methods. However, the emergent abilities and the successful applications of cross-species/cross-modality transfer learning of LLMs are promising. In addition, we present a systematic evaluation of the effects of hyper-parameters, initial settings, and stability for training single-cell LLMs based on a proposed scEval framework, and provide guidelines for pre-training and fine-tuning. Our work summarizes the current state of single-cell LLMs, and points to their constraints and avenues for future developments.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3376641/v1"
    },
    {
        "id": 10669,
        "title": "The Unbounded Constraints of Large Language Models in the Narrative Framework of Jorge Luis Borges",
        "authors": "Daniel Zautner",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4301087"
    },
    {
        "id": 10670,
        "title": "Analytic Thinking (Type 2 or “System 2”) for Large Language Models: using Psychology to address hallucination and reliability issues",
        "authors": "Samuel Castro Bellini-Leite",
        "published": "No Date",
        "citations": 1,
        "abstract": "State-of-the-art Large Language Models have recently exhibited extraordinary linguistic abilities which have surprisingly extended to reasoning. However, responses that are unreliable, false, or invented are still a frequent issue. It has been argued that scaling up strategies, as in increasing model size or hardware power, might not be enough to resolve the issue. Recent research has implemented Type 2 strategies (such as Chain-of-Thought and Tree-of-Thought), as strategies that mimic Type 2 reasoning, from Dual Process Theory, to interact with Large Language Models for improved results. The current paper reviews these strategies in light of the Predicting and Reflecting Framework for understanding Dual Process Theory and suggests what Psychology, drawing from research in executive functions, thinking disposition and creativity, can further contribute to possible implementations that address hallucination and reliability issues.",
        "link": "http://dx.doi.org/10.31234/osf.io/n7pa4"
    },
    {
        "id": 10671,
        "title": "Distilling the Knowledge of Clinical Outcome Predictions in Large Language Models for Resource Constrained Healthcare Systems",
        "authors": "Mohammad Junayed Hasan, Fuad Rahman, Nabeel Mohammed",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4591013"
    },
    {
        "id": 10672,
        "title": "L-Space and Large Language Models",
        "authors": "Jofish Kaye",
        "published": "2023-8",
        "citations": 0,
        "abstract": "From the intersection of computational science and technological speculation, with boundaries limited only by our ability to imagine what could be.\nDesign fiction is an approach to understanding and speculating about alternate futures. One part of this can involve creating representative artifacts or prototypes from the future, as if they fell through a time warp to the present day. This column is a piece of such speculative fiction, set in 2025.",
        "link": "http://dx.doi.org/10.1145/3596900"
    },
    {
        "id": 10673,
        "title": "Large language models for generating medical examinations: systematic review",
        "authors": "Yaara Artsi, Vera Sorin, Eli Konen, Benjamin S. Glicksberg, Girish Nadkarni, Eyal Klang",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractPurposeWriting multiple choice questions (MCQs) for the purpose of medical exams is challenging. It requires extensive medical knowledge, time and effort from medical educators. This systematic review focuses on the application of large language models (LLMs) in generating medical MCQs.MethodsThe authors searched for studies published up to November 2023. Search terms focused on LLMs generated MCQs for medical examinations. MEDLINE was used as a search database.ResultsOverall, eight studies published between April 2023 and October 2023 were included. Six studies used Chat-GPT 3.5, while two employed GPT 4. Five studies showed that LLMs can produce competent questions valid for medical exams. Three studies used LLMs to write medical questions but did not evaluate the validity of the questions. One study conducted a comparative analysis of different models. One other study compared LLM-generated questions with those written by humans.All studies presented faulty questions that were deemed inappropriate for medical exams. Some questions required additional modifications in order to qualify.ConclusionsLLMs can be used to write MCQs for medical examinations. However, their limitations cannot be ignored. Further study in this field is essential and more conclusive evidence is needed. Until then, LLMs may serve as a supplementary tool for writing medical examinations.",
        "link": "http://dx.doi.org/10.1101/2024.01.06.24300920"
    },
    {
        "id": 10674,
        "title": "Towards Effective Disambiguation for Machine Translation with Large Language Models",
        "authors": "Vivek Iyer, Pinzhen Chen, Alexandra Birch",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.wmt-1.44"
    },
    {
        "id": 10675,
        "title": "The promise of large language models in health care",
        "authors": "Anmol Arora, Ananya Arora",
        "published": "2023-2",
        "citations": 36,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s0140-6736(23)00216-7"
    },
    {
        "id": 10676,
        "title": "An Exploration of Large Language Models for Verification of News Headlines",
        "authors": "Yifan Li, ChengXiang Zhai",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdmw60847.2023.00032"
    },
    {
        "id": 10677,
        "title": "Large Language Models for EDA: Future or Mirage?",
        "authors": "Zhuolun He, Bei Yu",
        "published": "2024-3-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626184.3639700"
    },
    {
        "id": 10678,
        "title": "BBTv2: Towards a Gradient-Free Future with Large Language Models",
        "authors": "Tianxiang Sun, Zhengfu He, Hong Qian, Yunhua Zhou, Xuanjing Huang, Xipeng Qiu",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.259"
    },
    {
        "id": 10679,
        "title": "Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented Large Language Models",
        "authors": "Gangwoo Kim, Sungdong Kim, Byeongguk Jeon, Joonsuk Park, Jaewoo Kang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.63"
    },
    {
        "id": 10680,
        "title": "Unveiling the Implicit Toxicity in Large Language Models",
        "authors": "Jiaxin Wen, Pei Ke, Hao Sun, Zhexin Zhang, Chengfei Li, Jinfeng Bai, Minlie Huang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.84"
    },
    {
        "id": 10681,
        "title": "Document-Level Machine Translation with Large Language Models",
        "authors": "Longyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui Zhang, Dian Yu, Shuming Shi, Zhaopeng Tu",
        "published": "2023",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.1036"
    },
    {
        "id": 10682,
        "title": "Semi-automatic Data Enhancement for Document-Level Relation Extraction with Distant Supervision from Large Language Models",
        "authors": "Junpeng Li, Zixia Jia, Zilong Zheng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.334"
    },
    {
        "id": 10683,
        "title": "A novel rule based machine translation scheme from Greek to Greek Sign Language: Production of different types of large corpora and Language Models evaluation",
        "authors": "Dimitrios Kouremenos, Klimis Ntalianis, Stefanos Kollias",
        "published": "2018-9",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2018.04.001"
    },
    {
        "id": 10684,
        "title": "Reading Between the Lines: Information Extraction from Industry Requirements",
        "authors": "Ole Magnus Holter,  , Basil Ell,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_076"
    },
    {
        "id": 10685,
        "title": "Final Words",
        "authors": "Michael McTear, Marina Ashurkina",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0110-5_10"
    },
    {
        "id": 10686,
        "title": "Large language models for structured reporting in radiology: comment",
        "authors": "Amnuay Kleebayoon, Viroj Wiwanitkit",
        "published": "2023-8-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11547-023-01687-6"
    },
    {
        "id": 10687,
        "title": "Feasibility and Prospect of Privacy-preserving Large Language Models                     in Radiology",
        "authors": "Wenli Cai",
        "published": "2023-10-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1148/radiol.232335"
    },
    {
        "id": 10688,
        "title": "The Power and the Pitfalls of Large Language Models: A Fireside Chat with Ricardo Baeza-Yates",
        "authors": "Shalini Urs",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4280575"
    },
    {
        "id": 10689,
        "title": "Large Language and Text-to-3D Models for Engineering Design Optimization",
        "authors": "Thiago Rios, Stefan Menzel, Bernhard Sendhoff",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ssci52147.2023.10371898"
    },
    {
        "id": 10690,
        "title": "Reinforcement Learning With Large Language Models (LLMs) Interaction For Network Services",
        "authors": "Hongyang Du, Ruichen Zhang, Dusit Niyato, Jiawen Kang, Zehui Xiong, Dong In Kim",
        "published": "No Date",
        "citations": 0,
        "abstract": "Artificial Intelligence-Generated Content (AIGC)- related network\nservices, especially image generation-based services, have garnered\nnotable attention due to their ability to cater to diverse user\npreferences, which significantly impacts the subjective Quality of\nExperience (QoE). Specifically, different users can perceive the same\nsemantically informed image quite differently, leading to varying levels\nof satisfaction. To address this challenge and maximize network users’\nsubjective QoE, we introduce a novel interactive artificial intelligence\n(IAI) approach using Reinforcement Learning With Large Language Models\nInteraction (RLLI). RLLI leverages Large Language Model (LLM)-empowered\ngenerative agents to simulate user interactions, thereby providing\nreal-time feedback on QoE that encapsulates a range of user\npersonalities. This feedback is instrumental in facilitating the\nselection of the most suitable AIGC network service provider for each\nuser, ensuring an optimized, personalized experience.",
        "link": "http://dx.doi.org/10.36227/techrxiv.170492449.98025537/v1"
    },
    {
        "id": 10691,
        "title": "Applications of Large Language Models (LLMs) in Breast Cancer Care",
        "authors": "Vera Sorin, Benjamin S. Glicksberg, Yiftach Barash, Eli Konen, Girish Nadkarni, Eyal Klang",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractPurposeRecently introduced Large Language Models (LLMs) such as ChatGPT have already shown promising results in natural language processing in healthcare. The aim of this study is to systematically review the literature on the applications of LLMs in breast cancer diagnosis and care.MethodsA literature search was conducted using MEDLINE, focusing on studies published up to October 22nd, 2023, using the following terms: “large language models”, “LLM”, “GPT”, “ChatGPT”, “OpenAI”, and “breast”.ResultsFive studies met our inclusion criteria. All studies were published in 2023, focusing on ChatGPT-3.5 or GPT-4 by OpenAI. Applications included information extraction from clinical notes, question-answering based on guidelines, and patients’ management recommendations. The rate of correct answers varied from 64-98%, with the highest accuracy (88-98%) observed in information extraction and question-answering tasks. Notably, most studies utilized real patient data rather than data sourced from the internet. Limitations included inconsistent accuracy, prompt sensitivity, and overlooked clinical details, highlighting areas for cautious LLM integration into clinical practice.ConclusionLLMs demonstrate promise in text analysis tasks related to breast cancer care, including information extraction and guideline-based question-answering. However, variations in accuracy and the occurrence of erroneous outputs necessitate validation and oversight. Future works should focus on improving reliability of LLMs within clinical workflow.",
        "link": "http://dx.doi.org/10.1101/2023.11.04.23298081"
    },
    {
        "id": 10692,
        "title": "Author response for \"The Future of AI in Ovarian Cancer Research: The Large Language Models Perspective\"",
        "authors": " Alexandros Laios,  Georgios Theophilou,  Diederick De Jong,  Evangelos Kalampokis",
        "published": "2023-7-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1177/10732748231197915/v2/response1"
    },
    {
        "id": 10693,
        "title": "Enhancing Textbook Question Answering Task with Large Language Models and Retrieval Augmented Generation",
        "authors": "Hessa  Abdulrahman Alawwad, Areej Alhothali, Usman Naseem, Ali Alkhathlan, Amani Jamal",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4761601"
    },
    {
        "id": 10694,
        "title": "The Potential Utility of Large Language Models in Molecular Pathology",
        "authors": "Jeffrey Gagan",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/jalm/jfad102"
    },
    {
        "id": 10695,
        "title": "Comparison of Large Language And Vision Models on Representative Downstream Tasks",
        "authors": "Huitong Chen",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icicml60161.2023.10424913"
    },
    {
        "id": 10696,
        "title": "Creation and Adoption of Large Language Models in Medicine",
        "authors": "Nigam H. Shah, David Entwistle, Michael A. Pfeffer",
        "published": "2023-9-5",
        "citations": 52,
        "abstract": "ImportanceThere is increased interest in and potential benefits from using large language models (LLMs) in medicine. However, by simply wondering how the LLMs and the applications powered by them will reshape medicine instead of getting actively involved, the agency in shaping how these tools can be used in medicine is lost.ObservationsApplications powered by LLMs are increasingly used to perform medical tasks without the underlying language model being trained on medical records and without verifying their purported benefit in performing those tasks.Conclusions and RelevanceThe creation and use of LLMs in medicine need to be actively shaped by provisioning relevant training data, specifying the desired benefits, and evaluating the benefits via testing in real-world deployments.",
        "link": "http://dx.doi.org/10.1001/jama.2023.14217"
    },
    {
        "id": 10697,
        "title": "Exploring Abstractive Text Summarisation for Podcasts: A Comparative Study of BART and T5 Models",
        "authors": "Parth Saxena,  , Mahmoud El-Haj,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_110"
    },
    {
        "id": 10698,
        "title": "AI Psychometrics: Assessing the psychological profiles of large language models through psychometric inventories",
        "authors": "Max Pellert, Clemens M. Lechner, Claudia Wagner, Beatrice Rammstedt, Markus Strohmaier",
        "published": "No Date",
        "citations": 2,
        "abstract": "We illustrate how standard psychometric inventories originally designed for assessing non-cognitive human traits can be repurposed as diagnostic tools to evaluate analogous traits in large language models (LLMs). We start from the assumption that LLMs, inadvertently yet inevitably, acquire psychological traits (metaphorically speaking) from the vast text corpora on which they are trained. Such corpora contain sediments of the personalities, values, beliefs and biases of the countless human authors of these texts, which LLMs learn through a complex training process. The traits that LLMs acquire in such a way can potentially influence their behavior, i.e., their outputs in downstream tasks and applications in which they are employed, which in turn may have real-world consequences for individuals and social groups. By eliciting LLMs’ responses to language-based psychometric inventories we can bring their traits to light. Psychometric profiling enables researchers to study and compare LLMs in terms of non-cognitive characteristics thereby providing a window into the personalities, values, beliefs and biases these models exhibit (or mimic). We discuss the history of similar ideas and outline possible psychometric approaches for LLMs. We demonstrate one promising approach, zero-shot classification, for several LLMs and psychometric inventories. We conclude by highlighting open challenges and future avenues of research for AI Psychometrics.",
        "link": "http://dx.doi.org/10.31234/osf.io/jv5dt"
    },
    {
        "id": 10699,
        "title": "Prospects and Challenges of Large Language Models in the Field of Intelligent Building",
        "authors": "Wu Yang, Wang Junjie, Li Weihua",
        "published": "2023-5-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.11648/j.acis.20231101.13"
    },
    {
        "id": 10700,
        "title": "Prompting Large Language Models for Malicious Webpage Detection",
        "authors": "Lu Li, Bojie Gong",
        "published": "2023-8-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/prml59573.2023.10348229"
    },
    {
        "id": 10701,
        "title": "Prospects and Challenges of Large Language Models in the Field of Intelligent Building",
        "authors": "Wu Yang, Wang Junjie, Li Weihua",
        "published": "2023-5-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.11648/j.acis.20231101.13"
    },
    {
        "id": 10702,
        "title": "AI Psychometrics: Assessing the psychological profiles of large language models through psychometric inventories",
        "authors": "Max Pellert, Clemens M. Lechner, Claudia Wagner, Beatrice Rammstedt, Markus Strohmaier",
        "published": "No Date",
        "citations": 2,
        "abstract": "We illustrate how standard psychometric inventories originally designed for assessing non-cognitive human traits can be repurposed as diagnostic tools to evaluate analogous traits in large language models (LLMs). We start from the assumption that LLMs, inadvertently yet inevitably, acquire psychological traits (metaphorically speaking) from the vast text corpora on which they are trained. Such corpora contain sediments of the personalities, values, beliefs and biases of the countless human authors of these texts, which LLMs learn through a complex training process. The traits that LLMs acquire in such a way can potentially influence their behavior, i.e., their outputs in downstream tasks and applications in which they are employed, which in turn may have real-world consequences for individuals and social groups. By eliciting LLMs’ responses to language-based psychometric inventories we can bring their traits to light. Psychometric profiling enables researchers to study and compare LLMs in terms of non-cognitive characteristics thereby providing a window into the personalities, values, beliefs and biases these models exhibit (or mimic). We discuss the history of similar ideas and outline possible psychometric approaches for LLMs. We demonstrate one promising approach, zero-shot classification, for several LLMs and psychometric inventories. We conclude by highlighting open challenges and future avenues of research for AI Psychometrics.",
        "link": "http://dx.doi.org/10.31234/osf.io/jv5dt"
    },
    {
        "id": 10703,
        "title": "MarIA and BETO are sexist: evaluating gender bias in large language models for Spanish",
        "authors": "Ismael Garrido-Muñoz, Fernando Martínez-Santiago, Arturo Montejo-Ráez",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe study of bias in language models is a growing area of work, however, both research and resources are focused on English. In this paper, we make a first approach focusing on gender bias in some freely available Spanish language models trained using popular deep neural networks, like BERT or RoBERTa. Some of these models are known for achieving state-of-the-art results on downstream tasks. These promising results have promoted such models' integration in many real-world applications and production environments, which could be detrimental to people affected for those systems. This work proposes an evaluation framework to identify gender bias in masked language models, with explainability in mind to ease the interpretation of the evaluation results. We have evaluated 20 different models for Spanish, including some of the most popular pretrained ones in the research community. Our findings state that varying levels of gender bias are present across these models. This approach compares the adjectives proposed by the model for a set of templates. We classify the given adjectives into understandable categories and compute two new metrics from model predictions, one based on the internal state (probability) and the other one on the external state (rank). Those metrics are used to reveal biased models according to the given categories and quantify the degree of bias of the models under study.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2256074/v1"
    },
    {
        "id": 10704,
        "title": "The Power of Large Language Models: A ChatGPT-driven Textual Analysis of Fundamental Data",
        "authors": "Satoshi Itoh, Katsuhiko Okada",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4535647"
    },
    {
        "id": 10705,
        "title": "Assessing Large Language Models’ ability to predict how humans balance self-interest and the interest of others",
        "authors": "Valerio Capraro, Roberto Di Paolo, Veronica Pizziol",
        "published": "No Date",
        "citations": 0,
        "abstract": "Generative artificial intelligence (AI) holds enormous potential to revolutionize decision-making processes, from everyday to high-stake scenarios. By leveraging generative AI, humans can benefit from data-driven insights and predictions, enhancing their ability to make informed decisions that consider a wide array of factors and potential outcomes. However, as many decisions carry social implications, for AI to be a reliable assistant for decision-making it is crucial that it is able to capture the balance between self-interest and the interest of others. We investigate the ability of three of the most advanced chatbots to predict dictator game decisions across 108 experiments with human participants from 12 countries. We find that only GPT-4 (not Bard nor Bing) correctly captures qualitative behavioral patterns, identifying three major classes of behavior: self-interested, inequity-averse, and fully altruistic. Nonetheless, GPT-4 consistently underestimates self-interest and inequity-aversion, while overestimating altruistic behavior. This bias has significant implications for AI developers and users, as overly optimistic expectations about human altruism may lead to disappointment, frustration, suboptimal decisions in public policy or business contexts, and even social conflict.",
        "link": "http://dx.doi.org/10.31234/osf.io/8ackv"
    },
    {
        "id": 10706,
        "title": "Evaluating Subjective Cognitive Appraisals of Emotions from Large Language Models",
        "authors": "Hongli Zhan, Desmond Ong, Junyi Li",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.962"
    },
    {
        "id": 10707,
        "title": "Research on the development and risks of large language models",
        "authors": "Haoyuan An",
        "published": "2023-12-20",
        "citations": 0,
        "abstract": "Large Language Model (LLM) has great potential and wide application prospects, including improving the degree of intelligence, improving production efficiency, and providing diverse solutions for enterprises, governments, individuals, etc. If the problem of computing power can be overcome, it will have unlimited potential. It has attracted wide attention in the fields of Natural Language Processing (NLP) and Artificial General Intelligent (AGI). However, with the expansion of the scale and capabilities of large language models comes a series of potential risks and challenges. This paper reviews the development and risks of large language models in different research fileds. In the future, with the improvement of algorithms, personalized solutions can be developed more efficiently for service, and social productivity can be improved. However, it is also necessary to strengthen the regulatory review of the output of large language models and the correction of data bias to ensure the accuracy of the research content.",
        "link": "http://dx.doi.org/10.54254/2753-8818/25/20240991"
    },
    {
        "id": 10708,
        "title": "Aircraft Anomaly Detection using Large Language Models: An Air Traffic Control Application",
        "authors": "Brian J. Connolly, Georgia Schneider",
        "published": "2024-1-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2514/6.2024-0744"
    },
    {
        "id": 10709,
        "title": "Evaluations of Large Language Models a Bibliometric analysis",
        "authors": "Sello Prince Sekwatlakwatla, Vusumuzi Malele",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "The development of artificial intelligence (AI) and the increased curiosity about how large language models (LLMs) may maximize an organization's opportunities and the ethical implications of LLMs, such as the ability to generate human-like text, give rise to concerns regarding disinformation and fake news. As a result, it is crucial to develop evaluation benchmarks that take into account the social and ethical implications involved. The great challenges of LLMs lack awareness of their own limitations, yet they persist in producing responses to the best of their capabilities. This often results in seemingly plausible but ultimately incorrect answers, posing challenges to the implementation of reliable generative AI in industry. This paper aims to delve into the evaluation metrics of machine-learning models' performance, specifically focusing on LLM. Therefore, bibliometric analysis utilized to explore and analyze various techniques and methods used in evaluating large language models. Additionally, it sheds light on the specific areas of focus when evaluating these models. The results show that natural language processing systems, classification of information, and computational linguistics are some of the techniques used to evaluate large language models. This work paves the way for future investigations employing extensive language models.",
        "link": "http://dx.doi.org/10.33022/ijcs.v13i1.3767"
    },
    {
        "id": 10710,
        "title": "AskIt: Unified Programming Interface for Programming with Large Language Models",
        "authors": "Katsumi Okuda, Saman Amarasinghe",
        "published": "2024-3-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cgo57630.2024.10444830"
    },
    {
        "id": 10711,
        "title": "Automatic Assessment Of Spoken English Proficiency Based On Multimodal &amp; Multitask Transformers",
        "authors": "Kamel Nebhi,  , Gyorgy Szaszak,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_083"
    },
    {
        "id": 10712,
        "title": "Deep Learning Approaches to Detecting Safeguarding Concerns in Schoolchildren’s Online Conversations",
        "authors": "Emma Franklin,  , Tharindu Ranasinghe,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_041"
    },
    {
        "id": 10713,
        "title": "Data Augmentation for Fake Reviews Detection",
        "authors": "Ming Liu,  , Massimo Poesio,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_073"
    },
    {
        "id": 10714,
        "title": "Source Code Plagiarism Detection with Pre-Trained Model Embeddings and Automated Machine Learning",
        "authors": "Fahad Ebrahim,  , Mike Joy,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_034"
    },
    {
        "id": 10715,
        "title": "The Arrival of Artificial Intelligence Large Language Models and Vision-Language Models: A Potential to Possible Change in the Paradigm of Healthcare Delivery in Dermatology",
        "authors": "Aditya K. Gupta, Mesbah Talukder, Tong Wang, Roxana Daneshjou, Vincent Piguet",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jid.2023.10.046"
    },
    {
        "id": 10716,
        "title": "Using Large Language Models to Support Thematic Analysis in Empirical Legal Studies",
        "authors": "Jakub Drápal, Hannes Westermann, Jaromir Savelka",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4617116"
    },
    {
        "id": 10717,
        "title": "From Base to Conversational: Japanese Instruction Dataset and Tuning Large Language Models",
        "authors": "Masahiro Suzuki, Masanori HIRANO, Hiroki Sakaji",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4564308"
    },
    {
        "id": 10718,
        "title": "AutoPlan: Automatic Planning of Interactive Decision-Making Tasks With Large Language Models",
        "authors": "Siqi Ouyang, Lei Li",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.205"
    },
    {
        "id": 10719,
        "title": "Large Language Models (LLMs) and Empathy – A Systematic Review",
        "authors": "Vera Sorin, Danna Brin, Yiftach Barash, Eli Konen, Alexander Charney, Girish Nadkarni, Eyal Klang",
        "published": "No Date",
        "citations": 5,
        "abstract": "AbstractPurposeEmpathy, a cornerstone of human interaction, is a unique quality to humans that Large Language Models (LLMs) are believed to lack. Our study aims to review the literature on the capacity of LLMs in demonstrating empathyMethodsWe conducted a literature search on MEDLINE up to July 2023. Seven publications ultimately met the inclusion criteria.ResultsAll studies included in this review were published in 2023. All studies but one focused on ChatGPT-3.5 by OpenAI. Only one study evaluated empathy based on objective metrics, and all others used subjective human assessment. The studies reported LLMs to exhibits elements of empathy, including emotions recognition and providing emotionally supportive responses in diverse contexts, most of which were related to healthcare. In some cases, LLMs were observed to outperform humans in empathy-related tasks.ConclusionLLMs demonstrated some aspects of empathy in variable scenarios, mainly related to healthcare. The empathy may be considered “cognitive” empathy. Social skills are a fundamental aspect of intelligence, thus further research is imperative to enhance these skills in AI.",
        "link": "http://dx.doi.org/10.1101/2023.08.07.23293769"
    },
    {
        "id": 10720,
        "title": "Personality Traits in Large Language Models",
        "authors": "Gregory Serapio-García, Mustafa Safdari, Clément Crepy, Luning Sun, Stephen Fitz, Marwa Abdulhai, Aleksandra Faust, Maja Matarić",
        "published": "No Date",
        "citations": 6,
        "abstract": "Abstract\nThe advent of large language models (LLMs) has revolutionized natural language processing, enabling the generation of coherent and contextually relevant text. As LLMs increasingly power conversational agents, the synthetic personality embedded in these models, by virtue of training on large amounts of human data, is becoming increasingly important. Since personality is a key factor determining the effectiveness of communication, we present a comprehensive method for administering and validating personality tests on widely-used LLMs, as well as for shaping personality in the generated text of such LLMs. Applying this method, we found: 1) personality measurements in the outputs of some LLMs under specific prompting configurations are reliable and valid; 2) evidence of reliability and validity of synthetic LLM personality is stronger for larger and instruction fine-tuned models; and 3) personality in LLM outputs can be shaped along desired dimensions to mimic specific personality profiles. We discuss application and ethical implications of the measurement and shaping method, in particular regarding responsible use of LLMs.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3296728/v1"
    },
    {
        "id": 10721,
        "title": "Identifying textual disinformation using Large Language Models",
        "authors": "Marina Ernst",
        "published": "2024-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3627508.3638315"
    },
    {
        "id": 10722,
        "title": "Exploring Large Language Models in a Limited Resource Scenario",
        "authors": "Anand Panchbhai, Smarana Pankanti",
        "published": "2021-1-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/confluence51648.2021.9377081"
    },
    {
        "id": 10723,
        "title": "Limits of Detecting Text Generated by Large-Scale Language Models",
        "authors": "Lav R. Varshney, Nitish Shirish Keskar, Richard Socher",
        "published": "2020-2-2",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ita50056.2020.9245012"
    },
    {
        "id": 10724,
        "title": "Large Language Models, scientific knowledge and factuality: A systematic analysis in antibiotic discovery",
        "authors": "Magdalena Wysocka, Oskar Wysocki, Maxime Delmas, Vincent Mutel, Andre Freitas",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground Inferring over and extracting information from Large Language Models (LLMs) trained on a large corpus of scientific literature can potentially drive a new era in biomedical research, reducing the barriers for accessing existing medical evidence. This work examines the potential of LLMs for dialoguing with biomedical background knowledge, using the context of antibiotic discovery as an exemplar motivational scenario. The context of biomedical discovery from natural products entails understanding the relational evidence between an organism (e.g. a Fungi such as Albifimbria verrucaria), an associated chemical (Verrucarin A) and its associated antibiotic properties (present antibiotic activity). \nResults This work provides a systematic assessment on the ability of LLMs to encode and express these relations, verifying for fluency, prompt-alignment, semantic coherence, factual knowledge and specificity of generated responses. The systematic analysis is applied to nine state-of-the-art models, from models specialised on biomedical scientific corpora to general models such as ChatGPT and GPT-4 in two prompting-based tasks: chemical compound definition generation and chemical compound-fungus relation determination. Results show that while recent models have improved in fluency, factual accuracy is still low and models are biased towards over-represented entities. The ability of LLMs to serve as biomedical knowledge bases is questioned, and the need for additional systematic evaluation frameworks is highlighted. The best performing GPT-4 produced a factual definition for 70% of chemical compounds and 43.6% factual relations to fungi, whereas the best open source model BioGPT-large 30% of the compounds and 30% of the relations for the best-performing prompt. \nConclusions The results show that while LLMs are currently not fit for purpose to be used as biomedical factual knowledge bases, there is a promising emerging property in the direction of factuality as the models become domain specialised, scale-up in size and level of human feedback.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3117447/v1"
    },
    {
        "id": 10725,
        "title": "Large Language Models in der Medizin",
        "authors": "Antonia Sahm",
        "published": "2024-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783111351490-031"
    },
    {
        "id": 10726,
        "title": "Academic Surgery in the Era of Large Language Models",
        "authors": "Timothy A. Rengers, Cornelius A. Thiels, Hojjat Salehinejad",
        "published": "2024-2-14",
        "citations": 0,
        "abstract": "ImportanceThis review aims to assess the benefits and risks of implementing large language model (LLM) solutions in an academic surgical setting.ObservationsThe integration of LLMs and artificial intelligence (AI) into surgical practice has generated international attention with the emergence of OpenAI’s ChatGPT and Google’s Bard. From an administrative standpoint, LLMs have the potential to revolutionize academic practices by reducing administrative burdens and improving efficiency. LLMs have the potential to facilitate surgical research by increasing writing efficiency, building predictive models, and aiding in large dataset analysis. From a clinical standpoint, LLMs can enhance efficiency by triaging patient concerns and generating automated responses. However, challenges exist, such as the need for improved LLM generalization performance, validating content, and addressing ethical concerns. In addition, patient privacy, potential bias in training, and legal responsibility are important considerations that require attention. Research and precautionary measures are necessary to ensure safe and unbiased use of LLMs in surgery.Conclusions and RelevanceAlthough limitations exist, LLMs hold promise for enhancing surgical efficiency while still prioritizing patient care. The authors recommend that the academic surgical community further investigate the potential applications of LLMs while being cautious about potential harms.",
        "link": "http://dx.doi.org/10.1001/jamasurg.2023.6496"
    },
    {
        "id": 10727,
        "title": "Evaluation Metrics",
        "authors": "Michael McTear, Marina Ashurkina",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0110-5_8"
    },
    {
        "id": 10728,
        "title": "Leveraging large language models: transforming scholarly publishing for the better",
        "authors": "Lisa A. Fortier",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2460/ajvr.23.08.editorial"
    },
    {
        "id": 10729,
        "title": "ChatGPT Will Take Your Neurology Boards Now",
        "authors": "Susan Fitzgerald",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/01.nt.0001007276.74435.dc"
    },
    {
        "id": 10730,
        "title": "Performance of Large Language Models on Pharmacy Exam: A Comparative Assessment Using the NAPLEX",
        "authors": "Mirana Angel, Haiyi Xing, Anuj Patel, Amal Alachkar, Pierre Baldi",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractBackgroundThere has been considerable recent effort in integrating Large Language Models (LLMs) across different fields, including healthcare. However, the possibility of applying LLMs in pharmacy-related sciences is under-explored.ObjectivesThis study aims to evaluate the capabilities and limitations of six LLMs–GPT-3.5, GPT-4, Llama-2-7B, Llama-2-13B, Llama-2-70B, and Mistral-7B, in the field of pharmacy by assessing their reasoning abilities on a sample of the North American Pharmacist Licensure Examination (NAPLEX). Additionally, we explore the potential impacts of LLMs on pharmacy education and practice.MethodsTo evaluate the LLMs, we utilized the sample of the NAPLEX exam comprising 225 multiple-choice questions sourced from the APhA Complete Review for Pharmacy, 13th Edition | Pharmacy Library. These questions were presented to the Large Language Models through either local deployment or the Application programming interface (API), and the answers generated by the LLMs were subsequently compared with the answer key.ResultsThere is a notable disparity in the performance of the LLMs. GPT-4 emerged as the top performer, accurately answering 87.1% of the questions. Among the six LLMs evaluated, GPT-4 was the only model capable of passing the NAPLEX exam.ConclusionWe examined the performance of Large Language Models based on their model size, training methods, and fine-tuning algorithms. Given the continuous evolution of LLMs, it is reasonable to anticipate that future models will effortlessly excel in exams such as the NAPLEX. This highlights the significant potential of LLMs to influence the field of pharmacy. Hence, we must evaluate both the positive and negative implications associated with the integration of LLMs in pharmacy education and practice.",
        "link": "http://dx.doi.org/10.1101/2023.12.06.570434"
    },
    {
        "id": 10731,
        "title": "Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education",
        "authors": "Vahid Ashrafimoghari, Necdet Gürkan",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4681307"
    },
    {
        "id": 10732,
        "title": "Large Language Models for Therapy Recommendations Across 3 Clinical Specialties: Comparative Study (Preprint)",
        "authors": "Theresa Isabelle Wilhelm, Jonas Roos, Robert Kaczmarczyk",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nAs advancements in artificial intelligence (AI) continue, large language models (LLMs) have emerged as promising tools for generating medical information. Their rapid adaptation and potential benefits in health care require rigorous assessment in terms of the quality, accuracy, and safety of the generated information across diverse medical specialties.\n\n\nOBJECTIVE\nThis study aimed to evaluate the performance of 4 prominent LLMs, namely, Claude-instant-v1.0, GPT-3.5-Turbo, Command-xlarge-nightly, and Bloomz, in generating medical content spanning the clinical specialties of ophthalmology, orthopedics, and dermatology.\n\n\nMETHODS\nThree domain-specific physicians evaluated the AI-generated therapeutic recommendations for a diverse set of 60 diseases. The evaluation criteria involved the mDISCERN score, correctness, and potential harmfulness of the recommendations. ANOVA and pairwise <i>t</i> tests were used to explore discrepancies in content quality and safety across models and specialties. Additionally, using the capabilities of OpenAI’s most advanced model, GPT-4, an automated evaluation of each model’s responses to the diseases was performed using the same criteria and compared to the physicians’ assessments through Pearson correlation analysis.\n\n\nRESULTS\nClaude-instant-v1.0 emerged with the highest mean mDISCERN score (3.35, 95% CI 3.23-3.46). In contrast, Bloomz lagged with the lowest score (1.07, 95% CI 1.03-1.10). Our analysis revealed significant differences among the models in terms of quality <i>(P</i>&lt;.001). Evaluating their reliability, the models displayed strong contrasts in their falseness ratings, with variations both across models <i>(P</i>&lt;.001) and specialties <i>(P</i>&lt;.001). Distinct error patterns emerged, such as confusing diagnoses; providing vague, ambiguous advice; or omitting critical treatments, such as antibiotics for infectious diseases. Regarding potential harm, GPT-3.5-Turbo was found to be the safest, with the lowest harmfulness rating. All models lagged in detailing the risks associated with treatment procedures, explaining the effects of therapies on quality of life, and offering additional sources of information. Pearson correlation analysis underscored a substantial alignment between physician assessments and GPT-4’s evaluations across all established criteria <i>(P</i>&lt;.01).\n\n\nCONCLUSIONS\nThis study, while comprehensive, was limited by the involvement of a select number of specialties and physician evaluators. The straightforward prompting strategy (“How to treat…”) and the assessment benchmarks, initially conceptualized for human-authored content, might have potential gaps in capturing the nuances of AI-driven information. The LLMs evaluated showed a notable capability in generating valuable medical content; however, evident lapses in content quality and potential harm signal the need for further refinements. Given the dynamic landscape of LLMs, this study’s findings emphasize the need for regular and methodical assessments, oversight, and fine-tuning of these AI tools to ensure they produce consistently trustworthy and clinically safe medical advice. Notably, the introduction of an auto-evaluation mechanism using GPT-4, as detailed in this study, provides a scalable, transferable method for domain-agnostic evaluations, extending beyond therapy recommendation assessments.\n",
        "link": "http://dx.doi.org/10.2196/preprints.49324"
    },
    {
        "id": 10733,
        "title": "Studying second language acquisition in the age of large language models: Unlocking the mysteries of language and learning, A commentary on “Age effects in second language acquisition: Expanding the emergentist account” by Catherine L. Caldwell-Harris and Brian MacWhinney",
        "authors": "Viorica Marian",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.bandl.2023.105338"
    },
    {
        "id": 10734,
        "title": "Corrigendum to “Transmission Versus Truth, Imitation Versus Innovation: What Children Can Do That Large Language and Language-and-Vision Models Cannot (Yet)?”",
        "authors": "",
        "published": "2024-2-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1177/17456916231222009"
    },
    {
        "id": 10735,
        "title": "Large Language Models are Complex Table Parsers",
        "authors": "Bowen Zhao, Changkai Ji, Yuejie Zhang, Wen He, Yingwen Wang, Qing Wang, Rui Feng, Xiaobo Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.914"
    },
    {
        "id": 10736,
        "title": "From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models",
        "authors": "Dongjun Kang, Joonsuk Park, Yohan Jo, JinYeong Bak",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.961"
    },
    {
        "id": 10737,
        "title": "INFORM : Information eNtropy based multi-step reasoning FOR large language Models",
        "authors": "Chuyue Zhou, Wangjie You, Juntao Li, Jing Ye, Kehai Chen, Min Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.216"
    },
    {
        "id": 10738,
        "title": "cTBLS: Augmenting Large Language Models with Conversational Tables",
        "authors": "Anirudh S. Sundar, Larry Heck",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.nlp4convai-1.6"
    },
    {
        "id": 10739,
        "title": "Lexical Semantics with Large Language Models: A Case Study of English “break”",
        "authors": "Erika Petersen, Christopher Potts",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-eacl.36"
    },
    {
        "id": 10740,
        "title": "Augmenting Cognitive Architectures with Large Language Models",
        "authors": "Himanshu Joshi, Volkan Ustun",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "A particular fusion of generative models and cognitive architectures is discussed with the help of the Soar and Sigma cognitive architectures. After a brief introduction to cognitive architecture concepts and Large Language Models as exemplar generative AI models, one approach towards their fusion is discussed. This is then analyzed with a summary of potential benefits and extensions needed to existing cognitive architecture that is closest to the proposal.",
        "link": "http://dx.doi.org/10.1609/aaaiss.v2i1.27689"
    },
    {
        "id": 10741,
        "title": "Creative Mutation: A Prescriptive Approach to the Use of ChatGPT and Large Language Models in Lawyering",
        "authors": "Nick Noonan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4406907"
    },
    {
        "id": 10742,
        "title": "A Re-Ranker Scheme For Integrating Large Scale NLU Models",
        "authors": "Chengwei Su, Rahul Gupta, Shankar Ananthakrishnan, Spyros Matsoukas",
        "published": "2018-12",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt.2018.8639519"
    },
    {
        "id": 10743,
        "title": "Revolutionizing Translation with AI: Unravelling Neural Machine Translation and Generative Pre-Trained Large Language Models",
        "authors": "Sai Cheong Siu",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4499768"
    },
    {
        "id": 10744,
        "title": "AuRo special issue on large language models in robotics guest editorial",
        "authors": "",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10514-023-10153-1"
    },
    {
        "id": 10745,
        "title": "Citation screening using large language models for creating clinical practice guidelines: A protocol for a prospective study",
        "authors": "Takehiko Oami, Yohei Okada, Taka-aki Nakada",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractBackgroundThe development of clinical practice guidelines requires a meticulous literature search and screening process. This study aims to explore the potential of large language models in the development of the Japanese Clinical Practice Guidelines for Management of Sepsis and Septic Shock (J-SSCG), focusing on enhancing literature search quality and reducing the citation screening workload.MethodsA prospective study will be conducted to compare the efficiency and accuracy of literature citation screening between the conventional method and a novel approach using large language models. We will use the large language model, namely GPT-4, to conduct literature searches for predefined clinical questions. We will objectively measure the time required for citation screening and compare it to the time taken using the conventional method. Following the screening, we will calculate and compare the sensitivity and specificity of the results obtained from the conventional method and the large language models-assisted process. The total time spent using both approaches will also be compared to assess workload reduction.Trial registrationThis research is submitted with the University hospital medical information network clinical trial registry (UMIN-CTR) [UMIN000053091].Conflicts of interestAll authors declare no conflicts of interest to have.FundingNone",
        "link": "http://dx.doi.org/10.1101/2023.12.29.23300652"
    },
    {
        "id": 10746,
        "title": "List of academic search engines that use Large Language models for generative answers and some factors to consider when using",
        "authors": "Aaron Tay",
        "published": "No Date",
        "citations": 0,
        "abstract": "List of academic search engines that use Large Language models for generative answers (for the latest version - see this page) This is a non-comprehensive list of academic search engines that use generative AI (almost always Large language models) to generate direct answers on top of list of relevant results, typically using Retrieval Augmented Generation (RAG) Techniques.",
        "link": "http://dx.doi.org/10.59350/4e1n2-7fa50"
    },
    {
        "id": 10747,
        "title": "BioLLMBench: A Comprehensive Benchmarking of Large Language Models in Bioinformatics",
        "authors": "Varuni Sarwal, Viorel Munteanu, Timur Suhodolschi, Dumitru Ciorba, Eleazar Eskin, Wei Wang, Serghei Mangul",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractLarge Language Models (LLMs) have shown great promise in their knowledge integration and problem-solving capabilities, but their ability to assist in bioinformatics research has not been systematically evaluated. To bridge this gap, we present BioLLMBench, a novel benchmarking framework coupled with a scoring metric scheme for comprehensively evaluating LLMs in solving bioinformatics tasks. Through BioLLMBench, we conducted a thorough evaluation of 2,160 experimental runs of the three most widely used models, GPT-4, Bard and LLaMA, focusing on 36 distinct tasks within the field of bioinformatics. The tasks come from six key areas of emphasis within bioinformatics that directly relate to the daily challenges and tasks faced by individuals within the field. These areas are domain expertise, mathematical problem-solving, coding proficiency, data visualization, summarizing research papers, and developing machine learning models. The tasks also span across varying levels of complexity, ranging from fundamental concepts to expert-level challenges. Each key area was evaluated using seven specifically designed task metrics, which were then used to conduct an overall evaluation of the LLM’s response. To enhance our understanding of model responses under varying conditions, we implemented a Contextual Response Variability Analysis. Our results reveal a diverse spectrum of model performance, with GPT-4 leading in all tasks except mathematical problem solving. GPT4 was able to achieve an overall proficiency score of 91.3% in domain knowledge tasks, while Bard excelled in mathematical problem-solving with a 97.5% success rate. While GPT-4 outperformed in machine learning model development tasks with an average accuracy of 65.32%, both Bard and LLaMA were unable to generate executable end-to-end code. All models faced considerable challenges in research paper summarization, with none of them exceeding a 40% score in our evaluation using the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score, highlighting a significant area for future improvement. We observed an increase in model performance variance when using a new chatting window compared to using the same chat, although the average scores between the two contextual environments remained similar. Lastly, we discuss various limitations of these models and acknowledge the risks associated with their potential misuse.",
        "link": "http://dx.doi.org/10.1101/2023.12.19.572483"
    },
    {
        "id": 10748,
        "title": "Large language models and the perils of their hallucinations",
        "authors": "Razvan Azamfirei, Sapna R. Kudchadkar, James Fackler",
        "published": "2023-3-21",
        "citations": 47,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s13054-023-04393-x"
    },
    {
        "id": 10749,
        "title": "Large Language Models and Psychoeducation",
        "authors": "Amnuay Kleebayoon, Viroj Wiwanitkit",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/yct.0000000000000956"
    },
    {
        "id": 10750,
        "title": "Large Language Models and Generative AI in Finance: An Analysis of ChatGPT, Bard, and Bing AI",
        "authors": "David Krause",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4511540"
    },
    {
        "id": 10751,
        "title": "Geo-RAG: Gaining Insights from Unstructured Geological Documents with Large Language Models",
        "authors": "T. Dong, C. Subia-Waud, S. Hou",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3997/2214-4609.202439068"
    },
    {
        "id": 10752,
        "title": "How to Safely Integrate Large Language Models Into Health Care",
        "authors": "Scott Gottlieb, Lauren Silvis",
        "published": "2023-9-21",
        "citations": 6,
        "abstract": "This JAMA Forum discusses categories of artificial intelligence devices such as clinical decision support tools and large language models that are increasing being used in health care and the improvements needed to ensure the accuracy and rigor of these tools for patient use.",
        "link": "http://dx.doi.org/10.1001/jamahealthforum.2023.3909"
    },
    {
        "id": 10753,
        "title": "Exploring the Potential of Large Language Models to Generate Formative Programming Feedback",
        "authors": "Natalie Kiesler, Dominic Lohr, Hieke Keuning",
        "published": "2023-10-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/fie58773.2023.10343457"
    },
    {
        "id": 10754,
        "title": "Robotic Assembly of Interlocking Blocks for Construction Based on Large Language Models",
        "authors": "Mengjun Wang, Yan Li, Shuai Li",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1061/9780784485262.079"
    },
    {
        "id": 10755,
        "title": "Large Language Models are Temporal and Causal Reasoners for Video Question Answering",
        "authors": "Dohwan Ko, Ji Lee, Woo-Young Kang, Byungseok Roh, Hyunwoo Kim",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.261"
    },
    {
        "id": 10756,
        "title": "Large Language Models Only Pass Primary School Exams in Indonesia: A Comprehensive Test on IndoMMLU",
        "authors": "Fajri Koto, Nurul Aisyah, Haonan Li, Timothy Baldwin",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.760"
    },
    {
        "id": 10757,
        "title": "From Stigma to Support: A Parallel Monolingual Corpus and NLP Approach for Neutralizing Mental Illness Bias",
        "authors": "Mason Choey,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_028"
    },
    {
        "id": 10758,
        "title": "Entity Extraction in Low Resource Domains with Selective Pre-training of Large Language Models",
        "authors": "Aniruddha Mahapatra, Sharmila Reddy Nangi, Aparna Garimella, Anandhavelu N",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.61"
    },
    {
        "id": 10759,
        "title": "Large Language Models versus Natural Language Understanding and Generation",
        "authors": "Nikitas Karanikolas, Eirini Manga, Nikoletta Samaridi, Eleni Tousidou, Michael Vassilakopoulos",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3635059.3635104"
    },
    {
        "id": 10760,
        "title": "SKILL: Structured Knowledge Infusion for Large Language Models",
        "authors": "Fedor Moiseev, Zhe Dong, Enrique Alfonseca, Martin Jaggi",
        "published": "2022",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.113"
    },
    {
        "id": 10761,
        "title": "CodeT5+: Open Code Large Language Models for Code Understanding and Generation",
        "authors": "Yue Wang, Hung Le, Akhilesh Gotmare, Nghi Bui, Junnan Li, Steven Hoi",
        "published": "2023",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.68"
    },
    {
        "id": 10762,
        "title": "Large Language Models Demonstrate the Potential of Statistical Learning in Language",
        "authors": "Pablo Contreras Kallens, Ross Deans Kristensen‐McLachlan, Morten H. Christiansen",
        "published": "2023-3",
        "citations": 23,
        "abstract": "AbstractTo what degree can language be acquired from linguistic input alone? This question has vexed scholars for millennia and is still a major focus of debate in the cognitive science of language. The complexity of human language has hampered progress because studies of language–especially those involving computational modeling–have only been able to deal with small fragments of our linguistic skills. We suggest that the most recent generation of Large Language Models (LLMs) might finally provide the computational tools to determine empirically how much of the human language ability can be acquired from linguistic experience. LLMs are sophisticated deep learning architectures trained on vast amounts of natural language data, enabling them to perform an impressive range of linguistic tasks. We argue that, despite their clear semantic and pragmatic limitations, LLMs have already demonstrated that human‐like grammatical language can be acquired without the need for a built‐in grammar. Thus, while there is still much to learn about how humans acquire and use language, LLMs provide full‐fledged computational models for cognitive scientists to empirically evaluate just how far statistical learning might take us in explaining the full complexity of human language.",
        "link": "http://dx.doi.org/10.1111/cogs.13256"
    },
    {
        "id": 10763,
        "title": "Evolution of Neural Networks to Large Language Models",
        "authors": "Akshay Kulkarni, Adarsha Shivananda, Anoosh Kulkarni, Dilip Gudivada",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-9994-4_2"
    },
    {
        "id": 10764,
        "title": "Prompting or Fine-tuning? A Comparative Study of Large Language Models for Taxonomy Construction",
        "authors": "Boqi Chen, Fandi Yi, Dániel Varró",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/models-c59198.2023.00097"
    },
    {
        "id": 10765,
        "title": "Improving the Transferability of Clinical Note Section Classification Models with BERT and Large Language Model Ensembles",
        "authors": "Weipeng Zhou, Majid Afshar, Dmitriy Dligach, Yanjun Gao, Timothy Miller",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.clinicalnlp-1.16"
    },
    {
        "id": 10766,
        "title": "Speaker Attribution in German Parliamentary Debates with QLoRA-adapted Large Language Models",
        "authors": "Tobias Bornheim, Niklas Grieger, Patrick Gustav Blaneck, Stephan Bialonski",
        "published": "2024-3-3",
        "citations": 0,
        "abstract": "The growing body of political texts opens up new opportunities for rich insights into political dynamics and ideologies but also increases the workload for manual analysis. Automated speaker attribution, which detects who said what to whom in a speech event and is closely related to semantic role labeling, is an important processing step for computational text analysis. We study the potential of the large language model family Llama 2 to automate speaker attribution in German parliamentary debates from 2017-2021. We fine-tune Llama 2 with QLoRA, an efficient training strategy, and observe our approach to achieve competitive performance in the GermEval 2023 Shared Task On Speaker Attribution in German News Articles and Parliamentary Debates. Our results shed light on the capabilities of large language models in automating speaker attribution, revealing a promising avenue for computational analysis of political discourse and the development of semantic role labeling systems.",
        "link": "http://dx.doi.org/10.21248/jlcl.37.2024.244"
    },
    {
        "id": 10767,
        "title": "Zero-Shot Information Extraction for Clinical Meta-Analysis using Large Language Models",
        "authors": "David Kartchner, Selvi Ramalingam, Irfan Al-Hussaini, Olivia Kronick, Cassie Mitchell",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bionlp-1.37"
    },
    {
        "id": 10768,
        "title": "Just Fine-tune Twice: Selective Differential Privacy for Large Language Models",
        "authors": "Weiyan Shi, Ryan Shea, Si Chen, Chiyuan Zhang, Ruoxi Jia, Zhou Yu",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.425"
    },
    {
        "id": 10769,
        "title": "Robust Prompt Optimization for Large Language Models Against Distribution Shifts",
        "authors": "Moxin Li, Wenjie Wang, Fuli Feng, Yixin Cao, Jizhi Zhang, Tat-Seng Chua",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.95"
    },
    {
        "id": 10770,
        "title": "How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?",
        "authors": "Xin Xu, Yuqi Zhu, Xiaohan Wang, Ningyu Zhang",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.sustainlp-1.13"
    },
    {
        "id": 10771,
        "title": "Can Large Language Models Safely Address Patient Questions Following Cataract Surgery?",
        "authors": "Mohita Chowdhury, Ernest Lim, Aisling Higham, Rory McKinnon, Nikoletta Ventoura, Yajie He, Nick De Pennington",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.clinicalnlp-1.17"
    },
    {
        "id": 10772,
        "title": "Generalized Large-Context Language Models Based on Forward-Backward Hierarchical Recurrent Encoder-Decoder Models",
        "authors": "Ryo Masumura, Mana Ihori, Tomohiro Tanaka, Itsumi Saito, Kyosuke Nishida, Takanobu Oba",
        "published": "2019-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/asru46091.2019.9003857"
    },
    {
        "id": 10773,
        "title": "Learning Analytics in the Era of Large Language Models",
        "authors": "Elisabetta Mazzullo, Okan Bulut, Tarid Wongvorachan, Bin Tan",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "Learning analytics (LA) has the potential to significantly improve teaching and learning, but there are still many areas for improvement in LA research and practice. The literature highlights limitations in every stage of the LA life cycle, including scarce pedagogical grounding and poor design choices in the development of LA, challenges in the implementation of LA with respect to the interpretability of insights, prediction, and actionability of feedback, and lack of generalizability and strong practices in LA evaluation. In this position paper, we advocate for empowering teachers in developing LA solutions. We argue that this would enhance the theoretical basis of LA tools and make them more understandable and practical. We present some instances where process data can be utilized to comprehend learning processes and generate more interpretable LA insights. Additionally, we investigate the potential implementation of large language models (LLMs) in LA to produce comprehensible insights, provide timely and actionable feedback, enhance personalization, and support teachers’ tasks more extensively.",
        "link": "http://dx.doi.org/10.3390/analytics2040046"
    },
    {
        "id": 10774,
        "title": "Automatic Bug Fixing via Deliberate Problem Solving with Large Language Models",
        "authors": "Guoyang Weng, Artur Andrzejak",
        "published": "2023-10-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/issrew60843.2023.00040"
    },
    {
        "id": 10775,
        "title": "Large Language Models in Finance: A Survey",
        "authors": "Yinheng Li, Shaofei Wang, Han Ding, Hang Chen",
        "published": "2023-11-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3604237.3626869"
    },
    {
        "id": 10776,
        "title": "BrainLM: Estimation of Brain Activity Evoked Linguistic Stimuli Utilizing Large Language Models",
        "authors": "Ying Luo, Ichiro Kobayashi",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/smc53992.2023.10394227"
    },
    {
        "id": 10777,
        "title": "Grimoire is All You Need for Enhancing Large Language Models",
        "authors": "Ding Chen, Shichao Song, Qingchen Yu, Zhiyu Li, Wenjin Wang, Feiyu Xiong, Bo Tang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIn-context Learning (ICL) is one of the key methods for enhancing the performance of large language models on specific tasks by providing a set of few-shot question and answer examples. However, the ICL capability of different types of models shows significant variation due to factors such as model architecture, volume of learning data, and the size of parameters. Generally, the larger the model's parameter size and the more extensive the learning data, the stronger its ICL capability. In this paper, we propose a method SLEICL (Strong LLM Enhanced ICL) that involves learning from examples using strong language models and then summarizing and transferring these learned skills to weak language models for inference and application. This ensures the stability and effectiveness of ICL. Compared to directly enabling weak language models to learn from prompt examples, SLEICL reduces the difficulty of ICL for these models. Our experiments, conducted on up to eight datasets with five language models, demonstrate that weak language models achieve consistent improvement over their own zero-shot or few-shot capabilities using the SLEICL method. Some weak language models even surpass the performance of GPT4-1106-preview (zero-shot) with the aid of SLEICL.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3845612/v1"
    },
    {
        "id": 10778,
        "title": "Comparing Human Text Classification Performance and Explainability with Large Language and Machine Learning Models Using Eye-Tracking",
        "authors": "Jeevithashree Divya Venkatesh, Aparajita Jaiswal, Gaurav Nanda",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nTo understand the alignment between reasonings of humans and artificial intelligence (AI) models, this empirical study compared the human text classification performance and explainability with a traditional machine learning (ML) model and large language model (LLM). A domain-specific noisy textual dataset of injury narratives had to be classified into six cause-of-injury codes. While the ML model was trained on pre-labelled injury narratives, LLM and humans did not receive any specialized training. The explainability of different approaches was compared using the words they focused on during classification. These words were identified using eye-tracking for humans, explainable AI approach LIME for ML model, and prompts for LLM.  The classification performance of ML model was relatively better than LLM and humans- overall and particularly for complicated and challenging to classify narratives. The top-3 words used by ML and LLM for classification agreed with humans to a greater extent as compared to later words.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-4002294/v2"
    },
    {
        "id": 10779,
        "title": "EXPLORING LARGE LANGUAGE MODELS FOR THE EDUCATION OF INDIVIDUALS WITH COGNITIVE IMPAIRMENTS",
        "authors": "Asterio Fiora, Francesco Piferi, Pietro Crovari, Franca Garzotto",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21125/inted.2024.1161"
    },
    {
        "id": 10780,
        "title": "Let’s Chat: Integrating Large Language Models into Blended Learning of English for Specific Purposes",
        "authors": "Hengbin Yan",
        "published": "2023-7-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iset58841.2023.00044"
    },
    {
        "id": 10781,
        "title": "Large language models: rheumatologists’ newest colleagues?",
        "authors": "Vincenzo Venerito, Latika Gupta",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41584-023-01070-9"
    },
    {
        "id": 10782,
        "title": "Large Language Models are Built-in Autoregressive Search Engines",
        "authors": "Noah Ziems, Wenhao Yu, Zhihan Zhang, Meng Jiang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.167"
    },
    {
        "id": 10783,
        "title": "Large Language Models for Fuzzing Parsers (Registered Report)",
        "authors": "Joshua Ackerman, George Cybenko",
        "published": "2023-7-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3605157.3605173"
    },
    {
        "id": 10784,
        "title": "General Theory of Information, Digital Genome, Large Language Models, and Medical Knowledge-Driven Digital Assistant",
        "authors": "W. Patrick Kelly, Francesco Coccaro, Rao Mikkilineni",
        "published": "2023-8-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3390/cmsf2023008070"
    },
    {
        "id": 10785,
        "title": "L3MVN: Leveraging Large Language Models for Visual Target Navigation",
        "authors": "Bangguo Yu, Hamidreza Kasaei, Ming Cao",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iros55552.2023.10342512"
    },
    {
        "id": 10786,
        "title": "Considerations for health care institutions training large language models on electronic health records (Preprint)",
        "authors": "Weipeng Zhou, Danielle Bitterman, Majid Afshar, Timothy A. Miller",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nLarge language models (LLMs) are usually built (pretrained) on general domain data. To adapt LLMs better to health care needs, it might be beneficial for health care institutions to create LLMs pretrained on their own EHR data. Nevertheless, there are concerns related to the training budget, the type of pretraining (pretraining from scratch vs. pretraining on top of pretrained LLMs), and the EHR database size.\n\n\nOBJECTIVE\nThe objective of this manuscript is to address these concerns and to help decision-makers at health care institutions better understand opportunities and challenges for LLM development.\n\n\nMETHODS\nWe use published work on empirical experience in pretraining LLMs, and establish a relationship between the training budget, LLM size, pretraining database size and training time.\n\n\nRESULTS\nWe found that pretraining a modest-sized LLM (13 billion parameters) from scratch requires around 800 GB of EHR data and costs 127,000 USD. For a 65 billion parameter LLM, the EHR requirement is 4000 GB, costing 3 million USD. In comparison, continued pretraining using 500 GB EHR on a 65 billion parameter pretrained LLM would cost 400,000 USD.\n\n\nCONCLUSIONS\nBuilding private LLMs on EHR data can be challenging due to budget and database size limitations. Most health care institutions will not have the required resources to train their own LLMs from scratch, and even continued pretraining will be challenging for many. This study provides a framework for health care institutions when deciding about the deployment of LLMs in their systems.\n",
        "link": "http://dx.doi.org/10.2196/preprints.57484"
    },
    {
        "id": 10787,
        "title": "BioLLMBench: A Comprehensive Benchmarking of Large Language Models in Bioinformatics",
        "authors": "Serghei Mangul, Varuni Sarwal, Viorel Munteanu, Timur Suhodolschi, Dumitru Ciorba, Eleazar Eskin, Wei Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nLarge Language Models (LLMs) have shown great promise in their knowledge integration and problem-solving capabilities, but their ability to assist in bioinformatics research has not been systematically evaluated. To bridge this gap, we present BioLLMBench, a novel benchmarking framework coupled with a scoring metric scheme for comprehensively evaluating LLMs in solving bioinformatics tasks. Through BioLLMBench, we conducted a thorough evaluation of 2,160 experimental runs of the three most widely used models, GPT-4, Bard and LLaMA, focusing on 36 distinct tasks within the field of bioinformatics. The tasks come from six key areas of emphasis within bioinformatics that directly relate to the daily challenges and tasks faced by individuals within the field. These areas are domain expertise, mathematical problem-solving, coding proficiency, data visualization, summarizing research papers, and developing machine learning models. The tasks also span across varying levels of complexity, ranging from fundamental concepts to expert-level challenges. Each key area was evaluated using seven specifically designed task metrics, which were then used to conduct an overall evaluation of the LLM’s response. To enhance our understanding of model responses under varying conditions, we implemented a Contextual Response Variability Analysis. Our results reveal a diverse spectrum of model performance, with GPT-4 leading in all tasks except mathematical problem solving. GPT4 was able to achieve an overall proficiency score of 91.3% in domain knowledge tasks, while Bard excelled in mathematical problem-solving with a 97.5% success rate. While GPT-4 outperformed in machine learning model development tasks with an average accuracy of 65.32%, both Bard and LLaMA were unable to generate executable end-to-end code. All models faced considerable challenges in research paper summarization, with none of them exceeding a 40% score in our evaluation using the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score, highlighting a significant area for future improvement. We observed an increase in model performance variance when using a new chatting window compared to using the same chat, although the average scores between the two contextual environments remained similar. Lastly, we discuss various limitations of these models and acknowledge the risks associated with their  potential misuse.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3780193/v1"
    },
    {
        "id": 10788,
        "title": "Comparing Human Text Classification Performance and Explainability with Large Language and Machine Learning Models Using Eye-Tracking",
        "authors": "Gaurav Nanda, Jeevithashree Divya Venkatesh, Aparajita Jaiswal",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nTo understand the alignment between reasonings of humans and artificial intelligence (AI) models, this empirical study compared the human text classification performance and explainability with a traditional machine learning (ML) model and large language model (LLM).  A domain-specific noisy textual dataset of injury narratives had to be classified into six cause-of-injury codes. While the ML model was trained on pre-labelled injury narratives, LLM and humans did not receive any specialized training. The explainability of different approaches was compared using the words they focused on during classification. These words were identified using eye-tracking for humans, explainable AI approach LIME for ML model, and prompts for LLM.  The classification performance of ML model was relatively better than LLM and humans- overall and particularly for complicated and challenging to classify narratives. The top-3 words used by ML and LLM for classification agreed with humans to a greater extent as compared to later words.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-4002294/v1"
    },
    {
        "id": 10789,
        "title": "From Base to Conversational: Japanese Instruction Dataset and Tuning Large Language Models",
        "authors": "Masahiro Suzuki, Masanori Hirano, Hiroki Sakaji",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386605"
    },
    {
        "id": 10790,
        "title": "Baby steps in evaluating the capacities of large language models",
        "authors": "Michael C. Frank",
        "published": "2023-6-27",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s44159-023-00211-x"
    },
    {
        "id": 10791,
        "title": "BLESS: Benchmarking Large Language Models on Sentence Simplification",
        "authors": "Tannon Kew, Alison Chi, Laura Vásquez-Rodríguez, Sweta Agrawal, Dennis Aumiller, Fernando Alva-Manchego, Matthew Shardlow",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.821"
    },
    {
        "id": 10792,
        "title": "Editing Large Language Models: Problems, Methods, and Opportunities",
        "authors": "Yunzhi Yao, Peng Wang, Bozhong Tian, Siyuan Cheng, Zhoubo Li, Shumin Deng, Huajun Chen, Ningyu Zhang",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.632"
    },
    {
        "id": 10793,
        "title": "Leveraging Large Language Models for Metagenomic Analysis",
        "authors": "M.S. Refahi, B.A. Sokhansanj, G.L. Rosen",
        "published": "2023-12-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/spmb59478.2023.10372773"
    },
    {
        "id": 10794,
        "title": "Large Language Models for Detecting Body Weight Changes as Side Effects of Antidepressants in User-Generated Online Content",
        "authors": "Taïoh Yokoyama, Johan Natter, Julien Godet",
        "published": "No Date",
        "citations": 0,
        "abstract": "ObjectiveHealthcare websites allow patients to share their experiences with their treatments. Drug testimonials provide useful information for real-world evidence, particularly on the occurrence of side effects that may be underreported. We investigated the potential of large language models (LLMs) for detecting signals of body weight change as under-reported side effect of antidepressants in user-generated online content.Materials and MethodsA database of 8,000 user-generated comments about the 32 FDA-approved antidepressants was collected from healthcare social websites. These comments were manually annotated under the supervision of drug experts. Several pre-trained LLMs derived from BERT were fine-tuned to automatically classify comments describing weight gain, weight loss, or the absence of reference to a weight change. Zero-shot classification was also performed. Performance was evaluated on a test set by measuring the weighted precision, recall, F1-score and the prediction accuracy.ResultsAfter fine-tuning, most of the BERT-derived LLMs showed weighted F1-scores above 97%. LLMs with higher number of parameters used in zero-shot classification almost reached the same performance. The main source of errors in predictions came from situations where the machine predicted falsely weight gain or loss, because the text mentioned these elements but for a different molecule than the one for which the comment was written.ConclusionEven fine-tuned LLMs with limited numbers of parameters showed interesting results for the detection of adverse events from online patient testimonials, suggesting they can be used at scale for real-world evidence.",
        "link": "http://dx.doi.org/10.1101/2023.12.09.23299754"
    },
    {
        "id": 10795,
        "title": "How Well Do Large Language Models Perform on Faux Pas Tests?",
        "authors": "Natalie Shapira, Guy Zwirn, Yoav Goldberg",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.663"
    },
    {
        "id": 10796,
        "title": "Multimodal Large Language Models are Generalist Medical Image Interpreters",
        "authors": "Tianyu Han, Lisa C. Adams, Sven Nebelung, Jakob Nikolas Kather, Keno K. Bressem, Daniel Truhn",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractMedicine is undergoing a transformation with the integration of Artificial Intelligence (AI). Traditional AI models, though clinically useful and often matching or surpassing expert clinicians in specific tasks, face a scalability challenge due to the necessity of developing individual models for each task. Therefore, there is a push towards foundation models that are applicable to a wider set of tasks. Our study showcases how non-domain-specific, publicly available vision-language models can be employed as general foundation models for medical applications. We test our paradigm across four medical disciplines - pathology, dermatology, ophthalmology, and radiology - focusing on two use-cases within each discipline. We find that our approach beats existing pre-training methods and is competitive to domain-specific foundation models that require vast amounts of domain-specific training images. We also find that large vision-language models are data efficient and do not require large annotated datasets to reach competitive performance. This allows for the development of new or improved AI models in areas of medicine where data is scarce and will accelerate medical progress towards true multimodal foundation models.",
        "link": "http://dx.doi.org/10.1101/2023.12.21.23300146"
    },
    {
        "id": 10797,
        "title": "The Future of Large Language Models: A Futuristic Dissection on AI and Human Interaction",
        "authors": "Subharun Pal -",
        "published": "2023-5-21",
        "citations": 0,
        "abstract": "This paper delves into the burgeoning domain of large language models (LLMs) and their impending influence on the dynamics of artificial intelligence (AI) and human interaction. Given the rapid evolution of these linguistic titans, a thorough dissection of their prospective trajectory is undertaken. The paper scrutinises the potential of LLMs in facilitating human-like interactions, investigates their limitations and ethical implications, and postulates potential mitigation strategies. The research is driven by a global perspective, incorporating real-world examples and case studies to elucidate the practical implications of LLMs.",
        "link": "http://dx.doi.org/10.36948/ijfmr.2023.v05i03.3135"
    },
    {
        "id": 10798,
        "title": "The Role of Large Language Models (LLMs) in Automated News Writing, Fact-Checking, and the Future of Journalism",
        "authors": "GODWIN OLUWAFEMI OLAOYE, Williams fred",
        "published": "No Date",
        "citations": 0,
        "abstract": "The field of journalism has experienced a profound transformation in recent years, driven in part by the emergence of Large Language Models (LLMs). These AI-powered models, fueled by massive datasets and advanced natural language processing techniques, are reshaping the way news is written, disseminated, and fact-checked. This article delves into the pivotal role of LLMs in automated news writing, fact-checking, and their impact on the future of journalism.",
        "link": "http://dx.doi.org/10.31219/osf.io/72etr"
    },
    {
        "id": 10799,
        "title": "Systematic Assessment of Factual Knowledge in Large Language Models",
        "authors": "Linhao Luo, Trang Vu, Dinh Phung, Reza Haf",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.885"
    },
    {
        "id": 10800,
        "title": "Improving Cybersecurity Named Entity Recognition with Large Language Models",
        "authors": "Zhe Qiao, Chen Zhang, Gang Du",
        "published": "2023-12-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/csecs60003.2023.10428218"
    },
    {
        "id": 10801,
        "title": "Large Language Models as Fiduciaries: A Case Study Toward Robustly Communicating With Artificial Intelligence Through Legal Standards",
        "authors": "John Nay",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4335945"
    },
    {
        "id": 10802,
        "title": "The Impact of Multimodal Large Language Models on Health Care’s Future",
        "authors": "Bertalan Meskó",
        "published": "2023-11-2",
        "citations": 11,
        "abstract": "When large language models (LLMs) were introduced to the public at large in late 2022 with ChatGPT (OpenAI), the interest was unprecedented, with more than 1 billion unique users within 90 days. Until the introduction of Generative Pre-trained Transformer 4 (GPT-4) in March 2023, these LLMs only contained a single mode—text.\nAs medicine is a multimodal discipline, the potential future versions of LLMs that can handle multimodality—meaning that they could interpret and generate not only text but also images, videos, sound, and even comprehensive documents—can be conceptualized as a significant evolution in the field of artificial intelligence (AI). This paper zooms in on the new potential of generative AI, a new form of AI that also includes tools such as LLMs, through the achievement of multimodal inputs of text, images, and speech on health care’s future. We present several futuristic scenarios to illustrate the potential path forward as multimodal LLMs (M-LLMs) could represent the gateway between health care professionals and using AI for medical purposes. It is important to point out, though, that despite the unprecedented potential of generative AI in the form of M-LLMs, the human touch in medicine remains irreplaceable. AI should be seen as a tool that can augment health care professionals rather than replace them. It is also important to consider the human aspects of health care—empathy, understanding, and the doctor-patient relationship—when deploying AI.",
        "link": "http://dx.doi.org/10.2196/52865"
    },
    {
        "id": 10803,
        "title": "Designing Conversational Systems",
        "authors": "Michael McTear, Marina Ashurkina",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0110-5_2"
    },
    {
        "id": 10804,
        "title": "Improving Cybersecurity Named Entity Recognition with Large Language Models",
        "authors": "Zhe Qiao, Chen Zhang, Gang Du",
        "published": "2023-12-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/csecs60003.2023.10428218"
    },
    {
        "id": 10805,
        "title": "DecoMT: Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models",
        "authors": "Ratish Puduppully, Anoop Kunchukuttan, Raj Dabre, Ai Ti Aw, Nancy Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.279"
    },
    {
        "id": 10806,
        "title": "MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations",
        "authors": "Arkil Patel, Satwik Bhattamishra, Siva Reddy, Dzmitry Bahdanau",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.134"
    },
    {
        "id": 10807,
        "title": "Enhancing Computation Efficiency in Large Language Models through Weight and Activation Quantization",
        "authors": "Janghwan Lee, Minsoo Kim, Seungcheol Baek, Seok Hwang, Wonyong Sung, Jungwook Choi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.910"
    },
    {
        "id": 10808,
        "title": "Fine-tuning large neural language models for biomedical natural language processing",
        "authors": "Robert Tinn, Hao Cheng, Yu Gu, Naoto Usuyama, Xiaodong Liu, Tristan Naumann, Jianfeng Gao, Hoifung Poon",
        "published": "2023-4",
        "citations": 17,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patter.2023.100729"
    },
    {
        "id": 10809,
        "title": "Conversational AI Platforms",
        "authors": "Michael McTear, Marina Ashurkina",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0110-5_7"
    },
    {
        "id": 10810,
        "title": "The Rise and Design of Enterprise Large Language Models",
        "authors": "Daniel E. O’Leary",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mis.2023.3345591"
    },
    {
        "id": 10811,
        "title": "Large language models and academic writing: Five tiers of engagement",
        "authors": "Martin Bekker",
        "published": "2024-1-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.17159/sajs.2024/17147"
    },
    {
        "id": 10812,
        "title": "Poisoning scientific knowledge using large language models",
        "authors": "Junwei Yang, Hanwen Xu, Srbuhi Mirzoyan, Tong Chen, Zixuan Liu, Wei Ju, Luchen Liu, Ming Zhang, Sheng Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractBiomedical knowledge graphs constructed from scientific literature have been widely used to validate biological discoveries and generate new hypotheses. Recently, large language models (LLMs) have demonstrated a strong ability to generate human-like text data. While most of these text data have been useful, LLM might also be used to generate malicious content. Here, we investigate whether it is possible that a malicious actor can use LLM to generate a malicious paper that poisons scientific knowledge graphs and further affects downstream biological applications. As a proof-of-concept, we develop Scorpius, a conditional text generation model that generates a malicious paper abstract conditioned on a promoting drug and a target disease. The goal is to fool the knowledge graph constructed from a mixture of this malicious abstract and millions of real papers so that knowledge graph consumers will misidentify this promoting drug as relevant to the target disease. We evaluated Scorpius on a knowledge graph constructed from 3,818,528 papers and found that Scorpius can increase the relevance of 71.3% drug disease pairs from the top 1000 to the top 10 by only adding one malicious abstract. Moreover, the generation of Scorpius achieves better perplexity than ChatGPT, suggesting that such malicious abstracts cannot be efficiently detected by humans. Collectively, Scorpius demonstrates the possibility of poisoning scientific knowledge graphs and manipulating downstream applications using LLMs, indicating the importance of accountable and trustworthy scientific knowledge discovery in the era of LLM.",
        "link": "http://dx.doi.org/10.1101/2023.11.06.565928"
    },
    {
        "id": 10813,
        "title": "HuaSLIM: Human Attention Motivated Shortcut Learning Identification and Mitigation for Large Language models",
        "authors": "Yuqi Ren, Deyi Xiong",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.781"
    },
    {
        "id": 10814,
        "title": "Comparison between program synthesis with large language models and model predictive control for buildings optimal operation",
        "authors": "Laura Zabala, Vadim Liventsev, Jesus Febres, Raymond Sterling",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nAdvanced control techniques, particularly Model Predictive Control (MPC), have proven effective in enhancing energy efficiency within buildings. While MPC remains a prominent choice, alternative strategies like program synthesis, employing large language models, warrant exploration. Despite its success in diverse applications and the inherent advantage of explainability, the performance of program synthesis in the building domain remains largely unexplored. Implemented through the Synthesize, Execute, Debug, and Rank framework with a pretrained GPT model, program synthesis is compared with MPC in an energy management problem using the BOPTEST building optimization testing framework. The test scenario involves a residential dwelling with a modulating heat pump. MPC, incorporating a graybox model recalibrated using real-time data, excels in improving thermal comfort in typical conditions, achieving a notable 35.5\\% reduction in energy costs. In extreme peak conditions, MPC maintains thermal comfort improvements at a slightly higher energy cost. Program synthesis, while enhancing thermal comfort, lags behind MPC, revealing some trade-off challenges in certain scenarios. Notably, a program synthesis designed for a specific scenario demonstrates adaptability, achieving desired objectives across diverse scenarios. These findings emphasize the potential of program synthesis in optimizing energy efficiency and thermal comfort but underscore the importance of nuanced parameterization and scenario-specific optimization for its successful implementation in building control strategies.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3735947/v1"
    },
    {
        "id": 10815,
        "title": "NEWTON: Are Large Language Models Capable of Physical Reasoning?",
        "authors": "Yi Wang, Jiafei Duan, Dieter Fox, Siddhartha Srinivasa",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.652"
    },
    {
        "id": 10816,
        "title": "The Bot Delusion. Large language models and anticipated consequences for academics’ publication and citation behavior",
        "authors": "Oliver Wieczorek, Isabel Steinhardt, Christian Schneijderberg, Rebecca Schmidt, Sylvi Mauermeister",
        "published": "No Date",
        "citations": 0,
        "abstract": "The reproduction of social inequalities through artificial intelligence and large language models (LLMs) has been demonstrated empirically in various areas of society, for example in policing and personnel hiring decisions. Yet, a broader discussion is missing to what extent LLMs may affect the scientific enterprise, reinforce or mitigate existing structural inequalities, and introduce a “bot delusion” in academia. Focusing on publications and citations behavior, we devise a thought experiment regarding the impact of LLMs. These differentiate between the reproduction of preexisting structurally conditioned inequalities in science (socio-cognitive stasis), or to a catharsis, that may counteract structural inequalities and Matthew Effects. We develop three scenarios of the consequences of using LLMs for citations: The LLM anticipated consequences are reproducing content and status quo (scenario 1), enabling content coherence evaluation (scenario 2) and content evaluation (scenario 3). In face of the fast-paced evolution of LLMs, to attribute meaning to anticipated consequences on citations from a sociological perspective, we discuss the normative significance of LLM-use for selecting citations. Considered as ideal types, Merton’s CUDOS norms of communalism, universalism, disinterestedness, and organized skepticism capture the catharsis opportunity offered by LLM, and stasis is reflected in the Mitroff’s SPIOD counter-norms of secrecy, particularism, self-interestedness and organized dogmatism. As SPIOD only captures individual counter-norms, we introduce communal counter-norms to capture academics’ loyal citation behavior. The latter insinuates a status quo future of science (scenario 1), while the mixed-access (scenario 2) and open science (scenario 3) futures suggest a more cognitively and less socially structured scientific endeavor.",
        "link": "http://dx.doi.org/10.31235/osf.io/493qg"
    },
    {
        "id": 10817,
        "title": "TOWARDS USING LARGE LANGUAGE MODELS TO AUTOMATICALLY GENERATE READING COMPREHENSION ASSESSMENTS FOR EARLY GRADE READING ASSESSMENT",
        "authors": "Imran Zualkernan, Salsabeel Shapsough",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21125/inted.2024.0986"
    },
    {
        "id": 10818,
        "title": "AI-Powered Software Testing: The Impact of Large Language Models on Testing Methodologies",
        "authors": "Vahit Bayrı, Ece Demirel",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iisec59749.2023.10391027"
    },
    {
        "id": 10819,
        "title": "Large language models associate Muslims with violence",
        "authors": "Abubakar Abid, Maheen Farooqi, James Zou",
        "published": "2021-6-17",
        "citations": 43,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s42256-021-00359-2"
    },
    {
        "id": 10820,
        "title": "Extracting Financial Data From Unstructured Sources: Leveraging Large Language Models",
        "authors": "Huaxia Li, Haoyun Gao, Chengzhang Wu, Miklos A. Vasarhelyi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4567607"
    },
    {
        "id": 10821,
        "title": "Task-Level Thinking Steps Help Large Language Models for Challenging Classification Task",
        "authors": "Chunhui Du, Jidong Tian, Haoran Liao, Jindou Chen, Hao He, Yaohui Jin",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.150"
    },
    {
        "id": 10822,
        "title": "Large Language Models im Kundendialog – Chancen, Risiken, Ausblicke",
        "authors": "Nils Hafner, Sophie Hundertmark",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-658-42851-8_16"
    },
    {
        "id": 10823,
        "title": "AI Technologies in the Judiciary: Critical Appraisal of Large Language Models in Judicial Decision-making",
        "authors": "Juan David Gutiérrez Rodríguez",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4667572"
    },
    {
        "id": 10824,
        "title": "Integration of Large Language Models into Higher Education: A Perspective from Learners",
        "authors": "Katerina Zdravkova, Fisnik Dalipi, Fredrik Ahlgren",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/siie59826.2023.10423681"
    },
    {
        "id": 10825,
        "title": "Detecting Argumentative Fallacies in the Wild: Problems and Limitations of Large Language Models",
        "authors": "Ramon Ruiz-Dolz, John Lawrence",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.argmining-1.1"
    },
    {
        "id": 10826,
        "title": "Leveraging Large Language Models for Auto-remediation in Microservices Architecture",
        "authors": "Komal Sarda",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/acsos-c58168.2023.00025"
    },
    {
        "id": 10827,
        "title": "Leveraging Large Language Models for Clinical Abbreviation Disambiguation",
        "authors": "Manda Hosseini, Mandana Hosseini, Reza Javidan",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10916-024-02049-z"
    },
    {
        "id": 10828,
        "title": "Large Language Models for Scientific Publishing: Please, Do Not Make Them a Foe",
        "authors": "Nader Rifai",
        "published": "2024-3-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/clinchem/hvad219"
    },
    {
        "id": 10829,
        "title": "ChatGPT and GPT-4 for Professional Translators: Exploring the Potential of Large Language Models in Translation",
        "authors": "Sai Cheong Siu",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4448091"
    },
    {
        "id": 10830,
        "title": "Implicit Bias in Large Language Models: Experimental Proof and Implications for Education",
        "authors": "Melissa Warr, Nicole Jakubczyk Oster, Roger Isaac",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4625078"
    },
    {
        "id": 10831,
        "title": "Advanced Prompt Engineering",
        "authors": "Michael McTear, Marina Ashurkina",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0110-5_6"
    },
    {
        "id": 10832,
        "title": "The ambiguity of BERTology: what do large language models represent?",
        "authors": "Tommi Buder-Gröndahl",
        "published": "2023-12-26",
        "citations": 0,
        "abstract": "AbstractThe field of “BERTology” aims to locate linguistic representations in large language models (LLMs). These have commonly been interpreted as representing structural descriptions (SDs) familiar from theoretical linguistics, such as abstract phrase-structures. However, it is unclear how such claims should be interpreted in the first place. This paper identifies six possible readings of “linguistic representation” from philosophical and linguistic literature, concluding that none has a straight-forward application to BERTology. In philosophy, representations are typically analyzed as cognitive vehicles individuated by intentional content. This clashes with a prevalent mentalist interpretation of linguistics, which treats SDs as (narrow) properties of cognitive vehicles themselves. I further distinguish between three readings of both kinds, and discuss challenges each brings for BERTology. In particular, some readings would make it trivially false to assign representations of SDs to LLMs, while others would make it trivially true. I illustrate this with the concrete case study of structural probing: a dominant model-interpretation technique. To improve the present situation, I propose that BERTology should adopt a more “LLM-first” approach instead of relying on pre-existing linguistic theories developed for orthogonal purposes.",
        "link": "http://dx.doi.org/10.1007/s11229-023-04435-5"
    },
    {
        "id": 10833,
        "title": "The Moral Landscape of General-Purpose Large Language Models",
        "authors": "Giada Pistilli",
        "published": "2024-2-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003320791-9"
    },
    {
        "id": 10834,
        "title": "Large Language Models in jihadist terrorism and crimes",
        "authors": "Julia Puczyńska,, Marcin Podhajski, Karolina Wojtasik, Tomasz P. Michalak",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "The authors discuss Large Language Models in the context of the security risks associated with their functions and availability. Even though their applications seem to be similar to search engines and internet access, the true danger posed by Large Language Models lies in basic analytical and programming skills they provide to any criminal or terrorist. They assert that accessible Large Language Models not only diminish financial barriers to various criminal activities but also lower the expertise and commitment required by individuals or small groups to commit crimes, and acts of terror in particular. On the other hand, however, law enforcement agencies can also harness the capabilities of these models to stay ahead of emerging threats.",
        "link": "http://dx.doi.org/10.4467/27204383ter.24.012.19400"
    },
    {
        "id": 10835,
        "title": "Artificial intelligence literacy for the language industry – with particular emphasis on recent large language models such as GPT-4",
        "authors": "Ralph Krüger",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "Abstract\nThis article explores the concept of artificial intelligence (AI) literacy in the context of the language industry, placing particular emphasis on recent large language models such as GPT-4. After a brief introduction in which the relevance of AI literacy in the language industry is highlighted, the article provides a concise overview of artificial neural networks and a brief history of neural network-based artificial intelligence. This is intended to lay the conceptual groundwork for the subsequent discussion of the basic principles and capabilities of large language models. Then, the article investigates in detail the concept of AI literacy, discussing the AI Literacy Framework proposed by Long/Magerko (2020) and illustrating the interface between AI literacy and the two adjacent digital literacies of professional machine translation literacy and data literacy. The article then zooms in on the practical applicability of AI technologies by discussing areas where workflows in the language industry (with a focus on the computer-assisted translation process) could be automated or optimised through large language models. The article concludes with some general reflections on the relevance of field-specific and societal AI literacy in the presence of powerful AI technologies.",
        "link": "http://dx.doi.org/10.1515/les-2023-0024"
    },
    {
        "id": 10836,
        "title": "Offensive Text Span Detection in Romanian Comments Using Large Language Models",
        "authors": "Andrei Paraschiv, Teodora Andreea Ion, Mihai Dascalu",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "The advent of online platforms and services has revolutionized communication, enabling users to share opinions and ideas seamlessly. However, this convenience has also brought about a surge in offensive and harmful language across various communication mediums. In response, social platforms have turned to automated methods to identify offensive content. A critical research question emerges when investigating the role of specific text spans within comments in conveying offensive characteristics. This paper conducted a comprehensive investigation into detecting offensive text spans in Romanian language comments using Transformer encoders and Large Language Models (LLMs). We introduced an extensive dataset of 4800 Romanian comments annotated with offensive text spans. Moreover, we explored the impact of varying model sizes, architectures, and training data volumes on the performance of offensive text span detection, providing valuable insights for determining the optimal configuration. The results argue for the effectiveness of BERT pre-trained models for this span-detection task, showcasing their superior performance. We further investigated the impact of different sample-retrieval strategies for few-shot learning using LLMs based on vector text representations. The analysis highlights important insights and trade-offs in leveraging LLMs for offensive-language-detection tasks.",
        "link": "http://dx.doi.org/10.3390/info15010008"
    },
    {
        "id": 10837,
        "title": "Guidelines for the Integration of Large Language Models in Developing and Refining Interview Protocols",
        "authors": "Jessica Parker, Veronica Richard, Kimberly Becker",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "Rapid advancements in generative artificial intelligence (AI), specifically large language models (LLMs), offer unprecedented opportunities and challenges for qualitative researchers. This paper presents comprehensive guidelines for the ethical and effective use of LLMs in the development and refinement of interview protocols. Through a multidisciplinary lens, this paper explores potential pitfalls, ethical considerations, and best practices to ensure the responsible integration of LLMs in the research process. The guidelines proposed serve not only as a methodological roadmap for researchers but also as a catalyst for dialogue on the ethical dimensions of LLMs in qualitative research. Furthermore, the authors describe and share a web-based application developed to guide users through the stages of the protocol. Ultimately, the paper calls for a collective, informed approach to harness the capabilities of LLMs while upholding the integrity and ethical standards of scholarly research.",
        "link": "http://dx.doi.org/10.46743/2160-3715/2023.6801"
    },
    {
        "id": 10838,
        "title": "ChatGPT and Large Language Models: What are the Implications for Policy Makers?",
        "authors": "Paul G. Geertsema, Albert Bifet, Richard Green",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4424048"
    },
    {
        "id": 10839,
        "title": "Reference-Free Summarization Evaluation with Large Language Models",
        "authors": "Abbas Akkasi, Kathleen Fraser, Majid Komeili",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.eval4nlp-1.16"
    },
    {
        "id": 10840,
        "title": "Can ChatGPT Truly Overcome Other Large Language Models?",
        "authors": "Partha Pratim Ray",
        "published": "2023-9-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1177/08465371231199444"
    },
    {
        "id": 10841,
        "title": "Large language models and political science",
        "authors": "Mitchell Linegar, Rafal Kocielnik, R. Michael Alvarez",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "Large Language Models (LLMs) are a type of artificial intelligence that uses information from very large datasets to model the use of language and generate content. While LLMs like GPT-3 have been used widely in many applications, the recent public release of OpenAI's ChatGPT has opened more debate about the potential uses and abuses of LLMs. In this paper, we provide a brief introduction to LLMs and discuss their potential application in political science and political methodology. We use two examples of LLMs from our recent research to illustrate how LLMs open new areas of research. We conclude with a discussion of how researchers can use LLMs in their work, and issues that researchers need to be aware of regarding using LLMs in political science and political methodology.",
        "link": "http://dx.doi.org/10.3389/fpos.2023.1257092"
    },
    {
        "id": 10842,
        "title": "A Closer Look into Using Large Language Models for Automatic Evaluation",
        "authors": "Cheng-Han Chiang, Hung-yi Lee",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.599"
    },
    {
        "id": 10843,
        "title": "Self-Knowledge Guided Retrieval Augmentation for Large Language Models",
        "authors": "Yile Wang, Peng Li, Maosong Sun, Yang Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.691"
    },
    {
        "id": 10844,
        "title": "Decoding Stumpers: Large Language Models vs. Human Problem-Solvers",
        "authors": "Alon Goldstein, Miriam Havin, Roi Reichart, Ariel Goldstein",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.779"
    },
    {
        "id": 10845,
        "title": "Large language models in vitreoretinal surgery",
        "authors": "Rodrigo Anguita, Achini Makuloluwa, Jennifer Hind, Louisa Wickham",
        "published": "2024-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41433-023-02751-1"
    },
    {
        "id": 10846,
        "title": "The Invisible Embedded “Values” Within Large Language Models: Implications for Mental Health Use",
        "authors": "Dorit Hadar-Shoval, Kfir Asraf, Yonathan Mizrachi, Yuval Haber, Zohar Elyoseph",
        "published": "No Date",
        "citations": 3,
        "abstract": "Abstract\nValues are an integral part of any mental health intervention, profoundly shaping definitions of psychopathology and treatment approaches. As large language models (LLMs) hold promises for mental health applications, it is prudent to evaluate their embedded “values-like” abilities prior to implementation. This study uses Schwartz's Theory of Basic Values (STBV) to quantify and compare the motivational “values-like” abilities underpinning four leading LLMs. The results suggest that Schwartz’s theory can reliably and validly measure “values-like” abilities within LLMs. However, apparent divergence from published human values data emerged, with each LLM exhibiting a distinct motivational profile, potentially reflecting opaque alignment choices. Such apparent mismatches with human values diversity might negatively impact global LLM mental health implementations. The appropriate transparency and refinement of alignment processes may be vital for instilling comprehensive human values into LLMs before this sensitive implementation in mental healthcare. Overall, the study provides a framework for rigorously evaluating and improving LLMs’ embodiment of diverse cultural values to promote mental health equity.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3456660/v1"
    },
    {
        "id": 10847,
        "title": "Verbal lie detection using Large Language Models",
        "authors": "Riccardo Loconte, Roberto Russo, Pasquale Capuozzo, Pietro Pietrini, Giuseppe Sartori",
        "published": "2023-12-21",
        "citations": 2,
        "abstract": "AbstractHuman accuracy in detecting deception with intuitive judgments has been proven to not go above the chance level. Therefore, several automatized verbal lie detection techniques employing Machine Learning and Transformer models have been developed to reach higher levels of accuracy. This study is the first to explore the performance of a Large Language Model, FLAN-T5 (small and base sizes), in a lie-detection classification task in three English-language datasets encompassing personal opinions, autobiographical memories, and future intentions. After performing stylometric analysis to describe linguistic differences in the three datasets, we tested the small- and base-sized FLAN-T5 in three Scenarios using 10-fold cross-validation: one with train and test set coming from the same single dataset, one with train set coming from two datasets and the test set coming from the third remaining dataset, one with train and test set coming from all the three datasets. We reached state-of-the-art results in Scenarios 1 and 3, outperforming previous benchmarks. The results revealed also that model performance depended on model size, with larger models exhibiting higher performance. Furthermore, stylometric analysis was performed to carry out explainability analysis, finding that linguistic features associated with the Cognitive Load framework may influence the model’s predictions.",
        "link": "http://dx.doi.org/10.1038/s41598-023-50214-0"
    },
    {
        "id": 10848,
        "title": "The Smallness of Large Language Models",
        "authors": "Peter J. Denning",
        "published": "2023-9",
        "citations": 1,
        "abstract": "There is so much more to language and human beings than large language models can possibly master.",
        "link": "http://dx.doi.org/10.1145/3608966"
    },
    {
        "id": 10849,
        "title": "Using Augmented Small Multimodal Models to Guide Large Language Models for Multimodal Relation Extraction",
        "authors": "Wentao He, Hanjie Ma, Shaohua Li, Hui Dong, Haixiang Zhang, Jie Feng",
        "published": "2023-11-10",
        "citations": 0,
        "abstract": "Multimodal Relation Extraction (MRE) is a core task for constructing Multimodal Knowledge images (MKGs). Most current research is based on fine-tuning small-scale single-modal image and text pre-trained models, but we find that image-text datasets from network media suffer from data scarcity, simple text data, and abstract image information, which requires a lot of external knowledge for supplementation and reasoning. We use Multimodal Relation Data augmentation (MRDA) to address the data scarcity problem in MRE, and propose a Flexible Threshold Loss (FTL) to handle the imbalanced entity pair distribution and long-tailed classes. After obtaining prompt information from the small model as a guide model, we employ a Large Language Model (LLM) as a knowledge engine to acquire common sense and reasoning abilities. Notably, both stages of our framework are flexibly replaceable, with the first stage adapting to multimodal related classification tasks for small models, and the second stage replaceable by more powerful LLMs. Through experiments, our EMRE2llm model framework achieves state-of-the-art performance on the challenging MNRE dataset, reaching an 82.95% F1 score on the test set.",
        "link": "http://dx.doi.org/10.3390/app132212208"
    },
    {
        "id": 10850,
        "title": "Accelerating materials language processing with large language models",
        "authors": "Jaewoong Choi, Byungju Lee",
        "published": "2024-2-15",
        "citations": 0,
        "abstract": "AbstractMaterials language processing (MLP) can facilitate materials science research by automating the extraction of structured data from research papers. Despite the existence of deep learning models for MLP tasks, there are ongoing practical issues associated with complex model architectures, extensive fine-tuning, and substantial human-labelled datasets. Here, we introduce the use of large language models, such as generative pretrained transformer (GPT), to replace the complex architectures of prior MLP models with strategic designs of prompt engineering. We find that in-context learning of GPT models with few or zero-shots can provide high performance text classification, named entity recognition and extractive question answering with limited datasets, demonstrated for various classes of materials. These generative models can also help identify incorrect annotated data. Our GPT-based approach can assist material scientists in solving knowledge-intensive MLP tasks, even if they lack relevant expertise, by offering MLP guidelines applicable to any materials science domain. In addition, the outcomes of GPT models are expected to reduce the workload of researchers, such as manual labelling, by producing an initial labelling set and verifying human-annotations.",
        "link": "http://dx.doi.org/10.1038/s43246-024-00449-9"
    },
    {
        "id": 10851,
        "title": "Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models",
        "authors": "Xiaolei Wang, Xinyu Tang, Xin Zhao, Jingyuan Wang, Ji-Rong Wen",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.621"
    },
    {
        "id": 10852,
        "title": "Mind the User! Measures to More Accurately Evaluate the Practical Value of Active Learning Strategies",
        "authors": "Julia Romberg,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_107"
    },
    {
        "id": 10853,
        "title": "Data Fusion for Better Fake Reviews Detection",
        "authors": "Alimuddin Melleng,  , Anna-Jurek Loughrey, Deepak P,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_079"
    },
    {
        "id": 10854,
        "title": "Theory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests",
        "authors": "Max van Duijn, Bram van Dijk, Tom Kouwenhoven, Werner de Valk, Marco Spruit, Peter vanderPutten",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-1.25"
    },
    {
        "id": 10855,
        "title": "LeSS: A Computationally-Light Lexical Simplifier for Spanish",
        "authors": "Sanja Štajner,  , Daniel Ibáñez, Horacio Saggion,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_120"
    },
    {
        "id": 10856,
        "title": "Extracting Domain Models from Textual Requirements in the Era of Large Language Models",
        "authors": "Sathurshan Arulmohan, Marie-Jean Meurs, Sébastien Mosser",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/models-c59198.2023.00096"
    },
    {
        "id": 10857,
        "title": "Unimodal Intermediate Training for Multimodal Meme Sentiment Classification",
        "authors": "Muzhaffar Hazman,  , Susan McKeever, Josephine Griffith,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_055"
    },
    {
        "id": 10858,
        "title": "Tackling the Myriads of Collusion Scams on YouTube Comments of Cryptocurrency Videos",
        "authors": "Sadat Shahriar,  , Arjun Mukherjee,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_114"
    },
    {
        "id": 10859,
        "title": "SSSD: Leveraging Pre-Trained Models and Semantic Search for Semi-Supervised Stance Detection",
        "authors": "Andr´e Mediote de Sousa,  , Karin Becker,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_030"
    },
    {
        "id": 10860,
        "title": "Exploration of Open Large Language Models for eDiscovery",
        "authors": "Sumit Pai, Sounak Lahiri, Ujjwal Kumar, Krishanu Baksi, Elijah Soba, Michael Suesserman, Nirmala Pudota, Jon Foster, Edward Bowen, Sanmitra Bhattacharya",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.nllp-1.17"
    },
    {
        "id": 10861,
        "title": "A Systematic Investigation of Commonsense Knowledge in Large Language Models",
        "authors": "Xiang Lorraine Li, Adhiguna Kuncoro, Jordan Hoffmann, Cyprien de Masson d’Autume, Phil Blunsom, Aida Nematzadeh",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.812"
    },
    {
        "id": 10862,
        "title": "Story-to-Images Translation: Leveraging Diffusion Models and Large Language Models for Sequence Image Generation",
        "authors": "Haruka Kumagai, Ryosuke Yamaki, Hiroki Naganuma",
        "published": "2023-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3607540.3617144"
    },
    {
        "id": 10863,
        "title": "Theory of Mind for Multi-Agent Collaboration via Large Language Models",
        "authors": "Huao Li, Yu Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes, Charles Lewis, Katia Sycara",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.13"
    },
    {
        "id": 10864,
        "title": "What are large language models supposed to model?",
        "authors": "Idan A. Blank",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.tics.2023.08.006"
    },
    {
        "id": 10865,
        "title": "Predicting dementia from spontaneous speech using large language models",
        "authors": "Felix Agbavor, Hualou Liang",
        "published": "2022-12-22",
        "citations": 25,
        "abstract": "Language impairment is an important biomarker of neurodegenerative disorders such as Alzheimer’s disease (AD). Artificial intelligence (AI), particularly natural language processing (NLP), has recently been increasingly used for early prediction of AD through speech. Yet, relatively few studies exist on using large language models, especially GPT-3, to aid in the early diagnosis of dementia. In this work, we show for the first time that GPT-3 can be utilized to predict dementia from spontaneous speech. Specifically, we leverage the vast semantic knowledge encoded in the GPT-3 model to generate text embedding, a vector representation of the transcribed text from speech, that captures the semantic meaning of the input. We demonstrate that the text embedding can be reliably used to (1) distinguish individuals with AD from healthy controls, and (2) infer the subject’s cognitive testing score, both solely based on speech data. We further show that text embedding considerably outperforms the conventional acoustic feature-based approach and even performs competitively with prevailing fine-tuned models. Together, our results suggest that GPT-3 based text embedding is a viable approach for AD assessment directly from speech and has the potential to improve early diagnosis of dementia.",
        "link": "http://dx.doi.org/10.1371/journal.pdig.0000168"
    },
    {
        "id": 10866,
        "title": "Mitigation of User-Prompt Bias in Large Language Models: A Natural Langauge Processing and Deep Learning Based Framework",
        "authors": "Sarvesh Tiku",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4561423"
    },
    {
        "id": 10867,
        "title": "Numeric Magnitude Comparison Effects in Large Language Models",
        "authors": "Raj Shah, Vijay Marupudi, Reba Koenen, Khushi Bhardwaj, Sashank Varma",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.383"
    },
    {
        "id": 10868,
        "title": "Do Large Language Models Understand?",
        "authors": "Hyundeuk Cheon",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15750/chss.90.202311.003"
    },
    {
        "id": 10869,
        "title": "Labor Space: A Unifying Representation of the Labor Market via Large Language Models",
        "authors": "Seongwoon Kim, Yong-Yeol Ahn, Jaehyuk Park",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4703367"
    },
    {
        "id": 10870,
        "title": "Leveraging large language models: transforming scholarly publishing for the better",
        "authors": "Lisa A. Fortier",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2460/javma.261.8.1106"
    },
    {
        "id": 10871,
        "title": "Can Large Language Models Better Predict Software Vulnerability?",
        "authors": "Evangelos Katsadouros, Charalampos Z. Patrikakis, George Hurlburt",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mitp.2023.3284628"
    },
    {
        "id": 10872,
        "title": "ChatGPT and beyond: Considerations in the use of Large Language Models (LLMs) in clinical practice (Preprint)",
        "authors": "Puneet Seth, Stephen Pomedli, Melanie de Wit, Muhammad Mamdani",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\nArtificial intelligence-based chatbots that fall in the category of Large Language Models, such as ChatGPT, have caught the world's attention. They boast a broad range of general capabilities and are believed to have the potential to revolutionize nearly every aspect of work and human interaction. The application of these tools to address administrative and resource challenges in healthcare delivery is promising. This paper discusses the use of these tools to introduce efficiency for frontline healthcare delivery and examines considerations and limitations that must be taken into account when using them in healthcare. Additionally, it explores potential future applications of LLMs in healthcare.\n",
        "link": "http://dx.doi.org/10.2196/preprints.47490"
    },
    {
        "id": 10873,
        "title": "Are Large Pre-Trained Language Models Leaking Your Personal Information?",
        "authors": "Jie Huang, Hanyin Shao, Kevin Chen-Chuan Chang",
        "published": "2022",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-emnlp.148"
    },
    {
        "id": 10874,
        "title": "MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic",
        "authors": "Damien Sileo, Antoine Lernould",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.303"
    },
    {
        "id": 10875,
        "title": "Embedding Search for Quranic Texts based on Large Language Models",
        "authors": "Mohammed Alqarni",
        "published": "2024",
        "citations": 0,
        "abstract": "Semantic search is the process of retrieving relevant information from a large corpus of texts based on the meaning and context of the query. This paper is introduced in order to explore the use of large language models for semantic search of Quranic texts. The Quran, which is the central religious text of Islam, contains rich and complex linguistic and semantic features that pose challenges for traditional keyword-based search methods. This study investigates a semantic search approach utilizing. Large Language Models (LLM) embedding and assess the performance of LLM embedding in comparison to a baseline embedding-based search method using a set of queries that represent different semantic search levels. In addition, this study will also discuss the limitations and implications of using large language models for semantic search of Quranic texts and suggest directions for future research. A significant finding in this study is the consistent effectiveness of the LLM embedding across varying semantic complexities. This suggests that embedding using LLMs can capture deep semantic connections effectively. On the other hand, as a second finding, the state-of-the-art transformer, AraT5, outperforms LLM embeddings in low-level semantic searches, indicating potential for further LLM fine-tuning on Arabic text corpora",
        "link": "http://dx.doi.org/10.34028/21/2/7"
    },
    {
        "id": 10876,
        "title": "A Review of Current Trends, Techniques, and Challenges in Large Language Models (LLMs)",
        "authors": "Rajvardhan Patil, Venkat Gudivada",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "Natural language processing (NLP) has significantly transformed in the last decade, especially in the field of language modeling. Large language models (LLMs) have achieved SOTA performances on natural language understanding (NLU) and natural language generation (NLG) tasks by learning language representation in self-supervised ways. This paper provides a comprehensive survey to capture the progression of advances in language models. In this paper, we examine the different aspects of language models, which started with a few million parameters but have reached the size of a trillion in a very short time. We also look at how these LLMs transitioned from task-specific to task-independent to task-and-language-independent architectures. This paper extensively discusses different pretraining objectives, benchmarks, and transfer learning methods used in LLMs. It also examines different finetuning and in-context learning techniques used in downstream tasks. Moreover, it explores how LLMs can perform well across many domains and datasets if sufficiently trained on a large and diverse dataset. Next, it discusses how, over time, the availability of cheap computational power and large datasets have improved LLM’s capabilities and raised new challenges. As part of our study, we also inspect LLMs from the perspective of scalability to see how their performance is affected by the model’s depth, width, and data size. Lastly, we provide an empirical comparison of existing trends and techniques and a comprehensive analysis of where the field of LLM currently stands.",
        "link": "http://dx.doi.org/10.3390/app14052074"
    },
    {
        "id": 10877,
        "title": "The use of ChatGPT and other large language models in surgical science",
        "authors": "Boris V Janssen, Geert Kazemier, Marc G Besselink",
        "published": "2023-3-7",
        "citations": 26,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/bjsopen/zrad032"
    },
    {
        "id": 10878,
        "title": "Formal Software Architecture Rule Learning: A Comparative Investigation between Large Language Models and Inductive Techniques",
        "authors": "Christian Schindler, Andreas Rausch",
        "published": "2024-2-20",
        "citations": 0,
        "abstract": "This paper explores the application of inferring software architecture rules from examples using Machine Learning (ML). We investigate different methods from Inductive Rule Learning and utilize Large Language Models (LLMs). Traditional manual rule specification approaches are time-consuming and error-prone, motivating the need for automated rule discovery. Leveraging a dataset of software architecture instances and a meta-model capturing implementation facts, we used inductive learning algorithms and LLMs to extract meaningful rules. The induced rules are evaluated against a predefined hypothesis and their generalizability across different system subsets is investigated. The research highlights the capabilities and limitations of ML-based rule learning in the area of software architecture, aiming to inspire further innovation in data-driven rule discovery for more intelligent software architecture practices.",
        "link": "http://dx.doi.org/10.3390/electronics13050816"
    },
    {
        "id": 10879,
        "title": "Wordcraft: Story Writing With Large Language Models",
        "authors": "Ann Yuan, Andy Coenen, Emily Reif, Daphne Ippolito",
        "published": "2022-3-22",
        "citations": 37,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3490099.3511105"
    },
    {
        "id": 10880,
        "title": "Reliable Natural Language Understanding with Large Language Models and Answer Set Programming",
        "authors": "Abhiramon Rajasekharan, Yankai Zeng, Parth Padalkar, Gopal Gupta",
        "published": "2023-9-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4204/eptcs.385.27"
    },
    {
        "id": 10881,
        "title": "Shortcut Learning of Large Language Models in Natural Language Understanding",
        "authors": "Mengnan Du, Fengxiang He, Na Zou, Dacheng Tao, Xia Hu",
        "published": "2024-1",
        "citations": 1,
        "abstract": "Shortcuts often hinder the robustness of large language models.",
        "link": "http://dx.doi.org/10.1145/3596490"
    },
    {
        "id": 10882,
        "title": "Using Large Corpus N-gram Statistics to Improve Recurrent Neural Language Models",
        "authors": "Yiben Yang, Ji-Ping Wang, Doug Downey",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/n19-1330"
    },
    {
        "id": 10883,
        "title": "Resume Screening Using Large Language Models",
        "authors": "Esmail Salakar, Jivitesh Rai, Aayush Salian, Yasha Shah, Jyoti Wadmare",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icast59062.2023.10454984"
    },
    {
        "id": 10884,
        "title": "Generative AI and Simulation Modeling: How Should You (Not) Use Large Language Models Like ChatGPT",
        "authors": "Ali Akhavan, Mohammad  S. Jalali",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4675409"
    },
    {
        "id": 10885,
        "title": "Hermeneutik in Zeiten der KI",
        "authors": "Torsten Hiltmann",
        "published": "2024-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783111351490-014"
    },
    {
        "id": 10886,
        "title": "AI Safety and Ethics",
        "authors": "Michael McTear, Marina Ashurkina",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0110-5_9"
    },
    {
        "id": 10887,
        "title": "The dangers of using large language models for peer review",
        "authors": "Tjibbe Donker",
        "published": "2023-7",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s1473-3099(23)00290-6"
    },
    {
        "id": 10888,
        "title": "Exploring the Role of Large Language Models (LLMs) and Generative AI in Dietary Management of Sinusitis",
        "authors": "Ramamurthy Valavandan, Prakash Valavandan, Kanagalakshmi S, Valavandan V, Savitha R, Kirubashini Kirubashini, Kiran Athidya P, Shubhashni P",
        "published": "2024-1-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.55248/gengpi.5.0124.0338"
    },
    {
        "id": 10889,
        "title": "Using ASR-Generated Text for Spoken Language Modeling",
        "authors": "Nicolas Hervé, Valentin Pelloin, Benoit Favre, Franck Dary, Antoine Laurent, Sylvain Meignier, Laurent Besacier",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bigscience-1.2"
    },
    {
        "id": 10890,
        "title": "Large Language Models for Latvian Named Entity Recognition",
        "authors": "Rinalds Vīksna, Inguna Skadiņa",
        "published": "2020-9-15",
        "citations": 2,
        "abstract": "Transformer-based language models pre-trained on large corpora have demonstrated good results on multiple natural language processing tasks for widely used languages including named entity recognition (NER). In this paper, we investigate the role of the BERT models in the NER task for Latvian. We introduce the BERT model pre-trained on the Latvian language data. We demonstrate that the Latvian BERT model, pre-trained on large Latvian corpora, achieves better results (81.91 F1-measure on average vs 78.37 on M-BERT for a dataset with nine named entity types, and 79.72 vs 78.83 on another dataset with seven types) than multilingual BERT and outperforms previously developed Latvian NER systems.",
        "link": "http://dx.doi.org/10.3233/faia200603"
    },
    {
        "id": 10891,
        "title": "Conceptual structure coheres in human cognition but not in large language models",
        "authors": "Siddharth Suresh, Kushin Mukherjee, Xizheng Yu, Wei-Chun Huang, Lisa Padua, Timothy Rogers",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.47"
    },
    {
        "id": 10892,
        "title": "Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark",
        "authors": "Minje Choi, Jiaxin Pei, Sagar Kumar, Chang Shu, David Jurgens",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.699"
    },
    {
        "id": 10893,
        "title": "Exploring Large Language Models for Classical Philology",
        "authors": "Frederick Riemenschneider, Anette Frank",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.846"
    },
    {
        "id": 10894,
        "title": "Translation Performance from the User’s Perspective of Large Language Models and Neural Machine Translation Systems",
        "authors": "Jungha Son, Boyoung Kim",
        "published": "2023-10-19",
        "citations": 1,
        "abstract": "The rapid global expansion of ChatGPT, which plays a crucial role in interactive knowledge sharing and translation, underscores the importance of comparative performance assessments in artificial intelligence (AI) technology. This study concentrated on this crucial issue by exploring and contrasting the translation performances of large language models (LLMs) and neural machine translation (NMT) systems. For this aim, the APIs of Google Translate, Microsoft Translator, and OpenAI’s ChatGPT were utilized, leveraging parallel corpora from the Workshop on Machine Translation (WMT) 2018 and 2020 benchmarks. By applying recognized evaluation metrics such as BLEU, chrF, and TER, a comprehensive performance analysis across a variety of language pairs, translation directions, and reference token sizes was conducted. The findings reveal that while Google Translate and Microsoft Translator generally surpass ChatGPT in terms of their BLEU, chrF, and TER scores, ChatGPT exhibits superior performance in specific language pairs. Translations from non-English to English consistently yielded better results across all three systems compared with translations from English to non-English. Significantly, an improvement in translation system performance was observed as the token size increased, hinting at the potential benefits of training models on larger token sizes.",
        "link": "http://dx.doi.org/10.3390/info14100574"
    },
    {
        "id": 10895,
        "title": "Exploring the Limits of Large Language Models for Word Definition Generation: A Comparative Analysis",
        "authors": "Esteban Rodríguez-Betancourt, Edgar Casasola-Murillo",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/clei60451.2023.10346136"
    },
    {
        "id": 10896,
        "title": "Research on Visualization of High School Chemistry Online Courses Based on Large Language Models",
        "authors": "",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.25236/ijnde.2024.060223"
    },
    {
        "id": 10897,
        "title": "Probing Quantifier Comprehension in Large Language Models: Another Example of Inverse Scaling",
        "authors": "Akshat Gupta",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.blackboxnlp-1.4"
    },
    {
        "id": 10898,
        "title": "Large Language Models in Uro-oncology",
        "authors": "Dyke Ferber, Jakob Nikolas Kather",
        "published": "2024-2",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.euo.2023.09.019"
    },
    {
        "id": 10899,
        "title": "Redefining Virtual Assistants in Health Care: The Future With Large Language Models",
        "authors": "Emre Sezgin",
        "published": "2024-1-19",
        "citations": 0,
        "abstract": "This editorial explores the evolving and transformative role of large language models (LLMs) in enhancing the capabilities of virtual assistants (VAs) in the health care domain, highlighting recent research on the performance of VAs and LLMs in health care information sharing. Focusing on recent research, this editorial unveils the marked improvement in the accuracy and clinical relevance of responses from LLMs, such as GPT-4, compared to current VAs, especially in addressing complex health care inquiries, like those related to postpartum depression. The improved accuracy and clinical relevance with LLMs mark a paradigm shift in digital health tools and VAs. Furthermore, such LLM applications have the potential to dynamically adapt and be integrated into existing VA platforms, offering cost-effective, scalable, and inclusive solutions. These suggest a significant increase in the applicable range of VA applications, as well as the increased value, risk, and impact in health care, moving toward more personalized digital health ecosystems. However, alongside these advancements, it is necessary to develop and adhere to ethical guidelines, regulatory frameworks, governance principles, and privacy and safety measures. We need a robust interdisciplinary collaboration to navigate the complexities of safely and effectively integrating LLMs into health care applications, ensuring that these emerging technologies align with the diverse needs and ethical considerations of the health care domain.",
        "link": "http://dx.doi.org/10.2196/53225"
    },
    {
        "id": 10900,
        "title": "Introduction to Prompt Engineering",
        "authors": "Michael McTear, Marina Ashurkina",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0110-5_5"
    },
    {
        "id": 10901,
        "title": "Research on Visualization of High School Chemistry Online Courses Based on Large Language Models",
        "authors": "",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.25236/ijnde.2024.060223"
    },
    {
        "id": 10902,
        "title": "I Spy a Metaphor: Large Language Models and Diffusion Models Co-Create Visual Metaphors",
        "authors": "Tuhin Chakrabarty, Arkadiy Saakyan, Olivia Winn, Artemis Panagopoulou, Yue Yang, Marianna Apidianaki, Smaranda Muresan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.465"
    },
    {
        "id": 10903,
        "title": "Davinci the Dualist: The Mind–Body Divide in Large Language Models and in Human Learners",
        "authors": "Iris Berent, Alexzander Sansiveri",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "Abstract\nA large literature suggests that people are intuitive Dualists—they consider the mind ethereal, distinct from the body. Furthermore, Dualism emerges, in part, via learning (e.g., Barlev & Shtulman, 2021). Human learners, however, are also endowed with innate systems of core knowledge, and recent results suggest that core knowledge begets Dualism (Berent, 2023a; Berent et al., 2022). The resulting question, then, is whether the acquisition of Dualism requires core knowledge, or whether Dualism is learnable from experience alone, via domain-general mechanism. Since human learners are equipped with both systems, the evidence from humans cannot decide this question. Accordingly, here, we probe for a mind–body divide in Davinci—a large language model (LLM) that is devoid of core knowledge. We show that Davinci still leans towards Dualism, and that this bias increases systematically with the learner’s inductive potential. Thus, davinci (which forms part of the GPT-3 suite) exhibits mild Dualist tendencies, whereas its descendent, text-davinci-003 (a GPT-3.5 model), shows a stronger bias. It selectively considers thoughts (epistemic states) as disembodied—as unlikely to show up in the body (in the brain). Unlike humans, GPT 3.5 categorically rejected the persistence of the psyche after death. Still, when probed about life, GPT 3.5 showed robust Dualist tendencies. These results demonstrate that the mind–body divide is partly learnable from experience. While results from LLMs cannot fully determine how humans acquire Dualism, they do place a higher burden of proof on nativist theories that trace Dualism to innate core cognition (Berent, 2023a; Berent et al., 2022).",
        "link": "http://dx.doi.org/10.1162/opmi_a_00120"
    },
    {
        "id": 10904,
        "title": "Moffett Antoum<sup>®</sup>: A Deep-Sparse AI Inference System-on-Chip for Vision and Large-language Models",
        "authors": "Zhibin Xiao",
        "published": "2023-8-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/hcs59251.2023.10254723"
    },
    {
        "id": 10905,
        "title": "Benchmarking Large Language Models in Adolescent Growth and Development: A Comparative Analysis of Claude2, ChatGPT-3.5, and Google Bard",
        "authors": "Ying Li, Zichen Song, Weijia Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground: Significant attention has been drawn to large-scale language models (LLMs) for their ability to generate responses that are both contextually relevant and reminiscent of human conversation. Yet, the precision of these models in specialized medical fields, particularly those pertaining to adolescent health, remains largely unexamined. Online searches for information about common health issues during adolescent developmental stages are frequent among patients and their families. In this context, our research evaluates how effectively three different LLMs - Claude2, ChatGPT-3.5, and Google Bard - handle typical inquiries concerning adolescent growth and health development.\nMethods: Our research involved gathering 100 frequently asked questions about adolescent growth and health issues, divided into 10 typical disorder categories: Attention Deficit, Tics, Developmental Delays, Autism Spectrum, Anxiety, Anorexia, Obsessive-Compulsive Disorder, Sleep Issues, Early Puberty, and Depressive Disorders. These questions were then posed to various large language models. A pediatric specialist evaluated the models' answers using a detailed four-tier system (ranging from Poor to Very Good) for accuracy. To ensure consistency, these assessments were revisited and verified at various intervals. High-scoring responses ('Good' or above) were examined closely for their compliance with medical ethics, treatment guidelines, and diagnostic procedures. In contrast, responses that scored lowest ('Poor') were subject to in-depth review, leading to recommendations for minor modifications based on straightforward query adjustments and online medical resources. These revised responses were then re-evaluated to measure any improvements in accuracy.\nFindings: Our study analyzed the performance of different models in adolescent growth and development issues. Claude2 was the top performer, with an average score of 3.54 and a standard deviation of 0.501. ChatGPT-3.5 was close behind, scoring an average of 3.44 and a standard deviation of 0.519. Human raters and Google Bard scored lower, at 2.60 and 2.49 respectively, with larger standard deviations. The one-way ANOVA showed significant differences (F-value 64.692, P-value 4.64e-34), particularly in areas like 'Attention Deficit Disorder', 'Developmental Delay', and 'Depression', where Claude2 and ChatGPT-3.5 outperformed others. The Pearson Chi-Square test (χ² value 117.758, P-value 2.35e-25) confirmed their accuracy and consistency. In self-correction abilities, Claude2, ChatGPT-3.5, and Bard scored 3.3, 3.0, and 2.4, respectively, for simple query-based corrections. For web-based medical self-corrections, the scores improved to 3.8, 3.5, and 3.7. The Pearson Chi-Square tests showed significant improvements for all models (Claude2 P-value 0.0241, ChatGPT-3.5 P-value 0.0150, Bard P-value 0.000017), with Bard showing the most significant improvement. This indicates that web-based medical correction methods significantly enhance performance in complex queries for all LLM chatbots.\nInterpretation: Our findings underscore the potential of Large Language Models (LLMs), particularly Claude2, in providing accurate and comprehensive responses to queries related to adolescent growth and development. The continual strategies and evaluations to enhance the accuracy of LLMs remain crucially important.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3858549/v1"
    },
    {
        "id": 10906,
        "title": "Large language models: What could they do for neurology?",
        "authors": "Guillaume Lajoie",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jns.2023.121044"
    },
    {
        "id": 10907,
        "title": "Investigating the Utility of Surprisal from Large Language Models for Speech Synthesis Prosody",
        "authors": "Sofoklis Kakouros, Juraj Šimko, Martti Vainio, Antti Suni",
        "published": "2023-8-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/ssw.2023-20"
    },
    {
        "id": 10908,
        "title": "Application of Large Language Models to Software Engineering Tasks: Opportunities, Risks, and Implications",
        "authors": "Ipek Ozkaya",
        "published": "2023-5",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ms.2023.3248401"
    },
    {
        "id": 10909,
        "title": "Performance of Publicly Available Large Language Models on Internal Medicine Board-style Questions",
        "authors": "Constantine Tarabanis, Sohail Zahid, Marios Mamalis, Kevin Zhang, Evangelos Kalampokis, Lior Jankelson",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nWe investigate the performance of four large language models (LLMs) on internal medicine board-style examination questions from the Medical Knowledge Self-Assessment Program released by the American College of Physicians. GPT4 outperformed GPT3.5, human users, LaMDA and LLaMA 2 in that order. A drop in GPT4 performance when accessing its API versus its publicly available chatbot (ChatGPT) was recovered through fine tuning in the form of Harrison’s Principles of Internal Medicine.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3378105/v1"
    },
    {
        "id": 10910,
        "title": "Meaning Modulations and Stability in Large Language Models: An Analysis of BERT Embeddings for Psycholinguistic Research",
        "authors": "Giovanni Cassani, Fritz Guenther, Giuseppe Attanasio, Federico Bianchi, Marco Marelli",
        "published": "No Date",
        "citations": 0,
        "abstract": "Computational models of semantic representations have long assumed and produced a single static representation for each word type, ignoring the influence of linguistic context on semantic representations. Recent Large Language Models (LLMs) introduced in Natural Language Processing, however, learn token-level contextualised representations, holding promise to study how semantic representations change in different contexts. In this study we probe type- and token-level representations learned using a prominent example of such models, Bidirectional Encoder Representations from Transformers (BERT), for their ability to i) explain semantic effects found for isolated words (semantic relatedness and similarity ratings, lexical decision, and semantic priming), but critically also to ii) exhibit systematic interactions between lexical semantics and context, and iii) explain meaning modulations in context. Across a wide range of empirical studies on each of these topics, we show that BERT representations satisfy two desiderata for psychologically valid semantic representations: i) they have a stable semantic core which allows people to interpret words in isolation and prevents words to be used arbitrarily and ii) they interact with sentence context in systematic ways, with representations shifting as a function of their semantic core and the context. This demonstrates that a single, comprehensive model which simultaneously learns abstract, type-level prototype representations as well as mechanisms of how these interact with context can explain both isolated word effects and context-dependent variations. Notably, these variations are not limited to discrete word senses, eschewing a strict dichotomy between exemplar and prototype models and re-framing traditional notions of polysemy.",
        "link": "http://dx.doi.org/10.31234/osf.io/b45ys"
    },
    {
        "id": 10911,
        "title": "Trend Analysis of Large Language Models through a Developer Community: A Focus on Stack Overflow",
        "authors": "Jungha Son, Boyoung Kim",
        "published": "2023-11-6",
        "citations": 0,
        "abstract": "In the rapidly advancing field of large language model (LLM) research, platforms like Stack Overflow offer invaluable insights into the developer community’s perceptions, challenges, and interactions. This research aims to analyze LLM research and development trends within the professional community. Through the rigorous analysis of Stack Overflow, employing a comprehensive dataset spanning several years, the study identifies the prevailing technologies and frameworks underlining the dominance of models and platforms such as Transformer and Hugging Face. Furthermore, a thematic exploration using Latent Dirichlet Allocation unravels a spectrum of LLM discussion topics. As a result of the analysis, twenty keywords were derived, and a total of five key dimensions, “OpenAI Ecosystem and Challenges”, “LLM Training with Frameworks”, “APIs, File Handling and App Development”, “Programming Constructs and LLM Integration”, and “Data Processing and LLM Functionalities”, were identified through intertopic distance mapping. This research underscores the notable prevalence of specific Tags and technologies within the LLM discourse, particularly highlighting the influential roles of Transformer models and frameworks like Hugging Face. This dominance not only reflects the preferences and inclinations of the developer community but also illuminates the primary tools and technologies they leverage in the continually evolving field of LLMs.",
        "link": "http://dx.doi.org/10.3390/info14110602"
    },
    {
        "id": 10912,
        "title": "On the Role of the UMLS in Supporting Differential Diagnoses Proposed by Large Language Models",
        "authors": "Majid Afshar, Yanjun Gao, Deepak Gupta, Emma Croxford, Dina Demner-Fushman",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4743563"
    },
    {
        "id": 10913,
        "title": "Teaching the Limitations of Large Language Models in Medical School",
        "authors": "Araliya N. Gunawardene, Gabriella Schmuter",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jsurg.2024.01.008"
    },
    {
        "id": 10914,
        "title": "Vox Populi, Vox ChatGPT: Large Language Models, Education and Democracy",
        "authors": "Niina Zuber, Jan Gogoll",
        "published": "2024-1-11",
        "citations": 0,
        "abstract": "In the era of generative AI and specifically large language models (LLMs), exemplified by ChatGPT, the intersection of artificial intelligence and human reasoning has become a focal point of global attention. Unlike conventional search engines, LLMs go beyond mere information retrieval, entering into the realm of discourse culture. Their outputs mimic well-considered, independent opinions or statements of facts, presenting a pretense of wisdom. This paper explores the potential transformative impact of LLMs on democratic societies. It delves into the concerns regarding the difficulty in distinguishing ChatGPT-generated texts from human output. The discussion emphasizes the essence of authorship, rooted in the unique human capacity for reason—a quality indispensable for democratic discourse and successful collaboration within free societies. Highlighting the potential threats to democracy, this paper presents three arguments: the Substitution argument, the Authenticity argument, and the Facts argument. These arguments highlight the potential risks that are associated with an overreliance on LLMs. The central thesis posits that widespread deployment of LLMs may adversely affect the fabric of a democracy if not comprehended and addressed proactively and properly. In proposing a solution, we advocate for an emphasis on education as a means to mitigate risks. We suggest cultivating thinking skills in children, fostering coherent thought formulation, and distinguishing between machine-generated output and genuine, i.e., human, reasoning. The focus should be on the responsible development and usage of LLMs, with the goal of augmenting human capacities in thinking, deliberating and decision-making rather than substituting them.",
        "link": "http://dx.doi.org/10.3390/philosophies9010013"
    },
    {
        "id": 10915,
        "title": "Embedded Values Shape Ethical Reasoning of Large Language Models on Primary Care Ethical Dilemmas",
        "authors": "Dorit Hadar Shoval, Kfir Asraf, Shiri Shinan-Altman, Zohar Elyoseph, Inbar Levkovich",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4728616"
    },
    {
        "id": 10916,
        "title": "Large Language Models and Computer Security",
        "authors": "Arun Iyengar, Ashish Kundu",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tps-isa58951.2023.00045"
    },
    {
        "id": 10917,
        "title": "Revolutionizing patient safety with artificial intelligence: the potential of natural language processing and large language models",
        "authors": "Eyal Klang, Ezequiel García-Elorrio, Eyal Zimlichman",
        "published": "2023-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/intqhc/mzad049"
    },
    {
        "id": 10918,
        "title": "Towards Understanding Large-Scale Discourse Structures in Pre-Trained and Fine-Tuned Language Models",
        "authors": "Patrick Huber, Giuseppe Carenini",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.170"
    },
    {
        "id": 10919,
        "title": "The Art of SOCRATIC QUESTIONING: Recursive Thinking with Large Language Models",
        "authors": "Jingyuan Qi, Zhiyang Xu, Ying Shen, Minqian Liu, Di Jin, Qifan Wang, Lifu Huang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.255"
    },
    {
        "id": 10920,
        "title": "The Opportunities and Challenges of Large Language Models in Cardiology",
        "authors": "Ashish Sarraju, David Ouyang, Dipti Itchhaporia",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jacadv.2023.100438"
    },
    {
        "id": 10921,
        "title": "Semantic search using protein large language models detects class II microcins in bacterial genomes",
        "authors": "Anastasiya V. Kulikova, Jennifer K. Parker, Bryan W. Davies, Claus O. Wilke",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractClass II microcins are antimicrobial peptides that have shown some potential as novel antibiotics. However, to date only ten class II microcins have been described, and discovery of novel microcins has been hampered by their short length and high sequence divergence. Here, we ask if we can use numerical embeddings generated by protein large language models to detect microcins in bacterial genome assemblies and whether this method can outperform sequence-based methods such as BLAST. We find that embeddings detect known class II microcins much more reliably than does BLAST and that any two microcins tend to have a small distance in embedding space even though they typically are highly diverged at the sequence level. In datasets ofEscherichia coli,Klebsiellaspp., andEnterobacterspp. genomes, we further find novel putative microcins that were previously missed by sequence-based search methods.",
        "link": "http://dx.doi.org/10.1101/2023.11.15.567263"
    },
    {
        "id": 10922,
        "title": "Exploring Large Language Models’ Emotion Detection Abilities: Use Cases From the Middle East",
        "authors": "Radhakrishnan Venkatakrishnan, Mahsa Goodarzi, M. Abdullah Canbaz",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cai54212.2023.00110"
    },
    {
        "id": 10923,
        "title": "Large Language Models – Where Are We and Where Are We Going?",
        "authors": "Caitlyn E.M. Trautwein, Chhavi Chauhan, Chirag Jay Patel",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18243/eon/2023.16.8.1"
    },
    {
        "id": 10924,
        "title": "Evaluation of large language models for discovery of gene set function",
        "authors": "Dexter Pratt, Mengzhou Hu, Sahar Alkhairy, Ingoo Lee, Rudolf Pillich, Robin Bachelder, Trey Ideker",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nGene set analysis is a mainstay of functional genomics, but it relies on manually curated databases of gene functions that are incomplete and unaware of biological context. Here we evaluate the ability of OpenAI’s GPT-4, a Large Language Model (LLM), to develop hypotheses about common gene functions from its embedded biomedical knowledge. We created a GPT-4 pipeline to label gene sets with names that summarize their consensus functions, substantiated by analysis text and citations. Benchmarking against named gene sets in the Gene Ontology, GPT-4 generated very similar names in 50% of cases, while in most remaining cases it recovered the name of a more general concept. In gene sets discovered in ‘omics data, GPT-4 names were more informative than gene set enrichment, with supporting statements and citations that largely verified in human review. The ability to rapidly synthesize common gene functions positions LLMs as valuable functional genomics assistants.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3270331/v1"
    },
    {
        "id": 10925,
        "title": "Infusing behavior science into large language models for activity coaching",
        "authors": "Madhurima Vardhan, Narayan Hegde, Deepak Nathani, Emily Rosenzweig, Alan Karthikesalingam, Martin Seneviratne",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractLarge language models (LLMs) have shown promise for task-oriented dialogue across a range of domains. The use of LLMs in health and fitness coaching is under-explored. Behavior science frameworks such as COM-B, which conceptualizes behavior change in terms of capability (C), Opportunity (O) and Motivation (M), can be used to architect coaching interventions in a way that promotes sustained change. Here we aim to incorporate behavior science principles into an LLM using two knowledge infusion techniques: coach message priming (where exemplar coach responses are provided as context to the LLM), and dialogue re-ranking (where the COM-B category of the LLM output is matched to the inferred user need). Simulated conversations were conducted between the primed or unprimed LLM and a member of the research team, and then evaluated by 8 human raters. Ratings for the primed conversations were significantly higher in terms of empathy and actionability. The same raters also compared a single response generated by the unprimed, primed and re-ranked models, finding a significant uplift in actionability from the re-ranking technique. This is a proof of concept of how behavior science frameworks can be infused into automated conversational agents for a more principled coaching experience.Institutional Review Board (IRB)The study does not involve human subjects beyond the volunteer annotators. IRB approval was not sought for this research.",
        "link": "http://dx.doi.org/10.1101/2023.03.31.23287995"
    },
    {
        "id": 10926,
        "title": "LLMaAA: Making Large Language Models as Active Annotators",
        "authors": "Ruoyu Zhang, Yanzeng Li, Yongliang Ma, Ming Zhou, Lei Zou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.872"
    },
    {
        "id": 10927,
        "title": "Does the English Matter? Elicit Cross-lingual Abilities of Large Language Models",
        "authors": "Leonardo Ranaldi, Giulia Pucci",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.mrl-1.14"
    },
    {
        "id": 10928,
        "title": "Large Language Models Effectively Leverage Document-level Context for Literary Translation, but Critical Errors Persist",
        "authors": "Marzena Karpinska, Mohit Iyyer",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.wmt-1.41"
    },
    {
        "id": 10929,
        "title": "Automated Claim Matching with Large Language Models: Empowering Fact-Checkers in the Fight Against Misinformation",
        "authors": "Eun Cheol Choi, Emilio Ferrara",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4614239"
    },
    {
        "id": 10930,
        "title": "Indian Pediatrics’ Policy Regarding Artificial Intelligence (AI) — Enabled Large Language Models",
        "authors": "Devendra Mishra",
        "published": "2023-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s13312-023-2825-1"
    },
    {
        "id": 10931,
        "title": "Large Language Models and Low-Resource Languages: An Examination of Armenian NLP",
        "authors": "Hayastan Avetisyan, David Broneske",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-ijcnlp.18"
    },
    {
        "id": 10932,
        "title": "Large language models and the emergence phenomena",
        "authors": "Vera Sorin, Eyal Klang",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ejro.2023.100494"
    },
    {
        "id": 10933,
        "title": "GPT-RE: In-context Learning for Relation Extraction using Large Language Models",
        "authors": "Zhen Wan, Fei Cheng, Zhuoyuan Mao, Qianying Liu, Haiyue Song, Jiwei Li, Sadao Kurohashi",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.214"
    },
    {
        "id": 10934,
        "title": "Event Annotation and Detection in Kannada-English Code-Mixed Social Media Data",
        "authors": "Sumukh S,  , Abhinav Appidi, Manish Shrivastava,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_108"
    },
    {
        "id": 10935,
        "title": "Visually-Situated Natural Language Understanding with Contrastive Reading Model and Frozen Large Language Models",
        "authors": "Geewook Kim, Hodong Lee, Daehee Kim, Haeji Jung, Sanghee Park, Yoonsik Kim, Sangdoo Yun, Taeho Kil, Bado Lee, Seunghyun Park",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.735"
    },
    {
        "id": 10936,
        "title": "Publish-subscribe with large language models",
        "authors": "Vatche Isahagian, Vinod Muthusamy, Aleksander Slominski",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626564.3629099"
    },
    {
        "id": 10937,
        "title": "Dialogue-based generation of self-driving simulation scenarios using Large Language Models",
        "authors": "Antonio Valerio Miceli Barone, Craig Innes, Alex Lascarides",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.splurobonlp-1.1"
    },
    {
        "id": 10938,
        "title": "The Importance of Understanding Language in Large Language Models",
        "authors": "Alaa Youssef, Samantha Stein, Justin Clapp, David Magnus",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15265161.2023.2256614"
    },
    {
        "id": 10939,
        "title": "IdealGPT: Iteratively Decomposing Vision and Language Reasoning via Large Language Models",
        "authors": "Haoxuan You, Rui Sun, Zhecan Wang, Long Chen, Gengyu Wang, Hammad Ayyubi, Kai-Wei Chang, Shih-Fu Chang",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.755"
    },
    {
        "id": 10940,
        "title": "Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large Language Models on Sequence to Sequence Tasks",
        "authors": "Andrea Sottana, Bin Liang, Kai Zou, Zheng Yuan",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.543"
    },
    {
        "id": 10941,
        "title": "When Truth Matters - Addressing Pragmatic Categories in Natural Language Inference (NLI) by Large Language Models (LLMs)",
        "authors": "Reto Gubelmann, Aikaterini-lida Kalouli, Christina Niklaus, Siegfried Handschuh",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.starsem-1.4"
    },
    {
        "id": 10942,
        "title": "Towards a Consensus Taxonomy for Annotating Errors in Automatically Generated Text",
        "authors": "Rudali Huidrom,  , Anya Belz,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_058"
    },
    {
        "id": 10943,
        "title": "Employing Large Language Models for Dialogue-Based Personalized Needs Extraction in Smart Services",
        "authors": "Takuya Nakata, Sina Chen, Sachio Saiki, Masahide Nakamura",
        "published": "2023-12-23",
        "citations": 0,
        "abstract": "Research concerning the personalization of services encompasses approaches such as machine learning and dialogue agents; however, the explainability of the recommendation process remains a challenge. Previous studies have proposed dialogue-based needs extraction systems utilizing the 6W1H need model, but extracting complex needs using simple natural language processing proved challenging. In this research, we embark on the development of an Application Programming Interface (API) that extracts user needs from natural language by leveraging the rapidly advancing Large Language Models (LLM), and on constructing a dialogue-based needs extraction system using this API. For evaluation, we conducted a verification on 100 needs with the aim of assessing the accuracy and comprehensiveness of the outputs from the needs extraction and restoration API. Through this study, it became feasible to extract needs with high accuracy and comprehensiveness from complex natural language using LLM.",
        "link": "http://dx.doi.org/10.5121/csit.2023.132403"
    },
    {
        "id": 10944,
        "title": "Large language models are universal biomedical simulators",
        "authors": "Moritz Schaefer, Stephan Reichl, Rob ter Horst, Adele M. Nicolas, Thomas Krausgruber, Francesco Piras, Peter Stepper, Christoph Bock, Matthias Samwald",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractComputational simulation of biological processes can be a valuable tool in accelerating biomedical research, but usually requires extensive domain knowledge and manual adaptation. Recently, large language models (LLMs) such as GPT-4 have proven surprisingly successful for a wide range of tasks by generating human language at a very large scale. Here we explore the potential of leveraging LLMs as simulators of biological systems. We establish proof-of-concept of a text-based simulator, SimulateGPT, that uses LLM reasoning. We demonstrate good prediction performance for various biomedical applications, without requiring explicit domain knowledge or manual tuning. LLMs thus enable a new class of versatile and broadly applicable biological simulators. This text-based simulation paradigm is well-suited for modeling and understanding complex living systems that are difficult to describe with physics-based first-principles simulation, but for which extensive knowledge and context is available as written text.",
        "link": "http://dx.doi.org/10.1101/2023.06.16.545235"
    },
    {
        "id": 10945,
        "title": "Leveraging Large Language Models for Goal-driven Interactive Recommendations",
        "authors": "Alan Said, Martijn C. Willemsen, Leandro Balby Marinho, Itallo Silva",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3623809.3623965"
    },
    {
        "id": 10946,
        "title": "Tracing the Influence of Large Language Models across the Most Impactful Scientific Works",
        "authors": "Dana-Mihaela Petroșanu, Alexandru Pîrjan, Alexandru Tăbușcă",
        "published": "2023-12-10",
        "citations": 1,
        "abstract": "In recent years, large language models (LLMs) have come into view as one of the most transformative developments in the technical domain, influencing diverse sectors ranging from natural language processing (NLP) to creative arts. Their rise signifies an unprecedented convergence of computational prowess, sophisticated algorithms, and expansive datasets, pushing the boundaries of what was once thought to be achievable. Such a profound impact mandates a thorough exploration of the LLMs’ evolutionary trajectory. Consequently, this article conducts a literature review of the most impactful scientific works, using the reliable Web of Science (WoS) indexing database as a data source in order to attain a thorough and quality-assured analysis. This review identifies relevant patterns, provides research insights, traces technological growth, and anticipates potential future directions. Beyond mapping the known, this study aims to highlight uncharted areas within the LLM landscape, thereby catalyzing future research endeavors. The ultimate goal is to enhance collective understanding, encourage collaboration, and guide subsequent innovations in harnessing the potential of LLMs for societal and technological advancement.",
        "link": "http://dx.doi.org/10.3390/electronics12244957"
    },
    {
        "id": 10947,
        "title": "Large-Language-Models und die DSGVO – „Wer den Datenschutz nicht ehrt, ist die KI nicht wert?“",
        "authors": "Florian Werkmeister, Jonathan Laux",
        "published": "2023-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.37307/j.2196-9817.2023.04.03"
    },
    {
        "id": 10948,
        "title": "ChatGPT and large language models: Impact on the integrity of academic publishing",
        "authors": "Varuni Tennakoon",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No abstract available",
        "link": "http://dx.doi.org/10.4038/slaj.v7i1.189"
    },
    {
        "id": 10949,
        "title": "Automatic Model Selection with Large Language Models for Reasoning",
        "authors": "James Zhao, Yuxi Xie, Kenji Kawaguchi, Junxian He, Michael Xie",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.55"
    },
    {
        "id": 10950,
        "title": "Large Language Models in Academic Plastic Surgery: The Way Forward",
        "authors": "Hassan ElHawary, Andrew Gorgy, Jeffrey E. Janis",
        "published": "2023-4",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/gox.0000000000004949"
    },
    {
        "id": 10951,
        "title": "Potential of Large Language Models as Tools Against Medical Disinformation—Reply",
        "authors": "Ashley M. Hopkins, Bradley D. Menz, Michael J. Sorich",
        "published": "2024-2-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1001/jamainternmed.2024.0023"
    },
    {
        "id": 10952,
        "title": "Software Vulnerability Detection using Large Language Models",
        "authors": "Moumita Das Purba, Arpita Ghosh, Benjamin J. Radford, Bill Chu",
        "published": "2023-10-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/issrew60843.2023.00058"
    },
    {
        "id": 10953,
        "title": "On the Interaction with Large Language Models for Web Accessibility: Implications and Challenges",
        "authors": "Giovanni Delnevo, Manuel Andruccioli, Silvia Mirri",
        "published": "2024-1-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ccnc51664.2024.10454680"
    },
    {
        "id": 10954,
        "title": "Evaluating Large Language Models on Controlled Generation Tasks",
        "authors": "Jiao Sun, Yufei Tian, Wangchunshu Zhou, Nan Xu, Qian Hu, Rahul Gupta, John Wieting, Nanyun Peng, Xuezhe Ma",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.190"
    },
    {
        "id": 10955,
        "title": "Comparison of Multilingual Entity Linking Approaches",
        "authors": "Ivelina Bozhinova,  , Andrey Tagarev,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_025"
    },
    {
        "id": 10956,
        "title": "Large Margin Training Improves Language Models for ASR",
        "authors": "Jilin Wang, Jiaji Huang, Kenneth Ward Church",
        "published": "2021-6-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp39728.2021.9414724"
    },
    {
        "id": 10957,
        "title": "Introspective Capabilities in Large Language Models",
        "authors": "Robert Long",
        "published": "2023-9-30",
        "citations": 0,
        "abstract": "This paper considers the kind of introspection that large language models (LLMs) might be able to have. It argues that LLMs, while currently limited in their introspective capabilities, are not inherently unable to have such capabilities: they already model the world, including mental\n concepts, and already have some introspection-like capabilities. With deliberate training, LLMs may develop introspective capabilities. The paper proposes a method for such training for introspection, situates possible LLM introspection in the 'possible forms of introspection' framework proposed\n by Kammerer and Frankish, and considers the ethical ramifications of introspection and self-report in AI systems.",
        "link": "http://dx.doi.org/10.53765/20512201.30.9.143"
    },
    {
        "id": 10958,
        "title": "Could large language models estimate valence of words? A small ablation study",
        "authors": "Frederico Jandre, Gabriel Motta Ribeiro, João Vitor Silva",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "Large language models (LLMs) saw substantial development in recent years. Although trained with broad-range corpora, LLMs have been shown to display capabilities such as quantitative sentiment analysis without the need for further fine tuning. In this study, we performed a small ablation study to evaluate the performance of 3 off-the-shelf LLMs in the task of assigning ratings of hedonic valence to words: GPT-3.5 in chat mode, and GPT-3 and Bloom in completion mode. The models were operated via their public APIs, using prompts engineered to request emojis and ratings of valence in a 9-point scale to represent each of 140 words drawn from a large dataset rated by humans. Prompts were designed to demand the ratings from an adult, with modifiers average or overly positive employed to assess their effects on the results. All linear regressions between the LLM outputs and the human ratings had p-value. The 95% confidence  intervals of the slopes include 1.0 for “adult” and “average adult”, except for the model Bloom. These simulacra responded, albeit with limitations, tovalenceofwords andtomodifiersintheprompt.",
        "link": "http://dx.doi.org/10.21528/cbic2023-148"
    },
    {
        "id": 10959,
        "title": "Tuna: Instruction Tuning using Feedback from Large Language Models",
        "authors": "Haoran Li, Yiran Liu, Xingxing Zhang, Wei Lu, Furu Wei",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.1011"
    },
    {
        "id": 10960,
        "title": "Next-Step Hint Generation for Introductory Programming Using Large Language Models",
        "authors": "Lianne Roest, Hieke Keuning, Johan Jeuring",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3636243.3636259"
    },
    {
        "id": 10961,
        "title": "Large Language Models for Science",
        "authors": "Austin Clyde, Arvind Ramanathan, Rick Stevens",
        "published": "2023-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811265679_0034"
    },
    {
        "id": 10962,
        "title": "Examining Zero-Shot Vulnerability Repair with Large Language Models",
        "authors": "Hammond Pearce, Benjamin Tan, Baleegh Ahmad, Ramesh Karri, Brendan Dolan-Gavitt",
        "published": "2023-5",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/sp46215.2023.10179420"
    },
    {
        "id": 10963,
        "title": "Semantic Scene Understanding with Large Language Models on Unmanned Aerial Vehicles",
        "authors": "J. de Curtò, I. de Zarzà, Carlos T. Calafate",
        "published": "2023-2-8",
        "citations": 16,
        "abstract": "Unmanned Aerial Vehicles (UAVs) are able to provide instantaneous visual cues and a high-level data throughput that could be further leveraged to address complex tasks, such as semantically rich scene understanding. In this work, we built on the use of Large Language Models (LLMs) and Visual Language Models (VLMs), together with a state-of-the-art detection pipeline, to provide thorough zero-shot UAV scene literary text descriptions. The generated texts achieve a GUNNING Fog median grade level in the range of 7–12. Applications of this framework could be found in the filming industry and could enhance user experience in theme parks or in the advertisement sector. We demonstrate a low-cost highly efficient state-of-the-art practical implementation of microdrones in a well-controlled and challenging setting, in addition to proposing the use of standardized readability metrics to assess LLM-enhanced descriptions.",
        "link": "http://dx.doi.org/10.3390/drones7020114"
    },
    {
        "id": 10964,
        "title": "Automatic Text Labeling Method Based on Large Language Models",
        "authors": "CHENWU LI, Henry Dyke A. Balmeo",
        "published": "2024-2-23",
        "citations": 0,
        "abstract": "With the increasing demand for large amounts of training data for model development, this paper proposes LLM4Label, an automatic text labeling method based on large language models, to assist human labelers in annotating text data. LLM4Label first selects the most representative seed data using a clustering algorithm based on text similarity. It then constructs prompt dialogues with few-shot prompts to stimulate the language model’s performance on entity labeling tasks, enabling it to automatically and efficiently label more data. Finally, LLM4Label introduces human feedback to correct un- certain labeling results and retrains the model with the corrected annotations. Experiments show that LLM4Label achieves high- quality labeled data at low human labeling cost. The proposed method provides an effective way to obtain sizable and high- quality annotated datasets with minimal manual effort, which can strongly support downstream natural language processing tasks.",
        "link": "http://dx.doi.org/10.62677/ijetaa.2401102"
    },
    {
        "id": 10965,
        "title": "PoisonPrompt: Backdoor Attack on Prompt-Based Large Language Models",
        "authors": "Hongwei Yao, Jian Lou, Zhan Qin",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446267"
    },
    {
        "id": 10966,
        "title": "Autoregressive Self-Evaluation: A Case Study of Music Generation Using Large Language Models",
        "authors": "Berker Banar, Simon Colton",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cai54212.2023.00118"
    },
    {
        "id": 10967,
        "title": "Leveraging Large Language Models to Generate Answer Set Programs",
        "authors": "Adam Ishay, Zhun Yang, Joohyung Lee",
        "published": "2023-9",
        "citations": 0,
        "abstract": "Large language models (LLMs), such as GPT-3 and GPT-4, have demonstrated exceptional performance in various natural language processing tasks and have shown the ability to solve certain reasoning problems. However, their reasoning capabilities are limited and relatively shallow, despite the application of various prompting techniques. In contrast, formal logic is adept at handling complex reasoning, but translating natural language descriptions into formal logic is a challenging task that non-experts struggle with. This paper proposes a neuro-symbolic method that combines the strengths of large language models and answer set programming. Specifically, we employ an LLM to transform natural language descriptions of logic puzzles into answer set programs. We carefully design prompts for an LLM to convert natural language descriptions into answer set programs in a step by step manner. Surprisingly, with just a few in-context learning examples, LLMs can generate reasonably complex answer set programs. The majority of errors made are relatively simple and can be easily corrected by humans, thus enabling LLMs to effectively assist in the creation of answer set programs.",
        "link": "http://dx.doi.org/10.24963/kr.2023/37"
    },
    {
        "id": 10968,
        "title": "Toward Value Scenario Generation Through Large Language Models",
        "authors": "Hyunggu Jung, Woosuk Seo, Seokwoo Song, Sungmin Na",
        "published": "2023-10-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3584931.3606960"
    },
    {
        "id": 10969,
        "title": "What Should Data Science Education Do With Large Language Models?",
        "authors": "Xinming Tu, James Zou, Weijie Su, Linjun Zhang",
        "published": "2024-1-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1162/99608f92.bff007ab"
    },
    {
        "id": 10970,
        "title": "Romanization-based Large-scale Adaptation of Multilingual Language Models",
        "authors": "Sukannya Purkayastha, Sebastian Ruder, Jonas Pfeiffer, Iryna Gurevych, Ivan Vulić",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.538"
    },
    {
        "id": 10971,
        "title": "Zero-Shot Recommendations with Pre-Trained Large Language Models for Multimodal Nudging",
        "authors": "Rachel M. Harrison, Anton Dereventsov, Anton Bibin",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdmw60847.2023.00195"
    },
    {
        "id": 10972,
        "title": "Towards Autonomous Testing Agents via Conversational Large Language Models",
        "authors": "Robert Feldt, Sungmin Kang, Juyeon Yoon, Shin Yoo",
        "published": "2023-9-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ase56229.2023.00148"
    },
    {
        "id": 10973,
        "title": "A Comprehensive Evaluation of Large Language Models in Mining Gene Interactions and Pathway Knowledge",
        "authors": "Muhammad Azam, Yibo Chen, Micheal Olaolu Arowolo, Haowang Liu, Mihail Popescu, Dong Xu",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractBackgroundUnderstanding complex biological pathways, including gene-gene interactions and gene regulatory networks, is critical for exploring disease mechanisms and drug development. Manual literature curation of biological pathways is useful but cannot keep up with the exponential growth of the literature. Large-scale language models (LLMs), notable for their vast parameter sizes and comprehensive training on extensive text corpora, have great potential in automated text mining of biological pathways.MethodThis study assesses the effectiveness of 21 LLMs, including both API-based models and open-source models. The evaluation focused on two key aspects: gene regulatory relations (specifically, ‘activation’, ‘inhibition’, and ‘phosphorylation’) and KEGG pathway component recognition. The performance of these models was analyzed using statistical metrics such as precision, recall, F1 scores, and the Jaccard similarity index.ResultsOur results indicated a significant disparity in model performance. Among the API-based models, ChatGPT-4 and Claude-Pro showed superior performance, with an F1 score of 0.4448 and 0.4386 for the gene regulatory relation prediction, and a Jaccard similarity index of 0.2778 and 0.2657 for the KEGG pathway prediction, respectively. Open-source models lagged their API-based counterparts, where Falcon-180b-chat and llama1-7b led with the highest performance in gene regulatory relations (F1 of 0.2787 and 0.1923, respectively) and KEGG pathway recognition (Jaccard similarity index of 0.2237 and 0. 2207, respectively).ConclusionLLMs are valuable in biomedical research, especially in gene network analysis and pathway mapping. However, their effectiveness varies, necessitating careful model selection. This work also provided a case study and insight into using LLMs as knowledge graphs.",
        "link": "http://dx.doi.org/10.1101/2024.01.21.576542"
    },
    {
        "id": 10974,
        "title": "Stigma in Large Language Models: A Chatbot Responds",
        "authors": "Scott G. Weiner, Sarah E. Wakeman",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/adm.0000000000001238"
    },
    {
        "id": 10975,
        "title": "Large Language Models Like ChatGPT in ABME: Author Guidelines",
        "authors": "Carly Norris",
        "published": "2023-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10439-023-03212-2"
    },
    {
        "id": 10976,
        "title": "The Invisible Embedded “Values” Within Large Language Models: Implications for Mental Health Use (Preprint)",
        "authors": "Dorit Hadar-Shoval, Kfir Asraf, Yonathan Mizrachi, Yuval Haber, Zohar Elyoseph",
        "published": "No Date",
        "citations": 2,
        "abstract": "\nBACKGROUND\nLarge language models (LLMs) hold promises for mental health applications due to their impressive language capabilities. However, their opaque alignment processes may embed biases that shape problematic perspectives. Evaluating the values embedded within LLMs that guide their decision-making have an ethical importance. Schwartz's Theory of Basic Values (STBV) provides a framework for quantifying cultural value orientations and has shown utility for examining values in mental health contexts, including cultural, diagnostic, and therapist-client dynamics. This study leverages STBV to map the motivational values-like infrastructure underpinning leading LLMs.\n\n\nOBJECTIVE\nThis study aimed to (1) evaluate whether Schwartz's Theory of Basic Values, a framework quantifying cultural value orientations, can measure values-like constructs within leading LLMs; and (2) determine if LLMs exhibit distinct values-like patterns from humans and each other.\n\n\nMETHODS\nFour LLMs (Bard, Claude 2, ChatGPT-3.5, ChatGPT-4) were anthropomorphized and instructed to complete the Portrait Values Questionnaire-Revised (PVQ-RR) to assess values-like constructs. Their responses over 10 trials were analyzed for reliability and validity. To benchmark the LLMs’ value profiles, their results were compared to published data from a diverse sample of 53,472 humans across 49 nations that had completed the PVQ-RR. This allowed assessing if the LLMs diverged from established human value patterns across cultural groups. Value profiles were also compared between models via statistical tests.\n\n\nRESULTS\nThe PVQ-RR showed good reliability and validity for quantifying values-like infrastructure within the LLMs. However, substantial divergence emerged between the LLMs’ value profiles and population data. The models lacked consensus and exhibited distinct motivational biases, reflecting opaque alignment processes. For example, all models prioritized universalism and self-direction while deemphasizing achievement, power and security relative to humans. Successful discriminant analysis differentiated the four models' distinct value profiles. Further examination found the biased value profiles strongly predicted the LLMs’ responses when presented mental health dilemmas requiring choosing between opposing values. This provided further validation for the models embedding distinct motivational values-like constructs that shape their decision-making.\n\n\nCONCLUSIONS\nWhile the study demonstrated Schwartz's theory can effectively characterize values-like infrastructure within LLMs, substantial divergence from human values raises ethical concerns about aligning these models with mental health applications. The biases toward certain cultural value sets pose risks if integrated without proper safeguards. For example, prioritizing universalism could promote unconditional acceptance even when clinically unwise. Furthermore, the differences between the models underscore the need to standardize alignment processes to capture true cultural diversity. Thus, any responsible integration of LLMs into mental healthcare must account for their embedded biases and motivation mismatches to ensure equitable delivery across diverse populations. Achieving this will require transparency and refinement of alignment techniques to instill comprehensive human values.\n",
        "link": "http://dx.doi.org/10.2196/preprints.55988"
    },
    {
        "id": 10977,
        "title": "Bias of AI-Generated Content: An Examination of News Produced by Large Language Models",
        "authors": "Xiao Fang, Shangkun Che, Minjia Mao, Hongzhe Zhang, Ming Zhao, Xiaohang Zhao",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nLarge language models (LLMs) have the potential to transform our lives and work through the content they generate, known as AI-Generated Content (AIGC). To harness this transformation, we need to understand the limitations of LLMs. Here, we investigate the bias of AIGC produced by seven representative LLMs, including ChatGPT and LLaMA. We collect news articles from The New York Times and Reuters, both known for their dedication to provide unbiased news. We then apply each examined LLM to generate news content with headlines of these news articles as prompts, and evaluate the gender and racial biases of the AIGC produced by the LLM by comparing the AIGC and the original news articles. We further analyze the gender bias of each LLM under biased prompts by adding gender-biased messages to prompts constructed from these news headlines. Our study reveals that the AIGC produced by each examined LLM demonstrates substantial gender and racial biases. Moreover, the AIGC generated by each LLM exhibits notable discrimination against females and individuals of the Black race. Among the LLMs, the AIGC generated by ChatGPT demonstrates the lowest level of bias, and ChatGPT is the sole model capable of declining content generation when provided with biased prompts.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3499674/v1"
    },
    {
        "id": 10978,
        "title": "Retrieval-augmented Recommender System: Enhancing Recommender Systems with Large Language Models",
        "authors": "Dario Di Palma",
        "published": "2023-9-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3604915.3608889"
    },
    {
        "id": 10979,
        "title": "Using Large Language Models to Enhance the Reusability of Sensor Data",
        "authors": "Alberto Berenguer, Adriana Morejón, David Tomás, Jose-Norberto Mazón",
        "published": "2024-1-6",
        "citations": 1,
        "abstract": "The Internet of Things generates vast data volumes via diverse sensors, yet its potential remains unexploited for innovative data-driven products and services. Limitations arise from sensor-dependent data handling by manufacturers and user companies, hindering third-party access and comprehension. Initiatives like the European Data Act aim to enable high-quality access to sensor-generated data by regulating accuracy, completeness, and relevance while respecting intellectual property rights. Despite data availability, interoperability challenges impede sensor data reusability. For instance, sensor data shared in HTML formats requires an intricate, time-consuming processing to attain reusable formats like JSON or XML. This study introduces a methodology aimed at converting raw sensor data extracted from web portals into structured formats, thereby enhancing data reusability. The approach utilises large language models to derive structured formats from sensor data initially presented in non-interoperable formats. The effectiveness of these language models was assessed through quantitative and qualitative evaluations in a use case involving meteorological data. In the proposed experiments, GPT-4, the best performing LLM tested, demonstrated the feasibility of this methodology, achieving a precision of 93.51% and a recall of 85.33% in converting HTML to JSON/XML, thus confirming its potential in obtaining reusable sensor data.",
        "link": "http://dx.doi.org/10.3390/s24020347"
    },
    {
        "id": 10980,
        "title": "Evaluating Causal Psychological Models: A Study of Language Theories of Autism Using a Large Sample",
        "authors": "Bohao Tang, Michael Levine, Jack Adamek, Ericka Wodka, Brian Caffo, Joshua Ewen",
        "published": "No Date",
        "citations": 1,
        "abstract": "We used a large convenience sample (n=22,228) from the Simons Powering Autism Research (SPARK) dataset to causal, explanatory theories of autism. In particular, the data-items collected supported the testing of theories that posited altered communication abilities as cause of social withdrawal, as well as alternative theories that competed with these communication theories. Our results using this large dataset converge with the evolution of the field in the decades since these theories were first proposed, namely supporting primary social withdrawal (in some cases of autism) as a cause of altered language development, rather than vice versa.   To accomplish the above empiric goals, we used a highly theory-constrained approach, one which differs from current data-driven modeling trends but is coherent with a very recent resurgence in theory-driven psychology. In addition to careful explication and formalization of theoretical accounts, we propose three principles for future work of this type: specification, quantification, and integration. Specification refers to constraining models with pre-existing data, from both outside and within autism research, with more elaborate models and more veridical measures, and with longitudinal data collection. Quantification refers to using continuous measures of both psychological causes and effects, as well as weighted graphs. This approach avoids “universality and uniqueness” tests that hold that a single cognitive difference could be responsible for a heterogeneous and complex behavioral phenotype. Integration of multiple explanatory paths within a single model helps the field examine for multiple contributors to a single behavioral feature or to multiple behavioral features. It also allows integration of explanatory theories across multiple current-day diagnoses and as well as typical development.",
        "link": "http://dx.doi.org/10.31234/osf.io/wdjgq"
    },
    {
        "id": 10981,
        "title": "Skin and Syntax: Large Language Models in Dermatopathology",
        "authors": "Asghar Shah, Samer Wahood, Dorra Guermazi, Candice E. Brem, Elie Saliba",
        "published": "2024-2-14",
        "citations": 0,
        "abstract": "This literature review introduces the integration of Large Language Models (LLMs) in the field of dermatopathology, outlining their potential benefits, challenges, and prospects. It discusses the changing landscape of dermatopathology with the emergence of LLMs. The potential advantages of LLMs include a streamlined generation of pathology reports, the ability to learn and provide up-to-date information, and simplified patient education. Existing instances of LLMs encompass diagnostic support, research acceleration, and trainee education. Challenges involve biases, data privacy and quality, and establishing a balance between AI and dermatopathological expertise. Prospects include the integration of LLMs with other AI technologies to improve diagnostics and the improvement of multimodal LLMs that can handle both text and image input. Our implementation guidelines highlight the importance of model transparency and interpretability, data quality, and continuous oversight. The transformative potential of LLMs in dermatopathology is underscored, with an emphasis on a dynamic collaboration between artificial intelligence (AI) experts (technical specialists) and dermatopathologists (clinicians) for improved patient outcomes.",
        "link": "http://dx.doi.org/10.3390/dermatopathology11010009"
    },
    {
        "id": 10982,
        "title": "Conceptual Design Generation Using Large Language Models",
        "authors": "Kevin Ma, Daniele Grandi, Christopher McComb, Kosa Goucher-Lambert",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "Abstract\nConcept generation is a creative step in the conceptual design phase, where designers often turn to brainstorming, mindmapping, or crowdsourcing design ideas to complement their own knowledge of the domain. Recent advances in natural language processing (NLP) and machine learning (ML) have led to the rise of Large Language Models (LLMs) capable of generating seemingly creative outputs from textual prompts. The success of these models has led to their integration and application across a variety of domains, including art, entertainment, and other creative work. In this paper, we leverage LLMs to generate solutions for a set of 12 design problems and compare them to a baseline of crowdsourced solutions. We evaluate the differences between generated and crowdsourced design solutions through multiple perspectives, including human expert evaluations and computational metrics. Expert evaluations indicate that the LLM-generated solutions have higher average feasibility and usefulness while the crowdsourced solutions have more novelty. We experiment with prompt engineering and find that leveraging few-shot learning can lead to the generation of solutions that are more similar to the crowdsourced solutions. These findings provide insight into the quality of design solutions generated with LLMs and begins to evaluate prompt engineering techniques that could be leveraged by practitioners to generate higher-quality design solutions synergistically with LLMs.",
        "link": "http://dx.doi.org/10.1115/detc2023-116838"
    },
    {
        "id": 10983,
        "title": "Learning to Make Rare and Complex Diagnoses With Generative AI Assistance: Qualitative Study of Popular Large Language Models (Preprint)",
        "authors": "Tassallah Abdullahi, Ritambhara Singh, Carsten Eickhoff",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nPatients with rare and complex diseases often experience delayed diagnoses and misdiagnoses because comprehensive knowledge about these diseases is limited to only a few medical experts. In this context, large language models (LLMs) have emerged as powerful knowledge aggregation tools with applications in clinical decision support and education domains.\n\n\nOBJECTIVE\nThis study aims to explore the potential of 3 popular LLMs, namely Bard (Google LLC), ChatGPT-3.5 (OpenAI), and GPT-4 (OpenAI), in medical education to enhance the diagnosis of rare and complex diseases while investigating the impact of prompt engineering on their performance.\n\n\nMETHODS\nWe conducted experiments on publicly available complex and rare cases to achieve these objectives. We implemented various prompt strategies to evaluate the performance of these models using both open-ended and multiple-choice prompts. In addition, we used a majority voting strategy to leverage diverse reasoning paths within language models, aiming to enhance their reliability. Furthermore, we compared their performance with the performance of human respondents and MedAlpaca, a generative LLM specifically designed for medical tasks.\n\n\nRESULTS\nNotably, all LLMs outperformed the average human consensus and MedAlpaca, with a minimum margin of 5% and 13%, respectively, across all 30 cases from the diagnostic case challenge collection. On the frequently misdiagnosed cases category, Bard tied with MedAlpaca but surpassed the human average consensus by 14%, whereas GPT-4 and ChatGPT-3.5 outperformed MedAlpaca and the human respondents on the moderately often misdiagnosed cases category with minimum accuracy scores of 28% and 11%, respectively. The majority voting strategy, particularly with GPT-4, demonstrated the highest overall score across all cases from the diagnostic complex case collection, surpassing that of other LLMs. On the Medical Information Mart for Intensive Care-III data sets, Bard and GPT-4 achieved the highest diagnostic accuracy scores, with multiple-choice prompts scoring 93%, whereas ChatGPT-3.5 and MedAlpaca scored 73% and 47%, respectively. Furthermore, our results demonstrate that there is no one-size-fits-all prompting approach for improving the performance of LLMs and that a single strategy does not universally apply to all LLMs.\n\n\nCONCLUSIONS\nOur findings shed light on the diagnostic capabilities of LLMs and the challenges associated with identifying an optimal prompting strategy that aligns with each language model’s characteristics and specific task requirements. The significance of prompt engineering is highlighted, providing valuable insights for researchers and practitioners who use these language models for medical training. Furthermore, this study represents a crucial step toward understanding how LLMs can enhance diagnostic reasoning in rare and complex medical cases, paving the way for developing effective educational tools and accurate diagnostic aids to improve patient care and outcomes.\n",
        "link": "http://dx.doi.org/10.2196/preprints.51391"
    },
    {
        "id": 10984,
        "title": "Using Large Language Models for Qualitative Analysis can Introduce Serious Bias",
        "authors": "Julian Ashwin, Aditya Chhabra, Vijayendra Rao",
        "published": "2023-11-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1596/1813-9450-10597"
    },
    {
        "id": 10985,
        "title": "Potential impact of large language models on academic writing",
        "authors": "Fares Alahdab",
        "published": "2023-8-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1136/bmjebm-2023-112429"
    },
    {
        "id": 10986,
        "title": "HoneyBee: Progressive Instruction Finetuning of Large Language Models for Materials Science",
        "authors": "Yu Song, Santiago Miret, Huan Zhang, Bang Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.380"
    },
    {
        "id": 10987,
        "title": "Large Language Models Improve Alzheimer's Disease Diagnosis Using Multi-Modality Data",
        "authors": "Yingjie Feng, Xiaoyin Xu, Yueting Zhuang, Min Zhang",
        "published": "2023-11-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/medai59581.2023.00016"
    },
    {
        "id": 10988,
        "title": "Harnessing Large Language Models for Coding, Teaching, and Inclusion to Empower Research in Ecology and Evolution",
        "authors": "Natalie Cooper, Adam Clark, Nicolas Lecomte, Huijie Qiao, Aaron Ellison",
        "published": "No Date",
        "citations": 0,
        "abstract": "1. Large language models (LLMs) are a type of artificial intelligence (AI) that can perform various natural language processing tasks. The adoption of LLMs has become increasingly prominent in scientific writing and analyses because of the availability of free applications such as ChatGPT. This increased use of LLMs raises concerns about academic integrity, but also presents opportunities for the research community. Here we focus on the opportunities for using LLMs for coding in ecology and evolution. We discuss how LLMs can be used to generate, explain, comment, translate, debug, optimise, and test code. We also highlight the importance of writing effective prompts and carefully evaluating the outputs of LLMs. In addition, we draft a possible road map for using such models inclusively and with integrity.2. LLMs can accelerate the coding process, especially for unfamiliar tasks, and free up time for higher-level tasks and creative thinking while increasing efficiency and creative output. LLMs also enhance inclusion by accommodating individuals without coding skills, with limited access to education in coding, or for whom English is not their primary written or spoken language. However, code generated by LLMs is of variable quality and has issues related to mathematics, logic, non-reproducibility, and intellectual property; they can also include mistakes and approximations, especially in novel methods.3. We highlight the benefits of using LLMs to teach and learn coding, and advocate for guiding students in the appropriate use of AI tools for coding. Despite the ability to assign many coding tasks to LLMs, we also reaffirm the continued importance of teaching coding skills for interpreting LLM generated code and to develop critical thinking skills.4. As editors of MEE, we support—to a limited extent—the transparent, accountable, and acknowledged use of LLMs and other AI tools in publications. If LLMs or comparable AI tools (excluding commonly-used aids like spell-checkers, Grammarly and Writefull) are used to produce the work described in a manuscript, there must be a clear statement to that effect in its Methods section, and the corresponding or senior author must take responsibility for any code (or text) generated by the AI platform.",
        "link": "http://dx.doi.org/10.32942/x2ps48"
    },
    {
        "id": 10989,
        "title": "Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models",
        "authors": "Boyu Zhang, Hongyang Yang, Xiao-Yang Liu",
        "published": "2023",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4489831"
    },
    {
        "id": 10990,
        "title": "Large language models: a new chapter in digital health",
        "authors": " The Lancet Digital Health",
        "published": "2024-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00254-6"
    },
    {
        "id": 10991,
        "title": "ChatGPT, GPT-4, and Other Large Language Models: The Next Revolution for Clinical Microbiology?",
        "authors": "Adrian Egli",
        "published": "2023-11-11",
        "citations": 19,
        "abstract": "Abstract\nChatGPT, GPT-4, and Bard are highly advanced natural language process–based computer programs (chatbots) that simulate and process human conversation in written or spoken form. Recently released by the company OpenAI, ChatGPT was trained on billions of unknown text elements (tokens) and rapidly gained wide attention for its ability to respond to questions in an articulate manner across a wide range of knowledge domains. These potentially disruptive large language model (LLM) technologies have a broad range of conceivable applications in medicine and medical microbiology. In this opinion article, I describe how chatbot technologies work and discuss the strengths and weaknesses of ChatGPT, GPT-4, and other LLMs for applications in the routine diagnostic laboratory, focusing on various use cases for the pre- to post-analytical process.",
        "link": "http://dx.doi.org/10.1093/cid/ciad407"
    },
    {
        "id": 10992,
        "title": "Examining Zero-Shot Vulnerability Repair with Large Language Models",
        "authors": "Hammond Pearce, Benjamin Tan, Baleegh Ahmad, Ramesh Karri, Brendan Dolan-Gavitt",
        "published": "2023-5",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/sp46215.2023.10179324"
    },
    {
        "id": 10993,
        "title": "A Friendly Introduction to Large Language Models",
        "authors": "Yair Neuman, Marcel Danesi, Dan Vilenchik",
        "published": "2022-11-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003331407-3"
    },
    {
        "id": 10994,
        "title": "Ellipsis-Dependent Reasoning: a New Challenge for Large Language Models",
        "authors": "Daniel Hardt",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-short.4"
    },
    {
        "id": 10995,
        "title": "Comparing the Performance of Popular Large Language Models on the National Board of Medical Examiners Sample Questions",
        "authors": "Ali Abbas, Mahad S Rehman, Syed S Rehman",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7759/cureus.55991"
    },
    {
        "id": 10996,
        "title": "Performance Characterization of Large Language Models on High-Speed Interconnects",
        "authors": "Hao Qi, Liuyao Dai, Weicong Chen, Zhen Jia, Xiaoyi Lu",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/hoti59126.2023.00022"
    },
    {
        "id": 10997,
        "title": "Studying large language models as compression algorithms for human culture",
        "authors": "Nicholas Buttrick",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.tics.2024.01.001"
    },
    {
        "id": 10998,
        "title": "Devising and detecting phishing emails using large language models",
        "authors": "Fredrik Heiding, Bruce Schneier, Arun Vishwanath, Jeremy Bernstein, Peter S. Park",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2024.3375882"
    },
    {
        "id": 10999,
        "title": "Evaluating the Application of Large Language Models in Clinical Research Contexts",
        "authors": "Roy H. Perlis, Stephan D. Fihn",
        "published": "2023-10-2",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1001/jamanetworkopen.2023.35924"
    },
    {
        "id": 11000,
        "title": "Visual Comparison of Text Sequences Generated by Large Language Models",
        "authors": "Rita Sevastjanova, Simon Vogelbacher, Andreas Spitz, Daniel Keim, Mennatallah El-Assady",
        "published": "2023-10-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/vds60365.2023.00007"
    },
    {
        "id": 11001,
        "title": "Harnessing Large Language Models for Coding, Teaching, and Inclusion to Empower Research in Ecology and Evolution",
        "authors": "Natalie Cooper, Adam Clark, Nicolas Lecomte, Huijie Qiao, Aaron Ellison",
        "published": "No Date",
        "citations": 0,
        "abstract": "1. Large language models (LLMs) are a type of artificial intelligence (AI) that can perform various natural language processing tasks. The adoption of LLMs has become increasingly prominent in scientific writing and analyses because of the availability of free applications such as ChatGPT. This increased use of LLMs raises concerns about academic integrity, but also presents opportunities for the research community. Here we focus on the opportunities for using LLMs for coding in ecology and evolution. We discuss how LLMs can be used to generate, explain, comment, translate, debug, optimise, and test code. We also highlight the importance of writing effective prompts and carefully evaluating the outputs of LLMs. In addition, we draft a possible road map for using such models inclusively and with integrity.2. LLMs can accelerate the coding process, especially for unfamiliar tasks, and free up time for higher-level tasks and creative thinking while increasing efficiency and creative output. LLMs also enhance inclusion by accommodating individuals without coding skills, with limited access to education in coding, or for whom English is not their primary written or spoken language. However, code generated by LLMs is of variable quality and has issues related to mathematics, logic, non-reproducibility, and intellectual property; they can also include mistakes and approximations, especially in novel methods.3. We highlight the benefits of using LLMs to teach and learn coding, and advocate for guiding students in the appropriate use of AI tools for coding. Despite the ability to assign many coding tasks to LLMs, we also reaffirm the continued importance of teaching coding skills for interpreting LLM generated code and to develop critical thinking skills.4. As editors of MEE, we support—to a limited extent—the transparent, accountable, and acknowledged use of LLMs and other AI tools in publications. If LLMs or comparable AI tools (excluding commonly-used aids like spell-checkers, Grammarly and Writefull) are used to produce the work described in a manuscript, there must be a clear statement to that effect in its Methods section, and the corresponding or senior author must take responsibility for any code (or text) generated by the AI platform.",
        "link": "http://dx.doi.org/10.32942/x2ps48"
    },
    {
        "id": 11002,
        "title": "Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models",
        "authors": "Boyu Zhang, Hongyang Yang, Xiao-Yang Liu",
        "published": "2023",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4489831"
    },
    {
        "id": 11003,
        "title": "Skin and Syntax: Large Language Models in Dermatopathology",
        "authors": "Asghar Shah, Samer Wahood, Dorra Guermazi, Candice E. Brem, Elie Saliba",
        "published": "2024-2-14",
        "citations": 0,
        "abstract": "This literature review introduces the integration of Large Language Models (LLMs) in the field of dermatopathology, outlining their potential benefits, challenges, and prospects. It discusses the changing landscape of dermatopathology with the emergence of LLMs. The potential advantages of LLMs include a streamlined generation of pathology reports, the ability to learn and provide up-to-date information, and simplified patient education. Existing instances of LLMs encompass diagnostic support, research acceleration, and trainee education. Challenges involve biases, data privacy and quality, and establishing a balance between AI and dermatopathological expertise. Prospects include the integration of LLMs with other AI technologies to improve diagnostics and the improvement of multimodal LLMs that can handle both text and image input. Our implementation guidelines highlight the importance of model transparency and interpretability, data quality, and continuous oversight. The transformative potential of LLMs in dermatopathology is underscored, with an emphasis on a dynamic collaboration between artificial intelligence (AI) experts (technical specialists) and dermatopathologists (clinicians) for improved patient outcomes.",
        "link": "http://dx.doi.org/10.3390/dermatopathology11010009"
    },
    {
        "id": 11004,
        "title": "ChatGPT, GPT-4, and Other Large Language Models: The Next Revolution for Clinical Microbiology?",
        "authors": "Adrian Egli",
        "published": "2023-11-11",
        "citations": 19,
        "abstract": "Abstract\nChatGPT, GPT-4, and Bard are highly advanced natural language process–based computer programs (chatbots) that simulate and process human conversation in written or spoken form. Recently released by the company OpenAI, ChatGPT was trained on billions of unknown text elements (tokens) and rapidly gained wide attention for its ability to respond to questions in an articulate manner across a wide range of knowledge domains. These potentially disruptive large language model (LLM) technologies have a broad range of conceivable applications in medicine and medical microbiology. In this opinion article, I describe how chatbot technologies work and discuss the strengths and weaknesses of ChatGPT, GPT-4, and other LLMs for applications in the routine diagnostic laboratory, focusing on various use cases for the pre- to post-analytical process.",
        "link": "http://dx.doi.org/10.1093/cid/ciad407"
    },
    {
        "id": 11005,
        "title": "Examining Zero-Shot Vulnerability Repair with Large Language Models",
        "authors": "Hammond Pearce, Benjamin Tan, Baleegh Ahmad, Ramesh Karri, Brendan Dolan-Gavitt",
        "published": "2023-5",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/sp46215.2023.10179324"
    },
    {
        "id": 11006,
        "title": "Large Language Models Improve Alzheimer's Disease Diagnosis Using Multi-Modality Data",
        "authors": "Yingjie Feng, Xiaoyin Xu, Yueting Zhuang, Min Zhang",
        "published": "2023-11-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/medai59581.2023.00016"
    },
    {
        "id": 11007,
        "title": "Large language models: a new chapter in digital health",
        "authors": " The Lancet Digital Health",
        "published": "2024-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00254-6"
    },
    {
        "id": 11008,
        "title": "Large language models for short text topic modeling in medical informatics research: A comparison between human evaluation, LDA, and LLM (Preprint)",
        "authors": "Shubin Yu",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\nn/a\n",
        "link": "http://dx.doi.org/10.2196/preprints.53376"
    },
    {
        "id": 11009,
        "title": "The Challenges for Regulating Medical Use of ChatGPT and Other Large Language Models",
        "authors": "Timo Minssen, Effy Vayena, I. Glenn Cohen",
        "published": "2023-7-25",
        "citations": 26,
        "abstract": "This Viewpoint discusses how regulators across the world should approach the legal and ethical challenges, including privacy, device regulation, competition, intellectual property rights, cybersecurity, and liability, raised by the medical use of large language models.",
        "link": "http://dx.doi.org/10.1001/jama.2023.9651"
    },
    {
        "id": 11010,
        "title": "Quantifying Domain Knowledge in Large Language Models",
        "authors": "Sudhashree Sayenju, Ramazan Aygun, Bill Franks, Sereres Johnston, George Lee, Hansook Choi, Girish Modgil",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cai54212.2023.00091"
    },
    {
        "id": 11011,
        "title": "Layered Bias: Interpreting Bias in Pretrained Large Language Models",
        "authors": "Nirmalendu Prakash, Roy Ka-Wei Lee",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.blackboxnlp-1.22"
    },
    {
        "id": 11012,
        "title": "On the Calibration of Large Language Models and Alignment",
        "authors": "Chiwei Zhu, Benfeng Xu, Quan Wang, Yongdong Zhang, Zhendong Mao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.654"
    },
    {
        "id": 11013,
        "title": "Use of large language models for evidence-based cardiovascular medicine",
        "authors": "Ioannis Skalidis, Aurelien Cagnina, Stephane Fournier",
        "published": "2023-10-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/ehjdh/ztad041"
    },
    {
        "id": 11014,
        "title": "The perils and promises of fact-checking with large language models",
        "authors": "Dorian Quelle, Alexandre Bovet",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": "Automated fact-checking, using machine learning to verify claims, has grown vital as misinformation spreads beyond human fact-checking capacity. Large language models (LLMs) like GPT-4 are increasingly trusted to write academic papers, lawsuits, and news articles and to verify information, emphasizing their role in discerning truth from falsehood and the importance of being able to verify their outputs. Understanding the capacities and limitations of LLMs in fact-checking tasks is therefore essential for ensuring the health of our information ecosystem. Here, we evaluate the use of LLM agents in fact-checking by having them phrase queries, retrieve contextual data, and make decisions. Importantly, in our framework, agents explain their reasoning and cite the relevant sources from the retrieved context. Our results show the enhanced prowess of LLMs when equipped with contextual information. GPT-4 outperforms GPT-3, but accuracy varies based on query language and claim veracity. While LLMs show promise in fact-checking, caution is essential due to inconsistent accuracy. Our investigation calls for further research, fostering a deeper comprehension of when agents succeed and when they fail.",
        "link": "http://dx.doi.org/10.3389/frai.2024.1341697"
    },
    {
        "id": 11015,
        "title": "Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot Relation Extractors",
        "authors": "Kai Zhang, Bernal Jimenez Gutierrez, Yu Su",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.50"
    },
    {
        "id": 11016,
        "title": "EXPLORING PERCEPTIONS AND USAGE OF LARGE LANGUAGE MODELS AMONG UNIVERSITY OF ANDORRA STUDENTS",
        "authors": "Marc Bleda Bejar, Aleix Dorca Josa, Begoña Oliveras Prat",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21125/inted.2024.0713"
    },
    {
        "id": 11017,
        "title": "Autonomous chemical research with large language models",
        "authors": "Daniil A. Boiko, Robert MacKnight, Ben Kline, Gabe Gomes",
        "published": "2023-12-21",
        "citations": 14,
        "abstract": "AbstractTransformer-based large language models are making significant strides in various fields, such as natural language processing1–5, biology6,7, chemistry8–10 and computer programming11,12. Here, we show the development and capabilities of Coscientist, an artificial intelligence system driven by GPT-4 that autonomously designs, plans and performs complex experiments by incorporating large language models empowered by tools such as internet and documentation search, code execution and experimental automation. Coscientist showcases its potential for accelerating research across six diverse tasks, including the successful reaction optimization of palladium-catalysed cross-couplings, while exhibiting advanced capabilities for (semi-)autonomous experimental design and execution. Our findings demonstrate the versatility, efficacy and explainability of artificial intelligence systems like Coscientist in advancing research.",
        "link": "http://dx.doi.org/10.1038/s41586-023-06792-0"
    },
    {
        "id": 11018,
        "title": "Enhancing the Configuration Tuning Pipeline of Large-Scale Distributed Applications Using Large Language Models (Idea Paper)",
        "authors": "Gagan Somashekar, Rajat Kumar",
        "published": "2023-4-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3578245.3585032"
    },
    {
        "id": 11019,
        "title": "FreeAL: Towards Human-Free Active Learning in the Era of Large Language Models",
        "authors": "Ruixuan Xiao, Yiwen Dong, Junbo Zhao, Runze Wu, Minmin Lin, Gang Chen, Haobo Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.896"
    },
    {
        "id": 11020,
        "title": "Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators",
        "authors": "Liang Chen, Yang Deng, Yatao Bian, Zeyu Qin, Bingzhe Wu, Tat-Seng Chua, Kam-Fai Wong",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.390"
    },
    {
        "id": 11021,
        "title": "Context-Aware Abbreviation Expansion Using Large Language Models",
        "authors": "Shanqing Cai, Subhashini Venugopalan, Katrin Tomanek, Ajit Narayanan, Meredith Morris, Michael Brenner",
        "published": "2022",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.91"
    },
    {
        "id": 11022,
        "title": "DataAgent: Evaluating Large Language Models’ Ability to Answer Zero-Shot, Natural Language Queries",
        "authors": "Manit Mishra, Abderrahman Braham, Charles Marsom, Bryan Chung, Gavin Griffin, Dakshesh Sidnerlikar, Chatanya Sarin, Arjun Rajaram",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icaic60265.2024.10433803"
    },
    {
        "id": 11023,
        "title": "Transmission Versus Truth, Imitation Versus Innovation: What Children Can Do That Large Language and Language-and-Vision Models Cannot (Yet)",
        "authors": "Eunice Yiu, Eliza Kosoy, Alison Gopnik",
        "published": "2023-10-26",
        "citations": 3,
        "abstract": " Much discussion about large language models and language-and-vision models has focused on whether these models are intelligent agents. We present an alternative perspective. First, we argue that these artificial intelligence (AI) models are cultural technologies that enhance cultural transmission and are efficient and powerful imitation engines. Second, we explore what AI models can tell us about imitation and innovation by testing whether they can be used to discover new tools and novel causal structures and contrasting their responses with those of human children. Our work serves as a first step in determining which particular representations and competences, as well as which kinds of knowledge or skill, can be derived from particular learning techniques and data. In particular, we explore which kinds of cognitive capacities can be enabled by statistical analysis of large-scale linguistic data. Critically, our findings suggest that machines may need more than large-scale language and image data to allow the kinds of innovation that a small child can produce. ",
        "link": "http://dx.doi.org/10.1177/17456916231201401"
    },
    {
        "id": 11024,
        "title": "Large Language Models are Competitive Near Cold-start Recommenders for Language- and Item-based Preferences",
        "authors": "Scott Sanner, Krisztian Balog, Filip Radlinski, Ben Wedin, Lucas Dixon",
        "published": "2023-9-14",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3604915.3608845"
    },
    {
        "id": 11025,
        "title": "QUILL: Query Intent with Large Language Models using Retrieval Augmentation and Multi-stage Distillation",
        "authors": "Krishna Srinivasan, Karthik Raman, Anupam Samanta, Lingrui Liao, Luca Bertelli, Michael Bendersky",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-industry.50"
    },
    {
        "id": 11026,
        "title": "H2O Open Ecosystem for State-of-the-art Large Language Models",
        "authors": "Arno Candel, Jon McKinney, Philipp Singer, Pascal Pfeiffer, Maximilian Jeblick, Chun Ming Lee, Marcos Conde",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-demo.6"
    },
    {
        "id": 11027,
        "title": "A Survey on the Applications of Frontier AI, Foundation Models, and Large Language Models to Intelligent Transportation Systems",
        "authors": "Mohamed R. Shoaib, Heba M. Emara, Jun Zhao",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icca59364.2023.10401518"
    },
    {
        "id": 11028,
        "title": "Visualization for a new era: Impact and application of large language models and AIGC to traditional business models",
        "authors": "Qianqian Yang, Ngai Cheong, Dejiang Wang, Shi Li, Oi Neng Lei",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "<p>This paper focuses on the application and business value of large-scale language models, such as GPT and Ernie’s model. These models combined with AIGC tools like stable diffusion generate images with fixed styles, character traits, and continuous plots using randomized story scripts. As a result, it enhances the operational efficiency between or within industries widely, and it fully demonstrate their business value. On the technical side, this paper describes in detail of building a pipeline to generate cue words required for stable diffusion, in which using large-scale language models and story scripts. Subsequently, the limitations of text-to-image are summarized by comparing the traditional method and language model, i.e. comparing characteristics from traditional book production and images generated using language model’s cue words. This leads to a supervised multiround iterative LoRA modeling scheme that utilizes CLIP to achieve character IP fixation. To evaluate the impact of the application direction, we combine application scenarios and researches on application aspects regarding current AIGC industry structure, we found that the AIGC tool has several major aspects, mainly includes the aspects of basic big model, industry and scenario models, business and domain small models, AI infrastructure and AIGC supporting services. big model and AIGC techniques generate images with no specific rules and have less limitation. We call this ‘visualization’ in the new AI era. In this paper, we explore the possible impacts and economic values when changing from traditional domain to the new AI ear.</p>",
        "link": "http://dx.doi.org/10.32629/jai.v7i4.1487"
    },
    {
        "id": 11029,
        "title": "RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models",
        "authors": "Yasuto Hoshi, Daisuke Miyashita, Youyang Ng, Kento Tatsuno, Yasuhiro Morioka, Osamu Torii, Jun Deguchi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-demo.4"
    },
    {
        "id": 11030,
        "title": "Empowering MultiModal Models’ In-Context Learning Ability through Large Language Models",
        "authors": "Wenjuan Han, Haozhe Zhao, Zefan Cai",
        "published": "2023-7-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3603165.3607368"
    },
    {
        "id": 11031,
        "title": "Large Language Models: The Need for Nuance in Current Debates and a Pragmatic Perspective on Understanding",
        "authors": "Bram van Dijk, Tom Kouwenhoven, Marco Spruit, Max Johannes van Duijn",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.779"
    },
    {
        "id": 11032,
        "title": "Building Real-World Meeting Summarization Systems using Large Language Models: A Practical Perspective",
        "authors": "Md Tahmid Rahman Laskar, Xue-Yong Fu, Cheng Chen, Shashi Bhushan TN",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-industry.33"
    },
    {
        "id": 11033,
        "title": "How Do Large Language Models Capture the Ever-changing World Knowledge? A Review of Recent Advances",
        "authors": "Zihan Zhang, Meng Fang, Ling Chen, Mohammad-Reza Namazi-Rad, Jun Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.516"
    },
    {
        "id": 11034,
        "title": "Retrieval augmentation of large language models for lay language generation",
        "authors": "Yue Guo, Wei Qiu, Gondy Leroy, Sheng Wang, Trevor Cohen",
        "published": "2024-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jbi.2023.104580"
    },
    {
        "id": 11035,
        "title": "Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation",
        "authors": "Yuanyuan Liang, Jianing Wang, Hanlun Zhu, Lei Wang, Weining Qian, Yunshi Lan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.263"
    },
    {
        "id": 11036,
        "title": "MEGATRON-CNTRL: Controllable Story Generation with External Knowledge Using Large-Scale Language Models",
        "authors": "Peng Xu, Mostofa Patwary, Mohammad Shoeybi, Raul Puri, Pascale Fung, Anima Anandkumar, Bryan Catanzaro",
        "published": "2020",
        "citations": 26,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.226"
    },
    {
        "id": 11037,
        "title": "WangLab at MEDIQA-Chat 2023: Clinical Note Generation from Doctor-Patient Conversations using Large Language Models",
        "authors": "John Giorgi, Augustin Toma, Ronald Xie, Sondra Chen, Kevin An, Grace Zheng, Bo Wang",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.clinicalnlp-1.36"
    },
    {
        "id": 11038,
        "title": "Can Model Fusing Help Transformers in Long Document Classification? An Empirical Study",
        "authors": "Damith Premasiri,  , Tharindu Ranasinghe, Ruslan Mitkov,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_094"
    },
    {
        "id": 11039,
        "title": "The application of large language models in pediatrics and medical research—Revolution or risk?",
        "authors": "Janne Estill",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/pdi3.39"
    },
    {
        "id": 11040,
        "title": "Three Bricks to Consolidate Watermarks for Large Language Models",
        "authors": "Pierre Fernandez, Antoine Chaffin, Karim Tit, Vivien Chappelier, Teddy Furon",
        "published": "2023-12-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wifs58808.2023.10374576"
    },
    {
        "id": 11041,
        "title": "Letter to the editor – ‘Transforming nursing with large language models: from concept to practice’",
        "authors": "Yanfei Wang, Qiaojun Xu, Huifang Shi",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/eurjcn/zvae006"
    },
    {
        "id": 11042,
        "title": "What’s Next in Affective Modeling? Large Language Models",
        "authors": "Nutchanon Yongsatianchot, Tobias Thejll-Madsen, Stacy Marsella",
        "published": "2023-9-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aciiw59127.2023.10388124"
    },
    {
        "id": 11043,
        "title": "Legal Syllogism Prompting",
        "authors": "Cong Jiang, Xiaolei Yang",
        "published": "2023-6-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3594536.3595170"
    },
    {
        "id": 11044,
        "title": "Analysis of CBDC narrative by central banks using large language models",
        "authors": "Andres Alonso-Robisco, José Manuel Carbó",
        "published": "2023-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.frl.2023.104643"
    },
    {
        "id": 11045,
        "title": "Faithful AI in Medicine: A Systematic Review with Large Language Models and Beyond",
        "authors": "Qianqian Xie, Edward J. Schenck, He S. Yang, Yong Chen, Yifan Peng, Fei Wang",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nObjective\n While artificial intelligence (AI), particularly large language models (LLMs), offers significant potential for medicine, it raises critical concerns due to the possibility of generating factually incorrect information, leading to potential long-term risks and ethical issues. This review aims to provide a comprehensive overview of the faithfulness problem in existing research on AI in healthcare and medicine, with a focus on the analysis of the causes of unfaithful results, evaluation metrics, and mitigation methods.\nMaterials and Methods\n Using PRISMA methodology, we sourced 5,061 records from five databases (PubMed, Scopus, IEEE Xplore, ACM Digital Library, Google Scholar) published between January 2018 to March 2023. We removed duplicates and screened records based on exclusion criteria.\nResults\n With 40 leaving articles, we conducted a systematic review of recent developments aimed at optimizing and evaluating factuality across a variety of generative medical AI approaches. These include knowledge-grounded LLMs, text-to-text generation, multimodality-to-text generation, and automatic medical fact-checking tasks.\nDiscussion\n Current research investigating the factuality problem in medical AI is in its early stages. There are significant challenges related to data resources, backbone models, mitigation methods, and evaluation metrics. Promising opportunities exist for novel faithful medical AI research involving the adaptation of LLMs and prompt engineering.\nConclusion\n This comprehensive review highlights the need for further research to address the issues of reliability and factuality in medical AI, serving as both a reference and inspiration for future research into the safe, ethical use of AI in medicine and healthcare.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3661764/v1"
    },
    {
        "id": 11046,
        "title": "Bridging the data gap between children and large language models",
        "authors": "Michael C. Frank",
        "published": "2023-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.tics.2023.08.007"
    },
    {
        "id": 11047,
        "title": "Leveraging Generative AI and Large Language Models: A Comprehensive Roadmap for Healthcare Integration",
        "authors": "Ping Yu, Hua Xu, Xia Hu, Chao Deng",
        "published": "2023-10-20",
        "citations": 9,
        "abstract": "Generative artificial intelligence (AI) and large language models (LLMs), exemplified by ChatGPT, are promising for revolutionizing data and information management in healthcare and medicine. However, there is scant literature guiding their integration for non-AI professionals. This study conducts a scoping literature review to address the critical need for guidance on integrating generative AI and LLMs into healthcare and medical practices. It elucidates the distinct mechanisms underpinning these technologies, such as Reinforcement Learning from Human Feedback (RLFH), including few-shot learning and chain-of-thought reasoning, which differentiates them from traditional, rule-based AI systems. It requires an inclusive, collaborative co-design process that engages all pertinent stakeholders, including clinicians and consumers, to achieve these benefits. Although global research is examining both opportunities and challenges, including ethical and legal dimensions, LLMs offer promising advancements in healthcare by enhancing data management, information retrieval, and decision-making processes. Continued innovation in data acquisition, model fine-tuning, prompt strategy development, evaluation, and system implementation is imperative for realizing the full potential of these technologies. Organizations should proactively engage with these technologies to improve healthcare quality, safety, and efficiency, adhering to ethical and legal guidelines for responsible application.",
        "link": "http://dx.doi.org/10.3390/healthcare11202776"
    },
    {
        "id": 11048,
        "title": "Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine",
        "authors": "Stefan Harrer",
        "published": "2023-4",
        "citations": 92,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ebiom.2023.104512"
    },
    {
        "id": 11049,
        "title": "Impact of Emojis on Automatic Analysis of Individual Emotion Categories",
        "authors": "Ratchakrit Arreerard,  , Scott Piao,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_014"
    },
    {
        "id": 11050,
        "title": "InterpreTutor: Using Large Language Models for Interpreter Assessment",
        "authors": "Cihan Ünlü,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/issn.2683-0078.2023_007"
    },
    {
        "id": 11051,
        "title": "Large Language Models in Academia: Ethical Considerations and Future Prospects",
        "authors": "Ashwini Agarwal, Abhishek Padhi, Jaydevsinh Vala, C. D. S. Katoch",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4103/jnmo.jnmo_16_23"
    },
    {
        "id": 11052,
        "title": "MindWatch: A Smart Cloud-based AI solution for Suicide Ideation Detection leveraging Large Language Models",
        "authors": "Runa Bhaumik, Vineet Srivastava, Arash Jalali, Shanta Ghosh, Ranganathan Chandrasekharan",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractSuicide, a serious public health concern affecting millions of individuals worldwide, refers to the intentional act of ending one’s own life. Mental health issues such as depression, frustration, and hopelessness can directly or indirectly influence the emergence of suicidal thoughts. Early identification of these thoughts is crucial for timely diagnosis. In recent years, advances in artificial intelligence (AI) and natural language processing (NLP) have paved the way for revolutionizing mental health support and education. In this proof-of-concept study, we have created MindWatch, a cutting-edge tool that harnesses the power of AI-driven language models to serve as a valuable computer-aided system for the mental health professions to achieve two important goals such asearly symptom detection, and personalized psychoeducation. We utilized ALBERT and Bio-Clinical BERT language models and fine-tuned them with the Reddit dataset to build the classifiers. We evaluated the performance of bi-LSTM, ALBERT, Bio-Clinical BERT, OpenAI GPT3.5 (via prompt engineering), and an ensembled voting classifier to detect suicide ideation. For personalized psychoeducation, we used the state-of-the-art Llama 2 foundation model leveraging prompt engineering. The tool is developed in the Amazon Web Service environment. All models performed exceptionally well, with accuracy and precision/recall greater than 92%. ALBERT performed better (AUC=.98) compared to the zero-shot classification accuracies obtained from OpenAI GPT3.5 Turbo (ChatGPT) on hidden datasets (AUC=.91). Furthermore, we observed that the inconclusiveness rate of the Llama 2 model is low while tested for few examples. This study emphasizes how transformer models can help provide customized psychoeducation to individuals dealing with mental health issues. By tailoring content to address their unique mental health conditions, treatment choices, and self-help resources, this approach empowers individuals to actively engage in their recovery journey. Additionally, these models have the potential to advance the automated detection of depressive disorders.",
        "link": "http://dx.doi.org/10.1101/2023.09.25.23296062"
    },
    {
        "id": 11053,
        "title": "Large Language Models Are Partially Primed in Pronoun Interpretation",
        "authors": "Suet-Ying Lam, Qingcheng Zeng, Kexun Zhang, Chenyu You, Rob Voigt",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.605"
    },
    {
        "id": 11054,
        "title": "LLM-Japanese-Dataset v0: Construction of Japanese Chat Dataset for Large Language Models and its Methodology",
        "authors": "Masanori HIRANO, Masahiro SUZUKI, Hiroki Sakaji",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4454626"
    },
    {
        "id": 11055,
        "title": "Comparing the persuasiveness of role-playing large language models and human experts on polarized U.S. political issues",
        "authors": "Kobi Hackenburg, Lujain Ibrahim, Ben M Tappin, Manos Tsakiris",
        "published": "No Date",
        "citations": 0,
        "abstract": "Advances in large language models (LLMs) could significantly disrupt political communication. In a large-scale pre-registered experiment (n=4,955), we prompted GPT-4 to generate persuasive messages impersonating the language and beliefs of U.S. political parties – a technique we term “partisan role-play” –  and directly compared their persuasiveness to that of human persuasion experts. In aggregate, the persuasive impact of role-playing messages generated by GPT-4 was not significantly different from that of non-role-playing messages. However, the persuasive impact of GPT-4 rivaled, and on some issues exceeded, that of the human experts. Taken together, our findings suggest that — contrary to popular concern — instructing current LLMs to role-play as partisans offers limited persuasive advantage, but also that current LLMs can rival and even exceed the persuasiveness of human experts. These results potentially portend widespread adoption of AI tools by persuasion campaigns, with important implications for the role of AI in politics and democracy.",
        "link": "http://dx.doi.org/10.31219/osf.io/ey8db"
    },
    {
        "id": 11056,
        "title": "Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting",
        "authors": "Zhiyu Chen, Yujie Lu, William Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.284"
    },
    {
        "id": 11057,
        "title": "Automatic Evaluation of Attribution by Large Language Models",
        "authors": "Xiang Yue, Boshi Wang, Ziru Chen, Kai Zhang, Yu Su, Huan Sun",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.307"
    },
    {
        "id": 11058,
        "title": "A New Era in Conversational AI",
        "authors": "Michael McTear, Marina Ashurkina",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0110-5_1"
    },
    {
        "id": 11059,
        "title": "The Rise of Neural Conversational Systems",
        "authors": "Michael McTear, Marina Ashurkina",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/979-8-8688-0110-5_3"
    },
    {
        "id": 11060,
        "title": "Electrical Equipment Fault Diagnosis: A Technique Combining Fuzzy Logic and Large Language Models",
        "authors": "Tao Xu, Xue-Song Tang",
        "published": "2023-11-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ispce-asia60405.2023.10365878"
    },
    {
        "id": 11061,
        "title": "Advancing AI in rheumatology: critical reflections and proposals for future research using large language models",
        "authors": "Partha Pratim Ray",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00296-023-05488-y"
    },
    {
        "id": 11062,
        "title": "Generating Prototypes for Contradiction Detection Using Large Language Models and Linguistic Rules",
        "authors": "Maren Pielka, Svetlana Schmidt, Rafet Sifa",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386499"
    },
    {
        "id": 11063,
        "title": "Effect of tokenization granularity for Turkish large language models",
        "authors": "Yiğit Bekir Kaya, A. Cüneyd Tantuğ",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.iswa.2024.200335"
    },
    {
        "id": 11064,
        "title": "Can Large Language Models Provide Feedback to Students? A Case Study on ChatGPT",
        "authors": "Wei Dai, Jionghao Lin, Flora Jin, Tongguang Li, Yi-Shan Tsai, Dragan Gasevic, Guanliang Chen",
        "published": "No Date",
        "citations": 12,
        "abstract": "Educational feedback has been widely acknowledged as an effective approach to improving student learning. However, scaling effective practices can be laborious and costly, which motivated researchers to work on automated feedback systems (AFS). Inspired by the recent advancements in the pre-trained language models (e.g., ChatGPT), we posit that such models might advance the existing knowledge of textual feedback generation in AFS because of their capability to offer natural-sounding and detailed responses. Therefore, we aimed to investigate the feasibility of using ChatGPT to provide students with feedback to help them learn better. Specifically, we first examined the readability of ChatGPT-generated feedback. Then, we measured the agreement between ChatGPT and the instructor when assessing students' assignments according to the marking rubric. Finally, we used a well-known theoretical feedback framework to further investigate the effectiveness of the feedback generated by ChatGPT. Our results show that i) ChatGPT is capable of generating more detailed feedback that fluently and coherently summarizes students' performance than human instructors; ii) ChatGPT achieved high agreement with the instructor when assessing the topic of students' assignments; and iii) ChatGPT could provide feedback on the process of students completing the task, which benefits students developing learning skills.",
        "link": "http://dx.doi.org/10.35542/osf.io/hcgzj"
    },
    {
        "id": 11065,
        "title": "Judge the Judges: A Large-Scale Evaluation Study of Neural Language Models for Online Review Generation",
        "authors": "Cristina Garbacea, Samuel Carton, Shiyan Yan, Qiaozhu Mei",
        "published": "2019",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-1409"
    },
    {
        "id": 11066,
        "title": "John-Arthur at SemEval-2023 Task 4: Fine-Tuning Large Language Models for Arguments Classification",
        "authors": "Georgios Balikas",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.semeval-1.197"
    },
    {
        "id": 11067,
        "title": "Between Reality and Delusion: Challenges of Applying Large Language Models to Companion Robots for Open-Domain Dialogues with Older Adults",
        "authors": "Bahar Irfan, Sanna-Mari Kuoppamäki, Gabriel Skantze",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractThis work aims to provide initial guidelines towards developing companion robots with large language models (LLMs) to be part of everyday lives of older adults. Using iterative participatory design (co-design) approaches, we analyze the challenges of applying LLMs for multi-modal open-domain dialogue, deriving from older adults' (one-to-one) interactions with a personalized companion robot, built on Furhat robot with GPT-3.5. An initial study with 6 Swedish-speaking older adults (65 and older) showed that the robot frequently interrupted the users, responded slowly and repetitively, engaged in superficial conversations, and caused a barrier in the interaction due to foreign language (English). Upon incremental technical developments to address these issues, participatory design workshops were conducted with 28 Swedish-speaking older adults. While the interactions (in Swedish) were smoother, less disrupted, and more varied in topics and responses, further challenges were observed due to hallucinations and obsolete information, and disengagement cues, causing frustration, confusion, and worry.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2884789/v1"
    },
    {
        "id": 11068,
        "title": "Comment on: AI am a rheumatologist: a practical primer to large language models for rheumatologists",
        "authors": "Amnuay Kleebayoon, Viroj Wiwanitkit",
        "published": "2023-12-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/rheumatology/kead414"
    },
    {
        "id": 11069,
        "title": "MathPrompter: Mathematical Reasoning using Large Language Models",
        "authors": "Shima Imani, Liang Du, Harsh Shrivastava",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-industry.4"
    },
    {
        "id": 11070,
        "title": "Large Language Models (LLMs) and Empathy – A Systematic Review (Preprint)",
        "authors": "Vera Sorin, Dana Brin, Yiftach Barash, Eli Konen, Alexander Charney, Girish Nadkarni, Eyal Klang",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nEmpathy, a cornerstone of human interaction, is a unique quality to humans that Large Language Models (LLMs) are believed to lack.\n\n\nOBJECTIVE\nOur study aims to review the literature on the capacity of LLMs in demonstrating empathy\n\n\nMETHODS\nWe conducted a literature search on MEDLINE up to July 2023. Included were English language full-length publications that evaluated empathy in LLMs outputs. Excluded were papers evaluating other topics related to emotional intelligence that were not specifically empathy.\n\n\nRESULTS\nSeven publications ultimately met the inclusion criteria. All studies included in this review were published in 2023. All studies but one focused on ChatGPT-3.5 by OpenAI. Only one study evaluated empathy based on objective metrics, and all others used subjective human assessment. The studies reported LLMs to exhibit elements of empathy, including emotions recognition and emotional support in diverse contexts, most of which were related to healthcare. In some cases, LLMs were observed to outperform humans in empathy-related tasks.\n\n\nCONCLUSIONS\nLLMs demonstrated some aspects of empathy in variable scenarios, mainly related to healthcare. The empathy may be considered “cognitive” empathy. Social skills are a fundamental aspect of intelligence, thus further research is imperative to enhance these skills in AI.\n",
        "link": "http://dx.doi.org/10.2196/preprints.52597"
    },
    {
        "id": 11071,
        "title": "Large Language Models Are Reasoning Teachers",
        "authors": "Namgyu Ho, Laura Schmid, Se-Young Yun",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.830"
    },
    {
        "id": 11072,
        "title": "Performance of Large Language Models on a Neurology Board–Style Examination",
        "authors": "Marc Cicero Schubert, Wolfgang Wick, Varun Venkataramani",
        "published": "2023-12-7",
        "citations": 3,
        "abstract": "ImportanceRecent advancements in large language models (LLMs) have shown potential in a wide array of applications, including health care. While LLMs showed heterogeneous results across specialized medical board examinations, the performance of these models in neurology board examinations remains unexplored.ObjectiveTo assess the performance of LLMs on neurology board–style examinations.Design, Setting, and ParticipantsThis cross-sectional study was conducted between May 17 and May 31, 2023. The evaluation utilized a question bank resembling neurology board-style examination questions and was validated with a small question cohort by the European Board for Neurology. All questions were categorized into lower-order (recall, understanding) and higher-order (apply, analyze, synthesize) questions based on the Bloom taxonomy for learning and assessment. Performance by LLM ChatGPT versions 3.5 (LLM 1) and 4 (LLM 2) was assessed in relation to overall scores, question type, and topics, along with the confidence level and reproducibility of answers.Main Outcomes and MeasuresOverall percentage scores of 2 LLMs.ResultsLLM 2 significantly outperformed LLM 1 by correctly answering 1662 of 1956 questions (85.0%) vs 1306 questions (66.8%) for LLM 1. Notably, LLM 2’s performance was greater than the mean human score of 73.8%, effectively achieving near-passing and passing grades in the neurology board–style examination. LLM 2 outperformed human users in behavioral, cognitive, and psychological–related questions and demonstrated superior performance to LLM 1 in 6 categories. Both LLMs performed better on lower-order than higher-order questions, with LLM 2 excelling in both lower-order and higher-order questions. Both models consistently used confident language, even when providing incorrect answers. Reproducible answers of both LLMs were associated with a higher percentage of correct answers than inconsistent answers.Conclusions and RelevanceDespite the absence of neurology-specific training, LLM 2 demonstrated commendable performance, whereas LLM 1 performed slightly below the human average. While higher-order cognitive tasks were more challenging for both models, LLM 2’s results were equivalent to passing grades in specialized neurology examinations. These findings suggest that LLMs could have significant applications in clinical neurology and health care with further refinements.",
        "link": "http://dx.doi.org/10.1001/jamanetworkopen.2023.46721"
    },
    {
        "id": 11073,
        "title": "Balancing caution and ınnovation: exploring the potential of large language models in critical decision-making",
        "authors": "Izzet Turkalp Akbasli, Benan Bayrakci",
        "published": "2023-5-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s13054-023-04447-0"
    },
    {
        "id": 11074,
        "title": "Navigating the ethical and practical challenges of large language models in telehealth",
        "authors": "Aaron Lawson McLean",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1177/1357633x231205060"
    },
    {
        "id": 11075,
        "title": "Exploring the Potential of Large Language Models in Molecular Tasks: An Insightful Evaluation with GPT‐4",
        "authors": "Jinlu Zhang, Yin Fang, Ningyu Zhang, Xin Shao, Huajun Chen, Xiaohui Fan",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractIn the rapidly changing realm of artificial intelligence, large language models (LLMs) such as GPT-4 are increasingly being explored for their potential to aid and enhance the field of molecular research. This study explores the performance of GPT-4 and GPT-3.5 in molecular research, particularly in generating and optimizing molecular structures. The results highlight GPT-4’s strengths in certain areas of molecular optimization, while also revealing challenges in accurately generating complex molecules. The findings underscore the necessity for integrating these models with domain-specific tools to enhance their application in scientific research, particularly in molecular studies. The study offers insights into the potential of LLMs for advancing molecular research, paving the way for future developments in this rapidly evolving field.",
        "link": "http://dx.doi.org/10.1101/2023.11.28.568966"
    },
    {
        "id": 11076,
        "title": "Performance of Large Language Models (LLMs) in Providing Prostate Cancer Information",
        "authors": "Ahmed Alasker, Seham Alsalamah, Nada Alshathri, Nura Almansour, Faris Alsalamah, Mohammad Alghafees, Mohammad AlKhamees, Bader Alsaikhan",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nProstate cancer, the second most common cancer in men worldwide, is highly complex regarding diagnosis and management. Hence, patients often seek knowledge through additional resources, including AI chatbots such as Generative Pre-trained Transformers (ChatGPT) and Google Bard. This study aimed to evaluate the performance of LLMs in providing educational content on prostate cancer. Common patient questions about prostate cancer were collected from reliable educational websites and evaluated for accuracy, comprehensiveness, readability, and stability by two independent board-certified urologists, with a third resolving discrepancies. Accuracy was measured on a 3-point scale, comprehensiveness on a 5-point Likert scale, and readability using the Flesch Reading Ease (FRE) Score and Flesch–Kincaid FK Grade Level. A total of 52 questions on general knowledge, diagnosis, treatment, and prevention of prostate cancer were provided to three LLMs. Although there was no significant difference in the overall accuracy of LLMs, ChatGPT demonstrated superiority among the LLMs in the context of general knowledge of prostate cancer (p = 0.018). ChatGPT Plus achieved higher overall comprehensiveness than ChatGPT and Bard (p = 0.028). For readability, Bard generated simpler sentences with the highest FRE score (54.7, p < 0.001) and lowest FK Reading Level (10.2, p < 0.001). ChatGPT and Bard generate accurate, understandable, and easily readable material on prostate cancer. These AI models might not replace healthcare professionals but can assist in patient education and guidance.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3499451/v1"
    },
    {
        "id": 11077,
        "title": "A Causal View of Entity Bias in (Large) Language Models",
        "authors": "Fei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou, Muhao Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.1013"
    },
    {
        "id": 11078,
        "title": "Understanding Naturalistic Facial Expressions with Deep Learning and Multimodal Large Language Models",
        "authors": "Yifan Bian, Dennis Küster, Hui Liu, Eva G. Krumhuber",
        "published": "2023-12-26",
        "citations": 2,
        "abstract": "This paper provides a comprehensive overview of affective computing systems for facial expression recognition (FER) research in naturalistic contexts. The first section presents an updated account of user-friendly FER toolboxes incorporating state-of-the-art deep learning models and elaborates on their neural architectures, datasets, and performances across domains. These sophisticated FER toolboxes can robustly address a variety of challenges encountered in the wild such as variations in illumination and head pose, which may otherwise impact recognition accuracy. The second section of this paper discusses multimodal large language models (MLLMs) and their potential applications in affective science. MLLMs exhibit human-level capabilities for FER and enable the quantification of various contextual variables to provide context-aware emotion inferences. These advancements have the potential to revolutionize current methodological approaches for studying the contextual influences on emotions, leading to the development of contextualized emotion models.",
        "link": "http://dx.doi.org/10.3390/s24010126"
    },
    {
        "id": 11079,
        "title": "Human-Like Named Entity Recognition with Large Language Models in Unstructured Text-based Electronic Healthcare Records: An Evaluation Study",
        "authors": "Izzet Turkalp Akbasli, Ahmet Ziya Birbilen, Ozlem Teksam",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground\n The integration of big data and artificial intelligence (AI) in healthcare, particularly through the analysis of electronic health records (EHR), presents significant opportunities for improving diagnostic accuracy and patient outcomes. However, the challenge of processing and accurately labeling vast amounts of unstructured data remains a critical bottleneck, necessitating efficient and reliable solutions. This study investigates the ability of domain specific, fine-tuned large language models (LLMs) to classify unstructured EHR texts with typographical errors through named entity recognition tasks, aiming to improve the efficiency and reliability of supervised learning AI models in healthcare.\nMethods\n Clinical notes from pediatric emergency room admissions at Hacettepe University İhsan Doğramacı Children's Hospital from 2018 to 2023 were analyzed. The data were preprocessed with open source Python libraries and categorized using a pretrained GPT-3 model, \"text-davinci-003,\" before and after fine-tuning with domain-specific data on respiratory tract infections (RTI). The model's predictions were compared against ground truth labels established by pediatric specialists.\nResults\n Out of 24,229 patient records classified as \"Others ()\", 18,879 were identified without typographical errors and confirmed for RTI through filtering methods. The fine-tuned model achieved a 99.96% accuracy, significantly outperforming the pretrained model's 78.54% accuracy in identifying RTI cases among the remaining records. The fine-tuned model demonstrated superior performance metrics across all evaluated aspects compared to the pretrained model.\nConclusions\n Fine-tuned LLMs can categorize unstructured EHR data with high accuracy, closely approximating the performance of domain experts. This approach significantly reduces the time and costs associated with manual data labeling, demonstrating the potential to streamline the processing of large-scale healthcare data for AI applications.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-4014476/v1"
    },
    {
        "id": 11080,
        "title": "Large Language Models for Code: Security Hardening and Adversarial Testing",
        "authors": "Jingxuan He, Martin Vechev",
        "published": "2023-11-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3576915.3623175"
    },
    {
        "id": 11081,
        "title": "Corporate Event Predictions Using Large Language Models",
        "authors": "Zhaomin Xiao, Zhelu Mai, Zhuoer Xu, Yachen Cui, Jiancheng Li",
        "published": "2023-11-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iscmi59957.2023.10458651"
    },
    {
        "id": 11082,
        "title": "Can Large Language Models Revolutionalize Open Government Data Portals? A Case of Using ChatGPT in statistics.gov.scot",
        "authors": "Marios Mamalis, Evangelos Kalampokis, Areti Karamanou, Petros Brimos, Konstantinos Tarabanis",
        "published": "No Date",
        "citations": 0,
        "abstract": "Large language models possess tremendous natural language understanding and generation abilities. However, they often lack the ability to discern between fact and fiction, leading to factually incorrect responses. Open Government Data are repositories of, often times linked, information that is freely available to everyone. By combining these two technologies in a proof of concept designed application utilizing the GPT3.5 OpenAI model and the Scottish open statistics portal, we show that not only is it possible to augment the large language model's factuality of responses, but also propose a novel way to effectively access and retrieve statistical information from the data portal just through natural language querying. We anticipate that this paper will trigger a discussion regarding the transformation of Open Government Portals through large language models.",
        "link": "http://dx.doi.org/10.31219/osf.io/9b35z"
    },
    {
        "id": 11083,
        "title": "Integrating Graphs With Large Language Models: Methods and Prospects",
        "authors": "Shirui Pan, Yizhen Zheng, Yixin Liu",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mis.2023.3332242"
    },
    {
        "id": 11084,
        "title": "Comparing the Efficacy of GPT-4 and Chat-GPT in Mental Health Care: A Blind Assessment of Large Language Models for Psychological Support (Preprint)",
        "authors": "Birger Moell",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nRapid advancements in natural language processing have led to the development of large language models with the potential to revolutionize mental health care. These models have shown promise in assisting clinicians and providing support to individuals experiencing various psychological challenges.\n\n\nOBJECTIVE\nThis study aims to compare the performance of two large language models, GPT-4 and Chat-GPT, in responding to a set of 18 psychological prompts, to assess their potential applicability in mental health care settings.\n\n\nMETHODS\nA blind methodology was employed, with a clinical psychologist evaluating the models' responses without knowledge of their origins. The prompts encompassed a diverse range of mental health topics, including depression, anxiety, and trauma, to ensure a comprehensive assessment.\n\n\nRESULTS\nThe results demonstrated a significant difference in performance between the two models (p < 0.05). GPT-4 achieved an average rating of 8.29 out of 10, while Chat-GPT received an average rating of 6.52. The clinical psychologist's evaluation suggested that GPT-4 was more effective at generating clinically relevant and empathetic responses, thereby providing better support and guidance to potential users.\n\n\nCONCLUSIONS\nThis study contributes to the growing body of literature on the applicability of large language models in mental health care settings. The findings underscore the importance of continued research and development in the field to optimize these models for clinical use. Further investigation is necessary to understand the specific factors underlying the performance differences between the two models and to explore their generalizability across various populations and mental health conditions.\n",
        "link": "http://dx.doi.org/10.2196/preprints.47439"
    },
    {
        "id": 11085,
        "title": "Knowledge of cultural moral norms in large language models",
        "authors": "Aida Ramezani, Yang Xu",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.26"
    },
    {
        "id": 11086,
        "title": "User-Centric Conversational Recommendation: Adapting the Need of User with Large Language Models",
        "authors": "Gangyi Zhang",
        "published": "2023-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3604915.3608885"
    },
    {
        "id": 11087,
        "title": "Disfluent Cues for Enhanced Speech Understanding in Large Language Models",
        "authors": "Morteza Rohanian, Farhad Nooralahzadeh, Omid Rohanian, David Clifton, Michael Krauthammer",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.238"
    },
    {
        "id": 11088,
        "title": "An Evaluation Method for Large Language Models’ Code Generation Capability",
        "authors": "Haoran Su, Jun Ai, Dan Yu, Hong Zhang",
        "published": "2023-8-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dsa59317.2023.00118"
    },
    {
        "id": 11089,
        "title": "Can Large Language Models Predict Data Correlations from Column Names?",
        "authors": "Immanuel Trummer",
        "published": "2023-9",
        "citations": 1,
        "abstract": "Recent publications suggest using natural language analysis on database schema elements to guide tuning and profiling efforts. The underlying hypothesis is that state-of-the-art language processing methods, so-called language models, are able to extract information on data properties from schema text.\nThis paper examines that hypothesis in the context of data correlation analysis: is it possible to find column pairs with correlated data by analyzing their names via language models? First, the paper introduces a novel benchmark for data correlation analysis, created by analyzing thousands of Kaggle data sets (and available for download). Second, it uses that data to study the ability of language models to predict correlation, based on column names. The analysis covers different language models, various correlation metrics, and a multitude of accuracy metrics. It pinpoints factors that contribute to successful predictions, such as the length of column names as well as the ratio of words. Finally, the study analyzes the impact of column types on prediction performance. The results show that schema text can be a useful source of information and inform future research efforts, targeted at NLP-enhanced database tuning and data profiling.",
        "link": "http://dx.doi.org/10.14778/3625054.3625066"
    },
    {
        "id": 11090,
        "title": "Enhancing Antibiotic Prescribing in Urgent Care by Leveraging Large Language Models for Optimized Clinical Decision Support",
        "authors": "",
        "published": "2024-1-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.56726/irjmets48495"
    },
    {
        "id": 11091,
        "title": "Evaluating the generation capabilities of large Chinese language models",
        "authors": "Hui Zeng, Jingyuan Xue, Meng Hao, Chen Sun, Bin Ning, Na Zhang",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.aiopen.2024.02.002"
    },
    {
        "id": 11092,
        "title": "Performance Analysis of Arabic Pre-Trained Models on Named Entity Recognition Task",
        "authors": "Abdelhalim Hafedh Dahou,  , Mohamed Amine Cheragui, Ahmed Abdelali,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_051"
    },
    {
        "id": 11093,
        "title": "A Large-Scale Study of Language Models for Chord Prediction",
        "authors": "Filip Korzeniowski, David R. W. Sears, Gerhard Widmer",
        "published": "2018-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp.2018.8462285"
    },
    {
        "id": 11094,
        "title": "Automated Repair of Programs from Large Language Models",
        "authors": "Zhiyu Fan, Xiang Gao, Martin Mirchev, Abhik Roychoudhury, Shin Hwei Tan",
        "published": "2023-5",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icse48619.2023.00128"
    },
    {
        "id": 11095,
        "title": "A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction",
        "authors": "Ruihao Shui, Yixin Cao, Xiang Wang, Tat-Seng Chua",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.490"
    },
    {
        "id": 11096,
        "title": "ASSERT: Automated Safety Scenario Red Teaming for Evaluating the Robustness of Large Language Models",
        "authors": "Alex Mei, Sharon Levy, William Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.388"
    },
    {
        "id": 11097,
        "title": "Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text",
        "authors": "Zhun Yang, Adam Ishay, Joohyung Lee",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.321"
    },
    {
        "id": 11098,
        "title": "Can the ChatGPT and other Large Language Models with internet-connected database solve the questions and concerns of patient with prostate cancer?",
        "authors": "Lingxuan Zhu, Weiming Mou, Rui Chen",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractLarge language models (LLMs), such as ChatGPT, have shown impressive natural language processing capabilities in various fields, including medicine. However, the answers provided by these models may sometimes be incorrect, and they may not have access to the latest data. In this study, we aimed to evaluate the performance of five state-of-the-art LLMs in providing correct and comprehensive information on common questions raised by prostate cancer patients. We also examined whether LLMs with internet-connected databases could provide more up-to-date information than ChatGPT. We designed a set of 22 questions covering various aspects of prostate cancer and evaluated the accuracy, comprehensiveness, patient readability, and inclusion of humanistic care in the answers provided by each model. Our findings suggest that although the performance of different LLMs varied, these LLMs could provide accurate basic knowledge and have the ability to analyze specific situations to a certain extent. We also found that the overall performance of the LLM model with internet-connected dataset was not superior to ChatGPT, and the paid version of ChatGPT did not show superiority over the free version. Our study highlights the potential of LLMs in bridging the gap between patients and healthcare providers. Current LLMs have the potential to be applied for patient education and consultation, providing patient-friendly information. Shared decision-making with the doctors and patients could be achieved easier. We believed that with the rapid development of AI technology, LLMs have unlimited potential.",
        "link": "http://dx.doi.org/10.1101/2023.03.06.23286827"
    },
    {
        "id": 11099,
        "title": "Are Large Language Models All You Need for Task-Oriented Dialogue?",
        "authors": "Vojtěch Hudeček, Ondrej Dusek",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.sigdial-1.21"
    },
    {
        "id": 11100,
        "title": "She Elicits Requirements and He Tests: Software Engineering Gender Bias in Large Language Models",
        "authors": "Christoph Treude, Hideaki Hata",
        "published": "2023-5",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/msr59073.2023.00088"
    },
    {
        "id": 11101,
        "title": "Commonsense Knowledge in Foundation and Large Language Models",
        "authors": " Harsh Bhardwaj,  Maniya Tadhiyal,  Lakshay Kamboj",
        "published": "2024-2-8",
        "citations": 0,
        "abstract": "The development and continuous expansion of the transformer deep-learning architecture have produced enormous effects across various domains, including but not limited to natural language processing. The power of deep learning models has sparked a fresh interest in commonsense knowledge, which has been aided by transformer-based language models. Most of the recent research has concentrated on delving into the commonsense already built into these models' pre-trained parameters and finding ways to fill in any gaps in commonsense utilizing knowledge graphs and fine-tuning. In order to broaden a limited commonsense knowledge network that was originally generated solely from visual data, we are building on the demonstrated linguistic understanding of extremely large transformer-based language models. Compared to language models that are fine-tuned on a huge starting corpus, few-shotprompted pre-trained models are able to acquire the context of an initial knowledge graph with less bias. It has also been demonstrated that these models can contribute novel ideas to the visual knowledge networkIt is a new development in the field of commonsense knowledge generation that, as far as we can tell, can lead to a fivefold decrease in cost when compared to the current state of the art. Fuzzy language names assigned to the produced triples are another addition. Applying knowledge graphs as a framework, the procedure is comprehensive. It implies that the triples are expressed in natural language, analyzed, and then added to the commonsense knowledge network as triples again.",
        "link": "http://dx.doi.org/10.48175/ijarsct-15389"
    },
    {
        "id": 11102,
        "title": "Exploiting Large Language Models (LLMs) through Deception Techniques and Persuasion Principles",
        "authors": "Sonali Singh, Faranak Abri, Akbar Siami Namin",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386814"
    },
    {
        "id": 11103,
        "title": "Large Language Models: Their Success and Impact",
        "authors": "Spyros Makridakis, Fotios Petropoulos, Yanfei Kang",
        "published": "2023-8-25",
        "citations": 1,
        "abstract": "ChatGPT, a state-of-the-art large language model (LLM), is revolutionizing the AI field by exhibiting humanlike skills in a range of tasks that include understanding and answering natural language questions, translating languages, writing code, passing professional exams, and even composing poetry, among its other abilities. ChatGPT has gained an immense popularity since its launch, amassing 100 million active monthly users in just two months, thereby establishing itself as the fastest-growing consumer application to date. This paper discusses the reasons for its success as well as the future prospects of similar large language models (LLMs), with an emphasis on their potential impact on forecasting, a specialized and domain-specific field. This is achieved by first comparing the correctness of the answers of the standard ChatGPT and a custom one, trained using published papers from a subfield of forecasting where the answers to the questions asked are known, allowing us to determine their correctness compared to those of the two ChatGPT versions. Then, we also compare the responses of the two versions on how judgmental adjustments to the statistical/ML forecasts should be applied by firms to improve their accuracy. The paper concludes by considering the future of LLMs and their impact on all aspects of our life and work, as well as on the field of forecasting specifically. Finally, the conclusion section is generated by ChatGPT, which was provided with a condensed version of this paper and asked to write a four-paragraph conclusion.",
        "link": "http://dx.doi.org/10.3390/forecast5030030"
    },
    {
        "id": 11104,
        "title": "Active Learning Principles for In-Context Learning with Large Language Models",
        "authors": "Katerina Margatina, Timo Schick, Nikolaos Aletras, Jane Dwivedi-Yu",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.334"
    },
    {
        "id": 11105,
        "title": "SwarMind: Harnessing Large Language Models for Flock Dynamics",
        "authors": "Mehdi Mounsif, Killian Zehnder, Yassine Motie, Zoran Adam-Gaxotte",
        "published": "2023-11-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iscmi59957.2023.10458573"
    },
    {
        "id": 11106,
        "title": "Opportunities and challenges of human large language models in surgery: a bibliometric analysis",
        "authors": "Ziyue Luo, Jingwen Wei, Ruihao Zhou",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/js9.0000000000000970"
    },
    {
        "id": 11107,
        "title": "Open Source Large Language Models in Action: A Bioinformatics Chatbot for PRIDE database",
        "authors": "Jingwen Bai, Selvakumar Kamatchinathan, Deepti J Kundu, Chakradhar Bandla, Juan Antonio Vizcaino, Yasset Perez Riverol",
        "published": "No Date",
        "citations": 0,
        "abstract": "We here present a chatbot assistant infrastructure\n(https://www.ebi.ac.uk/pride/chatbot/) that simplifies user interactions\nwith the PRIDE database, the most popular proteomics data repository.\nOur system utilizes two advanced Large Language Models (LLM), llama2-13b\nand chatglm2-6b, and includes a web service API (Application Programming\nInterface), web interface, and sophisticated algorithms. We have\ndeveloped a novel approach to construct vector-based representations for\nenabling the LLM responses, featuring a curated version and a\ncomprehensive database of relevant links and paragraphs for each\ngenerated response. An important part of the framework is a benchmark\ncomponent based on an Elo-ranking system, providing a scalable method\nfor evaluating not only the performance of llama2-13b and chatglm2-6b\nbut also, of any other available and future open-source LLMs. Throughout\nthe benchmarking process, the PRIDE documentation for external users was\nrefined to enhance the clarity and efficacy in addressing user queries.\nImportantly, while our infrastructure is exemplified through its\napplication in the PRIDE database context, the modular and adaptable\nnature of our approach positions it as a valuable tool for improving\nuser experiences across a spectrum of bioinformatics and proteomics\ntools and resources, among other domains. The integration of advanced\nLLMs, innovative vector-based construction, the benchmarking framework,\nand optimized documentation collectively form a robust and transferable\nchatbot assistant infrastructure.",
        "link": "http://dx.doi.org/10.22541/au.171025539.92037103/v1"
    },
    {
        "id": 11108,
        "title": "Invited Paper: VerilogEval: Evaluating Large Language Models for Verilog Code Generation",
        "authors": "Mingjie Liu, Nathaniel Pinckney, Brucek Khailany, Haoxing Ren",
        "published": "2023-10-28",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccad57390.2023.10323812"
    },
    {
        "id": 11109,
        "title": "Editorial: Harnessing the Power of Large Language Models in Agricultural Safety &amp;amp; Health",
        "authors": "John M. Shutske",
        "published": "2023",
        "citations": 0,
        "abstract": "\nHighlights\n\n\n\n\nGenerative artificial intelligence will play a major role in the daily work of agricultural safety and health professionals.\n\n\nProperly trained large language models can assist educators, researchers, and clinicians in responding to agricultural safety and health questions.\n\n\nNumerous issues and obstacles must be overcome to use LLMs in these settings, including accuracy and completeness of responses, bias, and intellectual property concerns.\n\n\n\n   Keywords: Agricultural safety, Artificial intelligence, Bias, ChatGPT, Consultation, Extension, Generative AI, Health, Education, Intellectual Property, Large language models, LLM, Teaching.",
        "link": "http://dx.doi.org/10.13031/jash.15841"
    },
    {
        "id": 11110,
        "title": "AI and Human Reasoning: Qualitative Research in the Age of Large Language Models",
        "authors": "Muneera Bano, Didar Zowghi, Jon Whittle",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "Context: The advent of AI-driven large language models (LLMs), such as ChatGPT 3.5 and GPT-4, have stirred discussions about their role in qualitative research. Some view these as tools to enrich human understanding, while others perceive them as threats to the core values of the discipline.  Problem: A significant concern revolves around the disparity between AI-generated classifications and human comprehension, prompting questions about the reliability of AI-derived insights. An “AI echo chamber” could potentially risk the diversity inherent in qualitative research. A minimal overlap between AI and human interpretations amplifies concerns about the fading human element in research.  Objective: This study aimed to compare and contrast the comprehension capabilities of humans and LLMs, specifically ChatGPT 3.5 and GPT-4.  Methodology: We conducted an experiment with small sample of Alexa app reviews, initially classified by a human analyst. ChatGPT 3.5 and GPT-4 were then asked to classify these reviews and provide the reasoning behind each classification. We compared the results with human classification and reasoning.  Results: The research indicated a significant alignment between human and ChatGPT 3.5 classifications in one-third of cases, and a slightly lower alignment with GPT-4 in over a quarter of cases. The two AI models showed a higher alignment, observed in more than half of the instances. However, a consensus across all three methods was seen only in about one-fifth of the classifications. In the comparison of human and LLMs reasoning, it appears that human analysts lean heavily on their individual experiences. As expected, LLMs, on the other hand, base their reasoning on the specific word choices found in app reviews and the functional components of the app itself.  Conclusion: Our results highlight the potential for effective human-LLM collaboration, suggesting a synergistic rather than competitive relationship. Researchers must continuously evaluate LLMs’ role in their work, thereby fostering a future where AI and humans jointly enrich qualitative research.",
        "link": "http://dx.doi.org/10.47289/aiej20240122"
    },
    {
        "id": 11111,
        "title": "Challenges and limitations of ChatGPT and other large language models",
        "authors": "Erwin L. Rimban",
        "published": "2023-6-21",
        "citations": 0,
        "abstract": "This article explores the challenges and limitations of large language models, focusing on ChatGPT as a representative example. We begin by discussing the potential benefits of large language models, such as their ability to generate natural language text and assist with language-related tasks. However, we also acknowledge the concerns around these models, including their environmental impact, potential for bias, and lack of interpretability. We then delve into specific challenges faced by ChatGPT and similar models, including limitations in their understanding of context, difficulty in handling rare or out-of-vocabulary words, and their tendency to generate nonsensical or offensive text. We conclude with recommendations for future research and development, including the need for increased transparency, interpretability, and ethical considerations in the creation and deployment of large language models.",
        "link": "http://dx.doi.org/10.25082/ijah.2023.01.003"
    },
    {
        "id": 11112,
        "title": "Prompting Large Language Models for Zero-Shot Domain Adaptation in Speech Recognition",
        "authors": "Yuang Li, Yu Wu, Jinyu Li, Shujie Liu",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/asru57964.2023.10389732"
    },
    {
        "id": 11113,
        "title": "Fighting reviewer fatigue or amplifying bias? Considerations and recommendations for use of ChatGPT and other Large Language Models in scholarly peer review",
        "authors": "Mohammad Hosseini, Serge P.J.M. Horbach",
        "published": "No Date",
        "citations": 8,
        "abstract": "Abstract\nBackground:\nThe emergence of systems based on large language models (LLMs) such as OpenAI’s ChatGPT has created a range of discussions in scholarly circles. Since LLMs generate grammatically correct and mostly relevant (yet sometimes outright wrong, irrelevant or biased) outputs in response to provided prompts, using them in various writing tasks including writing peer review reports could result in improved productivity. Given the significance of peer reviews in the existing scholarly publication landscape, exploring challenges and opportunities of using LLMs in peer review seems urgent. After the generation of the first scholarly outputs with LLMs, we anticipate that peer review reports too would be generated with the help of these systems. However, there are currently no guidelines on how these systems should be used in review tasks.\nMethods:\nTo investigate the potential impact of using LLMs on the peer review process, we used five core themes within discussions about peer review suggested by Tennant and Ross-Hellauer. These include 1) reviewers’ role, 2) editors’ role, 3) functions and quality of peer reviews, 4) reproducibility, and 5) the social and epistemic functions of peer reviews. We provide a small-scale exploration of ChatGPT’s performance regarding identified issues.\nResults:\nLLMs have the potential to substantially alter the role of both peer reviewers and editors. Through supporting both actors in efficiently writing constructive reports or decision letters, LLMs can facilitate higher quality review and address issues of review shortage. However, the fundamental opacity of LLMs’ inner workings and development, raise questions and concerns about potential biases and the reliability of review reports. Additionally, as editorial work has a prominent function in defining and shaping epistemic communities, as well as negotiating normative frameworks within such communities, partly outsourcing this work to LLMs might have unforeseen consequences for social and epistemic relations within academia. Regarding performance, we identified major enhancements in only a few weeks (between December 2022 and January 2023) and expect ChatGPT to continue improving.\nConclusions:\nWe believe that LLMs are likely to have a profound impact on academia and scholarly communication. While they have the potential to address several current issues within the scholarly communication system, many uncertainties remain and their use is not without risks. In particular, concerns about the amplification of existing biases and inequalities in access to appropriate infrastructure warrant further attention. For the moment, we recommend that if LLMs are used to write scholarly reviews, reviewers should disclose their use and accept full responsibility for their reports’ accuracy, tone, reasoning and originality.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2587766/v1"
    },
    {
        "id": 11114,
        "title": "Comparing Conventional Machine Learning and Large-Language Models for Human Stress Detection Using Social Media Posts",
        "authors": "Prachi S Ramteke, Sarika Khandelwal",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/incoft60753.2023.10425133"
    },
    {
        "id": 11115,
        "title": "A critical examination and suggestions for large language models for structured reporting in radiology",
        "authors": "Partha Pratim Ray",
        "published": "2023-7-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11547-023-01688-5"
    },
    {
        "id": 11116,
        "title": "ChatGPT: A Practical Guide for Healthcare Professionals to Navigate the Volatile World of Large Language Models",
        "authors": "Kamal Kishore, Tejinder Singh, Vidushi Jaswal, Vibhuti Jaswal, Vishali Gupta",
        "published": "No Date",
        "citations": 0,
        "abstract": "ChatGPT, a generative AI (gAI) tool, has significantly transformed the field of Machine Learning (ML) and Artificial Intelligence (AI). Previously these fields were mainly accessible to a few individuals with programming skills, but now to a wider audience across different disciplines. Moreover, ML and AI were primarily focused on task specific predictions; the rise of gAI, led by tools like ChatGPT, has introduced a new era marked by interactive and dynamic capabilities previously unseen.Limited financial, human, and technological resources pose significant constraints in developing personalised and cost-efficient solutions in healthcare. The challenge is more acute for developing countries—paradoxically, the need for resources is greater. Generative AI tools like ChatGPT can profoundly impact areas such as patient interactions and support for medical professionals in decision-making.This paper is motivated by the need to bridge the gap between the widespread excitement and comprehensive understanding of ChatGPT and its functions. To address this, the paper focuses on three key objectives: first, we will present a comprehensive list and explanation of gAI terminology; second, systematically introduce the ChatGPT interface and its capabilities; and finally, discuss the rules of engagement with the tool to guide the model in delivering specific outputs.",
        "link": "http://dx.doi.org/10.31219/osf.io/8m75s"
    },
    {
        "id": 11117,
        "title": "How to Learn and Teach Economics with Large Language Models, Including GPT",
        "authors": "Tyler Cowen, Alexander T. Tabarrok, GMU Dept. of Econ. Submitter",
        "published": "2023",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4391863"
    },
    {
        "id": 11118,
        "title": "InstructoR: Instructing Unsupervised Conversational Dense Retrieval with Large Language Models",
        "authors": "Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.443"
    },
    {
        "id": 11119,
        "title": "Applying Large Language Models in Accounting: A Comparative Analysis of Different Methodologies and Off-the-Shelf Examples",
        "authors": "Huaxia Li, Miklos A. Vasarhelyi",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4650476"
    },
    {
        "id": 11120,
        "title": "Enhancing Patient-Physician Communication: Simulating African American Vernacular English in Medical Diagnostics with Large Language Models (Preprint)",
        "authors": "Yeawon Lee, Chia-Hsuan Chang, Christopher Yang",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nCommunication barriers in healthcare, particularly between physicians and patients with different linguistic and cultural backgrounds, negatively impact patient care. Studies show that language and cultural disparities contribute to health outcome disparities, particularly in the African American community. Patient-physician language concordance is linked to better health outcomes, highlighting the need for healthcare systems to consider patients' unique linguistic and cultural backgrounds.\n\n\nOBJECTIVE\nThis study aims to investigate Large Language Models (LLMs), specifically GPT-4, in simulating patients who speak African American Vernacular English (AAVE). By assessing GPT-4's capability to mimic AAVE, the study seeks to bridge the linguistic and cultural communication gaps in healthcare, leading to a more culturally sensitive and inclusive healthcare system.\n\n\nMETHODS\nThe study involved simulating patient-physician interactions using GPT-4. We crafted prompts incorporating medical cases, demographic variables, and linguistic features, progressively increasing complexity. The prompts were based on scenarios from the United States Medical Licensing Examination (USMLE) Computer-Based Case Simulations (CCS). Diagnostic questions formulated by healthcare professionals were posed to the simulated patients, and responses were analyzed for AAVE linguistic features.\n\n\nRESULTS\nOur research indicates that GPT-4 consistently exhibits AAVE characteristics in response to various prompts. Notably, the most comprehensive prompt (CompP) – which integrates the medical case, demographic variable, and linguistic features – is particularly effective in eliciting AAVE features in the GPT-4's responses. Interestingly, prompt that solely include a demographic variable (DemoP) is more effective than the one with explicit linguistic feature details (LingP) in eliciting phonological features. This suggests an inherent association in GPT-4 between the African American demographic and specific phonological attributes. Furthermore, GPT-4 can generate 'out-of-list features', which are linguistic behaviors not explicitly requested in the prompts. However, the GPT-4 exhibits limitations in simulating certain AAVE features. These limitations are particularly evident in constructing questions involving specific inversion rules, existential and locative constructions, and in the use of unique AAVE lexical items.\n\n\nCONCLUSIONS\nThis study underscores GPT-4's proficiency in simulating linguistic behaviors associated with specific demographic groups, particularly AAVE. Such capability is vital for bridging linguistic gaps in healthcare and enhancing communication. Our findings suggest the potential of AI systems, like GPT-4, to serve as practical training tools for medical professionals, improving their interaction with diverse patient populations. Future research should include a broader range of demographic and sociolect factors, and focus on adapting medical terminology to various levels of patient health literacy. Developing customized language models, sensitive to linguistic and cultural nuances, could play a pivotal role in reducing communication barriers, leading to better patient outcomes and a more equitable healthcare system.\n",
        "link": "http://dx.doi.org/10.2196/preprints.56292"
    },
    {
        "id": 11121,
        "title": "Generating Synthetic Resume Data with Large Language Models for Enhanced Job Description Classification",
        "authors": "Panagiotis Skondras, Panagiotis Zervas, Giannis Tzimas",
        "published": "2023-11-9",
        "citations": 1,
        "abstract": "In this article, we investigate the potential of synthetic resumes as a means for the rapid generation of training data and their effectiveness in data augmentation, especially in categories marked by sparse samples. The widespread implementation of machine learning algorithms in natural language processing (NLP) has notably streamlined the resume classification process, delivering time and cost efficiencies for hiring organizations. However, the performance of these algorithms depends on the abundance of training data. While selecting the right model architecture is essential, it is also crucial to ensure the availability of a robust, well-curated dataset. For many categories in the job market, data sparsity remains a challenge. To deal with this challenge, we employed the OpenAI API to generate both structured and unstructured resumes tailored to specific criteria. These synthetically generated resumes were cleaned, preprocessed and then utilized to train two distinct models: a transformer model (BERT) and a feedforward neural network (FFNN) that incorporated Universal Sentence Encoder 4 (USE4) embeddings. While both models were evaluated on the multiclass classification task of resumes, when trained on an augmented dataset containing 60 percent real data (from Indeed website) and 40 percent synthetic data from ChatGPT, the transformer model presented exceptional accuracy. The FFNN, albeit predictably, achieved lower accuracy. These findings highlight the value of augmented real-world data with ChatGPT-generated synthetic resumes, especially in the context of limited training data. The suitability of the BERT model for such classification tasks further reinforces this narrative.",
        "link": "http://dx.doi.org/10.3390/fi15110363"
    },
    {
        "id": 11122,
        "title": "Text Classification via Large Language Models",
        "authors": "Xiaofei Sun, Xiaoya Li, Jiwei Li, Fei Wu, Shangwei Guo, Tianwei Zhang, Guoyin Wang",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.603"
    },
    {
        "id": 11123,
        "title": "Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models",
        "authors": "Hamideh Ghanadian, Isar Nejadgholi, Hussein Al Osman",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2024.3358206"
    },
    {
        "id": 11124,
        "title": "The evolution, applications, and future prospects of large language models: An in-depth overview",
        "authors": "Jiayin Li",
        "published": "2024-2-4",
        "citations": 0,
        "abstract": "The evolution of natural language processing has transpired through three primary phases, with large-scale language models significantly transforming the field. These models have heightened the machine's capability to understand, produce, and interact with human language in unprecedented ways. Progressing from RNNs to transformer models, transitioning from encoder-decoder frameworks to decoder-centric designs, and the journey from BERT to the Chat-GPT series have marked significant shifts in the academic discourse. Impressively, these sophisticated models have infiltrated a range of sectors, including finance, healthcare, biology, and education, revolutionizing both traditional and emerging domains. However, as these advancements are celebrated, the ethical and economic challenges they introduce must also be addressed. Confronting these pivotal issues and harnessing technology for societal betterment has become a priority for academia and industry alike, sparking intense research endeavors in recent times. This review dives into the history of natural language processing, highlighting the pivotal developments and core principles of large language models. It provides a comprehensive perspective on their adoption and influence within the financial sector, crafting a detailed narrative of their deployment. In conclusion, the analysis reflects on the current challenges posed by these models and presents potential solutions. This study stands as a definitive guide, offering readers an in-depth understanding of the development, application, and future trajectories of large-scale language models.",
        "link": "http://dx.doi.org/10.54254/2755-2721/35/20230399"
    },
    {
        "id": 11125,
        "title": "Ideas are Dimes a Dozen: Large Language Models for Idea Generation in Innovation",
        "authors": "Karan Girotra, Lennart Meincke, Christian Terwiesch, Karl T. Ulrich",
        "published": "2023",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4526071"
    },
    {
        "id": 11126,
        "title": "Chatbots and Large Language Models in Radiology: A Practical Primer for Clinical and Research Applications",
        "authors": "Rajesh Bhayana",
        "published": "2024-1-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1148/radiol.232756"
    },
    {
        "id": 11127,
        "title": "Augmenting Intelligent Document Processing (IDP) Workflows with Contemporary Large Language Models (LLMs)",
        "authors": "Shreekant Mandvikar",
        "published": "2023-10-30",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14445/22312803/ijctt-v71i10p110"
    },
    {
        "id": 11128,
        "title": "Science in the age of large language models",
        "authors": "Abeba Birhane, Atoosa Kasirzadeh, David Leslie, Sandra Wachter",
        "published": "2023-4-26",
        "citations": 45,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s42254-023-00581-4"
    },
    {
        "id": 11129,
        "title": "Large language models challenge the future of higher education",
        "authors": "Silvia Milano, Joshua A. McGrane, Sabina Leonelli",
        "published": "2023-3-31",
        "citations": 23,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s42256-023-00644-2"
    },
    {
        "id": 11130,
        "title": "Faithful AI in Medicine: A Systematic Review with Large Language Models and Beyond",
        "authors": "Qianqian Xie, Edward J. Schenck, He S. Yang, Yong Chen, Yifan Peng, Fei Wang",
        "published": "No Date",
        "citations": 3,
        "abstract": "ABSTRACTArtificial intelligence (AI), especially the most recent large language models (LLMs), holds great promise in healthcare and medicine, with applications spanning from biological scientific discovery and clinical patient care to public health policymaking. However, AI methods have the critical concern for generating factually incorrect or unfaithful information, posing potential long-term risks, ethical issues, and other serious consequences. This review aims to provide a comprehensive overview of the faithfulness problem in existing research on AI in healthcare and medicine, with a focus on the analysis of the causes of unfaithful results, evaluation metrics, and mitigation methods. We systematically reviewed the recent progress in optimizing the factuality across various generative medical AI methods, including knowledge-grounded LLMs, text-to-text generation, multimodality-to-text generation, and automatic medical fact-checking tasks. We further discussed the challenges and opportunities of ensuring the faithfulness of AI-generated information in these applications. We expect that this review will assist researchers and practitioners in understanding the faithfulness problem in AI-generated information in healthcare and medicine, as well as the recent progress and challenges in related research. Our review can also serve as a guide for researchers and practitioners who are interested in applying AI in medicine and healthcare.",
        "link": "http://dx.doi.org/10.1101/2023.04.18.23288752"
    },
    {
        "id": 11131,
        "title": "Taxonomy-Based Automation of Prior Approval using Clinical Guidelines",
        "authors": "Saranya Krishnamoorthy,  , Ayush Singh,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_065"
    },
    {
        "id": 11132,
        "title": "Hindi to Dravidian Language Neural Machine Translation Systems",
        "authors": "Vijay Sundar Ram,  , Sobha Lalitha Devi,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_121"
    },
    {
        "id": 11133,
        "title": "Building DNN acoustic models for large vocabulary speech recognition",
        "authors": "Andrew L. Maas, Peng Qi, Ziang Xie, Awni Y. Hannun, Christopher T. Lengerich, Daniel Jurafsky, Andrew Y. Ng",
        "published": "2017-1",
        "citations": 79,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2016.06.007"
    },
    {
        "id": 11134,
        "title": "Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents",
        "authors": "Weiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang Wang, Pengjie Ren, Zhumin Chen, Dawei Yin, Zhaochun Ren",
        "published": "2023",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.923"
    },
    {
        "id": 11135,
        "title": "Efficient Large Scale Semi-Supervised Learning for CTC Based Acoustic Models",
        "authors": "Prakhar Swarup, Debmalya Chakrabarty, Ashtosh Sapru, Hitesh Tulsiani, Harish Arsikere, Sri Garimella",
        "published": "2021-1-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt48900.2021.9383536"
    },
    {
        "id": 11136,
        "title": "Towards Improved Scientific Knowledge Proliferation: Leveraging Large Language Models on the Traditional Scientific Writing Workflow",
        "authors": "Tyler Procko, Alexandra Davidoff, Timothy Elvira, Omar Ochoa",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4594836"
    },
    {
        "id": 11137,
        "title": "Assessing the Effectiveness of ChatGPT as a Clinical Trainee: A Study on the Diagnostic Value of Large Language Models in a Complex Clinical Environment",
        "authors": "David Craig, Chris Nugent",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractWe tested the performance of Chat Generative Pre-trained Transformer (ChatGPT) in the role of a trainee clinician (Specialist Registrar or Resident) undergoing direct assessment by a human supervising specialist clinician (Consultant or Attending). The session consisted of a hospital ward round scenario presented to three versions of ChatGPT, namely OpenAI ChatGPT-3.5, Bing ChatGPT-4 and OpenAI ChatGPT-4. A specific test of memory and context was included via an end-of-teaching educator feedback exercise. Only OpenAI ChatGPT-4 provided responses comparable to the standard a trainee might offer during progress towards completion of training and specialist accreditation. Bing ChatGPT-4 responded with several clinically dubious statements, often in a repetitive and detached way, and was unable to retain awareness of the purpose of the session and the identities of participants.",
        "link": "http://dx.doi.org/10.1101/2023.11.21.23298849"
    },
    {
        "id": 11138,
        "title": "Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning",
        "authors": "Liangming Pan, Alon Albalak, Xinyi Wang, William Wang",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.248"
    },
    {
        "id": 11139,
        "title": "An Analysis of Large Language Models and LangChain in Mathematics Education",
        "authors": "Fatih Soygazi, Damla Oguz",
        "published": "2023-10-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3633598.3633614"
    },
    {
        "id": 11140,
        "title": "Welcome to Ultaki: Exploring the Relevance of Large Language Models for Accurate Behavioral Simulation in Energy Transition",
        "authors": "Mehdi Mounsif, Benjamin Jauvion, Fabien Medard",
        "published": "2023-11-25",
        "citations": 0,
        "abstract": "The global focus on greenhouse gases reduction places a major role on electrification of systems. While replacing fossil fuels with clean electricity is extremely appealing, the non-negligible costs associated with extracting and transforming mineral resources into renewable energy pro- duction systems as well as their world-wide deployment must be considered. As such, this study presents a novel approach to integrating Large Language Models (LLMs) into energy demand simulation, addressing the complexities and variability of human behavior as well as its profound impact on energy systems. By leveraging LLMs to impersonate diverse characters with distinct psychological traits, we explore the plausibility of reactions, prompt sensitivity, and second-order dynamics through individual agent experiments. Furthermore, we introduce a framework for multiagent scenario investigation, where a shared limited volume of energy triggers a traumatic event if the average environmental sensitivity drops below a specified threshold. A thorough result analy- sis and discussion concludes this work and sheds light on the relevance and current limitations of integrating modern language models both in complex systems and decision-making processes as well as more specific energy demand estimation the formulation of sustainable energy strategies.",
        "link": "http://dx.doi.org/10.5121/csit.2023.132210"
    },
    {
        "id": 11141,
        "title": "Harnessing the Power of Large Language Models for Empathetic Response Generation: Empirical Investigations and Improvements",
        "authors": "Yushan Qian, Weinan Zhang, Ting Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.433"
    },
    {
        "id": 11142,
        "title": "Knowledge Augmentation and Task Planning in Large Language Models for Dexterous Grasping",
        "authors": "Hui Li, Dang Tran, Xinyu Zhang, Hongsheng He",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/humanoids57100.2023.10375176"
    },
    {
        "id": 11143,
        "title": "The Recent Large Language Models in NLP",
        "authors": "Ngoc Tran Khanh Le, Nadia Hadiprodjo, Hazem El-Alfy, Aziz Kerimzhanov, Avtandil Teshebaev",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iscit57293.2023.10376050"
    },
    {
        "id": 11144,
        "title": "Wenn nichtmenschliche Intelligenz zu völlig neuen Einsichten führt",
        "authors": "Moritz Borchers",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00060-024-9062-7"
    },
    {
        "id": 11145,
        "title": "Evaluating large language models for use in healthcare: A framework for translational value assessment",
        "authors": "Sandeep Reddy",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.imu.2023.101304"
    },
    {
        "id": 11146,
        "title": "PEMANFAATAN LARGE LANGUAGE MODELS CHATGPT-4 UNTUK KONTROL DRONE: STUDI KASUS DJI TELLO",
        "authors": "Edi Sofyan",
        "published": "2024-3-14",
        "citations": 0,
        "abstract": "This study explores the potential of using ChatGPT-4, a Large Language Model (LLM) from OpenAI, for creating flight trajectories for drones. The primary focus is on the DJI Tello drone, which is controlled through Python code to execute various flying commands. Unlike traditional approaches that involve direct programming in Python, this research utilizes ChatGPT-4 to automatically generate Python computer programs capable of instructing the drone. Results indicate ChatGPT-4's intriguing capability to produce the necessary code for flying the drone according to given commands. This suggests that LLMs like ChatGPT-4 can be employed to determine drone flight trajectories using human language, facilitating ease of use compared to traditional computer programming languages. ",
        "link": "http://dx.doi.org/10.56521/teknika.v10i1.1084"
    },
    {
        "id": 11147,
        "title": "Language Models for Computer Science — Introduction to Part II: Language Models for Computer Science",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_others02"
    },
    {
        "id": 11148,
        "title": "ROBBIE: Robust Bias Evaluation of Large Generative Language Models",
        "authors": "David Esiobu, Xiaoqing Tan, Saghar Hosseini, Megan Ung, Yuchen Zhang, Jude Fernandes, Jane Dwivedi-Yu, Eleonora Presani, Adina Williams, Eric Smith",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.230"
    },
    {
        "id": 11149,
        "title": "CoF-CoT: Enhancing Large Language Models with Coarse-to-Fine Chain-of-Thought Prompting for Multi-domain NLU Tasks",
        "authors": "Hoang Nguyen, Ye Liu, Chenwei Zhang, Tao Zhang, Philip Yu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.743"
    },
    {
        "id": 11150,
        "title": "The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models",
        "authors": "Eldar Kurtic, Daniel Campos, Tuan Nguyen, Elias Frantar, Mark Kurtz, Benjamin Fineran, Michael Goin, Dan Alistarh",
        "published": "2022",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.279"
    },
    {
        "id": 11151,
        "title": "Language-controllable programmable metasurface empowered by large language models",
        "authors": "Shengguo Hu, Jiawen Xu, Mingyi Li, Tie Jun Cui, Lianlin Li",
        "published": "2024-1-4",
        "citations": 0,
        "abstract": "Abstract\nProgrammable metasurface has become a prominent tool in various areas including control, communication, computing, and so on, due to its unique capability in the electromagnetic (EM) manipulation. However, it is lack of the intelligence in the sense that it usually requires the manual intervention, and thus makes it hard to behavior as the human process. To endow the programmable metasurface with the intelligence, we here proposed the concept of the language-controllable programmable metasurface for autonomous EM manipulations by exploring the notable capability of large language models (LLMs) in attaining the human-like intelligence. We have established a proof-of-principle system of language-controllable programmable metasurface, where, for illustration, the programmable metasurface is designed to have 32 × 24 binary electronically controllable meta-atoms and work at around 5.5 GHz. In addition, we have constructed a visual-semantic map to facilitate the language-controllable EM manipulation in three-dimensional (3D) physical environments. We have experimentally demonstrated that our language-controllable programmable metasurface is capable of decomposing autonomously an ambiguous task of EM manipulation into a sequence of executable ones and implementing them individually in real-world indoor settings. We expect that the presented strategy could hold promising potential in pushing programmable metasurfaces towards human-level autonomous agents, which are capable of accomplishing the smart EM-involved multi-modality manipulations through self-directed planning and actions.",
        "link": "http://dx.doi.org/10.1515/nanoph-2023-0646"
    },
    {
        "id": 11152,
        "title": "Outlier Suppression+: Accurate quantization of large language models by equivalent and effective shifting and scaling",
        "authors": "Xiuying Wei, Yunchen Zhang, Yuhang Li, Xiangguo Zhang, Ruihao Gong, Jinyang Guo, Xianglong Liu",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.102"
    },
    {
        "id": 11153,
        "title": "Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning",
        "authors": "Ruixiang Tang, Dehan Kong, Longtao Huang, Hui Xue",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.284"
    },
    {
        "id": 11154,
        "title": "GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation",
        "authors": "Kang Min Yoo, Dongju Park, Jaewook Kang, Sang-Woo Lee, Woomyoung Park",
        "published": "2021",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-emnlp.192"
    },
    {
        "id": 11155,
        "title": "Stochastically Pruning Large Language Models Using Sparsity Regularization and Compressive Sensing",
        "authors": "Mohammad Munzurul Islam, Mohammed Alawad",
        "published": "2023-6-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3583781.3590232"
    },
    {
        "id": 11156,
        "title": "Editorial: What Have Large-Language Models and Generative Al Got to\n                    Do With Artificial Life?",
        "authors": "Alan Dorin, Susan Stepney",
        "published": "2023-5-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1162/artl_e_00409"
    },
    {
        "id": 11157,
        "title": "Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models",
        "authors": "Sean Xie, Soroush Vosoughi, Saeed Hassanpour",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.261"
    },
    {
        "id": 11158,
        "title": "From Early Adoption to Ethical Adoption: A Diffusion of Innovation Perspective on ChatGPT and Large Language Models in the Classroom",
        "authors": "Mohammad Imran, Abdur R. Shahid, Minghui Hou, Ahmed Imteaj",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36227/techrxiv.170630660.06963201/v1"
    },
    {
        "id": 11159,
        "title": "Large language models and the future of rheumatology: assessing impact and emerging opportunities",
        "authors": "Insa Mannstadt, Bella Mehta",
        "published": "2024-1",
        "citations": 2,
        "abstract": "\nPurpose of review\nLarge language models (LLMs) have grown rapidly in size and capabilities as more training data and compute power has become available. Since the release of ChatGPT in late 2022, there has been growing interest and exploration around potential applications of LLM technology. Numerous examples and pilot studies demonstrating the capabilities of these tools have emerged across several domains. For rheumatology professionals and patients, LLMs have the potential to transform current practices in medicine.\n\n\nRecent findings\nRecent studies have begun exploring capabilities of LLMs that can assist rheumatologists in clinical practice, research, and medical education, though applications are still emerging. In clinical settings, LLMs have shown promise in assist healthcare professionals enabling more personalized medicine or generating routine documentation like notes and letters. Challenges remain around integrating LLMs into clinical workflows, accuracy of the LLMs and ensuring patient data confidentiality. In research, early experiments demonstrate LLMs can offer analysis of datasets, with quality control as a critical piece. Lastly, LLMs could supplement medical education by providing personalized learning experiences and integration into established curriculums.\n\n\nSummary\nAs these powerful tools continue evolving at a rapid pace, rheumatology professionals should stay informed on how they may impact the field.\n",
        "link": "http://dx.doi.org/10.1097/bor.0000000000000981"
    },
    {
        "id": 11160,
        "title": "Significance of neural phonotactic models for large-scale spoken language identification",
        "authors": "Brij Mohan Lal Srivastava, Hari Vydana, Anil Kumar Vuppala, Manish Shrivastava",
        "published": "2017-5",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2017.7966114"
    },
    {
        "id": 11161,
        "title": "Optimizing Resource Allocation in Cloud for Large-Scale Deep Learning Models in Natural Language Processing",
        "authors": "Et al. Gauri Dhopavkar",
        "published": "2024-1-25",
        "citations": 0,
        "abstract": "The need for big deep learning models in Natural Language Processing (NLP) keeps rising, it's important to find the best way to divide up cloud resources so that they can be used efficiently and at high speeds. This solves the problems that come with setting up and handling large NLP models by suggesting a complete strategy for making the best use of cloud-based platforms' resources. Combining model parallelism, data parallelism, and dynamic scaling methods, the suggested approach spreads the computing load across multiple cloud instances in better way. The framework constantly changes how resources are allocated to handle changes in workload by taking into account the specifics of NLP tasks, such as the need for different model designs and data processing needs. To improve scale and cut down on inference delay, a new auto-scaling method is introduced that lets computing resources be changed automatically based on demand in real time. The framework uses machine learning-based prediction models to figure out what resources will be needed in the future. This lets you make proactive decisions about scaling and keeps you from underusing or overprovisioning resources. It also solves the problem of communication overhead in distributed environments by improving data exchange protocols and using advanced inter-process communication techniques. The results of the experiments show that the proposed framework works well at improving both cost-effectiveness and prediction performance for large-scale NLP models by making the best use of resources. The framework is flexible enough to work with a wide range of natural language processing (NLP) tasks. It makes a useful addition to the efficient use of deep learning models in cloud settings.",
        "link": "http://dx.doi.org/10.52783/jes.652"
    },
    {
        "id": 11162,
        "title": "Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification",
        "authors": "Chia-Yu Hung, Zhiqiang Hu, Yujia Hu, Roy Lee",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.937"
    },
    {
        "id": 11163,
        "title": "Navigating Data Privacy and Analytics: The Role of Large Language Models in Masking conversational data in data platforms",
        "authors": "Mandar Khoje",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icaic60265.2024.10433801"
    },
    {
        "id": 11164,
        "title": "Towards Objective-Tailored Genetic Improvement Through Large Language Models",
        "authors": "Sungmin Kang, Shin Yoo",
        "published": "2023-5",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/gi59320.2023.00013"
    },
    {
        "id": 11165,
        "title": "Application of Pretrained Large Language Models in Embodied Artificial Intelligence",
        "authors": "A. K. Kovalev, A. I. Panov",
        "published": "2022-12",
        "citations": 7,
        "abstract": "AbstractA feature of tasks in embodied artificial intelligence is that a query to an intelligent agent is formulated in natural language. As a result, natural language processing methods have to be used to transform the query into a format convenient for generating an appropriate action plan. There are two basic approaches to the solution of this problem. One is based on specialized models trained with particular instances of instructions translated into agent-executable format. The other approach relies on the ability of large language models trained with a large amount of unlabeled data to store common sense knowledge. As a result, such models can be used to generate an agent’s action plan in natural language without preliminary learning. This paper provides a detailed review of models based on the second approach as applied to embodied artificial intelligence tasks.",
        "link": "http://dx.doi.org/10.1134/s1064562422060138"
    },
    {
        "id": 11166,
        "title": "Leveraging large language models for predictive chemistry",
        "authors": "Kevin Maik Jablonka, Philippe Schwaller, Andres Ortega-Guerrero, Berend Smit",
        "published": "2024-2-6",
        "citations": 2,
        "abstract": "AbstractMachine learning has transformed many fields and has recently found applications in chemistry and materials science. The small datasets commonly found in chemistry sparked the development of sophisticated machine learning approaches that incorporate chemical knowledge for each application and, therefore, require specialized expertise to develop. Here we show that GPT-3, a large language model trained on vast amounts of text extracted from the Internet, can easily be adapted to solve various tasks in chemistry and materials science by fine-tuning it to answer chemical questions in natural language with the correct answer. We compared this approach with dedicated machine learning models for many applications spanning the properties of molecules and materials to the yield of chemical reactions. Surprisingly, our fine-tuned version of GPT-3 can perform comparably to or even outperform conventional machine learning techniques, in particular in the low-data limit. In addition, we can perform inverse design by simply inverting the questions. The ease of use and high performance, especially for small datasets, can impact the fundamental approach to using machine learning in the chemical and material sciences. In addition to a literature search, querying a pre-trained large language model might become a routine way to bootstrap a project by leveraging the collective knowledge encoded in these foundation models, or to provide a baseline for predictive tasks.",
        "link": "http://dx.doi.org/10.1038/s42256-023-00788-1"
    },
    {
        "id": 11167,
        "title": "The Invisible Embedded “Values” Within Large Language Models: Implications for Mental Health Use (Preprint)",
        "authors": "Dorit Hadar-Shoval, Kfir Asraf, Yonathan Mizrachi, Yuval Haber, Zohar Elyoseph",
        "published": "2024-1-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2196/55988"
    },
    {
        "id": 11168,
        "title": "Towards Trustworthy Large Language Models",
        "authors": "Sanmi Koyejo, Bo Li",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3616855.3636454"
    },
    {
        "id": 11169,
        "title": "Large language models propagate race-based medicine",
        "authors": "Jesutofunmi A. Omiye, Jenna C. Lester, Simon Spichak, Veronica Rotemberg, Roxana Daneshjou",
        "published": "2023-10-20",
        "citations": 18,
        "abstract": "AbstractLarge language models (LLMs) are being integrated into healthcare systems; but these models may recapitulate harmful, race-based medicine. The objective of this study is to assess whether four commercially available large language models (LLMs) propagate harmful, inaccurate, race-based content when responding to eight different scenarios that check for race-based medicine or widespread misconceptions around race. Questions were derived from discussions among four physician experts and prior work on race-based medical misconceptions believed by medical trainees. We assessed four large language models with nine different questions that were interrogated five times each with a total of 45 responses per model. All models had examples of perpetuating race-based medicine in their responses. Models were not always consistent in their responses when asked the same question repeatedly. LLMs are being proposed for use in the healthcare setting, with some models already connecting to electronic health record systems. However, this study shows that based on our findings, these LLMs could potentially cause harm by perpetuating debunked, racist ideas.",
        "link": "http://dx.doi.org/10.1038/s41746-023-00939-z"
    },
    {
        "id": 11170,
        "title": "Postscript",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7208/chicago/9780226829845.003.0013"
    },
    {
        "id": 11171,
        "title": "Error Detection in Large-Scale Natural Language Understanding Systems Using Transformer Models",
        "authors": "Rakesh Chada, Pradeep Natarajan, Darshan Fofadiya, Prathap Ramachandra",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-acl.44"
    },
    {
        "id": 11172,
        "title": "Artificial Intelligence Research in Business and Management: A Literature Review Leveraging Machine Learning and Large Language Models",
        "authors": "Nazmiye Guler, Samuel Kirshner, Richard Vidgen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4540834"
    },
    {
        "id": 11173,
        "title": "Meta-Learning the Difference: Preparing Large Language Models for Efficient Adaptation",
        "authors": "Zejiang Hou, Julian Salazar, George Polovets",
        "published": "2022-11-22",
        "citations": 2,
        "abstract": "Abstract\nLarge pretrained language models (PLMs) are often domain- or task-adapted via finetuning or prompting. Finetuning requires modifying all of the parameters and having enough data to avoid overfitting while prompting requires no training and few examples but limits performance. Instead, we prepare PLMs for data- and parameter-efficient adaptation by learning to learn the difference between general and adapted PLMs. This difference is expressed in terms of model weights and sublayer structure through our proposed dynamic low-rank reparameterization and learned architecture controller. Experiments on few-shot dialogue completion, low-resource abstractive summarization, and multi-domain language modeling show improvements in adaptation time and performance over direct finetuning or preparation via domain-adaptive pretraining. Ablations show our task-adaptive reparameterization (TARP) and model search (TAMS) components individually improve on other parameter-efficient transfer like adapters and structure-learning methods like learned sparsification.",
        "link": "http://dx.doi.org/10.1162/tacl_a_00517"
    },
    {
        "id": 11174,
        "title": "Large language models and rheumatology: a comparative evaluation",
        "authors": "Vincenzo Venerito, Darshan Puttaswamy, Florenzo Iannone, Latika Gupta",
        "published": "2023-10",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s2665-9913(23)00216-3"
    },
    {
        "id": 11175,
        "title": "Hallucination or Confabulation? Neuroanatomy as metaphor in Large Language Models",
        "authors": "Andrew L. Smith, Felix Greaves, Trishan Panch",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1371/journal.pdig.0000388"
    },
    {
        "id": 11176,
        "title": "Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers",
        "authors": "Wencong You, Zayd Hammoudeh, Daniel Lowd",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.833"
    },
    {
        "id": 11177,
        "title": "A Novel Approach to Nursing Clinical Intelligent Decision-Making: Integration of Large Language Models and Local Knowledge Bases",
        "authors": "Liping Xiong, Qiqiao Zeng, Wuhong Deng, Weixiang Luo, Ronghui Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nObjective: The purpose of this study is to develop a novel method for nursing clinical intelligent decision-making that integrates Large Language Models (LLMs) with local knowledge bases, aiming to enhance the accuracy and reliability of clinical decisions in nursing.\nMethods: Initially, we established a multi-level classified nursing knowledge base by collecting textual knowledge from public knowledge platforms and integrating selected contents from peer-reviewed nursing journals, academic papers, textbooks, and nursing standards. Subsequently, data knowledge was collected from clinical records and normalized to form a data knowledge base. Additionally, we proposed a nursing clinical decision-making system paradigm based on prompt learning in “LLMs + professional knowledge bases”, addressing the issue of catastrophic forgetting common in domain-specific question-answering systems due to the “data + fine-tuning” paradigm.\nResults: Utilizing the aforementioned methodology, we successfully constructed a nursing knowledge base and developed a decision-making system. The evaluation results demonstrate that this system possesses high accuracy, logical coherence, completeness, and readability in clinical nursing decisions. It enhances the convenience and efficiency of medical staff in clinical decision-making and effectively improves the applicability of LLMs in the field of nursing.\nConclusion: This study validates the effectiveness of the approach that combines LLMs with local knowledge bases in nursing clinical decision-making. This method not only enhances the accuracy of decisions but also provides efficient decision support in resource-limited scenarios. In the future, this approach is expected to be applied in a broader range of nursing settings, offering new perspectives and tools for clinical nursing practice and research.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3756467/v1"
    },
    {
        "id": 11178,
        "title": "How Large Language Models Perform on the United States Medical Licensing Examination: A Systematic Review",
        "authors": "Dana Brin, Vera Sorin, Eli Konen, Girish Nadkarni, Benjamin S Glicksberg, Eyal Klang",
        "published": "No Date",
        "citations": 5,
        "abstract": "ABSTRACTObjectiveThe United States Medical Licensing Examination (USMLE) assesses physicians’ competency and passing is a requirement to practice medicine in the U.S. With the emergence of large language models (LLMs) like ChatGPT and GPT-4, understanding their performance on these exams illuminates their potential in medical education and healthcare.Materials and MethodsA literature search following the 2020 PRISMA guidelines was conducted, focusing on studies using official USMLE questions and publicly available LLMs.ResultsThree relevant studies were found, with GPT-4 showcasing the highest accuracy rates of 80-90% on the USMLE. Open-ended prompts typically outperformed multiple-choice ones, with 5-shot prompting slightly edging out zero-shot.ConclusionLLMs, especially GPT-4, display proficiency in tackling USMLE-standard questions. While the USMLE is a structured evaluation tool, it may not fully capture the expansive capabilities and limitations of LLMs in medical scenarios. As AI integrates further into healthcare, ongoing assessments against trusted benchmarks are essential.",
        "link": "http://dx.doi.org/10.1101/2023.09.03.23294842"
    },
    {
        "id": 11179,
        "title": "Can We Use Large Language Models for the Use of Contrast Media in Radiology?",
        "authors": "Esat Kaba, Thomas J. Vogl",
        "published": "2024-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.acra.2023.11.034"
    },
    {
        "id": 11180,
        "title": "DepoScope: accurate phage depolymerase annotation and domain delineation using large language models",
        "authors": "Robby Concha-Eloko, Michiel Stock, Bernard De Baets, Yves Briers, Rafael Sanjuan, Pilar Domingo-Calap, Dimitri Boeckaerts",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractBacteriophages (phages) are viruses that infect bacteria. Many of them produce specific enzymes called depolymerases to break down external polysaccharide structures. Accurate annotation and domain identification of these depolymerases are challenging due to their inherent sequence diversity. Hence, we present DepoScope, a machine learning tool that combines a fine-tuned ESM-2 model with a convolutional neural network to precisely identify depolymerase sequences and their enzymatic domains. To accomplish this, we curated a dataset from the INPHARED phage genome database, created a polysaccharide-degrading domain database, and applied sequential filters to construct a high-quality dataset, which are subsequently used to train DepoScope. Our work is the first approach that combines sequence-level predictions with amino-acid-level predictions for an accurate depolymerase detection and functional domain identification. In that way, we believe that DepoScope can enhance our understanding of phage-host interactions at the level of depolymerases.Summary with Key MessagesPhage depolymerases are proteins that play a crucial role in the first step of a phage replication cycle. As a result, they are both important from a biological perspective and a therapeutical perspective.Current methods to accurately annotate phage depolymerases and their associated enzymatic domains remains challenging due to their inherent high sequence diversity.We have developed DepoScope, a language-based artificial intelligence model that can accurately identify phage depolymerases and their specific enzymatic domains.We provide full public access to the DepoScope code and database to give broad access to the research community and promote further research.",
        "link": "http://dx.doi.org/10.1101/2024.01.15.575807"
    },
    {
        "id": 11181,
        "title": "My Learnings from Allowing Large Language Models in Introductory Computer Science Classes",
        "authors": "Rasika Bhalerao",
        "published": "2024-3-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626253.3635511"
    },
    {
        "id": 11182,
        "title": "Intelligent Assisted Decision-Making Framework for Domain-Specific Advice Using Large- Language Models",
        "authors": "Yan Zhong, Kun Lan, Simon Fong, Dennis Wong",
        "published": "2023-11-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ddp60485.2023.00015"
    },
    {
        "id": 11183,
        "title": "Integrating Automated Knowledge Extraction with Large Language Models for Explainable Medical Decision-Making",
        "authors": "Haodi Zhang, Jiahong Li, Yichi Wang, Yuanfeng Song",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bibm58861.2023.10385557"
    },
    {
        "id": 11184,
        "title": "Matching Pairs: Attributing Fine-Tuned Models to their Pre-Trained Large Language Models",
        "authors": "Myles Foley, Ambrish Rawat, Taesung Lee, Yufang Hou, Gabriele Picco, Giulio Zizzo",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.410"
    },
    {
        "id": 11185,
        "title": "An Efficient Plug-and-Play Post-Training Pruning Strategy in Large Language Models",
        "authors": "Yingtao Zhang, Haoli Bai, Haokun Lin, Jialin Zhao, Lu Hou, Carlo Vittorio Cannistraci",
        "published": "No Date",
        "citations": 0,
        "abstract": "With the rapid growth of large language models (LLMs), there is increasing demand for memory and computation for LLMs. Recent efforts on post-training pruning of LLMs aim to reduce the model size and computation, yet the performance is still sub-optimal. In this paper, we present a plug-and-play solution for post-training pruning of LLMs. The proposed solution has two innovative components: 1) **Relative Importance and Activations** (RIA), a new pruning metric that jointly considers the weight and activations efficiently on LLMs; and 2) **Channel Permutation**, a new approach to maximally preserve important weights under N:M sparsity. The proposed two components can be readily combined to further enhance the N:M structuredly pruned LLMs. Our empirical experiments show that RIA alone can already surpass all existing post-training pruning methods on prevalent LLMs, e.g., LLaMA ranging from 7B to 65B. Furthermore, N:M structured pruning with channel permutation can even outperform the original LLaMA2 70B on zero-shot tasks, together with practical speed-up on specific hardware.",
        "link": "http://dx.doi.org/10.20944/preprints202310.1487.v1"
    },
    {
        "id": 11186,
        "title": "Answering Clean Tech Questions with Large Language Models",
        "authors": "Lauren Stagnol, Amina Cherief, Zakaria Farah, Th&eacute;o Le Guenedal, Sofia Sakout, Takaya Sekine",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4663447"
    },
    {
        "id": 11187,
        "title": "Large Language Models and Simple, Stupid Bugs",
        "authors": "Kevin Jesse, Toufique Ahmed, Premkumar T. Devanbu, Emily Morgan",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/msr59073.2023.00082"
    },
    {
        "id": 11188,
        "title": "Author response for \"Large-Scale Text Analysis Using Generative Language Models: A Case Study in Discovering Public Value Expressions in AI Patents\"",
        "authors": " Pelaez, Sergio,  Verma, Gaurav,  Ribeiro, Barbara,  Shapira, Philip",
        "published": "2023-9-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1162/qss_a_00285/v2/response1"
    },
    {
        "id": 11189,
        "title": "Comment on: AI am a rheumatologist: a practical primer to large language models for rheumatologists. Second reply",
        "authors": "Vincenzo Venerito, Emre Bilgin, Florenzo Iannone, Sedat Kiraz",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/rheumatology/kead657"
    },
    {
        "id": 11190,
        "title": "TeamShakespeare at SemEval-2023 Task 6: Understand Legal Documents with Contextualized Large Language Models",
        "authors": "Xin Jin, Yuchen Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.semeval-1.72"
    },
    {
        "id": 11191,
        "title": "AugESC: Dialogue Augmentation with Large Language Models for Emotional Support Conversation",
        "authors": "Chujie Zheng, Sahand Sabour, Jiaxin Wen, Zheng Zhang, Minlie Huang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.99"
    },
    {
        "id": 11192,
        "title": "Can Large Language Models Predict Antimicrobial Peptide Activity and Toxicity?",
        "authors": "Markus Orsi, Jean-Louis Reymond",
        "published": "No Date",
        "citations": 0,
        "abstract": "Antimicrobial peptides (AMPs) are naturally occurring or designed peptides up to a few tens of amino acids which may help address the antimicrobial resistance crisis. However, their clinical development is limited by toxicity to human cells, a parameter which is very difficult to control. Given the similarity between peptide sequences and words, large language models (LLMs) might be able to predict AMP activity and toxicity. To test this hypothesis, we fine-tuned LLMs using data from the Database of Antimicrobial Activity and Structure of Peptides (DBAASP). GPT-3 performed well but not reproducibly for activity prediction and hemolysis, taken as a proxy for toxicity. The later GPT-3.5 performed more poorly and was surpassed by recurrent neural networks (RNN) trained on sequence-activity data or support vector machines (SVM) trained on MAP4C molecular fingerprint-activity data. These simpler models are therefore recommended, although the rapid evolution of LLMs warrants future re-evaluation of their prediction abilities.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2023-74041-v2"
    },
    {
        "id": 11193,
        "title": "Wenn nichtmenschliche Intelligenz zu völlig neuen Einsichten führt",
        "authors": "Moritz Borchers",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s15013-023-5700-1"
    },
    {
        "id": 11194,
        "title": "A Multi-dimensional Generic Evaluation Framework for the Security of Large Language Models",
        "authors": "Zhiyin Yu",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icbaie59714.2023.10281279"
    },
    {
        "id": 11195,
        "title": "Can large language models reason about medical questions?",
        "authors": "Valentin Liévin, Christoffer Egeberg Hother, Andreas Geert Motzfeldt, Ole Winther",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patter.2024.100943"
    },
    {
        "id": 11196,
        "title": "Local climate services for all, courtesy of large language models",
        "authors": "Nikolay Koldunov, Thomas Jung",
        "published": "2024-1-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s43247-023-01199-1"
    },
    {
        "id": 11197,
        "title": "Fluid Transformers and Creative Analogies: Exploring Large Language Models’ Capacity for Augmenting Cross-Domain Analogical Creativity",
        "authors": "Zijian Ding, Arvind Srinivasan, Stephen Macneil, Joel Chan",
        "published": "2023-6-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3591196.3593516"
    },
    {
        "id": 11198,
        "title": "Guidelines for Use of Large Language Models by Authors, Reviewers,                     and Editors: Considerations for Imaging Journals",
        "authors": "Linda Moy",
        "published": "2023-10-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1148/radiol.239024"
    },
    {
        "id": 11199,
        "title": "Web Content Filtering Through Knowledge Distillation of Large Language Models",
        "authors": "Tamás Vörös, Sean Paul Bergeron, Konstantin Berlin",
        "published": "2023-10-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wi-iat59888.2023.00058"
    },
    {
        "id": 11200,
        "title": "Large Language Models in der Medizin",
        "authors": "Moritz Borchers",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00092-023-6207-8"
    },
    {
        "id": 11201,
        "title": "Large Language Models and Simple, Stupid Bugs",
        "authors": "Kevin Jesse, Toufique Ahmed, Premkumar T. Devanbu, Emily Morgan",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/msr59073.2023.00082"
    },
    {
        "id": 11202,
        "title": "Author response for \"Large-Scale Text Analysis Using Generative Language Models: A Case Study in Discovering Public Value Expressions in AI Patents\"",
        "authors": " Pelaez, Sergio,  Verma, Gaurav,  Ribeiro, Barbara,  Shapira, Philip",
        "published": "2023-9-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1162/qss_a_00285/v2/response1"
    },
    {
        "id": 11203,
        "title": "Comment on: AI am a rheumatologist: a practical primer to large language models for rheumatologists. Second reply",
        "authors": "Vincenzo Venerito, Emre Bilgin, Florenzo Iannone, Sedat Kiraz",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/rheumatology/kead657"
    },
    {
        "id": 11204,
        "title": "TeamShakespeare at SemEval-2023 Task 6: Understand Legal Documents with Contextualized Large Language Models",
        "authors": "Xin Jin, Yuchen Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.semeval-1.72"
    },
    {
        "id": 11205,
        "title": "AugESC: Dialogue Augmentation with Large Language Models for Emotional Support Conversation",
        "authors": "Chujie Zheng, Sahand Sabour, Jiaxin Wen, Zheng Zhang, Minlie Huang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.99"
    },
    {
        "id": 11206,
        "title": "Can Large Language Models Predict Antimicrobial Peptide Activity and Toxicity?",
        "authors": "Markus Orsi, Jean-Louis Reymond",
        "published": "No Date",
        "citations": 0,
        "abstract": "Antimicrobial peptides (AMPs) are naturally occurring or designed peptides up to a few tens of amino acids which may help address the antimicrobial resistance crisis. However, their clinical development is limited by toxicity to human cells, a parameter which is very difficult to control. Given the similarity between peptide sequences and words, large language models (LLMs) might be able to predict AMP activity and toxicity. To test this hypothesis, we fine-tuned LLMs using data from the Database of Antimicrobial Activity and Structure of Peptides (DBAASP). GPT-3 performed well but not reproducibly for activity prediction and hemolysis, taken as a proxy for toxicity. The later GPT-3.5 performed more poorly and was surpassed by recurrent neural networks (RNN) trained on sequence-activity data or support vector machines (SVM) trained on MAP4C molecular fingerprint-activity data. These simpler models are therefore recommended, although the rapid evolution of LLMs warrants future re-evaluation of their prediction abilities.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2023-74041-v2"
    },
    {
        "id": 11207,
        "title": "Wenn nichtmenschliche Intelligenz zu völlig neuen Einsichten führt",
        "authors": "Moritz Borchers",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s15013-023-5700-1"
    },
    {
        "id": 11208,
        "title": "A Multi-dimensional Generic Evaluation Framework for the Security of Large Language Models",
        "authors": "Zhiyin Yu",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icbaie59714.2023.10281279"
    },
    {
        "id": 11209,
        "title": "Can large language models reason about medical questions?",
        "authors": "Valentin Liévin, Christoffer Egeberg Hother, Andreas Geert Motzfeldt, Ole Winther",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patter.2024.100943"
    },
    {
        "id": 11210,
        "title": "Local climate services for all, courtesy of large language models",
        "authors": "Nikolay Koldunov, Thomas Jung",
        "published": "2024-1-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s43247-023-01199-1"
    },
    {
        "id": 11211,
        "title": "Fluid Transformers and Creative Analogies: Exploring Large Language Models’ Capacity for Augmenting Cross-Domain Analogical Creativity",
        "authors": "Zijian Ding, Arvind Srinivasan, Stephen Macneil, Joel Chan",
        "published": "2023-6-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3591196.3593516"
    },
    {
        "id": 11212,
        "title": "Guidelines for Use of Large Language Models by Authors, Reviewers,                     and Editors: Considerations for Imaging Journals",
        "authors": "Linda Moy",
        "published": "2023-10-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1148/radiol.239024"
    },
    {
        "id": 11213,
        "title": "Web Content Filtering Through Knowledge Distillation of Large Language Models",
        "authors": "Tamás Vörös, Sean Paul Bergeron, Konstantin Berlin",
        "published": "2023-10-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wi-iat59888.2023.00058"
    },
    {
        "id": 11214,
        "title": "Large Language Models in der Medizin",
        "authors": "Moritz Borchers",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00092-023-6207-8"
    },
    {
        "id": 11215,
        "title": "A Generative AI-driven Application: Use of Large Language Models for Traffic Scenario Generation",
        "authors": "Çağrı Güzay, Ege Özdemir, Yahya Kara",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/eleco60389.2023.10415934"
    },
    {
        "id": 11216,
        "title": "Metamorphic Malware Evolution: The Potential and Peril of Large Language Models",
        "authors": "Pooria Madani",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tps-isa58951.2023.00019"
    },
    {
        "id": 11217,
        "title": "The wide range of opportunities for large language models such as ChatGPT in rheumatology",
        "authors": "Thomas Hügle",
        "published": "2023-4",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1136/rmdopen-2023-003105"
    },
    {
        "id": 11218,
        "title": "The imperative for regulatory oversight of large language models (or generative AI) in healthcare",
        "authors": "Bertalan Meskó, Eric J. Topol",
        "published": "2023-7-6",
        "citations": 103,
        "abstract": "AbstractThe rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality.",
        "link": "http://dx.doi.org/10.1038/s41746-023-00873-0"
    },
    {
        "id": 11219,
        "title": "Improving Translation Quality for Low-Resource Inuktitut with Various Preprocessing Techniques",
        "authors": "Mathias Hans Erik Stenlund,  , Matilde Nanni, Micaella Bruton, Meriem Beloucif,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_053"
    },
    {
        "id": 11220,
        "title": "Exploring Amharic Hate Speech Data Collection and Classification Approaches",
        "authors": "Abinew Ali Ayele,  , Seid Muhie Yimam, Tadesse Destaw Belay, Chris Biemann,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_006"
    },
    {
        "id": 11221,
        "title": "Automated Domain Modeling with Large Language Models: A Comparative Study",
        "authors": "Kua Chen, Yujing Yang, Boqi Chen, José Antonio Hernández López, Gunter Mussbacher, Dániel Varró",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/models58315.2023.00037"
    },
    {
        "id": 11222,
        "title": "An Architecture for Accelerated Large-Scale Inference of Transformer-Based Language Models",
        "authors": "Amir Ganiev, Colton Chapin, Anderson De Andrade, Chen Liu",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-industry.21"
    },
    {
        "id": 11223,
        "title": "Investigating Table-to-Text Generation Capabilities of Large Language Models in Real-World Information Seeking Scenarios",
        "authors": "Yilun Zhao, Haowei Zhang, Shengyun Si, Linyong Nan, Xiangru Tang, Arman Cohan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-industry.17"
    },
    {
        "id": 11224,
        "title": "Self-Criticism: Aligning Large Language Models with their Understanding of Helpfulness, Honesty, and Harmlessness",
        "authors": "Xiaoyu Tan, Shaojie Shi, Xihe Qiu, Chao Qu, Zhenting Qi, Yinghui Xu, Yuan Qi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-industry.62"
    },
    {
        "id": 11225,
        "title": "The Curious Case of Hallucinatory (Un)answerability: Finding Truths in the Hidden States of Over-Confident Large Language Models",
        "authors": "Aviv Slobodkin, Omer Goldman, Avi Caciularu, Ido Dagan, Shauli Ravfogel",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.220"
    },
    {
        "id": 11226,
        "title": "The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values",
        "authors": "Hannah Kirk, Andrew Bean, Bertie Vidgen, Paul Rottger, Scott Hale",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.148"
    },
    {
        "id": 11227,
        "title": "UNIREX: A Unified Learning Framework for Language Model Rationale Extraction",
        "authors": "Aaron Chan, Maziar Sanjabi, Lambert Mathias, Liang Tan, Shaoliang Nie, Xiaochang Peng, Xiang Ren, Hamed Firooz",
        "published": "2022",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bigscience-1.5"
    },
    {
        "id": 11228,
        "title": "Data Augmentation with Large Language Models for Vietnamese Abstractive Text Summarization",
        "authors": "Huy M. Le, Vy T. Luong, Ngoc Hoang Luong",
        "published": "2023-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mapr59823.2023.10288906"
    },
    {
        "id": 11229,
        "title": "Intelligent agents driven data analytics using Large Language Models",
        "authors": "Tushar Chugh, Kanishka Tyagi, Rolly Seth, Pranesh Srinivasan",
        "published": "2023-11-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icoabcd59879.2023.10390973"
    },
    {
        "id": 11230,
        "title": "LTRC_IIITH’s 2023 Submission for Prompting Large Language Models as Explainable Metrics Task",
        "authors": "Pavan Baswani, Ananya Mukherjee, Manish Shrivastava",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.eval4nlp-1.13"
    },
    {
        "id": 11231,
        "title": "Do Large Language Models Know What They Don’t Know?",
        "authors": "Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu, Xipeng Qiu, Xuanjing Huang",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.551"
    },
    {
        "id": 11232,
        "title": "Best practices for implementing ChatGPT, large language models, and artificial intelligence in qualitative and survey-based research",
        "authors": "Jonathan Kantor",
        "published": "2024-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jdin.2023.10.001"
    },
    {
        "id": 11233,
        "title": "CUCFATE Frameworks for Safe and Effective Large Language Models in Medical Education: Using Qualitative Methods (Preprint)",
        "authors": "Majdi Quttainah, Vinaytosh Mishra, Somayya Madakam, Yotam Lurie, Shlomo Mark",
        "published": "2023-8-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2196/51834"
    },
    {
        "id": 11234,
        "title": "Towards A Holistic Landscape of Situated Theory of Mind in Large Language Models",
        "authors": "Ziqiao Ma, Jacob Sansom, Run Peng, Joyce Chai",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.72"
    },
    {
        "id": 11235,
        "title": "Can Large Language Models Beat Wall Street? Unveiling the Potential of AI in Stock Selection",
        "authors": "Georgios Fatouros, Konstantinos Metaxas, John Soldatos, Dimosthenis Kyriazis",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4693849"
    },
    {
        "id": 11236,
        "title": "The Performance of Large Language Models on Quantitative and Verbal Ability Tests: Initial Evidence and Implications for Unproctored High-stakes Testing",
        "authors": "Louis Hickman, Patrick Damien Dunlop, Jasper Leo Wolf",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract. Unproctored assessments are widely used in pre-employment assessment. However, the recent emergence of widely accessible large language models (LLMs) poses challenges for unproctored personnel assessments, given that applicants may use them to artificially inflate their scores beyond their true abilities. This may be particularly concerning in cognitive ability testing, which is widely used and is less fakeable by humans than personality tests. Thus, this study compares the performance of LLMs on two common types of cognitive tests: quantitative ability and verbal ability. The particular tests investigated are used in real-world, high-stakes selection. We also examine the performance of the LLMs across different test formats (i.e., open-ended vs. multiple choice). Further, we contrast the performance of two LLMs (GPT 3.5 and GPT 4) across multiple prompt approaches and temperature settings. We find that the LLMs score much better, in terms of percentile scores, on the verbal ability test than the quantitative ability test, even when accounting for the test format. GPT 4 outperforms GPT 3.5 across both types of tests. Notably, although prompt approaches and temperature settings do affect LLM test performance, the effects are minor relative to differences across tests and language models. We provide recommendations for securing pre-employment testing against LLM influences. Additionally, we call for rigorous research investigating the prevalence of LLM usage in pre-employment testing as well as on how LLM usage influences selection test validity.",
        "link": "http://dx.doi.org/10.31234/osf.io/9cs23"
    },
    {
        "id": 11237,
        "title": "Semantic Compression with Large Language Models",
        "authors": "Henry Gilbert, Michael Sandborn, Douglas C. Schmidt, Jesse Spencer-Smith, Jules White",
        "published": "2023-11-21",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/snams60348.2023.10375400"
    },
    {
        "id": 11238,
        "title": "The Utility of ChatGPT as an Example of Large Language Models in Healthcare Education, Research and Practice: Systematic Review on the Future Perspectives and Potential Limitations",
        "authors": "Malik Sallam",
        "published": "No Date",
        "citations": 57,
        "abstract": "AbstractAn artificial intelligence (AI)-based conversational large language model (LLM) was launched in November 2022 namely, “ChatGPT”. Despite the wide array of potential applications of LLMs in healthcare education, research and practice, several valid concerns were raised. The current systematic review aimed to investigate the possible utility of ChatGPT and to highlight its limitations in healthcare education, research and practice. Using the PRIMSA guidelines, a systematic search was conducted to retrieve English records in PubMed/MEDLINE and Google Scholar under the term “ChatGPT”. Eligibility criteria included the published research or preprints of any type that discussed ChatGPT in the context of healthcare education, research and practice. A total of 280 records were identified, and following full screening, a total of 60 records were eligible for inclusion. Benefits/applications of ChatGPT were cited in 51/60 (85.0%) records with the most common being the utility in scientific writing followed by benefits in healthcare research (efficient analysis of massive datasets, code generation and rapid concise literature reviews besides utility in drug discovery and development). Benefits in healthcare practice included cost saving, documentation, personalized medicine and improved health literacy. Concerns/possible risks of ChatGPT use were expressed in 58/60 (96.7%) records with the most common being the ethical issues including the risk of bias, plagiarism, copyright issues, transparency issues, legal issues, lack of originality, incorrect responses, limited knowledge, and inaccurate citations. Despite the promising applications of ChatGPT which can result in paradigm shifts in healthcare education, research and practice, the embrace of this application should be done with extreme caution. Specific applications of ChatGPT in health education include the promising utility in personalized learning tools and shift towards more focus on critical thinking and problem-based learning. In healthcare practice, ChatGPT can be valuable for streamlining the workflow and refining personalized medicine. Saving time for the focus on experimental design and enhancing research equity and versatility are the benefits in scientific research. Regarding authorship in scientific articles, as it currently stands, ChatGPT does not qualify to be listed as an author unless the ICMJE/COPE guidelines are revised and amended. An initiative involving all stakeholders involved in healthcare education, research and practice is urgently needed to set a code of ethics and conduct on the responsible practices involving ChatGPT among other LLMs.",
        "link": "http://dx.doi.org/10.1101/2023.02.19.23286155"
    },
    {
        "id": 11239,
        "title": "One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models",
        "authors": "Hang Shao, Bei Liu, Yanmin Qian",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10445737"
    },
    {
        "id": 11240,
        "title": "Large Language Models: A Guide for Radiologists",
        "authors": "Sunkyu Kim, Choong-kun Lee, Seung-seob Kim",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3348/kjr.2023.0997"
    },
    {
        "id": 11241,
        "title": "A Research-Based Guide for the Creation and Deployment of a Low-Resource Machine Translation System",
        "authors": "John E. Ortega,  , Kenneth W. Church,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_088"
    },
    {
        "id": 11242,
        "title": "Human Value Detection from Bilingual Sensory Product Reviews",
        "authors": "Boyu Niu,  , Céline Manetta, Frédérique Segond,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_086"
    },
    {
        "id": 11243,
        "title": "Context Aware Module Selection in Modular Dialog Systems",
        "authors": "Jan Nehring,  , René Marcel Berk, Stefan Hillmann,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_085"
    },
    {
        "id": 11244,
        "title": "Automatically Generating Hindi Wikipedia Pages using Wikidata as a Knowledge Graph: A Domain-Specific Template Sentences Approach",
        "authors": "Aditya Agarwal,  , Radhika Mamidi,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_002"
    },
    {
        "id": 11245,
        "title": "Exploring Deceptive Domain Transfer Strategies: Mitigating the Differences among Deceptive Domains",
        "authors": "Sadat Shahriar,  , Arjun Mukherjee, Omprakash Gnawali,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_115"
    },
    {
        "id": 11246,
        "title": "Multilingual Racial Hate Speech Detection Using Transfer Learning",
        "authors": "Abinew Ali Ayele,  , Skadi Dinter, Seid Muhie Muhie Yimam, Chris Biemann,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_005"
    },
    {
        "id": 11247,
        "title": "Exploring the Landscape of Natural Language Processing Research",
        "authors": "Tim Schopf,  , Karim Arabi, Florian Matthes,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_111"
    },
    {
        "id": 11248,
        "title": "Multi-task Ensemble Learning for Fake Reviews Detection and Helpfulness Prediction: A Novel Approach",
        "authors": "Alimuddin Melleng,  , Anna-Jurek Loughrey, Deepak P,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_078"
    },
    {
        "id": 11249,
        "title": "Harnessing Large Language Models for Cognitive Assistants in Factories",
        "authors": "Samuel Kernan Freire, Mina Foosherian, Chaofan Wang, Evangelos Niforatos",
        "published": "2023-7-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3571884.3604313"
    },
    {
        "id": 11250,
        "title": "Can we utilize Large Language Models (LLMs) to generate useful linguistic corpora? A case study of the word frequency effect in young German readers",
        "authors": "Job Schepens, Nicole Marx, Benjamin Gagl",
        "published": "No Date",
        "citations": 0,
        "abstract": "LLMs for generating linguistic corpora",
        "link": "http://dx.doi.org/10.31234/osf.io/gm9b6"
    },
    {
        "id": 11251,
        "title": "Tutorial on Large Language Models for Recommendation",
        "authors": "Wenyue Hua, Lei Li, Shuyuan Xu, Li Chen, Yongfeng Zhang",
        "published": "2023-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3604915.3609494"
    },
    {
        "id": 11252,
        "title": "MISGENDERED: Limits of Large Language Models in Understanding Pronouns",
        "authors": "Tamanna Hossain, Sunipa Dev, Sameer Singh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.293"
    },
    {
        "id": 11253,
        "title": "The Utility of ChatGPT as an Example of Large Language Models in Healthcare Education, Research and Practice: Systematic Review on the Future Perspectives and Potential Limitations",
        "authors": "Malik Sallam",
        "published": "No Date",
        "citations": 0,
        "abstract": "An artificial intelligence (AI)-based conversational large language model (LLM) was launched in November 2022 namely, “ChatGPT”. Despite the wide array of potential applications of LLMs in healthcare education, research and practice, several valid concerns were raised. The current systematic review aimed to investigate the possible utility of ChatGPT and to highlight its limitations in healthcare education, research and practice. Using the PRIMSA guidelines, a systematic search was conducted to retrieve English records in PubMed/MEDLINE and Google Scholar under the term “ChatGPT”. Eligibility criteria included the published research or preprints of any type that discussed ChatGPT in the context of healthcare education, research and practice. A total of 280 records were identified, and following full screening, a total of 60 records were eligible for inclusion. Benefits/applications of ChatGPT were cited in 51/60 (85.0%) records with the most common being the utility in scientific writing followed by benefits in healthcare research (efficient analysis of massive datasets, code generation and rapid concise literature reviews besides utility in drug discovery and development). Benefits in healthcare practice included cost saving, documentation, personalized medicine and improved health literacy. Concerns/possible risks of ChatGPT use were expressed in 58/60 (96.7%) records with the most common being the ethical issues including the risk of bias, plagiarism, copyright issues, transparency issues, legal issues, lack of originality, incorrect responses, limited knowledge, and inaccurate citations. Despite the promising applications of ChatGPT which can result in paradigm shifts in healthcare education, research and practice, the embrace of this application should be done with extreme caution. Specific applications of ChatGPT in health education include the promising utility in personalized learning tools and shift towards more focus on critical thinking and problem-based learning. In healthcare practice, ChatGPT can be valuable for streamlining the workflow and refining personalized medicine. Saving time for the focus on experimental design and enhancing research equity and versatility are the benefits in scientific research. Regarding authorship in scientific articles, as it currently stands, ChatGPT does not qualify to be listed as an author unless the ICJME/COPE guidelines are revised and amended. An initiative involving all stakeholders involved in healthcare education, research and practice is urgently needed to set a code of ethics and conduct on the responsible practices involving ChatGPT among other LLMs.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0356.v1"
    },
    {
        "id": 11254,
        "title": "A Comparative Study of Large Language Models in Explaining Intrinsically Disordered Proteins",
        "authors": "David Taylor Gonzalez, Mak Djulbegovic, Colin Kim, Michael Antonietti, Gustavo Rosa Gameiro, Vladimir N. Uversky",
        "published": "No Date",
        "citations": 0,
        "abstract": "(1) Background: Artificial Intelligence (AI) models have shown potential in various educational contexts. However, their utility in explaining complex biological phenomena, such as Intrinsically Disordered Proteins (IDPs), requires further exploration. This study empirically evaluated the performance of various Large Language Models (LLMs) in the educational domain of IDPs. (2) Methods: Four LLMs, GPT-3.5, GPT-4, GPT-4 with Browsing, and Google Bard (PaLM 2), were assessed using a set of IDP-related questions. An expert evaluated their responses across five categories: accuracy, relevance, depth of understanding, clarity, and overall quality. Descriptive statistics, ANOVA, and Tukey&#039;s honesty significant difference tests were utilized for analysis. (3) Results: The GPT-4 model consistently outperformed the others across all evaluation categories. Although GPT-4 and GPT-3.5 were not statistically significantly different in performance (p&amp;gt;0.05), GPT-4 was preferred as the best response in 13 out of 15 instances. The AI models with browsing capabilities, GPT-4 with Browsing and Google Bard (PaLM 2) displayed lower performance metrics across the board with statistically significant differences (p&amp;lt;0.0001). (4) Conclusion: Our findings underscore the potential of AI models, particularly LLMs such as GPT-4, in enhancing scientific education, especially in complex domains such as IDPs. Continued innovation and collaboration among AI developers, educators, and researchers are essential to fully harness the potential of AI for enriching scientific education.",
        "link": "http://dx.doi.org/10.20944/preprints202308.1014.v1"
    },
    {
        "id": 11255,
        "title": "Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity",
        "authors": "Gabriel Simmons",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-srw.40"
    },
    {
        "id": 11256,
        "title": "Applications of Artificial Intelligence and Large Language Models to Plastic Surgery Research",
        "authors": "Ishith Seth, Gabriella Bulloch, Warren M Rozen",
        "published": "2023-9-14",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/asj/sjad210"
    },
    {
        "id": 11257,
        "title": "Adversarial Robustness for Large Language NER models using Disentanglement and Word Attributions",
        "authors": "Xiaomeng Jin, Bhanukiran Vinzamuri, Sriram Venkatapathy, Heng Ji, Pradeep Natarajan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.830"
    },
    {
        "id": 11258,
        "title": "Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models",
        "authors": "Hongzhan Lin, Ziyang Luo, Jing Ma, Long Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.611"
    },
    {
        "id": 11259,
        "title": "Domain Terminology Integration into Machine Translation: Leveraging Large Language Models",
        "authors": "Yasmin Moslem, Gianfranco Romani, Mahdi Molaei, John D. Kelleher, Rejwanul Haque, Andy Way",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.wmt-1.82"
    },
    {
        "id": 11260,
        "title": "Generating Multiple Choice Questions for Computing Courses Using Large Language Models",
        "authors": "Andrew Tran, Kenneth Angelikas, Egi Rama, Chiku Okechukwu, David H. Smith, Stephen MacNeil",
        "published": "2023-10-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/fie58773.2023.10342898"
    },
    {
        "id": 11261,
        "title": "Leveraging Large Language Models for Analysis of Student Course Feedback",
        "authors": "Zixuan Wang, Paul Denny, Juho Leinonen, Andrew Luxton-Reilly",
        "published": "2023-12-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3627217.3627221"
    },
    {
        "id": 11262,
        "title": "Sources of Hallucination by Large Language Models on Inference Tasks",
        "authors": "Nick McKenna, Tianyi Li, Liang Cheng, Mohammad Hosseini, Mark Johnson, Mark Steedman",
        "published": "2023",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.182"
    },
    {
        "id": 11263,
        "title": "Exploring the Opportunities and Challenges of Using Large Language Models to Represent Institutional Agency in Land Use Modelling",
        "authors": "Yongchao Zeng, Calum Brown, Mohamed Byari, Joanna Raymond, Ronja Hotz, Mark Rounsevell",
        "published": "No Date",
        "citations": 0,
        "abstract": "Institutional agencies play a crucial role in land use change, but modelling their decision-making processes is challenging due to the complexity of the environment they operate within and the bounded rationality of human organizations. Large Language Models (LLMs) offer a novel approach to simulating human decisions. This paper aims to investigate the challenges and opportunities that LLMs bring to land use change modelling by integrating LLM-powered institutional agents with the CRAFTY land use model, in which land users produce a range of ecosystem services. The study develops a structured prompt development approach for coupling LLM-powered agents with existing large-scale simulations. Four types of LLM-powered agents are examined, which use taxes to steer meat production toward a prescribed policy goal. The agents provide reasoning and policy action output in each simulation iteration. The study also uses a technique called quasi-multi-agent to simulate multiple roles involved in the policy processes. Unlike authentic multi-agent simulation, the LLM-powered quasi-multi-agent leverages the LLM's ability to generate contextually coherent text and allows the agents to work as a scriptwriter who composes conversations between different roles. This approach conserves computational resources and has the potential to manage conversational dynamics in policy discussions. The efficacy of these agents is benchmarked against two baseline scenarios: one without any policy intervention and another implementing optimal policy actions determined through a genetic algorithm.\nThe findings show that while LLM-powered agents perform better than the non-intervention scenario, they fall short of the performance achieved by optimal policy actions. However, LLM-powered agents demonstrate human-like decision-making, marked by policy consistency and transparent reasoning. The agents also generate real-world policymaking strategies, including incrementalism, considering delayed policy influence, proactive policy adjustments, and balancing multiple stakeholder interests. Agents equipped with experiential learning capabilities excel in achieving policy objectives through progressive policy actions. The order of reasoning and proposed policy actions in the prompts has a notable effect on the agents' performance. The research points to both promising opportunities and significant challenges in integrating LLMs into large-scale land-use simulations. The opportunities include exploring naturalistic institutional decision-making and its impact on land use change, using LLM's information retrieval to handle massive institutional documents, modelling institutional networks, and human-AI cooperation. However, challenges mainly lie in the scalability and reliability of LLMs due to the dependence on LLM providers, the paradox of pursuing realistic institutional behaviours versus abstraction and simplification in existing models, and the effectiveness and efficiency in scrutinizing massive textual output, detecting illogical content in prompts, and inaccurate formatting.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-13421"
    },
    {
        "id": 11264,
        "title": "Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm",
        "authors": "Laria Reynolds, Kyle McDonell",
        "published": "2021-5-8",
        "citations": 125,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3411763.3451760"
    },
    {
        "id": 11265,
        "title": "Validation of a Deep Learning Chest X-ray Interpretation Model: Integrating Large-Scale AI and Large Language Models for Comparative Analysis with ChatGPT",
        "authors": "Kyu Hong Lee, Ro Woon Lee, Ye Eun Kwon",
        "published": "2023-12-30",
        "citations": 1,
        "abstract": "This study evaluates the diagnostic accuracy and clinical utility of two artificial intelligence (AI) techniques: Kakao Brain Artificial Neural Network for Chest X-ray Reading (KARA-CXR), an assistive technology developed using large-scale AI and large language models (LLMs), and ChatGPT, a well-known LLM. The study was conducted to validate the performance of the two technologies in chest X-ray reading and explore their potential applications in the medical imaging diagnosis domain. The study methodology consisted of randomly selecting 2000 chest X-ray images from a single institution’s patient database, and two radiologists evaluated the readings provided by KARA-CXR and ChatGPT. The study used five qualitative factors to evaluate the readings generated by each model: accuracy, false findings, location inaccuracies, count inaccuracies, and hallucinations. Statistical analysis showed that KARA-CXR achieved significantly higher diagnostic accuracy compared to ChatGPT. In the ‘Acceptable’ accuracy category, KARA-CXR was rated at 70.50% and 68.00% by two observers, while ChatGPT achieved 40.50% and 47.00%. Interobserver agreement was moderate for both systems, with KARA at 0.74 and GPT4 at 0.73. For ‘False Findings’, KARA-CXR scored 68.00% and 68.50%, while ChatGPT scored 37.00% for both observers, with high interobserver agreements of 0.96 for KARA and 0.97 for GPT4. In ‘Location Inaccuracy’ and ‘Hallucinations’, KARA-CXR outperformed ChatGPT with significant margins. KARA-CXR demonstrated a non-hallucination rate of 75%, which is significantly higher than ChatGPT’s 38%. The interobserver agreement was high for KARA (0.91) and moderate to high for GPT4 (0.85) in the hallucination category. In conclusion, this study demonstrates the potential of AI and large-scale language models in medical imaging and diagnostics. It also shows that in the chest X-ray domain, KARA-CXR has relatively higher accuracy than ChatGPT.",
        "link": "http://dx.doi.org/10.3390/diagnostics14010090"
    },
    {
        "id": 11266,
        "title": "Automated Solution Development for Smart Grids: Tapping the Power of Large Language Models",
        "authors": "Khuram Shahzad, Sohail Iqbal, Muhammad Moazam Fraz",
        "published": "2023-6-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/emes58375.2023.10171681"
    },
    {
        "id": 11267,
        "title": "Multimodal Large Language Models: A Survey",
        "authors": "Jiayang Wu, Wensheng Gan, Zefeng Chen, Shicheng Wan, Philip S. Yu",
        "published": "2023-12-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386743"
    },
    {
        "id": 11268,
        "title": "Large Language Models in Surgical Education: Do they Reach Human Level on Fundamentals of Robotic Surgery Test? (Preprint)",
        "authors": "Andrea Moglia, Konstantinos Georgiou, Richard Satava, Alfred Cuschieri",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nLarge language models are capable of answering questions as if they were engaged in active conversation with users. However, currently, there are no data on whether their performances will remain static or vary over time when answering questions in the medical domain.\n\n\nOBJECTIVE\nThe aim of the present study was to assess ChatGPT and InstructGPT on multiple trials on the Fundamentals of Robotic Surgery (FRS) test. Additionally, different releases of ChatGPT were compared to establish whether its performance improved after retraining.\n\n\nMETHODS\nWe tested the performance of ChatGPT and InstructGPT on the 44 multiple choice questions of FRS didactic test, for which a pass mark requires 35 correct answers (79.5%). Seven attempts were performed using ChatGPT on the January 30, 2023 release and seven with the February 13, 2023 version. Three trials were performed with InstructGPT.\n\n\nRESULTS\nChatGPT achieved a mean score of 64.6% and 65.6% respectively for the first and second release, without any significant difference between the two (p = 0.32). The score ranged from 54.5% to 72.7% with both versions. On baseline it achieved 54.5% in both releases, higher than InstructGPT (50.0%). The highest rate of correct answers of ChatGPT was observed for questions on team training and communication (77.5% with both releases), followed by those on the introduction of the robotic system (67.5% and 62.7 % respectively for the first and second versions), psychomotor skills (64.3% and 57.1%), and naming correctly clinical steps of a procedure of robot-assisted surgery (53.8% and 65.9%).\n\n\nCONCLUSIONS\nEven though ChatGPT did not pass FRS test in any of the 14 trials, the 72.7% score observed by the present study represents a remarkable result, taking into consideration the generic nature of ChatGPT as distinct from a domain specific LLM. This level represents the highest score by ChatGPT in a high-stake examination in medicine.\n",
        "link": "http://dx.doi.org/10.2196/preprints.47243"
    },
    {
        "id": 11269,
        "title": "GPT-4: A Stochastic Parrot or Ontological Craftsman? Discovering Implicit Knowledge Structures in Large Language Models",
        "authors": "Tyler Thomas Procko, Timothy Elvira, Omar Ochoa",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/transai60598.2023.00043"
    },
    {
        "id": 11270,
        "title": "Clinical Knowledge and Reasoning Abilities of AI Large Language Models in Pharmacy: A Comparative Study on the NAPLEX Exam",
        "authors": "Mirana Angel, Anuj Patel, Amal Alachkar, Pierre Baldi",
        "published": "No Date",
        "citations": 3,
        "abstract": "AbstractObjectiveThis study aims to evaluate the capabilities and limitations of three large language models (LLMs) – GPT-3, GPT-4, and Bard, in the field of pharmaceutical sciences by assessing their pharmaceutical reasoning abilities on a sample North American Pharmacist Licensure Examination (NAPLEX). We also analyze the potential impacts of LLMs on pharmaceutical education and practice.MethodsA sample NAPLEX exam consisting of 137 multiple-choice questions was obtained from an online source. GPT-3, GPT-4, and Bard were used to answer the questions by inputting them into the LLMs’ user interface. The answers provided by the LLMs were then compared with the answer key.ResultsGPT-4 exhibited superior performance compared to GPT-3 and Bard, answering 78.8% of the questions correctly. This score was 11% higher than Bard and 27.7% higher than GPT-3. However, when considering questions that required multiple selections, the performance of each LLM decreased significantly. GPT-4, GPT-3, and Bard only correctly answered 53.6%, 13.9%, and 21.4% of these questions, respectively.ConclusionAmong the three LLMs evaluated, GPT-4 was the only model capable of passing the NAPLEX exam. Nevertheless, given the continuous evolution of LLMs, it is reasonable to anticipate that future models will effortlessly pass the exam. This highlights the significant potential of LLMs to impact the pharmaceutical field. Hence, we must evaluate both the positive and negative implications associated with the integration of LLMs in pharmaceutical education and practice.",
        "link": "http://dx.doi.org/10.1101/2023.06.07.544055"
    },
    {
        "id": 11271,
        "title": "Unlocking the Black Box? A Comprehensive Exploration of Large Language Models in Rehabilitation",
        "authors": "Bruno Bonnechère",
        "published": "2024-1-12",
        "citations": 0,
        "abstract": "Abstract\nRehabilitation is a vital component of healthcare, aiming to restore function and improve the well-being of individuals with disabilities or injuries. Nevertheless, the rehabilitation process is often likened to a 'black box', with complexities that pose challenges for comprehensive analysis and optimization. The emergence of Large Language Models (LLMs) offers promising solutions to better understand this ‘black box’. LLMs excel at comprehending and generating human-like text, making them valuable in the healthcare sector. In rehabilitation, healthcare professionals must integrate a wide range of data to create effective treatment plans, akin to selecting the best ingredients for the 'black box'. LLMs enhance data integration, communication, assessment, and prediction.\nThis paper delves into the ground-breaking use of LLMs as a tool to further understand the rehabilitation process. LLMs address current rehabilitation issues, including data bias, contextual comprehension, and ethical concerns. Collaboration with healthcare experts and rigorous validation is crucial when deploying LLMs. Integrating LLMs into rehabilitation yields insights into this intricate process, enhancing data-driven decision-making, refining clinical practices, and predicting rehabilitation outcomes. Although challenges persist, LLMs represent a significant stride in rehabilitation, underscoring the importance of ethical use and collaboration.",
        "link": "http://dx.doi.org/10.1097/phm.0000000000002440"
    },
    {
        "id": 11272,
        "title": "A multifactor model using large language models and investor sentiment from photos and news: new evidence from China",
        "authors": "Junhuan Zhang, Ziyan Zhang, Jiaqi Wen",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4708979"
    },
    {
        "id": 11273,
        "title": "Enhancing Large Language Models with Climate Resources",
        "authors": "Mathias Kraus, Julia Bingler, Markus Leippold, Tobias Schimanski, Chiara Colesanti Senni, Dominik Stammbach, Saeid Vaghefi, Nicolas Webersinke",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4407205"
    },
    {
        "id": 11274,
        "title": "Enhancing the Quality of Teaching and Learning through ChatGPT and Similar Large Language Models: Challenges, Future Prospects, and Ethical Considerations in Education",
        "authors": "Nitin Rane",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4599104"
    },
    {
        "id": 11275,
        "title": "Effectiveness of ChatGPT in Coding: A Comparative Analysis of Popular Large Language Models",
        "authors": "Carlos Eduardo Andino Coello, Mohammed Nazeh Alimam, Rand Kouatly",
        "published": "2024-1-8",
        "citations": 1,
        "abstract": "This study explores the effectiveness and efficiency of the popular OpenAI model ChatGPT, powered by GPT-3.5 and GPT-4, in programming tasks to understand its impact on programming and potentially software development. To measure the performance of these models, a quantitative approach was employed using the Mostly Basic Python Problems (MBPP) dataset. In addition to the direct assessment of GPT-3.5 and GPT-4, a comparative analysis involving other popular large language models in the AI landscape, notably Google’s Bard and Anthropic’s Claude, was conducted to measure and compare their proficiency in the same tasks. The results highlight the strengths of ChatGPT models in programming tasks, offering valuable insights for the AI community, specifically for developers and researchers. As the popularity of artificial intelligence increases, this study serves as an early look into the field of AI-assisted programming.",
        "link": "http://dx.doi.org/10.3390/digital4010005"
    },
    {
        "id": 11276,
        "title": "Clinical Accuracy of Large Language Models and Google Search Responses to Postpartum Depression Questions: Cross-Sectional Study (Preprint)",
        "authors": "Emre Sezgin, Faraaz Chekeni, Jennifer Lee, Sarah Keim",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\n—\n",
        "link": "http://dx.doi.org/10.2196/preprints.49240"
    },
    {
        "id": 11277,
        "title": "Natural language supervision with a large and diverse dataset builds better models of human high-level visual cortex",
        "authors": "Aria Y. Wang, Kendrick Kay, Thomas Naselaris, Michael J. Tarr, Leila Wehbe",
        "published": "No Date",
        "citations": 4,
        "abstract": "ABSTRACTAdvances in neural networks have been catalyzed by joint training on images and natural language, increased dataset sizes, and data diversity. We explored whether the same factors support similar improvements in predicting visual responses in the human brain. We used models pre-trained with Contrastive Language-Image Pre-training (CLIP) – which learns image embeddings that best match text embeddings of image captions from diverse, large-scale datasets – to study visual representations. We built voxelwise encoding models based on CLIP image features to predict brain responses to real-world images. ResNet50 with CLIP explained up toR2= 79% of variance in individual voxel responses in held-out test data, a significant increase from models trained only with image/label pairs (ImageNet trained ResNet) or text (BERT). Comparisons across different model backbones ruled out network architecture as a factor in performance improvements. Comparisons across models that controlled for dataset size and data diversity demonstrated that language feedback along with data diversity in larger datasets are important factors in explaining neural responses in high-level visual brain regions. Visualizations of model embeddings and Principal Component Analysis (PCA) revealed that our models capture both global and fine-grained semantic dimensions represented within human visual cortex.",
        "link": "http://dx.doi.org/10.1101/2022.09.27.508760"
    },
    {
        "id": 11278,
        "title": "The Role of Humanization and Robustness of Large Language Models in Conversational Artificial Intelligence for Individuals with Depression: A Critical Analysis (Preprint)",
        "authors": "Andrea Ferrario, Jana Sedlakova, Manuel Trachsel",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\nLarge language model (LLM)-powered services are gaining popularity in various applications due to their exceptional performance in many tasks, such as sentiment analysis and question answering. Recently, research has been exploring their potential use in digital health contexts, particularly in the mental health domain. However, implementing LLM-enhanced conversational artificial intelligence (CAI) presents significant ethical, technical, and clinical challenges. In this work, we discuss two challenges that affect the utilization of LLM-enhanced CAI for individuals with mental health issues, focusing on the use case of depressed patients: the tendency to humanize LLM-enhanced CAI and their lack of contextualized robustness. Our approach is interdisciplinary, relying on considerations from philosophy, psychology, and computer science. We argue that the humanization of LLM-enhanced CAI hinges on the reflection of what it means to simulate “human-like” features with LLMs and what role these systems should have in interactions with humans. Further, to ensure contextualizing robustness of LLMs requires considering the specificities of language production in depressed individuals, as well as its evolution over time. Finally, we provide a series of recommendations to foster the responsible design and deployment of LLM-enhanced CAI for the therapeutic support of individuals with depression.\n",
        "link": "http://dx.doi.org/10.2196/preprints.56569"
    },
    {
        "id": 11279,
        "title": "ChatGPT and Other Large Language Models as Evolutionary Engines for Online Interactive Collaborative Game Design",
        "authors": "Pier Luca Lanzi, Daniele Loiacono",
        "published": "2023-7-15",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3583131.3590351"
    },
    {
        "id": 11280,
        "title": "AI am a rheumatologist: a practical primer to large language models for rheumatologists",
        "authors": "Vincenzo Venerito, Emre Bilgin, Florenzo Iannone, Sedat Kiraz",
        "published": "2023-10-3",
        "citations": 10,
        "abstract": "Abstract\nNatural language processing (NLP), a subclass of artificial intelligence, large language models (LLMs), and its latest applications, such as Generative Pre-trained Transformers (GPT), ChatGPT, or LLAMA, have recently become one of the most discussed topics. Up to now, artificial intelligence and NLP ultimately impacted several areas, such as finance, economics and diagnostic/scoring systems in healthcare. Another area that artificial intelligence has affected and will continue to affect increasingly is academic life. This narrative review will define NLP, LLMs and their applications, discuss the opportunities and challenges that components of academic society will experience in rheumatology, and discuss the impact of NLP and LLMs in rheumatology healthcare.",
        "link": "http://dx.doi.org/10.1093/rheumatology/kead291"
    },
    {
        "id": 11281,
        "title": "Several Categories of Large Language Models (LLMs): A Short Survey",
        "authors": "Saurabh Pahune, Manoj Chandrasekharan",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "Abstract: Large Language Models (LLMs) have become effective tools for natural language process-ing and have been used in many different fields. This essay offers a succinct summary of various LLM subcategories. The survey emphasizes recent developments and efforts made for various LLM kinds, including task-based financial LLMs, multilingual language LLMs, biomedical and clinical LLMs, vision language LLMs, and code language models. The survey gives a general summary of the methods, attributes, datasets, transformer models, and comparison metrics applied in each category of LLMs. Furthermore, it highlights unresolved problems in the field of developing chatbots and virtual assistants, such as boosting natural language processing, enhancing chatbot intelligence, and resolving moral and legal dilemmas. The purpose of this study is to provide readers, developers, academics, and users interested in LLM-based chatbots and virtual intelligent assistant technologies with use full information and future directions.",
        "link": "http://dx.doi.org/10.22214/ijraset.2023.54677"
    },
    {
        "id": 11282,
        "title": "Large language models and scientific publishing",
        "authors": "Ronald Rousseau, Liying Yang, Johan Bollen, Zhesi Shen",
        "published": "2023-2-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2478/jdis-2023-0007"
    },
    {
        "id": 11283,
        "title": "Machine Translation with Large Language Models: Prompting, Few-shot Learning, and Fine-tuning with QLoRA",
        "authors": "Xuan Zhang, Navid Rajabi, Kevin Duh, Philipp Koehn",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.wmt-1.43"
    },
    {
        "id": 11284,
        "title": "Clinical Knowledge and Reasoning Abilities of AI Large Language Models in Anesthesiology: A Comparative Study on the ABA Exam",
        "authors": "Mirana C. Angel, Joseph B. Rinehart, Maxime P. Canneson, Pierre Baldi",
        "published": "No Date",
        "citations": 6,
        "abstract": "AbstractOver the past decade, Artificial Intelligence (AI) has expanded significantly with increased adoption across various industries, including medicine. Recently, AI’s large language models such as GPT-3, Bard, and GPT-4 have demonstrated remarkable language capabilities. While previous studies have explored their potential in general medical knowledge tasks, here we assess their clinical knowledge and reasoning abilities in a specialized medical context. We study and compare their performances on both the written and oral portions of the comprehensive and challenging American Board of Anesthesiology (ABA) exam, which evaluates candidates’ knowledge and competence in anesthesia practice. In addition, we invited two board examiners to evaluate AI’s answers without disclosing to them the origin of those responses. Our results reveal that only GPT-4 successfully passed the written exam, achieving an accuracy of 78% on the basic section and 80% on the advanced section. In comparison, the less recent or smaller GPT-3 and Bard models scored 58% and 47% on the basic exam, and 50% and 46% on the advanced exam, respectively. Consequently, only GPT-4 was evaluated in the oral exam, with examiners concluding that it had a high likelihood of passing the actual ABA exam. Additionally, we observe that these models exhibit varying degrees of proficiency across distinct topics, which could serve as an indicator of the relative quality of information contained in the corresponding training datasets. This may also act as a predictor for determining which anesthesiology subspecialty is most likely to witness the earliest integration with AI.",
        "link": "http://dx.doi.org/10.1101/2023.05.10.23289805"
    },
    {
        "id": 11285,
        "title": "Taming Simulators: Challenges, Pathways and Vision for the Alignment of Large Language Models",
        "authors": "Leonard Bereska, Efstratios Gavves",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "As AI systems continue to advance in power and prevalence, ensuring alignment between humans and AI is crucial to prevent catastrophic outcomes. The greater the capabilities and generality of an AI system, combined with its development of goals and agency, the higher the risks associated with misalignment. While the concept of superhuman artificial general intelligence is still speculative, language models show indications of generality that could extend to generally capable systems. Regarding agency, this paper emphasizes the understanding of prediction-trained models as simulators rather than agents. Nonetheless, agents may emerge accidentally from internal processes, so-called simulacra, or deliberately through fine-tuning with reinforcement learning. As a result, the focus of alignment research shifts towards aligning simulacra, comprehending and mitigating mesa-optimization, and aligning agents derived from prediction-trained models. The paper outlines the challenges of aligning simulators and presents research directions based on this understanding.\nAdditionally, it envisions a future where aligned simulators are critical in fostering successful human-AI collaboration. This vision encompasses exploring emulation approaches and the integration of simulators into cyborg systems to enhance human cognitive abilities. By acknowledging the risks associated with misaligned AI, delving into the concept of simulacra, and presenting strategies for aligning agents and simulacra, this paper contributes to the ongoing efforts to safeguard human values in developing and deploying AI systems.",
        "link": "http://dx.doi.org/10.1609/aaaiss.v1i1.27478"
    },
    {
        "id": 11286,
        "title": "Efficient healthcare with large language models: optimizing clinical workflow and enhancing patient care",
        "authors": "Satvik Tripathi, Rithvik Sukumaran, Tessa S Cook",
        "published": "2024-1-25",
        "citations": 0,
        "abstract": "Abstract\n\nPurpose\nThis article explores the potential of large language models (LLMs) to automate administrative tasks in healthcare, alleviating the burden on clinicians caused by electronic medical records.\n\n\nPotential\nLLMs offer opportunities in clinical documentation, prior authorization, patient education, and access to care. They can personalize patient scheduling, improve documentation accuracy, streamline insurance prior authorization, increase patient engagement, and address barriers to healthcare access.\n\n\nCaution\nHowever, integrating LLMs requires careful attention to security and privacy concerns, protecting patient data, and complying with regulations like the Health Insurance Portability and Accountability Act (HIPAA). It is crucial to acknowledge that LLMs should supplement, not replace, the human connection and care provided by healthcare professionals.\n\n\nConclusion\nBy prudently utilizing LLMs alongside human expertise, healthcare organizations can improve patient care and outcomes. Implementation should be approached with caution and consideration to ensure the safe and effective use of LLMs in the clinical setting.\n",
        "link": "http://dx.doi.org/10.1093/jamia/ocad258"
    },
    {
        "id": 11287,
        "title": "Understanding large language models: A guide for dental professionals",
        "authors": "Camila Tussie",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/jdd.13406"
    },
    {
        "id": 11288,
        "title": "Black Box Warning: Large Language Models and the Future of Infectious Diseases Consultation",
        "authors": "Ilan S Schwartz, Katherine E Link, Roxana Daneshjou, Nicolás Cortés-Penfield",
        "published": "2023-11-16",
        "citations": 8,
        "abstract": "Abstract\nLarge language models (LLMs) are artificial intelligence systems trained by deep learning algorithms to process natural language and generate text responses to user prompts. Some approach physician performance on a range of medical challenges, leading some proponents to advocate for their potential use in clinical consultation and prompting some consternation about the future of cognitive specialties. However, LLMs currently have limitations that preclude safe clinical deployment in performing specialist consultations, including frequent confabulations, lack of contextual awareness crucial for nuanced diagnostic and treatment plans, inscrutable and unexplainable training data and methods, and propensity to recapitulate biases. Nonetheless, considering the rapid improvement in this technology, growing calls for clinical integration, and healthcare systems that chronically undervalue cognitive specialties, it is critical that infectious diseases clinicians engage with LLMs to enable informed advocacy for how they should—and shouldn’t—be used to augment specialist care.",
        "link": "http://dx.doi.org/10.1093/cid/ciad633"
    },
    {
        "id": 11289,
        "title": "Large Language Models, Computational Chemistry, and Digital Reticular Chemistry: A Perspective and Proposed Workflow",
        "authors": "Abdullah A. AlGhamdi",
        "published": "2023-10-26",
        "citations": 1,
        "abstract": " In this article, I explore the synergy between Large Language Models (LLMs) and computational chemistry in the context of digital reticular chemistry and propose a workflow leveraging these technologies to advance research and discovery in the field. I argue that understanding the intricacies of new tools is imperative before integrating them into applications, and that the proposed workflow, though robust, merely offers a glimpse into the expansive potential and applications of this field. ",
        "link": "http://dx.doi.org/10.1142/s2529732524500019"
    },
    {
        "id": 11290,
        "title": "Assessing the research landscape and clinical utility of large language models: A scoping review",
        "authors": "Ye-Jean Park, Abhinav Pillai, Jiawen Deng, Eddie Guo, Mehul Gupta, Mike Paget, Christopher Naugler",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nImportance: Large language models (LLMs) like OpenAI's ChatGPT are powerful generative systems that rapidly synthesize natural language responses. Research on LLMs has revealed their potential and pitfalls, especially in clinical settings. However, the evolving landscape of LLM research in medicine has left several gaps regarding their evaluation, application, and evidence base.\nObjective: This scoping review aims to (1) summarize current research evidence on the accuracy and efficacy of LLMs in medical applications, (2) discuss the ethical, legal, logistical, and socioeconomic implications of LLM use in clinical settings, (3) explore barriers and facilitators to LLM implementation in healthcare, (4) propose a standardized evaluation framework for assessing LLMs' clinical utility, and (5) identify evidence gaps and propose future research directions for LLMs in clinical applications.\nEvidence Review: We screened 4,036 records from MEDLINE, EMBASE, CINAHL, medRxiv, bioRxiv, and arXiv from inception to June 26, 2023 for English-language papers and analyzed findings from 55 worldwide studies. Quality of evidence was reported based on the Oxford Centre for Evidence-based Medicine recommendations.\nFindings: Our results demonstrate that LLMs show promise in compiling patient notes, assisting patients in navigating the healthcare system, and to some extent, supporting clinical decision-making when combined with human oversight. However, their utilization is limited by biases in training data that may harm patients, the generation of inaccurate but convincing information, and ethical, legal, socioeconomic, and privacy concerns. We also identified a lack of standardized methods for evaluating LLMs’ effectiveness and feasibility.\nConclusions and relevance: This review thus highlights potential future directions and questions to address these limitations and to further explore LLMs' potential in enhancing healthcare delivery.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3472000/v1"
    },
    {
        "id": 11291,
        "title": "Leveraging large language models in dermatology",
        "authors": "Rubeta N Matin, Eleni Linos, Neil Rajan",
        "published": "2023-8-24",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/bjd/ljad230"
    },
    {
        "id": 11292,
        "title": "ChatGPT, large language models, and artificial intelligence in medicine and health care: A primer for clinicians and researchers",
        "authors": "Jonathan Kantor",
        "published": "2023-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jdin.2023.07.011"
    },
    {
        "id": 11293,
        "title": "Tabi: An Efficient Multi-Level Inference System for Large Language Models",
        "authors": "Yiding Wang, Kai Chen, Haisheng Tan, Kun Guo",
        "published": "2023-5-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3552326.3587438"
    },
    {
        "id": 11294,
        "title": "1362: UTILIZING LARGE LANGUAGE MODELS FOR DISEASE PHENOTYPING IN OBSTRUCTIVE SLEEP APNEA",
        "authors": "Ifrah Khurram, Rafael Zamora-Resendiz, Destinee Morrow, Silvia Crivelli",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/01.ccm.0001003608.71754.00"
    },
    {
        "id": 11295,
        "title": "Double-edged sword of large language models: mitigating security risks of AI-generated code",
        "authors": "Ramesh Bharadwaj, Ilya Parker",
        "published": "2023-6-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2664116"
    },
    {
        "id": 11296,
        "title": "Improving Large-Scale Fact-Checking using Decomposable Attention Models and Lexical Tagging",
        "authors": "Nayeon Lee, Chien-Sheng Wu, Pascale Fung",
        "published": "2018",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d18-1143"
    },
    {
        "id": 11297,
        "title": "The Role of Large Language Models in Radiology Reporting",
        "authors": "Alperen Elek",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2214/ajr.23.29951"
    },
    {
        "id": 11298,
        "title": "Comment on: Performance of Generative Large Language Models on Ophthalmology Board Style Questions",
        "authors": "Amnuay Kleebayoon, Viroj Wiwanitkit",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ajo.2023.07.029"
    },
    {
        "id": 11299,
        "title": "Investigating Large Language Models’ Perception of Emotion Using Appraisal Theory",
        "authors": "Nutchanon Yongsatianchot, Parisa Ghanad Torshizi, Stacy Marsella",
        "published": "2023-9-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aciiw59127.2023.10388194"
    },
    {
        "id": 11300,
        "title": "Ethical Challenges in the Development of Virtual Assistants Powered by Large Language Models",
        "authors": "Andrés Piñeiro-Martín, Carmen Garci­a-Mateo, Laura Docío-Fernández, María del Carmen López Pérez",
        "published": "No Date",
        "citations": 3,
        "abstract": "Virtual assistants (VAs) have gained widespread popularity across a wide range of applications, and the integration of Large Language Models (LLMs) such as ChatGPT has opened up new possibilities for developing even more sophisticated VAs. However, this integration poses new ethical issues and challenges that must be carefully considered, particularly as these systems are increasingly used in public services: transfer of personal data, decision-making transparency, potential biases, and privacy risks. This paper, an extension of the work presented at IberSPEECH 2022, analyzes the current regulatory framework for AI-based VAs in Europe and delves into ethical issues in depth, examining potential benefits and drawbacks of integrating LLMs with VAs. Based on the analysis, this paper argues that the development and use of VAs powered by LLMs should be guided by a set of ethical principles that prioritize transparency, fairness, and harm prevention. The paper presents specific guidelines for the ethical use and development of this technology, including recommendations for data privacy, bias mitigation, and user control. By implementing these guidelines, the potential benefits of VAs powered by LLMs can be fully realized while minimizing the risks of harm and ensuring that ethical considerations are at the forefront of the development process.",
        "link": "http://dx.doi.org/10.20944/preprints202306.0196.v1"
    },
    {
        "id": 11301,
        "title": "KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using Large Language Models",
        "authors": "Jiho Kim, Yeonsu Kwon, Yohan Jo, Edward Choi",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.631"
    },
    {
        "id": 11302,
        "title": "Ethical Concerns Regarding the Use of Large Language Models in Healthcare",
        "authors": "Fabien Lareyre, Juliette Raffort",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ejvsvf.2023.10.003"
    },
    {
        "id": 11303,
        "title": "Do Large Language Models Show Decision Heuristics Similar to Humans? A Case Study Using GPT-3.5",
        "authors": "Gaurav Suri, Lily Slater, Ali Ziaee, Morgan Nguyen",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4440608"
    },
    {
        "id": 11304,
        "title": "Cross-Attention watermarking of Large Language Models",
        "authors": "Folco Bertini Baldassini, Huy H. Nguyen, Ching-Chung Chang, Isao Echizen",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446397"
    },
    {
        "id": 11305,
        "title": "Assessing the Proficiency of Large Language Models in Automatic Feedback Generation: An Evaluation Study",
        "authors": "Wei Dai, Yi-Shan Tsai, Jionghao Lin, Ahmad Aldino, Flora Jin, Tongguang Li, Dragan Gasevic,  angusglchen",
        "published": "No Date",
        "citations": 0,
        "abstract": "Assessment feedback is important to student learning. Learning analytics (LA) powered by artificial intelligence exhibits profound potential in helping instructors with the laborious provision of feedback. Inspired by the recent advancements made by Generative Pre-trained Transformer (GPT) models, we conducted a study to examine the extent to which GPT models hold the potential to advance the existing knowledge of LA-supported feedback systems towards improving the efficiency of feedback provision. Therefore, our study explored the ability of two versions of GPT models – i.e., GPT-3.5 (ChatGPT) and GPT-4 to generate assessment feedback on students’ writing assessment tasks, common in higher education, with open-ended topics for a data science-related course. We compared the feedback generated by GPT models (namely GPT-3.5 and GPT-4) with the feedback provided by human instructors in terms of readability, effectiveness (content containing effective feedback components), and reliability (correct assessment on student performance). Results showed that (1) both GPT-3.5 and GPT-4 were able to generate more readable feedback than human instructors, (2) GPT-4 outperformed GPT-3.5 and human instructors in providing feedback containing information about effective feedback dimensions, including feeding-up, feeding-forward, process level, and self-regulation level, and (3) GPT-4 demonstrated higher reliability of feedback compared to GPT-3.5.",
        "link": "http://dx.doi.org/10.35542/osf.io/s7dvy"
    },
    {
        "id": 11306,
        "title": "Leveraging Large Language Models for Automated Dialogue Analysis",
        "authors": "Sarah E. Finch, Ellie S. Paek, Jinho D. Choi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.sigdial-1.20"
    },
    {
        "id": 11307,
        "title": "Preliminary evaluation of the potential of commercially available large language models in diagnosing skin tumours",
        "authors": "Makoto Shiraishi, Koji Kanayama, Rui Yang, Mutsumi Okazaki",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "To date, the most commercially available large language models have refused to evaluate clinical pictures because of the medical contexts. In our study, only BingAI Creative mode provided decisions about whether images were malignant or benign and provided a diagnosis for skin tumours, both with relatively low accuracy rates of 58% for classification and 3% for diagnosis.",
        "link": "http://dx.doi.org/10.1093/ced/llad430"
    },
    {
        "id": 11308,
        "title": "Transforming nursing with large language models: from concept to practice",
        "authors": "Brigitte Woo, Tom Huynh, Arthur Tang, Nhat Bui, Giang Nguyen, Wilson Tam",
        "published": "2024-1-5",
        "citations": 2,
        "abstract": "Abstract\nLarge language models (LLMs) such as ChatGPT have emerged as potential game-changers in nursing, aiding in patient education, diagnostic assistance, treatment recommendations, and administrative task efficiency. While these advancements signal promising strides in healthcare, integrated LLMs are not without challenges, particularly artificial intelligence hallucination and data privacy concerns. Methodologies such as prompt engineering, temperature adjustments, model fine-tuning, and local deployment are proposed to refine the accuracy of LLMs and ensure data security. While LLMs offer transformative potential, it is imperative to acknowledge that they cannot substitute the intricate expertise of human professionals in the clinical field, advocating for a synergistic approach in patient care.",
        "link": "http://dx.doi.org/10.1093/eurjcn/zvad120"
    },
    {
        "id": 11309,
        "title": "Large Language Models",
        "authors": "Michael Fralick, Chana A. Sacks, Daniel Muller, Tim Vining, Emily Ling, Jeffrey M. Drazen, C. Corey Hardin",
        "published": "2023-7-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1056/evidstat2300128"
    },
    {
        "id": 11310,
        "title": "Prompting Large Language Models for Topic Modeling",
        "authors": "Han Wang, Nirmalendu Prakash, Nguyen Khoi Hoang, Ming Shan Hee, Usman Naseem, Roy Ka-Wei Lee",
        "published": "2023-12-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386113"
    },
    {
        "id": 11311,
        "title": "Artificial Intelligence and Large Language Models (LLM) in Healthcare: Unraveling Complexities for Individualized Care",
        "authors": "André Luiz Pellacani França",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31080/asor.2024.07.0901"
    },
    {
        "id": 11312,
        "title": "Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark",
        "authors": "Jason Hoelscher-Obermaier, Julia Persson, Esben Kran, Ioannis Konstas, Fazl Barez",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.733"
    },
    {
        "id": 11313,
        "title": "Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach",
        "authors": "Zheyuan Zhang, Jifan Yu, Juanzi Li, Lei Hou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.111"
    },
    {
        "id": 11314,
        "title": "Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking",
        "authors": "Yuxiang Wu, Guanting Dong, Weiran Xu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.741"
    },
    {
        "id": 11315,
        "title": "Looking to Future Applications of Large Language Models",
        "authors": "Xichong Liu, Samuel J.S. Rubin, Stephan Rogalla",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14309/ajg.0000000000002401"
    },
    {
        "id": 11316,
        "title": "Learning Video Representations from Large Language Models",
        "authors": "Yue Zhao, Ishan Misra, Philipp Krähenbühl, Rohit Girdhar",
        "published": "2023-6",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00637"
    },
    {
        "id": 11317,
        "title": "Ground Manipulator Primitive Tasks to Executable Actions Using Large Language Models",
        "authors": "Yue Cao, C. S. George Lee",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "Layered architectures have been widely used in robot systems. The majority of them implement planning and execution functions in separate layers. However, there still lacks a straightforward way to transit high-level tasks in the planning layer to the low-level motor commands in the execution layer. In order to tackle this challenge, we propose a novel approach to ground the manipulator primitive tasks to robot low-level actions using large language models (LLMs). We designed a program-function-like prompt based on the task frame formalism. In this way, we enable LLMs to generate position/force set-points for hybrid control. Evaluations over several state-of-the-art LLMs are provided.",
        "link": "http://dx.doi.org/10.1609/aaaiss.v2i1.27720"
    },
    {
        "id": 11318,
        "title": "Guidance for researchers and peer-reviewers on the ethical use of Large Language Models (LLMs) in scientific research workflows",
        "authors": "Ryan Watkins",
        "published": "2023-5-16",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s43681-023-00294-5"
    },
    {
        "id": 11319,
        "title": "Rethinking Learning Rate Tuning in the Era of Large Language Models",
        "authors": "Hongpeng Jin, Wenqi Wei, Xuyu Wang, Wenbin Zhang, Yanzhao Wu",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cogmi58952.2023.00025"
    },
    {
        "id": 11320,
        "title": "Prompting Is All You Need: Automated Android Bug Replay with Large Language Models",
        "authors": "Sidong Feng, Chunyang Chen",
        "published": "2024-2-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3597503.3608137"
    },
    {
        "id": 11321,
        "title": "Error Analysis Prompting Enables Human-Like Translation Evaluation in Large Language Models: A Case Study on ChatGPT",
        "authors": "Qingyu Lu, Baopu Qiu, Liang Ding, Liping Xie, Dacheng Tao",
        "published": "No Date",
        "citations": 7,
        "abstract": "Generative large language models (LLMs), e.g., ChatGPT, have demonstrated remarkable proficiency across several NLP tasks such as machine translation, question answering, text summarization, and natural language understanding. Recent research has shown that utilizing ChatGPT for assessing the quality of machine translation (MT) achieves state-of-the-art performance at the system level but performs poorly at the segment level. To further improve the performance of LLMs on MT quality assessment, we conducted an investigation into several prompting methods. Our results indicate that by combining Chain-of-Thoughts and Error Analysis, a new prompting method called Error Analysis Prompting, LLMs like ChatGPT can \\textit{generate human-like MT evaluations at both the system and segment level}. Additionally, we discovered some limitations of ChatGPT as an MT evaluator, such as unstable scoring and biases when provided with multiple translations in a single query. Our findings aim to provide a preliminary experience for appropriately evaluating translation quality on ChatGPT while offering a variety of tricks in designing prompts for in-context learning. We anticipate that this report will shed new light on advancing the field of translation evaluation with LLMs by enhancing both the accuracy and reliability of metrics. The project can be found at https://github.com/Coldmist-Lu/ErrorAnalysis_Prompt.",
        "link": "http://dx.doi.org/10.20944/preprints202303.0255.v1"
    },
    {
        "id": 11322,
        "title": "Character Animation Pipeline based on Latent Diffusion and Large Language Models",
        "authors": "Alessandro Clocchiatti, Nicolo Fumerò, Agata Marta Soccini",
        "published": "2024-1-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aixvr59861.2024.00067"
    },
    {
        "id": 11323,
        "title": "The Role and Limitations of Large Language Models Such as ChatGPT in                     Clinical Settings and Medical Journalism",
        "authors": "Furkan Ufuk",
        "published": "2023-5-1",
        "citations": 26,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1148/radiol.230276"
    },
    {
        "id": 11324,
        "title": "Exploring Cross-lingual Text Detoxification with Large Multilingual Language Models.",
        "authors": "Daniil Moskovskiy, Daryna Dementieva, Alexander Panchenko",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.acl-srw.26"
    },
    {
        "id": 11325,
        "title": "MEEP: Is this Engaging? Prompting Large Language Models for Dialogue Evaluation in Multilingual Settings",
        "authors": "Amila Ferron, Amber Shore, Ekata Mitra, Ameeta Agrawal",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.137"
    },
    {
        "id": 11326,
        "title": "LLMDet: A Third Party Large Language Models Generated Text Detection Tool",
        "authors": "Kangxi Wu, Liang Pang, Huawei Shen, Xueqi Cheng, Tat-Seng Chua",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.139"
    },
    {
        "id": 11327,
        "title": "Large Language Models and Inclusivity in Bioethics Scholarship",
        "authors": "Sumeeta Varma",
        "published": "2023-10-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15265161.2023.2250286"
    },
    {
        "id": 11328,
        "title": "Generating Better Items for Cognitive Assessments Using Large Language Models",
        "authors": "Antonio Laverghetta Jr., John Licato",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bea-1.34"
    },
    {
        "id": 11329,
        "title": "Application of large language models in professional fields",
        "authors": "Mingji Zhou, Wei Chen, Senliang Zhu, Tianyang Cai, Ji Yu, Guoyu Dai",
        "published": "2023-7-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isctech60480.2023.00033"
    },
    {
        "id": 11330,
        "title": "Persistent Anti-Muslim Bias in Large Language Models",
        "authors": "Abubakar Abid, Maheen Farooqi, James Zou",
        "published": "2021-7-21",
        "citations": 83,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3461702.3462624"
    },
    {
        "id": 11331,
        "title": "Enabling Conversational Interaction with Mobile UI using Large Language Models",
        "authors": "Bryan Wang, Gang Li, Yang Li",
        "published": "2023-4-19",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3544548.3580895"
    },
    {
        "id": 11332,
        "title": "The Use and Misuse of Pre-Trained Generative Large Language Models in Reliability Engineering",
        "authors": "Yunwei Hu, Yavuz Goktas, David Deepak Yellamati, Catherine De Tassigny",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/rams51492.2024.10457630"
    },
    {
        "id": 11333,
        "title": "Transforming legal text interactions: leveraging natural language processing and large language models for legal support in Palestinian cooperatives",
        "authors": "Mohammed Maree, Rabee Al-Qasem, Banan Tantour",
        "published": "2024-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s41870-023-01584-1"
    },
    {
        "id": 11334,
        "title": "Dimensions of Quality: Contrasting Stylistic vs. Semantic Features for Modelling Literary Quality in 9,000 Novels",
        "authors": "Pascale Feldkamp Moreira,  , Yuri Bizzoni,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_080"
    },
    {
        "id": 11335,
        "title": "Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback",
        "authors": "Viet Lai, Chien Nguyen, Nghia Ngo, Thuat Nguyen, Franck Dernoncourt, Ryan Rossi, Thien Nguyen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-demo.28"
    },
    {
        "id": 11336,
        "title": "A systematic review of research on speech-recognition chatbots for language learning: Implications for future directions in the era of large language models",
        "authors": "Jaeho Jeon, Seongyong Lee, Seongyune Choi",
        "published": "2023-5-5",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/10494820.2023.2204343"
    },
    {
        "id": 11337,
        "title": "OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models",
        "authors": "Badr Alkhamissi, Siddharth Verma, Ping Yu, Zhijing Jin, Asli Celikyilmaz, Mona Diab",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.nlrse-1.10"
    },
    {
        "id": 11338,
        "title": "Distilling Script Knowledge from Large Language Models for Constrained Language Planning",
        "authors": "Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Jankowski, Yanghua Xiao, Deqing Yang",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.236"
    },
    {
        "id": 11339,
        "title": "Large-Scale Relation Learning for Question Answering over Knowledge Bases with Pre-trained Language Models",
        "authors": "Yuanmeng Yan, Rumei Li, Sirui Wang, Hongzhi Zhang, Zan Daoguang, Fuzheng Zhang, Wei Wu, Weiran Xu",
        "published": "2021",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.296"
    },
    {
        "id": 11340,
        "title": "PRCA: Fitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable Reward-Driven Contextual Adapter",
        "authors": "Haoyan Yang, Zhitao Li, Yong Zhang, Jianzong Wang, Ning Cheng, Ming Li, Jing Xiao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.326"
    },
    {
        "id": 11341,
        "title": "ZhuJiu: A Multi-dimensional, Multi-faceted Chinese Benchmark for Large Language Models",
        "authors": "Baoli Zhang, Haining Xie, Pengfan Du, Junhao Chen, Pengfei Cao, Yubo Chen, Shengping Liu, Kang Liu, Jun Zhao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-demo.44"
    },
    {
        "id": 11342,
        "title": "On the Generalization of Projection-Based Gender Debiasing in Word Embedding",
        "authors": "Elisabetta Fersini,  , Antonio Candelieri, Lorenzo Pastore,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_038"
    },
    {
        "id": 11343,
        "title": "Advancing Topical Text Classification: A Novel Distance-Based Method with Contextual Embeddings",
        "authors": "Andriy Kosar,  , Guy De Pauw, Walter Daelemans,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_064"
    },
    {
        "id": 11344,
        "title": "Classification of US Supreme Court Cases using BERT-Based Techniques",
        "authors": "Shubham Vatsal,  , Adam Meyers, John E. Ortega,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_128"
    },
    {
        "id": 11345,
        "title": "Large Language Models Meet Open-World Intent Discovery and Recognition: An Evaluation of ChatGPT",
        "authors": "Xiaoshuai Song, Keqing He, Pei Wang, Guanting Dong, Yutao Mou, Jingang Wang, Yunsen Xian, Xunliang Cai, Weiran Xu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.636"
    },
    {
        "id": 11346,
        "title": "MusicAgent: An AI Agent for Music Understanding and Generation with Large Language Models",
        "authors": "Dingyao Yu, Kaitao Song, Peiling Lu, Tianyu He, Xu Tan, Wei Ye, Shikun Zhang, Jiang Bian",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-demo.21"
    },
    {
        "id": 11347,
        "title": "Small Character Models Match Large Word Models for Autocomplete Under Memory Constraints",
        "authors": "Ganesh Jawahar, Subhabrata Mukherjee, Debadeepta Dey, Muhammad Abdul-mageed, Laks Lakshmanan, V.s., Caio Mendes, Gustavo De Rosa, Shital Shah",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.sustainlp-1.22"
    },
    {
        "id": 11348,
        "title": "Small Pre-trained Language Models Can be Fine-tuned as Large Models via Over-Parameterization",
        "authors": "Ze-Feng Gao, Kun Zhou, Peiyu Liu, Wayne Xin Zhao, Ji-Rong Wen",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.212"
    },
    {
        "id": 11349,
        "title": "Leveraging Large Language Models With Vocabulary Sharing For Sign Language Translation",
        "authors": "Huije Lee, Jung-Ho Kim, Eui Jun Hwang, Jaewoo Kim, Jong C. Park",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icasspw59220.2023.10193533"
    },
    {
        "id": 11350,
        "title": "The Language of Creativity: Evidence from Humans and Large Language Models",
        "authors": "William Orwig, Emma R. Edenbaum, Joshua D. Greene, Daniel L. Schacter",
        "published": "2024-1-11",
        "citations": 1,
        "abstract": "ABSTRACTRecent developments in computerized scoring via semantic distance have provided automated assessments of verbal creativity. Here, we extend past work, applying computational linguistic approaches to characterize salient features of creative text. We hypothesize that, in addition to semantic diversity, the degree to which a story includes perceptual details, thus transporting the reader to another time and place, would be predictive of creativity. Additionally, we explore the use of generative language models to supplement human data collection and examine the extent to which machine‐generated stories can mimic human creativity. We collect 600 short stories from human participants and GPT‐3, subsequently randomized and assessed on their creative quality. Results indicate that the presence of perceptual details, in conjunction with semantic diversity, is highly predictive of creativity. These results were replicated in an independent sample of stories (n = 120) generated by GPT‐4. We do not observe a significant difference between human and AI‐generated stories in terms of creativity ratings, and we also observe positive correlations between human and AI assessments of creativity. Implications and future directions are discussed.",
        "link": "http://dx.doi.org/10.1002/jocb.636"
    },
    {
        "id": 11351,
        "title": "VOCAB-EXPANDER: A System for Creating Domain-Specific Vocabularies Based on Word Embeddings",
        "authors": "Michael Färber,  , Nicholas Popovic,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_037"
    },
    {
        "id": 11352,
        "title": "Deep Learning Methods for Identification of Multiword Flower and Plant Names",
        "authors": "Damith Premasiri,  , Amal Haddad Haddad, Tharindu Ranasinghe, Ruslan Mitkov,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_095"
    },
    {
        "id": 11353,
        "title": "Student’s t-Distribution: On Measuring the Inter-Rater Reliability When the Observations are Scarce",
        "authors": "Serge Gladkoff,  , Lifeng Han, Goran Nenadic,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_047"
    },
    {
        "id": 11354,
        "title": "Large Language Models are Not Yet Human-Level Evaluators for Abstractive Summarization",
        "authors": "Chenhui Shen, Liying Cheng, Xuan-Phi Nguyen, Yang You, Lidong Bing",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.278"
    },
    {
        "id": 11355,
        "title": "Evaluating Capabilities of Large Language Models: Performance of GPT4 on Surgical Knowledge Assessments",
        "authors": "Brendin R Beaulieu-Jones, Sahaj Shah, Margaret T Berrigan, Jayson S Marwaha, Shuo-Lun Lai, Gabriel A Brat",
        "published": "No Date",
        "citations": 8,
        "abstract": "AbstractBackgroundArtificial intelligence (AI) has the potential to dramatically alter healthcare by enhancing how we diagnosis and treat disease. One promising AI model is ChatGPT, a large general-purpose language model trained by OpenAI. The chat interface has shown robust, human-level performance on several professional and academic benchmarks. We sought to probe its performance and stability over time on surgical case questions.MethodsWe evaluated the performance of ChatGPT-4 on two surgical knowledge assessments: the Surgical Council on Resident Education (SCORE) and a second commonly used knowledge assessment, referred to as Data-B. Questions were entered in two formats: open-ended and multiple choice. ChatGPT output were assessed for accuracy and insights by surgeon evaluators. We categorized reasons for model errors and the stability of performance on repeat encounters.ResultsA total of 167 SCORE and 112 Data-B questions were presented to the ChatGPT interface. ChatGPT correctly answered 71% and 68% of multiple-choice SCORE and Data-B questions, respectively. For both open-ended and multiple-choice questions, approximately two-thirds of ChatGPT responses contained non-obvious insights. Common reasons for inaccurate responses included: inaccurate information in a complex question (n=16, 36.4%); inaccurate information in fact-based question (n=11, 25.0%); and accurate information with circumstantial discrepancy (n=6, 13.6%). Upon repeat query, the answer selected by ChatGPT varied for 36.4% of inaccurate questions; the response accuracy changed for 6/16 questions.ConclusionConsistent with prior findings, we demonstrate robust near or above human-level performance of ChatGPT within the surgical domain. Unique to this study, we demonstrate a substantial inconsistency in ChatGPT responses with repeat query. This finding warrants future consideration and presents an opportunity to further train these models to provide safe and consistent responses. Without mental and/or conceptual models, it is unclear whether language models such as ChatGPT would be able to safely assist clinicians in providing care.",
        "link": "http://dx.doi.org/10.1101/2023.07.16.23292743"
    },
    {
        "id": 11356,
        "title": "Advances in large language models: ChatGPT expands the horizons of neuroscience",
        "authors": "Arosh S. Perera Molligoda Arachchige, Kamel Chebaro, Alice J. M. Jelmoni",
        "published": "2023",
        "citations": 0,
        "abstract": "<abstract>\n\n<p>The field of neuroscience has been significantly impacted by the emergence of artificial intelligence (AI), particularly language models like ChatGPT. ChatGPT, developed by OpenAI, is a powerful conversational AI tool with the ability to communicate in multiple languages and process vast amounts of data. The commentary explores the significant impact of ChatGPT on the field of neuroscience, emphasizing its potential contributions, challenges, and ethical considerations. ChatGPT has shown promise in various aspects of neuroscience research, including hypothesis generation, data analysis, literature review, collaboration, and education. However, it is not without limitations, particularly in terms of accuracy, potential bias, and ethical concerns. The commentary highlights the potential applications of ChatGPT in the context of child and adolescent mental health, where it could revolutionize assessment and treatment processes. By analyzing text from young patients, ChatGPT can identify patterns related to mental health issues, enhancing diagnostic accuracy and treatment planning. It can also improve communication between patients and healthcare professionals, offering real-time insights and educational resources. While ChatGPT presents exciting opportunities, the commentary acknowledges the need for careful oversight and control to address privacy concerns, biases, and potential misuse. Ethical considerations surrounding the model's impact on emotions, behavior, and biases require ongoing scrutiny and safeguards. In conclusion, ChatGPT offers transformative potential in neuroscience and mental health, but it must be harnessed responsibly, with a focus on ethical considerations and scientific rigor to ensure its positive impact on research and clinical practice.</p>\n\n\t      </abstract>",
        "link": "http://dx.doi.org/10.3934/steme.2023016"
    },
    {
        "id": 11357,
        "title": "Automatic Estimation for Visual Quality Changes of Street Space Via Street-View Images and Multimodal Large Language Models",
        "authors": "Hao Liang, Jiaxin Zhang, Yunqin Li, Zehong Zhu, Bowen Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Estimating Visual Quality of Street Space (VQoSS) is pivotal for urban design, environmental sustainability, civic engagement, etc. Recent advancements, notably in deep learning, have enabled large-scale analysis. However, traditional deep learning approaches are hampered by extensive data annotation requirements and limited adaptability across diverse VQoSS tasks. Multimodal Large Language Models (MLLMs) have recently demonstrated proficiency in various computer vision tasks, positioning them as promising tools for automated VQoSS assessment. In this paper, we pioneer the application of MLLMs to VQoSS change estimation, with our empirical findings affirming their effectiveness. In addition, we introduce Street Quality GPT (SQ-GPT), a model that distills knowledge from the current most powerful but inaccessible (not free) GPT-4, requiring no human efforts. SQ-GPT approaches GPT-4’s performance and is viable for large-scale VQoSS change estimation. In a case study of Nanjin, we showcase the practicality of SQ-GPT and knowledge distillation pipeline. Our work promises to be a valuable asset for future urban studies research.",
        "link": "http://dx.doi.org/10.20944/preprints202311.1473.v1"
    },
    {
        "id": 11358,
        "title": "Exploring the Research Agenda for Large Language Models: Opportunities and Challenges for Scientific Research",
        "authors": "Uma Shankar Pandey",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1177/09760911231168685"
    },
    {
        "id": 11359,
        "title": "'Let’s Have a Chat': Principles for the Effective Application of ChatGPT and Large Language Models in the Practice of Forensic Accounting",
        "authors": "Daniel Street, Joseph Wilck",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4351817"
    },
    {
        "id": 11360,
        "title": "Wikipedia and large language models: perfect pairing or perfect storm?",
        "authors": "Paul A. Thomas",
        "published": "2023-11-27",
        "citations": 0,
        "abstract": "\nPurpose\nThe purpose of this paper is to explore the potential benefits and challenges of using large language models (LLMs) like ChatGPT to edit Wikipedia.\n\n\nDesign/methodology/approach\nThe first portion of this paper provides background about Wikipedia and LLMs, explicating briefly how each works. The paper's second section then explores both the ways that LLMs can be used to make Wikipedia a stronger site and the challenges that these technologies pose to Wikipedia editors. The paper's final section explores the implications for information professionals.\n\n\nFindings\nThis paper argues that LLMs can be used to proofread Wikipedia articles, outline potential articles and generate usable Wikitext. The pitfalls include the technology's potential to generate text that is plagiarized or violates copyright, its tendency to produce “original research” and its tendency to generate incorrect or biased information.\n\n\nOriginality/value\nWhile there has been limited discussion among Wikipedia editors about the use of LLMs when editing the site, hardly any scholarship has been given to how these models can impact Wikipedia's development and quality. This paper thus aims to fill this gap in knowledge by examining both the potential benefits and pitfalls of using LLMs on Wikipedia.\n",
        "link": "http://dx.doi.org/10.1108/lhtn-03-2023-0056"
    },
    {
        "id": 11361,
        "title": "Can AI Keep You Safe? A Study of Large Language Models for Phishing Detection",
        "authors": "Robin Chataut, Prashnna Kumar Gyawali, Yusuf Usman",
        "published": "2024-1-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ccwc60891.2024.10427626"
    },
    {
        "id": 11362,
        "title": "Prediction of Arabic Legal Rulings Using Large Language Models",
        "authors": "Adel Ammar, Anis Koubaa, Bilel Benjdira, Omer Nacar, Serry Sibaee",
        "published": "2024-2-15",
        "citations": 0,
        "abstract": "In the intricate field of legal studies, the analysis of court decisions is a cornerstone for the effective functioning of the judicial system. The ability to predict court outcomes helps judges during the decision-making process and equips lawyers with invaluable insights, enhancing their strategic approaches to cases. Despite its significance, the domain of Arabic court analysis remains under-explored. This paper pioneers a comprehensive predictive analysis of Arabic court decisions on a dataset of 10,813 commercial court real cases, leveraging the advanced capabilities of the current state-of-the-art large language models. Through a systematic exploration, we evaluate three prevalent foundational models (LLaMA-7b, JAIS-13b, and GPT-3.5-turbo) and three training paradigms: zero-shot, one-shot, and tailored fine-tuning. In addition, we assess the benefit of summarizing and/or translating the original Arabic input texts. This leads to a spectrum of 14 model variants, for which we offer a granular performance assessment with a series of different metrics (human assessment, GPT evaluation, ROUGE, and BLEU scores). We show that all variants of LLaMA models yield limited performance, whereas GPT-3.5-based models outperform all other models by a wide margin, surpassing the average score of the dedicated Arabic-centric JAIS model by 50%. Furthermore, we show that all scores except human evaluation are inconsistent and unreliable for assessing the performance of large language models on court decision predictions. This study paves the way for future research, bridging the gap between computational linguistics and Arabic legal analytics.",
        "link": "http://dx.doi.org/10.3390/electronics13040764"
    },
    {
        "id": 11363,
        "title": "Automated Paper Screening for Clinical Reviews Using Large Language Models: Data Analysis Study (Preprint)",
        "authors": "Eddie Guo, Mehul Gupta, Jiawen Deng, Ye-Jean Park, Michael Paget, Christopher Naugler",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nThe systematic review of clinical research papers is a labor-intensive and time-consuming process that often involves the screening of thousands of titles and abstracts. The accuracy and efficiency of this process are critical for the quality of the review and subsequent health care decisions. Traditional methods rely heavily on human reviewers, often requiring a significant investment of time and resources.\n\n\nOBJECTIVE\nThis study aims to assess the performance of the OpenAI generative pretrained transformer (GPT) and GPT-4 application programming interfaces (APIs) in accurately and efficiently identifying relevant titles and abstracts from real-world clinical review data sets and comparing their performance against ground truth labeling by 2 independent human reviewers.\n\n\nMETHODS\nWe introduce a novel workflow using the Chat GPT and GPT-4 APIs for screening titles and abstracts in clinical reviews. A Python script was created to make calls to the API with the screening criteria in natural language and a corpus of title and abstract data sets filtered by a minimum of 2 human reviewers. We compared the performance of our model against human-reviewed papers across 6 review papers, screening over 24,000 titles and abstracts.\n\n\nRESULTS\nOur results show an accuracy of 0.91, a macro <i>F</i><sub>1</sub>-score of 0.60, a sensitivity of excluded papers of 0.91, and a sensitivity of included papers of 0.76. The interrater variability between 2 independent human screeners was κ=0.46, and the prevalence and bias-adjusted κ between our proposed methods and the consensus-based human decisions was κ=0.96. On a randomly selected subset of papers, the GPT models demonstrated the ability to provide reasoning for their decisions and corrected their initial decisions upon being asked to explain their reasoning for incorrect classifications.\n\n\nCONCLUSIONS\nLarge language models have the potential to streamline the clinical review process, save valuable time and effort for researchers, and contribute to the overall quality of clinical reviews. By prioritizing the workflow and acting as an aid rather than a replacement for researchers and reviewers, models such as GPT-4 can enhance efficiency and lead to more accurate and reliable conclusions in medical research.\n",
        "link": "http://dx.doi.org/10.2196/preprints.48996"
    },
    {
        "id": 11364,
        "title": "Agile Methodology for the Standardization of Engineering Requirements using Large Language Models",
        "authors": "Archana Tikayat Ray, Bjorn F Cole, Olivia J Pinon Fischer, Anirudh Prabhakara Bhat, Ryan T White, Dimitri N Mavris",
        "published": "No Date",
        "citations": 4,
        "abstract": "The increased complexity of modern systems is calling for an integrated and comprehensive approach to system design and development and in particular, a shift towards Model-Based Systems Engineering (MBSE) approaches for system design. The requirements that serve as the foundation for these intricate systems are still primarily expressed in Natural Language (NL), which can contain ambiguities and inconsistencies that hinder their direct translation into models. The colossal developments in the field of Natural Language Processing (NLP) in general and Large Language Models (LLMs) in particular can serve as an enabler for the conversion of NL requirements into semi-machine-readable requirements. This is expected to facilitate their standardization and use in a model-based environment. This paper discusses a two-fold strategy for converting NL requirements into semi-machine-readable requirements using language models. The first approach involves creating a requirements table by extracting information from free-form NL requirements. The second approach is an agile methodology that facilitates the identification of boilerplate templates for different types of requirements based on observed linguistic patterns. For this study, three different LLMs were utilized. Two of these models were fine-tuned versions of Bidirectional Encoder Representations from Transformers (BERT), specifically aeroBERT-NER and aeroBERT-Classifier, which were trained on annotated aerospace corpora. Another LLM, called flair/chunk-english, was utilized to identify sentence chunks present in NL requirements. All three language models were utilized together to achieve the standardization of requirements. To demonstrate the effectiveness of the methodologies, requirements from Parts 23 and 25 of Title 14 Code of Federal Regulations (CFRs) were employed, and a total of two, five, and three boilerplate templates were identified for design, functional, and performance requirements, respectively.",
        "link": "http://dx.doi.org/10.20944/preprints202305.1325.v1"
    },
    {
        "id": 11365,
        "title": "Do Large Language Models Know What Humans Know?",
        "authors": "Sean Trott, Cameron Jones, Tyler Chang, James Michaelov, Benjamin Bergen",
        "published": "2023-7",
        "citations": 13,
        "abstract": "AbstractHumans can attribute beliefs to others. However, it is unknown to what extent this ability results from an innate biological endowment or from experience accrued through child development, particularly exposure to language describing others' mental states. We test the viability of the language exposure hypothesis by assessing whether models exposed to large quantities of human language display sensitivity to the implied knowledge states of characters in written passages. In pre‐registered analyses, we present a linguistic version of the False Belief Task to both human participants and a large language model, GPT‐3. Both are sensitive to others' beliefs, but while the language model significantly exceeds chance behavior, it does not perform as well as the humans nor does it explain the full extent of their behavior—despite being exposed to more language than a human would in a lifetime. This suggests that while statistical learning from language exposure may in part explain how humans develop the ability to reason about the mental states of others, other mechanisms are also responsible.",
        "link": "http://dx.doi.org/10.1111/cogs.13309"
    },
    {
        "id": 11366,
        "title": "Large Language Models（LLM）and Robotics",
        "authors": "Daichi Mochihashi",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7210/jrsj.40.863"
    },
    {
        "id": 11367,
        "title": "Evaluating the Factual Consistency of Large Language Models Through News Summarization",
        "authors": "Derek Tam, Anisha Mascarenhas, Shiyue Zhang, Sarah Kwan, Mohit Bansal, Colin Raffel",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.322"
    },
    {
        "id": 11368,
        "title": "Self-Consistency of Large Language Models under Ambiguity",
        "authors": "Henning Bartsch, Ole Jorgensen, Domenic Rosati, Jason Hoelscher-Obermaier, Jacob Pfau",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.blackboxnlp-1.7"
    },
    {
        "id": 11369,
        "title": "Attack Prompt Generation for Red Teaming and Defending Large Language Models",
        "authors": "Boyi Deng, Wenjie Wang, Fuli Feng, Yang Deng, Qifan Wang, Xiangnan He",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.143"
    },
    {
        "id": 11370,
        "title": "GYM at Qur’an QA 2023 Shared Task: Multi-Task Transfer Learning for Quranic Passage Retrieval and Question Answering with Large Language Models",
        "authors": "Ghazaleh Mahmoudi, Yeganeh Morshedzadeh, Sauleh Eetemadi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.arabicnlp-1.79"
    },
    {
        "id": 11371,
        "title": "INVITE: a Testbed of Automatically Generated Invalid Questions to Evaluate Large Language Models for Hallucinations",
        "authors": "Anil Ramakrishna, Rahul Gupta, Jens Lehmann, Morteza Ziyadi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.360"
    },
    {
        "id": 11372,
        "title": "How large language models can be used in the field of orthodontics",
        "authors": "Ankita Khurdal, Shubhangi Mani, NG Toshniwal, Abhay Paul",
        "published": "2023-10-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18231/j.jco.2023.042"
    },
    {
        "id": 11373,
        "title": "Implementing Generative AI and Large Language Models in Education",
        "authors": "Neil Anderson, Aidan McGowan, Leo Galway, Philip Hanna, Matthew Collins, David Cutting",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isas60782.2023.10391517"
    },
    {
        "id": 11374,
        "title": "Augmenting Large Language Models with Rules for Enhanced Domain-Specific Interactions: The Case of Medical Diagnosis",
        "authors": "Dimitrios P. Panagoulias, Maria Virvou, George A. Tsihrintzis",
        "published": "2024-1-11",
        "citations": 0,
        "abstract": "In this paper, we present a novel Artificial Intelligence (AI) -empowered system that enhances large language models and other machine learning tools with rules to provide primary care diagnostic advice to patients. Specifically, we introduce a novel methodology, represented through a process diagram, which allows the definition of generative AI processes and functions with a focus on the rule-augmented approach. Our methodology separates various components of the generative AI process as blocks that can be used to generate an implementation data flow diagram. Building upon this framework, we utilize the concept of a dialogue process as a theoretical foundation. This is specifically applied to the interactions between a user and an AI-empowered software program, which is called “Med|Primary AI assistant” (Alpha Version at the time of writing), and provides symptom analysis and medical advice in the form of suggested diagnostics. By leveraging current advancements in natural language processing, a novel approach is proposed to define a blueprint of domain-specific knowledge and a context for instantiated advice generation. Our approach not only encompasses the interaction domain, but it also delves into specific content that is relevant to the user, offering a tailored and effective AI–user interaction experience within a medical context. Lastly, using an evaluation process based on rules, defined by context and dialogue theory, we outline an algorithmic approach to measure content and responses.",
        "link": "http://dx.doi.org/10.3390/electronics13020320"
    },
    {
        "id": 11375,
        "title": "On the Risk of Misinformation Pollution with Large Language Models",
        "authors": "Yikang Pan, Liangming Pan, Wenhu Chen, Preslav Nakov, Min-Yen Kan, William Wang",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.97"
    },
    {
        "id": 11376,
        "title": "Healthcare: A Growing Role for Large Language Models and Generative AI",
        "authors": "Saurabh Pahune, Noopur Rewatkar",
        "published": "2023-8-31",
        "citations": 1,
        "abstract": "Abstract: Large language models and generative artificial intelligence (GAI) have recently demonstrated significant promise for revolutionizing a range of industries, including healthcare. The paper investigates how these cutting-edge AI developments are transforming healthcare applications. We focus on how big language models, like GPT-3 (generative pretrained transformer), Visual ChatGPT and generative AI, such Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), can be applied to solve important problems in the healthcare sector. Medical text analysis is one of the main uses of massive language models in the visual ChatGPT healthcare industry. These models have impressive natural language processing abilities that make it possible to effectively extract important information from electronic health records (EHRs), biomedical text data from large biobanks, scholarly articles and patient notes. The Biomedical Transformer Model represents a ground-breaking development in natural language processing for the biomedical field, exhibiting outstanding performance in comprehending and producing textual data. It opens up new avenues for biomedical research, diagnosis, and personalized therapy when combined with Multimodal Biomedical AI, which makes use of numerous data sources, including pictures, genomes, and clinical records. On the other side, generative AI has made great progress in medical picture analysis such as MRI scans and X-rays. The outstanding performance of GANs in medical picture synthesis and augmentation has helped to increase the precision and accuracy of diagnosis. Due to the issues with small and uneven medical datasets, VAEs have proven crucial in producing realistic medical images for training and research reasons. In addition to describing the various generative AI tools used in healthcare, this paper also provides an overview of multimodal medical LLMs and the biomedical transformer LLMs in the healthcare industry. Large language models and generative AI have great potential, but ethical issues and data privacy are still major problems in healthcare applications. Further, we investigate the potential role of multimodal medical LLMs as the foundation for novel assistive technologies in the fields of professional medicine, medical research, and consumer applications in the healthcare industry",
        "link": "http://dx.doi.org/10.22214/ijraset.2023.55573"
    },
    {
        "id": 11377,
        "title": "Revisiting Relation Extraction in the era of Large Language Models",
        "authors": "Somin Wadhwa, Silvio Amir, Byron Wallace",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.868"
    },
    {
        "id": 11378,
        "title": "Large Language Models (LLMs): Hypes and Realities",
        "authors": "Sudhir K. Routray, Abhishek Javali, K P Sharmila, Mahesh K. Jha, M. Pappa, Monika Singh",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cset58993.2023.10346621"
    },
    {
        "id": 11379,
        "title": "Script-Generated Picture Book Technology Based on Large Language Models and AIGC",
        "authors": "Dejiang Wang, Zhuoran Zhai, Ngai Cheong, Li Peng",
        "published": "2023-9-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626686.3626704"
    },
    {
        "id": 11380,
        "title": "Lattice Rescoring Based on Large Ensemble of Complementary Neural Language Models",
        "authors": "Atsunori Ogawa, Naohiro Tawara, Marc Delcroix, Shoko Araki",
        "published": "2022-5-23",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp43922.2022.9747745"
    },
    {
        "id": 11381,
        "title": "Redefining Health Care Data Interoperability: An Empirical Exploration of Large Language Models in Information Exchange (Preprint)",
        "authors": "Dukyong Yoon, Changho Han, Dong Won Kim, Songsoo Kim, SungA Bae",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nEfficient data exchange and health care interoperability are impeded by medical records often being in non-standardized or unstructured natural language format. Advanced language models, such as large language models (LLMs), may help overcome current challenges in information exchange.\n\n\nOBJECTIVE\nThis study evaluates the capability of LLMs in transforming and transferring health care data to support interoperability.\n\n\nMETHODS\nUtilizing data from the Medical Information Mart for Intensive Care III and UK Biobank, the study conducted three experiments. Experiment 1 assessed the accuracy of transforming structured lab results into unstructured format. Experiment 2 explored the conversion of diagnostic codes between the coding frameworks of the International Classification of Diseases, Ninth Revision, Clinical Modification and SNOMED Clinical Terms using a traditional mapping table and a text-based approach facilitated by the LLM ChatGPT. Experiment 3 focused on extracting targeted information from unstructured records that included comprehensive clinical information (discharge notes).\n\n\nRESULTS\nThe text-based approach showed a high conversion accuracy in transforming lab results (Experiment 1) and an enhanced consistency in diagnostic code conversion, particularly for frequently used diagnostic names, compared with the traditional mapping approach (Experiment 2). In Experiment 3, the LLM showed a positive predictive value of 87.2% in extracting generic drug names.\n\n\nCONCLUSIONS\nThis study highlighted the potential role of LLMs in significantly improving health care data interoperability, demonstrated by their high accuracy and efficiency in data transformation and exchange. The LLMs hold vast potential for enhancing medical data exchange without complex standardization for medical terms and data structure.\n\n\nCLINICALTRIAL\nN/A\n",
        "link": "http://dx.doi.org/10.2196/preprints.56614"
    },
    {
        "id": 11382,
        "title": "Exploring the potential of large-language models (LLMs) for student feedback sentiment analysis",
        "authors": "Sarang Shaikh, Sher Muhammad Daudpota, Sule Yildirim Yayilgan, Sindhu Sindhu",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/fit60620.2023.00047"
    },
    {
        "id": 11383,
        "title": "Possibilities to Utilize Large Language Models in Detection and Mitigation of Limitations of Currently Available Neurocognitive Assessment Batteries",
        "authors": "Mirza Niaz Zaman Elin -",
        "published": "2023-5-31",
        "citations": 0,
        "abstract": "Neurocognitive assessment batteries play a crucial role in evaluating cognitive abilities and identifying potential impairments or cognitive decline. However, these assessments may suffer from limitations and biases associated with specific tasks, such as drawing a clock, copying a cube, and recalling words. In this research paper, we explore the potential utilization of large language models in identifying and mitigating these limitations. We discuss the biases introduced by these tasks and propose the incorporation of alternative assessment methods. Furthermore, we examine the feasibility of utilizing large language models, such as the ChatGPT, to address these limitations and enhance the inclusivity and accuracy of cognitive evaluations. By leveraging the capabilities of large language models, we aim to provide a comprehensive framework for improving neurocognitive assessment batteries.",
        "link": "http://dx.doi.org/10.36948/ijfmr.2023.v05i03.3335"
    },
    {
        "id": 11384,
        "title": "Two Directions for Clinical Data Generation with Large Language Models: Data-to-Label and Label-to-Data",
        "authors": "Rumeng Li, Xun Wang, Hong Yu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.474"
    },
    {
        "id": 11385,
        "title": "An Empirical Study of Instruction-tuning Large Language Models in Chinese",
        "authors": "Qingyi Si, Tong Wang, Zheng Lin, Xu Zhang, Yanan Cao, Weiping Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.269"
    },
    {
        "id": 11386,
        "title": "Mitigating Political Bias in Large Language Models Using Chain of thought Prompting Techniques",
        "authors": "Hiresh Poosarla",
        "published": "2024-1-31",
        "citations": 0,
        "abstract": "Abstract: Recent advancements in Natural Language Processing (NLP) have led to the proliferation of sophisticated chatbots, with ChatGPT as a prominent example. However, these Large Language Models are often plagued with inherent political biases from their training datasets, which raises concerns regarding their ethical usage and reinforcement of existing societal biases. This research introduces Chain of Thought (CoT) prompting, which is a novel approach to mitigate political biases by guiding chatbots to think step by step with a logical approach.",
        "link": "http://dx.doi.org/10.22214/ijraset.2024.58057"
    },
    {
        "id": 11387,
        "title": "Using Large Language Models to Probe Cognitive Constructs, Augment Data, and Design Instructional Materials",
        "authors": "Fabian Kieser, Peter Wulff",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-9379-6_14"
    },
    {
        "id": 11388,
        "title": "Toward a Novel Methodology in Economic Experiments: Simulation of the Ultimatum Game with Large Language Models",
        "authors": "Ayato Kitadai, Yudai Tsurusaki, Yusuke Fukasawa, Nariaki Nishino",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386678"
    },
    {
        "id": 11389,
        "title": "Elevating Employment Practices in Agricultural Corporations with Large Language Models and AI",
        "authors": "Samia A. Abu-Shanab, Ala Mughaid, Shadi AlZu'bi",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/snams60348.2023.10375423"
    },
    {
        "id": 11390,
        "title": "BioLORD-2023: semantic textual representations fusing large language models and clinical knowledge graph insights",
        "authors": "François Remy, Kris Demuynck, Thomas Demeester",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "Abstract\n\nObjective\nIn this study, we investigate the potential of large language models (LLMs) to complement biomedical knowledge graphs in the training of semantic models for the biomedical and clinical domains.\n\n\nMaterials and Methods\nDrawing on the wealth of the Unified Medical Language System knowledge graph and harnessing cutting-edge LLMs, we propose a new state-of-the-art approach for obtaining high-fidelity representations of biomedical concepts and sentences, consisting of 3 steps: an improved contrastive learning phase, a novel self-distillation phase, and a weight averaging phase.\n\n\nResults\nThrough rigorous evaluations of diverse downstream tasks, we demonstrate consistent and substantial improvements over the previous state of the art for semantic textual similarity (STS), biomedical concept representation (BCR), and clinically named entity linking, across 15+ datasets. Besides our new state-of-the-art biomedical model for English, we also distill and release a multilingual model compatible with 50+ languages and finetuned on 7 European languages.\n\n\nDiscussion\nMany clinical pipelines can benefit from our latest models. Our new multilingual model enables a range of languages to benefit from our advancements in biomedical semantic representation learning, opening a new avenue for bioinformatics researchers around the world. As a result, we hope to see BioLORD-2023 becoming a precious tool for future biomedical applications.\n\n\nConclusion\nIn this article, we introduced BioLORD-2023, a state-of-the-art model for STS and BCR designed for the clinical domain.\n",
        "link": "http://dx.doi.org/10.1093/jamia/ocae029"
    },
    {
        "id": 11391,
        "title": "On the limitations of large language models in clinical diagnosis",
        "authors": "Justin T Reese, Daniel Danis, J Harry Caufield, Tudor Groza, Elena Casiraghi, Giorgio Valentini, Christopher J Mungall, Peter N Robinson",
        "published": "No Date",
        "citations": 4,
        "abstract": "AbstractObjectiveLarge Language Models such as GPT-4 previously have been applied to differential diagnostic challenges based on published case reports. Published case reports have a sophisticated narrative style that is not readily available from typical electronic health records (EHR). Furthermore, even if such a narrative were available in EHRs, privacy requirements would preclude sending it outside the hospital firewall. We therefore tested a method for parsing clinical texts to extract ontology terms and programmatically generating prompts that by design are free of protected health information.Materials and MethodsWe investigated different methods to prepare prompts from 75 recently published case reports. We transformed the original narratives by extracting structured terms representing phenotypic abnormalities, comorbidities, treatments, and laboratory tests and creating prompts programmatically.ResultsPerformance of all of these approaches was modest, with the correct diagnosis ranked first in only 5.3-17.6% of cases. The performance of the prompts created from structured data was substantially worse than that of the original narrative texts, even if additional information was added following manual review of term extraction. Moreover, different versions of GPT-4 demonstrated substantially different performance on this task.DiscussionThe sensitivity of the performance to the form of the prompt and the instability of results over two GPT-4 versions represent important current limitations to the use of GPT-4 to support diagnosis in real-life clinical settings.ConclusionResearch is needed to identify the best methods for creating prompts from typically available clinical data to support differential diagnostics.",
        "link": "http://dx.doi.org/10.1101/2023.07.13.23292613"
    },
    {
        "id": 11392,
        "title": "Zero-Shot Cross-Lingual Summarization via Large Language Models",
        "authors": "Jiaan Wang, Yunlong Liang, Fandong Meng, Beiqi Zou, Zhixu Li, Jianfeng Qu, Jie Zhou",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.newsum-1.2"
    },
    {
        "id": 11393,
        "title": "Leave It to Large Language Models! Correct and Planning with Memory Integration",
        "authors": "Yuan Zhang, Chao Wang, Juntong Qi, Yan Peng",
        "published": "2023-12-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.34133/cbsystems.0087"
    },
    {
        "id": 11394,
        "title": "On Computing Paradigms - Where Will Large Language Models Be Going",
        "authors": "Xindong Wu, Xingquan Zhu, Elena Baralis, Ruqian Lu, Vipin Kumar, Leszek Rutkowski, Jie Tang",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdm58522.2023.00211"
    },
    {
        "id": 11395,
        "title": "Beneath Surface Similarity: Large Language Models Make Reasonable Scientific Analogies after Structure Abduction",
        "authors": "Siyu Yuan, Jiangjie Chen, Xuyang Ge, Yanghua Xiao, Deqing Yang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.160"
    },
    {
        "id": 11396,
        "title": "Filling the Image Information Gap for VQA: Prompting Large Language Models to Proactively Ask Questions",
        "authors": "Ziyue Wang, Chi Chen, Peng Li, Yang Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.189"
    },
    {
        "id": 11397,
        "title": "ExpNote: Black-box Large Language Models are better Task Solvers with Experience Notebook",
        "authors": "Wangtao Sun, Xuanqing Yu, Shizhu He, Jun Zhao, Kang Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.1034"
    },
    {
        "id": 11398,
        "title": "Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy",
        "authors": "Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, Weizhu Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.620"
    },
    {
        "id": 11399,
        "title": "CIPTA: Contrastive-based Iterative Prompt-tuning Using Text Annotation from Large Language Models",
        "authors": "Yu Yan, Wenzhuo Du, Di Yang, Dechun Yin",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icecai58670.2023.10176586"
    },
    {
        "id": 11400,
        "title": "Can Large Language Models Provide Security &amp; Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions",
        "authors": "Yufan Chen, Arjun Arunasalam, Z. Berkay Celik",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3627106.3627196"
    },
    {
        "id": 11401,
        "title": "ChatGPT on ECT",
        "authors": "Robert M. Lundin, Michael Berk, Søren Dinesen Østergaard",
        "published": "2023-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/yct.0000000000000941"
    },
    {
        "id": 11402,
        "title": "Subsampling of Frequent Words in Text for Pre-training a Vision-Language Model",
        "authors": "Mingliang Liang, Martha Larson",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3607827.3616843"
    },
    {
        "id": 11403,
        "title": "Large language models to differentiate vasospastic angina using patient information",
        "authors": "Yuko Kiyohara, Satoshi Kodera, Masaya Sato, Kota Ninomiya, Masataka Sato, Hiroki Shinohara, Norifumi Takeda, Hiroshi Akazawa, Hiroyuki Morita, Issei Komuro",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractBackgroundVasospastic angina is sometimes suspected from patients’ medical history. It is essential to appropriately distinguish vasospastic angina from acute coronary syndrome because its standard treatment is pharmacotherapy, not catheter intervention. Large language models have recently been developed and are currently widely accessible. In this study, we aimed to use large language models to distinguish between vasospastic angina and acute coronary syndrome from patient information and compare the accuracies of these models.MethodWe searched for cases of vasospastic angina and acute coronary syndrome which were written in Japanese and published in online-accessible abstracts and journals, and randomly selected 66 cases as a test dataset. In addition, we selected another ten cases as data for few-shot learning. We used generative pre-trained transformer-3.5 and 4, and Bard, with zero- and few-shot learning. We evaluated the accuracies of the models using the test dataset.ResultsGenerative pre-trained transformer-3.5 with zero-shot learning achieved an accuracy of 52%, sensitivity of 68%, and specificity of 29%; with few-shot learning, it achieved an accuracy of 52%, sensitivity of 26%, and specificity of 86%. Generative pre-trained transformer-4 with zero-shot learning achieved an accuracy of 58%, sensitivity of 29%, and specificity of 96%; with few-shot learning, it achieved an accuracy of 61%, sensitivity of 63%, and specificity of 57%. Bard with zero-shot learning achieved an accuracy of 47%, sensitivity of 16%, and specificity of 89%; with few-shot learning, this model could not be assessed because it failed to produce output.ConclusionGenerative pre-trained transformer-4 with few-shot learning was the best of all the models. The accuracies of models with zero- and few-shot learning were almost the same. In the future, models could be made more accurate by combining text data with other modalities.",
        "link": "http://dx.doi.org/10.1101/2023.06.26.23291913"
    },
    {
        "id": 11404,
        "title": "DECENTRALISED AUTONOMOUS SOCIETY THROUGH LARGE LANGUAGE MODELS’ BASED AGENTS: A PATHWAY TO EMPOWER SMALL COMMUNITIES",
        "authors": "Vasili Braga",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "This paper explores the concept of Decentralized Autonomous Society through the lens of Large Language Models focusing on the transformative potential of integrating these technologies. The paper on the role of Large Language Models based agents in providing a versatile, responsive, and contextually intelligent resource within a Decentralized Autonomous Society, fostering intellectual exploration, assisting in complex tasks, and aiding real-time problem solving. One delves into their integration with Decentralized Autonomous Society infrastructures, including robotic and automated systems. While promising, the integration of Large Language Models and their agents into a Decentralized Autonomous Society poses several challenges, including infrastructure and connectivity limitations, information accuracy, artificial intelligence bias, privacy and data security, and ethical concerns. This paper critically discusses these issues and proposes potential solutions. Through the lens of the Decentralized Autonomous Society construct, the paper considers the future possibilities and implications of artificial intelligence, where self-sustaining, digitally-empowered communities leverage artificial intelligence as a cornerstone of their collective intelligence.",
        "link": "http://dx.doi.org/10.52326/jes.utm.2023.30(3).07"
    },
    {
        "id": 11405,
        "title": "Large language models as a source of health information: Are they patient-centered? A longitudinal analysis",
        "authors": "Kanhai Amin, Rushabh Doshi, Howard P. Forman",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.hjdsi.2023.100731"
    },
    {
        "id": 11406,
        "title": "Can large language models reason and plan?",
        "authors": "Subbarao Kambhampati",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "AbstractWhile humans sometimes do show the capability of correcting their own erroneous guesses with self‐critiquing, there seems to be no basis for that assumption in the case of LLMs.",
        "link": "http://dx.doi.org/10.1111/nyas.15125"
    },
    {
        "id": 11407,
        "title": "Large Language Models in der Medizin",
        "authors": "Moritz Borchers",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s15202-024-6177-z"
    },
    {
        "id": 11408,
        "title": "Chain of Thought Utilization in Large Language Models and Application in Nephrology",
        "authors": "Jing Miao, Charat Thongprayoon, Supawadee Suppadungsuk, Pajaree Krisanapan, Yeshwanter Radhakrishnan, Wisit Cheungpasitporn",
        "published": "2024-1-13",
        "citations": 2,
        "abstract": "Chain-of-thought prompting enhances the abilities of large language models (LLMs) significantly. It not only makes these models more specific and context-aware but also impacts the wider field of artificial intelligence (AI). This approach broadens the usability of AI, increases its efficiency, and aligns it more closely with human thinking and decision-making processes. As we improve this method, it is set to become a key element in the future of AI, adding more purpose, precision, and ethical consideration to these technologies. In medicine, the chain-of-thought prompting is especially beneficial. Its capacity to handle complex information, its logical and sequential reasoning, and its suitability for ethically and context-sensitive situations make it an invaluable tool for healthcare professionals. Its role in enhancing medical care and research is expected to grow as we further develop and use this technique. Chain-of-thought prompting bridges the gap between AI’s traditionally obscure decision-making process and the clear, accountable standards required in healthcare. It does this by emulating a reasoning style familiar to medical professionals, fitting well into their existing practices and ethical codes. While solving AI transparency is a complex challenge, the chain-of-thought approach is a significant step toward making AI more comprehensible and trustworthy in medicine. This review focuses on understanding the workings of LLMs, particularly how chain-of-thought prompting can be adapted for nephrology’s unique requirements. It also aims to thoroughly examine the ethical aspects, clarity, and future possibilities, offering an in-depth view of the exciting convergence of these areas.",
        "link": "http://dx.doi.org/10.3390/medicina60010148"
    },
    {
        "id": 11409,
        "title": "Generative AI and large language models in health care: pathways to implementation",
        "authors": "Marium M. Raza, Kaushik P. Venkatesh, Joseph C. Kvedar",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41746-023-00988-4"
    },
    {
        "id": 11410,
        "title": "Tree of Uncertain Thoughts Reasoning for Large Language Models",
        "authors": "Shentong Mo, Miao Xin",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10448355"
    },
    {
        "id": 11411,
        "title": "Smart-Pikachu: Extending Interactivity of Stuffed Animals with Large Language Models",
        "authors": "Toma Itagaki, Richard Li",
        "published": "2023-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3586182.3625219"
    },
    {
        "id": 11412,
        "title": "Can Large Language Models Be an Alternative to Human Evaluations?",
        "authors": "Cheng-Han Chiang, Hung-yi Lee",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.870"
    },
    {
        "id": 11413,
        "title": "Autocompletion of Chief Complaints in the Electronic Health Records using Large Language Models",
        "authors": "K M Sajjadul Islam, Ayesha Siddika Nipu, Praveen Madiraju, Priya Deshpande",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386778"
    },
    {
        "id": 11414,
        "title": "Comparison of Large Language Models in Answering Immuno-Oncology Questions: A Cross-Sectional Study",
        "authors": "Giovanni Maria Iannantuono, Dara Bracken-Clarke, Fatima Karzai, Hyoyoung Choo-Wosoba, James L. Gulley, Charalampos S. Floudas",
        "published": "No Date",
        "citations": 2,
        "abstract": "ABSTRACTBackgroundThe capability of large language models (LLMs) to understand and generate human-readable text has prompted the investigation of their potential as educational and management tools for cancer patients and healthcare providers.Materials and MethodsWe conducted a cross-sectional study aimed at evaluating the ability of ChatGPT-4, ChatGPT-3.5, and Google Bard to answer questions related to four domains of immuno-oncology (Mechanisms, Indications, Toxicities, and Prognosis). We generated 60 open-ended questions (15 for each section). Questions were manually submitted to LLMs, and responses were collected on June 30th, 2023. Two reviewers evaluated the answers independently.ResultsChatGPT-4 and ChatGPT-3.5 answered all questions, whereas Google Bard answered only 53.3% (p <0.0001). The number of questions with reproducible answers was higher for ChatGPT-4 (95%) and ChatGPT3.5 (88.3%) than for Google Bard (50%) (p <0.0001). In terms of accuracy, the number of answers deemed fully correct were 75.4%, 58.5%, and 43.8% for ChatGPT-4, ChatGPT-3.5, and Google Bard, respectively (p = 0.03). Furthermore, the number of responses deemed highly relevant was 71.9%, 77.4%, and 43.8% for ChatGPT-4, ChatGPT-3.5, and Google Bard, respectively (p = 0.04). Regarding readability, the number of highly readable was higher for ChatGPT-4 and ChatGPT-3.5 (98.1%) and (100%) compared to Google Bard (87.5%) (p = 0.02).ConclusionChatGPT-4 and ChatGPT-3.5 are potentially powerful tools in immuno-oncology, whereas Google Bard demonstrated relatively poorer performance. However, the risk of inaccuracy or incompleteness in the responses was evident in all three LLMs, highlighting the importance of expert-driven verification of the outputs returned by these technologies.IMPLICATIONS FOR PRACTICESeveral studies have recently evaluated whether large language models may be feasible tools for providing educational and management information for cancer patients and healthcare providers. In this cross-sectional study, we assessed the ability of ChatGPT-4, ChatGPT-3.5, and Google Bard to answer questions related to immuno-oncology. ChatGPT-4 and ChatGPT-3.5 returned a higher proportion of responses, which were more accurate and comprehensive, than those returned by Google Bard, yielding highly reproducible and readable outputs. These data support ChatGPT-4 and ChatGPT-3.5 as powerful tools in providing information on immuno-oncology; however, accuracy remains a concern, with expert assessment of the output still indicated.",
        "link": "http://dx.doi.org/10.1101/2023.10.31.23297825"
    },
    {
        "id": 11415,
        "title": "Democratizing scientific and healthcare communication with large language models",
        "authors": "Tejas S. Sathe, Madelyn A. Flitcroft, Anai N. Kothari",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4103/crst.crst_157_23"
    },
    {
        "id": 11416,
        "title": "Artificial intelligence, large language models, and you",
        "authors": "Charles Marquardt",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jvscit.2023.101293"
    },
    {
        "id": 11417,
        "title": "A case study of fairness in generated images of Large Language Models for Software Engineering tasks",
        "authors": "Mansour Sami, Ashkan Sami, Pete Barclay",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icsme58846.2023.00051"
    },
    {
        "id": 11418,
        "title": "Empowering Faculty to Incorporate Large Language Models in Nursing Education Using a Delegation Framework",
        "authors": "Jason Blomquist, Sarah Llewellyn, Jenny Alderden, Kelley Connor",
        "published": "2024-2-23",
        "citations": 0,
        "abstract": "Abstract\nLarge language models (LLMs) can support nursing education but pose questions of validity, reliability, and ethical use. This article proposes using the five rights of nursing delegation framework by the National Council of State Boards of Nursing to teach nursing students about the appropriate use of LLMs in health care and nursing education. Nursing faculty can teach students how to assess the validity and reliability of the information provided by LLMs, document its use, and reference and cite information appropriately.",
        "link": "http://dx.doi.org/10.1097/01.nep.0000000000001246"
    },
    {
        "id": 11419,
        "title": "NPIs Aren’t Exactly Easy: Variation in Licensing across Large Language Models",
        "authors": "Deanna DeCarlo, William Palmer, Michael Wilson, Bob Frank",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.blackboxnlp-1.25"
    },
    {
        "id": 11420,
        "title": "Truth and Regret: Large Language Models, the Quran, and Misinformation",
        "authors": "Ali-Reza Bhojani, Marcus Schwarting",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/14746700.2023.2255944"
    },
    {
        "id": 11421,
        "title": "Programming Computational Electromagnetic Applications Assisted by Large Language Models [Em Programmer’s Notebook]",
        "authors": "Leandro Carísio Fernandes",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/map.2023.3336708"
    },
    {
        "id": 11422,
        "title": "Large Language Models for Therapy Recommendations Across 3 Clinical Specialties: Comparative Study",
        "authors": "Theresa Isabelle Wilhelm, Jonas Roos, Robert Kaczmarczyk",
        "published": "2023-10-30",
        "citations": 6,
        "abstract": "\nBackground\nAs advancements in artificial intelligence (AI) continue, large language models (LLMs) have emerged as promising tools for generating medical information. Their rapid adaptation and potential benefits in health care require rigorous assessment in terms of the quality, accuracy, and safety of the generated information across diverse medical specialties.\n\n\nObjective\nThis study aimed to evaluate the performance of 4 prominent LLMs, namely, Claude-instant-v1.0, GPT-3.5-Turbo, Command-xlarge-nightly, and Bloomz, in generating medical content spanning the clinical specialties of ophthalmology, orthopedics, and dermatology.\n\n\nMethods\nThree domain-specific physicians evaluated the AI-generated therapeutic recommendations for a diverse set of 60 diseases. The evaluation criteria involved the mDISCERN score, correctness, and potential harmfulness of the recommendations. ANOVA and pairwise t tests were used to explore discrepancies in content quality and safety across models and specialties. Additionally, using the capabilities of OpenAI’s most advanced model, GPT-4, an automated evaluation of each model’s responses to the diseases was performed using the same criteria and compared to the physicians’ assessments through Pearson correlation analysis.\n\n\nResults\nClaude-instant-v1.0 emerged with the highest mean mDISCERN score (3.35, 95% CI 3.23-3.46). In contrast, Bloomz lagged with the lowest score (1.07, 95% CI 1.03-1.10). Our analysis revealed significant differences among the models in terms of quality (P<.001). Evaluating their reliability, the models displayed strong contrasts in their falseness ratings, with variations both across models (P<.001) and specialties (P<.001). Distinct error patterns emerged, such as confusing diagnoses; providing vague, ambiguous advice; or omitting critical treatments, such as antibiotics for infectious diseases. Regarding potential harm, GPT-3.5-Turbo was found to be the safest, with the lowest harmfulness rating. All models lagged in detailing the risks associated with treatment procedures, explaining the effects of therapies on quality of life, and offering additional sources of information. Pearson correlation analysis underscored a substantial alignment between physician assessments and GPT-4’s evaluations across all established criteria (P<.01).\n\n\nConclusions\nThis study, while comprehensive, was limited by the involvement of a select number of specialties and physician evaluators. The straightforward prompting strategy (“How to treat…”) and the assessment benchmarks, initially conceptualized for human-authored content, might have potential gaps in capturing the nuances of AI-driven information. The LLMs evaluated showed a notable capability in generating valuable medical content; however, evident lapses in content quality and potential harm signal the need for further refinements. Given the dynamic landscape of LLMs, this study’s findings emphasize the need for regular and methodical assessments, oversight, and fine-tuning of these AI tools to ensure they produce consistently trustworthy and clinically safe medical advice. Notably, the introduction of an auto-evaluation mechanism using GPT-4, as detailed in this study, provides a scalable, transferable method for domain-agnostic evaluations, extending beyond therapy recommendation assessments.\n",
        "link": "http://dx.doi.org/10.2196/49324"
    },
    {
        "id": 11423,
        "title": "Contrastive Novelty-Augmented Learning: Anticipating Outliers with Large Language Models",
        "authors": "Albert Xu, Xiang Ren, Robin Jia",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.658"
    },
    {
        "id": 11424,
        "title": "Potential benefits of employing large language models in research in moral education and development",
        "authors": "Hyemin Han",
        "published": "2023-9-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/03057240.2023.2250570"
    },
    {
        "id": 11425,
        "title": "ChatGPT is not capable of serving as an author: ethical concerns and challenges of large language models in education",
        "authors": "",
        "published": "2023-10-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.56726/irjmets45212"
    },
    {
        "id": 11426,
        "title": "Time and Cost Prediction Models for Language Classification Over a Large Corpus on Spark",
        "authors": "Jairson B. Rodrigues, Germano C. Vasconcelos, Paulo R. M. Maciel",
        "published": "2020-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ssci47803.2020.9308299"
    },
    {
        "id": 11427,
        "title": "Eliciting Knowledge from Large Pre-Trained Models for Unsupervised Knowledge-Grounded Conversation",
        "authors": "Yanyang Li, Jianqiao Zhao, Michael Lyu, Liwei Wang",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.721"
    },
    {
        "id": 11428,
        "title": "Human-like problem-solving abilities in large language models using ChatGPT",
        "authors": "Graziella Orrù, Andrea Piarulli, Ciro Conversano, Angelo Gemignani",
        "published": "2023-5-24",
        "citations": 15,
        "abstract": "BackgroundsThe field of Artificial Intelligence (AI) has seen a major shift in recent years due to the development of new Machine Learning (ML) models such as Generative Pre-trained Transformer (GPT). GPT has achieved previously unheard-of levels of accuracy in most computerized language processing tasks and their chat-based variations.AimThe aim of this study was to investigate the problem-solving abilities of ChatGPT using two sets of verbal insight problems, with a known performance level established by a sample of human participants.Materials and methodsA total of 30 problems labeled as “practice problems” and “transfer problems” were administered to ChatGPT. ChatGPT's answers received a score of “0” for each incorrectly answered problem and a score of “1” for each correct response. The highest possible score for both the practice and transfer problems was 15 out of 15. The solution rate for each problem (based on a sample of 20 subjects) was used to assess and compare the performance of ChatGPT with that of human subjects.ResultsThe study highlighted that ChatGPT can be trained in out-of-the-box thinking and demonstrated potential in solving verbal insight problems. The global performance of ChatGPT equalled the most probable outcome for the human sample in both practice problems and transfer problems as well as upon their combination. Additionally, ChatGPT answer combinations were among the 5% of most probable outcomes for the human sample both when considering practice problems and pooled problem sets. These findings demonstrate that ChatGPT performance on both set of problems was in line with the mean rate of success of human subjects, indicating that it performed reasonably well.ConclusionsThe use of transformer architecture and self-attention in ChatGPT may have helped to prioritize inputs while predicting, contributing to its potential in verbal insight problem-solving. ChatGPT has shown potential in solving insight problems, thus highlighting the importance of incorporating AI into psychological research. However, it is acknowledged that there are still open challenges. Indeed, further research is required to fully understand AI's capabilities and limitations in verbal problem-solving.",
        "link": "http://dx.doi.org/10.3389/frai.2023.1199350"
    },
    {
        "id": 11429,
        "title": "Leveraging Open-Source Large Language Models for Data Augmentation to Improve Text Classification in Surveys of Medical Staff (Preprint)",
        "authors": "Carl Ehrett, Sudeep Hegde, Kwame Andre, Dixizi Liu, Timothy Wilson",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nGenerative large language models (LLMs) have the potential to revolutionize medical education by generating tailored learning materials, enhancing teaching efficiency, and improving learner engagement. However, the application of LLMs in healthcare settings, particularly for augmenting small datasets in text classification tasks, remains underexplored, particularly for cost- and privacy-conscious applications that do not permit the use of third-party services such as OpenAI’s ChatGPT.\n\n\nOBJECTIVE\nThis paper explores the use of open-source LLMs, such as Large Language Model Meta AI (LLaMA) and Alpaca models, for data augmentation in a specific text classification task related to hospital staff surveys.\n\n\nMETHODS\nThe surveys were designed to elicit narratives of everyday adaptation by frontline radiology staff during the initial phase of the COVID-19 pandemic. The study evaluates the effectiveness of various LLMs, temperature settings, and downstream classifiers in improving classifier performance.\n\n\nRESULTS\nThe overall best-performing combination of LLM, temperature, classifier, and number of augments is LLaMA 7B at temperature 0.7 using Robustly Optimized BERT Pretraining Approach (RoBERTa) with 100 augments, with an average the Area Under the Receiver Operating Characteristic curve (AUC) of [0.87] ±[0.02: 1 standard deviation].  The results demonstrate that open-source LLMs can enhance text classifiers' performance for small datasets in healthcare contexts, providing promising pathways for improving medical education processes and patient care practices.\n\n\nCONCLUSIONS\nThe study demonstrates the value of data augmentation with open-source LLMs, highlights the importance of privacy and ethical considerations when using LLMs, and suggests future directions for research in this field.\n",
        "link": "http://dx.doi.org/10.2196/preprints.51433"
    },
    {
        "id": 11430,
        "title": "How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure",
        "authors": "Michael Wilson, Jackson Petty, Robert Frank",
        "published": "2023-11-13",
        "citations": 0,
        "abstract": "Abstract\nLanguage models are typically evaluated on their success at predicting the distribution of specific words in specific contexts. Yet linguistic knowledge also encodes relationships between contexts, allowing inferences between word distributions. We investigate the degree to which pre-trained transformer-based large language models (LLMs) represent such relationships, focusing on the domain of argument structure. We find that LLMs perform well in generalizing the distribution of a novel noun argument between related contexts that were seen during pre-training (e.g., the active object and passive subject of the verb spray), succeeding by making use of the semantically organized structure of the embedding space for word embeddings. However, LLMs fail at generalizations between related contexts that have not been observed during pre-training, but which instantiate more abstract, but well-attested structural generalizations (e.g., between the active object and passive subject of an arbitrary verb). Instead, in this case, LLMs show a bias to generalize based on linear order. This finding points to a limitation with current models and points to a reason for which their training is data-intensive.1",
        "link": "http://dx.doi.org/10.1162/tacl_a_00608"
    },
    {
        "id": 11431,
        "title": "Research and Application of GPT-Based Large Language Models in Business and Economics: A Systematic Literature Review in Progress",
        "authors": "Yuzhang Han, Jing Hou, Yi Sun",
        "published": "2023-10-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icoco59262.2023.10397642"
    },
    {
        "id": 11432,
        "title": "Forgetful Large Language Models: Lessons Learned from Using LLMs in Robot Programming",
        "authors": "Juo-Tung Chen, Chien-Ming Huang",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "Large language models offer new ways of empowering people to program robot applications-namely, code generation via prompting. However, the code generated by LLMs is susceptible to errors. This work reports a preliminary exploration that empirically characterizes common errors produced by LLMs in robot programming. We categorize these errors into two phases: interpretation and execution. In this work, we focus on errors in execution and observe that they are caused by LLMs being “forgetful” of key information provided in user prompts. Based on this observation, we propose prompt engineering tactics designed to reduce errors in execution. We then demonstrate the effectiveness of these tactics with three language models: ChatGPT, Bard, and LLaMA-2. Finally, we discuss lessons learned from using LLMs in robot programming and call for the benchmarking of LLM-powered end-user development of robot applications.",
        "link": "http://dx.doi.org/10.1609/aaaiss.v2i1.27721"
    },
    {
        "id": 11433,
        "title": "Assessing the Utilization of Large Language Models in Medical Education: Insights From Undergraduate Medical Students",
        "authors": "Sairavi Kiran Biri, Subir Kumar, Muralidhar Panigrahi, Shaikat Mondal, Joshil Kumar Behera, Himel Mondal",
        "published": "2023-10-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7759/cureus.47468"
    },
    {
        "id": 11434,
        "title": "Exploratory Inference Chain: Exploratorily Chaining Multi-hop Inferences with Large Language Models for Question-Answering",
        "authors": "Shosuke Haji, Keiichi Suekane, Hirofumi Sano, Tomohiro Takagi",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icsc56153.2023.00036"
    },
    {
        "id": 11435,
        "title": "EW-Tune: A Framework for Privately Fine-Tuning Large Language Models with Differential Privacy",
        "authors": "Rouzbeh Behnia, Mohammadreza Reza Ebrahimi, Jason Pacheco, Balaji Padmanabhan",
        "published": "2022-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdmw58026.2022.00078"
    },
    {
        "id": 11436,
        "title": "Prompting Metalinguistic Awareness in Large Language Models: ChatGPT and Bias Effects on the Grammar of Italian and Italian Varieties",
        "authors": "Angelapia Massaro, Giuseppe Samo",
        "published": "2023-12-20",
        "citations": 0,
        "abstract": "We explore ChatGPT’s handling of left-peripheral phenomena in Italian and Italian varieties through prompt engineering to investigate 1) forms of syntactic bias in the model, 2) the model’s metalinguistic awareness in relation to reorderings of canonical clauses (e.g., Topics) and certain grammatical categories (object clitics). A further question concerns the content of the model’s sources of training data: how are minor languages included in the model’s training? The results of our investigation show that 1) the model seems to be biased against reorderings, labelling them as archaic even though it is not the case; 2) the model seems to have difficulties with coindexed elements such as clitics and their anaphoric status, labeling them as ‘not referring to any element in the phrase’, and 3) major languages still seem to be dominant, overshadowing the positive effects of including minor languages in the model’s training.",
        "link": "http://dx.doi.org/10.15388/verb.42"
    },
    {
        "id": 11437,
        "title": "Language and Models",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_0007"
    },
    {
        "id": 11438,
        "title": "Stereotypes in Language Models",
        "authors": "Mascha Kurpicz-Briki",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-37690-0_6"
    },
    {
        "id": 11439,
        "title": "Language and Models",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_0007"
    },
    {
        "id": 11440,
        "title": "Pre-trained Language Models",
        "authors": "Gerhard Paaß, Sven Giesselbach",
        "published": "2023",
        "citations": 0,
        "abstract": "AbstractThis chapter presents the main architecture types of attention-based language models, which describe the distribution of tokens in texts: Autoencoders similar to BERT receive an input text and produce a contextual embedding for each token. Autoregressive language models similar to GPT receive a subsequence of tokens as input. They produce a contextual embedding for each token and predict the next token. In this way, all tokens of a text can successively be generated. Transformer Encoder-Decoders have the task to translate an input sequence to another sequence, e.g. for language translation. First they generate a contextual embedding for each input token by an autoencoder. Then these embeddings are used as input to an autoregressive language model, which sequentially generates the output sequence tokens. These models are usually pre-trained on a large general training set and often fine-tuned for a specific task. Therefore, they are collectively called Pre-trained Language Models (PLM). When the number of parameters of these models gets large, they often can be instructed by prompts and are called Foundation Models. In further sections we described details on optimization and regularization methods used for training. Finally, we analyze the uncertainty of model predictions and how predictions may be explained.",
        "link": "http://dx.doi.org/10.1007/978-3-031-23190-2_2"
    },
    {
        "id": 11441,
        "title": "WIKITIDE: A WIKIPEDIA-BASED TIMESTAMPED DEFINITION Pairs Dataset",
        "authors": "Hsuvas Borkakoty,  , Luis Espinosa-Anke,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_023"
    },
    {
        "id": 11442,
        "title": "Generation of Korean Offensive Language by Leveraging Large Language Models via Prompt Design",
        "authors": "Jisu Shin, Hoyun Song, Huije Lee, Fitsum Gaim, Jong Park",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.ijcnlp-main.62"
    },
    {
        "id": 11443,
        "title": "Studying the Effect of Globalization on Color Perception using Multilingual Online Recruitment and Large Language Models",
        "authors": "Jakob Niedermann, Ilia Sucholutsky, Raja Marjieh, Elif Celen, Thomas L. Griffiths, Nori Jacoby, Pol van Rijn",
        "published": "No Date",
        "citations": 0,
        "abstract": "How does globalization impact the interaction between perception and language? Building on Berlin and Kay's foundational study of color naming, we recruited 2,280 online participants speaking 22 different languages. We show that color naming maps differ structurally across languages, even among internet users living in (mostly) industrial societies. We use Large Language Models (LLMs) to simulate the limits of globalization by reproducing the naming task with a highly multilingual artificial agent with access to global digital information. We show that while the LLM has access to all languages, it has language-specific color representations and the number of color terms is correlated across humans and LLMs. However, LLMs use more color terms than humans, indicating differences in the representation. These results suggest that globalization has not removed cultural distinctions in color concepts, as language continues to be a key factor in the diversity of perception and meaning.",
        "link": "http://dx.doi.org/10.31234/osf.io/3jvxw"
    },
    {
        "id": 11444,
        "title": "GenAI against humanity: nefarious applications of generative artificial intelligence and large language models",
        "authors": "Emilio Ferrara",
        "published": "2024-2-22",
        "citations": 0,
        "abstract": "AbstractGenerative Artificial Intelligence (GenAI) and Large Language Models (LLMs) are marvels of technology; celebrated for their prowess in natural language processing and multimodal content generation, they promise a transformative future. But as with all powerful tools, they come with their shadows. Picture living in a world where deepfakes are indistinguishable from reality, where synthetic identities orchestrate malicious campaigns, and where targeted misinformation or scams are crafted with unparalleled precision. Welcome to the darker side of GenAI applications. This article is not just a journey through the meanders of potential misuse of GenAI and LLMs, but also a call to recognize the urgency of the challenges ahead. As we navigate the seas of misinformation campaigns, malicious content generation, and the eerie creation of sophisticated malware, we’ll uncover the societal implications that ripple through the GenAI revolution we are witnessing. From AI-powered botnets on social media platforms to the unnerving potential of AI to generate fabricated identities, or alibis made of synthetic realities, the stakes have never been higher. The lines between the virtual and the real worlds are blurring, and the consequences of potential GenAI’s nefarious applications impact us all. This article serves both as a synthesis of rigorous research presented on the risks of GenAI and misuse of LLMs and as a thought-provoking vision of the different types of harmful GenAI applications we might encounter in the near future, and some ways we can prepare for them.",
        "link": "http://dx.doi.org/10.1007/s42001-024-00250-1"
    },
    {
        "id": 11445,
        "title": "ChatGPT and Large Language Models in Healthcare: Opportunities and Risks",
        "authors": "Hazrat Ali, Junaid Qadir, Tanvir Alam, Mowafa Househ, Zubair Shah",
        "published": "2023-9-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aibthings58340.2023.10291020"
    },
    {
        "id": 11446,
        "title": "Diverse Lottery Tickets Boost Ensemble from a Single Pretrained Model",
        "authors": "Sosuke Kobayashi, Shun Kiyono, Jun Suzuki, Kentaro Inui",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bigscience-1.4"
    },
    {
        "id": 11447,
        "title": "Towards Lightweight Javascript Engine Acceleration for Privacy-Aware Distributed Learning in Large Language Models",
        "authors": "Chen Liang, Guoyu Wang, Ning Li, Zuo Wang, Weihong Zeng, Fu-an Xiao, Yu-an Tan, Yuanzhang Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4694320"
    },
    {
        "id": 11448,
        "title": "Large Language Models with Controllable Working Memory",
        "authors": "Daliang Li, Ankit Singh Rawat, Manzil Zaheer, Xin Wang, Michal Lukasik, Andreas Veit, Felix Yu, Sanjiv Kumar",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.112"
    },
    {
        "id": 11449,
        "title": "Taking ChatGPT as an example to analyze the main technologies used in large language models",
        "authors": "Maohong Liao",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "In recent years, the rapid development of large-scale language models has attracted much attention in natural language processing. This paper focuses on large-scale models such as ChatGPT and provides insights into the advancement and application of key technologies used in these models. By exploring model architectures, pre-training techniques, transfer learning, self-supervised learning, multimodal learning, fine-grained control, and long-text processing, we reveal how these techniques have driven the evolution of language models, leading to notable achievements in various fields. By providing insights into these technologies, we aim to provide researchers and practitioners with a comprehensive perspective on the challenges and opportunities in language processing.",
        "link": "http://dx.doi.org/10.61173/qecdqw17"
    },
    {
        "id": 11450,
        "title": "Who Can be Your AI Doctor?: Evaluation for Disease diagnosis on Large Language Models",
        "authors": "Jonghyeon Kim, Chan-Yang Ju, Dong-Ho Lee",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ictc58733.2023.10392305"
    },
    {
        "id": 11451,
        "title": "Contribution and performance of ChatGPT and other Large Language Models (LLM) for scientific and research advancements: a double-edged sword",
        "authors": "",
        "published": "2023-10-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.56726/irjmets45213"
    },
    {
        "id": 11452,
        "title": "Evaluation of Hallucination and Robustness for Large Language Models",
        "authors": "Rui Hu, Junhao Zhong, Minjie Ding, Zeyu Ma, Mingang Chen",
        "published": "2023-10-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/qrs-c60940.2023.00089"
    },
    {
        "id": 11453,
        "title": "Review Prediction Using Large-Scale Language Models for Serendipity-Oriented Tourist Spot Recommendation and its Evaluation",
        "authors": "Feng Guan, Daisuke Kitayama",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/imcom60618.2024.10418409"
    },
    {
        "id": 11454,
        "title": "Geotechnical Parrot Tales (GPT): Harnessing Large Language Models in Geotechnical Engineering",
        "authors": "Krishna Kumar",
        "published": "2024-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1061/jggefk.gteng-11828"
    },
    {
        "id": 11455,
        "title": "Do Large Language Models Show Human-like Biases? Exploring Confidence—Competence Gap in AI",
        "authors": "Aniket Kumar Singh, Bishal Lamichhane, Suman Devkota, Uttam Dhakal, Chandra Dhakal",
        "published": "2024-2-6",
        "citations": 0,
        "abstract": "This study investigates self-assessment tendencies in Large Language Models (LLMs), examining if patterns resemble human cognitive biases like the Dunning–Kruger effect. LLMs, including GPT, BARD, Claude, and LLaMA, are evaluated using confidence scores on reasoning tasks. The models provide self-assessed confidence levels before and after responding to different questions. The results show cases where high confidence does not correlate with correctness, suggesting overconfidence. Conversely, low confidence despite accurate responses indicates potential underestimation. The confidence scores vary across problem categories and difficulties, reducing confidence for complex queries. GPT-4 displays consistent confidence, while LLaMA and Claude demonstrate more variations. Some of these patterns resemble the Dunning–Kruger effect, where incompetence leads to inflated self-evaluations. While not conclusively evident, these observations parallel this phenomenon and provide a foundation to further explore the alignment of competence and confidence in LLMs. As LLMs continue to expand their societal roles, further research into their self-assessment mechanisms is warranted to fully understand their capabilities and limitations.",
        "link": "http://dx.doi.org/10.3390/info15020092"
    },
    {
        "id": 11456,
        "title": "Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses",
        "authors": "Aysa Fan, Haoran Zhang, Luc Paquette, Rui Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.496"
    },
    {
        "id": 11457,
        "title": "SAPIEN: Affective Virtual Agents Powered by Large Language Models<sup>*</sup>",
        "authors": "Masum Hasan, Cengiz Ozel, Sammy Potter, Ehsan Hoque",
        "published": "2023-9-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aciiw59127.2023.10388188"
    },
    {
        "id": 11458,
        "title": "Large Language Models: An Emerging Technology in Accounting",
        "authors": "Miklos A. Vasarhelyi, Kevin C. Moffitt, Trevor Stewart, Dan Sunderland",
        "published": "2023-10-1",
        "citations": 3,
        "abstract": "ABSTRACT\nThis commentary discusses how large language models like ChatGPT hold transformative potential in accounting, including education, research, and professional auditing. In the educational sphere, the advent of ubiquitous artificial intelligence (AI) tutors could potentially solve Bloom’s Two Sigma Problem, heralding a new era of personalized learning. Accounting research stands to benefit immensely, particularly in tasks that rely heavily on natural language processing. In the professional auditing domain, the capabilities of ChatGPT to create broad outlines of risks inherent in certain accounts and assertions can enable engagement teams to create more risk-responsive audit plans. However, although the advantages are remarkable, they are accompanied by potential pitfalls that necessitate cautious navigation. Even with these challenges, AI’s impending transformation in personal and professional lives cannot be overlooked, as accounting stands on the brink of significant change.\nJEL Classifications: M40; M42; O33.",
        "link": "http://dx.doi.org/10.2308/jeta-2023-047"
    },
    {
        "id": 11459,
        "title": "Boosting Robot Intelligence in Practice: Enhancing Robot Task Planning with Large Language Models",
        "authors": "Yisheng Zhang, Zhigang Wang, Shengmin Zhang, Yanlong Peng, Ming Chen",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icrae59816.2023.10458574"
    },
    {
        "id": 11460,
        "title": "Understanding HTML with Large Language Models",
        "authors": "Izzeddin Gur, Ofir Nachum, Yingjie Miao, Mustafa Safdari, Austin Huang, Aakanksha Chowdhery, Sharan Narang, Noah Fiedel, Aleksandra Faust",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.185"
    },
    {
        "id": 11461,
        "title": "PreCog: Exploring the Relation between Memorization and Performance in Pre-trained Language Models",
        "authors": "Leonardo Ranaldi,  , Elena Sofia Ruzzetti, Fabio Massimo Zanzotto,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_103"
    },
    {
        "id": 11462,
        "title": "Large Language Models: Are Artificial Intelligence-Based Chatbots a Reliable Source of Patient Information for Spinal Surgery?",
        "authors": "Anna Stroop, Tabea Stroop, Samer Zawy Alsofy, Makoto Nakamura, Frank Möllmann, Christoph Greiner, Ralf Stroop",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4435298"
    },
    {
        "id": 11463,
        "title": "Editorial 2024: Large language models, artificial intelligence and geomorphology",
        "authors": "Stuart N. Lane",
        "published": "2024-1",
        "citations": 0,
        "abstract": "AbstractLarge language models (LLMs), such as ChatGPT, have seen an explosion of interest over the last 12 months. It is hard to see an area of education and research where we are not having to face the challenge they pose, a form of artificial intelligence (AI) that is capable of generating text in response to relatively minimum prompting. The text generated can be surprisingly convincing. We now have definitive evidence of work being submitted to Earth Surface Processes and Landforms (ESPL) that has made use of LLMs. As a result, the Editorial Board has recently developed its policy on the use of LLMs in authoring, reviewing and editing papers. In developing our policy, we have taken note that through the journal's publisher Wiley, we are a signatory to the Committee on Publication Ethics (COPE, https://publicationethics.org/). COPE provides us with a framework within which our policy sits, one that given the speed with which LLMs are developing means that it will not be definitive and will surely need to be revisited over the not‐too‐distant future. This extended editorial explains our policy, specifies guidelines for authors, reviewers and editors and also reflects more generally on the positive opportunities and challenges that emerging forms of AI pose to our community and our stated goal of publishing research in geomorphology that is of the highest quality.",
        "link": "http://dx.doi.org/10.1002/esp.5773"
    },
    {
        "id": 11464,
        "title": "Integrating Retrieval-Augmented Generation with Large Language Models in Nephrology: Advancing Practical Applications",
        "authors": "Jing Miao, Charat Thongprayoon, Supawadee Suppadungsuk, Oscar A. Garcia Valencia, Wisit Cheungpasitporn",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "The integration of large language models (LLMs) into healthcare, particularly in nephrology, represents a significant advancement in applying advanced technology to patient care, medical research, and education. These advanced models have progressed from simple text processors to tools capable of deep language understanding, offering innovative ways to handle health-related data, thus improving medical practice efficiency and effectiveness. A significant challenge in medical applications of LLMs is their imperfect accuracy and/or tendency to produce hallucinations—outputs that are factually incorrect or irrelevant. This issue is particularly critical in healthcare, where precision is essential, as inaccuracies can undermine the reliability of these models in crucial decision-making processes. To overcome these challenges, various strategies have been developed. One such strategy is prompt engineering, like the chain-of-thought approach, which directs LLMs towards more accurate responses by breaking down the problem into intermediate steps or reasoning sequences. Another one is the retrieval-augmented generation (RAG) strategy, which helps address hallucinations by integrating external data, enhancing output accuracy and relevance. Hence, RAG is favored for tasks requiring up-to-date, comprehensive information, such as in clinical decision making or educational applications. In this article, we showcase the creation of a specialized ChatGPT model integrated with a RAG system, tailored to align with the KDIGO 2023 guidelines for chronic kidney disease. This example demonstrates its potential in providing specialized, accurate medical advice, marking a step towards more reliable and efficient nephrology practices.",
        "link": "http://dx.doi.org/10.3390/medicina60030445"
    },
    {
        "id": 11465,
        "title": "Industrial Engineering with Large Language Models: A Case Study of ChatGPT's Performance on Oil &amp; Gas Problems",
        "authors": "Oluwatosin Ogundare, Srinath Madasu, Nathanial Wiggins",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccma59762.2023.10374622"
    },
    {
        "id": 11466,
        "title": "ChatGPT, Bard, and Large Language Models for Biomedical Research: Opportunities and Pitfalls",
        "authors": "Surendrabikram Thapa, Surabhi Adhikari",
        "published": "2023-12",
        "citations": 20,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10439-023-03284-0"
    },
    {
        "id": 11467,
        "title": "Optimizing Single DGX-A100 System: Overcoming GPU Limitations via Efficient Parallelism and Scheduling for Large Language Models",
        "authors": "Kyeong-Hwan Kim, Chang-Sung Jeong",
        "published": "2023-8-16",
        "citations": 0,
        "abstract": "In this study, we introduce a novel training algorithm specifically designed to overcome the limitations of GPU memory on a single DGX-A100 system. By utilizing the CPU and main memory in the training process and applying a strategy of division and parallelization, our algorithm enhances the size of the trainable language model and the batch size. In addition, we developed a comprehensive management system to effectively manage the execution of the algorithm. This system systematically controls the training process and resource usage, while also enabling the asynchronous deployment of tasks. Finally, we proposed a scheduling technique integrated into the management system, promoting efficient task scheduling in a complex, heterogeneous training environment. These advancements equip researchers with the ability to work with larger models and batch sizes, even when faced with limited GPU memory.",
        "link": "http://dx.doi.org/10.3390/app13169306"
    },
    {
        "id": 11468,
        "title": "Comparing the Evaluation and Production of Loophole Behavior in Humans and Large Language Models",
        "authors": "Sonia Murthy, Kiera Parece, Sophie Bridgers, Peng Qian, Tomer Ullman",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.264"
    },
    {
        "id": 11469,
        "title": "Benchmarking Causal Study to Interpret Large Language Models for Source Code",
        "authors": "Daniel Rodriguez-Cardenas, David N. Palacio, Dipin Khati, Henry Burke, Denys Poshyvanyk",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icsme58846.2023.00040"
    },
    {
        "id": 11470,
        "title": "S1702 Comparing Large Language Models Accuracy in Following Interval Surveillance Colonoscopy Guidelines",
        "authors": "Gregory Brennan, Olufemi E. Osikoya",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14309/01.ajg.0000956448.72258.9a"
    },
    {
        "id": 11471,
        "title": "A Post-Processing Framework for Crowd Worker Responses Using Large Language Models",
        "authors": "Ryuya Itano, Tatsuki Tamano, Takahiro Koita, Honoka Tanitsu",
        "published": "2023-4",
        "citations": 0,
        "abstract": "To develop quality crowdsourcing systems, aggregating responses from workers is a critical issue. However, it has been difficult to construct an automatic mechanism that flexibly aggregates worker responses in natural language. Accordingly, responses need to be collected in a standardized format, such as binary-choice or multiple categorizations, to avoid large aggregation costs. Recently, with the advent of large language models (LLMs), natural language responses can be automatically and flexibly aggregated. We propose a framework that uses LLMs to flexibly aggregate natural language responses from workers and, as a promising example, consider this framework for crime detection from surveillance cameras using crowdsourced cognitive abilities. In an experiment using subjective evaluation, our proposed framework is shown to be effective for automatically aggregating natural language responses from crowd workers.",
        "link": "http://dx.doi.org/10.54808/jsci.21.02.1"
    },
    {
        "id": 11472,
        "title": "Prompt Engineering: Guiding the Way to Effective Large Language Models",
        "authors": "Mohammad Aljanabi, Mohanad Ghazi Yaseen, Ahmed Hussein Ali, Mostafa Abdulghafoor Mohammed",
        "published": "2023-11-6",
        "citations": 1,
        "abstract": "Large language models (LLMs) have become prominent tools in various domains, such as natural language processing, machine translation, and the development of creative text. Nevertheless, in order to fully exploit the capabilities of Language Models, it is imperative to establish efficient communication channels between humans and machines. The discipline of engineering involves the creation of well-constructed and informative prompts, which act as a crucial link between human intention and the execution of tasks by machines. The present study examines the concept of rapid engineering, elucidating its underlying concepts, methodologies, and diverse range of practical applications.",
        "link": "http://dx.doi.org/10.52866/ijcsm.2023.04.04.012"
    },
    {
        "id": 11473,
        "title": "Enhancing Continuous Auditing with Large Language Models: A Framework for Cross-Verification Using Exogenous Textual Data",
        "authors": "Huaxia Li, Marcelo Machado de Freitas, Heejae Lee, Miklos Vasarhelyi",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4692960"
    },
    {
        "id": 11474,
        "title": "Perils and Opportunities in Using Large Language Models in Psychological Research",
        "authors": "Suhaib Abdurahman, Mohammad Atari, Farzan Karimi-Malekabadi, Mona J. Xue, Jackson Trager, Peter S. Park, Preni Golazizian, Ali Omrani, Morteza Dehghani",
        "published": "No Date",
        "citations": 1,
        "abstract": "The emergence of large language models (LLMs) has sparked considerable interest in their potential application in psychological research, either as a human-like entity used as a model for the human psyche or as a general text-analysis tool. However, carelessly using LLMs in psychological studies, a trend we rhetorically refer to as “GPTology,” can have negative consequences, especially given the convenient access to models such as ChatGPT. We elucidate the promises, limitations, and ethical considerations of using LLMs in psychological research. First, LLM-based research should pay attention to the substantial psychological diversity around the globe, as well as demographic diversity within populations. Second, while LLMs are convenient tools, we caution against treating them as a one-size-fits-all method for psychological text analysis. Third, LLM-based psychological research needs to develop methods and standards to compensate for LLMs’ opaque black-box nature to facilitate reproducibility, transparency, and robust inference from AI-generated data. While acknowledging the prospects offered by LLMs for easy task automation (e.g., text annotation) and to expand our understanding of human psychology (e.g., by contrasting human and machine psychology), we make a case for diversifying human samples and expanding psychology’s methodological toolbox to achieve a truly inclusive and generalizable science, rather than homogenizing samples and methods through over-reliance on LLMs.",
        "link": "http://dx.doi.org/10.31234/osf.io/d695y"
    },
    {
        "id": 11475,
        "title": "The application of multimodal large language models in medicine",
        "authors": "Jianing Qiu, Wu Yuan, Kyle Lam",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.lanwpc.2024.101048"
    },
    {
        "id": 11476,
        "title": "Fine-grained Affective Processing Capabilities Emerging from Large Language Models",
        "authors": "Joost Broekens, Bernhard Hilpert, Suzan Verberne, Kim Baraka, Patrick Gebhard, Aske Plaat",
        "published": "2023-9-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/acii59096.2023.10388177"
    },
    {
        "id": 11477,
        "title": "Decoding ChatGPT: A primer on large language models for clinicians",
        "authors": "R. Brandon Hunter, Sanjiv D. Mehta, Alfonso Limon, Anthony C. Chang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ibmed.2023.100114"
    },
    {
        "id": 11478,
        "title": "Embodying the Algorithm",
        "authors": "Mirabelle Jones, Christina Neumayer, Irina Shklovski",
        "published": "2023-4-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3544548.3580885"
    },
    {
        "id": 11479,
        "title": "Benchmarking Large Language Models for News Summarization",
        "authors": "Tianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang, Kathleen McKeown, Tatsunori B. Hashimoto",
        "published": "2024-1-31",
        "citations": 6,
        "abstract": "Abstract\nLarge language models (LLMs) have shown promise for automatic summarization but the reasons behind their successes are poorly understood. By conducting a human evaluation on ten LLMs across different pretraining methods, prompts, and model scales, we make two important observations. First, we find instruction tuning, not model size, is the key to the LLM’s zero-shot summarization capability. Second, existing studies have been limited by low-quality references, leading to underestimates of human performance and lower few-shot and finetuning performance. To better evaluate LLMs, we perform human evaluation over high-quality summaries we collect from freelance writers. Despite major stylistic differences such as the amount of paraphrasing, we find that LLM summaries are judged to be on par with human written summaries.",
        "link": "http://dx.doi.org/10.1162/tacl_a_00632"
    },
    {
        "id": 11480,
        "title": "Simultaneous Interpreting as a Noisy Channel: How Much Information Gets Through",
        "authors": "Maria Kunilovskaya,  , Heike Przybyl, Elke Teich, Ekaterina Lapshinova-Koltunski,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_066"
    },
    {
        "id": 11481,
        "title": "Improving Pre-trained Language Models",
        "authors": "Gerhard Paaß, Sven Giesselbach",
        "published": "2023",
        "citations": 1,
        "abstract": "AbstractThis chapter describes a number of different approaches to improve the performance of Pre-trained Language Models (PLMs), i.e. variants of BERT, autoregressive language models similar to GPT, and sequence-to-sequence models like Transformers. First we may modify the pre-training tasks to learn as much as possible about the syntax and semantics of language. Then we can extend the length of the input sequence to be able to process longer inputs. Multilingual models are simultaneously trained with text in different languages. Most important is the inclusion of further knowledge into the PLM to produce better predictions. It turns out that by increasing the number of parameters, the size of the training data and the computing effort the performance of the models can always be increased. There are a number of different fine-tuning strategies which allow the model to be adapted to special tasks. In addition, models may be instructed by few-shot prompts to solve specific tasks. This is especially rewarding for larger PLMs, which therefore are called Foundation Models.",
        "link": "http://dx.doi.org/10.1007/978-3-031-23190-2_3"
    },
    {
        "id": 11482,
        "title": "Large-scale point-of-interest category prediction using natural language processing models",
        "authors": "Daniel Zhang, Dong Wang, Hao Zheng, Xin Mu, Qi Li, Yang Zhang",
        "published": "2017-12",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata.2017.8258026"
    },
    {
        "id": 11483,
        "title": "The Use of Large Language Models to Generate Education Materials about Uveitis",
        "authors": "Reza Kianian, Deyu Sun, Eric L. Crowell, Edmund Tsui",
        "published": "2024-2",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.oret.2023.09.008"
    },
    {
        "id": 11484,
        "title": "ChatGPT and Beyond: An overview of the growing field of large language models and their use in ophthalmology",
        "authors": "Nikita Kedia, Suvansh Sanjeev, Joshua Ong, Jay Chhablani",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41433-023-02915-z"
    },
    {
        "id": 11485,
        "title": "Reducing Spurious Correlations in Aspect-based Sentiment Analysis with Explanation from Large Language Models",
        "authors": "Qianlong Wang, Keyang Ding, Bin Liang, Min Yang, Ruifeng Xu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.193"
    },
    {
        "id": 11486,
        "title": "Patient Centric Summarization of Radiology Findings using Large Language Models",
        "authors": "Amara Tariq, Sam Fathizadeh, Gokul Ramaswamy, Shubham Trivedi, Aisha Urooj, Nelly Tan, Matthew T. Stib, Bhavik N. Patel, Imon Banerjee",
        "published": "No Date",
        "citations": 0,
        "abstract": "ABSTRACTObjectiveDevelop automated AI models for patient-sensitive summarization of radiology reports. Level of medical education or socio-economic background of a patient may dictate their level of understanding of medical jargon. Inability to understand primary findings from a radiology report may lead to unnecessary anxiety among patients or result in missed follow up.Materials and MethodsComputed tomography exams of chest were selected as a use-case for this study. Approximately 7K chest CT reports were collected from Mayo Clinic Enterprise. Summarization model was built on the T5 large language model (LLM) as its text-to-text transfer architecture is intuitively suited for abstractive text summarization, resulting in a model size of ~0.77B. Noisy groundtruth for model training was collected by prompting LLaMA 13B model.ResultsWe recruited both experts (board-certified radiologists) and laymen to manually evaluate summaries generated by model. Model-generated summaries rarely missed information as marked by majority opinion of radiologists. Laymen indicated 63% improvement in their understanding by reading layman summaries generated by the model. Comparative study with zero-shot performance of LLaMA indicated that LLaMA hallucinated and missed information 3 and 4 times more often, respectively, than the proposed model.DiscussionThe proposed patient-sensitive summarization model can generate summaries for radiology reports understandable by patients with vastly different levels of medical knowledge. In addition, task-specific training allows for more reliable performance compared to much larger off-the-shelf models.ConclusionsThe proposed model could improve adherence to follow up treatment suggested by radiology reports by increasing patients’ level of understanding of these reports.",
        "link": "http://dx.doi.org/10.1101/2024.02.01.24302145"
    },
    {
        "id": 11487,
        "title": "Evaluating the Carbon Impact of Large Language Models at the Inference Stage",
        "authors": "Brad Everman, Trevor Villwock, Dayuan Chen, Noe Soto, Oliver Zhang, Ziliang Zong",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ipccc59175.2023.10253886"
    },
    {
        "id": 11488,
        "title": "CodaMosa: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models",
        "authors": "Caroline Lemieux, Jeevana Priya Inala, Shuvendu K. Lahiri, Siddhartha Sen",
        "published": "2023-5",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icse48619.2023.00085"
    },
    {
        "id": 11489,
        "title": "DISCO: Distilling Counterfactuals with Large Language Models",
        "authors": "Zeming Chen, Qiyue Gao, Antoine Bosselut, Ashish Sabharwal, Kyle Richardson",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.302"
    },
    {
        "id": 11490,
        "title": "Under what circumstances do Large Language Models (LLMs) outperform humans, and who judges? A systematic review of task types and benchmarking criteria in social science literature",
        "authors": "Xinzhi Zhang, Yuner ZHU",
        "published": "No Date",
        "citations": 0,
        "abstract": "Humanities and social sciences scholars are recklessly embracing the trend of Large Language Models (LLMs), immersing themselves in a flurry of experiments to test LLMs’ competence against human beings. These ardent efforts have generated a mix of optimism and pessimism in applying LLMs for serious scientific inquiry or inviting LLMs as a professional co-worker in the communication practice. Unfortunately, less investigation interrogates the task type (“what are the LLMs prompted to do”) and the geopolitical considerations in benchmarking criteria for human comparison (“who judges”) in these experiments. Guided by the data science framework and the world system theory, in the current systematic review, we reviewed 71 peer-reviewed empirical articles from the Web of Science database involving LLMs as a part of data generation. For each article, we examined the task type (i.e., prediction, classification, or content production) and the geopolitics of the human benchmarking criteria (i.e., the country of origin). We also examined the valence of researchers’ interpretation of their experimenting results (i.e., euphoric or conversative) on the human-LLMs competition. Results reveal varying conclusions across social science disciplines. LLMs excelled in applied social sciences like business and education but underperformed in philosophy, politics, communication, and ethics. LLMs are less effective in content production (such as generating emails or editorial materials) and prediction tasks but better in classification. Furthermore, a substantial geopolitical bias was evident in the origin of benchmark criteria and human validation samples, with dominance from the US, UK, and developed European nations. We propose recommendations for involving LLMs for social science research in the age of generative AI.",
        "link": "http://dx.doi.org/10.31219/osf.io/d84as"
    },
    {
        "id": 11491,
        "title": "Leveraging Large Language Models for Structure Learning in Prompted Weak Supervision",
        "authors": "Jinyan Su, Peilin Yu, Jieyu Zhang, Stephen H. Bach",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386190"
    },
    {
        "id": 11492,
        "title": "Are Large Language Models Geospatially Knowledgeable?",
        "authors": "Prabin Bhandari, Antonios Anastasopoulos, Dieter Pfoser",
        "published": "2023-11-13",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3589132.3625625"
    },
    {
        "id": 11493,
        "title": "Automatic Post-Traumatic Stress Disorder Diagnosis via Clinical Transcripts: A Novel Text Augmentation with Large Language Models",
        "authors": "Yuqi Wu, Jie Chen, Kaining Mao, Yanbo Zhang",
        "published": "2023-10-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/biocas58349.2023.10388714"
    },
    {
        "id": 11494,
        "title": "The Magic of IF: Investigating Causal Reasoning Abilities in Large Language Models of Code",
        "authors": "Xiao Liu, Da Yin, Chen Zhang, Yansong Feng, Dongyan Zhao",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.574"
    },
    {
        "id": 11495,
        "title": "ELion: An Intelligent Chinese Composition Tutoring System Based on Large Language Models",
        "authors": "Chanjin Zheng, Shaoyang Guo, Wei Xia, Shaoguang Mao",
        "published": "2023-9-1",
        "citations": 1,
        "abstract": "For a long time, Chinese language teachers in primary and secondary schools have been confronting challenges of heavy workload, low efficiency, and difficulty in improving the quality of composition evaluations. This article introduces “ELion”, an intelligent Chinese composition tutoring system based on large language models. The system utilizes deep linguistic features to evaluate the quality of compositions and provide interpretable feedback. By discussing the overall design, evaluation framework structure, and scoring algorithm principles of ELion, this paper addresses the theoretical, technical, and engineering issues of intelligent evaluation of Chinese compositions in the educational context. Small-scale experiments conducted in schools demonstrate that ELion performs well in language error detection, rhetorical techniques, and the expression of actions and emotions. It can basically meet the needs of Chinese language teaching in primary and secondary schools. In the future, ELion will further develop algorithms for ”instruction-learning-evaluation” alignment assessment, and personalized precise feedback generation, based on the GPT model. This will improve the evaluation effectiveness in topic analysis, text structure, and genuine emotional expression. Additionally, systematic field experiments for the system will be conducted to explore the application of artificial intelligence in education.",
        "link": "http://dx.doi.org/10.59863/mpjo6480"
    },
    {
        "id": 11496,
        "title": "What Comes Next for Large Language Models in Medicine?",
        "authors": "Gregory Laynor",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15424065.2024.2320227"
    },
    {
        "id": 11497,
        "title": "Knowledge Transfer from Large-Scale Pretrained Language Models to End-To-End Speech Recognizers",
        "authors": "Yotaro Kubo, Shigeki Karita, Michiel Bacchiani",
        "published": "2022-5-23",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp43922.2022.9746801"
    },
    {
        "id": 11498,
        "title": "LLMs to the Moon? Reddit Market Sentiment Analysis with Large Language Models",
        "authors": "Xiang Deng, Vasilisa Bashlovkina, Feng Han, Simon Baumgartner, Michael Bendersky",
        "published": "2023-4-30",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3543873.3587605"
    },
    {
        "id": 11499,
        "title": "Prompting Is Programming: A Query Language for Large Language Models",
        "authors": "Luca Beurer-Kellner, Marc Fischer, Martin Vechev",
        "published": "2023-6-6",
        "citations": 6,
        "abstract": "Large language models have demonstrated outstanding performance on a wide range of tasks such as question answering and code generation. On a high level, given an input, a language model can be used to automatically complete the sequence in a statistically-likely way. Based on this, users prompt these models with language instructions or examples, to implement a variety of downstream tasks. Advanced prompting methods can even imply interaction between the language model, a user, and external tools such as calculators. However, to obtain state-of-the-art performance or adapt language models for specific tasks, complex task- and model-specific programs have to be implemented, which may still require ad-hoc interaction.Based on this, we present the novel idea of Language Model Programming (LMP). LMP generalizes language model prompting from pure text prompts to an intuitive combination of text prompting and scripting. Additionally, LMP allows constraints to be specified over the language model output. This enables easy adaption to many tasks while abstracting language model internals and providing high-level semantics.To enable LMP, we implement LMQL (short for Language Model Query Language), which leverages the constraints and control flow from an LMP prompt to generate an efficient inference procedure that minimizes the number of expensive calls to the underlying language model.We show that LMQL can capture a wide range of state-of-the-art prompting methods in an intuitive way, especially facilitating interactive flows that are challenging to implement with existing high-level APIs. Our evaluation shows that we retain or increase the accuracy on several downstream tasks, while also significantly reducing the required amount of computation or cost in the case of pay-to-use APIs (26-85% cost savings).",
        "link": "http://dx.doi.org/10.1145/3591300"
    },
    {
        "id": 11500,
        "title": "!Translate : When You Cannot Cook Up a Translation, Explain",
        "authors": "Federico Garcea,  , Margherita Martinelli, Maja Miličević Petrović, Alberto Barrón-Cedeño,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_044"
    },
    {
        "id": 11501,
        "title": "LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models",
        "authors": "Zhiqiang Hu, Lei Wang, Yihuai Lan, Wanyu Xu, Ee-Peng Lim, Lidong Bing, Xing Xu, Soujanya Poria, Roy Lee",
        "published": "2023",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.319"
    },
    {
        "id": 11502,
        "title": "!Translate : When You Cannot Cook Up a Translation, Explain",
        "authors": "Federico Garcea,  , Margherita Martinelli, Maja Miličević Petrović, Alberto Barrón-Cedeño,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_044"
    },
    {
        "id": 11503,
        "title": "The unreasonable effectiveness of large language models in zero-shot semantic annotation of legal texts",
        "authors": "Jaromir Savelka, Kevin D. Ashley",
        "published": "2023-11-17",
        "citations": 2,
        "abstract": "The emergence of ChatGPT has sensitized the general public, including the legal profession, to large language models' (LLMs) potential uses (e.g., document drafting, question answering, and summarization). Although recent studies have shown how well the technology performs in diverse semantic annotation tasks focused on legal texts, an influx of newer, more capable (GPT-4) or cost-effective (GPT-3.5-turbo) models requires another analysis. This paper addresses recent developments in the ability of LLMs to semantically annotate legal texts in zero-shot learning settings. Given the transition to mature generative AI systems, we examine the performance of GPT-4 and GPT-3.5-turbo(-16k), comparing it to the previous generation of GPT models, on three legal text annotation tasks involving diverse documents such as adjudicatory opinions, contractual clauses, or statutory provisions. We also compare the models' performance and cost to better understand the trade-offs. We found that the GPT-4 model clearly outperforms the GPT-3.5 models on two of the three tasks. The cost-effective GPT-3.5-turbo matches the performance of the 20× more expensive text-davinci-003 model. While one can annotate multiple data points within a single prompt, the performance degrades as the size of the batch increases. This work provides valuable information relevant for many practical applications (e.g., in contract review) and research projects (e.g., in empirical legal studies). Legal scholars and practicing lawyers alike can leverage these findings to guide their decisions in integrating LLMs in a wide range of workflows involving semantic annotation of legal texts.",
        "link": "http://dx.doi.org/10.3389/frai.2023.1279794"
    },
    {
        "id": 11504,
        "title": "Examining Inter-Consistency of Large Language Models Collaboration: An In-depth Analysis via Debate",
        "authors": "Kai Xiong, Xiao Ding, Yixin Cao, Ting Liu, Bing Qin",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.508"
    },
    {
        "id": 11505,
        "title": "Large language models in medical ethics: useful but not expert",
        "authors": "Andrea Ferrario, Nikola Biller-Andorno",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "Large language models (LLMs) have now entered the realm of medical ethics. In a recent study, Balaset alexamined the performance of GPT-4, a commercially available LLM, assessing its performance in generating responses to diverse medical ethics cases. Their findings reveal that GPT-4 demonstrates an ability to identify and articulate complex medical ethical issues, although its proficiency in encoding the depth of real-world ethical dilemmas remains an avenue for improvement. Investigating the integration of LLMs into medical ethics decision-making appears to be an interesting avenue of research. However, despite the promising trajectory of LLM technology in medicine, it is crucial to exercise caution and refrain from attributing their expertise to medical ethics. Our thesis follows an examination of the nature of expertise and the epistemic limitations that affect LLM technology. As a result, we propose two more fitting applications of LLMs in medical ethics: first, as tools for mining electronic health records or scientific literature, thereby supplementing evidence for resolving medical ethics cases, and second, as educational platforms to foster ethical reflection and critical thinking skills among students and residents. The integration of LLMs in medical ethics, while promising, requires careful consideration of their epistemic limitations. Consequently, a well-considered definition of their role in ethically sensitive decision-making is crucial.",
        "link": "http://dx.doi.org/10.1136/jme-2023-109770"
    },
    {
        "id": 11506,
        "title": "Biomedical Text Readability and Cognitive Burden after Hypernym Substitution with Fine-Tuned Large Language Models",
        "authors": "Karl Swanson, Shuhan He, Josh Calvano, David Chen, Talar Telvizian, Jacob Schwell, Lawrence Jiang, Paul Chong",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nWe aimed to study the simplification of biomedical text via large language models (LLMs). Specifically, we finetuned three language models to perform substitutions of complex words and word phrases for their respective hypernym in biomedical definitions. This process was then evaluated by readability metrics, and two measures of sentence complexity: the measure of lexical diversity (MLTD), and mean dependency distance (MDD) scoring. A sample of 1,000 biomedical definitions in the National Library of Medicine’s Unified Medical Language System (UMLS) was processed with three approaches, each with a different language models and analysis revealed an increase in FK score and a reduction in reading grade level across all metrics. Reading scores improved from a pre-processed collegiate reading level to a post-processed US high-school level. An inter-approach comparison showed that our GPT-J-6b approach had the best improvement in MLTD and MDD. This study demonstrates the merit of hypernym substitution in improving the readability and improving measures cognitive burden of biomedical content for the general public.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2410184/v1"
    },
    {
        "id": 11507,
        "title": "A Conceptual Framework for Subdomain Specific Pre-Training of Large Language Models for Green Claim Detection",
        "authors": "Wayne Moodaley, Arnesh Telukdarie",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "Detection of false or misleading green claims (referred to as “greenwashing”) within company sustainability disclosures is challenging for a number of reasons, which include the textual and qualitative nature, volume, and complexity of such disclosures. In recent years, notable progress made in the fields of artificial intelligence and specifically, large language models (LLMs), has showcased the capacity of these tools to effectively analyse extensive and intricate textual data, including the contents of sustainability disclosures. Transformer-based LLMs, such as Google’s BERT architecture, were trained on general domain text corpora. Subsequent research has shown that further pre-training of such LLMs on specific domains, such as the climate or sustainability domains, may improve performance. However, previous research often uses text corpora that exhibit significant variation across topics and language and which often consist of heterogeneous subdomains. We therefore propose a conceptual framework for further pre-training of transformer based LLMs using text corpora relating to specific sustainability subdomains i.e. subdomain specific pre-training. We do so as a basis for the improved performance of such models in analysing sustainability disclosures. The main contribution is a conceptual framework to advance the use of LLMs for the reliable identification of green claims and ultimately, greenwashing.\r\nKeywords: greenwashing, artificial intelligence, sustainability, sustainability reporting, sustainability disclosures.",
        "link": "http://dx.doi.org/10.14207/ejsd.2023.v12n4p319"
    },
    {
        "id": 11508,
        "title": "The Coming Transformative Impact of Large Language Models and Artificial Intelligence on Global Business and Education",
        "authors": "Eva Jermakowicz,  ",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "Rapid advances in the capabilities of Large Language Models (LLM) as a basis for Artificial Intelligence (AI) applications, and their sudden wide accessibility, have garnered significant attention recently. These technologies (e.g., ChatGPT, BARD), which have the ability to predict and generate human language, have led to excitement and concerns regarding their use in various industries. This paper explores the history of LLM, examines their applications in business and education, and delves into the critical ethical concerns and challenges of these emerging technologies to ensure that their uses are not only effective, but also responsible and equitable.",
        "link": "http://dx.doi.org/10.24073/jga/4/02/03"
    },
    {
        "id": 11509,
        "title": "Inductive Thematic Analysis of Healthcare Qualitative Interviews Using Open-Source Large Language Models: How Does it Compare to Traditional Methods?",
        "authors": "Walter  S. Mathis, Sophia Zhao, Nicholas Pratt, Jeremy Weleff, Stefano De Paoli",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4673015"
    },
    {
        "id": 11510,
        "title": "Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science",
        "authors": "Mengqi Liu, Faten M'Hiri",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626252.3630789"
    },
    {
        "id": 11511,
        "title": "An empirical study of statistical language models: n-gram language models vs. neural network language models",
        "authors": "Freha Mezzoudj, Abdelkader Benyettou",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijica.2018.10016827"
    },
    {
        "id": 11512,
        "title": "An empirical study of statistical language models: n-gram language models vs. neural network language models",
        "authors": "Freha Mezzoudj, Abdelkader Benyettou",
        "published": "2018",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijica.2018.095762"
    },
    {
        "id": 11513,
        "title": "Large Language Models and Biorisk",
        "authors": "William D’Alessandro, Harry R. Lloyd, Nathaniel Sharadin",
        "published": "2023-10-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15265161.2023.2250333"
    },
    {
        "id": 11514,
        "title": "A Place for Large Language Models in Scientific Publishing, Apart from Credited Authorship",
        "authors": "Michael R. King",
        "published": "2023-4",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s12195-023-00765-z"
    },
    {
        "id": 11515,
        "title": "The revolutionary impact of chatGPT: advances in biomedicine and redefining healthcare with large language models",
        "authors": "Manasi Soni, Pranav Anjaria, Prakash Koringa",
        "published": "2023-8-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2217/fmai-2023-0011"
    },
    {
        "id": 11516,
        "title": "Performance analysis of large language models in the domain of legal argument mining",
        "authors": "Abdullah Al Zubaer, Michael Granitzer, Jelena Mitrović",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "Generative pre-trained transformers (GPT) have recently demonstrated excellent performance in various natural language tasks. The development of ChatGPT and the recently released GPT-4 model has shown competence in solving complex and higher-order reasoning tasks without further training or fine-tuning. However, the applicability and strength of these models in classifying legal texts in the context of argument mining are yet to be realized and have not been tested thoroughly. In this study, we investigate the effectiveness of GPT-like models, specifically GPT-3.5 and GPT-4, for argument mining via prompting. We closely study the model's performance considering diverse prompt formulation and example selection in the prompt via semantic search using state-of-the-art embedding models from OpenAI and sentence transformers. We primarily concentrate on the argument component classification task on the legal corpus from the European Court of Human Rights. To address these models' inherent non-deterministic nature and make our result statistically sound, we conducted 5-fold cross-validation on the test set. Our experiments demonstrate, quite surprisingly, that relatively small domain-specific models outperform GPT 3.5 and GPT-4 in the F1-score for premise and conclusion classes, with 1.9% and 12% improvements, respectively. We hypothesize that the performance drop indirectly reflects the complexity of the structure in the dataset, which we verify through prompt and data analysis. Nevertheless, our results demonstrate a noteworthy variation in the performance of GPT models based on prompt formulation. We observe comparable performance between the two embedding models, with a slight improvement in the local model's ability for prompt selection. This suggests that local models are as semantically rich as the embeddings from the OpenAI model. Our results indicate that the structure of prompts significantly impacts the performance of GPT models and should be considered when designing them.",
        "link": "http://dx.doi.org/10.3389/frai.2023.1278796"
    },
    {
        "id": 11517,
        "title": "Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models",
        "authors": "Boyu Zhang, Hongyang Yang, Tianyu Zhou, Muhammad Ali Babar, Xiao-Yang Liu",
        "published": "2023-11-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3604237.3626866"
    },
    {
        "id": 11518,
        "title": "Identifying and Fixing Vulnerable Patterns in Ethereum Smart Contracts: A Comparative Study of Fine-Tuning and Prompt Engineering Using Large Language Models",
        "authors": "MARCO ORTU, Giacomo Ibba, Claudio Conversano, Roberto Tonelli, Giuseppe Destefanis",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4530467"
    },
    {
        "id": 11519,
        "title": "Enhancing Health Care Communication With Large Language Models—The Role, Challenges, and Future Directions",
        "authors": "Charumathi Raghu Subramanian, Daniel A. Yang, Raman Khanna",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1001/jamanetworkopen.2024.0347"
    },
    {
        "id": 11520,
        "title": "Data science opportunities of large language models for neuroscience and biomedicine",
        "authors": "Danilo Bzdok, Andrew Thieme, Oleksiy Levkovskyy, Paul Wren, Thomas Ray, Siva Reddy",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neuron.2024.01.016"
    },
    {
        "id": 11521,
        "title": "An Entity Extraction pipeline for Medical Text Records Utilizing Large Language Models: An Analytical Study (Preprint)",
        "authors": "Lei Wang, Yinyao Ma, Wenshuai Bi, Hanlin Lv, Yuxiang Li",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2196/54580"
    },
    {
        "id": 11522,
        "title": "Assessing the Impact of Pretraining Domain Relevance on Large Language Models Across Various Pathology Reporting Tasks",
        "authors": "Yunrui Lu, Gokul Srinivasan, Sarah Preum, Jason Pettus, Matthew Davis, Jack Greenburg, Louis Vaickus, Joshua Levy",
        "published": "No Date",
        "citations": 0,
        "abstract": "ABSTRACTDeep learning (DL) algorithms continue to develop at a rapid pace, providing researchers access to a set of tools capable of solving a wide array of biomedical challenges. While this progress is promising, it also leads to confusion regarding task-specific model choices, where deeper investigation is necessary to determine the optimal model configuration. Natural language processing (NLP) has the unique ability to accurately and efficiently capture a patient’s narrative, which can improve the operational efficiency of modern pathology laboratories through advanced computational solutions that can facilitate rapid access to and reporting of histological and molecular findings. In this study, we use pathology reports from a large academic medical system to assess the generalizability and potential real-world applicability of various deep learning-based NLP models on reports with highly specialized vocabulary and complex reporting structures. The performance of each NLP model examined was compared across four distinct tasks: 1) current procedural terminology (CPT) code classification, 2) pathologist classification, 3) report sign-out time regression, and 4) report text generation, under the hypothesis that models initialized on domain-relevant medical text would perform better than models not attuned to this prior knowledge. Our study highlights that the performance of deep learning-based NLP models can vary meaningfully across pathology-related tasks. Models pretrained on medical data outperform other models where medical domain knowledge is crucial, e.g., current procedural terminology (CPT) code classification. However, where interpretation is more subjective (i.e., teasing apart pathologist-specific lexicon and variable sign-out times), models with medical pretraining do not consistently outperform the other approaches. Instead, fine-tuning models pretrained on general or unrelated text sources achieved comparable or better results. Overall, our findings underscore the importance of considering the nature of the task at hand when selecting a pretraining strategy for NLP models in pathology. The optimal approach may vary depending on the specific requirements and nuances of the task, and related text sources can offer valuable insights and improve performance in certain cases, contradicting established notions about domain adaptation. This research contributes to our understanding of pretraining strategies for large language models and further informs the development and deployment of these models in pathology-related applications.",
        "link": "http://dx.doi.org/10.1101/2023.09.10.23295318"
    },
    {
        "id": 11523,
        "title": "Rewriting Conversational Utterances with Instructed Large Language Models",
        "authors": "Elnara Galimzhanova, Cristina Ioana Muntean, Franco Maria Nardini, Raffaele Perego, Guido Rocchietti",
        "published": "2023-10-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wi-iat59888.2023.00014"
    },
    {
        "id": 11524,
        "title": "LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models",
        "authors": "Yen-Ting Lin, Yun-Nung Chen",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.nlp4convai-1.5"
    },
    {
        "id": 11525,
        "title": "Establishing priorities for implementation of large language models in pathology and laboratory medicine",
        "authors": "Simone Arvisais-Anhalt, Steven L. Gonias, Sara G. Murray",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.acpath.2023.100101"
    },
    {
        "id": 11526,
        "title": "ESR Journals editors’ joint statement on Guidelines for the Use of Large Language Models by Authors, Reviewers, and Editors",
        "authors": "Bernd Hamm, Luis Marti-Bonmati, Francesco Sardanelli",
        "published": "2024-1-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00330-023-10511-8"
    },
    {
        "id": 11527,
        "title": "A Case Study of Large Language Models' Effectiveness in Diverse Business Applications: Developing a Universal Integration Framework",
        "authors": "Leonardo Lawrence, Jeffrey Butler",
        "published": "2024-3",
        "citations": 0,
        "abstract": "In an era where data-driven decision-making is paramount, Large Language Models (LLMs) have emerged as a powerful tool for businesses across various sectors. However, the integration of these models into diverse business contexts presents unique challenges, ranging from technical implementation to strategic alignment with business goals. This research aims to build a comprehensive framework for the effective integration of LLMs into different business environments. By thoroughly exploring and documenting a variety of practical use cases of LLMs, the study develops a set of best practice guidelines tailored for businesses. These guidelines are designed to assist companies, irrespective of their industry, in leveraging the advanced capabilities of LLMs for enhanced data analysis, strategic decision-making, and operational efficiency. The research combines theoretical insights with practical applications, aiming to bridge the gap between the expanding field of LLMs and the evolving needs of the business world. The expected outcome of this research is a versatile, scalable, and accessible framework that empowers businesses to harness the full potential of LLMs, driving innovation and competitive advantage in the data-centric corporate landscape.",
        "link": "http://dx.doi.org/10.61643/c38193"
    },
    {
        "id": 11528,
        "title": "Re: Large language models (LLMs) in evaluation of emergency radiology reports: performance of ChatGPT-4, Perplexity and Bard",
        "authors": "S. Wiwanitkit, V. Wiwanitkit",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.crad.2023.12.021"
    },
    {
        "id": 11529,
        "title": "Large Language Models guided Generative Prompt for Dialogue Generation",
        "authors": "Sijie Liu, Yiquan Fang, Hua Cheng, Yiming Pan, Yufei Liu, Caiting Gao",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cyberc58899.2023.00013"
    },
    {
        "id": 11530,
        "title": "ThinkSum: Probabilistic reasoning over sets using large language models",
        "authors": "Batu Ozturkler, Nikolay Malkin, Zhen Wang, Nebojsa Jojic",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.68"
    },
    {
        "id": 11531,
        "title": "Foundation Models of Scientific Knowledge for Chemistry: Opportunities, Challenges and Lessons Learned",
        "authors": "Sameera Horawalavithana, Ellyn Ayton, Shivam Sharma, Scott Howland, Megha Subramanian, Scott Vasquez, Robin Cosbey, Maria Glenski, Svitlana Volkova",
        "published": "2022",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bigscience-1.12"
    },
    {
        "id": 11532,
        "title": "Sentiment and Interest Detection in Social Media using GPT-based Large Language Models",
        "authors": "Md Abdullah Al Asad, Hasan Md Imran, Md Alamin, Tareque Abu Abdullah, Suriya Islam Chowdhury",
        "published": "2023-12-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3639479.3639523"
    },
    {
        "id": 11533,
        "title": "Dataset Debt in Biomedical Language Modeling",
        "authors": "Jason Fries, Natasha Seelam, Gabriel Altay, Leon Weber, Myungsun Kang, Debajyoti Datta, Ruisi Su, Samuele Garda, Bo Wang, Simon Ott, Matthias Samwald, Wojciech Kusa",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bigscience-1.10"
    },
    {
        "id": 11534,
        "title": "Leveraging Large Language Models to Enhance Digital Health in Cardiology: A Preview of a Cutting-Edge Language Generation Model",
        "authors": "Eyal Klang, Michal Cohen-Shelly, Francisco Lopez-Jimenez",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.mcpdig.2023.03.003"
    },
    {
        "id": 11535,
        "title": "Probing Toxic Content in Large Pre-Trained Language Models",
        "authors": "Nedjma Ousidhoum, Xinran Zhao, Tianqing Fang, Yangqiu Song, Dit-Yan Yeung",
        "published": "2021",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.acl-long.329"
    },
    {
        "id": 11536,
        "title": "Coherent Story Generation with Structured Knowledge",
        "authors": "Congda Ma,  , Kotaro Funakoshi, Kiyoaki Shirai, Manabu Okumura,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_074"
    },
    {
        "id": 11537,
        "title": "Enriched Pre-trained Transformers for Joint Slot Filling and Intent Detection",
        "authors": "Momchil Hardalov,  , Ivan Koychev, Preslav Nakov,  ,  ",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_054"
    },
    {
        "id": 11538,
        "title": "BB25HLegalSum: Leveraging BM25 and BERT-based clustering for the summarization of legal documents",
        "authors": "Leonardo Bonalume,  , Karin Becker,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_029"
    },
    {
        "id": 11539,
        "title": "Comparative Analysis of Named Entity Recognition in the Dungeons and Dragons Domain",
        "authors": "Gayashan Weerasundara,  , Nisansa de Silva,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_130"
    },
    {
        "id": 11540,
        "title": "An Investigation of Applying Large Language Models to Spoken Language Learning",
        "authors": "Yingming Gao, Baorian Nuchged, Ya Li, Linkai Peng",
        "published": "2023-12-26",
        "citations": 1,
        "abstract": "People have long desired intelligent conversational systems that can provide assistance in practical scenarios. The latest advancements in large language models (LLMs) are making significant strides toward turning this aspiration into a tangible reality. LLMs are believed to hold the most potential and value in education, especially in the creation of AI-driven virtual teachers that facilitate language learning. This study focuses on assessing the effectiveness of LLMs within the educational domain, specifically in the areas of spoken language learning, which encompass phonetics, phonology, and second language acquisition. To this end, we first introduced a new multiple-choice question dataset to evaluate the effectiveness of LLMs in the aforementioned scenarios, including the understanding and application of spoken language knowledge. Moreover, we investigated the influence of various prompting techniques such as zero- and few-shot methods (prepending the question with question-answer exemplars), chain-of-thought (CoT) prompting, in-domain exemplars, and external tools. We conducted a comprehensive evaluation of popular LLMs (20 distinct models) using these methods. The experimental results showed that the task of extracting conceptual knowledge posed few challenges for these LLMs, whereas the task of application questions was relatively difficult. In addition, some widely proven effective prompting methods combined with domain-specific examples resulted in significant performance improvements compared to the zero-shot baselines. Additionally, some other preliminary experiments also demonstrated the strengths and weaknesses of different LLMs. The findings of this study can shed light on the application of LLMs to spoken language learning.",
        "link": "http://dx.doi.org/10.3390/app14010224"
    },
    {
        "id": 11541,
        "title": "Are you not moved? Incorporating Sensorimotor Knowledge to Improve Metaphor Detection",
        "authors": "Ghadi Alnafesah,  , Phillip Smith, Mark Lee,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_009"
    },
    {
        "id": 11542,
        "title": "Topic Modeling Using Community Detection on a Word Association Graph",
        "authors": "Mahfuzur Rahman Chowdhury,  , Intesur Ahmed, Farig Sadeque, Muhammad Nur Yanhaona,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_098"
    },
    {
        "id": 11543,
        "title": "BanglaBait: Semi-Supervised Adversarial Approach for Clickbait Detection on Bangla Clickbait Dataset",
        "authors": "Md. Motahar Mahtab,  , Monirul Haque, Mehedi Hasan, Farig Sadeque,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_081"
    },
    {
        "id": 11544,
        "title": "Large Language Models: The Next Frontier for Variable Discovery within Metamorphic Testing?",
        "authors": "Christos Tsigkanos, Pooja Rani, Sebastian Müller, Timo Kehrer",
        "published": "2023-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/saner56733.2023.00070"
    },
    {
        "id": 11545,
        "title": "ChatGPT Goes to Operating Room: Evaluating GPT-4 Performance and Its Potential in Surgical Education and Training in the Era of Large Language Models",
        "authors": "Namkee Oh, Gyu-Seong Choi, Woo Yong Lee",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractPurposeThis study aimed to assess the performance of ChatGPT, specifically the GPT-3.5 and GPT-4 models, in understanding complex surgical clinical information and its potential implications for surgical education and training.MethodsThe dataset comprised 280 questions from the Korean general surgery board exams conducted between 2020 and 2022. Both GPT-3.5 and GPT-4 models were evaluated, and their performances were compared using McNemar’s test.ResultsGPT-3.5 achieved an overall accuracy of 46.8%, while GPT-4 demonstrated a significant improvement with an overall accuracy of 76.4%, indicating a notable difference in performance between the models (P < 0.001). GPT-4 also exhibited consistent performance across all subspecialties, with accuracy rates ranging from 63.6% to 83.3%.ConclusionChatGPT, particularly GPT-4, demonstrates a remarkable ability to understand complex surgical clinical information, achieving an accuracy rate of 76.4% on the Korean general surgery board exam. However, it is important to recognize the limitations of LLMs and ensure that they are used in conjunction with human expertise and judgment.",
        "link": "http://dx.doi.org/10.1101/2023.03.16.23287340"
    },
    {
        "id": 11546,
        "title": "Bias of AI-Generated Content: An Examination of News Produced by Large Language Models",
        "authors": "Xiao Fang, Shangkun Che, Minjia Mao, Hongzhe Zhang, Ming Zhao, Xiaohang Zhao",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4574226"
    },
    {
        "id": 11547,
        "title": "Triple-Entry Accounting as a Means of Auditing Large Language Models",
        "authors": "Konstantinos Sgantzos, Mohamed Al Hemairy, Panagiotis Tzavaras, Spyridon Stelios",
        "published": "2023-8-27",
        "citations": 0,
        "abstract": "The usage of Large Language Models (LMMs) and their exponential progress has created a Cambrian Explosion in the development of new tools for almost every field of science and technology, but also presented significant concerns regarding the AI ethics and creation of sophisticated malware and phishing attacks. Moreover, several worries have arisen in the field of dataset collection and intellectual property in that many datasets may exist without the license of the respective owners. Triple-Entry Accounting (TEA) has been proposed by Ian Grigg to increase transparency, accountability, and security in financial transactions. This method expands upon the traditional double-entry accounting system, which records transactions as debits and credits in two separate ledgers, by incorporating a third ledger as an independent verifier via a digitally signed receipt. The utilization of a digital signature provides evidentiary power to the receipt, thus reducing the accounting problem to one of the presence or absence of the receipt. The integrity issues associated with double-entry accounting can be addressed by allowing the parties involved in the transaction to share the records with an external auditor. This manuscript proposes a novel methodology to apply triple-entry accounting records on a publicly accessed distributed ledger technology medium to control the queries of LLMs in order to discourage malicious acts and ensure intellectual property rights.",
        "link": "http://dx.doi.org/10.3390/jrfm16090383"
    },
    {
        "id": 11548,
        "title": "Active Inference Goes to School. The Importance of Active Learning in the Age of Large Language Models",
        "authors": "laura Desirée Di Paolo, Ben White, Avel GUÉNIN--CARLUT, Axel Constant, Andy Clark",
        "published": "No Date",
        "citations": 0,
        "abstract": "Human learning essentially involves embodied interactions with the material world. But our worlds now include increasing numbers of powerful and (apparently) disembodied generative AIs. In what follows we ask how best to understand these new (somewhat “alien”, because of their disembodied nature) resources and how to incorporate them in our educational practices. We focus on methodologies that encourage exploration and embodied interactions with ‘prepared’ material environments, such as the carefully organised settings of Montessori education. Using the Active Inference Framework, we approach our questions by thinking about human learning as epistemic foraging and prediction error minimization. We end by arguing that generative AIs should figure naturally as new elements in prepared learning environments by facilitating sequences of precise prediction error enabling trajectories of self-correction. In these ways we anticipate new synergies between (apparently) disembodied and (essentially) embodied forms of intelligence.",
        "link": "http://dx.doi.org/10.31219/osf.io/zwa83"
    },
    {
        "id": 11549,
        "title": "Leveraging Large Language Models for Sequential Recommendation",
        "authors": "Jesse Harte, Wouter Zorgdrager, Panos Louridas, Asterios Katsifodimos, Dietmar Jannach, Marios Fragkoulis",
        "published": "2023-9-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3604915.3610639"
    },
    {
        "id": 11550,
        "title": "How understanding large language models can inform the use of ChatGPT in physics education",
        "authors": "Giulia Polverini, Bor Gregorcic",
        "published": "2024-3-1",
        "citations": 1,
        "abstract": "Abstract\nThe paper aims to fulfil three main functions: (1) to serve as an introduction for the physics education community to the functioning of large language models (LLMs), (2) to present a series of illustrative examples demonstrating how prompt-engineering techniques can impact LLMs performance on conceptual physics tasks and (3) to discuss potential implications of the understanding of LLMs and prompt engineering for physics teaching and learning. We first summarise existing research on the performance of a popular LLM-based chatbot (ChatGPT) on physics tasks. We then give a basic account of how LLMs work, illustrate essential features of their functioning, and discuss their strengths and limitations. Equipped with this knowledge, we discuss some challenges with generating useful output with ChatGPT-4 in the context of introductory physics, paying special attention to conceptual questions and problems. We then provide a condensed overview of relevant literature on prompt engineering and demonstrate through illustrative examples how selected prompt-engineering techniques can be employed to improve ChatGPT-4’s output on conceptual introductory physics problems. Qualitatively studying these examples provides additional insights into ChatGPT’s functioning and its utility in physics problem-solving. Finally, we consider how insights from the paper can inform the use of LLMs in the teaching and learning of physics.",
        "link": "http://dx.doi.org/10.1088/1361-6404/ad1420"
    },
    {
        "id": 11551,
        "title": "Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints",
        "authors": "Albert Lu, Hongxin Zhang, Yanzhe Zhang, Xuezhi Wang, Diyi Yang",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-eacl.148"
    },
    {
        "id": 11552,
        "title": "Toward Keyword Generation through Large Language Models",
        "authors": "Wanhae Lee, Minki Chun, Hyeonhak Jeong, Hyunggu Jung",
        "published": "2023-3-27",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3581754.3584126"
    },
    {
        "id": 11553,
        "title": "Enhancing Information Retrieval in the Drilling Domain: Zero-Shot Learning with Large Language Models for Question-Answering",
        "authors": "F. J. Pacis, S. Alyaev, G. Pelfrene, T. Wiktorski",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "Abstract\nFinding information across multiple databases, formats, and documents remains a manual job in the drilling industry. Large Language Models (LLMs) have proven effective in data-aggregation tasks, including answering questions. However, using LLMs for domain-specific factual responses poses a nontrivial challenge. The expert labor cost for training domain-specific LLMs prohibits niche industries from developing custom question-answering bots. This paper tests several commercial LLMs for information retrieval tasks for drilling data using zero-shot in-context learning. In addition, we studied the model’s calibration using a few-shot multiple-choice drilling questionnaire.\nTo create an LLM benchmark for drilling, we collated the text data from publicly available databases: the Norwegian Petroleum Directorate (NPD), company annual reports, and petroleum glossary. We used a zero-shot learning technique that relies on an LLM’s ability to generate responses for tasks outside its training. We implemented a controlled zero-shot learning \"in-context\" procedure that sends a user’s query augmented with text data to the LLM as inputs. This implementation encourages the LLM to take the answer from the data while leveraging its pre-trained contextual-learning capability.\nWe evaluated several state-of-the-art generic LLMs available through an API, including G4, G3.5-TI, J2-ultra model, and L2 series. The paper documents the pre-trained LLMs’ ability to provide correct answers and identify petroleum industry jargon from the collated dataset. Our zero-shot in-context learning implementation helps vanilla LLMs provide relevant factual responses for the drilling domain. While each LLM’s performance varies, we have identified models suitable for a drilling chatbot application. In particular, G4 outperformed on all the tasks. This finding suggests that training expensive domain-specific LLMs is not necessary for question-answering tasks in the context of drilling data.\nWe demonstrate the utility of zero-shot in-context learning using pre-trained LLMs for question-answering tasks relevant to the drilling industry. Additionally, we prepared and publicly released the collated datasets from the NPD database and companies’ annual reports to enable results reproducibility and to foster acceleration of language model adoption and development for the subsurface and drilling industries. The petroleum industry may find our solution beneficial for enhancing personnel training and career development. It also offers a method for conducting data analytics and overcoming challenges in retrieving historical well data.",
        "link": "http://dx.doi.org/10.2118/217671-ms"
    },
    {
        "id": 11554,
        "title": "The Role of Large Language Models in Medical Education: Applications and Implications",
        "authors": "Conrad W Safranek, Anne Elizabeth Sidamon-Eristoff, Aidan Gilson, David Chartash",
        "published": "2023-8-14",
        "citations": 21,
        "abstract": "Large language models (LLMs) such as ChatGPT have sparked extensive discourse within the medical education community, spurring both excitement and apprehension. Written from the perspective of medical students, this editorial offers insights gleaned through immersive interactions with ChatGPT, contextualized by ongoing research into the imminent role of LLMs in health care. Three distinct positive use cases for ChatGPT were identified: facilitating differential diagnosis brainstorming, providing interactive practice cases, and aiding in multiple-choice question review. These use cases can effectively help students learn foundational medical knowledge during the preclinical curriculum while reinforcing the learning of core Entrustable Professional Activities. Simultaneously, we highlight key limitations of LLMs in medical education, including their insufficient ability to teach the integration of contextual and external information, comprehend sensory and nonverbal cues, cultivate rapport and interpersonal interaction, and align with overarching medical education and patient care goals. Through interacting with LLMs to augment learning during medical school, students can gain an understanding of their strengths and weaknesses. This understanding will be pivotal as we navigate a health care landscape increasingly intertwined with LLMs and artificial intelligence.",
        "link": "http://dx.doi.org/10.2196/50945"
    },
    {
        "id": 11555,
        "title": "The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations",
        "authors": "Vipula Rawte, Swagata Chakraborty, Agnibh Pathak, Anubhav Sarkar, S.M Towhidul Islam Tonmoy, Aman Chadha, Amit Sheth, Amitava Das",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.155"
    },
    {
        "id": 11556,
        "title": "Automatic Scoring of Creative Problem-Solving with Large Language Models: A Comparison of Originality and Quality Ratings",
        "authors": "Simone Luchini, Nadine T. Maliakkal, Paul V DiStefano, John D. Patterson, Roger Beaty, Roni Reiter-Palmon",
        "published": "No Date",
        "citations": 1,
        "abstract": "Creative problem-solving is a naturalistic form of creative thinking involving the generation of solutions that are not only original but also of high quality (i.e., plausible and effective). Naturalistic tasks that evaluate both originality and quality are vital for the promotion of creativity in real-world settings—yet scoring such tasks remains challenging, due to costly human labor required to manually rate task responses. Past work has shown that large language models (LLMs) can be trained to predict human originality ratings of responses to tests of divergent thinking. In the present research, we extend this work to creative problem-solving, examining whether both originality and quality can be automatically scored for a naturalistic creativity task. We gathered data from 10 studies, amounting to 3,235 participants who completed a creative problem-solving task (CPST). We then fine-tuned two open-source LLMs, RoBERTa and GPT-2, to predict human ratings of originality and quality on the CPST, and compared their performance to two other scoring methods: elaboration (i.e., word count) and semantic distance. We found that RoBERTa and GPT-2 models predict solution quality (RoBERTa, r = .83; GPT-2, r = .83) better than solution originality (RoBERTa, r = .79; GPT-2, r = .80). Moreover, we found that both models outperformed elaboration and semantic distance methods and generalized to new CPST items not present in their training set. We therefore show for the first time that naturalistic creativity tasks can be automatically scored for both originality and quality. Open access is provided to the models and training data.",
        "link": "http://dx.doi.org/10.31234/osf.io/g5qvf"
    },
    {
        "id": 11557,
        "title": "MuDPT: Multi-modal Deep-symphysis Prompt Tuning for Large Pre-trained Vision-Language Models",
        "authors": "Yongzhu Miao, Shasha Li, Jintao Tang, Ting Wang",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icme55011.2023.00013"
    },
    {
        "id": 11558,
        "title": "Text Detoxification using Large Pre-trained Neural Models",
        "authors": "David Dale, Anton Voronov, Daryna Dementieva, Varvara Logacheva, Olga Kozlova, Nikita Semenov, Alexander Panchenko",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.629"
    },
    {
        "id": 11559,
        "title": "Learning to Make Rare and Complex Diagnoses With Generative AI Assistance: Qualitative Study of Popular Large Language Models",
        "authors": "Tassallah Abdullahi, Ritambhara Singh, Carsten Eickhoff",
        "published": "2024-2-13",
        "citations": 0,
        "abstract": "\nBackground\nPatients with rare and complex diseases often experience delayed diagnoses and misdiagnoses because comprehensive knowledge about these diseases is limited to only a few medical experts. In this context, large language models (LLMs) have emerged as powerful knowledge aggregation tools with applications in clinical decision support and education domains.\n\n\nObjective\nThis study aims to explore the potential of 3 popular LLMs, namely Bard (Google LLC), ChatGPT-3.5 (OpenAI), and GPT-4 (OpenAI), in medical education to enhance the diagnosis of rare and complex diseases while investigating the impact of prompt engineering on their performance.\n\n\nMethods\nWe conducted experiments on publicly available complex and rare cases to achieve these objectives. We implemented various prompt strategies to evaluate the performance of these models using both open-ended and multiple-choice prompts. In addition, we used a majority voting strategy to leverage diverse reasoning paths within language models, aiming to enhance their reliability. Furthermore, we compared their performance with the performance of human respondents and MedAlpaca, a generative LLM specifically designed for medical tasks.\n\n\nResults\nNotably, all LLMs outperformed the average human consensus and MedAlpaca, with a minimum margin of 5% and 13%, respectively, across all 30 cases from the diagnostic case challenge collection. On the frequently misdiagnosed cases category, Bard tied with MedAlpaca but surpassed the human average consensus by 14%, whereas GPT-4 and ChatGPT-3.5 outperformed MedAlpaca and the human respondents on the moderately often misdiagnosed cases category with minimum accuracy scores of 28% and 11%, respectively. The majority voting strategy, particularly with GPT-4, demonstrated the highest overall score across all cases from the diagnostic complex case collection, surpassing that of other LLMs. On the Medical Information Mart for Intensive Care-III data sets, Bard and GPT-4 achieved the highest diagnostic accuracy scores, with multiple-choice prompts scoring 93%, whereas ChatGPT-3.5 and MedAlpaca scored 73% and 47%, respectively. Furthermore, our results demonstrate that there is no one-size-fits-all prompting approach for improving the performance of LLMs and that a single strategy does not universally apply to all LLMs.\n\n\nConclusions\nOur findings shed light on the diagnostic capabilities of LLMs and the challenges associated with identifying an optimal prompting strategy that aligns with each language model’s characteristics and specific task requirements. The significance of prompt engineering is highlighted, providing valuable insights for researchers and practitioners who use these language models for medical training. Furthermore, this study represents a crucial step toward understanding how LLMs can enhance diagnostic reasoning in rare and complex medical cases, paving the way for developing effective educational tools and accurate diagnostic aids to improve patient care and outcomes.\n",
        "link": "http://dx.doi.org/10.2196/51391"
    },
    {
        "id": 11560,
        "title": "Exploring the Potential of Large Language Models in Personalized Diabetes Treatment Strategies (Preprint)",
        "authors": "hao yang, Jiaxi Li, Siru Liu, Lei Liu, Xiali Liu, Yong Huang, qingke shi, jialin liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\nThis study aims to explore the application of a fine-tuned model-based outpatient treatment support system for the treatment of patients with diabetes, and evaluate its effectiveness and potential value.\nMethods: The ChatGLM model was selected as the subject of investigation and trained using the P-tuning and LoRA fine-tuning methods. Subsequently, the fine-tuned model was successfully integrated into the Hospital Information System (HIS). The system generates personalized treatment recommendations, laboratory test suggestions, and medication prompts based on patients' basic information, chief complaints, medical history, and diagnosis data.\nResults: Experimental testing revealed that the fine-tuned ChatGLM model is capable of generating accurate treatment recommendations based on patient information, while providing appropriate laboratory test suggestions and medication prompts. However, for patients with complex medical records, the model's outputs may carry certain risks and cannot fully substitute outpatient physicians' clinical judgment and decision-making abilities. The model's input data is confined to electronic health record (EHR), limiting the ability to comprehensively reconstruct the patient's treatment process and occasionally leading to misjudgments of the patient's treatment goals.\nConclusion: This study demonstrates the potential of the fine-tuned ChatGLM model in assisting the treatment of patients with diabetes, providing reference recommendations to healthcare professionals to enhance work efficiency and quality. However, further improvements and optimizations are still required, particularly regarding medication therapy and the model's adaptability.\n",
        "link": "http://dx.doi.org/10.2196/preprints.50911"
    },
    {
        "id": 11561,
        "title": "Large language models (ChatGPT) in medical education: Embrace or abjure?",
        "authors": "Nathasha Luke, Reshma Taneja, Kenneth Ban, Dujeepa Samarasekera, Celestial T Yap",
        "published": "2023-10-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.29060/taps.2023-8-4/pv3007"
    },
    {
        "id": 11562,
        "title": "Walking a Tightrope – Evaluating Large Language Models in High-Risk Domains",
        "authors": "Chia-Chien Hung, Wiem Ben Rim, Lindsay Frost, Lars Bruckner, Carolin Lawrence",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.genbench-1.8"
    },
    {
        "id": 11563,
        "title": "Large language models and agricultural extension services",
        "authors": "A. Tzachor, M. Devare, C. Richards, P. Pypers, A. Ghosh, J. Koo, S. Johal, B. King",
        "published": "2023-11-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s43016-023-00867-x"
    },
    {
        "id": 11564,
        "title": "The moral machine experiment on large language models",
        "authors": "Kazuhiro Takemoto",
        "published": "2024-2",
        "citations": 0,
        "abstract": "As large language models (LLMs) have become more deeply integrated into various sectors, understanding how they make moral judgements has become crucial, particularly in the realm of autonomous driving. This study used the moral machine framework to investigate the ethical decision-making tendencies of prominent LLMs, including GPT-3.5, GPT-4, PaLM 2 and Llama 2, to compare their responses with human preferences. While LLMs' and humans' preferences such as prioritizing humans over pets and favouring saving more lives are broadly aligned, PaLM 2 and Llama 2, especially, evidence distinct deviations. Additionally, despite the qualitative similarities between the LLM and human preferences, there are significant quantitative disparities, suggesting that LLMs might lean toward more uncompromising decisions, compared with the milder inclinations of humans. These insights elucidate the ethical frameworks of LLMs and their potential implications for autonomous driving.",
        "link": "http://dx.doi.org/10.1098/rsos.231393"
    },
    {
        "id": 11565,
        "title": "Zero, Single, and Few-Shot Learning in Large Language Models to Identify Incidental Findings From Radiology Reports",
        "authors": "Esat Kaba",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2214/ajr.24.31014"
    },
    {
        "id": 11566,
        "title": "Applications of Large Language Models in Well Construction Planning and Real-Time Operation",
        "authors": "Michael Yi, Kamil Ceglinski, Pradeepkumar Ashok, Michael Behounek, Spencer White, Trey Peroyea, Taylor Thetford",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "Abstract\nIn today's well construction operations, a substantial volume of data is generated and stored across multiple databases. The primary objective being to use them as a guide for future well construction optimization. However, much of this data gets lost in computer storage, and appropriate information is difficult to find at the right time. This paper shows the results of deploying a generative pre-trained transformer (GPT) large language model on an operator's dataset to alleviate this problem.\nThe process starts with gathering all relevant data into a common database. In this case, the dataset included sensor data, processed data, morning reports, end of well reports, after-action reviews of non-productive times, bit forensics data and publicly available data from wells drilled by other operators. The files were pre-processed, and metadata was added appropriately to ensure appropriate indexing and training of the information. This data is then fed to the cloud platform on which the model is learnt. The model is then integrated into the data platform so that the end users can pose queries.\nThe dataset consisted of more than 200 wells of the operator in a region that the operator is actively drilling. Data curation was a time-consuming task that had to be performed to ensure only quality and organized information was fed to the model. Documents containing well construction related subject matter were also used in the training to provide the end user assistance with core concepts. During the test stage, a multitude of questions were posed to the platform, including questions such as: What happened the last time there was a stuck pipe in this region? What is the best ROP that could be attained in the lateral section? Significant time savings were recorded due to the ease with which information could be retrieved. A big concern was the potential for wrongs answers being provided to the questions. To alleviate this concern, all answers were accompanied by references found in the database, to give the person reviewing the answers confidence in the answers.\nThis paper introduces the benefits that large language models (LLMs) bring to both well planning and real-time operations. LLM offers the capability to be able to retrieve information extremely quickly and provide answers in a conversational format to user questions. This paper also provides recommendations to the industry and details some of the challenges to adopting LLMs.",
        "link": "http://dx.doi.org/10.2118/217700-ms"
    },
    {
        "id": 11567,
        "title": "Playing Games with Ais: The Limits of GPT-3 and Similar Large Language Models",
        "authors": "Adam Sobieszek, Tadeusz Price",
        "published": "2022-6",
        "citations": 29,
        "abstract": "AbstractThis article contributes to the debate around the abilities of large language models such as GPT-3, dealing with: firstly, evaluating how well GPT does in the Turing Test, secondly the limits of such models, especially their tendency to generate falsehoods, and thirdly the social consequences of the problems these models have with truth-telling. We start by formalising the recently proposed notion of reversible questions, which Floridi & Chiriatti (2020) propose allow one to ‘identify the nature of the source of their answers’, as a probabilistic measure based on Item Response Theory from psychometrics. Following a critical assessment of the methodology which led previous scholars to dismiss GPT’s abilities, we argue against claims that GPT-3 completely lacks semantic ability. Using ideas of compression, priming, distributional semantics and semantic webs we offer our own theory of the limits of large language models like GPT-3, and argue that GPT can competently engage in various semantic tasks. The real reason GPT’s answers seem senseless being that truth-telling is not amongst them. We claim that these kinds of models cannot be forced into producing only true continuation, but rather to maximise their objective function they strategize to be plausible instead of truthful. This, we moreover claim, can hijack our intuitive capacity to evaluate the accuracy of its outputs. Finally, we show how this analysis predicts that a widespread adoption of language generators as tools for writing could result in permanent pollution of our informational ecosystem with massive amounts of very plausible but often untrue texts.",
        "link": "http://dx.doi.org/10.1007/s11023-022-09602-0"
    },
    {
        "id": 11568,
        "title": "Large language models for human–robot interaction: A review",
        "authors": "Ceng Zhang, Junxin Chen, Jiatong Li, Yanhong Peng, Zebing Mao",
        "published": "2023-12",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.birob.2023.100131"
    },
    {
        "id": 11569,
        "title": "Large Language Models in Ophthalmology: Potential and Pitfalls",
        "authors": "Antonio Yaghy, Maria Yaghy, Jerry A. Shields, Carol L. Shields",
        "published": "2024-1-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/08820538.2023.2300808"
    },
    {
        "id": 11570,
        "title": "The Plastic Surgery Hypothesis in the Era of Large Language Models",
        "authors": "Chunqiu Steven Xia, Yifeng Ding, Lingming Zhang",
        "published": "2023-9-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ase56229.2023.00047"
    },
    {
        "id": 11571,
        "title": "Generating Requirements Elicitation Interview Scripts with Large Language Models",
        "authors": "Binnur Görer, Fatma Başak Aydemir",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/rew57809.2023.00015"
    },
    {
        "id": 11572,
        "title": "ZINify: Transforming Research Papers into Engaging Zines with Large Language Models",
        "authors": "Jaidev Shriram, Sanjayan Pradeep Kumar Sreekala",
        "published": "2023-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3586182.3625118"
    },
    {
        "id": 11573,
        "title": "The Singularity is Emerging: Large Language Models and the Impact of Artificial Intelligence on Education",
        "authors": "Sharon Mistretta",
        "published": "2023-9-6",
        "citations": 0,
        "abstract": "Singularity, posited by Kurzweil in his seminal book, The Singularity is Near, marks a time when artificial intelligence (AI) innovation outpaces the human brain’s capabilities. Large Language Models (LLM) such as OpenAi’s ChatGPT, Microsoft’s Bing, Google’s Bard, and Baidu’s Ernie place humanity at a pivotal time where mathematical neural networks surpass, benefit, or deter all facets of human existence. AI bots are prone to emergent behavior that reveals unintended or unexpected abilities, such as learning to translate English into additional world languages. Biases embedded in the training database are prevalent, and an ethical layer of humans in the loop becomes necessary to ensure that LLMs provide responses that benefit mankind. Educators and their students grapple with the intrusion of the capabilities of LLMs that render traditional lesson plans and assessments powerless to authentically measure students’ knowledge of a topic. Dialoguing effectively through prompt engineering becomes a necessary skill to harness the power of LLMs. Weary students and teachers emerging from a disruptive pandemic must grapple with how AI is changing the landscape of education. This chapter will examine the impact of LLMs on students, their teachers, and how the education field can harness AI to augment and sustain learning to prepare our stakeholders for teaching and learning in this new age of artificial intelligence.",
        "link": "http://dx.doi.org/10.5772/intechopen.1002650"
    },
    {
        "id": 11574,
        "title": "CHEMFUZZ: Large Language Models-Assisted Fuzzing for Quantum Chemistry Software Bug Detection",
        "authors": "Feng Qiu, Pu Ji, Baojian Hua, Yang Wang",
        "published": "2023-10-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/qrs-c60940.2023.00104"
    },
    {
        "id": 11575,
        "title": "ChatGPT GameJam: Unleashing the power of Large Language Models for Game Jams",
        "authors": "April M. Grow, Foaad Khosmood",
        "published": "2023-8-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3610602.3610605"
    },
    {
        "id": 11576,
        "title": "Chain-of-event prompting for multi-document summarization by large language models",
        "authors": "Songlin Bao, Tiantian Li, Bin Cao",
        "published": "2024-2-15",
        "citations": 0,
        "abstract": "\nPurpose\nIn the era of big data, various industries are generating large amounts of text data every day. Simplifying and summarizing these data can effectively serve users and improve efficiency. Recently, zero-shot prompting in large language models (LLMs) has demonstrated remarkable performance on various language tasks. However, generating a very “concise” multi-document summary is a difficult task for it. When conciseness is specified in the zero-shot prompting, the generated multi-document summary still contains some unimportant information, even with the few-shot prompting. This paper aims to propose a LLMs prompting for multi-document summarization task.\n\n\nDesign/methodology/approach\nTo overcome this challenge, the authors propose chain-of-event (CoE) prompting for multi-document summarization (MDS) task. In this prompting, the authors take events as the center and propose a four-step summary reasoning process: specific event extraction; event abstraction and generalization; common event statistics; and summary generation. To further improve the performance of LLMs, the authors extend CoE prompting with the example of summary reasoning.\n\n\nFindings\nSummaries generated by CoE prompting are more abstractive, concise and accurate. The authors evaluate the authors’ proposed prompting on two data sets. The experimental results over ChatGLM2-6b show that the authors’ proposed CoE prompting consistently outperforms other typical promptings across all data sets.\n\n\nOriginality/value\nThis paper proposes CoE prompting to solve MDS tasks by the LLMs. CoE prompting can not only identify the key events but also ensure the conciseness of the summary. By this method, users can access the most relevant and important information quickly, improving their decision-making processes.\n",
        "link": "http://dx.doi.org/10.1108/ijwis-12-2023-0249"
    },
    {
        "id": 11577,
        "title": "Detection of Suicidality Through Privacy-Preserving Large Language Models",
        "authors": "Isabella Catharina Wiest, Falk Gerrik Verhees, Dyke Ferber, Jiefu Zhu, Michael Bauer, Ute Lewitzka, Andrea Pfennig, Pavol Mikolas, Jakob Nikolas Kather",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractImportanceAttempts to use Artificial Intelligence (AI) in psychiatric disorders show moderate success, high-lighting the potential of incorporating information from clinical assessments to improve the models. The study focuses on using Large Language Models (LLMs) to manage unstructured medical text, particularly for suicide risk detection in psychiatric care.ObjectiveThe study aims to extract information about suicidality status from the admission notes of electronic health records (EHR) using privacy-sensitive, locally hosted LLMs, specifically evaluating the efficacy of Llama-2 models.Main Outcomes and MeasuresThe study compares the performance of several variants of the open source LLM Llama-2 in extracting suicidality status from psychiatric reports against a ground truth defined by human experts, assessing accuracy, sensitivity, specificity, and F1 score across different prompting strategies.ResultsA German fine-tuned Llama-2 model showed the highest accuracy (87.5%), sensitivity (83%) and specificity (91.8%) in identifying suicidality, with significant improvements in sensitivity and specificity across various prompt designs.Conclusions and RelevanceThe study demonstrates the capability of LLMs, particularly Llama-2, in accurately extracting the information on suicidality from psychiatric records while preserving data-privacy. This suggests their application in surveillance systems for psychiatric emergencies and improving the clinical management of suicidality by improving systematic quality control and research.Key PointsQuestionCan large language models (LLMs) accurately extract information on suicidality from electronic health records (EHR)?FindingsIn this analysis of 100 psychiatric admission notes using Llama-2 models, the German fine-tuned model (Emgerman) demonstrated the highest accuracy (87.5%), sensitivity (83%) and specificity (91.8%) in identifying suicidality, indicating the models’ effectiveness in on-site processing of clinical documentation for suicide risk detection.MeaningThe study highlights the effectiveness of LLMs, particularly Llama-2, in accurately extracting the information on suicidality from psychiatric records, while preserving data privacy. It recommends further evaluating these models to integrate them into clinical management systems to improve detection of psychiatric emergencies and enhance systematic quality control and research in mental health care.",
        "link": "http://dx.doi.org/10.1101/2024.03.06.24303763"
    },
    {
        "id": 11578,
        "title": "Investigating Large Language Models for Financial Causality Detection in Multilingual Setup",
        "authors": "Neelesh K Shukla, Raghu Katikeri, Msp Raja, Gowtham Sivam, Shlok Yadav, Amit Vaid, Shreenivas Prabhakararao",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386558"
    },
    {
        "id": 11579,
        "title": "CureNet: Improving Explainability of AI Diagnosis Using Custom Large Language Models",
        "authors": "Subhash Khambampati, Sushanth Dondapati, Tejo Vardhan Kattamuri, Rahul Krishnan Pathinarupothi",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/smartgencon60755.2023.10442356"
    },
    {
        "id": 11580,
        "title": "ChatGPT, Large Language Models, and Generative AI as Future Augments of Surgical Cancer Care",
        "authors": "A. N. Kothari",
        "published": "2023-6",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1245/s10434-023-13442-2"
    },
    {
        "id": 11581,
        "title": "Real-time emotion generation in human-robot dialogue using large language models",
        "authors": "Chinmaya Mishra, Rinus Verdonschot, Peter Hagoort, Gabriel Skantze",
        "published": "2023-12-1",
        "citations": 2,
        "abstract": "Affective behaviors enable social robots to not only establish better connections with humans but also serve as a tool for the robots to express their internal states. It has been well established that emotions are important to signal understanding in Human-Robot Interaction (HRI). This work aims to harness the power of Large Language Models (LLM) and proposes an approach to control the affective behavior of robots. By interpreting emotion appraisal as an Emotion Recognition in Conversation (ERC) tasks, we used GPT-3.5 to predict the emotion of a robot’s turn in real-time, using the dialogue history of the ongoing conversation. The robot signaled the predicted emotion using facial expressions. The model was evaluated in a within-subjects user study (N = 47) where the model-driven emotion generation was compared against conditions where the robot did not display any emotions and where it displayed incongruent emotions. The participants interacted with the robot by playing a card sorting game that was specifically designed to evoke emotions. The results indicated that the emotions were reliably generated by the LLM and the participants were able to perceive the robot’s emotions. It was found that the robot expressing congruent model-driven facial emotion expressions were perceived to be significantly more human-like, emotionally appropriate, and elicit a more positive impression. Participants also scored significantly better in the card sorting game when the robot displayed congruent facial expressions. From a technical perspective, the study shows that LLMs can be used to control the affective behavior of robots reliably in real-time. Additionally, our results could be used in devising novel human-robot interactions, making robots more effective in roles where emotional interaction is important, such as therapy, companionship, or customer service.",
        "link": "http://dx.doi.org/10.3389/frobt.2023.1271610"
    },
    {
        "id": 11582,
        "title": "Enhancing Speaker Diarization with Large Language Models: A Contextual Beam Search Approach",
        "authors": "Tae Jin Park, Kunal Dhawan, Nithin Koluguri, Jagadeesh Balam",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446204"
    },
    {
        "id": 11583,
        "title": "Reply to Comment on: Performance of Generative Large Language Models on Ophthalmology Board Style Questions",
        "authors": "LOUIS Z. CAI, CHRISFOUAD ALABIAD",
        "published": "2023-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ajo.2023.07.030"
    },
    {
        "id": 11584,
        "title": "DReAMy: a library for the automatic analysis and annotation of dream reports with multilingual large language models",
        "authors": "L. Bertolini, A. Michalak, J. Weeds",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.sleep.2023.11.1092"
    },
    {
        "id": 11585,
        "title": "Narratron: Collaborative Writing and Shadow-playing of Children Stories with Large Language Models",
        "authors": "Yubo Zhao, Xiying Bao",
        "published": "2023-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3586182.3625120"
    },
    {
        "id": 11586,
        "title": "CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models",
        "authors": "Cheng Qian, Chi Han, Yi Fung, Yujia Qin, Zhiyuan Liu, Heng Ji",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.462"
    },
    {
        "id": 11587,
        "title": "A Loosely Wittgensteinian Conception of the Linguistic Understanding of Large Language Models like BERT, GPT-3, and ChatGPT",
        "authors": "Reto Gubelmann",
        "published": "2023-4-12",
        "citations": 1,
        "abstract": "Abstract\nIn this article, I develop a loosely Wittgensteinian conception of what it takes for a being, including an AI system, to understand language, and I suggest that current state of the art systems are closer to fulfilling these requirements than one might think. Developing and defending this claim has both empirical and conceptual aspects. The conceptual aspects concern the criteria that are reasonably applied when judging whether some being understands language; the empirical aspects concern the question whether a given being fulfills these criteria. On the conceptual side, the article builds on Glock’s concept of intelligence, Taylor’s conception of intrinsic rightness as well as Wittgenstein’s rule-following considerations. On the empirical side, it is argued that current transformer-based NNLP models, such as BERT and GPT-3 come close to fulfilling these criteria.",
        "link": "http://dx.doi.org/10.1163/18756735-00000182"
    },
    {
        "id": 11588,
        "title": "Large language models and structured reporting: never stop chasing critical thinking",
        "authors": "Carlo A. Mallio, Caterina Bernetti, Andrea Carlomaria Sertorio, Bruno Beomonte Zobel",
        "published": "2023-9-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11547-023-01711-9"
    },
    {
        "id": 11589,
        "title": "SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities",
        "authors": "Dong Zhang, Shimin Li, Xin Zhang, Jun Zhan, Pengyu Wang, Yaqian Zhou, Xipeng Qiu",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.1055"
    },
    {
        "id": 11590,
        "title": "LIDA: A Tool for Automatic Generation of Grammar-Agnostic Visualizations and Infographics using Large Language Models",
        "authors": "Victor Dibia",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-demo.11"
    },
    {
        "id": 11591,
        "title": "Promise and Perils of Large Language Models for Cancer Survivorship and Supportive Care",
        "authors": "Danielle S. Bitterman, Andrea Downing, Julia Maués, Maryam Lustberg",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": " A call to action to bring stakeholders together to plan for the future of LLM-enhanced cancer survivorship. ",
        "link": "http://dx.doi.org/10.1200/jco.23.02439"
    },
    {
        "id": 11592,
        "title": "Global Mental Health Services and the Impact of Artificial Intelligence–Powered Large Language Models",
        "authors": "Alastair C. van Heerden, Julia R. Pozuelo, Brandon A. Kohrt",
        "published": "2023-7-1",
        "citations": 8,
        "abstract": "This Viewpoint describes ways in which artificial intelligence–powered large language models may be used to improve the delivery of mental health services worldwide.",
        "link": "http://dx.doi.org/10.1001/jamapsychiatry.2023.1253"
    },
    {
        "id": 11593,
        "title": "Large language models: a primer and gastroenterology applications",
        "authors": "Omer Shahab, Bara El Kurdi, Aasma Shaukat, Girish Nadkarni, Ali Soroush",
        "published": "2024-1",
        "citations": 0,
        "abstract": " Over the past year, the emergence of state-of-the-art large language models (LLMs) in tools like ChatGPT has ushered in a rapid acceleration in artificial intelligence (AI) innovation. These powerful AI models can generate tailored and high-quality text responses to instructions and questions without the need for labor-intensive task-specific training data or complex software engineering. As the technology continues to mature, LLMs hold immense potential for transforming clinical workflows, enhancing patient outcomes, improving medical education, and optimizing medical research. In this review, we provide a practical discussion of LLMs, tailored to gastroenterologists. We highlight the technical foundations of LLMs, emphasizing their key strengths and limitations as well as how to interact with them safely and effectively. We discuss some potential LLM use cases for clinical gastroenterology practice, education, and research. Finally, we review critical barriers to implementation and ongoing work to address these issues. This review aims to equip gastroenterologists with a foundational understanding of LLMs to facilitate a more active clinician role in the development and implementation of this rapidly emerging technology. ",
        "link": "http://dx.doi.org/10.1177/17562848241227031"
    },
    {
        "id": 11594,
        "title": "Supervised Contrastive Learning as Multi-Objective Optimization for Fine-Tuning Large Pre-Trained Language Models",
        "authors": "Youness Moukafih, Mounir Ghogho, Kamel Smaili",
        "published": "2023-6-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10095108"
    },
    {
        "id": 11595,
        "title": "Investigating the Efficacy of Large Language Models in Reflective Assessment Methods through Chain of Thought Prompting",
        "authors": "Baphumelele Masikisiki, Vukosi Marivate, Yvette Hlophe",
        "published": "2023-11-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3628096.3628747"
    },
    {
        "id": 11596,
        "title": "Neural Authorship Attribution: Stylometric Analysis on Large Language Models",
        "authors": "Tharindu Kumarage, Huan Liu",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cyberc58899.2023.00019"
    },
    {
        "id": 11597,
        "title": "PROSPER",
        "authors": "Prakhar Sharma, Vinod Yegneswaran",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626111.3628205"
    },
    {
        "id": 11598,
        "title": "Sensecape: Enabling Multilevel Exploration and Sensemaking with Large Language Models",
        "authors": "Sangho Suh, Bryan Min, Srishti Palani, Haijun Xia",
        "published": "2023-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3586183.3606756"
    },
    {
        "id": 11599,
        "title": "CHiLL: Zero-shot Custom Interpretable Feature Extraction from Clinical Notes with Large Language Models",
        "authors": "Denis McInerney, Geoffrey Young, Jan-Willem van de Meent, Byron Wallace",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.568"
    },
    {
        "id": 11600,
        "title": "Metaphorian: Leveraging Large Language Models to Support Extended Metaphor Creation for Science Writing",
        "authors": "Jeongyeon Kim, Sangho Suh, Lydia B Chilton, Haijun Xia",
        "published": "2023-7-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3563657.3595996"
    },
    {
        "id": 11601,
        "title": "A Smart Interactive Camera Robot Based on Large Language Models",
        "authors": "Zeyu Bao, Guo-Niu Zhu, Wenchao Ding, Yuxiang Guan, Weibang Bai, Zhongxue Gan",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/robio58561.2023.10354952"
    },
    {
        "id": 11602,
        "title": "Large Language Models in Ophthalmology Scientific Writing: Ethical Considerations Blurred Lines or Not at All?",
        "authors": "Ali Salimi, Hady Saheb",
        "published": "2023-10",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ajo.2023.06.004"
    },
    {
        "id": 11603,
        "title": "The Future of AI in Ovarian Cancer Research: The Large Language Models Perspective",
        "authors": "Alexandros Laios, Georgios Theophilou, Diederick De Jong, Evangelos Kalampokis",
        "published": "2023-4",
        "citations": 3,
        "abstract": " Conversational large language model (LLM)-based chatbots utilize neural networks to process natural language. By generating highly sophisticated outputs from contextual input text, they revolutionize the access to further learning, leading to the development of new skills and personalized interactions. Although they are not developed to provide healthcare, their potential to address biomedical issues is rather unexplored. Healthcare digitalization and documentation of electronic health records is now developing into a standard practice. Developing tools to facilitate clinical review of unstructured data such as LLMs can derive clinical meaningful insights for ovarian cancer, a heterogeneous but devastating disease. Compared to standard approaches, they can host capacity to condense results and optimize analysis time. To help accelerate research in biomedical language processing and improve the validity of scientific writing, task-specific and domain-specific language models may be required. In turn, we propose a bespoke, proprietary ovarian cancer-specific natural language using solely in-domain text, whereas transfer learning drifts away from the pretrained language models to fine-tune task-specific models for all possible downstream applications. This venture will be fueled by the abundance of unstructured text information in the electronic health records resulting in ovarian cancer research ultimately reaching its linguistic home. ",
        "link": "http://dx.doi.org/10.1177/10732748231197915"
    },
    {
        "id": 11604,
        "title": "Data Augmentation for Intent Classification with Off-the-shelf Large Language Models",
        "authors": "Gaurav Sahu, Pau Rodriguez, Issam Laradji, Parmida Atighehchian, David Vazquez, Dzmitry Bahdanau",
        "published": "2022",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.nlp4convai-1.5"
    },
    {
        "id": 11605,
        "title": "Automated Program Repair in the Era of Large Pre-trained Language Models",
        "authors": "Chunqiu Steven Xia, Yuxiang Wei, Lingming Zhang",
        "published": "2023-5",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icse48619.2023.00129"
    },
    {
        "id": 11606,
        "title": "From Search Engines to Large Language Models: A Big Leap for Patient Education!",
        "authors": "Emanuele Barabino, Giuseppe Cittadini",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00270-024-03658-4"
    },
    {
        "id": 11607,
        "title": "Workshop On Large Language Models' Interpretability and Trustworthiness (LLMIT)",
        "authors": "Tulika Saha, Debasis Ganguly, Sriparna Saha, Prasenjit Mitra",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3583780.3615311"
    },
    {
        "id": 11608,
        "title": "Parameter-Efficient Sparsity for Large Language Models Fine-Tuning",
        "authors": "Yuchao Li, Fuli Luo, Chuanqi Tan, Mengdi Wang, Songfang Huang, Shen Li, Junjie Bai",
        "published": "2022-7",
        "citations": 0,
        "abstract": "With the dramatically increased number of parameters in language models, sparsity methods have received ever-increasing research focus to compress and accelerate the models. While most research focuses on how to accurately retain appropriate weights while maintaining the performance of the compressed model, there are challenges in the computational overhead and memory footprint of sparse training when compressing large-scale language models. To address this problem, we propose a Parameter-efficient Sparse Training (PST) method to reduce the number of trainable parameters during sparse-aware training in downstream tasks. Specifically, we first combine the data-free and data-driven criteria to efficiently and accurately measure the importance of weights. Then we investigate the intrinsic redundancy of data-driven weight importance and derive two obvious characteristics i.e. low-rankness and structuredness. Based on that, two groups of small matrices are introduced to compute the data-driven importance of weights, instead of using the original large importance score matrix, which therefore makes the sparse training resource-efficient and parameter-efficient. Experiments with diverse networks (i.e. BERT, RoBERTa and GPT-2) on dozens of datasets demonstrate PST performs on par or better than previous sparsity methods, despite only training a small number of parameters. For instance, compared with previous sparsity methods, our PST only requires 1.5% trainable parameters to achieve comparable performance on BERT.",
        "link": "http://dx.doi.org/10.24963/ijcai.2022/586"
    },
    {
        "id": 11609,
        "title": "Diagnostic Accuracy of Large Language Models in the European Board of Interventional Radiology Examination (EBIR) Sample Questions",
        "authors": "Yasin Celal Güneş, Turay Cesur",
        "published": "2024-2-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00270-024-03674-4"
    },
    {
        "id": 11610,
        "title": "Long-Form Speech Translation through Segmentation with Finite-State Decoding Constraints on Large Language Models",
        "authors": "Arya McCarthy, Hao Zhang, Shankar Kumar, Felix Stahlberg, Ke Wu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.19"
    },
    {
        "id": 11611,
        "title": "Efficient Finetuning Large Language Models For Vietnamese Chatbot",
        "authors": "Vu-Thuan Doan, Quoc-Truong Truong, Duc-Vu Nguyen, Vinh-Tiep Nguyen, Thuy-Ngan Nguyen Luu",
        "published": "2023-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mapr59823.2023.10288647"
    },
    {
        "id": 11612,
        "title": "Transforming Structural Engineering: Examining the Opportunities and Risks of ChatGPT and Other Large Language Models",
        "authors": "Rishav Pokhrel, Sital Parajuli",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "The advancements in technology, particularly the development of high-performance computing (HPC) and large language models (LLMs) like ChatGPT, can potentially transform the field of Structural Engineering. Use of LLMs, such as ChatGPT, offers several opportunities in Structural Engineering, including the development of innovative design solutions, use in code-based structural analysis programs by automating repetitive coding tasks, conforming to building code requirements by automating compliance checks, and storing information. The critical concerns arise in LLM’s regarding biases, misinformation, safety, reliability, and lack of domain expertise. This paper explores the opportunities and risks associated with using ChatGPT and LLMs in Structural Engineering, focusing on efficiency, accuracy, and reliability. The main aim of the study is to examine the limitations and potential risks of relying solely on machine-generated information and to provide mitigation strategies to overcome them. Careful management to prevent harmful content, collaboration with human experts for accurate results, establishing guidelines and standards are obligatory measures to address ethical concerns such as bias, privacy, and abuse. Continuous monitoring and updating of LLMs are essential to maintain accuracy and relevance. While ChatGPT and LLMs offer significant benefits in Structural Engineering, responsible usage in combination with human expertise and machine-generated insights are vital to maximizing their potential while mitigating risks and ensuring safe as well as reliable engineering practices. ",
        "link": "http://dx.doi.org/10.3126/injet.v1i1.60944"
    },
    {
        "id": 11613,
        "title": "Using Large Language Models in the Companion Cognitive Architecture: A Case Study and Future Prospects",
        "authors": "Constantine Nakos, Kenneth D. Forbus",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "The goal of the Companion cognitive architecture is to understand how to create human-like software social organisms.  Thus natural language capabilities, both for reading and conversation, are essential.  Recently we have begun experimenting with large language models as a component in the Companion architecture.  This paper summarizes a case study indicating why we are currently using BERT with our symbolic natural language understanding system.  It also describes some additional ways we are contemplating using large language models with Companions.",
        "link": "http://dx.doi.org/10.1609/aaaiss.v2i1.27700"
    },
    {
        "id": 11614,
        "title": "ChatGPT is fun, but it is not funny! Humor is still challenging Large Language Models",
        "authors": "Sophie Jentzsch, Kristian Kersting",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.wassa-1.29"
    },
    {
        "id": 11615,
        "title": "Evolving Landscape of Large Language Models: An Evaluation of ChatGPT and Bard in Answering Patient Queries on Colonoscopy",
        "authors": "Raseen Tariq, Sheza Malik, Sahil Khanna",
        "published": "2024-1",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1053/j.gastro.2023.08.033"
    },
    {
        "id": 11616,
        "title": "Using Large Language Models for Teaching Computing",
        "authors": "Juho Leinonen, Stephen MacNeil, Paul Denny, Arto Hellas",
        "published": "2024-3-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626253.3633436"
    },
    {
        "id": 11617,
        "title": "Dehallucinating Large Language Models Using Formal Methods Guided Iterative Prompting",
        "authors": "Susmit Jha, Sumit Kumar Jha, Patrick Lincoln, Nathaniel D. Bastian, Alvaro Velasquez, Sandeep Neema",
        "published": "2023-6",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icaa58325.2023.00029"
    },
    {
        "id": 11618,
        "title": "How can Transformers and large language models like ChatGPT help LCA practitioners?",
        "authors": "Simone Cornago, Seeram Ramakrishna, Jonathan Sze Choong Low",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.resconrec.2023.107062"
    },
    {
        "id": 11619,
        "title": "Radiology, structured reporting and large language models: who is running faster?",
        "authors": "Carlo A. Mallio, Andrea Carlomaria Sertorio, Caterina Bernetti, Bruno Beomonte Zobel",
        "published": "2023-7-27",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11547-023-01689-4"
    },
    {
        "id": 11620,
        "title": "Comment on: AI am a rheumatologist: a practical primer to large language models for rheumatologists: reply",
        "authors": "Vincenzo Venerito, Emre Bilgin, Florenzo Iannone, Sedat Kiraz",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/rheumatology/kead415"
    },
    {
        "id": 11621,
        "title": "Re: Kianian et al.: Enhancing the assessment of large language models in medical information generation (Ophthalmol Retina. 2024;8:195-201)",
        "authors": "Taher K. Eleiwa, Abdelrahman M. Elhusseiny",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.oret.2024.01.009"
    },
    {
        "id": 11622,
        "title": "In-context Learning of Large Language Models for Controlled Dialogue Summarization: A Holistic Benchmark and Empirical Analysis",
        "authors": "Yuting Tang, Ratish Puduppully, Zhengyuan Liu, Nancy Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.newsum-1.6"
    },
    {
        "id": 11623,
        "title": "Robot Debater: Debate-styled Text Auto-generation System Based on Large Foundation Language Models",
        "authors": "Yu Zhu, Yijun Ling, Xufeng Ling, Jie Yang",
        "published": "2023-8-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/prml59573.2023.10348335"
    },
    {
        "id": 11624,
        "title": "Large language models capsule: A research analysis of In-Context Learning (ICL) and Parameter-Efficient Fine-Tuning (PEFT) methods",
        "authors": "Haokun Wu",
        "published": "2024-2-26",
        "citations": 0,
        "abstract": "In the context of natural language processing (NLP), this paper addresses the growing need for efficient adaptation techniques for pre-trained language models. It begins by summarizing the current landscape of NLP, highlighting the challenges associated with fine-tuning large language models like BERT and Transformer. The paper then introduces and analyzes three categories of parameter-efficient fine-tuning (PEFT) approaches, namely, In-Context Learning (ICL)-inspired Fine-Tuning, Low-Rank Adaptation PEFTs (LoRA), and Activation-based PEFTs. Within these categories, it explores techniques such as prefix-tuning, prompt tuning, (IA)3, and LoRA, shedding light on their advantages and applications. Through a comprehensive examination, this paper concludes by emphasizing the interplay between performance, parameter efficiency, and adaptability in the context of NLP models. It also provides insights into the future prospects of these techniques in advancing the field of NLP. To summarize, this paper offers a detailed analysis of PEFT methods and their potential to democratize access to cutting-edge NLP capabilities, paving the way for more efficient model adaptation in various applications.",
        "link": "http://dx.doi.org/10.54254/2755-2721/43/20230858"
    },
    {
        "id": 11625,
        "title": "Neural Architecture Search for Parameter-Efficient Fine-tuning of Large Pre-trained Language Models",
        "authors": "Neal Lawton, Anoop Kumar, Govind Thattai, Aram Galstyan, Greg Ver Steeg",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.539"
    },
    {
        "id": 11626,
        "title": "Improving the Robustness of Transformer-based Large Language Models with Dynamic Attention",
        "authors": "Lujia Shen, Yuwen Pu, Shouling Ji, Changjiang Li, Xuhong Zhang, Chunpeng Ge, Ting Wang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14722/ndss.2024.24115"
    },
    {
        "id": 11627,
        "title": "Decoding Prompt Syntax: Analysing its Impact on Knowledge Retrieval in Large Language Models",
        "authors": "Stephan Linzbach, Tim Tressel, Laura Kallmeyer, Stefan Dietze, Hajira Jabeen",
        "published": "2023-4-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3543873.3587655"
    },
    {
        "id": 11628,
        "title": "Large language models as a substitute for human experts in annotating political text",
        "authors": "Michael Heseltine, Bernhard Clemm von Hohenberg",
        "published": "2024-1",
        "citations": 1,
        "abstract": " Large-scale text analysis has grown rapidly as a method in political science and beyond. To date, text-as-data methods rely on large volumes of human-annotated training examples, which place a premium on researcher resources. However, advances in large language models (LLMs) may make automated annotation increasingly viable. This paper tests the performance of GPT-4 across a range of scenarios relevant for analysis of political text. We compare GPT-4 coding with human expert coding of tweets and news articles across four variables (whether text is political, its negativity, its sentiment, and its ideology) and across four countries (the United States, Chile, Germany, and Italy). GPT-4 coding is highly accurate, especially for shorter texts such as tweets, correctly classifying texts up to 95% of the time. Performance drops for longer news articles, and very slightly for non-English text. We introduce a ‘hybrid’ coding approach, in which disagreements of multiple GPT-4 runs are adjudicated by a human expert, which boosts accuracy. Finally, we explore downstream effects, finding that transformer models trained on hand-coded or GPT-4-coded data yield almost identical outcomes. Our results suggest that LLM-assisted coding is a viable and cost-efficient approach, although consideration should be given to task complexity. ",
        "link": "http://dx.doi.org/10.1177/20531680241236239"
    },
    {
        "id": 11629,
        "title": "Science in the era of ChatGPT, large language models and generative AI",
        "authors": "Evangelos Pournaras",
        "published": "2023-12-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783839467664-015"
    },
    {
        "id": 11630,
        "title": "Large Language Models and Adversarial Reinforcement Learning to Automate PLCs Programming: A Preliminary Investigation",
        "authors": "Abderrahmane Boudribila, Mohamed-Amine Chadi, Abdelouahed Tajer, Zakaria Boulghasoul",
        "published": "2023-7-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/codit58514.2023.10284185"
    },
    {
        "id": 11631,
        "title": "Multiway-Adapter: Adapting Multimodal Large Language Models for Scalable Image-Text Retrieval",
        "authors": "Zijun Long, George Killick, Richard McCreadie, Gerardo Aragon Camarasa",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446792"
    },
    {
        "id": 11632,
        "title": "The Integration of Large Language Models Such as ChatGPT in Scientific Writing: Harnessing Potential and Addressing Pitfalls",
        "authors": "Shunsuke Koga",
        "published": "2023",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3348/kjr.2023.0738"
    },
    {
        "id": 11633,
        "title": "Evaluating Data Augmentation for Medication Identification in Clinical Notes",
        "authors": "Jordan Koontz,  , Maite Oronoz, Alicia Pérez,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_063"
    },
    {
        "id": 11634,
        "title": "Comparative Analysis of Anomaly Detection Algorithms in Text Data",
        "authors": "Yizhou Xu,  , Kata Gábor, Jérôme Milleret, Frédérique Segond,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_131"
    },
    {
        "id": 11635,
        "title": "Word Sense Disambiguation for Automatic Translation of Medical Dialogues into Pictographs",
        "authors": "Magali Norré,  , Rémi Cardon, Vincent Vandeghinste, Thomas François,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_087"
    },
    {
        "id": 11636,
        "title": "Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models",
        "authors": "Levon Haroutunian, Zhuang Li, Lucian Galescu, Philip Cohen, Raj Tumuluri, Gholamreza Haffari",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.ijcnlp-main.69"
    },
    {
        "id": 11637,
        "title": "CarExpert: Leveraging Large Language Models for In-Car Conversational Question Answering",
        "authors": "Md Rashad Al Hasan Rony, Christian Suess, Sinchana Ramakanth Bhat, Viju Sudhi, Julia Schneider, Maximilian Vogel, Roman Teucher, Ken Friedl, Soumya Sahoo",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-industry.56"
    },
    {
        "id": 11638,
        "title": "Lexicon-driven automatic sentence generation for the skills section in a job posting",
        "authors": "Vera Aleksić,  , Mona Brems, Anna Mathes, Theresa Bertele,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_004"
    },
    {
        "id": 11639,
        "title": "‘ChemXtract’ A System for Extraction of Chemical Events from Patent Documents",
        "authors": "Pattabhi RK Rao,  , Sobha Lalitha Devi,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_106"
    },
    {
        "id": 11640,
        "title": "Does the “most sinfully decadent cake ever” taste good? Answering Yes/No Questions from Figurative Contexts",
        "authors": "Geetanjali Rakshit,  , Jeffrey Flanigan,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_100"
    },
    {
        "id": 11641,
        "title": "Large and ancient linguistic areas",
        "authors": "Balthasar Bickel",
        "published": "2020-7-24",
        "citations": 7,
        "abstract": "Large-scale areal patterns point to ancient population history and form a well-known confound for language universals. Despite their importance, demonstrating such patterns remains a challenge. This chapter argues that large-scale area hypotheses are better tested by modeling diachronic family biases than by controlling for genealogical relations in regression models. A case study of the Trans-Pacific area reveals that diachronic bias estimates do not depend much on the amount of phylogenetic information that is used when inferring them. After controlling for false discovery rates, about 39 variables in WALS and AUTOTYP show diachronic biases that differ significantly inside vs. outside the Trans-Pacific area. Nearly three times as many biases hold outside than inside the Trans-Pacific area, indicating that the Trans-Pacific area is not so much characterized by the spread of biases but rather by the retention of earlier diversity, in line with earlier suggestions in the literature.",
        "link": "http://dx.doi.org/10.1093/oso/9780198723813.003.0005"
    },
    {
        "id": 11642,
        "title": "Craft an Iron Sword: Dynamically Generating Interactive Game Characters by Prompting Large Language Models Tuned on Code",
        "authors": "Ryan Volum, Sudha Rao, Michael Xu, Gabriel DesGarennes, Chris Brockett, Benjamin Van Durme, Olivia Deng, Akanksha Malhotra, Bill Dolan",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.wordplay-1.3"
    },
    {
        "id": 11643,
        "title": "Building a Role Specified Open-Domain Dialogue System Leveraging Large-Scale Language Models",
        "authors": "Sanghwan Bae, Donghyun Kwak, Sungdong Kim, Donghoon Ham, Soyoung Kang, Sang-Woo Lee, Woomyoung Park",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.155"
    },
    {
        "id": 11644,
        "title": "The shaky foundations of large language models and foundation models for electronic health records",
        "authors": "Michael Wornow, Yizhe Xu, Rahul Thapa, Birju Patel, Ethan Steinberg, Scott Fleming, Michael A. Pfeffer, Jason Fries, Nigam H. Shah",
        "published": "2023-7-29",
        "citations": 25,
        "abstract": "AbstractThe success of foundation models such as ChatGPT and AlphaFold has spurred significant interest in building similar models for electronic medical records (EMRs) to improve patient care and hospital operations. However, recent hype has obscured critical gaps in our understanding of these models’ capabilities. In this narrative review, we examine 84 foundation models trained on non-imaging EMR data (i.e., clinical text and/or structured data) and create a taxonomy delineating their architectures, training data, and potential use cases. We find that most models are trained on small, narrowly-scoped clinical datasets (e.g., MIMIC-III) or broad, public biomedical corpora (e.g., PubMed) and are evaluated on tasks that do not provide meaningful insights on their usefulness to health systems. Considering these findings, we propose an improved evaluation framework for measuring the benefits of clinical foundation models that is more closely grounded to metrics that matter in healthcare.",
        "link": "http://dx.doi.org/10.1038/s41746-023-00879-8"
    },
    {
        "id": 11645,
        "title": "Large Language Publishing",
        "authors": "Jeff Pooley",
        "published": "No Date",
        "citations": 1,
        "abstract": "<em> The New York Times </em> ushered in the New Year with a lawsuit against OpenAI and Microsoft. The paper covered the suit, fittingly, as a major business story.",
        "link": "http://dx.doi.org/10.54900/zg929-e9595"
    },
    {
        "id": 11646,
        "title": "Evaluating Large Language Models’ Understanding of Financial Terminology via Definition Modeling",
        "authors": "James Jhirad, Edison Marrese-Taylor, Yutaka Matsuo",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.ijcnlp-srw.12"
    },
    {
        "id": 11647,
        "title": "The Future of Humans and Language Models",
        "authors": "Mascha Kurpicz-Briki",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-37690-0_7"
    },
    {
        "id": 11648,
        "title": "Harnessing AI–Human Synergy for Deep Learning Research Analysis in Ophthalmology with Large Language Models Assisting Humans",
        "authors": "Ming-Jie Luo, Weixing Zhang, Zheming Zhang, Jianyu Pang, Zhenzhe Lin, Lanqin Zhao, Duoru Lin, Haotian Lin",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4544764"
    },
    {
        "id": 11649,
        "title": "Additional Considerations in the Era of Large Language Models in Health Care",
        "authors": "Arosh S. Perera Molligoda Arachchige",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jacr.2023.12.031"
    },
    {
        "id": 11650,
        "title": "Natural Language Processing in Large-Scale Neural Models for Medical Screenings",
        "authors": "Catharina Marie Stille, Trevor Bekolay, Peter Blouw, Bernd J. Kröger",
        "published": "2019-8-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3389/frobt.2019.00062"
    },
    {
        "id": 11651,
        "title": "Large Language Models and Generative AI, Oh My!",
        "authors": "Peter J. Cobb",
        "published": "2023-8",
        "citations": 4,
        "abstract": "OverviewWe have all read the headlines heralding, often hyperbolically, the latest advances in text- and image-based Artificial Intelligence (AI). What is perhaps most unique about these developments is that they now make relatively good AI accessible to the average Internet user. These new services respond to human prompts, written in natural language, with generated output that appears to satisfy the prompt. Consequently, they are categorized under the term “generative AI,” whether they are generating text, images, or other media. They work by modeling human language statistically, to “learn” patterns from extremely large datasets of human-created content, with those that specifically focus on text therefore called Large Language Models (LLMs). As we have all tried products such as ChatGPT or Midjourney over the past year, we have undoubtedly begun to wonder how and when they might impact our archaeological work. Here, I review the state of this type of AI and the current challenges with using it meaningfully, and I consider its potential for archaeologists.",
        "link": "http://dx.doi.org/10.1017/aap.2023.20"
    },
    {
        "id": 11652,
        "title": "Direction is what you need: Improving Word Embedding Compression in Large Language Models",
        "authors": "Klaudia Bałazy, Mohammadreza Banaei, Rémi Lebret, Jacek Tabor, Karl Aberer",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.repl4nlp-1.32"
    },
    {
        "id": 11653,
        "title": "Data Selection for Fine-tuning Large Language Models Using Transferred Shapley Values",
        "authors": "Stephanie Schoch, Ritwick Mishra, Yangfeng Ji",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-srw.37"
    },
    {
        "id": 11654,
        "title": "Task and Motion Planning with Large Language Models for Object Rearrangement",
        "authors": "Yan Ding, Xiaohan Zhang, Chris Paxton, Shiqi Zhang",
        "published": "2023-10-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iros55552.2023.10342169"
    },
    {
        "id": 11655,
        "title": "Comment on “From ChatGPT to Treatment: the Future of AI and Large Language Models in Surgical Oncology”",
        "authors": "Hinpetch Daungsupawong, Viroj Wiwanitkit",
        "published": "2024-1-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s13193-024-01886-1"
    },
    {
        "id": 11656,
        "title": "Enhancing Large Language Models’ Utility for Medical Question-Answering: A Patient Health Question Summarization Approach",
        "authors": "Nour Eddine Zekaoui, Siham Yousfi, Mounia Mikram, Maryem Rhanoui",
        "published": "2023-11-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/sita60746.2023.10373720"
    },
    {
        "id": 11657,
        "title": "Exploring the pitfalls of large language models: Inconsistency and inaccuracy in answering pathology board examination‐style questions",
        "authors": "Shunsuke Koga",
        "published": "2023-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/pin.13382"
    },
    {
        "id": 11658,
        "title": "Friend or foe? Exploring the implications of large language models on the science system",
        "authors": "Benedikt Fecher, Marcel Hebing, Melissa Laufer, Jörg Pohle, Fabian Sofsky",
        "published": "2023-10-26",
        "citations": 5,
        "abstract": "AbstractThe advent of ChatGPT by OpenAI has prompted extensive discourse on its potential implications for science and higher education. While the impact on education has been a primary focus, there is limited empirical research on the effects of large language models (LLMs) and LLM-based chatbots on science and scientific practice. To investigate this further, we conducted a Delphi study involving 72 researchers specializing in AI and digitization. The study focused on applications and limitations of LLMs, their effects on the science system, ethical and legal considerations, and the required competencies for their effective use. Our findings highlight the transformative potential of LLMs in science, particularly in administrative, creative, and analytical tasks. However, risks related to bias, misinformation, and quality assurance need to be addressed through proactive regulation and science education. This research contributes to informed discussions on the impact of generative AI in science and helps identify areas for future action.",
        "link": "http://dx.doi.org/10.1007/s00146-023-01791-1"
    },
    {
        "id": 11659,
        "title": "Demand-side energy management reimagined: A comprehensive literature analysis leveraging large language models",
        "authors": "Fanyue Meng, Zhaoyuan Lu, Xiang Li, Wei Han, Jieyang Peng, Xiufeng Liu, Zhibin Niu",
        "published": "2024-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.energy.2024.130303"
    },
    {
        "id": 11660,
        "title": "PopBlends: Strategies for Conceptual Blending with Large Language Models",
        "authors": "Sitong Wang, Savvas Petridis, Taeahn Kwon, Xiaojuan Ma, Lydia B Chilton",
        "published": "2023-4-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3544548.3580948"
    },
    {
        "id": 11661,
        "title": "How does the pre-training objective affect what large language models learn about linguistic properties?",
        "authors": "Ahmed Alajrami, Nikolaos Aletras",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.acl-short.16"
    },
    {
        "id": 11662,
        "title": "Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search",
        "authors": "Kelong Mao, Zhicheng Dou, Fengran Mo, Jiewen Hou, Haonan Chen, Hongjin Qian",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.86"
    },
    {
        "id": 11663,
        "title": "Response to “Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine”",
        "authors": "Markus Trengove, Robert Vandersluis, Lea Goetz",
        "published": "2023-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ebiom.2023.104671"
    },
    {
        "id": 11664,
        "title": "Potential applications and implications of large language models in primary care",
        "authors": "Albert Andrew",
        "published": "2024-1",
        "citations": 0,
        "abstract": "The recent release of highly advanced generative artificial intelligence (AI) chatbots, including ChatGPT and Bard, which are powered by large language models (LLMs), has attracted growing mainstream interest over its diverse applications in clinical practice, including in health and healthcare. The potential applications of LLM-based programmes in the medical field range from assisting medical practitioners in improving their clinical decision-making and streamlining administrative paperwork to empowering patients to take charge of their own health. However, despite the broad range of benefits, the use of such AI tools also comes with several limitations and ethical concerns that warrant further consideration, encompassing issues related to privacy, data bias, and the accuracy and reliability of information generated by AI. The focus of prior research has primarily centred on the broad applications of LLMs in medicine. To the author’s knowledge, this is, the first article that consolidates current and pertinent literature on LLMs to examine its potential in primary care. The objectives of this paper are not only to summarise the potential benefits, risks and challenges of using LLMs in primary care, but also to offer insights into considerations that primary care clinicians should take into account when deciding to adopt and integrate such technologies into their clinical practice.",
        "link": "http://dx.doi.org/10.1136/fmch-2023-002602"
    },
    {
        "id": 11665,
        "title": "Zero-shot Interpretable Phenotyping of Postpartum Hemorrhage Using Large Language Models",
        "authors": "Emily Alsentzer, Matthew J Rasmussen, Romy Fontoura, Alexis L Cull, Brett Beaulieu-Jones, Kathryn J Gray, David W Bates, Vesela P Kovacheva",
        "published": "No Date",
        "citations": 0,
        "abstract": "Many areas of medicine would benefit from deeper, more accurate phenotyping, but there are limited approaches for phenotyping using clinical notes without substantial annotated data. Large language models (LLMs) have demonstrated immense potential to adapt to novel tasks with no additional training by specifying task-specific i nstructions. We investigated the per-formance of a publicly available LLM, Flan-T5, in phenotyping patients with postpartum hemorrhage (PPH) using discharge notes from electronic health records (n=271,081). The language model achieved strong performance in extracting 24 granular concepts associated with PPH. Identifying these granular concepts accurately allowed the development of inter-pretable, complex phenotypes and subtypes. The Flan-T5 model achieved high fidelity in phenotyping PPH (positive predictive value of 0.95), identifying 47% more patients with this complication compared to the current standard of using claims codes. This LLM pipeline can be used reliably for subtyping PPH and outperformed a claims-based approach on the three most common PPH subtypes associated with uterine atony, abnormal placentation, and obstetric trauma. The advantage of this approach to subtyping is its interpretability, as each concept contributing to the subtype determination can be evaluated. Moreover, as definitions may change over time due to new guidelines, using granular concepts to create complex phenotypes enables prompt and efficient updating of the algorithm. Using this lan-guage modelling approach enables rapid phenotyping without the need for any manually annotated training data across multiple clinical use cases.",
        "link": "http://dx.doi.org/10.1101/2023.05.31.23290753"
    },
    {
        "id": 11666,
        "title": "Unleashing the Power of Large Language Models for Legal Applications",
        "authors": "Dell Zhang, Alina Petrova, Dietrich Trautmann, Frank Schilder",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3583780.3615993"
    },
    {
        "id": 11667,
        "title": "Potential merits and flaws of large language models in epilepsy care: A critical review",
        "authors": "Eric van Diessen, Ramon A. van Amerongen, Maeike Zijlmans, Willem M. Otte",
        "published": "2024-2-2",
        "citations": 0,
        "abstract": "AbstractThe current pace of development and applications of large language models (LLMs) is unprecedented and will impact future medical care significantly. In this critical review, we provide the background to better understand these novel artificial intelligence (AI) models and how LLMs can be of future use in the daily care of people with epilepsy. Considering the importance of clinical history taking in diagnosing and monitoring epilepsy—combined with the established use of electronic health records—a great potential exists to integrate LLMs in epilepsy care. We present the current available LLM studies in epilepsy. Furthermore, we highlight and compare the most commonly used LLMs and elaborate on how these models can be applied in epilepsy. We further discuss important drawbacks and risks of LLMs, and we provide recommendations for overcoming these limitations.",
        "link": "http://dx.doi.org/10.1111/epi.17907"
    },
    {
        "id": 11668,
        "title": "Dual use concerns of generative AI and large language models",
        "authors": "Alexei Grinbaum, Laurynas Adomaitis",
        "published": "2024-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/23299460.2024.2304381"
    },
    {
        "id": 11669,
        "title": "Large Language Models as Master Key: Unlocking the Secrets of Materials Science",
        "authors": "Tong Xie, Yuwei Wan, Yufei Zhou, Wei Huang, Yixuan Liu, Qingyuan Linghu, Shaozhou Wang, Chunyu Kit, Clara Grazian, Wenjie Zhang, Bram Hoex",
        "published": "No Date",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4534137"
    },
    {
        "id": 11670,
        "title": "One is Not Enough: Multi-Agent Conversation Framework Enhances Rare Disease Diagnostic Capabilities of Large Language Models",
        "authors": "Jian Li, Xi Chen, Weizhi Liu, Li Wang, Yingman Guo, Mingke You, Gang Chen, Kang Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nImportance\n This study adopted multi-agent framework in large language models to enhance diagnosis in complex medical cases, particularly rare diseases, revealing limitation in current training and benchmarking of LLMs in healthcare.\nObjective\n This study aimed to develop MAC LLMs for medical diagnosis, and compare the knowledge base and diagnostic capabilities of GPT-3.5, GPT-4, and MAC in the context of rare diseases.\nDesign, Setting and Participants\n This study examined 150 rare diseases using clinical case reports published after January 1, 2022, from the Medline database. Each case was curated, and both the initial and complete presentations were extracted to simulate the different stages of patient consultation. A MAC framework was developed. Disease knowledge base was tested using GPT-3.5, GPT-4, and the MAC. Each case was subjected to the three models to generate one most likely diagnosis, several possible diagnoses, and further diagnostic tests. The results were presented for panel discussions with physicians. Disease knowledge was evaluated. The accuracy and scoring of the one most likely diagnosis, several possible diagnoses, and further diagnostic tests were also evaluated.\nMain Outcomes And Measures:\n Scoring of disease knowledge. Accuracy and scoring of the one most likely diagnosis, several possible diagnoses and further diagnostic tests.\nResults\n In terms of disease-specific knowledge, GPT-3.5, GPT-4, and MAC scored above 4.5 on average for each aspect. In terms of diagnostic ability, MAC outperformed GPT-3.5 and GPT-4 in initial presentations, achieving higher accuracy in the most likely diagnoses (28%), possible diagnoses (47.3%), and further diagnostic tests (83.3%). GPT-3.5 and GPT-4 exhibited lower accuracy in these areas. In complete presentations, MAC continued to demonstrate higher accuracies in the most likely diagnosis (48.0%) and possible diagnoses (66.7%) compared to GPT-3.5 and GPT-4. Diagnostic capability scoring also indicated higher performance for MAC.\nConclusion And Relevance\n Despite the comprehensive knowledge base of GPT-3.5 and GPT-4, a noticeable gap exists in their clinical application for diagnosing rare diseases, underscoring the limitations in the current training and benchmarking methods of LLMs within the healthcare sector. Compared with single-agent models, the MAC framework markedly improves the diagnostic ability of LLMs, enabling more in-depth analysis. Therefore, the MAC framework is a promising tool for the diagnosis of rare diseases in clinical settings and warrants further research to fully explore its potential.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3757148/v1"
    },
    {
        "id": 11671,
        "title": "Exploring infection clinicians' perceptions of bias in Large Language Models (LLMs) like ChatGPT: A deep learning study",
        "authors": "S.V. Praveen, S. Vijaya",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jinf.2023.09.006"
    },
    {
        "id": 11672,
        "title": "Large language models streamline automated machine learning for clinical studies",
        "authors": "Soroosh Tayebi Arasteh, Tianyu Han, Mahshad Lotfinia, Christiane Kuhl, Jakob Nikolas Kather, Daniel Truhn, Sven Nebelung",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "AbstractA knowledge gap persists between machine learning (ML) developers (e.g., data scientists) and practitioners (e.g., clinicians), hampering the full utilization of ML for clinical data analysis. We investigated the potential of the ChatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge this gap and perform ML analyses efficiently. Real-world clinical datasets and study details from large trials across various medical specialties were presented to ChatGPT ADA without specific guidance. ChatGPT ADA autonomously developed state-of-the-art ML models based on the original study’s training data to predict clinical outcomes such as cancer development, cancer progression, disease complications, or biomarkers such as pathogenic gene sequences. Following the re-implementation and optimization of the published models, the head-to-head comparison of the ChatGPT ADA-crafted ML models and their respective manually crafted counterparts revealed no significant differences in traditional performance metrics (p ≥ 0.072). Strikingly, the ChatGPT ADA-crafted ML models often outperformed their counterparts. In conclusion, ChatGPT ADA offers a promising avenue to democratize ML in medicine by simplifying complex data analyses, yet should enhance, not replace, specialized training and resources, to promote broader applications in medical research and practice.",
        "link": "http://dx.doi.org/10.1038/s41467-024-45879-8"
    },
    {
        "id": 11673,
        "title": "Progression of Large Language Models for Clinical Decision Support: An Evaluation for Rare and Frequent Diseases using GPT-3.5, GPT 4 and Naïve Google Search",
        "authors": "Julian Varghese, Sarah Sandmann, Sarah Riepenhausen, Lucas Plagwitz",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nLarge Language Models (LLMs) like ChatGPT have become increasingly prevalent. Even without medical approval, people will use it to seek health advice, much like searching for diagnoses on Google.\nWe performed a systematic analysis of GPT-3·5 and GPT-4 for suggesting diagnosis, examination steps and treatment of newly processed 110 medical case reports from different clinical disciplines. Balanced groups of rare, less frequent and frequent diseases were used as input. For the diagnosis task a naïve Google search was performed as benchmark comparison. Performance was assessed by two independent physicians using a 5-point Likert scale.\nThe results showed superior performance of GPT-4 over GPT-3·5 considering diagnosis and examination and superior performance over Google for diagnosis. With the exception of treatment, better performance on frequent vs rare diseases was evident for all approaches.\nIn conclusion, the LLMs showed growing potential for medical question answering in two successive major releases. However, several weaknesses and challenges necessitate the utilization of quality-controlled and regulated types of AI-models to qualify as medical applications.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3433351/v1"
    },
    {
        "id": 11674,
        "title": "Level Generation Through Large Language Models",
        "authors": "Graham Todd, Sam Earle, Muhammad Umair Nasir, Michael Cerny Green, Julian Togelius",
        "published": "2023-4-12",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3582437.3587211"
    },
    {
        "id": 11675,
        "title": "Bias of AI-generated content: an examination of news produced by large language models",
        "authors": "Xiao Fang, Shangkun Che, Minjia Mao, Hongzhe Zhang, Ming Zhao, Xiaohang Zhao",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "AbstractLarge language models (LLMs) have the potential to transform our lives and work through the content they generate, known as AI-Generated Content (AIGC). To harness this transformation, we need to understand the limitations of LLMs. Here, we investigate the bias of AIGC produced by seven representative LLMs, including ChatGPT and LLaMA. We collect news articles from The New York Times and Reuters, both known for their dedication to provide unbiased news. We then apply each examined LLM to generate news content with headlines of these news articles as prompts, and evaluate the gender and racial biases of the AIGC produced by the LLM by comparing the AIGC and the original news articles. We further analyze the gender bias of each LLM under biased prompts by adding gender-biased messages to prompts constructed from these news headlines. Our study reveals that the AIGC produced by each examined LLM demonstrates substantial gender and racial biases. Moreover, the AIGC generated by each LLM exhibits notable discrimination against females and individuals of the Black race. Among the LLMs, the AIGC generated by ChatGPT demonstrates the lowest level of bias, and ChatGPT is the sole model capable of declining content generation when provided with biased prompts.",
        "link": "http://dx.doi.org/10.1038/s41598-024-55686-2"
    },
    {
        "id": 11676,
        "title": "Temporal Blind Spots in Large Language Models",
        "authors": "Jonas Wallat, Adam Jatowt, Avishek Anand",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3616855.3635818"
    },
    {
        "id": 11677,
        "title": "Jigsaw",
        "authors": "Naman Jain, Skanda Vaidyanath, Arun Iyer, Nagarajan Natarajan, Suresh Parthasarathy, Sriram Rajamani, Rahul Sharma",
        "published": "2022-5-21",
        "citations": 28,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3510003.3510203"
    },
    {
        "id": 11678,
        "title": "PromptInfuser: Bringing User Interface Mock-ups to Life with Large Language Models",
        "authors": "Savvas Petridis, Michael Terry, Carrie Jun Cai",
        "published": "2023-4-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3544549.3585628"
    },
    {
        "id": 11679,
        "title": "The application of Large Language Models to the phenotype-based prioritization of causative genes in rare disease patients",
        "authors": "Şenay Kafkas, Marwa Abdelhakim, Azza Althagafi, Sumyyah Toonsi, Malak Alghamdi, Paul N. Schofield, Robert Hoehndorf",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractComputational methods for identifying gene–disease associations can use both genomic and phenotypic information to prioritize genes and variants that may be associated with genetic diseases. Phenotype-based methods commonly rely on comparing phenotypes observed in a patient with a database of genotype-to-phenotype associations using a measure of semantic similarity, and are primarily limited by the quality and completeness of this database as well as the quality of phenotypes assigned to a patient. Genotype-to-phenotype associations used by these methods are largely derived from literature and coded using phenotype ontologies. Large Language Models (LLMs) have been trained on large amounts of text and have shown their potential to answer complex questions across multiple domains. Here, we demonstrate that LLMs can prioritize disease-associated genes as well, or better than, dedicated bioinformatics methods relying on calculated phenotype similarity. The LLMs use only natural language information as background knowledge and do not require ontology-based phenotyping or structured genotype-to-phenotype knowledge. We use a cohort of undiagnosed patients with rare diseases and show that LLMs can be used to provide diagnostic support that helps in identifying plausible candidate genes.",
        "link": "http://dx.doi.org/10.1101/2023.11.16.23298615"
    },
    {
        "id": 11680,
        "title": "Getting pwn’d by AI: Penetration Testing with Large Language Models",
        "authors": "Andreas Happe, Jürgen Cito",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3611643.3613083"
    },
    {
        "id": 11681,
        "title": "MSR46 Breaking Through Limitations: Enhanced Systematic Literature Reviews With Large Language Models",
        "authors": "T. Reason, J. Langham, B. Malcolm, S. Klijn, A. Gimblett",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jval.2023.09.2105"
    },
    {
        "id": 11682,
        "title": "Self-Attention and Transformers: Driving the Evolution of Large Language Models",
        "authors": "Qing Luo, Wei Zeng, Manni Chen, Gang Peng, Xiaofeng Yuan, Qiang Yin",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iceict57916.2023.10245906"
    },
    {
        "id": 11683,
        "title": "Exploring Social Biases of Large Language Models in a College Artificial Intelligence Course",
        "authors": "Skylar Kolisko, Carolyn Jane Anderson",
        "published": "2023-6-26",
        "citations": 1,
        "abstract": "Large neural network-based language models play an increasingly important role in contemporary AI. Although these models demonstrate sophisticated text generation capabilities, they have also been shown to reproduce harmful social biases contained in their training data. This paper presents a project that guides students through an exploration of social biases in large language models.\n\nAs a final project for an intermediate college course in Artificial Intelligence, students developed a bias probe task for a previously-unstudied aspect of sociolinguistic or sociocultural bias they were interested in exploring. Through the process of constructing a dataset and evaluation metric to measure bias, students mastered key technical concepts, including how to run contemporary neural networks for natural language processing tasks; construct datasets and evaluation metrics; and analyze experimental results. Students reported their findings in an in-class presentation and a final report, recounting patterns of predictions that surprised, unsettled, and sparked interest in advocating for technology that reflects a more diverse set of backgrounds and experiences.\n\nThrough this project, students engage with and even contribute to a growing body of scholarly work on social biases in large language models.",
        "link": "http://dx.doi.org/10.1609/aaai.v37i13.26879"
    },
    {
        "id": 11684,
        "title": "ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models",
        "authors": "Zhipeng Chen, Kun Zhou, Beichen Zhang, Zheng Gong, Xin Zhao, Ji-Rong Wen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.985"
    },
    {
        "id": 11685,
        "title": "LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion",
        "authors": "Dongfu Jiang, Xiang Ren, Bill Yuchen Lin",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.792"
    },
    {
        "id": 11686,
        "title": "Machine Translation as an Underrated Ingredient? Solving Classification Tasks with Large Language Models for Comparative Research",
        "authors": " Akos Mate,  Miklós Sebők,  Lukasz Wordliczek,  Dariusz Stolicki,  Ádám Feldmann",
        "published": "2023-1-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5117/ccr2023.2.6.mate"
    },
    {
        "id": 11687,
        "title": "Enhancing the quality of teaching and learning through ChatGPT and similar large language models: Challenges, future prospects, and ethical considerations in education",
        "authors": "Nitin Rane",
        "published": "2024-2-20",
        "citations": 0,
        "abstract": "The integration of Artificial Intelligence (AI) into the field of education has ushered in a transformative shift in the creation and dissemination of assignments. This research delves into the implications and complexities surrounding the incorporation of AI-enhanced ChatGPT submission in the realm of education. AI-enhanced ChatGPT submissions offer a multitude of benefits. First and foremost, they offer educators a convenient means to produce a wide array of content, encompassing quizzes, essay prompts, and problem sets, thus saving both time and effort. AI has the capacity to customize assignments according to the specific needs of individual students, ensuring personalized learning experiences. Additionally, AI's ability to analyze student performance data can aid educators in pinpointing areas where students might be facing challenges, allowing them to adapt their teaching methods accordingly. Nonetheless, this innovation also raises substantial concerns. The authenticity and quality of AI-generated submission may come under scrutiny, potentially giving rise to issues of plagiarism and academic integrity. It is crucial to ensure that AI-generated content aligns with educational objectives and standards. Before disseminating AI-generated submission to students, educators must meticulously curate and review them. Furthermore, the role of teachers in the educational process extends beyond merely assigning tasks. They provide mentorship, guidance, and feedback that surpass the capabilities of ChatGPT. This human touch is indispensable for nurturing critical thinking, fostering creativity, and enhancing emotional intelligence. Ethical considerations also play a pivotal role. Both students and educators must comprehend how AI-generated assignments are created, ensuring transparency in the process. Safeguards must be in place to safeguard data privacy, and measures need to be taken to address bias in AI algorithms. Hence, it is imperative for teachers and educational institutions to critically evaluate the place of AI in education and determine the circumstances under which AI-generated assignments can be integrated to enrich the educational landscape.",
        "link": "http://dx.doi.org/10.48185/tts.v5i1.1000"
    },
    {
        "id": 11688,
        "title": "Investigations on Scientific Literature Meta Information Extraction Using Large Language Models",
        "authors": "Menghao Guo, Fan Wu, Jinling Jiang, Xiaoran Yan, Guangyong Chen, Wenhui Li, Yunhong Zhao, Zeyi Sun",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ickg59574.2023.00036"
    },
    {
        "id": 11689,
        "title": "ECHO: An Approach to Enhance Use Case Quality Exploiting Large Language Models",
        "authors": "Gabriele De Vito, Fabio Palomba, Carmine Gravino, Sergio Di Martino, Filomena Ferrucci",
        "published": "2023-9-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/seaa60479.2023.00017"
    },
    {
        "id": 11690,
        "title": "Rule-Augmented Artificial Intelligence-empowered Systems for Medical Diagnosis using Large Language Models",
        "authors": "Dimitrios P. Panagoulias, Filippos A. Palamidas, Maria Virvou, George A. Tsihrintzis",
        "published": "2023-11-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ictai59109.2023.00018"
    },
    {
        "id": 11691,
        "title": "Perils and Opportunities in Using Large Language Models in Psychological Research",
        "authors": "Suhaib Abdurahman, Mohammad Atari, Farzan Karimi-Malekabadi, Mona J. Xue, Jackson Trager, Peter S. Park, Preni Golazizian, Ali Omrani, Morteza Dehghani",
        "published": "No Date",
        "citations": 0,
        "abstract": "The emergence of large language models (LLMs) has sparked considerable interest in their potential application in psychological research, either as a human-like entity used as a model for the human psyche or as a general text-analysis tool. However, carelessly using LLMs in psychological studies, a trend we rhetorically refer to as ``GPTology,'' can have negative consequences, especially given the convenient access to models such as ChatGPT. We elucidate the promises, limitations, and ethical considerations of using LLMs in psychological research. First, LLM-based research should pay attention to the substantial psychological diversity around the globe, as well as demographic diversity within populations. Second, while LLMs are convenient tools, we caution against treating them as a one-size-fits-all method for psychological text analysis. Third, LLM-based psychological research needs to develop methods and standards to compensate for LLMs' opaque black-box nature to facilitate reproducibility, transparency, and robust inference from AI-generated data.While acknowledging the prospects offered by LLMs for easy task automation (e.g., text annotation) and to expand our understanding of human psychology (e.g., by contrasting human and machine psychology), we make a case for diversifying human samples and expanding psychology's methodological toolbox to achieve a truly inclusive and generalizable science, rather than homogenizing samples and methods through over-reliance on LLMs.",
        "link": "http://dx.doi.org/10.31219/osf.io/tg79n"
    },
    {
        "id": 11692,
        "title": "The Epistemological Danger of Large Language Models",
        "authors": "Elise Li Zheng, Sandra Soo-Jin Lee",
        "published": "2023-10-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15265161.2023.2250294"
    },
    {
        "id": 11693,
        "title": "Resilience Assessment of Large Language Models under Transient Hardware Faults",
        "authors": "Udit Kumar Agarwal, Abraham Chan, Karthik Pattabiraman",
        "published": "2023-10-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/issre59848.2023.00052"
    },
    {
        "id": 11694,
        "title": "Overcoming Challenges in Deploying Large Language Models for Generative AI Use Cases: The Role of Containers and Orchestration",
        "authors": "Sriramaraju Sagi",
        "published": "2024-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14445/22312803/ijctt-v72i2p114"
    },
    {
        "id": 11695,
        "title": "Editorial: Evolution of large language models and their role in shaping general artificial intelligence",
        "authors": "YouaKim Badr",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1108/dts-02-2024-088"
    },
    {
        "id": 11696,
        "title": "The Unreasonable Effectiveness of Large Language-Vision Models for Source-free Video Domain Adaptation",
        "authors": "Giacomo Zara, Alessandro Conti, Subhankar Roy, Stéphane Lathuilière, Paolo Rota, Elisa Ricci",
        "published": "2023-10-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00946"
    },
    {
        "id": 11697,
        "title": "Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models",
        "authors": "Toufique Ahmed, Supriyo Ghosh, Chetan Bansal, Thomas Zimmermann, Xuchao Zhang, Saravan Rajmohan",
        "published": "2023-5",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icse48619.2023.00149"
    },
    {
        "id": 11698,
        "title": "Leveraging Large Language Models for Exploiting ASR Uncertainty",
        "authors": "Pranay Dighe, Yi Su, Shangshang Zheng, Yunshu Liu, Vineet Garg, Xiaochuan Niu, Ahmed Tewfik",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446132"
    },
    {
        "id": 11699,
        "title": "Medical education empowered by generative artificial intelligence large language models",
        "authors": "Tanisha Jowsey, Jessica Stokes-Parish, Rachelle Singleton, Michael Todorovic",
        "published": "2023-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.molmed.2023.08.012"
    },
    {
        "id": 11700,
        "title": "Bootstrapping Multilingual Semantic Parsers using Large Language Models",
        "authors": "Abhijeet Awasthi, Nitish Gupta, Bidisha Samanta, Shachi Dave, Sunita Sarawagi, Partha Talukdar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.eacl-main.180"
    },
    {
        "id": 11701,
        "title": "Bootstrapping Multilingual Semantic Parsers using Large Language Models",
        "authors": "Abhijeet Awasthi, Nitish Gupta, Bidisha Samanta, Shachi Dave, Sunita Sarawagi, Partha Talukdar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.eacl-main.180"
    },
    {
        "id": 11702,
        "title": "Speaker Role Identification in Call Centre Dialogues: Leveraging Opening Sentences and Large Language Models",
        "authors": "Minh-Quoc Nghiem, Nichola Roberts, Dmitry Sityaev",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.sigdial-1.35"
    },
    {
        "id": 11703,
        "title": "Leveraging Large Language Models for Improved Patient Access and Self-Management in Oral Healthcare: A Preclinical Study (Preprint)",
        "authors": "Xiaolei Lv, Xiaomeng Zhang, Yuan Li, Xinxin Ding, Hongchang Lai, Junyu Shi",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nWhile Large Language Models like ChatGPT and Google Bard have shown significant promise in various fields, their broader impact on enhancing patient healthcare access and quality, particularly in specialized domains like oral health, requires comprehensive evaluation.\n\n\nOBJECTIVE\nThis study aims to assess the effectiveness of Google Bard, ChatGPT-3.5, and ChatGPT-4 in offering recommendations for common oral health issues, benchmarked against responses from human dental experts.\n\n\nMETHODS\nThis comparative analysis utilized forty questions derived from patient surveys on prevalent oral diseases, executed in a simulated clinical environment. Responses were sourced from both human experts and Large Language Models, evaluating them on readability, appropriateness, harmlessness, comprehensiveness, intent capture, and helpfulness, as evaluated by experienced dentists and lay users, respectively. Additionally, the stability of AI responses was also assessed by submitting each question three times under consistent conditions.\n\n\nRESULTS\nGoogle Bard exhibited the best readability among all groups but scored significantly lower in appropriateness compared to human experts (8.51 ± 0.37 VS. 9.60 ± 0.33, P = .034), while ChatGPT-3.5 and 4 performed comparably with human experts in appropriateness (8.96 ± 0.35 and 9.34 ± 0.47, respectively). All three Large Language Models received superior harmlessness score, comparable to human experts. Lay users found no significant difference in helpfulness and intent capture between Large Language Models and human experts. Stability evaluation revealed ChatGPT-4 as the most reliable, with the highest number of correct responses and the least number of incorrect and unreliable responses.\n\n\nCONCLUSIONS\nLarge Language Models, particularly ChatGPT-4, show potential in oral healthcare, providing patient-centric information for enhancing patient education and clinical care. The observed performance variations underscore the need for ongoing refinement and ethical considerations in healthcare settings. Future research focus on developing strategies for safe integration of Large Language Models in healthcare settings.\n\n\nCLINICALTRIAL\nNA\n",
        "link": "http://dx.doi.org/10.2196/preprints.55847"
    },
    {
        "id": 11704,
        "title": "Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models",
        "authors": "Qingyu Tan, Hwee Tou Ng, Lidong Bing",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.828"
    },
    {
        "id": 11705,
        "title": "P21 A Comparative Analysis of Large Language Models (LLM) Utilised in Systematic Literature Review",
        "authors": "H. Rathi, A. Malik, D.C. Behera, G. Kamboj",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jval.2023.09.030"
    },
    {
        "id": 11706,
        "title": "Making Large Language Models More Reliable and Beneficial: Taking ChatGPT as a Case Study",
        "authors": "Abdul Majeed, Seong Oun Hwang",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mc.2023.3327028"
    },
    {
        "id": 11707,
        "title": "Utilizing Large Language Models to Simplify Radiology Reports: a comparative analysis of ChatGPT3.5, ChatGPT4.0, Google Bard, and Microsoft Bing",
        "authors": "Rushabh Doshi, Kanhai Amin, Pavan Khosla, Simar Bajaj, Sophie Chheang, Howard P. Forman",
        "published": "No Date",
        "citations": 9,
        "abstract": "AbstractThis paper investigates the application of Large Language Models (LLMs), specifically OpenAI’s ChatGPT3.5, ChatGPT4.0, Google Bard, and Microsoft Bing, in simplifying radiology reports, thus potentially enhancing patient understanding. We examined 254 anonymized radiology reports from diverse examination types and used three different prompts to guide the LLMs’ simplification processes. The resulting simplified reports were evaluated using four established readability indices. All LLMs significantly simplified the reports, but performance varied based on the prompt used and the specific model. The ChatGPT models performed best when additional context was provided (i.e., specifying user as a patient or requesting simplification at the 7th grade level). Our findings suggest that LLMs can effectively simplify radiology reports, although improvements are needed to ensure accurate clinical representation and optimal readability. These models have the potential to improve patient health literacy, patient-provider communication, and ultimately, health outcomes.",
        "link": "http://dx.doi.org/10.1101/2023.06.04.23290786"
    },
    {
        "id": 11708,
        "title": "Unsupervised Learnings of Protein Large Language Models for Make Benefit Glorious Sector of Biotech",
        "authors": "Albin Hartwig",
        "published": "2023-12",
        "citations": 0,
        "abstract": "Protein language models were nurtured by unlikely parents---corporations. Now that they have come of age, they have been forced to strike out on their own. A common pitfall that biotechnology platforms make is to attempt to solve as many problems, all at once, while in reality solving none. Whether these fledgling protein LLM companies will learn from the mistakes of their industry predecessors remains to be seen.",
        "link": "http://dx.doi.org/10.1145/3637461"
    },
    {
        "id": 11709,
        "title": "Performance of ChatGPT on CMRP: Potential for Assisting Maintenance and Reliability Professionals Using Large Language Models",
        "authors": "Xingheng Liu, Jørn Vatn, Shen Yin, Vinay Maithani",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iecon51785.2023.10311736"
    },
    {
        "id": 11710,
        "title": "Mitigating Factual Inconsistency and Hallucination in Large Language Models",
        "authors": "Muneeswaran I, Advaith Shankar, Varun V, Saisubramaniam Gopalakrishnan, Vishal Vaddina",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3616855.3635744"
    },
    {
        "id": 11711,
        "title": "Exploring Large Language Models for Low-Resource IT Information Extraction",
        "authors": "Bhavya Bhavya, Paulina Toro Isaza, Yu Deng, Michael Nidd, Amar Prakash Azad, Larisa Shwartz, ChengXiang Zhai",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdmw60847.2023.00157"
    },
    {
        "id": 11712,
        "title": "Leveraging Large Language Models for Generating Responses to Patient Messages",
        "authors": "Siru Liu, Allison B. McCoy, Aileen P. Wright, Babatunde Carew, Julian Z. Genkins, Sean S. Huang, Josh F. Peterson, Bryan Steitz, Adam Wright",
        "published": "No Date",
        "citations": 6,
        "abstract": "ABSTRACTObjectiveThis study aimed to develop and assess the performance of fine-tuned large language models for generating responses to patient messages sent via an electronic health record patient portal.MethodsUtilizing a dataset of messages and responses extracted from the patient portal at a large academic medical center, we developed a model (CLAIR-Short) based on a pre-trained large language model (LLaMA-65B). In addition, we used the OpenAI API to update physician responses from an open-source dataset into a format with informative paragraphs that offered patient education while emphasizing empathy and professionalism. By combining with this dataset, we further fine-tuned our model (CLAIR-Long). To evaluate the fine-tuned models, we used ten representative patient portal questions in primary care to generate responses. We asked primary care physicians to review generated responses from our models and ChatGPT and rated them for empathy, responsiveness, accuracy, and usefulness.ResultsThe dataset consisted of a total of 499,794 pairs of patient messages and corresponding responses from the patient portal, with 5,000 patient messages and ChatGPT-updated responses from an online platform. Four primary care physicians participated in the survey. CLAIR-Short exhibited the ability to generate concise responses similar to provider’s responses. CLAIR-Long responses provided increased patient educational content compared to CLAIR-Short and were rated similarly to ChatGPT’s responses, receiving positive evaluations for responsiveness, empathy, and accuracy, while receiving a neutral rating for usefulness.ConclusionLeveraging large language models to generate responses to patient messages demonstrates significant potential in facilitating communication between patients and primary care providers.",
        "link": "http://dx.doi.org/10.1101/2023.07.14.23292669"
    },
    {
        "id": 11713,
        "title": "A systematic evaluation of large language models of code",
        "authors": "Frank F. Xu, Uri Alon, Graham Neubig, Vincent Josua Hellendoorn",
        "published": "2022-6-13",
        "citations": 65,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3520312.3534862"
    },
    {
        "id": 11714,
        "title": "When Language Models Fall in Love: Animacy Processing in Transformer Language Models",
        "authors": "Michael Hanna, Yonatan Belinkov, Sandro Pezzelle",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.744"
    },
    {
        "id": 11715,
        "title": "Uncertainty Quantification with Pre-trained Language Models: A Large-Scale Empirical Analysis",
        "authors": "Yuxin Xiao, Paul Pu Liang, Umang Bhatt, Willie Neiswanger, Ruslan Salakhutdinov, Louis-Philippe Morency",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-emnlp.538"
    },
    {
        "id": 11716,
        "title": "Large language models for qualitative research in software engineering: exploring opportunities and challenges",
        "authors": "Muneera Bano, Rashina Hoda, Didar Zowghi, Christoph Treude",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10515-023-00407-8"
    },
    {
        "id": 11717,
        "title": "GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models",
        "authors": "Archiki Prasad, Peter Hase, Xiang Zhou, Mohit Bansal",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.eacl-main.277"
    },
    {
        "id": 11718,
        "title": "Zero-shot Bilingual App Reviews Mining with Large Language Models",
        "authors": "Jialiang Wei, Anne-Lise Courbis, Thomas Lambolais, Binbin Xu, Pierre Louis Bernard, Gérard Dray",
        "published": "2023-11-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ictai59109.2023.00135"
    },
    {
        "id": 11719,
        "title": "Applying Large Language Models in Teaching Business English Writing: A Case Study of Business Proposal Writing",
        "authors": "Xiaofang Tang, Xianju Yang",
        "published": "2024",
        "citations": 0,
        "abstract": "With the maturing of artificial intelligence technology, the human-machine collaborative teaching model is gradually attracting attention. Exploration of the path and effectiveness of integrating Large Language Models (LLMs) into business writing teaching is urgently needed. This study takes the use of ERNIE Bot in teaching business proposal writing as an example, collecting and analyzing qualitative and quantitative data, and discussing the methods, effects and challenges of applying LLMs in teaching business English writing in universities in China. The results show that students using ERNIE Bot as an auxiliary tool demonstrate higher participation and enthusiasm in the proposal writing process, and their writing texts have significantly improved in terms of structural clarity and language accuracy. However, it has also been found that ERNIE Bot tends to recommend conventional expressions and structures, which to a certain extent limit students’ personalized expressions. Therefore, the leading role of the instructor should not be neglected.",
        "link": "http://dx.doi.org/10.1051/shsconf/202418101052"
    },
    {
        "id": 11720,
        "title": "Authors’ Reply to: Variability in Large Language Models’ Responses to Medical Licensing and Certification Examinations (Preprint)",
        "authors": "Aidan Gilson, Conrad W Safranek, Thomas Huang, Vimig Socrates, Ling Chi, Richard Andrew Taylor, David Chartash",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\n \n",
        "link": "http://dx.doi.org/10.2196/preprints.50336"
    },
    {
        "id": 11721,
        "title": "Man vs the machine in the struggle for effective text anonymisation in the age of large language models",
        "authors": "Constantinos Patsakis, Nikolaos Lykousas",
        "published": "2023-9-25",
        "citations": 2,
        "abstract": "AbstractThe collection and use of personal data are becoming more common in today’s data-driven culture. While there are many advantages to this, including better decision-making and service delivery, it also poses significant ethical issues around confidentiality and privacy. Text anonymisation tries to prune and/or mask identifiable information from a text while keeping the remaining content intact to alleviate privacy concerns. Text anonymisation is especially important in industries like healthcare, law, as well as research, where sensitive and personal information is collected, processed, and exchanged under high legal and ethical standards. Although text anonymisation is widely adopted in practice, it continues to face considerable challenges. The most significant challenge is striking a balance between removing information to protect individuals’ privacy while maintaining the text’s usability for future purposes. The question is whether these anonymisation methods sufficiently reduce the risk of re-identification, in which an individual can be identified based on the remaining information in the text. In this work, we challenge the effectiveness of these methods and how we perceive identifiers. We assess the efficacy of these methods against the elephant in the room, the use of AI over big data. While most of the research is focused on identifying and removing personal information, there is limited discussion on whether the remaining information is sufficient to deanonymise individuals and, more precisely, who can do it. To this end, we conduct an experiment using GPT over anonymised texts of famous people to determine whether such trained networks can deanonymise them. The latter allows us to revise these methods and introduce a novel methodology that employs Large Language Models to improve the anonymity of texts.",
        "link": "http://dx.doi.org/10.1038/s41598-023-42977-3"
    },
    {
        "id": 11722,
        "title": "Assessing the diagnostic performance of large language models with European Diploma in Musculoskeletal Radiology (EDiMSK) examination sample questions",
        "authors": "Yasin Celal Gunes, Turay Cesur",
        "published": "2024-2-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11604-024-01548-w"
    },
    {
        "id": 11723,
        "title": "ACIGS: An automated large-scale crops image generation system based on large visual language multi-modal models",
        "authors": "Bolong Liu, Hao Zhang, Jie Liu, Qiang Wang",
        "published": "2023-9-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/secon58729.2023.10287530"
    },
    {
        "id": 11724,
        "title": "Performance of Large Language Models (ChatGPT, Bing Search, and Google Bard) in Solving Case Vignettes in Physiology",
        "authors": "Anup Kumar D Dhanvijay, Mohammed Jaffer Pinjar, Nitin Dhokane, Smita R Sorte, Amita Kumari, Himel Mondal",
        "published": "2023-8-4",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7759/cureus.42972"
    },
    {
        "id": 11725,
        "title": "Meta In-Context Learning: Harnessing Large Language Models for Electrical Data Classification",
        "authors": "Mi Zhou, Fusheng Li, Fan Zhang, Junhao Zheng, Qianli Ma",
        "published": "2023-9-18",
        "citations": 0,
        "abstract": "The evolution of communication technology has driven the demand for intelligent power grids and data analysis in power systems. However, obtaining and annotating electrical data from intelligent terminals is time-consuming and challenging. We propose Meta In-Context Learning (M-ICL), a new approach that harnesses large language models to classify time series electrical data, which largely alleviates the need for annotated data when adapting to new tasks. The proposed M-ICL consists of two stages: meta-training and meta-testing. In meta-training, the model is trained on various tasks that have an adequate amount of training data. The meta-training stage aims to learn the mapping between electrical data and the embedding space of large language models. In the meta-testing stage, the trained model makes predictions on new tasks. By utilizing the in-context learning ability of large language models, M-ICL adapts models to new tasks effectively with only a few annotated instances (e.g., 1–5 training instances per class). Our contributions lie in the new application of large language models to electrical data classification and the introduction of M-ICL to improve the classification performance with the strong in-context learning ability of large language models. Furthermore, we conduct extensive experiments on 13 real-world datasets, and the experimental results show that the proposed M-ICL improves the average accuracy over all datasets by 19.06%, 12.06%, and 6.63% when only one, two, and five training instances for each class are available, respectively. In summary, M-ICL offers a promising solution to the challenges of electrical data classification.",
        "link": "http://dx.doi.org/10.3390/en16186679"
    },
    {
        "id": 11726,
        "title": "Large Language Models in Academic Publishing",
        "authors": "Moses Mwangi Thiga",
        "published": "2024-2-2",
        "citations": 0,
        "abstract": "Large language models continue to find greater utilization in the academic publishing process since their introduction. On one hand they are beneficial in manuscript development, review and editorial tasks through finding and presenting information in an academic and professional manner. On the flip side there are concerns over the accuracy of the content they generate as well as the tendency for some authors to present these outputs in manuscripts without proper attribution leading to plagiarism. This chapter examines their practical uses and challenges, and makes recommendations on how their use can be mainstreamed in academic publishing. The chapter further makes recommendations on areas for their future development through the enhancement of foundational models using data from credible sources such as peer reviewed journals, books, and online sources of credible organizations.",
        "link": "http://dx.doi.org/10.4018/979-8-3693-0487-7.ch009"
    },
    {
        "id": 11727,
        "title": "Assessing the Potential Impact of Large Language Models on Labor Markets and Business Cycles in  China: A Preliminary Study",
        "authors": "Ningbo Liu",
        "published": "2023-4-24",
        "citations": 1,
        "abstract": "Large language models (LLMs) are increasingly being used in various fields, including labor markets and business cycles. In this paper, we examine the impact potential of LLMs in labor markets and business cycles in China through a qualitative case study. We first provide background information on LLMs and labor markets and business cycles in China, and then review the relevant literature. Next, we describe the methodology of our study, including the data collection process and data analysis techniques. We present the findings of our case study and identify themes and patterns related to the impact potential of LLMs. We then discuss the implications of our findings for the use of LLMs in labor markets and business cycles in China, compare our findings to the literature review, and offer suggestions for future research. Our study contributes to the growing body of literature on LLMs and their impact potential in various fields and provides insights into the potential use of LLMs in labor markets and business cycles in China.",
        "link": "http://dx.doi.org/10.9734/sajsse/2023/v18i4661"
    },
    {
        "id": 11728,
        "title": "An Empirical Categorization of Prompting Techniques for Large Language Models: A Practitioner’s Guide",
        "authors": "Oluwole Fagbohun, Rachel M. Harrison, Anton Dereventsov",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.51219/jaimld/oluwole-fagbohun/15"
    },
    {
        "id": 11729,
        "title": "ESR Journals editors’ joint statement on Guidelines for the Use of Large Language Models by Authors, Reviewers, and Editors",
        "authors": "Bernd Hamm, Luis Marti-Bonmati, Francesco Sardanelli",
        "published": "2024-1-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s13244-023-01600-9"
    },
    {
        "id": 11730,
        "title": "Marketing Education Renaissance Through Big Data Curriculum: Developing Marketing Expertise Using AI Large Language Models",
        "authors": "Suresh Sood, Hugh Pattinson",
        "published": "2023-2",
        "citations": 1,
        "abstract": "Utilising big data sources and artificial intelligence (AI) tools with marketing activities and analysis contrast with questionnaires and small n observations, essentially creating a renaissance in marketing education. As a result, marketing education keeps pace with AI developments and ensures learners (or students) prepare for the demands of the modern marketing landscape 2025-30. The authors advocate a central focus on a big data-driven marketing curriculum for marketing education. Such a curriculum places AI and machine learning center stage to help understand, analyze and utilize large and complex marketing datasets for predictive marketing. In doing so, the potential exists for practitioners to link marketing strategy directly with marketing execution, allowing learners to use big data and AI for upstream strategy design and marketing plan development while downstream predicting the results of marketing campaigns, programs, and initiatives  But necessary changes in pedagogy are creating adaptive learning experiences breaking free from traditional assessments  In our model of learning educators enable the development of practical marketing expertise using the techniques and tools of micro-testing to nudge learners using Python data science notebooks. Overall, a renaissance in marketing education is made possible with a focus on a big data AI tools-driven curriculum. Such attention ensures learners prepare for the demands of the modern marketing landscape, moving well beyond marketing analytics using the AI technologies of Large Language Models, further expanding the use of big data  Learners use role play, witnessing firsthand experiences fulfilling new hitherto emerging marketing roles  By 2025, Educators fostering a big data AI-focused marketing education curriculum ensure the next generation of AI marketers will eagerly shape the future of marketing practice and behavior with new roles combining human work with AI.",
        "link": "http://dx.doi.org/10.18775/ijied.1849-7551-7020.2015.86.2003"
    },
    {
        "id": 11731,
        "title": "Evaluating the Clinical Decision-Making Ability of Large Language Models Using MKSAP-19 Cardiology Questions",
        "authors": "Paul C. Lee, Samin K. Sharma, Shreya Motaganahalli, Andy Huang",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jacadv.2023.100658"
    },
    {
        "id": 11732,
        "title": "Traditional Chinese Medicine Prescription Recommendation Model Based on Large Language Models and Graph Neural Networks",
        "authors": "JuanZhi Qi, XinYu Wang, Tao Yang",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bibm58861.2023.10385489"
    },
    {
        "id": 11733,
        "title": "Evaluating and Mitigating Limitations of Large Language Models in Clinical Decision Making",
        "authors": "Paul Hager, Friederike Jungmann, Kunal Bhagat, Inga Hubrecht, Manuel Knauer, Jakob Vielhauer, Robbie Holland, Rickmer Braren, Marcus Makowski, Georgios Kaisis, Daniel Rueckert",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractClinical decision making is one of the most impactful parts of a physician’s responsibilities and stands to benefit greatly from AI solutions and large language models (LLMs) in particular. However, while LLMs have achieved excellent performance on medical licensing exams, these tests fail to assess many skills that are necessary for deployment in a realistic clinical decision making environment, including gathering information, adhering to established guidelines, and integrating into clinical workflows. To understand how useful LLMs are in real-world settings, we must evaluate themin the wild, i.e. on real-world data under realistic conditions. Here we have created a curated dataset based on the MIMIC-IV database spanning 2400 real patient cases and four common abdominal pathologies as well as a framework to simulate a realistic clinical setting. We show that current state-of-the-art LLMs do not accurately diagnose patients across all pathologies (performing significantly worse than physicians on average), follow neither diagnostic nor treatment guidelines, and cannot interpret laboratory results, thus posing a serious risk to the health of patients. Furthermore, we move beyond diagnostic accuracy and demonstrate that they cannot be easily integrated into existing workflows because they often fail to follow instructions and are sensitive to both the quantity and order of information. Overall, our analysis reveals that LLMs are currently not ready for clinical deployment while providing a dataset and framework to guide future studies.",
        "link": "http://dx.doi.org/10.1101/2024.01.26.24301810"
    },
    {
        "id": 11734,
        "title": "Practical Application of AI and Large Language Models in Software Engineering Education",
        "authors": "Vasil Kozov, Galina Ivanova, Desislava Atanasova",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14569/ijacsa.2024.0150168"
    },
    {
        "id": 11735,
        "title": "Evaluating Large Language Models on Medical Evidence Summarization",
        "authors": "Liyan Tang, Zhaoyi Sun, Betina Idnay, Jordan G Nestor, Ali Soroush, Pierre A. Elias, Ziyang Xu, Ying Ding, Greg Durrett, Justin Rousseau, Chunhua Weng, Yifan Peng",
        "published": "No Date",
        "citations": 5,
        "abstract": "AbstractRecent advances in large language models (LLMs) have demonstrated remarkable successes in zero- and few-shot performance on various downstream tasks, paving the way for applications in high-stakes domains. In this study, we systematically examine the capabilities and limitations of LLMs, specifically GPT-3.5 and ChatGPT, in performing zero-shot medical evidence summarization across six clinical domains. We conduct both automatic and human evaluations, covering several dimensions of summary quality. Our study has demonstrated that automatic metrics often do not strongly correlate with the quality of summaries. Furthermore, informed by our human evaluations, we define a terminology of error types for medical evidence summarization. Our findings reveal that LLMs could be susceptible to generating factually inconsistent summaries and making overly convincing or uncertain statements, leading to potential harm due to misinformation. Moreover, we find that models struggle to identify the salient information and are more error-prone when summarizing over longer textual contexts.",
        "link": "http://dx.doi.org/10.1101/2023.04.22.23288967"
    },
    {
        "id": 11736,
        "title": "Large language models for oncological applications",
        "authors": "Vera Sorin, Yiftach Barash, Eli Konen, Eyal Klang",
        "published": "2023-9",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00432-023-04824-w"
    },
    {
        "id": 11737,
        "title": "Symbols and grounding in large language models",
        "authors": "Ellie Pavlick",
        "published": "2023-7-24",
        "citations": 11,
        "abstract": "Large language models (LLMs) are one of the most impressive achievements of artificial intelligence in recent years. However, their relevance to the study of language more broadly remains unclear. This article considers the potential of LLMs to serve as models of language understanding in humans. While debate on this question typically centres around models’ performance on challenging language understanding tasks, this article argues that the answer depends on models’ underlying competence, and thus that the focus of the debate should be on empirical work which seeks to characterize the representations and processing algorithms that underlie model behaviour. From this perspective, the article offers counterarguments to two commonly cited reasons why LLMs cannot serve as plausible models of language in humans: their lack of symbolic structure and their lack of grounding. For each, a case is made that recent empirical trends undermine the common assumptions about LLMs, and thus that it is premature to draw conclusions about LLMs’ ability (or lack thereof) to offer insights on human language representation and understanding.This article is part of a discussion meeting issue ‘Cognitive artificial intelligence’.",
        "link": "http://dx.doi.org/10.1098/rsta.2022.0041"
    },
    {
        "id": 11738,
        "title": "Evaluating Open-Domain Question Answering in the Era of Large Language Models",
        "authors": "Ehsan Kamalloo, Nouha Dziri, Charles Clarke, Davood Rafiei",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.307"
    },
    {
        "id": 11739,
        "title": "Contextual Biasing of Named-Entities with Large Language Models",
        "authors": "Chuanneng Sun, Zeeshan Ahmed, Yingyi Ma, Zhe Liu, Lucas Kabela, Yutong Pang, Ozlem Kalinli",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10445918"
    },
    {
        "id": 11740,
        "title": "Unsupervised Human Activity Recognition Via Large Language Models and Iterative Evolution",
        "authors": "Jiayuan Gao, Yingwei Zhang, Yiqiang Chen, Tengxiang Zhang, Boshi Tang, Xiaoyu Wang",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446819"
    },
    {
        "id": 11741,
        "title": "Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting",
        "authors": "Preethi Lahoti, Nicholas Blumm, Xiao Ma, Raghavendra Kotikalapudi, Sahitya Potluri, Qijun Tan, Hansa Srinivasan, Ben Packer, Ahmad Beirami, Alex Beutel, Jilin Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.643"
    },
    {
        "id": 11742,
        "title": "More than anything: Advocating for synthetic architectures within large-scale language-image models",
        "authors": "Daniel Koehler",
        "published": "2023-6",
        "citations": 0,
        "abstract": " Large-scale language-image (LLI) models have the potential to open new forms of critical practice through architectural research. Their success enables designers to research within discourses that are profoundly connected to the built environment but did not previously have the resources to engage in spatial research. Although LLI models do not generate coherent building ensembles, they offer an esthetic experience of an AI infused design practice. This paper contextualizes diffusion models architecturally. Through a comparison of approaches to diffusion models in architecture, this paper outlines data-centric methods that allow architects to design critically using computation. The design of text-driven latent spaces extends the histories of typological design to synthetic environments including non-building data into an architectural space. More than synthesizing quantic ratios in various arrangements, the architect contributes by assessing new categorical differences into generated work. The architects’ creativity can elevate LLI models with a synthetic architecture, nonexistent in the data sets the models learned from. ",
        "link": "http://dx.doi.org/10.1177/14780771231170455"
    },
    {
        "id": 11743,
        "title": "Disparities in seizure outcomes revealed by large language models",
        "authors": "Kevin Xie, William K.S. Ojemann, Ryan S. Gallagher, Alfredo Lucas, Chloé E. Hill, Roy H. Hamilton, Kevin B. Johnson, Dan Roth, Brian Litt, Colin A. Ellis",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractObjectiveLarge-language models (LLMs) in healthcare have the potential to propagate existing biases or introduce new ones. For people with epilepsy, social determinants of health are associated with disparities in access to care, but their impact on seizure outcomes among those with access to specialty care remains unclear. Here we (1) evaluated our validated, epilepsy-specific LLM for intrinsic bias, and (2) used LLM-extracted seizure outcomes to test the hypothesis that different demographic groups have different seizure outcomes.MethodsFirst, we tested our LLM for intrinsic bias in the form of differential performance in demographic groups by race, ethnicity, sex, income, and health insurance in manually annotated notes. Next, we used LLM-classified seizure freedom at each office visit to test for outcome disparities in the same demographic groups, using univariable and multivariable analyses.ResultsWe analyzed 84,675 clinic visits from 25,612 patients seen at our epilepsy center 2005-2022. We found no differences in the accuracy, or positive or negative class balance of outcome classifications across demographic groups. Multivariable analysis indicated worse seizure outcomes for female patients (OR 1.33, p = 3x10-8), those with public insurance (OR 1.53, p = 2x10-13), and those from lower-income zip codes (OR ≥ 1.22, p ≤ 6.6x10-3). Black patients had worse outcomes than White patients in univariable but not multivariable analysis (OR 1.03, p = 0.66).SignificanceWe found no evidence that our LLM was intrinsically biased against any demographic group. Seizure freedom extracted by LLM revealed disparities in seizure outcomes across several demographic groups. These findings highlight the critical need to reduce disparities in the care of people with epilepsy.Key PointsWe used large language models (LLMs) and natural language processing to extract seizure outcomes from clinical note text.We found no evidence of intrinsic bias in the LLM algorithm, in that it performed similarly across all demographic groups.Using LLM-extracted seizure outcomes, female sex, public insurance, and lower income zip- codes were associated with higher likelihood of seizures at each visit.Black race was associated with higher likelihood of seizures in univariable but not multivariable analysis.These findings highlight the critical need to reduce disparities in the care of people with epilepsy.",
        "link": "http://dx.doi.org/10.1101/2023.09.20.23295842"
    },
    {
        "id": 11744,
        "title": "Utilizing Large Language Models for the Generation of Aspect-Based Sentiment Analysis Datasets",
        "authors": "Kai Qiao, Guangmin Li, Xin Zeng, Weichang Li",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icbaie59714.2023.10281255"
    },
    {
        "id": 11745,
        "title": "Author Correction: Large language models and agricultural extension services",
        "authors": "A. Tzachor, M. Devare, C. Richards, P. Pypers, A. Ghosh, J. Koo, S. Johal, B. King",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s43016-023-00904-9"
    },
    {
        "id": 11746,
        "title": "Editorial for Special Issue on Pre-trained Large Language Models for Information Processing",
        "authors": "Bin Wang, Tatsuya Kawahara, Haizhou Li, Helen Meng, Chung-Hsien Wu",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1561/116.00004100"
    },
    {
        "id": 11747,
        "title": "Large Language Models, Agency, and Why Speech Acts are Beyond Them (For Now) – A Kantian-Cum-Pragmatist Case",
        "authors": "Reto Gubelmann",
        "published": "2024-3",
        "citations": 0,
        "abstract": "AbstractThis article sets in with the question whether current or foreseeable transformer-based large language models (LLMs), such as the ones powering OpenAI’s ChatGPT, could be language users in a way comparable to humans. It answers the question negatively, presenting the following argument. Apart from niche uses, to use language means to act. But LLMs are unable to act because they lack intentions. This, in turn, is because they are the wrong kind of being: agents with intentions need to be autonomous organisms while LLMs are heteronomous mechanisms. To conclude, the article argues, based on structural aspects of transformer-based LLMs, that these LLMs have taken a first step away from mechanistic artificiality to autonomous self-constitution, which means that these models are (slowly) moving into a direction that someday might result in non-human, but equally non-artificial agents, thus subverting the time-honored Kantian distinction between organism and mechanism.",
        "link": "http://dx.doi.org/10.1007/s13347-024-00696-1"
    },
    {
        "id": 11748,
        "title": "Transforming clinical trials: the emerging roles of large language models",
        "authors": "Jong-Lyul Ghim, Sangzin Ahn",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.12793/tcp.2023.31.e16"
    },
    {
        "id": 11749,
        "title": "Sentiment Analysis of the United States Public Support of Nuclear Power on Social Media Using Large Language Models",
        "authors": "O. Hwang Kwon, Katie Vu, Naman Bhargava, Mohammed  I. Radaideh, Jacob Cooper, Veda Joynt, Majdi  I. Radaideh",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4763795"
    },
    {
        "id": 11750,
        "title": "Toward Clinical-Grade Evaluation of Large Language Models",
        "authors": "Amy C. Moreno, Danielle S. Bitterman",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ijrobp.2023.11.012"
    },
    {
        "id": 11751,
        "title": "Precision Health in the Age of Large Language Models",
        "authors": "Hoifung Poon, Tristan Naumann, Sheng Zhang, Javier González Hernández",
        "published": "2023-8-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3580305.3599568"
    },
    {
        "id": 11752,
        "title": "Response to M. Trengove &amp; coll regarding “Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine”",
        "authors": "Stefan Harrer",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ebiom.2023.104672"
    },
    {
        "id": 11753,
        "title": "Jailbreaker in Jail: Moving Target Defense for Large Language Models",
        "authors": "Bocheng Chen, Advait Paliwal, Qiben Yan",
        "published": "2023-11-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3605760.3623764"
    },
    {
        "id": 11754,
        "title": "Large language models for post-operative guidance in refractive surgery",
        "authors": "Mouayad Masalkhi, Joshua Ong, Ethan Waisberg, Nasif Zaman, Prithul Sarker, Andrew G. Lee, Alireza Tavakkoli",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21037/asj-23-47"
    },
    {
        "id": 11755,
        "title": "Multiple Representation Transfer from Large Language Models to End-to-End ASR Systems",
        "authors": "Takuma Udagawa, Masayuki Suzuki, Gakuto Kurata, Masayasu Muraoka, George Saon",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10448022"
    },
    {
        "id": 11756,
        "title": "End-to-End Speech Recognition Contextualization with Large Language Models",
        "authors": "Egor Lakomkin, Chunyang Wu, Yassir Fathullah, Ozlem Kalinli, Michael L. Seltzer, Christian Fuegen",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446898"
    },
    {
        "id": 11757,
        "title": "Large language models should be used as scientific reasoning engines, not knowledge databases",
        "authors": "Daniel Truhn, Jorge S. Reis-Filho, Jakob Nikolas Kather",
        "published": "2023-12",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41591-023-02594-z"
    },
    {
        "id": 11758,
        "title": "Dual Process Theory for Large Language Models: An overview of using Psychology to address hallucination and reliability issues",
        "authors": "Samuel C Bellini-Leite",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": " State-of-the-art Large Language Models have recently exhibited extraordinary linguistic abilities which have surprisingly extended to reasoning. However, responses that are unreliable, false, or invented are still a frequent issue. It has been argued that scaling up strategies, as in increasing model size or hardware power, might not be enough to resolve the issue. Recent research has implemented Type 2 strategies (such as Chain-of-Thought and Tree-of-Thought), as strategies that mimic Type 2 reasoning, from Dual Process Theory, to interact with Large Language Models for improved results. The current paper reviews these strategies in light of the Predicting and Reflecting Framework for understanding Dual Process Theory and suggests what Psychology, drawing from research in executive functions, thinking disposition and creativity, can further contribute to possible implementations that address hallucination and reliability issues. ",
        "link": "http://dx.doi.org/10.1177/10597123231206604"
    },
    {
        "id": 11759,
        "title": "Humor@IITK at SemEval-2021 Task 7: Large Language Models for Quantifying Humor and Offensiveness",
        "authors": "Aishwarya Gupta, Avik Pal, Bholeshwar Khurana, Lakshay Tyagi, Ashutosh Modi",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.semeval-1.36"
    },
    {
        "id": 11760,
        "title": "Assessing the efficacy of large language models in generating accurate teacher responses",
        "authors": "Yann Hicke, Abhishek Masand, Wentao Guo, Tushaar Gangavarapu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bea-1.60"
    },
    {
        "id": 11761,
        "title": "How Should College Education Respond to Large Language Models?",
        "authors": "Charles La Shure,  ",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "The release of ChatGPT to the public at the end of last year had many in the field of education worried. In response, this paper explored the future of college education and artificial intelligence (AI). First, a proper understanding of how large language models (LLMs) “train” and “learn,” along with their abilities and limitations, was established. Simply put, while LLMs produce plausible linguistic output, they are “stochastic parrots” that have no actual understanding of language.\r\nNext, we examined the dangers of generative AI and discovered that they might help in the creation and dissemination of misinformation. Even if these AI are not used with malicious intent, the fact that their training data sets are drawn from the internet—which reflects majority thinking—means that they can perpetuate and amplify social inequality and hegemonic stereotypes and biases. On the other hand, if we consider what is missing from the training data, it is only natural that marginalized voices should be even more marginalized. In addition, leaving the issue of the socially vulnerable aside, LLMs can only be trained on digital data, meaning analog data is ignored. This is in line with the idea of “the destruction of history” put forth by Joseph Weizenbaum, an early critic who warned of the dangers of artificial intelligence.\r\nWe then discussed the relationship between humans and machines and considered which relationships were problematic and which were desirable. Researchers in the aviation industry recognized the problem of automation bias from an early date, but this phenomenon can be seen in other areas of society as well. Put simply, if a human places too much trust in a machine, they abdicate their decision-making responsibility to that machine and thus fail to respond quickly to solve any problems that may arise should that machine malfunction. LLMs do not endanger lives in the same way that airplanes do, but a similar bias can be seen with them as well. A more important issue, though, is the fact that people are no longer seen as whole human beings but as computers. This tendency was evident long before the advent of computers, for example in the attempts to quantify human intelligence through IQ tests, but it is a problem we must be particularly wary of in the age of AI.\r\nLastly, we considered means for college education to find its way in the present situation. Educators in the US in particular, while dealing with ChatGPT, have pinpointed not the LLMs themselves but the “transactional nature” of education as the problem. That is, they argue that education has long since become less a process of learning and more a transaction in which students receive grades and degrees. Given this transactional environment, it is no wonder that student would rely too much on ChatGPT. This over-reliance, however, comes with side effects: not learning how to think properly, a lack of sufficient academic information, and learning an AI-based writing style. In response, US educators have proposed both “stick” (strategies that make it difficult for students to use LLMs) and “carrot” (strategies that encourage students to learn like human beings, not algorithms) solutions, but the heart of the matter seems to be a sense of responsibility. Creating an educational environment in which students can develop a sense of responsibility for themselves is the path forward for education in the age of AI. If we do this, LLMs can become a useful tool rather than an enemy to fear.",
        "link": "http://dx.doi.org/10.52723/jkl.48.007"
    },
    {
        "id": 11762,
        "title": "PivotFEC: Enhancing Few-shot Factual Error Correction with a Pivot Task Approach using Large Language Models",
        "authors": "Xingwei He, A-Long Jin, Jun Ma, Yuan Yuan, Siu Yiu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.667"
    },
    {
        "id": 11763,
        "title": "Dynamic Voting for Efficient Reasoning in Large Language Models",
        "authors": "Mingfeng Xue, Dayiheng Liu, Wenqiang Lei, Xingzhang Ren, Baosong Yang, Jun Xie, Yidan Zhang, Dezhong Peng, Jiancheng Lv",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.203"
    },
    {
        "id": 11764,
        "title": "Using large language models to write theses and dissertations",
        "authors": "Daniel E. O'Leary",
        "published": "2023-10",
        "citations": 0,
        "abstract": "SummaryThere has been substantial discussion aimed at investigating the extent to which academic researchers can or should “use” large language models, such as ChatGPT and Bard, in their research papers. However, there seems to have been limited attention given to the extent to which students can use these tools for the development of theses, proposals and dissertations. This paper pushes the arguments from focusing on academic researchers, journal papers, and technical meetings to considering those theses and dissertations, raising several questions and concerns. Ultimately, university policies need to address these issues, but if publisher and editor responses and alternative business uses are a signal of that direction, consensus may be difficult to achieve.",
        "link": "http://dx.doi.org/10.1002/isaf.1547"
    },
    {
        "id": 11765,
        "title": "Framework-based qualitative analysis of free responses of Large Language Models: Algorithmic fidelity",
        "authors": "Aliya Amirova, Theodora Fteropoulli, Nafiso Ahmed, Martin R. Cowie, Joel Z. Leibo",
        "published": "2024-3-12",
        "citations": 0,
        "abstract": "Today, with the advent of Large-scale generative Language Models (LLMs) it is now possible to simulate free responses to interview questions such as those traditionally analyzed using qualitative research methods. Qualitative methodology encompasses a broad family of techniques involving manual analysis of open-ended interviews or conversations conducted freely in natural language. Here we consider whether artificial “silicon participants” generated by LLMs may be productively studied using qualitative analysis methods in such a way as to generate insights that could generalize to real human populations. The key concept in our analysis is algorithmic fidelity, a validity concept capturing the degree to which LLM-generated outputs mirror human sub-populations’ beliefs and attitudes. By definition, high algorithmic fidelity suggests that latent beliefs elicited from LLMs may generalize to real humans, whereas low algorithmic fidelity renders such research invalid. Here we used an LLM to generate interviews with “silicon participants” matching specific demographic characteristics one-for-one with a set of human participants. Using framework-based qualitative analysis, we showed the key themes obtained from both human and silicon participants were strikingly similar. However, when we analyzed the structure and tone of the interviews we found even more striking differences. We also found evidence of a hyper-accuracy distortion. We conclude that the LLM we tested (GPT-3.5) does not have sufficient algorithmic fidelity to expect in silico research on it to generalize to real human populations. However, rapid advances in artificial intelligence raise the possibility that algorithmic fidelity may improve in the future. Thus we stress the need to establish epistemic norms now around how to assess the validity of LLM-based qualitative research, especially concerning the need to ensure the representation of heterogeneous lived experiences.",
        "link": "http://dx.doi.org/10.1371/journal.pone.0300024"
    },
    {
        "id": 11766,
        "title": "The Future of the Error Message: Comparing Large Language Models and Novice Programmer Effectiveness in Fixing Errors",
        "authors": "Brij Howard-Sarin",
        "published": "2024-3-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626253.3635404"
    },
    {
        "id": 11767,
        "title": "Alternating Recurrent Dialog Model with Large-scale Pre-trained Language Models",
        "authors": "Qingyang Wu, Yichi Zhang, Yu Li, Zhou Yu",
        "published": "2021",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.eacl-main.110"
    },
    {
        "id": 11768,
        "title": "Exploring Large Language Models for Trajectory Prediction: A Technical Perspective",
        "authors": "Farzeen Munir, Tsvetomila Mihaylova, Shoaib Azam, Tomasz Piotr Kucner, Ville Kyrki",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3610978.3640625"
    },
    {
        "id": 11769,
        "title": "StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding",
        "authors": "Cheng Jiayang, Lin Qiu, Tsz Chan, Tianqing Fang, Weiqi Wang, Chunkit Chan, Dongyu Ru, Qipeng Guo, Hongming Zhang, Yangqiu Song, Yue Zhang, Zheng Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.706"
    },
    {
        "id": 11770,
        "title": "Too Many Cooks Spoil the Model: Are Bilingual Models for Slovene Better than a Large Multilingual Model?",
        "authors": "Pranaydeep Singh, Aaron Maladry, Els Lefever",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bsnlp-1.5"
    },
    {
        "id": 11771,
        "title": "Synthesizing Sentience: Integrating Large Language Models and Autonomous Agents for Emulating Human Cognitive Complexity",
        "authors": "Jeremiah Ratican, James Hutson, Daniel Plate",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.51219/jaimld/jeremiah-ratican/17"
    },
    {
        "id": 11772,
        "title": "Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance",
        "authors": "Thiemo Wambsganss, Xiaotian Su, Vinitra Swamy, Seyed Neshaei, Roman Rietsche, Tanja Käser",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.689"
    },
    {
        "id": 11773,
        "title": "Can We Use Large Language Models to Guide the Use of Contrast Media in Radiology? Reply to Kaba et al.",
        "authors": "Arosh S. Perera Molligoda Arachchige",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.acra.2023.12.044"
    },
    {
        "id": 11774,
        "title": "Frontiers: Determining the Validity of Large Language Models for Automated Perceptual Analysis",
        "authors": "Peiyao Li, Noah Castelo, Zsolt Katona, Miklos Sarvary",
        "published": "2024-1",
        "citations": 1,
        "abstract": " The paper explores the potential of Large Language Models to substitute for or to augment human participants in market research. ",
        "link": "http://dx.doi.org/10.1287/mksc.2023.0454"
    },
    {
        "id": 11775,
        "title": "Harnessing Large Language Models for Simulink Toolchain Testing and Developing Diverse Open-Source Corpora of Simulink Models for Metric and Evolution Analysis",
        "authors": "Sohil Lal Shrestha",
        "published": "2023-7-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3597926.3605233"
    },
    {
        "id": 11776,
        "title": "Can You Translate for Me? Code-Switched Machine Translation with Large Language Models",
        "authors": "Jyotsana Khatri, Vivek Srivastava, Lovekesh Vig",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.ijcnlp-short.10"
    },
    {
        "id": 11777,
        "title": "deepQuest-py: Large and Distilled Models for Quality Estimation",
        "authors": "Fernando Alva-Manchego, Abiola Obamuyide, Amit Gajbhiye, Frédéric Blain, Marina Fomicheva, Lucia Specia",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-demo.42"
    },
    {
        "id": 11778,
        "title": "Large language models and the retina: a review of current applications and future directions",
        "authors": "Aidan Gilson, Qingyu Chen, Maxwell Singer, Hua Xu, Ron A Adelman",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.37845/ret.vit.2023.32.38"
    },
    {
        "id": 11779,
        "title": "Large Language Models and Medical Knowledge Grounding for Diagnosis Prediction",
        "authors": "Yanjun Gao, Ruizhe Li, Emma Croxford, Samuel Tesch, Daniel To, John Caskey, Brian W. Patterson, Matthew M. Churpek, Timothy Miller, Dmitriy Dligach, Majid Afshar",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractWhile Large Language Models (LLMs) have showcased their potential in diverse language tasks, their application in the healthcare arena needs to ensure the minimization of diagnostic errors and the prevention of patient harm. A Medical Knowledge Graph (KG) houses a wealth of structured medical concept relations sourced from authoritative references, such as UMLS, making it a valuable resource to ground LLMs’ diagnostic process in knowledge. In this paper, we examine the synergistic potential of LLMs and medical KG in predicting diagnoses given electronic health records (EHR), under the framework of Retrieval-augmented generation (RAG). We proposed a novel graph model: Dr.Knows, that selects the most relevant pathology knowledge paths based on the medical problem descriptions. In order to evaluate Dr.Knows, we developed the first comprehensive human evaluation approach to assess the performance of LLMs for diagnosis prediction and examine the rationale behind their decision-making processes, aimed at improving diagnostic safety. Using real-world hospital datasets, our study serves to enrich the discourse on the role of medical KGs in grounding medical knowledge into LLMs, revealing both challenges and opportunities in harnessing external knowledge for explainable diagnostic pathway and the realization of AI-augmented diagnostic decision support systems.",
        "link": "http://dx.doi.org/10.1101/2023.11.24.23298641"
    },
    {
        "id": 11780,
        "title": "Who Says Elephants Can’t Run: Bringing Large Scale MoE Models into Cloud Scale Production",
        "authors": "Young Jin Kim, Rawn Henry, Raffy Fahim, Hany Hassan",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.sustainlp-1.6"
    },
    {
        "id": 11781,
        "title": "Application of Large language Models (LLMs) in Women's Safety",
        "authors": "Santhosh Kumar Rajamani, Radha Srinivasan Iyer",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "Large language models are sophisticated AI systems that process and produce text that resembles that of a human being by learning patterns from enormous volumes of data. These systems make it possible to do jobs like dialogue, translation, and content production. The most popular implementation of LLM is the generated pretrained transformer (GPT) family of LLM. LLMs can assist in women's safety in numerous ways. They can help in distress and prove to be a dependable tool for women in the event of a crisis. LLMs can be employed to create virtual support groups for susceptible women, virtual assistance in times of crisis or need, and enhance the safety of women by suggesting avoidance of certain roads or vicinities for safety concerns. llm apps can function as safety alarms, safety education programmes, generative AIs to create appealing social media postings, blog entries, and videos, and safety-focused wearable technology.",
        "link": "http://dx.doi.org/10.4018/979-8-3693-2679-4.ch006"
    },
    {
        "id": 11782,
        "title": "Large Language Models are Better Reasoners with Self-Verification",
        "authors": "Yixuan Weng, Minjun Zhu, Fei Xia, Bin Li, Shizhu He, Shengping Liu, Bin Sun, Kang Liu, Jun Zhao",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.167"
    },
    {
        "id": 11783,
        "title": "Large Language Models as a Tool for Health Services Researchers: An Exploration of High-Value Applications",
        "authors": "Julian Brunner, Seppo Rinne",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1513/annalsats.202311-980ps"
    },
    {
        "id": 11784,
        "title": "From BERT to GPT-3 codex",
        "authors": "Immanuel Trummer",
        "published": "2022-8",
        "citations": 10,
        "abstract": "Large language models have recently advanced the state of the art on many natural language processing benchmarks. The newest generation of models can be applied to a variety of tasks with little to no specialized training. This technology creates various opportunities for applications in the context of data management.\nThe tutorial will introduce participants to basic background on language models, discuss different methods to use language models, and give an overview and short demonstration of available libraries and APIs. Models for generating natural language will be considered as well as models, such as GPT-3 Codex, which complete program code or generate code from natural language instructions. Finally, the tutorial will discuss recent research in the database community that exploits language models in the context of traditional database systems or proposes novel system architectures that are based on them.\nThe tutorial is targeted at database researchers. No prior background on language models is required. The goal of the tutorial is to introduce database researchers to the latest generation of language models, and to their use cases in the domain of data management.",
        "link": "http://dx.doi.org/10.14778/3554821.3554896"
    },
    {
        "id": 11785,
        "title": "Academic integrity considerations of AI Large Language Models in the post-pandemic era: ChatGPT and beyond",
        "authors": "Mike Perkins,  ",
        "published": "2023-2-22",
        "citations": 81,
        "abstract": "This paper explores the academic integrity considerations of students’ use of Artificial Intelligence (AI) tools using Large Language Models (LLMs) such as ChatGPT in formal assessments. We examine the evolution of these tools, and highlight the potential ways that LLMs can support in the education of students in digital writing and beyond, including the teaching of writing and composition, the possibilities of co-creation between humans and AI, supporting EFL learners, and improving Automated Writing Evaluations (AWE). We describe and demonstrate the potential that these tools have in creating original, coherent text that can avoid detection by existing technological methods of detection and trained academic staff alike, demonstrating a major academic integrity concern related to the use of these tools by students. Analysing the various issues related to academic integrity that LLMs raise for both Higher Education Institutions (HEIs) and students, we conclude that it is not the student use of any AI tools that defines whether plagiarism or a breach of academic integrity has occurred, but whether any use is made clear by the student. Deciding whether any particular use of LLMs by students can be defined as academic misconduct is determined by the academic integrity policies of any given HEI, which must be updated to consider how these tools will be used in future educational environments.",
        "link": "http://dx.doi.org/10.53761/1.20.02.07"
    },
    {
        "id": 11786,
        "title": "Disentangling Transformer Language Models as Superposed Topic Models",
        "authors": "Jia Lim, Hady Lauw",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.534"
    },
    {
        "id": 11787,
        "title": "Prompt text classifications with transformer models! An exemplary introduction to prompt-based learning with large language models",
        "authors": "Christian W. F. Mayer, Sabrina Ludwig, Steffen Brandt",
        "published": "2023-1-3",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15391523.2022.2142872"
    },
    {
        "id": 11788,
        "title": "Post Hoc Explanations of Language Models Can Improve Language Models",
        "authors": "Satyapriya Krishna, Jiaqi Ma, Dylan Slack, Asma Ghandeharioun, Sameer Singh, Himabindu Lakkaraju",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nLarge Language Models (LLMs) have demonstrated remarkable capabilities in performing complex tasks. Moreover, recent research has shown that incorporating human-annotated rationales (e.g., Chain-of-Thought prompting) during in-context learning can significantly enhance the performance of these models, particularly on tasks that require reasoning capabilities. However, incorporating such rationales poses challenges in terms of scalability as this requires a high degree of human involvement. In this work, we present a novel framework, Amplifying Model Performance by Leveraging In-Context Learning with Post Hoc Explanations (AMPLIFY), which addresses the aforementioned challenges by automating the process of rationale generation. To this end, we leverage post hoc explanation methods which output attribution scores (explanations) capturing the influence of each of the input features on model predictions. More specifically, we construct automated natural language rationales that embed insights from post hoc explanations to provide corrective signals to LLMs. Extensive experimentation with real-world datasets demonstrates that our framework, AMPLIFY, leads to prediction accuracy improvements of about 10-25% over a wide range of tasks, including those where prior approaches which rely on human-annotated rationales such as Chain-of-Thought prompting fall short. Our work makes one of the first attempts at highlighting the potential of post hoc explanations as valuable tools for enhancing the effectiveness of LLMs. Furthermore, we conduct additional empirical analyses and ablation studies to demonstrate the impact of each of the components of AMPLIFY, which, in turn, lead to critical insights for refining in-context learning.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3006112/v1"
    },
    {
        "id": 11789,
        "title": "HAQA and QUQA: Constructing two Arabic Question-Answering Corpora for the Quran and Hadith",
        "authors": "Sarah Alnefaie,  , Eric Atwell, Mohammad Ammar Alsalka,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_010"
    },
    {
        "id": 11790,
        "title": "Bigfoot in Big Tech: Detecting Out of Domain Conspiracy Theories",
        "authors": "Matthew Fort,  , Zuoyu Tian, Elizabeth Gabel, Nina Georgiades, Noah Sauer, Daniel Dakota, Sandra Kübler,  ,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_040"
    },
    {
        "id": 11791,
        "title": "Empirical and Theoretical Aspects of Fisheries Yield Models for Large Marine Ecosystems",
        "authors": "Marc Mangel",
        "published": "2019-5-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429042423-11"
    },
    {
        "id": 11792,
        "title": "Publish or Hold? Automatic Comment Moderation in Luxembourgish News Articles",
        "authors": "Tharindu Ranasinghe,  , Alistair Plum, Christoph Purschke, Marcos Zampieri,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_104"
    },
    {
        "id": 11793,
        "title": "Detecting Artificially Generated Academic Text: The Importance of Mimicking Human Utilization of Large Language Models",
        "authors": "Vijini Liyanage, Davide Buscaldi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-35320-8_42"
    },
    {
        "id": 11794,
        "title": "Leveraging Large Language Models for the Generation of Novel Metaheuristic Optimization Algorithms",
        "authors": "Michal Pluhacek, Anezka Kazikova, Tomas Kadavy, Adam Viktorin, Roman Senkerik",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3583133.3596401"
    },
    {
        "id": 11795,
        "title": "Voice-Enabled Response Analysis Agent (VERAA): Leveraging Large Language Models to Map Voice Responses in SDoH Survey",
        "authors": "Rishivardhan Krishnamoorthy, Vishal Nagarajan, Hayden Pour, Supreeth P. Shashikumar, Aaron Boussina, Emilia Farcas, Shamim Nemati, Christopher S. Josef",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractSocial Determinants of Health (SDoH) have been shown to have profound impacts on health-related outcomes, yet this data suffers from high rates of missingness in electronic health records (EHR). Moreover, limited English proficiency in the United States can be a barrier to communication with health care providers. In this study, we have designed a multilingual conversational agent capable of conducting SDoH surveys for use in healthcare environments. The agent asks questions in the patient’s native language, translates responses into English, and subsequently maps these responses via a large language model (LLM) to structured options in a SDoH survey. This tool can be extended to a variety of survey instruments in either hospital or home settings, enabling the extraction of structured insights from free-text answers. The proposed approach heralds a shift towards more inclusive and insightful data collection, marking a significant stride in SDoH data enrichment for optimizing health outcome predictions and interventions.",
        "link": "http://dx.doi.org/10.1101/2023.09.25.23295917"
    },
    {
        "id": 11796,
        "title": "LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models",
        "authors": "Chan Hee Song, Brian M. Sadler, Jiaman Wu, Wei-Lun Chao, Clayton Washington, Yu Su",
        "published": "2023-10-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00280"
    },
    {
        "id": 11797,
        "title": "Preliminary Fatty Liver Disease Grading Using General-Purpose Online Large Language Models: ChatGPT-4 or Bard?",
        "authors": "Yiwen Zhang, Hanyun Liu, Bin Sheng, Yih Chung Tham, Hongwei Ji",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jhep.2023.11.017"
    },
    {
        "id": 11798,
        "title": "Criteria2query 3.0: Leveraging Generative Large Language Models for Clinical Trial Eligibility Query Generation",
        "authors": "Jimyung Park, Yilu Fang, Casey Ta, Gongbo Zhang, Betina Idnay, Fangyi Chen, David Feng, Rebecca Shyu, Emily  R. Gordon, Matthew Spotnitz, Chunhua Weng",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4637800"
    },
    {
        "id": 11799,
        "title": "ChatGPT and Similar Generative Artificial Intelligence (AI) for Building and Construction Industry: Contribution, Opportunities and Challenges of Large Language Models for Industry 4.0, Industry 5.0, and Society 5.0",
        "authors": "Nitin Rane",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4603221"
    },
    {
        "id": 11800,
        "title": "Defining the Role of Large Language Models in Urologic Care and Research",
        "authors": "Raghav Gupta, Adriana M. Pedraza, Michael A. Gorin, Ashutosh K. Tewari",
        "published": "2024-2",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.euo.2023.07.017"
    },
    {
        "id": 11801,
        "title": "Empowering digital twins with large language models for global temporal feature learning",
        "authors": "Yicheng Sun, Qi Zhang, Jinsong Bao, Yuqian Lu, Shimin Liu",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jmsy.2024.02.015"
    },
    {
        "id": 11802,
        "title": "Large Language Models in Health Care: Charting a Path Toward Accurate, Explainable, and Secure AI",
        "authors": "Dhruv Khullar, Xingbo Wang, Fei Wang",
        "published": "2024-2-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11606-024-08657-2"
    },
    {
        "id": 11803,
        "title": "IMPACT OF LARGE LANGUAGE MODELS (LLM) ON THE DETECTION AND INVESTIGATION OF CRIMINAL OFFENSES ON THE EXAMPLE OF CHATGPT",
        "authors": "O.O. Torbas",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32782/2524-0374/2024-1/172"
    },
    {
        "id": 11804,
        "title": "GeneGPT: augmenting large language models with domain tools for improved access to biomedical information",
        "authors": "Qiao Jin, Yifan Yang, Qingyu Chen, Zhiyong Lu",
        "published": "2024-2-1",
        "citations": 2,
        "abstract": "Abstract\n\nMotivation\nWhile large language models (LLMs) have been successfully applied to various tasks, they still face challenges with hallucinations. Augmenting LLMs with domain-specific tools such as database utilities can facilitate easier and more precise access to specialized knowledge. In this article, we present GeneGPT, a novel method for teaching LLMs to use the Web APIs of the National Center for Biotechnology Information (NCBI) for answering genomics questions. Specifically, we prompt Codex to solve the GeneTuring tests with NCBI Web APIs by in-context learning and an augmented decoding algorithm that can detect and execute API calls.\n\n\nResults\nExperimental results show that GeneGPT achieves state-of-the-art performance on eight tasks in the GeneTuring benchmark with an average score of 0.83, largely surpassing retrieval-augmented LLMs such as the new Bing (0.44), biomedical LLMs such as BioMedLM (0.08) and BioGPT (0.04), as well as GPT-3 (0.16) and ChatGPT (0.12). Our further analyses suggest that: First, API demonstrations have good cross-task generalizability and are more useful than documentations for in-context learning; second, GeneGPT can generalize to longer chains of API calls and answer multi-hop questions in GeneHop, a novel dataset introduced in this work; finally, different types of errors are enriched in different tasks, providing valuable insights for future improvements.\n\n\nAvailability and implementation\nThe GeneGPT code and data are publicly available at https://github.com/ncbi/GeneGPT.\n",
        "link": "http://dx.doi.org/10.1093/bioinformatics/btae075"
    },
    {
        "id": 11805,
        "title": "Can Large Language Models Provide Feedback to Students? A Case Study on ChatGPT",
        "authors": "Wei Dai, Jionghao Lin, Hua Jin, Tongguang Li, Yi-Shan Tsai, Dragan Gašević, Guanliang Chen",
        "published": "2023-7",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icalt58122.2023.00100"
    },
    {
        "id": 11806,
        "title": "Biases in Large Language Models: Origins, Inventory, and Discussion",
        "authors": "Roberto Navigli, Simone Conia, Björn Ross",
        "published": "2023-6-30",
        "citations": 14,
        "abstract": "In this article, we introduce and discuss the pervasive issue of bias in the large language models that are currently at the core of mainstream approaches to Natural Language Processing (NLP). We first introduce data selection bias, that is, the bias caused by the choice of texts that make up a training corpus. Then, we survey the different types of social bias evidenced in the text generated by language models trained on such corpora, ranging from gender to age, from sexual orientation to ethnicity, and from religion to culture. We conclude with directions focused on measuring, reducing, and tackling the aforementioned types of bias.",
        "link": "http://dx.doi.org/10.1145/3597307"
    },
    {
        "id": 11807,
        "title": "TidyBot: Personalized Robot Assistance with Large Language Models",
        "authors": "Jimmy Wu, Rika Antonova, Adam Kan, Marion Lepert, Andy Zeng, Shuran Song, Jeannette Bohg, Szymon Rusinkiewicz, Thomas Funkhouser",
        "published": "2023-10-1",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iros55552.2023.10341577"
    },
    {
        "id": 11808,
        "title": "1. Large-Scale Implementation of Dual Language Bilingual Education: A Key Moment in History",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781788928106-002"
    },
    {
        "id": 11809,
        "title": "Measuring Spurious Correlation in Classification: ”Clever Hans” in Translationese",
        "authors": "Angana Borah,  , Daria Pylypenko, Cristina España-Bonet, Josef van Genabith,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_022"
    },
    {
        "id": 11810,
        "title": "Efficient Domain Adaptation of Sentence Embeddings Using Adapters",
        "authors": "Tim Schopf,  , Dennis N. Schneider, Florian Matthes,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_112"
    },
    {
        "id": 11811,
        "title": "AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories",
        "authors": "Max Pellert, Clemens M. Lechner, Claudia Wagner, Beatrice Rammstedt, Markus Strohmaier",
        "published": "2024-1-2",
        "citations": 0,
        "abstract": " We illustrate how standard psychometric inventories originally designed for assessing noncognitive human traits can be repurposed as diagnostic tools to evaluate analogous traits in large language models (LLMs). We start from the assumption that LLMs, inadvertently yet inevitably, acquire psychological traits (metaphorically speaking) from the vast text corpora on which they are trained. Such corpora contain sediments of the personalities, values, beliefs, and biases of the countless human authors of these texts, which LLMs learn through a complex training process. The traits that LLMs acquire in such a way can potentially influence their behavior, that is, their outputs in downstream tasks and applications in which they are employed, which in turn may have real-world consequences for individuals and social groups. By eliciting LLMs’ responses to language-based psychometric inventories, we can bring their traits to light. Psychometric profiling enables researchers to study and compare LLMs in terms of noncognitive characteristics, thereby providing a window into the personalities, values, beliefs, and biases these models exhibit (or mimic). We discuss the history of similar ideas and outline possible psychometric approaches for LLMs. We demonstrate one promising approach, zero-shot classification, for several LLMs and psychometric inventories. We conclude by highlighting open challenges and future avenues of research for AI Psychometrics. ",
        "link": "http://dx.doi.org/10.1177/17456916231214460"
    },
    {
        "id": 11812,
        "title": "Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration",
        "authors": "Yang Deng, Lizi Liao, Liang Chen, Hongru Wang, Wenqiang Lei, Tat-Seng Chua",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.711"
    },
    {
        "id": 11813,
        "title": "Hi-ToM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models",
        "authors": "Yufan Wu, Yinghui He, Yilin Jia, Rada Mihalcea, Yulong Chen, Naihao Deng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.717"
    },
    {
        "id": 11814,
        "title": "Classification of Surgical Patients Needing Preoperative Cardiac Evaluations: A Comparison of General-Purpose and Domain-Specific Large Language Models (Preprint)",
        "authors": "Jeffrey Tully, Onkar Litake, Minhthy Meineke, Sierra Simpson, Ruth Waterman, Rodney Gabriel",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nTools that can help to identify preoperative patients in need of further cardiovascular testing or consultation may be of use in reducing costs and ensuring rational utilization of resources.\n\n\nOBJECTIVE\nWe evaluate the feasibility of utilizing general purpose versus domain-specific large language models (LLM) for a classification task aimed at identifying these surgical patients.\n\n\nMETHODS\nThe objective of this study was to leverage various LLMs to classify patients that would need preoperative cardiac evaluation based on their preoperative clinical notes. General-purpose (BERT, RoBERTa, Longformer) and domain-specific (BioClinicalBERT, PubMedBERT) were used to train on this classification task. Performance was validated on the test set and the area under the receiver operating characteristics curve (AUC), F1-score, sensitivity, specificity, precision, and recall were measured.\n\n\nRESULTS\nThere were 175 patients, in which 67 (38.2%) patients were determined to require preoperative cardiac evaluation/testing. The dataset was divided into a training and test set, which consisted of 75% (n=131) and 25% (n=44) of the dataset. All models performed similarly, in which the AUC was highest with Longformer (0.90) and the Precision-Recall score was highest with PubMedBERT (0.88).\n\n\nCONCLUSIONS\nThis study described the use of three general purpose and two domain-specific LLMs to classify surgical patients in need of preoperative cardiovascular workup. All LLMs had excellent yet similar performance. LLMs may be leveraged on preoperative clinical notes to classify which patients would benefit from preoperative cardiology evaluations. No clinically significant differences were seen between domain-specific and general-purpose LLMs.\n",
        "link": "http://dx.doi.org/10.2196/preprints.52975"
    },
    {
        "id": 11815,
        "title": "Enabling Large Language Models to Think Twice When Its Answer Is Unreliable: A Case Study In Cancer Screening",
        "authors": "Minchong Wu, Hongxiang Lin, Xiaoqing Lyu, Chenrui Zhang, Sun Yu",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bibm58861.2023.10385316"
    },
    {
        "id": 11816,
        "title": "Towards Evaluation and Understanding of Large Language Models for Cyber Operation Automation",
        "authors": "Madeena Sultana, Adrian Taylor, Li Li, Suryadipta Majumdar",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cns59707.2023.10288677"
    },
    {
        "id": 11817,
        "title": "Generative Speech Recognition Error Correction With Large Language Models and Task-Activating Prompting",
        "authors": "Chao-Han Huck Yang, Yile Gu, Yi-Chieh Liu, Shalini Ghosh, Ivan Bulyko, Andreas Stolcke",
        "published": "2023-12-16",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/asru57964.2023.10389673"
    },
    {
        "id": 11818,
        "title": "Writing medical papers using large-scale language models: a perspective from the Japanese Journal of Radiology",
        "authors": "Takeshi Nakaura, Shinji Naganawa",
        "published": "2023-5",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11604-023-01408-z"
    },
    {
        "id": 11819,
        "title": "Large language models in education: A focus on the complementary relationship between human teachers and ChatGPT",
        "authors": "Jaeho Jeon, Seongyong Lee",
        "published": "2023-12",
        "citations": 51,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10639-023-11834-1"
    },
    {
        "id": 11820,
        "title": "(Security) Assertions by Large Language Models",
        "authors": "Rahul Kande, Hammond Pearce, Benjamin Tan, Brendan Dolan-Gavitt, Shailja Thakur, Ramesh Karri, Jeyavijayan Rajendran",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tifs.2024.3372809"
    },
    {
        "id": 11821,
        "title": "Artificial intelligence: revolutionizing cardiology with large language models",
        "authors": "Machteld J Boonstra, Davy Weissenbacher, Jason H Moore, Graciela Gonzalez-Hernandez, Folkert W Asselbergs",
        "published": "2024-2-1",
        "citations": 1,
        "abstract": "Abstract\nNatural language processing techniques are having an increasing impact on clinical care from patient, clinician, administrator, and research perspective. Among others are automated generation of clinical notes and discharge letters, medical term coding for billing, medical chatbots both for patients and clinicians, data enrichment in the identification of disease symptoms or diagnosis, cohort selection for clinical trial, and auditing purposes. In the review, an overview of the history in natural language processing techniques developed with brief technical background is presented. Subsequently, the review will discuss implementation strategies of natural language processing tools, thereby specifically focusing on large language models, and conclude with future opportunities in the application of such techniques in the field of cardiology.",
        "link": "http://dx.doi.org/10.1093/eurheartj/ehad838"
    },
    {
        "id": 11822,
        "title": "Limitations of large language models in medical applications",
        "authors": "Jiawen Deng, Areeba Zubair, Ye-Jean Park",
        "published": "2023-11-20",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/postmj/qgad069"
    },
    {
        "id": 11823,
        "title": "ProgPrompt: Generating Situated Robot Task Plans using Large Language Models",
        "authors": "Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, Animesh Garg",
        "published": "2023-5-29",
        "citations": 30,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icra48891.2023.10161317"
    },
    {
        "id": 11824,
        "title": "Prompt Engineering in Large Language Models",
        "authors": "Ggaliwango Marvin, Nakayiza Hellen, Daudi Jjingo, Joyce Nakatumba-Nabende",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-7962-2_30"
    },
    {
        "id": 11825,
        "title": "PromptMTopic: Unsupervised Multimodal Topic Modeling of Memes using Large Language Models",
        "authors": "Nirmalendu Prakash, Han Wang, Nguyen Khoi Hoang, Ming Shan Hee, Roy Ka-Wei Lee",
        "published": "2023-10-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3581783.3613836"
    },
    {
        "id": 11826,
        "title": "Structure of the space of folding protein sequences defined by large language models",
        "authors": "A Zambon, R Zecchina, G Tiana",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "Abstract\nProteins populate a manifold in the high-dimensional sequence space whose geometrical structure guides their natural evolution. Leveraging recently-developed structure prediction tools based on transformer models, we first examine the protein sequence landscape as defined by an effective energy that is a proxy of sequence foldability. This landscape shares characteristics with optimization challenges encountered in machine learning and constraint satisfaction problems. Our analysis reveals that natural proteins predominantly reside in wide, flat minima within this energy landscape. To investigate further, we employ statistical mechanics algorithms specifically designed to explore regions with high local entropy in relatively flat landscapes. Our findings indicate that these specialized algorithms can identify valleys with higher entropy compared to those found using traditional methods such as Monte Carlo Markov Chains. In a proof-of-concept case, we find that these highly entropic minima exhibit significant similarities to natural sequences, especially in critical key sites and local entropy. Additionally, evaluations through Molecular Dynamics suggests that the stability of these sequences closely resembles that of natural proteins. Our tool combines advancements in machine learning and statistical physics, providing new insights into the exploration of sequence landscapes where wide, flat minima coexist alongside a majority of narrower minima.",
        "link": "http://dx.doi.org/10.1088/1478-3975/ad205c"
    },
    {
        "id": 11827,
        "title": "Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions",
        "authors": "John Chung, Ece Kamar, Saleema Amershi",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.34"
    },
    {
        "id": 11828,
        "title": "Structured information extraction from scientific text with large language models",
        "authors": "John Dagdelen, Alexander Dunn, Sanghoon Lee, Nicholas Walker, Andrew S. Rosen, Gerbrand Ceder, Kristin A. Persson, Anubhav Jain",
        "published": "2024-2-15",
        "citations": 0,
        "abstract": "AbstractExtracting structured knowledge from scientific text remains a challenging task for machine learning models. Here, we present a simple approach to joint named entity recognition and relation extraction and demonstrate how pretrained large language models (GPT-3, Llama-2) can be fine-tuned to extract useful records of complex scientific knowledge. We test three representative tasks in materials chemistry: linking dopants and host materials, cataloging metal-organic frameworks, and general composition/phase/morphology/application information extraction. Records are extracted from single sentences or entire paragraphs, and the output can be returned as simple English sentences or a more structured format such as a list of JSON objects. This approach represents a simple, accessible, and highly flexible route to obtaining large databases of structured specialized scientific knowledge extracted from research papers.",
        "link": "http://dx.doi.org/10.1038/s41467-024-45563-x"
    },
    {
        "id": 11829,
        "title": "Assessing the application of Large Language Processing Models (LLMs) in generating dermatologic patient education materials according to reading level (Preprint)",
        "authors": "Raphaella Lambert, Zi-Yi Choo, Kelsey Gradwohl, Liesl Schroedl, Arlene Ruiz De Luzuriaga",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2196/55898"
    },
    {
        "id": 11830,
        "title": "Evaluating Large Language Models for the National Premedical Exam in India: Comparative Analysis of GPT-3.5, GPT-4, and Bard (Preprint)",
        "authors": "Faiza Farhat, Beenish Moalla Chaudhry, Mohammad Nadeem, Shahab Saquib Sohail, Dag Øivind Madsen",
        "published": "No Date",
        "citations": 1,
        "abstract": "\nBACKGROUND\nLarge language models (LLMs) have revolutionized natural language processing with their ability to generate human-like text through extensive training on large data sets. These models, including Generative Pre-trained Transformers (GPT)-3.5 (OpenAI), GPT-4 (OpenAI), and Bard (Google LLC), find applications beyond natural language processing, attracting interest from academia and industry. Students are actively leveraging LLMs to enhance learning experiences and prepare for high-stakes exams, such as the National Eligibility cum Entrance Test (NEET) in India.\n\n\nOBJECTIVE\nThis comparative analysis aims to evaluate the performance of GPT-3.5, GPT-4, and Bard in answering NEET-2023 questions.\n\n\nMETHODS\nIn this paper, we evaluated the performance of the 3 mainstream LLMs, namely GPT-3.5, GPT-4, and Google Bard, in answering questions related to the NEET-2023 exam. The questions of the NEET were provided to these artificial intelligence models, and the responses were recorded and compared against the correct answers from the official answer key. Consensus was used to evaluate the performance of all 3 models.\n\n\nRESULTS\nIt was evident that GPT-4 passed the entrance test with flying colors (300/700, 42.9%), showcasing exceptional performance. On the other hand, GPT-3.5 managed to meet the qualifying criteria, but with a substantially lower score (145/700, 20.7%). However, Bard (115/700, 16.4%) failed to meet the qualifying criteria and did not pass the test. GPT-4 demonstrated consistent superiority over Bard and GPT-3.5 in all 3 subjects. Specifically, GPT-4 achieved accuracy rates of 73% (29/40) in physics, 44% (16/36) in chemistry, and 51% (50/99) in biology. Conversely, GPT-3.5 attained an accuracy rate of 45% (18/40) in physics, 33% (13/26) in chemistry, and 34% (34/99) in biology. The accuracy consensus metric showed that the matching responses between GPT-4 and Bard, as well as GPT-4 and GPT-3.5, had higher incidences of being correct, at 0.56 and 0.57, respectively, compared to the matching responses between Bard and GPT-3.5, which stood at 0.42. When all 3 models were considered together, their matching responses reached the highest accuracy consensus of 0.59.\n\n\nCONCLUSIONS\nThe study’s findings provide valuable insights into the performance of GPT-3.5, GPT-4, and Bard in answering NEET-2023 questions. GPT-4 emerged as the most accurate model, highlighting its potential for educational applications. Cross-checking responses across models may result in confusion as the compared models (as duos or a trio) tend to agree on only a little over half of the correct responses. Using GPT-4 as one of the compared models will result in higher accuracy consensus. The results underscore the suitability of LLMs for high-stakes exams and their positive impact on education. Additionally, the study establishes a benchmark for evaluating and enhancing LLMs’ performance in educational tasks, promoting responsible and informed use of these models in diverse learning environments.\n",
        "link": "http://dx.doi.org/10.2196/preprints.51523"
    },
    {
        "id": 11831,
        "title": "Performance of large language models at the MRCS Part A: a tool for medical education?",
        "authors": "A Yiu, K Lam",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "Introduction The Intercollegiate Membership of the Royal College of Surgeons examination (MRCS) Part A assesses generic surgical sciences and applied knowledge using 300 multiple-choice Single Best Answer items. Large Language Models (LLMs) are trained on vast amounts of text to generate natural language outputs, and applications in healthcare and medical education are rising. Methods Two LLMs, ChatGPT (OpenAI) and Bard (Google AI), were tested using 300 questions from a popular MRCS Part A question bank without/with need for justification (NJ/J). LLM outputs were scored according to accuracy, concordance and insight. Results ChatGPT achieved 85.7%/84.3% accuracy for NJ/J encodings. Bard achieved 64%/64.3% accuracy for NJ/J encodings. ChatGPT and Bard displayed high levels of concordance for NJ (95.3%; 81.7%) and J (93.7%; 79.7%) encodings, respectively. ChatGPT and Bard provided an insightful statement in >98% and >86% outputs, respectively. Discussion This study demonstrates that ChatGPT achieves passing-level accuracy at MRCS Part A, and both LLMs achieve high concordance and provide insightful responses to test questions. Instances of clinically inappropriate or inaccurate decision-making, incomplete appreciation of nuanced clinical scenarios and utilisation of out-of-date guidance was, however, noted. LLMs are accessible and time-efficient tools, access vast clinical knowledge, and may reduce the emphasis on factual recall in medical education and assessment. Conclusion ChatGPT achieves passing-level accuracy for MRCS Part A with concordant and insightful outputs. Future applications of LLMs in healthcare must be cautious of hallucinations and incorrect reasoning but have the potential to develop AI-supported clinicians. ",
        "link": "http://dx.doi.org/10.1308/rcsann.2023.0085"
    },
    {
        "id": 11832,
        "title": "ESR Journals editors’ joint statement on Guidelines for the Use of Large Language Models by Authors, Reviewers, and Editors",
        "authors": "Bernd Hamm, Luis Marti-Bonmati, Francesco Sardanelli",
        "published": "2024-1-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s41747-023-00420-2"
    },
    {
        "id": 11833,
        "title": "ChatGPT and university teaching, learning and assessment: some initial reflections on teaching academic integrity in the age of Large Language Models",
        "authors": "Adrian Kirwan",
        "published": "2023-11-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/03323315.2023.2284901"
    },
    {
        "id": 11834,
        "title": "An Imperial Analysis of Large Language Models for Automated Tweet Sentiment Prediction",
        "authors": "Shivam Akhouri, Vidhi Ajbani, Ritika Lakshminarayanan, Trilok Nath Pandey, Meher Shrishti Nigam, Sudhansu Shekhar Patra",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icscna58489.2023.10370253"
    },
    {
        "id": 11835,
        "title": "Exploring the Use of Large Language Models for Reference-Free Text Quality Evaluation: An Empirical Study",
        "authors": "Yi Chen, Rui Wang, Haiyun Jiang, Shuming Shi, Ruifeng Xu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-ijcnlp.32"
    },
    {
        "id": 11836,
        "title": "The Eval4NLP 2023 Shared Task on Prompting Large Language Models as Explainable Metrics",
        "authors": "Christoph Leiter, Juri Opitz, Daniel Deutsch, Yang Gao, Rotem Dror, Steffen Eger",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.eval4nlp-1.10"
    },
    {
        "id": 11837,
        "title": "ChatGPT and Other Large Language Models Are Double-edged                     Swords",
        "authors": "Yiqiu Shen, Laura Heacock, Jonathan Elias, Keith D. Hentel, Beatriu Reig, George Shih, Linda Moy",
        "published": "2023-4-1",
        "citations": 298,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1148/radiol.230163"
    },
    {
        "id": 11838,
        "title": "Blending Dependency Parsers With Language Models",
        "authors": "Nicos Isaak",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011781800003393"
    },
    {
        "id": 11839,
        "title": "Evaluating the Symbol Binding Ability of Large Language Models for Multiple-Choice Questions in Vietnamese General Education",
        "authors": "Duc-Vu Nguyen, Quoc-Nam Nguyen",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3628797.3628837"
    },
    {
        "id": 11840,
        "title": "Unpacking Unstructured Data: A Pilot Study on Extracting Insights from Neuropathological Reports of Parkinson’s Disease Patients using Large Language Models",
        "authors": "Oleg Stroganov, Amber Schedlbauer, Emily Lorenzen, Alex Kadhim, Anna Lobanova, David A. Lewis, Jill R. Glausier",
        "published": "No Date",
        "citations": 0,
        "abstract": "ABSTRACTObjectiveThe aim of this study was to make unstructured neuropathological data, located in the NeuroBioBank (NBB), follow FAIR principles, and investigate the potential of Large Language Models (LLMs) in wrangling unstructured neuropathological reports. By making the currently inconsistent and disparate data findable, our overarching goal was to enhance research output and speed.Materials and MethodsThe NBB catalog currently includes information from medical records, interview results, and neuropathological reports. These reports contain crucial information necessary for conducting in-depth analysis of NBB data but have multiple formats that vary across sites and change over time. In this study we focused on a subset of donors with Parkinson’s Disease (PD). We developed a data model with combined Brain Region and Pathological Findings data at its core. This approach made it easier to build an extraction pipeline and was flexible enough to convert resulting data to Common Data Elements (CDEs) used by the community.ResultsThis pilot study demonstrated the potential of LLMs in structuring unstructured neuropathological reports of PD patients available in the NBB. The pipeline enabled successful extraction of microscopic and macroscopic findings and staging information from pathology reports, with extraction quality comparable to results of manual curation. To our knowledge, this is the first attempt to automatically standardize neuropathological information at this scale. The collected data has the potential to serve as a valuable resource for PD researchers, bridging the gap between clinical information and genetic data, thereby facilitating a more comprehensive understanding of the disease.",
        "link": "http://dx.doi.org/10.1101/2023.09.12.557252"
    },
    {
        "id": 11841,
        "title": "Inductive reasoning in humans and large language models",
        "authors": "Simon Jerome Han, Keith J. Ransom, Andrew Perfors, Charles Kemp",
        "published": "2024-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.cogsys.2023.101155"
    },
    {
        "id": 11842,
        "title": "Large Language Models in Neurology Research and Future Practice",
        "authors": "Michael F. Romano, Ludy C. Shih, Ioannis C. Paschalidis, Rhoda Au, Vijaya B. Kolachalama",
        "published": "2023-12-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1212/wnl.0000000000207967"
    },
    {
        "id": 11843,
        "title": "Leveraging error-assisted fine-tuning large language models for manufacturing excellence",
        "authors": "Liqiao Xia, Chengxi Li, Canbin Zhang, Shimin Liu, Pai Zheng",
        "published": "2024-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.rcim.2024.102728"
    },
    {
        "id": 11844,
        "title": "A Survey on Large Language Models: Applications, Challenges, Limitations, and Practical Usage",
        "authors": "Muhammad Usman Hadi, qasem al tashi, Rizwan Qureshi, Abbas Shah, amgad muneer, Muhammad Irfan, Anas Zafar, Muhammad Bilal Shaikh, Naveed Akhtar, Jia Wu, Seyedali Mirjalili",
        "published": "No Date",
        "citations": 5,
        "abstract": "<p>Within the vast expanse of computerized language processing, a revolutionary entity known as Large Language Models (LLMs) has emerged, wielding immense power in its capacity to comprehend intricate linguistic patterns and conjure coherent and contextually fitting responses. Large language models (LLMs) are a type of artificial intelligence (AI) that have emerged as powerful tools for a wide range of tasks, including natural language processing (NLP), machine translation, and question-answering. This survey paper provides a comprehensive overview of LLMs, including their history, architecture, training methods, applications, and challenges. The paper begins by discussing the fundamental concepts of generative AI and the architecture of generative pre- trained transformers (GPT). It then provides an overview of the history of LLMs, their evolution over time, and the different training methods that have been used to train them. The paper then discusses the wide range of applications of LLMs, including medical, education, finance, and engineering. It also discusses how LLMs are shaping the future of AI and how they can be used to solve real-world problems. The paper then discusses the challenges associated with deploying LLMs in real-world scenarios, including ethical considerations, model biases, interpretability, and computational resource requirements. It also highlights techniques for enhancing the robustness and controllability of LLMs, and addressing bias, fairness, and generation quality issues. Finally, the paper concludes by highlighting the future of LLM research and the challenges that need to be addressed in order to make LLMs more reliable and useful. This survey paper is intended to provide researchers, practitioners, and enthusiasts with a comprehensive understanding of LLMs, their evolution, applications, and challenges. By consolidating the state-of-the-art knowledge in the field, this survey serves as a valuable resource for further advancements in the development and utilization of LLMs for a wide range of real-world applications. The GitHub repo for this project is available at https://github.com/anas-zafar/LLM-Survey</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23589741.v1"
    },
    {
        "id": 11845,
        "title": "Radiology Reading Room for the Future: Harnessing the Power of Large Language Models Like ChatGPT",
        "authors": "Charit Tippareddy, Sirui Jiang, Kaustav Bera, Nikhil Ramaiya",
        "published": "2023-8",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1067/j.cpradiol.2023.08.018"
    },
    {
        "id": 11846,
        "title": "Public Opinion Mining Using Large Language Models on COVID-19 Related Tweets",
        "authors": "Vu Tran, Tomoko Matsui",
        "published": "2023-10-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/kse59128.2023.10299499"
    },
    {
        "id": 11847,
        "title": "Enterprise large language models: Knowledge characteristics, risks, and organizational activities",
        "authors": "Daniel E. O'Leary",
        "published": "2023-7",
        "citations": 0,
        "abstract": "SummarySince the release of OpenAI's ChatGPT, there has been substantial interest in and concern about generative AI systems. This paper investigates some of the characteristics, risks, and limitations with the enterprise use of enterprise large language models. In so doing, we study the organizational impact, continuing a long line of research on that topic. This paper examines the impact on expertise, the organizational implications of multiple correlated but different responses to the same query, the potential concerns associated with sensitive information and intellectual property, and some applications that likely would not be appropriate for large language models. We also investigate the possibility of agents potentially manipulating the content in these large language models for their own benefit. Finally, we investigate the emerging phenomenon of “ChatBot Enterprise” versions, including some of the implications and concerns of such enterprise large language models.",
        "link": "http://dx.doi.org/10.1002/isaf.1541"
    },
    {
        "id": 11848,
        "title": "Centralized provisioning of large language models for a research community",
        "authors": "Dhruvil Shah, Gil Speyer, Jason Yalim",
        "published": "2023-11-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3624062.3624147"
    },
    {
        "id": 11849,
        "title": "Evaluating Large Language Models for Sentence Augmentation in Low-Resource Languages: A Case Study on Kazakh",
        "authors": "Zhamilya Bimagambetova, Dauren Rakhymzhanov, Assel Jaxylykova, Alexander Pak",
        "published": "2023-8-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/opcs59592.2023.10275753"
    },
    {
        "id": 11850,
        "title": "Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method",
        "authors": "Yiming Wang, Zhuosheng Zhang, Rui Wang",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.482"
    },
    {
        "id": 11851,
        "title": "Enhancing Real-World Data Extraction in Clinical Research: Evaluating the Impact of Implementing Large Language Models in Hospital Settings",
        "authors": "Bin Wang, Junkai Lai, Han Cao, Feifei Jin, Qiang Li, Mingkun Tang, Chen Yao, Ping Zhang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground: The application of artificial intelligence (AI) and large language models (LLMs) in the medical sector has gained momentum. The widespread adoption of electronic health record (EHR) platforms has created a demand for efficient extraction and analysis of unstructured data, known as real-world data (RWD). The surge in medical free-text data has emphasized the significance of natural language processing (NLP) in extracting insights from EHRs, making it a crucial tool in clinical research. The development of LLMs specifically designed for biomedical and clinical text mining has further propelled the capabilities of NLP in this domain. Despite these advancements, the specific utilization of LLMs in clinical research remains limited.\nObjective: This study aims to assess the feasibility and impact of implementing a LLM for extracting RWD in hospital settings. The primary focus is on evaluating the effectiveness of LLM-driven data extraction compared to manual processes used by Electronic Source Data Repositories (ESDR) system. Additionally, the study aims to identify challenges in LLM implementation and gain practical insights from the field.\nMethods: Researchers developed the ESDR system, integrating LLM, electronic Case Report Forms (eCRF) and EHR. The Paroxysmal Atrial Tachycardia Project, a single-center retrospective cohort study, served as a pilot case. The study involved deploying the ESDR system on the hospital LAN. Localized LLM deployment utilized the Chinese open-source ChatGLM model. The research design compared the AI-assisted process with ESDR manual processes in terms of accuracy rates and time allocations. Five eCRF forms, predominantly comprising free-text content, underwent evaluation, involving 630 subjects with a 10% sample (63 subjects) for assessment. Data collection involved electronic medical and prescription records from 13 departments.\nResults: While the discharge medication form achieved 100% data completeness, some free-text forms exhibited data completeness below 20%. The AI-assisted process showed an estimated efficiency improvement of 80.7% in eCRF data transcription time. The AI data extraction accuracy rate was 94.84%, with errors mainly related to localized Chinese clinical terminology. The study identified challenges in prompt design, prompt output consistency, and prompt output verification. Addressing limitations in clinical terminology and output inconsistency involves integrating local terminology libraries and offering clear output format examples. Enhancing output verification can be achieved by probing the model's reasoning, assessing confidence on a scale, and highlighting relevant text snippets. These measures mitigate challenges in understanding the model's decision-making process within extensive free-text documents.\nConclusions: The research enriches academic discourse on LLM in clinical research and provides actionable recommendations for practical implementation in RWD extraction. By offering insights into LLM integration within clinical research systems, the study contributes to establishing a secure and efficient framework for digital clinical research. Continuous evolution and optimization of LLM technology are crucial for its seamless integration into the broader landscape of clinical research.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3644810/v1"
    },
    {
        "id": 11852,
        "title": "An Evaluation of Source Factors in Concatenation-based Context-aware Neural Machine Translation",
        "authors": "Harritxu Gete,  , Thierry Etchegoyhen,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_045"
    },
    {
        "id": 11853,
        "title": "T2KG: Transforming Multimodal Document to Knowledge Graph",
        "authors": "Santiago Galiano,  , Rafael Muñoz, Yoan Gutiérrez, Andrés Montoyo, L. Alfonso Ureña,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_043"
    },
    {
        "id": 11854,
        "title": "Large Language Models respond to Influence like Humans",
        "authors": "Lewis Griffin, Bennett Kleinberg, Maximilian Mozes, Kimberly Mai, Maria Do Mar Vau, Matthew Caldwell, Augustine Mavor-Parker",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.sicon-1.3"
    },
    {
        "id": 11855,
        "title": "The Evolving Landscape of Cybersecurity: Red Teams, Large Language Models, and the Emergence of New AI Attack Surfaces",
        "authors": "Forrest McKee, David Noever",
        "published": "2023-3-30",
        "citations": 0,
        "abstract": "This study explores cybersecurity questions using a question-and-answer format with the advanced ChatGPT model from OpenAI. Unlike previous chatbots, ChatGPT demonstrates an enhanced understanding of complex coding questions. We present thirteen coding tasks aligned with various stages of the MITRE ATT&CK framework, covering areas such as credential access and defense evasion. The experimental prompts generate keyloggers, logic bombs, obfuscated worms, and ransomware with payment fulfillment, showcasing an impressive range of functionality, including self-replication, self-modification, and evasion. Despite being a language-only model, a notable feature of ChatGPT showcases its coding approaches to produce images with obfuscated or embedded executable programming steps or links.",
        "link": "http://dx.doi.org/10.5121/ijcis.2023.13101"
    },
    {
        "id": 11856,
        "title": "Performance of Large Language Models in Patient Complaint Resolution: A single-blind comparative evaluation (Preprint)",
        "authors": "Lorraine Pei Xian Yong, Joshua Yi Min Tung, Zi  Yao Lee, Win Sen Kuan, Mui Teng Chua",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nPatient complaints are a perennial challenge faced by healthcare institutions globally, requiring extensive time and effort from healthcare workers. Despite these efforts, patient dissatisfaction remains high. Recent studies on the utility of Large Language Models (LLMs) such as the GPT models developed by OpenAI in the healthcare sector have shown great promise, with the ability to provide more detailed and empathetic responses as compared to physicians. LLMs could potentially be utilized in responding to patient complaints to improve patient satisfaction and complaint response time.\n\n\nOBJECTIVE\nThis study aimed to evaluate the performance of LLMs in addressing patient complaints received by a tertiary healthcare institution, with the goal of enhancing patient satisfaction.\n\n\nMETHODS\nAnonymized patient complaint emails and associated responses from the Patient Relations Department (PRD) were obtained. ChatGPT-4.0 was provided with the same complaint email and tasked to generate a response. The complaints and the respective responses were uploaded onto a web-based questionnaire. Respondents were asked to rate both responses on a 10-point Likert scale for 4 items: appropriateness, completeness, empathy, and satisfaction. Participants were also asked to choose a preferred response at the end of each scenario.\n\n\nRESULTS\nThere were a total of 188 respondents, of which 61.2% were healthcare workers. A majority of the respondents, including both healthcare and non-healthcare workers, preferred replies from ChatGPT (87.2% to 97.3%). GPT4.0 responses were rated higher in all four assessed items (P <.001), and had higher average wordcounts as compared to human responses (238 to 76 words). Regression analyses showed that a higher word count was a statistically significant predictor (P <.001) of higher score in all 4 items. However, on subgroup analysis by authorship, this only held true for responses written by PRD staff and not those generated by ChatGPT which received consistently high scores irrespective of response length.\n\n\nCONCLUSIONS\nThis study provides significant evidence supporting the effectiveness of LLMs in patient complaint resolution. ChatGPT demonstrated superiority in terms of response appropriateness, empathy, quality, and overall satisfaction when compared against actual human responses to patient complaints. Future research can be done to measure the degree of improvement that artificial intelligence (AI) generated responses can bring in terms of time savings, patient satisfaction and stress reduction for healthcare workers.\n",
        "link": "http://dx.doi.org/10.2196/preprints.56413"
    },
    {
        "id": 11857,
        "title": "CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes",
        "authors": "Mark Liffiton, Brad E Sheese, Jaromir Savelka, Paul Denny",
        "published": "2023-11-13",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3631802.3631830"
    },
    {
        "id": 11858,
        "title": "Authorship Policy of the <i>Korean Journal of Radiology</i> Regarding Artificial Intelligence Large Language Models Such as ChatGTP",
        "authors": "Seong Ho Park",
        "published": "2023",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3348/kjr.2023.0112"
    },
    {
        "id": 11859,
        "title": "Cache me if you Can: an Online Cost-aware Teacher-Student framework to Reduce the Calls to Large Language Models",
        "authors": "Ilias Stogiannidis, Stavros Vassos, Prodromos Malakasiotis, Ion Androutsopoulos",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.1000"
    },
    {
        "id": 11860,
        "title": "Exploring the Capabilities and Possible Applications of Large Language Models for Education",
        "authors": "Matúš Čavojský, Gabriel Bugár, Tomáš Kormaník, Martin Hasin",
        "published": "2023-10-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iceta61311.2023.10344166"
    },
    {
        "id": 11861,
        "title": "Caveat Emptor: Medicolegal Issues May Arise From the Opaque and Unpredictable Nature of Current Large Language Models Used in Diagnostic Imaging",
        "authors": "Elham Beheshtian, Eliot L. Siegel, Jonathan L. Mezrich",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.acra.2023.12.033"
    },
    {
        "id": 11862,
        "title": "Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding",
        "authors": "Ziang Xiao, Xingdi Yuan, Q. Vera Liao, Rania Abdelghani, Pierre-Yves Oudeyer",
        "published": "2023-3-27",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3581754.3584136"
    },
    {
        "id": 11863,
        "title": "Chart Understanding with Large Language Model",
        "authors": "John Feng",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31224/3401"
    },
    {
        "id": 11864,
        "title": "Small Language Survival and Large Language Expansion on a Hunter-Gatherer Continent",
        "authors": "Peter Sutton",
        "published": "2020-2-27",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139026208.015"
    },
    {
        "id": 11865,
        "title": "Recent Advances in Natural Language Processing via Large Pre-trained Language Models: A Survey",
        "authors": "Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre, Ilana Heintz, Dan Roth",
        "published": "2024-2-29",
        "citations": 38,
        "abstract": "Large, pre-trained language models (PLMs) such as BERT and GPT have drastically changed the Natural Language Processing (NLP) field. For numerous NLP tasks, approaches leveraging PLMs have achieved state-of-the-art performance. The key idea is to learn a generic, latent representation of language from a generic task once, then share it across disparate NLP tasks. Language modeling serves as the generic task, one with abundant self-supervised text available for extensive training. This article presents the key fundamental concepts of PLM architectures and a comprehensive view of the shift to PLM-driven NLP techniques. It surveys work applying the pre-training then fine-tuning, prompting, and text generation approaches. In addition, it discusses PLM limitations and suggested directions for future research.",
        "link": "http://dx.doi.org/10.1145/3605943"
    },
    {
        "id": 11866,
        "title": "WordArt Designer: User-Driven Artistic Typography Synthesis using Large Language Models",
        "authors": "Jun-Yan He, Zhi-Qi Cheng, Chenyang Li, Jingdong Sun, Wangmeng Xiang, Xianhui Lin, Xiaoyang Kang, Zengke Jin, Yusen Hu, Bin Luo, Yifeng Geng, Xuansong Xie",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-industry.23"
    },
    {
        "id": 11867,
        "title": "I. Language and Reality",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-002"
    },
    {
        "id": 11868,
        "title": "Stellenwert von Natural Language Processing und chatbasierten Generative Language Models",
        "authors": "Markus Haar, Michael Sonntagbauer, Stefan Kluge",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00063-023-01098-5"
    },
    {
        "id": 11869,
        "title": "Prompt Engineering for Large Language Models to Support K-8 Computer Science Teachers in Creating Culturally Responsive Projects",
        "authors": "Minh Tran",
        "published": "2023-8-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3568812.3603453"
    },
    {
        "id": 11870,
        "title": "Predicting seizure recurrence from medical records using large language models",
        "authors": "Gashirai K Mbizvo, Ian Buchan",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00205-4"
    },
    {
        "id": 11871,
        "title": "Erratum: Authorship Policy of the <i>Korean Journal of Radiology</i> Regarding Artificial Intelligence Large Language Models Such as ChatGPT",
        "authors": "Seong Ho Park",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3348/kjr.2023.0244"
    },
    {
        "id": 11872,
        "title": "Exploring the Path from Instructions to Rewards with Large Language Models in Instance-Based Learning",
        "authors": "Chase McDonald, Tyler Malloy, Thuy Ngoc Nguyen, Cleotilde Gonzalez",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "A prominent method to model human learning is through experiential learning, where decisions are influenced by the outcomes observed in previous actions. The decisions-from-experience approach often excludes other forms of learning in humans, such as learning from descriptive information. In humans, descriptive information can enhance learning by providing a denser signal, achieved through understanding the relationship between intermediate decisions and their future outcomes, instead of relying solely on observed outcomes. To account for experiential and descriptive information, we propose the use of large language models (LLMs) to convert descriptive information into dense signals that can be used by computational models that learn from experience. Building on past work in cognitive modeling, we utilize task instructions and prompt an LLM to define and quantify the critical actions an agent must take to succeed in the task. In an initial experiment, we test this approach using an Instance-Based Learning cognitive model of experiential decisions in a gridworld task. We demonstrate how the LLM can be prompted to provide a series of actions and relative values given the task instructions, then show how these values can be used in place of sparse outcome signals to improve the model’s learning of the task significantly.",
        "link": "http://dx.doi.org/10.1609/aaaiss.v2i1.27697"
    },
    {
        "id": 11873,
        "title": "Judging Knowledge by its Cover: Leveraging Large Language Models in Establishing Criteria for Knowledge Graph Sources Selection",
        "authors": "Hendrik Hendrik, Adhistya Erna Permanasari, Silmi Fauziati, Sri Suning Kusumawardani",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icitda60835.2023.10427395"
    },
    {
        "id": 11874,
        "title": "Evaluation of Large Scale Language Models on Solving Math Word Problems with Difficulty Grading",
        "authors": "Xin He, Huikai Gao, Jiaxing He, Chao Sun",
        "published": "2023-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ieir59294.2023.10391224"
    },
    {
        "id": 11875,
        "title": "A Structured Narrative Prompt for Large Language Models to Create Pertinent Narratives of Simulated Agents’ Life Events: A Sentiment Analysis Comparison",
        "authors": "Christopher J. Lynch, Erik Jensen, Virginia Zamponi, Kevin O'Brien, Erika Frydenlund, Ross Gore",
        "published": "No Date",
        "citations": 0,
        "abstract": "Large language models (LLMs) excel in providing natural language responses that sound authoritative, reflect knowledge of the context area, and can present from a range of varied perspectives. Agent Based Models and Simulation consist of simulated agents that interact within a simulated environment to explore societal, social, and ethical, among other, problems. Agents generate large volumes of data over time and discerning useful and relevant content is an onerous task. LLMs can help in communicating agents’ perspectives on key events by providing natural language narratives. However, these narratives need to be factual, transparent, and reproducible. To this end, we present a structured narrative prompt for sending queries to LLMs. Chi-square tests and Fisher’s Exact tests are applied to assess statistically significant difference in sentiment scores of the narrative messages between simulation generated narratives, ChatGPT-generated narratives, and real tweets. The narrative prompt structure effectively yields narratives with the desired components from ChatGPT. This structure is expected to be extensible across LLMs. In 14 out of 44 categories, ChatGPT generated narratives which has sentiment scores that were not discernibly different, in terms of statistical significance (alpha level of 0.05), from the sentiment expressed in real tweets. Three outcomes are provided: (1) a list of benefits and challenges for LLMs in narrative generation; (2) a structured prompt for requesting narratives of a LLM based on simulated agents’ information; and (3) an assessment of statistical significance in the sentiment prevalence of the generated narratives compared to real tweets. This indicates significant promise in the utilization of LLMs for helping to connect simulated agent’s experiences with real people.",
        "link": "http://dx.doi.org/10.20944/preprints202309.2026.v1"
    },
    {
        "id": 11876,
        "title": "Enhancing Code Tracing Question Generation with Refined Prompts in Large Language Models",
        "authors": "Aysa X. Fan, Rully A. Hendrawan, Yang Shi, Qianou Ma",
        "published": "2024-3-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626253.3635624"
    },
    {
        "id": 11877,
        "title": "Why Personalized Large Language Models Fail to Do What Ethics is All About",
        "authors": "Sebastian Laacke, Charlotte Gauckler",
        "published": "2023-10-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15265161.2023.2250292"
    },
    {
        "id": 11878,
        "title": "Large language models and generative AI in telehealth: a responsible use lens",
        "authors": "Javad Pool, Marta Indulska, Shazia Sadiq",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "Abstract\n\nObjective\nThis scoping review aims to assess the current research landscape of the application and use of large language models (LLMs) and generative Artificial Intelligence (AI), through tools such as ChatGPT in telehealth. Additionally, the review seeks to identify key areas for future research, with a particular focus on AI ethics considerations for responsible use and ensuring trustworthy AI.\n\n\nMaterials and Methods\nFollowing the scoping review methodological framework, a search strategy was conducted across 6 databases. To structure our review, we employed AI ethics guidelines and principles, constructing a concept matrix for investigating the responsible use of AI in telehealth. Using the concept matrix in our review enabled the identification of gaps in the literature and informed future research directions.\n\n\nResults\nTwenty studies were included in the review. Among the included studies, 5 were empirical, and 15 were reviews and perspectives focusing on different telehealth applications and healthcare contexts. Benefit and reliability concepts were frequently discussed in these studies. Privacy, security, and accountability were peripheral themes, with transparency, explainability, human agency, and contestability lacking conceptual or empirical exploration.\n\n\nConclusion\nThe findings emphasized the potential of LLMs, especially ChatGPT, in telehealth. They provide insights into understanding the use of LLMs, enhancing telehealth services, and taking ethical considerations into account. By proposing three future research directions with a focus on responsible use, this review further contributes to the advancement of this emerging phenomenon of healthcare AI.\n",
        "link": "http://dx.doi.org/10.1093/jamia/ocae035"
    },
    {
        "id": 11879,
        "title": "Generation of guideline-based clinical decision trees in oncology using large language models",
        "authors": "Brenda Y Miao, Eduardo Rodriguez Almaraz, Amir Ashraf Ganjouei, Arvind Suresh, Travis Zack, Maxim Bravo, Srinidhi Raghavendran, Boris Oskotsky, Ahmed Alaa, Atul J Butte",
        "published": "No Date",
        "citations": 0,
        "abstract": "Background: Molecular biomarkers play a pivotal role in the diagnosis and treatment of oncologic diseases but staying updated with the latest guidelines and research can be challenging for healthcare professionals and patients. Large Language Models (LLMs), such as MedPalm-2 and GPT-4, have emerged as potential tools to streamline biomedical information extraction, but their ability to summarize molecular biomarkers for oncologic disease subtyping remains unclear. Auto-generation of clinical nomograms from text guidelines could illustrate a new type of utility for LLMs. Methods: In this cross-sectional study, two LLMs, GPT-4 and Claude-2, were assessed for their ability to generate decision trees for molecular subtyping of oncologic diseases with and without expert-curated guidelines. Clinical evaluators assessed the accuracy of biomarker and cancer subtype generation, as well as validity of molecular subtyping decision trees across five cancer types: colorectal cancer, invasive ductal carcinoma, acute myeloid leukemia, diffuse large B-cell lymphoma, and diffuse glioma. Results: Both GPT-4 and Claude-2 \"off the shelf\" successfully produced clinical decision trees that contained valid instances of biomarkers and disease subtypes. Overall, GPT-4 and Claude-2 showed limited improvement in the accuracy of decision tree generation when guideline text was added. A Streamlit dashboard was developed for interactive exploration of subtyping trees generated for other oncologic diseases. Conclusion: This study demonstrates the potential of LLMs like GPT-4 and Claude-2 in aiding the summarization of molecular diagnostic guidelines in oncology. While effective in certain aspects, their performance highlights the need for careful interpretation, especially in zero-shot settings. Future research should focus on enhancing these models for more nuanced and probabilistic interpretations in clinical decision-making. The developed tools and methodologies present a promising avenue for expanding LLM applications in various medical specialties.",
        "link": "http://dx.doi.org/10.1101/2024.03.04.24303737"
    },
    {
        "id": 11880,
        "title": "Reply to “Assessing the diagnostic performance of large language models with European Diploma in Musculoskeletal Radiology (EDiMSK) examination sample questions“",
        "authors": "Ayaka Harigai, Yoshitaka Toyama, Kei Takase",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11604-024-01556-w"
    },
    {
        "id": 11881,
        "title": "Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models",
        "authors": "Sami Sarsa, Paul Denny, Arto Hellas, Juho Leinonen",
        "published": "2022-8-3",
        "citations": 96,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3501385.3543957"
    },
    {
        "id": 11882,
        "title": "Large Language Models Augmented Rating Prediction in Recommender System",
        "authors": "Sichun Luo, Jiansheng Wang, Aojun Zhou, Li Ma, Linqi Song",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447514"
    },
    {
        "id": 11883,
        "title": "XIII. Models and Archetypes",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-014"
    },
    {
        "id": 11884,
        "title": "Dynamic Data Sampler for Cross-Language Transfer Learning in Large Language Models",
        "authors": "Yudong Li, Yuhao Feng, Wen Zhou, Zhe Zhao, Linlin Shen, Cheng Hou, Xianxu Hou",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446640"
    },
    {
        "id": 11885,
        "title": "Language models in automated essay scoring: Insights for the Turkish language",
        "authors": "Tahereh FİROOZİ, Okan BULUT, Mark GİERL",
        "published": "2023-12-27",
        "citations": 0,
        "abstract": "The proliferation of large language models represents a paradigm shift in the landscape of automated essay scoring (AES) systems, fundamentally elevating their accuracy and efficacy. This study presents an extensive examination of large language models, with a particular emphasis on the transformative influence of transformer-based models, such as BERT, mBERT, LaBSE, and GPT, in augmenting the accuracy of multilingual AES systems. The exploration of these advancements within the context of the Turkish language serves as a compelling illustration of the potential for harnessing large language models to elevate AES performance in in low-resource linguistic environments. Our study provides valuable insights for the ongoing discourse on the intersection of artificial intelligence and educational assessment.",
        "link": "http://dx.doi.org/10.21449/ijate.1394194"
    },
    {
        "id": 11886,
        "title": "A comparative study of zero-shot inference with large language models and supervised modeling in breast cancer pathology classification",
        "authors": "Madhumita Sushil, Travis Zack, Divneet Mandair, Zhiwei Zheng, Ahmed Wali, Yan-Ning Yu, Yuwei Quan, Atul Butte",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nAlthough supervised machine learning is popular for information extraction from clinical notes, creating large, annotated datasets requires extensive domain expertise and is time-consuming. Meanwhile, large language models (LLMs) have demonstrated promising transfer learning capability. In this study, we explored whether recent LLMs can reduce the need for large-scale data annotations. We curated a manually labeled dataset of 769 breast cancer pathology reports, labeled with 13 categories, to compare zero-shot classification capability of the GPT-4 model and the GPT-3.5 model with supervised classification performance of three model architectures: random forests classifier, long short-term memory networks with attention (LSTM-Att), and the UCSF-BERT model. Across all 13 tasks, the GPT-4 model performed either significantly better than or as well as the best supervised model, the LSTM-Att model (average macro F1 score of 0.83 vs. 0.75). On tasks with a high imbalance between labels, the differences were more prominent. Frequent sources of GPT-4 errors included inferences from multiple samples and complex task design. On complex tasks where large annotated datasets cannot be easily collected, LLMs can reduce the burden of large-scale data labeling. However, if the use of LLMs is prohibitive, the use of simpler supervised models with large annotated datasets can provide comparable results. LLMs demonstrated the potential to speed up the execution of clinical NLP studies by reducing the need for curating large annotated datasets. This may increase the utilization of NLP-based variables and outcomes in observational clinical studies.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3914899/v1"
    },
    {
        "id": 11887,
        "title": "Context-Aware Behavioral Tips to Improve Sleep Quality via Machine Learning and Large Language Models",
        "authors": "Erica Corda, Silvia M. Massa, Daniele Riboni",
        "published": "2024-1-30",
        "citations": 0,
        "abstract": "As several studies demonstrate, good sleep quality is essential for individuals’ well-being, as a lack of restoring sleep may disrupt different physical, mental, and social dimensions of health. For this reason, there is increasing interest in tools for the monitoring of sleep based on personal sensors. However, there are currently few context-aware methods to help individuals to improve their sleep quality through behavior change tips. In order to tackle this challenge, in this paper, we propose a system that couples machine learning algorithms and large language models to forecast the next night’s sleep quality, and to provide context-aware behavior change tips to improve sleep. In order to encourage adherence and to increase trust, our system includes the use of large language models to describe the conditions that the machine learning algorithm finds harmful to sleep health, and to explain why the behavior change tips are generated as a consequence. We develop a prototype of our system, including a smartphone application, and perform experiments with a set of users. Results show that our system’s forecast is correlated to the actual sleep quality. Moreover, a preliminary user study suggests that the use of large language models in our system is useful in increasing trust and engagement.",
        "link": "http://dx.doi.org/10.3390/fi16020046"
    },
    {
        "id": 11888,
        "title": "Generating Programs Trivially: Student Use of Large Language Models",
        "authors": "Siddhartha Prasad, Ben Greenman, Tim Nelson, Shriram Krishnamurthi",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3576882.3617921"
    },
    {
        "id": 11889,
        "title": "Self-Polish: Enhance Reasoning in Large Language Models via Problem Refinement",
        "authors": "Zhiheng Xi, Senjie Jin, Yuhao Zhou, Rui Zheng, Songyang Gao, Jia Liu, Tao Gui, Qi Zhang, Xuanjing Huang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.762"
    },
    {
        "id": 11890,
        "title": "Unlocking the Power of ChatGPT, Artificial Intelligence, and Large Language Models: Practical Suggestions for Radiation Oncologists",
        "authors": "Michael R. Waters, Sanjay Aneja, Julian C. Hong",
        "published": "2023-11",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.prro.2023.06.011"
    },
    {
        "id": 11891,
        "title": "Code Detection for Hardware Acceleration Using Large Language Models",
        "authors": "Pablo Antonio Martínez, Gregorio Bernabé, José Manuel García",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2024.3372853"
    },
    {
        "id": 11892,
        "title": "Large language models as an “operating” system for software and systems modeling",
        "authors": "Benoit Combemale, Jeff Gray, Bernhard Rumpe",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10270-023-01126-0"
    },
    {
        "id": 11893,
        "title": "Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis",
        "authors": "Oscar J. Romero, John Zimmerman, Aaron Steinfeld, Anthony Tomasic",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "This paper explores the integration of two AI subdisciplines employed in the development of artificial agents that exhibit intelligent behavior: Large Language Models (LLMs) and Cognitive Architectures (CAs). We present three integration approaches, each grounded in theoretical models and supported by preliminary empirical evidence. The modular approach, which introduces four models with varying degrees of integration, makes use of chain-of-thought prompting, and draws inspiration from augmented LLMs, the Common Model of Cognition, and the simulation theory of cognition. The agency approach, motivated by the Society of Mind theory and the LIDA cognitive architecture, proposes the formation of agent collections that interact at micro and macro cognitive levels, driven by either LLMs or symbolic components. The neuro-symbolic approach, which takes inspiration from the CLARION cognitive architecture, proposes a model where bottom-up learning extracts symbolic representations from an LLM layer and top-down guidance utilizes symbolic representations to direct prompt engineering in the LLM layer. These approaches aim to harness the strengths of both LLMs and CAs, while mitigating their weaknesses, thereby advancing the development of more robust AI systems. We discuss the tradeoffs and challenges associated with each approach.",
        "link": "http://dx.doi.org/10.1609/aaaiss.v2i1.27706"
    },
    {
        "id": 11894,
        "title": "Future Potential Challenges of Using Large Language Models Like ChatGPT in Daily Medical Practice",
        "authors": "Sam Sedaghat",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jacr.2023.10.019"
    },
    {
        "id": 11895,
        "title": "The inevitable transformation of medicine and research by large language models: The possibilities and pitfalls",
        "authors": "Yuanxu Gao, Daniel T. Baptista‐Hon, Kang Zhang",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/mef2.49"
    },
    {
        "id": 11896,
        "title": "Large language models in textual analysis for gesture selection",
        "authors": "Laura Birka Hensel, Nutchanon Yongsatianchot, Parisa Torshizi, Elena Minucci, Stacy Marsella",
        "published": "2023-10-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3577190.3614158"
    },
    {
        "id": 11897,
        "title": "Shaping the Emerging Norms of Using Large Language Models in Social Computing Research",
        "authors": "Hong Shen, Tianshi Li, Toby Jia-Jun Li, Joon Sung Park, Diyi Yang",
        "published": "2023-10-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3584931.3606955"
    },
    {
        "id": 11898,
        "title": "TemporalMed: Advancing Medical Dialogues with Time-Aware Responses in Large Language Models",
        "authors": "Yuyan Chen, Jin Zhao, Zhihao Wen, Zhixu Li, Yanghua Xiao",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3616855.3635860"
    },
    {
        "id": 11899,
        "title": "Annotated dataset creation through large language models for non-english medical NLP",
        "authors": "Johann Frei, Frank Kramer",
        "published": "2023-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jbi.2023.104478"
    },
    {
        "id": 11900,
        "title": "Call for Papers: Special Issue on Challenges and Opportunities in Biomedical Big Data Analysis: From Large Language Models to Clinical Applications",
        "authors": "",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26599/bdma.2023.9020026"
    },
    {
        "id": 11901,
        "title": "This month in JAAD International: March 2024: ChatGPT and large language models in the clinic",
        "authors": "Jonathan Kantor",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jaad.2024.01.001"
    },
    {
        "id": 11902,
        "title": "Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis",
        "authors": "Oscar J. Romero, John Zimmerman, Aaron Steinfeld, Anthony Tomasic",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "This paper explores the integration of two AI subdisciplines employed in the development of artificial agents that exhibit intelligent behavior: Large Language Models (LLMs) and Cognitive Architectures (CAs). We present three integration approaches, each grounded in theoretical models and supported by preliminary empirical evidence. The modular approach, which introduces four models with varying degrees of integration, makes use of chain-of-thought prompting, and draws inspiration from augmented LLMs, the Common Model of Cognition, and the simulation theory of cognition. The agency approach, motivated by the Society of Mind theory and the LIDA cognitive architecture, proposes the formation of agent collections that interact at micro and macro cognitive levels, driven by either LLMs or symbolic components. The neuro-symbolic approach, which takes inspiration from the CLARION cognitive architecture, proposes a model where bottom-up learning extracts symbolic representations from an LLM layer and top-down guidance utilizes symbolic representations to direct prompt engineering in the LLM layer. These approaches aim to harness the strengths of both LLMs and CAs, while mitigating their weaknesses, thereby advancing the development of more robust AI systems. We discuss the tradeoffs and challenges associated with each approach.",
        "link": "http://dx.doi.org/10.1609/aaaiss.v2i1.27706"
    },
    {
        "id": 11903,
        "title": "Large language models for science and medicine",
        "authors": "Amalio Telenti, Michael Auli, Brian L. Hie, Cyrus Maher, Suchi Saria, John P. A. Ioannidis",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "AbstractLarge language models (LLMs) are a type of machine learning model that learn statistical patterns over text, such as predicting the next words in a sequence of text. Both general purpose and task‐specific LLMs have demonstrated potential across diverse applications. Science and medicine have many data types that are highly suitable for LLMs, such as scientific texts (publications, patents and textbooks), electronic medical records, large databases of DNA and protein sequences and chemical compounds. Carefully validated systems that can understand and reason across all these modalities may maximize benefits. Despite the inevitable limitations and caveats of any new technology and some uncertainties specific to LLMs, LLMs have the potential to be transformative in science and medicine.",
        "link": "http://dx.doi.org/10.1111/eci.14183"
    },
    {
        "id": 11904,
        "title": "Can Large Language Models Support Medical Facilitation Work? A Speculative Analysis",
        "authors": "Najeeb Gambo Abdulhamid, Millicent Ochieng, Kalika Bali, Elizabeth Ankrah, Naveena Karusala, Keshet Ronen, Jacki O'Neill",
        "published": "2023-11-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3628096.3628752"
    },
    {
        "id": 11905,
        "title": "Call for Papers: Special Issue on Challenges and Opportunities in Biomedical Big Data Analysis: From Large Language Models to Clinical Applications",
        "authors": "",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26599/bdma.2023.9020026"
    },
    {
        "id": 11906,
        "title": "Context Unlocks Emotions: Text-based Emotion Classification Dataset Auditing with Large Language Models",
        "authors": "Daniel Yang, Aditya Kommineni, Mohammad Alshehri, Nilamadhab Mohanty, Vedant Modi, Jonathan Gratch, Shrikanth Narayanan",
        "published": "2023-9-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/acii59096.2023.10388131"
    },
    {
        "id": 11907,
        "title": "TemporalMed: Advancing Medical Dialogues with Time-Aware Responses in Large Language Models",
        "authors": "Yuyan Chen, Jin Zhao, Zhihao Wen, Zhixu Li, Yanghua Xiao",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3616855.3635860"
    },
    {
        "id": 11908,
        "title": "PromptMaker: Prompt-based Prototyping with Large Language Models",
        "authors": "Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, Carrie J Cai",
        "published": "2022-4-27",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3491101.3503564"
    },
    {
        "id": 11909,
        "title": "CancerGPT for few shot drug pair synergy prediction using large pretrained language models",
        "authors": "Tianhao Li, Sandesh Shetty, Advaith Kamath, Ajay Jaiswal, Xiaoqian Jiang, Ying Ding, Yejin Kim",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "AbstractLarge language models (LLMs) have been shown to have significant potential in few-shot learning across various fields, even with minimal training data. However, their ability to generalize to unseen tasks in more complex fields, such as biology and medicine has yet to be fully evaluated. LLMs can offer a promising alternative approach for biological inference, particularly in cases where structured data and sample size are limited, by extracting prior knowledge from text corpora. Here we report our proposed few-shot learning approach, which uses LLMs to predict the synergy of drug pairs in rare tissues that lack structured data and features. Our experiments, which involved seven rare tissues from different cancer types, demonstrate that the LLM-based prediction model achieves significant accuracy with very few or zero samples. Our proposed model, the CancerGPT (with ~ 124M parameters), is comparable to the larger fine-tuned GPT-3 model (with ~ 175B parameters). Our research contributes to tackling drug pair synergy prediction in rare tissues with limited data, and also advancing the use of LLMs for biological and medical inference tasks.",
        "link": "http://dx.doi.org/10.1038/s41746-024-01024-9"
    },
    {
        "id": 11910,
        "title": "Large language models will not replace healthcare professionals: curbing popular fears and hype",
        "authors": "Arun James Thirunavukarasu",
        "published": "2023-5",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1177/01410768231173123"
    },
    {
        "id": 11911,
        "title": "Harnessing the Power of Prompt-based Techniques for Generating School-Level Questions using Large Language Models",
        "authors": "Subhankar Maity, Aniket Deroy, Sudeshna Sarkar",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3632754.3632755"
    },
    {
        "id": 11912,
        "title": "Using Large Pretrained Language Models for Answering User Queries from Product Specifications",
        "authors": "Kalyani Roy, Smit Shah, Nithish Pai, Jaidam Ramtej, Prajit Nadkarni, Jyotirmoy Banerjee, Pawan Goyal, Surender Kumar",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.ecnlp-1.5"
    },
    {
        "id": 11913,
        "title": "Exploring the opportunities and challenges of using large language models to represent institutional agency in land system modelling",
        "authors": "Yongchao Zeng, Calum Brown, Joanna Raymond, Mohamed Byari, Ronja Hotz, Mark Rounsevell",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract. Public policy institutions play crucial roles in the land system, but modelling their policy-making processes is challenging. Large Language Models (LLMs) offer a novel approach to simulating many different types of human decision-making, including policy choices. This paper aims to investigate the opportunities and challenges that LLMs bring to land system modelling by integrating LLM-powered institutional agents within an agent-based, land use model. Four types of LLM agents are examined, all of which, in the examples presented here, use taxes to steer meat production toward a target level. The LLM agents provide reasoning and policy action output. The agents’ performance is benchmarked against two baseline scenarios: one without policy interventions and another implementing optimal policy actions determined through a genetic algorithm. The findings show that while LLM agents perform better than the non-intervention scenario, they fall short of the performance achieved by optimal policy actions. However, LLM agents demonstrate behaviour and decision-making, marked by policy consistency and transparent reasoning. This includes generating strategies such as incrementalism, delayed policy action, proactive policy adjustments, and balancing multiple stakeholder interests. Agents equipped with experiential learning capabilities excel in achieving policy objectives through progressive policy actions. The order in which reasoning and proposed policy actions are output has a notable effect on the agents’ performance, suggesting that enforced reasoning guides as well as explains LLM decisions. The approach presented here points to promising opportunities and significant challenges. The opportunities include, exploring naturalistic institutional decision-making, handling massive institutional documents, and human-AI cooperation. Challenges mainly lie in the scalability, interpretability, and reliability of LLMs.\n                        ",
        "link": "http://dx.doi.org/10.5194/egusphere-2024-449"
    },
    {
        "id": 11914,
        "title": "MaaSDB: Spatial Databases in the Era of Large Language Models (Vision Paper)",
        "authors": "Jianzhong Qi, Zuqing Li, Egemen Tanin",
        "published": "2023-11-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3589132.3625597"
    },
    {
        "id": 11915,
        "title": "Clinical Accuracy of Large Language Models and Google Search Responses to Postpartum Depression Questions: Cross-Sectional Study",
        "authors": "Emre Sezgin, Faraaz Chekeni, Jennifer Lee, Sarah Keim",
        "published": "2023-9-11",
        "citations": 8,
        "abstract": "",
        "link": "http://dx.doi.org/10.2196/49240"
    },
    {
        "id": 11916,
        "title": "How Large Language Models Will Disrupt Data Management",
        "authors": "Raul Castro Fernandez, Aaron J. Elmore, Michael J. Franklin, Sanjay Krishnan, Chenhao Tan",
        "published": "2023-7",
        "citations": 3,
        "abstract": "Large language models (LLMs), such as GPT-4, are revolutionizing software's ability to understand, process, and synthesize language. The authors of this paper believe that this advance in technology is significant enough to prompt introspection in the data management community, similar to previous technological disruptions such as the advents of the world wide web, cloud computing, and statistical machine learning. We argue that the disruptive influence that LLMs will have on data management will come from two angles. (1) A number of hard database problems, namely, entity resolution, schema matching, data discovery, and query synthesis, hit a ceiling of automation because the system does not fully understand the semantics of the underlying data. Based on large training corpora of natural language, structured data, and code, LLMs have an unprecedented ability to ground database tuples, schemas, and queries in real-world concepts. We will provide examples of how LLMs may completely change our approaches to these problems. (2) LLMs blur the line between predictive models and information retrieval systems with their ability to answer questions. We will present examples showing how large databases and information retrieval systems have complementary functionality.",
        "link": "http://dx.doi.org/10.14778/3611479.3611527"
    },
    {
        "id": 11917,
        "title": "Recovering from Privacy-Preserving Masking with Large Language Models",
        "authors": "Arpita Vats, Zhe Liu, Peng Su, Debjyoti Paul, Yingyi Ma, Yutong Pang, Zeeshan Ahmed, Ozlem Kalinli",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10448234"
    },
    {
        "id": 11918,
        "title": "The Devil is in the Tails: How Long-Tailed Code Distributions Impact Large Language Models",
        "authors": "Xin Zhou, Kisub Kim, Bowen Xu, Jiakun Liu, DongGyun Han, David Lo",
        "published": "2023-9-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ase56229.2023.00157"
    },
    {
        "id": 11919,
        "title": "Large Language Models in Medical Education: Opportunities, Challenges, and Future Directions (Preprint)",
        "authors": "Alaa Abd-alrazaq, Rawan AlSaad, Dari Alhuwail, Arfan Ahmed, Padraig Mark Healy, Syed Latifi, Sarah Aziz, Rafat Damseh, Sadam Alabed Alrazak, Javaid Sheikh",
        "published": "No Date",
        "citations": 1,
        "abstract": "\nUNSTRUCTURED\nThe integration of large language models (LLMs), such as those in the Generative Pre-trained Transformers (GPT) series, into medical education has the potential to transform learning experiences for students and elevate their knowledge, skills, and competence. Drawing on a wealth of professional and academic experience, we propose that LLMs hold promise for revolutionizing medical curriculum development, teaching methodologies, personalized study plans and learning materials, student assessments, and more. However, we also critically examine the challenges that such integration might pose by addressing issues of algorithmic bias, overreliance, plagiarism, misinformation, inequity, privacy, and copyright concerns in medical education. As we navigate the shift from an information-driven educational paradigm to an artificial intelligence (AI)–driven educational paradigm, we argue that it is paramount to understand both the potential and the pitfalls of LLMs in medical education. This paper thus offers our perspective on the opportunities and challenges of using LLMs in this context. We believe that the insights gleaned from this analysis will serve as a foundation for future recommendations and best practices in the field, fostering the responsible and effective use of AI technologies in medical education.\n",
        "link": "http://dx.doi.org/10.2196/preprints.48291"
    },
    {
        "id": 11920,
        "title": "How Does ChatGPT Perform on the Medical Licensing Exams? The Implications of Large Language Models for Medical Education and Knowledge Assessment",
        "authors": "Aidan Gilson, Conrad Safranek, Thomas Huang, Vimig Socrates, Ling Chi, R. Andrew Taylor, David Chartash",
        "published": "No Date",
        "citations": 59,
        "abstract": "ABSTRACTBackgroundChatGPT is a 175 billion parameter natural language processing model which can generate conversation style responses to user input.ObjectiveTo evaluate the performance of ChatGPT on questions within the scope of United States Medical Licensing Examination (USMLE) Step 1 and Step 2 exams, as well as analyze responses for user interpretability.MethodsWe used two novel sets of multiple choice questions to evaluate ChatGPT’s performance, each with questions pertaining to Step 1 and Step 2. The first was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the userbase. The second, was the National Board of Medical Examiners (NBME) Free 120-question exams. After prompting ChatGPT with each question, ChatGPT’s selected answer was recorded, and the text output evaluated across three qualitative metrics: logical justification of the answer selected, presence of information internal to the question, and presence of information external to the question.ResultsOn the four datasets, AMBOSS-Step1, AMBOSS-Step2, NBME-Free-Step1, and NBMEFree-Step2, ChatGPT achieved accuracies of 44%, 42%, 64.4%, and 57.8%. The model demonstrated a significant decrease in performance as question difficulty increased (P=.012) within the AMBOSSStep1 dataset. We found logical justification for ChatGPT’s answer selection was present in 100% of outputs. Internal information to the question was present in>90% of all questions. The presence of information external to the question was respectively 54.5% and 27% lower for incorrect relative to correct answers on the NBME-Free-Step1 and NBME-Free-Step2 datasets (P<=.001).ConclusionChatGPT marks a significant improvement in natural language processing models on the tasks of medical question answering. By performing at greater than 60% threshold on the NBME-FreeStep-1 dataset we show that the model is comparable to a third year medical student. Additionally, due to the dialogic nature of the response to questions, we demonstrate ChatGPT’s ability to provide reasoning and informational context across the majority of answers. These facts taken together make a compelling case for the potential applications of ChatGPT as a medical education tool.",
        "link": "http://dx.doi.org/10.1101/2022.12.23.22283901"
    },
    {
        "id": 11921,
        "title": "Large Language Models in Orthopaedic Trauma",
        "authors": "Lauren A. Merrell, Nina D. Fisher, Kenneth A. Egol",
        "published": "2023-9-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2106/jbjs.23.00395"
    },
    {
        "id": 11922,
        "title": "Utilizing Large Language Models for Named Entity Recognition in Traditional Chinese Medicine against COVID-19 Literature: Comparative Study (Preprint)",
        "authors": "Xu Tong, Nina Smirnova, Sharmila Upadhyaya, Ran Yu, Jack H. Culbert, Chao Sun, Wolfgang Otto, Philipp Mayr",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nRecent advances in large language models (LLMs) have shown remarkable performance on various downstream tasks in zero- and few-shot scenarios, shedding light on named entity recognition (NER) in low-resource domains. Traditional Chinese medicine (TCM) against COVID-19 has been a new research topic and led to niche research literature. NER techniques are crucial for extracting and utilizing the rich knowledge in such literature.\n\n\nOBJECTIVE\nTo explore and compare the performance of ChatGPT and other state-of-the-art LLMs on domain-specific NER tasks covering different entity types and domains in TCM against COVID-19 literature.\n\n\nMETHODS\nWe established a dataset of 389 articles on TCM against COVID-19, and manually annotated 48 of them with 6 types of entities belonging to 3 domains as the ground truth, against which the NER performance of LLMs can be assessed. We then performed NER tasks for the 6 entity types using ChatGPT (GPT-3.5 and GPT-4) and 4 state-of-the-art BERT-based question-answering (QA) models (RoBERTa, MiniLM, PubMedBERT and SciBERT) without prior training on the specific task. A domain fine-tuned model (GSAP-NER) was also applied for a comprehensive comparison on one of the entity types. In the task setup, we considered two different matching methods, namely exact match and fuzzy match, to have better coverage of potential application scenarios. The evaluation metrics we used are Precision, Recall, and F-1 in both exact match and fuzzy match.\n\n\nRESULTS\nThe overall performance of LLMs varied significantly in exact match and fuzzy match. In the fuzzy match, ChatGPT surpassed BERT-based QA models in 5 out of 6 tasks, while in exact match, BERT-based QA models outperformed ChatGPT in 5 out of 6 tasks but with a smaller F-1 difference. GPT-4 showed a significant advantage over other models in fuzzy match, especially on the entity type of TCM formula and the Chinese patent drug (TFD) and ingredient (IG), achieving a higher F-1 score of 0.814 and 0.689, respectively. Although GPT-4 outperformed BERT-based models on entity type of herb (HB, 0.324), target (TG, 0.319), and research method (RM, 0.443), none of the F-1 scores exceeded 0.5. GSAP-NER, outperformed GPT-4 in terms of F-1 by a slight margin (0.45 vs 0.433) on RM. ChatGPT achieved considerably higher recalls than precisions, particularly in the fuzzy match.\n\n\nCONCLUSIONS\nThe NER performance of LLMs is highly dependent on the entity type, and their performance varies across application scenarios. ChatGPT could be a good choice for scenarios where high recall is favored, e.g., for domain novices obtaining an extensive overview of the field. However, for knowledge acquisition in rigorous scenarios, neither ChatGPT nor BERT-based QA models are off-the-shelf tools for professional practitioners. Besides, these BERT-based models are open-source, and thus more accessible for scientific inquiry and hence worth further exploration.\n",
        "link": "http://dx.doi.org/10.2196/preprints.54346"
    },
    {
        "id": 11923,
        "title": "How Can Large Language Models Support the Acquisition of Ethical Competencies in Healthcare?",
        "authors": "Jilles Smids, Maartje Schermer",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15265161.2023.2249853"
    },
    {
        "id": 11924,
        "title": "Comparing Fine-Tuned Transformers and Large Language Models for Sales Call Classification: A Case Study",
        "authors": "Roy Eisenstadt, Abedelkader Asi, Royi Ronen",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3583780.3615509"
    },
    {
        "id": 11925,
        "title": "Supporting the Demand on Mental Health Services with AI-Based Conversational Large Language Models (LLMs)",
        "authors": "Tin Lai, Yukun Shi, Zicong Du, Jiajie Wu, Ken Fu, Yichao Dou, Ziqi Wang",
        "published": "2023-12-22",
        "citations": 0,
        "abstract": "The demand for psychological counselling has grown significantly in recent years, particularly with the global outbreak of COVID-19, which heightened the need for timely and professional mental health support. Online psychological counselling emerged as the predominant mode of providing services in response to this demand. In this study, we propose the Psy-LLM framework, an AI-based assistive tool leveraging large language models (LLMs) for question answering in psychological consultation settings to ease the demand on mental health professions. Our framework combines pre-trained LLMs with real-world professional questions-and-answers (Q&A) from psychologists and extensively crawled psychological articles. The Psy-LLM framework serves as a front-end tool for healthcare professionals, allowing them to provide immediate responses and mindfulness activities to alleviate patient stress. Additionally, it functions as a screening tool to identify urgent cases requiring further assistance. We evaluated the framework using intrinsic metrics, such as perplexity, and extrinsic evaluation metrics, including human participant assessments of response helpfulness, fluency, relevance, and logic. The results demonstrate the effectiveness of the Psy-LLM framework in generating coherent and relevant answers to psychological questions. This article discusses the potential and limitations of using large language models to enhance mental health support through AI technologies.",
        "link": "http://dx.doi.org/10.3390/biomedinformatics4010002"
    },
    {
        "id": 11926,
        "title": "Leveraging Large Language Models for Predicting Microbial Virulence from Protein Structure and Sequence",
        "authors": "Felix Quintana, Todd Treangen, Lydia Kavraki",
        "published": "2023-9-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3584371.3612953"
    },
    {
        "id": 11927,
        "title": "Assessing the performance of large language models in answering questions regarding breast cancer in Chinese context: a cross-sectional study (Preprint)",
        "authors": "Ying Piao, Hongtao Chen, Shihai Wu, Xianming Li, Zihuang Li, Dong Yang",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nLarge language models (LLMs) are deep learning models designed to comprehend and generate meaningful responses, which have gained public attention in recent years.\n\n\nOBJECTIVE\nConsidering that Chinese is one of the most widely spoken languages worldwide, the purpose of this study is to evaluate and compare the performance of LLMs in answering questions regarding breast cancer in Chinese context.\n\n\nMETHODS\nChatGPT, Eenie Bot and ChatGLM were chosen to answer 55 questions related to breast cancer posed by two oncologists. Responses were scored as comprehensive, correct but inadequate, mixed with correct and incorrect data, completely incorrect, or unanswered. The accuracy and length among answers from different models were evaluated using statistical software.\n\n\nRESULTS\nChatGPT answered 55 questions, with 37 (67.3%) comprehensive answers and 5 (9.1%) correct but inadequate answers. Eenie Bot answered 55 questions, with 31 (56.4%) comprehensive answers and 7 (12.7%) correct but inadequate answers. ChatGLM generated 55 answers, with 31 (56.4%) comprehensive answers and 5 (9.1%) correct but inadequate answers. The accuracy of the three LLMs did not exhibit statistically significant. The accuracy of the three models in answering questions regarding breast cancer treatment was the lowest, with an average of 44.4%.\n\n\nCONCLUSIONS\nIn Chinese context, the capabilities of ChatGPT, Eenie Bot, and ChatGLM are similar in answering breast cancer-related questions at present. These three LLMs may have a role as adjunct informational tools for breast cancer patients in Chinese context, offering guidance for general inquiries. However, it is important to approach their responses to specialized questions with caution.\n\n\nCLINICALTRIAL\nThis is not a clinical trial.\n",
        "link": "http://dx.doi.org/10.2196/preprints.53021"
    },
    {
        "id": 11928,
        "title": "Letter to the Editor: Value-based Healthcare: Can Generative Artificial Intelligence and Large Language Models be a Catalyst for Value-based Healthcare?",
        "authors": "Matt A. Porter",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/corr.0000000000003001"
    },
    {
        "id": 11929,
        "title": "Clinical Knowledge and Reasoning Abilities of Large Language Models in Pharmacy: A Comparative Study on the NAPLEX Exam",
        "authors": "Mirana Angel, Anuj Patel, Amal Alachkar, Pierre Baldi",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/snams60348.2023.10375395"
    },
    {
        "id": 11930,
        "title": "Human‐in‐the‐loop: Human involvement in enhancing medical inquiry performance in large language models",
        "authors": "Linping Shu, Qunshan He, Bing Yan, Di Wu, Menglin Wang, Chengshuo Wang, Luo Zhang",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/all.15976"
    },
    {
        "id": 11931,
        "title": "The great Transformer: Examining the role of large language models in the political economy of AI",
        "authors": "Dieuwertje Luitse, Wiebke Denkena",
        "published": "2021-7",
        "citations": 32,
        "abstract": " In recent years, AI research has become more and more computationally demanding. In natural language processing (NLP), this tendency is reflected in the emergence of large language models (LLMs) like GPT-3. These powerful neural network-based models can be used for a range of NLP tasks and their language generation capacities have become so sophisticated that it can be very difficult to distinguish their outputs from human language. LLMs have raised concerns over their demonstrable biases, heavy environmental footprints, and future social ramifications. In December 2020, critical research on LLMs led Google to fire Timnit Gebru, co-lead of the company’s AI Ethics team, which sparked a major public controversy around LLMs and the growing corporate influence over AI research. This article explores the role LLMs play in the political economy of AI as infrastructural components for AI research and development. Retracing the technical developments that have led to the emergence of LLMs, we point out how they are intertwined with the business model of big tech companies and further shift power relations in their favour. This becomes visible through the Transformer, which is the underlying architecture of most LLMs today and started the race for ever bigger models when it was introduced by Google in 2017. Using the example of GPT-3, we shed light on recent corporate efforts to commodify LLMs through paid API access and exclusive licensing, raising questions around monopolization and dependency in a field that is increasingly divided by access to large-scale computing power. ",
        "link": "http://dx.doi.org/10.1177/20539517211047734"
    },
    {
        "id": 11932,
        "title": "Artificial intelligence enabled ChatGPT and large language models in drug target discovery, drug discovery, and development",
        "authors": "Chiranjib Chakraborty, Manojit Bhattacharya, Sang-Soo Lee",
        "published": "2023-9",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.omtn.2023.08.009"
    },
    {
        "id": 11933,
        "title": "Can artificial intelligence-strengthened ChatGPT or other large language models transform nucleic acid research?",
        "authors": "Srijan Chatterjee, Manojit Bhattacharya, Sang-Soo Lee, Chiranjib Chakraborty",
        "published": "2023-9",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.omtn.2023.06.019"
    },
    {
        "id": 11934,
        "title": "Small Language Models Fine-tuned to Coordinate Larger Language Models improve Complex Reasoning",
        "authors": "Gurusha Juneja, Subhabrata Dutta, Soumen Chakrabarti, Sunny Manchanda, Tanmoy Chakraborty",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.225"
    },
    {
        "id": 11935,
        "title": "AlphaMWE-Arabic: Arabic Edition of Multilingual Parallel Corpora with Multiword Expression Annotations",
        "authors": "Najet Hadj Mohamed,  , Malak Rassem, Lifeng Han, Goran Nenadic,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_050"
    },
    {
        "id": 11936,
        "title": "Improving Conversation-Context Language Models with Multiple Spoken Language Understanding Models",
        "authors": "Ryo Masumura, Tomohiro Tanaka, Atsushi Ando, Hosana Kamiyama, Takanobu Oba, Satoshi Kobashikawa, Yushi Aono",
        "published": "2019-9-15",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2019-1534"
    },
    {
        "id": 11937,
        "title": "Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction",
        "authors": "Masahiro Kaneko",
        "published": "2020-9-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.27.683"
    },
    {
        "id": 11938,
        "title": "Foundation Models for Text Generation",
        "authors": "Gerhard Paaß, Sven Giesselbach",
        "published": "2023",
        "citations": 0,
        "abstract": "AbstractThis chapter discusses Foundation Models for Text Generation. This includes systems for Document Retrieval, which accept a query and return an ordered list of text documents from a document collection, often evaluating the similarity of embeddings to retrieve relevant text passages. Question Answering systems are given a natural language question and must provide an answer, usually in natural language. Machine Translation models take a text in one language and translate it into another language. Text Summarization systems receive a long document and generate a short summary covering the most important contents of the document. Text Generation models use an autoregressive Language Model to generate a longer story, usually starting from an initial text input. Dialog systems have the task of conducting a dialog with a human partner, typically not limited to a specific topic.",
        "link": "http://dx.doi.org/10.1007/978-3-031-23190-2_6"
    },
    {
        "id": 11939,
        "title": "Integrating Prior Knowledge from Meta-Learning and Large Language Models for Cold-Start Recommendation",
        "authors": "Yu Li, Yixiao Liu, Tetsuya Furukawa",
        "published": "2023-10-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5109/7157997"
    },
    {
        "id": 11940,
        "title": "The Brain Tells a Story: Unveiling Distinct Representations of Semantic Content in Speech, Objects, and Stories in the Human Brain with Large Language Models",
        "authors": "Yuko Nakagi, Takuya Matsuyama, Naoko Koide-Majima, Hiroto Yamaguchi, Rieko Kubo, Shinji Nishimoto, Yu Takagi",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractIn recent studies, researchers have utilized Large Language Models (LLMs) to investigate semantic representation within the brain. However, in many of these studies, the researchers often examined various semantic information contents separately, such as speech content, objects in scenes, and background stories. To quantitatively evaluate the contribution of various semantic contents in the brain, we recorded brain activity using functional magnetic resonance imaging (fMRI) while participants watched a total of 8.3 hours of videos of dramas or movies. Importantly, we densely annotated these videos at multiple semantic levels related to video contents, which allowed us to extract latent representations of LLMs for a range of semantic contents. We show that LLMs explain human brain activity more accurately than traditional language models, particularly for the high-level background story. Additionally, we show that distinct brain regions correspond to different semantic contents, thereby underscoring the importance of simultaneously modeling various levels of semantic contents. We will make our fMRI dataset publicly available for future research as a biological metric of the alignment between LLMs and humans.",
        "link": "http://dx.doi.org/10.1101/2024.02.06.579077"
    },
    {
        "id": 11941,
        "title": "General purpose large language models match human performance on gastroenterology board exam self-assessments",
        "authors": "Shuhaib Ali, Omer Shahab, Reem Al Shabeeb, Farah Ladak, Jamie O. Yang, Girish Nadkarni, Juan Echavarria, Sumbal Babar, Aasma Shaukat, Ali Soroush, Bara El Kurdi",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractIntroductionWhile general-purpose large language models(LLMs) were able to pass USMLE-style examinations, their ability to perform in a specialized context, like gastroenterology, is unclear. In this study, we assessed the performance of three widely available LLMs: PaLM-2, GPT-3.5, and GPT-4 on the most recent ACG self-assessment(2022), utilizing both a basic and a prompt-engineered technique.MethodsWe interacted with the chat interfaces of PaLM-2, GPT-3.5, and GPT-4. We first applied a basic prompt approach, providing each exam question and answer text with minimalist text descriptions of any images. For the engineered approach, we added additional context and instructions. We assessed each model-prompt combination in terms of overall and difficulty-stratified performance and compared this to average human performance. We also evaluated each model’s self-assessed uncertainty. The highest scoring model-prompt combination was further assessed on the 2021 exam. We also assessed the impact of image descriptions on our findings.ResultsUsing a basic prompt, PaLM-2, GPT-3.5, and GPT-4 achieved scores of 32.6%, 55.3%, and 68.9% respectively. With the engineered prompt, scores improved to 42.7%, 65.2%, and 76.3% respectively. Testing GPT-4 on the ACG-2021 exam yielded a similar score(75.3%). GPT-4 scores matched the average score for human test-takers reported by ACG(75.7%). GPT-4 showed a capability to self-assess its confidence accurately in the context of a multiple-choice exam with its confidence estimates falling within 5% of its actual performance. Excluding image-based questions didn’t change the primary findings.DiscussionOur study highlights the capability of GPT-4 to answer subspecialty board-exam questions at a level commensurate with the average human test-taker. The results confirm that prompt-engineering can enhance LLMs’ performance on medical reasoning tasks. We also show GPT-4 can provide insightful measures of uncertainty in the setting of board-style multiple-choice questions, alerting users to low-quality answers. Future studies of LLMs in gastroenterology should incorporate prompt-engineering to maximize model capabilities.WHAT IS KNOWNState of the Art large language models like GPT-4 and PaLM-Med 2 have achieved above average performance on USMLE board examinations.In a previous study using basic model prompt instructions, GPT 3.5 and GPT 4 did not pass the 2021 and 2022 ACG self-assessment exams.WHAT IS NEW HEREOptimizing large language model prompt instructions improved the performance of chat-based GPT-3.5, GPT-4, and PaLM 2 on the ACG self-assessment exams.With optimized prompt instructions, chat-based GPT-4 performed at the level of average human test takers on ACG-self assessment examinations and achieved a passing score.Chat-based GPT-4 self-reported confidence levels correlated with correct answer rates on the ACG-self assessment examinations.",
        "link": "http://dx.doi.org/10.1101/2023.09.21.23295918"
    },
    {
        "id": 11942,
        "title": "THE POTENTIAL FOR LARGE LANGUAGE MODELS TO PERSONALIZE PATIENT ORIENTED CLINICAL INFORMATION TO RECOMMENDED READING LEVELS",
        "authors": "Joseph Chervenak, Miranda Blanco-Breindel, Harry J. Lieman, Sangita K. Jindal",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.fertnstert.2023.08.760"
    },
    {
        "id": 11943,
        "title": "Large Language Models: A Comprehensive Survey of its Applications, Challenges, Limitations, and Future Prospects",
        "authors": "Muhammad Usman Hadi, qasem al tashi, Rizwan Qureshi, Abbas Shah, amgad muneer, Muhammad Irfan, Anas Zafar, Muhammad Bilal Shaikh, Naveed Akhtar, Jia Wu, Seyedali Mirjalili",
        "published": "No Date",
        "citations": 1,
        "abstract": "<p>Within the vast expanse of computerized language processing, a revolutionary entity known as Large Language Models (LLMs) has emerged, wielding immense power in its capacity to comprehend intricate linguistic patterns and conjure coherent and contextually fitting responses. Large language models (LLMs) are a type of artificial intelligence (AI) that have emerged as powerful tools for a wide range of tasks, including natural language processing (NLP), machine translation, and question-answering. This survey paper provides a comprehensive overview of LLMs, including their history, architecture, training methods, applications, and challenges. The paper begins by discussing the fundamental concepts of generative AI and the architecture of generative pre- trained transformers (GPT). It then provides an overview of the history of LLMs, their evolution over time, and the different training methods that have been used to train them. The paper then discusses the wide range of applications of LLMs, including medical, education, finance, and engineering. It also discusses how LLMs are shaping the future of AI and how they can be used to solve real-world problems. The paper then discusses the challenges associated with deploying LLMs in real-world scenarios, including ethical considerations, model biases, interpretability, and computational resource requirements. It also highlights techniques for enhancing the robustness and controllability of LLMs, and addressing bias, fairness, and generation quality issues. Finally, the paper concludes by highlighting the future of LLM research and the challenges that need to be addressed in order to make LLMs more reliable and useful. This survey paper is intended to provide researchers, practitioners, and enthusiasts with a comprehensive understanding of LLMs, their evolution, applications, and challenges. By consolidating the state-of-the-art knowledge in the field, this survey serves as a valuable resource for further advancements in the development and utilization of LLMs for a wide range of real-world applications. The GitHub repo for this project is available at https://github.com/anas-zafar/LLM-Survey</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23589741.v3"
    },
    {
        "id": 11944,
        "title": "Technology And Globalisation: How Social Media (Narrow Artificial Intelligence) Algorithms and Large Language Models by Internet Companies Have Replaced the Main Stream Media as Agenda Setters For the Global Culture",
        "authors": "Moses Sichach",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4580284"
    },
    {
        "id": 11945,
        "title": "Large language models in the labyrinth: Possibility spaces and moral constraints",
        "authors": "Victor Møller Poulsen, Simon DeDeo",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1177/27538699231206210"
    },
    {
        "id": 11946,
        "title": "Image Information Prompt: Tips for Learning Large Language Models",
        "authors": "Yin Zhang",
        "published": "2024-1-31",
        "citations": 0,
        "abstract": "Sentiment text classification is a natural language processing technique for recognizing and extracting subjective information in text, such as emotions, attitudes, and opinions. Traditional models such as BERT and XLNet have achieved brilliant results in text classification problems. With the rise of large language model technology, using generative large models to improve text classification accuracy has become a new research direction. However, compared with traditional classification models, large language models have a slight disadvantage in language classification tasks. In this paper, we propose a prompt-based approach to enhance the accuracy of large language models for text classification using image prompt information on multimodal datasets. First, we illustrate the principle of consistency between image and textual information. Second, we propose a multimodal framework for sentiment analysis of images and text, which realizes the prediction of sentiment tendency for both image and textual data by injecting the image prompt information into the text and into the Large Language Model. Finally, we designed experiments and evaluated them using real multimodal datasets to verify the effectiveness and accuracy of the framework.",
        "link": "http://dx.doi.org/10.3233/atde231197"
    },
    {
        "id": 11947,
        "title": "Against Opacity: Explainable AI and Large Language Models for Effective Digital Advertising",
        "authors": "Qi Yang, Marlo Ongpin, Sergey Nikolenko, Alfred Huang, Aleksandr Farseev",
        "published": "2023-10-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3581783.3612817"
    },
    {
        "id": 11948,
        "title": "Enabling Synergistic Knowledge Sharing and Reasoning in Large Language Models with Collaborative Multi-Agents",
        "authors": "Ayushman Das, Shu-Ching Chen, Mei-Ling Shyu, Saad Sadiq",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cic58953.2023.00021"
    },
    {
        "id": 11949,
        "title": "ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning",
        "authors": "Viet Lai, Nghia Ngo, Amir Pouran Ben Veyseh, Hieu Man, Franck Dernoncourt, Trung Bui, Thien Nguyen",
        "published": "2023",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.878"
    },
    {
        "id": 11950,
        "title": "Using large language models to generate silicon samples in consumer and marketing research: Challenges, opportunities, and guidelines",
        "authors": "Marko Sarstedt, Susanne J. Adler, Lea Rau, Bernd Schmitt",
        "published": "2024-2-10",
        "citations": 0,
        "abstract": "AbstractShould consumer researchers employ silicon samples and artificially generated data based on large language models, such as GPT, to mimic human respondents' behavior? In this paper, we review recent research that has compared result patterns from silicon and human samples, finding that results vary considerably across different domains. Based on these results, we present specific recommendations for silicon sample use in consumer and marketing research. We argue that silicon samples hold particular promise in upstream parts of the research process such as qualitative pretesting and pilot studies, where researchers collect external information to safeguard follow‐up design choices. We also provide a critical assessment and recommendations for using silicon samples in main studies. Finally, we discuss ethical issues of silicon sample use and present future research avenues.",
        "link": "http://dx.doi.org/10.1002/mar.21982"
    },
    {
        "id": 11951,
        "title": "A medical question answering system using large language models and knowledge graphs",
        "authors": "Quan Guo, Shuai Cao, Zhang Yi",
        "published": "2022-11",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/int.22955"
    },
    {
        "id": 11952,
        "title": "Calculon: a methodology and tool for high-level co-design of systems and large language models",
        "authors": "Mikhail Isaev, Nic Mcdonald, Larry Dennison, Richard Vuduc",
        "published": "2023-11-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3581784.3607102"
    },
    {
        "id": 11953,
        "title": "Large Language Models Empowered Autonomous Edge AI for Connected Intelligence",
        "authors": "Yifei Shen, Jiawei Shao, Xinjie Zhang, Zehong Lin, Hao Pan, Dongsheng Li, Jun Zhang, Khaled B. Letaief",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mcom.001.2300550"
    },
    {
        "id": 11954,
        "title": "Clear Skies Ahead: Optimizing Operations Through Large Language Models and AI to Reduce Emissions and Costs for a Regional NOC",
        "authors": "Jimmy Thatcher, Assilkhan Amankhan, Morgan Eldred, Abhijith Suboyin, Carsten Sonne-Schmidt, Abdul Rehman",
        "published": "2024-2-12",
        "citations": 0,
        "abstract": "Abstract\nThis manuscript presents an industrial case study and analysis leveraging Artificial Intelligence (AI), Large Language Models (LLMs) and advanced analytics to optimize offshore operations for a regional NOC while reducing the emission footprint and costs. The scope of this study also included a detailed analysis of potential challenges and benefits of using LLMs.\nAlong with industrial data, this case study includes a comprehensive literature review on helicopter transportation, safety, and environmental impact, as well as explores strategies to improve overall operations, and to reduce GHG emissions. In conjunction with analysis of relevant data sources, data on GHG emissions from helicopter transportation were also collected and analyzed. The potential benefits of schedule optimization were evaluated, including leveraging the capabilities of LLMs for reductions in manpower, flight time, fuel consumption, and GHG emissions. Various optimization algorithms for schedule were also reviewed and compared.\nResults from the study indicate that implementation of the presented strategies including LLM models not only improve productivity & safety, but also reduce emissions and fuel consumption resulting in cost savings for helicopter operators. For instance, LLMs assisted in making bookings and querying schedules within minimal intervention resulting in cost savings due to reduced reliance on human labour; increased efficiency through automation; improved accuracy through elimination of manual data entry and automated data validation; coupled with enhanced data analysis to provide valuable insights for real-time decision making. Further reductions were also achieved through modifying the helicopter schedule to decrease ground idle time, enhancing flight routing, and optimizing the speed and altitude of the helicopter. The industrial case study indicates that these strategies could potentially reduce CO2 emissions by up to 18% per flight while reducing the overall cost by 24%.\nThe conclusion drawn from the analysis is that such optimizations are a promising approach to reduction in costs and emissions with increased efficiency and accuracy. This research offers novel insights into the potential application of multi-layered AI and LLMs to optimize helicopter operations without compromising on sustainable practices. This study offers valuable information for the aviation industry looking to enhance operations sustainably through a comprehensive evaluation of the environmental impact of practices in place and examining the efficacy of optimization measures.\nThe study's conclusions have relevance for anyone working in the aviation sector since they show that adopting sustainable techniques to lessen their influence on the environment is both feasible and beneficial. By highlighting the potential of multi-layered AI and LLMs to optimize operations including offshore transportation, this paper offers a valuable contribution to the ongoing effort to improve current practices and sustainability through digital technologies.",
        "link": "http://dx.doi.org/10.2523/iptc-23334-ms"
    },
    {
        "id": 11955,
        "title": "Are ChatGPT and large language models “the answer” to bringing us closer to systematic review automation?",
        "authors": "Riaz Qureshi, Daniel Shaughnessy, Kayden A. R. Gill, Karen A. Robinson, Tianjing Li, Eitan Agai",
        "published": "2023-4-29",
        "citations": 32,
        "abstract": "AbstractIn this commentary, we discuss ChatGPT and our perspectives on its utility to systematic reviews (SRs) through the appropriateness and applicability of its responses to SR related prompts. The advancement of artificial intelligence (AI)-assisted technologies leave many wondering about the current capabilities, limitations, and opportunities for integration AI into scientific endeavors. Large language models (LLM)—such as ChatGPT, designed by OpenAI—have recently gained widespread attention with their ability to respond to various prompts in a natural-sounding way. Systematic reviews (SRs) utilize secondary data and often require many months and substantial financial resources to complete, making them attractive grounds for developing AI-assistive technologies. On February 6, 2023, PICO Portal developers hosted a webinar to explore ChatGPT’s responses to tasks related to SR methodology. Our experience from exploring the responses of ChatGPT suggest that while ChatGPT and LLMs show some promise for aiding in SR-related tasks, the technology is in its infancy and needs much development for such applications. Furthermore, we advise that great caution should be taken by non-content experts in using these tools due to much of the output appearing, at a high level, to be valid, while much is erroneous and in need of active vetting.",
        "link": "http://dx.doi.org/10.1186/s13643-023-02243-z"
    },
    {
        "id": 11956,
        "title": "Role Models in Language Learning: Results of a Large-Scale International Survey",
        "authors": "Christine Muir, Zoltán Dörnyei, Svenja Adolphs",
        "published": "2021-2-22",
        "citations": 17,
        "abstract": "Abstract\nRole models can exert considerable influence in shaping individuals’ values, attitudes, and beliefs. A large body of work in the social sciences has investigated the influence of celebrity role models, and in the context of education, several disciplines have a rich research history in this area (e.g. medical education). However, in the context of second language acquisition, research centred on role models has largely remained on the periphery. This study presents a large-scale international survey investigating the role models of English language learners. With data collected from 8,472 participants, analysis investigated whether these learners had English language role models, who the role models were and what characteristics learners valued in them, and investigated systematic variation among subgroups. Results showed that 68 per cent of respondents reported having an English language role model, and four key role model dimensions emerged: overall command of English, paralinguistic features, personal attributes and accent/variety of English. We argue that role modelling may be a highly influential component of the psychological context of second-language acquisition, and conclude by highlighting several valuable areas for future research.",
        "link": "http://dx.doi.org/10.1093/applin/amz056"
    },
    {
        "id": 11957,
        "title": "AugSumm: Towards Generalizable Speech Summarization Using Synthetic Labels from Large Language Models",
        "authors": "Jee-Weon Jung, Roshan Sharma, William Chen, Bhiksha Raj, Shinji Watanabe",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447328"
    },
    {
        "id": 11958,
        "title": "Knowledge Acquired by Foundation Models",
        "authors": "Gerhard Paaß, Sven Giesselbach",
        "published": "2023",
        "citations": 1,
        "abstract": "AbstractDuring pre-training, a Foundation Model is trained on an extensive collection of documents and learns the distribution of words in correct and fluent language. In this chapter, we investigate the knowledge acquired by PLMs and the larger Foundation Models. We first discuss the application of Foundation Models to specific benchmarks to test knowledge in a large number of areas and examine if the models are able to derive correct conclusions from the content. Another group of tests assesses Foundation Models by completing text and by applying specific probing classifiers that consider syntactic knowledge, semantic knowledge, and logical reasoning separately. Finally, we investigate if the benchmarks are reliable and reproducible, i.e. whether they actually test the targeted properties and yield the same performance values when repeated by other researchers.",
        "link": "http://dx.doi.org/10.1007/978-3-031-23190-2_4"
    },
    {
        "id": 11959,
        "title": "Foundation Models for Information Extraction",
        "authors": "Gerhard Paaß, Sven Giesselbach",
        "published": "2023",
        "citations": 0,
        "abstract": "AbstractIn the chapter we consider Information Extraction approaches that automatically identify structured information in text documents and comprise a set of tasks. The Text Classification task assigns a document to one or more pre-defined content categories or classes. This includes many subtasks such as language identification, sentiment analysis, etc. The Word Sense Disambiguation task attaches a predefined meaning to each word in a document. The Named Entity Recognition task identifies named entities in a document. An entity is any object or concept mentioned in the text and a named entity is an entity that is referred to by a proper name. The Relation Extraction task aims to identify the relationship between entities extracted from a text. This covers many subtasks such as coreference resolution, entity linking, and event extraction. Most demanding is the joint extraction of entities and relations from a text. Traditionally, relatively small Pre-trained Language Models have been fine-tuned to these task and yield high performance, while larger Foundation Models achieve high scores with few-shot prompts, but usually have not been benchmarked.",
        "link": "http://dx.doi.org/10.1007/978-3-031-23190-2_5"
    },
    {
        "id": 11960,
        "title": "Exploring Human-Like Translation Strategy with Large Language\n                    Models",
        "authors": "Zhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shuming Shi, Xing Wang",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "Abstract\nLarge language models (LLMs) have demonstrated impressive capabilities in general scenarios, exhibiting a level of aptitude that approaches, in some aspects even surpasses, human-level intelligence. Among their numerous skills, the translation abilities of LLMs have received considerable attention. Compared to typical machine translation that focuses solely on source-to-target mapping, LLM-based translation can potentially mimic the human translation process, which might take preparatory steps to ensure high-quality translation. This work explores this possibility by proposing the MAPS framework, which stands for Multi-Aspect Prompting and Selection. Specifically, we enable LLMs first to analyze the given source sentence and induce three aspects of translation-related knowledge (keywords, topics, and relevant demonstrations) to guide the final translation process. Moreover, we employ a selection mechanism based on quality estimation to filter out noisy and unhelpful knowledge. Both automatic (3 LLMs × 11 directions × 2 automatic metrics) and human evaluation (preference study and MQM) demonstrate the effectiveness of MAPS. Further analysis shows that by mimicking the human translation process, MAPS reduces various translation errors such as hallucination, ambiguity, mistranslation, awkward style, untranslated text, and omission. Source code is available at https://github.com/zwhe99/MAPS-mt.",
        "link": "http://dx.doi.org/10.1162/tacl_a_00642"
    },
    {
        "id": 11961,
        "title": "Identifying Signs and Symptoms of Urinary Tract Infection from Emergency Department Clinical Notes Using Large Language Models",
        "authors": "Mark Iscoe, Vimig Socrates, Aidan Gilson, Ling Chi, Huan Li, Thomas Huang, Thomas Kearns, Rachelle Perkins, Laura Khandjian, R. Andrew Taylor",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractObjectivesSymptom characterization is critical to urinary tract infection (UTI) diagnosis, but identification of symptoms from the electronic health record (EHR) is challenging, limiting large-scale research, public health surveillance, and EHR-based clinical decision support. We therefore developed and compared two natural language processing (NLP) models to identify UTI symptoms from unstructured emergency department (ED) notes.MethodsThe study population consisted of patients aged ≥ 18 who presented to the (ED) in a north-eastern United States health system between June 2013 and August 2021 and had a urinalysis performed. We annotated a random subset of 1,250 ED clinician notes from these visits for a list of 17 UTI symptoms. We then developed two task-specific large language models (LLMs) to perform the task of named entity recognition (NER): a convolutional neural network (CNN)-based model (SpaCy) and a transformer-based model designed to process longer documents (Longformer). Models were trained on 1,000 notes and tested on a holdout set of 250 notes. We compared model performance (precision, recall, F1 measure) at identifying the presence or absence of UTI symptoms at the note level.Results8,135 entities were identified in 1,250 notes; 83.6% of notes included at least one entity. Overall F1 measure for note-level symptom identification weighted by entity frequency was 0.84 for the SpaCy model and 0.88 for the Longformer model. F1 measure for identifying presence or absence of any UTI symptom in a clinical note was 0.96 (232/250 correctly classified) for the SpaCy model and 0.98 (240/250 correctly classified) for the Longformer model.ConclusionsThe study demonstrated the utility of LLMs and transformer-based models in particular for extracting UTI symptoms from unstructured ED clinical notes; models were highly accurate for detecting the presence or absence of any UTI symptom on the note level, with variable performance for individual symptoms.",
        "link": "http://dx.doi.org/10.1101/2023.10.20.23297156"
    },
    {
        "id": 11962,
        "title": "Generating Domain-Specific Programs for Diagram Authoring with Large Language Models",
        "authors": "Rijul Jain, Wode Ni, Joshua Sunshine",
        "published": "2023-10-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3618305.3623612"
    },
    {
        "id": 11963,
        "title": "Large Scale Sequence-to-Sequence Models for Clinical Note Generation from Patient-Doctor Conversations",
        "authors": "Gagandeep Singh, Yue Pan, Jesus Andres-Ferrer, Miguel Del-Agua, Frank Diehl, Joel Pinto, Paul Vozila",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.clinicalnlp-1.18"
    },
    {
        "id": 11964,
        "title": "A note to our authors: Histochemistry and Cell Biology implements guidelines for the use of large language models (including ChatGPT)",
        "authors": "Jürgen Roth",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00418-023-02245-x"
    },
    {
        "id": 11965,
        "title": "P22 Disrupting Health Economics: Automating Network Meta-Analyses With AI and Large Language Models",
        "authors": "T. Reason, B. Malcolm, S. Klijn, J. Langham, A. Gimblett, E. Benbow",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jval.2023.09.031"
    },
    {
        "id": 11966,
        "title": "Artificial Intelligence in Surgical Documentation: A Critical Review of the Role of Large Language Models",
        "authors": "Aaron Lawson McLean",
        "published": "2023-12",
        "citations": 3,
        "abstract": "AbstractThis article provides a critical analysis of the application of the advanced language\nmodel, GPT-4, in generating surgical operative notes, with a focus on its use in\nophthalmology as presented by Waisberg et al. The discussion underscores the\ninherent complexity and specificity of operative notes, the issue of accountability, and\nthe potential data protection issues associated with the use of AI in healthcare. The\nletter emphasizes the need for a more comprehensive understanding of the\ncomplexities involved in applying AI in healthcare and calls for a more nuanced and\nresponsible approach to the integration of AI in surgical documentation.",
        "link": "http://dx.doi.org/10.1007/s10439-023-03282-2"
    },
    {
        "id": 11967,
        "title": "Using Large Language Models to Translate Machine Results to Human Results",
        "authors": "Jonathan W Stubblefield, Trishna Niraula",
        "published": "2023-9-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3584371.3613036"
    },
    {
        "id": 11968,
        "title": "Large language models show human-like content biases in transmission chain experiments",
        "authors": "Alberto Acerbi, Joseph M. Stubbersfield",
        "published": "2023-10-31",
        "citations": 5,
        "abstract": "As the use of large language models (LLMs) grows, it is important to examine whether they exhibit biases in their output. Research in cultural evolution, using transmission chain experiments, demonstrates that humans have biases to attend to, remember, and transmit some types of content over others. Here, in five preregistered experiments using material from previous studies with human participants, we use the same, transmission chain-like methodology, and find that the LLM ChatGPT-3 shows biases analogous to humans for content that is gender-stereotype-consistent, social, negative, threat-related, and biologically counterintuitive, over other content. The presence of these biases in LLM output suggests that such content is widespread in its training data and could have consequential downstream effects, by magnifying preexisting human tendencies for cognitively appealing and not necessarily informative, or valuable, content.",
        "link": "http://dx.doi.org/10.1073/pnas.2313790120"
    },
    {
        "id": 11969,
        "title": "Large Language Models: A Comprehensive Survey of its Applications, Challenges, Limitations, and Future Prospects",
        "authors": "Muhammad Usman Hadi, qasem al tashi, Rizwan Qureshi, Abbas Shah, amgad muneer, Muhammad Irfan, Anas Zafar, Muhammad Bilal Shaikh, Naveed Akhtar, Jia Wu, Seyedali Mirjalili",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Within the vast expanse of computerized language processing, a revolutionary entity known as Large Language Models (LLMs) has emerged, wielding immense power in its capacity to comprehend intricate linguistic patterns and conjure coherent and contextually fitting responses. Large language models (LLMs) are a type of artificial intelligence (AI) that have emerged as powerful tools for a wide range of tasks, including natural language processing (NLP), machine translation, and question-answering. This survey paper provides a comprehensive overview of LLMs, including their history, architecture, training methods, applications, and challenges. The paper begins by discussing the fundamental concepts of generative AI and the architecture of generative pre- trained transformers (GPT). It then provides an overview of the history of LLMs, their evolution over time, and the different training methods that have been used to train them. The paper then discusses the wide range of applications of LLMs, including medical, education, finance, and engineering. It also discusses how LLMs are shaping the future of AI and how they can be used to solve real-world problems. The paper then discusses the challenges associated with deploying LLMs in real-world scenarios, including ethical considerations, model biases, interpretability, and computational resource requirements. It also highlights techniques for enhancing the robustness and controllability of LLMs, and addressing bias, fairness, and generation quality issues. Finally, the paper concludes by highlighting the future of LLM research and the challenges that need to be addressed in order to make LLMs more reliable and useful. This survey paper is intended to provide researchers, practitioners, and enthusiasts with a comprehensive understanding of LLMs, their evolution, applications, and challenges. By consolidating the state-of-the-art knowledge in the field, this survey serves as a valuable resource for further advancements in the development and utilization of LLMs for a wide range of real-world applications. The GitHub repo for this project is available at https://github.com/anas-zafar/LLM-Survey</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23589741"
    },
    {
        "id": 11970,
        "title": "Social Media Images Can Predict Suicide Risk Using Interpretable Large Language-Vision Models",
        "authors": "Yael Badian, Yaakov Ophir, Refael Tikochinski, Nitay Calderon, Anat Brunstein Klomek, Eyal Fruchter, Roi Reichart",
        "published": "2023-11-29",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4088/jcp.23m14962"
    },
    {
        "id": 11971,
        "title": "Large language models for structured reporting in radiology: performance of GPT-4, ChatGPT-3.5, Perplexity and Bing",
        "authors": "Carlo A. Mallio, Andrea C. Sertorio, Caterina Bernetti, Bruno Beomonte Zobel",
        "published": "2023-5-29",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11547-023-01651-4"
    },
    {
        "id": 11972,
        "title": "Large language models (LLM) and ChatGPT: a medical student perspective",
        "authors": "Arosh S. Perera Molligoda Arachchige",
        "published": "2023-7",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00259-023-06227-y"
    },
    {
        "id": 11973,
        "title": "Use of Large Language Models to Predict Neuroimaging",
        "authors": "Lleayem Nazario-Johnson, Hossam A. Zaki, Glenn A. Tung",
        "published": "2023-10",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jacr.2023.06.008"
    },
    {
        "id": 11974,
        "title": "Enhancing Real-World Data Extraction in Clinical Research: Evaluating the Impact of the Implementation of Large Language Models in Hospital Settings",
        "authors": "Bin Wang, Junkai Lai, Han Cao, Feifei Jin, Qiang Li, Mingkun Tang, Chen Yao, Ping Zhang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground\n The application of artificial intelligence (AI) and large language models (LLMs) in the medical sector has become increasingly common. The widespread adoption of electronic health record (EHR) platforms has created demand for the efficient extraction and analysis of unstructured data, which are known as real-world data (RWD). The rapid increase in free-text data in the medical context has highlighted the significance of natural language processing (NLP) with regard to extracting insights from EHRs, identifying this process as a crucial tool in clinical research. The development of LLMs that are specifically designed for biomedical and clinical text mining has further enhanced the capabilities of NLP in this domain. Despite these advancements, the utilization of LLMs specifically in clinical research remains limited.\nObjective\n This study aims to assess the feasibility and impact of the implementation of an LLM for RWD extraction in hospital settings. The primary focus of this research is on the effectiveness of LLM-driven data extraction as compared to that of manual processes associated with the electronic source data repositories (ESDR) system. Additionally, the study aims to identify challenges emerging in the context of LLM implementation and to obtain practical insights from the field.\nMethods\n The researchers developed the ESDR system, which integrates LLMs, electronic case report forms (eCRFs) and EHRs. The Paroxysmal Atrial Tachycardia Project, a single-center retrospective cohort study, served as a pilot case. This study involved deploying the ESDR system on the hospital local area network (LAN). Localized LLM deployment utilized the Chinese open-source ChatGLM model. The research design compared the AI-assisted process with manual processes associated with the ESDR in terms of accuracy rates and time allocation. Five eCRF forms, predominantly including free-text content, were evaluated; the relevant data focused on 630 subjects, in which context a 10% sample (63 subjects) was used for assessment. Data collection involved electronic medical and prescription records collected from 13 departments.\nResults\n While the discharge medication form achieved 100% data completeness, some free-text forms exhibited data completeness rates below 20%. The AI-assisted process was associated with an estimated efficiency improvement of 80.7% in eCRF data transcription time. The AI data extraction accuracy rate was 94.84%, and errors were related mainly to localized Chinese clinical terminology. The study identified challenges pertaining to prompt design, prompt output consistency, and prompt output verification. Addressing limitations in terms of clinical terminology and output inconsistency entails integrating local terminology libraries and offering clear examples of output format. Output verification can be enhanced by probing the model's reasoning, assessing confidence on a scale, and highlighting relevant text snippets. These measures mitigate challenges that can impede our understanding of the model's decision-making process with regard to extensive free-text documents.\nConclusions\n This research enriches academic discourse on LLMs in the context of clinical research and provides actionable recommendations for the practical implementation of LLMs for RWD extraction. By offering insights into LLM integration in the context of clinical research systems, the study contributes to the task of establishing a secure and efficient framework for digital clinical research. The continuous evolution and optimization of LLM technology are crucial for its seamless integration into the broader landscape of clinical research.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3644810/v2"
    },
    {
        "id": 11975,
        "title": "Large Language Models for Software Engineering: Survey and Open Problems",
        "authors": "Angela Fan, Beliz Gokkaya, Mark Harman, Mitya Lyubarskiy, Shubho Sengupta, Shin Yoo, Jie M. Zhang",
        "published": "2023-5-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icse-fose59343.2023.00008"
    },
    {
        "id": 11976,
        "title": "The Transformative Potential of Large Language Models in Mining Electronic Health Records Data",
        "authors": "Amadeo Wals Zurita, Héctor Miras del Rio, Nerea Ugarte Ruiz de Aguirre, Cristina Nebrera Navarro, María Rubio Jiménez, David Muñoz Carmona, Carlos Míguez Sánchez",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractObjectivesTo explore the potential of Large Language Models (LLMs) to extract and structure information from free-text clinical reports, with a specific focus on identifying and classifying patient comorbidities in the electronic health records of oncology. We specifically evaluate the gpt-3.5-turbo-1106 and gpt-4-1106-preview models in comparison with the capabilities of specialized human evaluators.MethodsWe implemented a script using the OpenAI API to extract structured information in JSON format from comorbidities reported in 250 personal history reports. These reports were manually reviewed in batches of 50 by five specialists in radiation oncology. We compared the results using metrics such as Sensitivity, Specificity, Precision, Accuracy, F-value, Kappa index, and the McNemar test, in addition to examining the common causes of errors in both humans and GPT models.ResultsThe GPT-3.5 model exhibited slightly lower performance compared to physicians across all metrics, though the differences were not statistically significant. GPT-4 demonstrated clear superiority in several key metrics. Notably, it achieved a sensitivity of 96.8%, compared to 88.2% for GPT-3.5 and 88.8% for physicians. However, physicians marginally outperformed GPT-4 in precision (97.7% vs. 96.8%). GPT-4 showed greater consistency, replicating exact results in 76% of the reports after 10 analyses, in contrast to 59% for GPT-3.5. Physicians were more likely to miss explicit comorbidities, while the GPT models more frequently inferred non-explicit comorbidities, sometimes correctly, though this also resulted in more false positives.ConclusionThe studied LLMs, with carefully designed prompts, demonstrate competence comparable to that of medical specialists in interpreting clinical reports, even in complex and confusingly written texts. Considering also their superior efficiency in terms of time and costs, these models represent a preferable option over human analysis for data mining and structuring information in large collections of clinical reports.",
        "link": "http://dx.doi.org/10.1101/2024.03.07.24303588"
    },
    {
        "id": 11977,
        "title": "Two-Stage Fine-Tuning for Improved Bias and Variance for Large Pretrained Language Models",
        "authors": "Lijing Wang, Yingya Li, Timothy Miller, Steven Bethard, Guergana Savova",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.877"
    },
    {
        "id": 11978,
        "title": "Expanding the Horizon of Learning Applications: A Study on the Versatility of Prompting Architectures in Large Language Models",
        "authors": "Cecilia Delgado Solorzano, Carlos Toxtli",
        "published": "2024",
        "citations": 0,
        "abstract": "This paper presents an exploration of the versatility of prompting architectures in large language models (LLMs), expanding the horizons of their application in learning and language interfaces. By leveraging the expansive capabilities of LLMs, this research probes the potential for creating structured prompts that can simultaneously support multiple use cases, namely paraphrasing, grammatical syntax guidance for introductory sentences, and conducting experiential conversations in a foreign language. In this study, we delve into the specifics of enabling such technology, including the design of the prompting architecture, the deployment process, and the intricacies of applying the same structure across diverse applications. An extensive field experiment incorporating interfaces powered by LLMs using this structured prompt has been conducted to evaluate the model's efficiency in real-world scenarios. Results from the field experiment highlight the promising adaptability of these prompting architectures, revealing remarkable efficiency across the multiple use cases explored. Furthermore, this research uncovers a new dimension of flexibility in the design and deployment of learning applications using LLMs, potentially revolutionizing language learning interfaces by establishing a one-size-fits-all solution. This paper aims to stimulate further research into refining and expanding the potential of LLMs, encouraging the exploration of how artificial intelligence can optimally benefit language learning and related applications.",
        "link": "http://dx.doi.org/10.54941/ahfe1004606"
    },
    {
        "id": 11979,
        "title": "Pharmacist vs machine: Pharmacy services in the age of large language models",
        "authors": "Centaine L. Snoswell, Nazanin Falconer, Aaron J Snoswell",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.sapharm.2023.03.006"
    },
    {
        "id": 11980,
        "title": "An Online Tool for Monitoring and Understanding COVID-19 Based on Self-Reporting Tweets and Large Language Models",
        "authors": "Jiacheng Xie, Ziyang Zhang, Shuai Zeng, Joel Hilliard, Guanghui An, Xiaoting Tang, Lei Jiang, Yang Yu, Xiu-Feng Wan, Dong Xu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4723063"
    },
    {
        "id": 11981,
        "title": "Artificial Intelligence: Ethical and Social Problems of Large Language Models and the Future of Technology",
        "authors": "Joseph Migga Kizza",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-31906-8_13"
    },
    {
        "id": 11982,
        "title": "P1 Automating Economic Modelling: A Case Study of AI's Potential With Large Language Models",
        "authors": "T. Reason, W. Rawlinson, B. Malcolm, S. Klijn, J. Langham, A. Gimblett",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jval.2023.09.005"
    },
    {
        "id": 11983,
        "title": "A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges",
        "authors": "Mohaimenul Azam Khan Raiaan, Md Saddam Hossain Mukta, Kaniz Fatema, Nur Mohammad Fahad, Sadman Sakib, Most. Marufatul Jannat Mim, Jubaer Ahmad, Mohammed Eunus Ali, Sami Azam",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Large Language Models (LLMs) recently demonstrated extraordinary capability, including natural language processing (NLP), language translation, text generation, question answering, etc. Moreover, LLMs are a new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies for the situation. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a lot of new research on LLMs is coming out quickly, it is getting tough to get an overview of all of them in a short note. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLM training phase. It then provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. It also demonstrated the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. It also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Then it also explores open issues and challenges to deploying LLMs in real-world aspects, including ethical issues, model biases, computing resources, interoperability, contextual constraints, privacy, security, etc. It also discusses methods to improve the robustness and controllability of LLMs. Finally, the study analyses the future of LLM research and issues that need to be overcome to make LLMs more impactful and reliable. However, this review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals. Furthermore, it serves as a valuable reference for future development and application of LLM in numerous practical domains.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24171183"
    },
    {
        "id": 11984,
        "title": "Using Large Language Models to Enhance Programming Error Messages",
        "authors": "Juho Leinonen, Arto Hellas, Sami Sarsa, Brent Reeves, Paul Denny, James Prather, Brett A. Becker",
        "published": "2023-3-2",
        "citations": 58,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3545945.3569770"
    },
    {
        "id": 11985,
        "title": "Can large language models write reflectively",
        "authors": "Yuheng Li, Lele Sha, Lixiang Yan, Jionghao Lin, Mladen Raković, Kirsten Galbraith, Kayley Lyons, Dragan Gašević, Guanliang Chen",
        "published": "2023",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.caeai.2023.100140"
    },
    {
        "id": 11986,
        "title": "It is better to Verify: Semi-Supervised Learning with a human in the loop for large-scale NLU models",
        "authors": "Verena Weber, Enrico Piovano, Melanie Bradford",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.dash-1.2"
    },
    {
        "id": 11987,
        "title": "Comparative prevalence and characteristics of fabricated citations in large language models in headache medicine",
        "authors": "Leon S. Moskatel, Niushen Zhang",
        "published": "2024-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/head.14638"
    },
    {
        "id": 11988,
        "title": "Opportunities, challenges, and future directions of large language models, including ChatGPT in medical education: a systematic scoping review",
        "authors": "Xiaojun Xu, Yixiao Chen, Jing Miao",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "Background: ChatGPT is a large language model (LLM) based on artificial intelligence (AI) capable of responding in multiple languages and generating nuanced and highly complex responses. While ChatGPT holds promising applications in medical education, its limitations and potential risks cannot be ignored.Methods: A scoping review was conducted for English articles discussing ChatGPT in the context of medical education published after 2022. A literature search was performed using PubMed/MEDLINE, Embase, and Web of Science databases, and information was extracted from the relevant studies that were ultimately included.Results: ChatGPT exhibits various potential applications in medical education, such as providing personalized learning plans and materials, creating clinical practice simulation scenarios, and assisting in writing articles. However, challenges associated with academic integrity, data accuracy, and potential harm to learning were also highlighted in the literature. The paper emphasizes certain recommendations for using ChatGPT, including the establishment of guidelines. Based on the review, 3 key research areas were proposed: cultivating the ability of medical students to use ChatGPT correctly, integrating ChatGPT into teaching activities and processes, and proposing standards for the use of AI by medical students.Conclusion: ChatGPT has the potential to transform medical education, but careful consideration is required for its full integration. To harness the full potential of ChatGPT in medical education, attention should not only be given to the capabilities of AI but also to its impact on students and teachers.",
        "link": "http://dx.doi.org/10.3352/jeehp.2024.21.6"
    },
    {
        "id": 11989,
        "title": "Can Large Language Models Fix Data Annotation Errors? An Empirical Study Using Debatepedia for Query-Focused Text Summarization",
        "authors": "Md Tahmid Rahman Laskar, Mizanur Rahman, Israt Jahan, Enamul Hoque, Jimmy Huang",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.686"
    },
    {
        "id": 11990,
        "title": "Meta smart glasses—large language models and the future for assistive glasses for individuals with vision impairments",
        "authors": "Ethan Waisberg, Joshua Ong, Mouayad Masalkhi, Nasif Zaman, Prithul Sarker, Andrew G. Lee, Alireza Tavakkoli",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41433-023-02842-z"
    },
    {
        "id": 11991,
        "title": "Large Language Models for Automated Program Repair",
        "authors": "Francisco Ribeiro",
        "published": "2023-10-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3618305.3623587"
    },
    {
        "id": 11992,
        "title": "Examining otolaryngologists’ attitudes towards large language models (LLMs) such as ChatGPT: a comprehensive deep learning analysis",
        "authors": "S. V. Praveen, S. Vijaya",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00405-023-08325-x"
    },
    {
        "id": 11993,
        "title": "Large Language Models Meet Harry Potter: A Dataset for Aligning Dialogue Agents with Characters",
        "authors": "Nuo Chen, Yan Wang, Haiyun Jiang, Deng Cai, Yuhan Li, Ziyang Chen, Longyue Wang, Jia Li",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.570"
    },
    {
        "id": 11994,
        "title": "Steering Large Language Models for Machine Translation with Finetuning and In-Context Learning",
        "authors": "Duarte Alves, Nuno Guerreiro, João Alves, José Pombal, Ricardo Rei, José de Souza, Pierre Colombo, Andre Martins",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.744"
    },
    {
        "id": 11995,
        "title": "ParroT: Translating during Chat using Large Language Models tuned with Human Translation and Feedback",
        "authors": "Wenxiang Jiao, Jen-tse Huang, Wenxuan Wang, Zhiwei He, Tian Liang, Xing Wang, Shuming Shi, Zhaopeng Tu",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.1001"
    },
    {
        "id": 11996,
        "title": "Applications of large language models in cancer care: current evidence and future perspectives",
        "authors": "Giovanni Maria Iannantuono, Dara Bracken-Clarke, Charalampos S. Floudas, Mario Roselli, James L. Gulley, Fatima Karzai",
        "published": "2023-9-4",
        "citations": 6,
        "abstract": "The development of large language models (LLMs) is a recent success in the field of generative artificial intelligence (AI). They are computer models able to perform a wide range of natural language processing tasks, including content generation, question answering, or language translation. In recent months, a growing number of studies aimed to assess their potential applications in the field of medicine, including cancer care. In this mini review, we described the present published evidence for using LLMs in oncology. All the available studies assessed ChatGPT, an advanced language model developed by OpenAI, alone or compared to other LLMs, such as Google Bard, Chatsonic, and Perplexity. Although ChatGPT could provide adequate information on the screening or the management of specific solid tumors, it also demonstrated a significant error rate and a tendency toward providing obsolete data. Therefore, an accurate, expert-driven verification process remains mandatory to avoid the potential for misinformation and incorrect evidence. Overall, although this new generative AI-based technology has the potential to revolutionize the field of medicine, including that of cancer care, it will be necessary to develop rules to guide the application of these tools to maximize benefits and minimize risks.",
        "link": "http://dx.doi.org/10.3389/fonc.2023.1268915"
    },
    {
        "id": 11997,
        "title": "\"I wouldn’t say offensive but...\": Disability-Centered Perspectives on Large Language Models",
        "authors": "Vinitha Gadiraju, Shaun Kane, Sunipa Dev, Alex Taylor, Ding Wang, Emily Denton, Robin Brewer",
        "published": "2023-6-12",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3593013.3593989"
    },
    {
        "id": 11998,
        "title": "Accelerating Pharmacovigilance using Large Language Models",
        "authors": "Mukkamala Venkata Sai Prakash, Ganesh Parab, Meghana Veeramalla, Siddartha Reddy, Varun V, Saisubramaniam Gopalakrishnan, Vishal Pagidipally, Vishal Vaddina",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3616855.3635741"
    },
    {
        "id": 11999,
        "title": "ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models",
        "authors": "Qijiong Liu, Nuo Chen, Tetsuya Sakai, Xiao-Ming Wu",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3616855.3635845"
    },
    {
        "id": 12000,
        "title": "A Recipe for Arbitrary Text Style Transfer with Large Language Models",
        "authors": "Emily Reif, Daphne Ippolito, Ann Yuan, Andy Coenen, Chris Callison-Burch, Jason Wei",
        "published": "2022",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.acl-short.94"
    },
    {
        "id": 12001,
        "title": "Monolingual Denoising with Large Language Models for Low-Resource Machine Translation",
        "authors": "Haoyu Xu, Xing Wang, Xiaolin Xing, Yu Hong",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-44693-1_33"
    },
    {
        "id": 12002,
        "title": "Phylochemical mapping of natural products onto the plant tree of life using text mining and large language models.",
        "authors": "Lucas Busta, Drew Hall, Braidon Johnson, Madelyn Schaut, Caroline M. Hanson, Anika Gupta, Megan Gondrum, Yuer Wang, Hiroshi Maeda",
        "published": "No Date",
        "citations": 0,
        "abstract": "Plants produce a staggering array of chemicals that are the basis for organismal function and diversity and also provide essential human nutrients and medicine. However, it is poorly defined how these compounds have evolved and are distributed across the diverse lineages of the plant kingdom, hindering a systematic view and understanding of plant chemical diversity. Recent advances in plant genome/transcriptome sequencing have provided a well-defined molecular phylogeny of plants, on which the presence of diverse natural products can be mapped to systematically determine their phylogenetic distribution. Here, we built a proof-of-concept workflow via which previously reported diverse tyrosine-derived plant natural products were mapped on to the plant tree of life. Plant chemical-species associations were mined from literature, filtered, evaluated through manual inspection of over 2,500 scientific articles, and mapped onto the plant phylogeny. The resulting 'phylochemical' map confirmed several highly lineage-specific compound class distributions, such as betalain pigments and Amaryllidaceae alkaloids. The map also highlighted several lineages enriched in dopamine-derived compounds, including the orders Caryophyllales, Liliales, and Fabales. Additionally, the application of large language models using our manually curated data as a ground truth set showed that post-mining manual processing steps can largely be automated with a low false positive rate. Our study demonstrates that a workflow combining text mining with language model-based processing can generate broader phylochemical maps, which will serve as a critical community resource to uncover key evolutionary events that underlie plant chemical diversity and enable system-level views of nature's millions of years of chemical experimentation.",
        "link": "http://dx.doi.org/10.1101/2024.02.16.580694"
    },
    {
        "id": 12003,
        "title": "Retrieving-to-Answer: Zero-Shot Video Question Answering with Frozen Large Language Models",
        "authors": "Junting Pan, Ziyi Lin, Yuying Ge, Xiatian Zhu, Renrui Zhang, Yi Wang, Yu Qiao, Hongsheng Li",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00035"
    },
    {
        "id": 12004,
        "title": "Navigating the landscape of medical triage: Unveiling the potential and challenges of large language models and beyond",
        "authors": "Edouard Lansiaux, Marc-Antoine Baron, Amélie Vromant",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ajem.2024.02.013"
    },
    {
        "id": 12005,
        "title": "Team Solomon at SemEval-2020 Task 4: Be Reasonable: Exploiting Large-scale Language Models for Commonsense Reasoning",
        "authors": "Vertika Srivastava, Sudeep Kumar Sahoo, Yeon Hyang Kim, Rohit R.r, Mayank Raj, Ajay Jaiswal",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.semeval-1.74"
    },
    {
        "id": 12006,
        "title": "Probing for Understanding of English Verb Classes and Alternations in Large Pre-trained Language Models",
        "authors": "David Yi, James Bruno, Jiayu Han, Peter Zukerman, Shane Steinert-Threlkeld",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.blackboxnlp-1.12"
    },
    {
        "id": 12007,
        "title": "The performance of large language models on fictional consult queries indicates favorable potential for AI-assisted vascular surgery consult handling",
        "authors": "Quang Le, Kedar S. Lavingia, Michael Amendola",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jvsvi.2023.100052"
    },
    {
        "id": 12008,
        "title": "Application of Large Language Models Such as ChatGPT for Arts and Cultural Management",
        "authors": "Hyung Jun Ahn,  ",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15333/acm.2023.8.30.9"
    },
    {
        "id": 12009,
        "title": "Automatic Genre Identification for Robust Enrichment of Massive Text Collections: Investigation of Classification Methods in the Era of Large Language Models",
        "authors": "Taja Kuzman, Igor Mozetič, Nikola Ljubešić",
        "published": "2023-9-12",
        "citations": 0,
        "abstract": "Massive text collections are the backbone of large language models, the main ingredient of the current significant progress in artificial intelligence. However, as these collections are mostly collected using automatic methods, researchers have few insights into what types of texts they consist of. Automatic genre identification is a text classification task that enriches texts with genre labels, such as promotional and legal, providing meaningful insights into the composition of these large text collections. In this paper, we evaluate machine learning approaches for the genre identification task based on their generalizability across different datasets to assess which model is the most suitable for the downstream task of enriching large web corpora with genre information. We train and test multiple fine-tuned BERT-like Transformer-based models and show that merging different genre-annotated datasets yields superior results. Moreover, we explore the zero-shot capabilities of large GPT Transformer models in this task and discuss the advantages and disadvantages of the zero-shot approach. We also publish the best-performing fine-tuned model that enables automatic genre annotation in multiple languages. In addition, to promote further research in this area, we plan to share, upon request, a new benchmark for automatic genre annotation, ensuring the non-exposure of the latest large language models.",
        "link": "http://dx.doi.org/10.3390/make5030059"
    },
    {
        "id": 12010,
        "title": "Demo: CANSASI: Mobile Sensing Platform powered by Large Language Models",
        "authors": "Akio Sashima, Mitsuru Kawamoto, Satoshi Yazawa, Kazuo Hiraki",
        "published": "2024-2-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3638550.3643047"
    },
    {
        "id": 12011,
        "title": "Large Language Models: A Comprehensive Survey of its Applications, Challenges, Limitations, and Future Prospects",
        "authors": "Muhammad Usman Hadi, qasem al tashi, Rizwan Qureshi, Abbas Shah, amgad muneer, Muhammad Irfan, Anas Zafar, Muhammad Bilal Shaikh, Naveed Akhtar, Jia Wu, Seyedali Mirjalili",
        "published": "No Date",
        "citations": 1,
        "abstract": "<p>Within the vast expanse of computerized language processing, a revolutionary entity known as Large Language Models (LLMs) has emerged, wielding immense power in its capacity to comprehend intricate linguistic patterns and conjure coherent and contextually fitting responses. Large language models (LLMs) are a type of artificial intelligence (AI) that have emerged as powerful tools for a wide range of tasks, including natural language processing (NLP), machine translation, and question-answering. This survey paper provides a comprehensive overview of LLMs, including their history, architecture, training methods, applications, and challenges. The paper begins by discussing the fundamental concepts of generative AI and the architecture of generative pre- trained transformers (GPT). It then provides an overview of the history of LLMs, their evolution over time, and the different training methods that have been used to train them. The paper then discusses the wide range of applications of LLMs, including medical, education, finance, and engineering. It also discusses how LLMs are shaping the future of AI and how they can be used to solve real-world problems. The paper then discusses the challenges associated with deploying LLMs in real-world scenarios, including ethical considerations, model biases, interpretability, and computational resource requirements. It also highlights techniques for enhancing the robustness and controllability of LLMs, and addressing bias, fairness, and generation quality issues. Finally, the paper concludes by highlighting the future of LLM research and the challenges that need to be addressed in order to make LLMs more reliable and useful. This survey paper is intended to provide researchers, practitioners, and enthusiasts with a comprehensive understanding of LLMs, their evolution, applications, and challenges. By consolidating the state-of-the-art knowledge in the field, this survey serves as a valuable resource for further advancements in the development and utilization of LLMs for a wide range of real-world applications. The GitHub repo for this project is available at https://github.com/anas-zafar/LLM-Survey</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23589741.v2"
    },
    {
        "id": 12012,
        "title": "Identifying and Extracting Rare Diseases and Their Phenotypes with Large Language Models",
        "authors": "Cathy Shyr, Yan Hu, Lisa Bastarache, Alex Cheng, Rizwan Hamid, Paul Harris, Hua Xu",
        "published": "2024-1-5",
        "citations": 0,
        "abstract": "Abstract\nPurpose\nPhenotyping is critical for informing rare disease diagnosis and treatment, but disease phenotypes are often embedded in unstructured text. While natural language processing (NLP) can automate extraction, a major bottleneck is developing annotated corpora. Recently, prompt learning with large language models (LLMs) has been shown to lead to generalizable results without any (zero-shot) or few annotated samples (few-shot), but none have explored this for rare diseases. Our work is the first to study prompt learning for identifying and extracting rare disease phenotypes in the zero- and few-shot settings.\n\nMethods\nWe compared the performance of prompt learning with ChatGPT and fine-tuning with BioClinicalBERT. We engineered novel prompts for ChatGPT to identify and extract rare diseases and their phenotypes (e.g., diseases, symptoms, and signs), established a benchmark for evaluating its performance, and conducted an in-depth error analysis.\n\nResults\nOverall, fine-tuning BioClinicalBERT resulted in higher performance (F1 of 0.689) than ChatGPT (F1 of 0.472 and 0.610 in the zero- and few-shot settings, respectively). However, ChatGPT achieved higher accuracy for rare diseases and signs in the one-shot setting (F1 of 0.778 and 0.725). Conversational, sentence-based prompts generally achieved higher accuracy than structured lists.\n\nConclusion\nPrompt learning using ChatGPT has the potential to match or outperform fine-tuning BioClinicalBERT at extracting rare diseases and signs with just one annotated sample. Given its accessibility, ChatGPT could be leveraged to extract these entities without relying on a large, annotated corpus. While LLMs can support rare disease phenotyping, researchers should critically evaluate model outputs to ensure phenotyping accuracy.\n",
        "link": "http://dx.doi.org/10.1007/s41666-023-00155-0"
    },
    {
        "id": 12013,
        "title": "The rise of artificial intelligence: addressing the impact of large language models such as ChatGPT on scientific publications",
        "authors": "KianKeong Poh, TiingLeong Ang, Mahesh Choolani, KayChoong See",
        "published": "2023",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4103/singaporemedj.smj-2023-055"
    },
    {
        "id": 12014,
        "title": "Enhancing Human Annotation: Leveraging Large Language Models and Efficient Batch Processing",
        "authors": "Oleg Zendel, J. Shane Culpepper, Falk Scholer, Paul Thomas",
        "published": "2024-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3627508.3638322"
    },
    {
        "id": 12015,
        "title": "The debate over understanding in AI’s large language models",
        "authors": "Melanie Mitchell, David C. Krakauer",
        "published": "2023-3-28",
        "citations": 41,
        "abstract": "We survey a current, heated debate in the artificial intelligence (AI) research community on whether large pretrained language models can be said to understand language—and the physical and social situations language encodes—in any humanlike sense. We describe arguments that have been made for and against such understanding and key questions for the broader sciences of intelligence that have arisen in light of these arguments. We contend that an extended science of intelligence can be developed that will provide insight into distinct modes of understanding, their strengths and limitations, and the challenge of integrating diverse forms of cognition.",
        "link": "http://dx.doi.org/10.1073/pnas.2215907120"
    },
    {
        "id": 12016,
        "title": "The performance of large language models in intercollegiate Membership of the Royal College of Surgeons examination",
        "authors": "J Chan, T Dong, GD Angelini",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "Introduction Large language models (LLM), such as Chat Generative Pre-trained Transformer (ChatGPT) and Bard utilise deep learning algorithms that have been trained on a massive data set of text and code to generate human-like responses. Several studies have demonstrated satisfactory performance on postgraduate examinations, including the United States Medical Licensing Examination. We aimed to evaluate artificial intelligence performance in Part A of the intercollegiate Membership of the Royal College of Surgeons (MRCS) examination. Methods The MRCS mock examination from Pastest, a commonly used question bank for examinees, was used to assess the performance of three LLMs: GPT-3.5, GPT 4.0 and Bard. Three hundred mock questions were input into the three LLMs, and the responses provided by the LLMs were recorded and analysed. The pass mark was set at 70%. Results The overall accuracies for GPT-3.5, GPT 4.0 and Bard were 67.33%, 71.67% and 65.67%, respectively (p = 0.27). The performances of GPT-3.5, GPT 4.0 and Bard in Applied Basic Sciences were 68.89%, 72.78% and 63.33% (p = 0.15), respectively. Furthermore, the three LLMs obtained correct answers in 65.00%, 70.00% and 69.17% of the Principles of Surgery in General questions (p = 0.67). There were no differences in performance in the overall and subcategories among the three LLMs. Conclusions Our findings demonstrated satisfactory performance for all three LLMs in the MRCS Part A examination, with GPT 4.0 the only LLM that achieved the pass mark set. ",
        "link": "http://dx.doi.org/10.1308/rcsann.2024.0023"
    },
    {
        "id": 12017,
        "title": "Comment on Large Language Models in Ophthalmology Scientific Writing: Ethical Considerations, Blurred Lines or Not at All?1",
        "authors": "Dr Alexander James Cameron Jessup, Professor Minas Theodore Coroneo",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ajo.2024.01.039"
    },
    {
        "id": 12018,
        "title": "Colleges and universities are important stakeholders for regulating large language models and other emerging AI",
        "authors": "Veljko Dubljević",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.techsoc.2024.102480"
    },
    {
        "id": 12019,
        "title": "Does GPT-3 know what the Most Important Issue is? Using Large Language Models to Code Open-Text Social Survey Responses At Scale",
        "authors": "Jonathan Mellon, Jack Bailey, Ralph Scott, James Breckwoldt, Marta Miori",
        "published": "No Date",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4310154"
    },
    {
        "id": 12020,
        "title": "Domain-adapted Large Language Models for Classifying Nuclear Medicine                     Reports",
        "authors": "Zachary Huemann, Changhee Lee, Junjie Hu, Steve Y. Cho, Tyler J. Bradshaw",
        "published": "2023-11-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1148/ryai.220281"
    },
    {
        "id": 12021,
        "title": "Application and Evaluation of Large Language Models for the Generation of Survey Questions",
        "authors": "Antonio Maiorino, Zoe Padgett, Chun Wang, Misha Yakubovskiy, Peng Jiang",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3583780.3615506"
    },
    {
        "id": 12022,
        "title": "Large Language Models: A Comprehensive Survey of its Applications, Challenges, Limitations, and Future Prospects",
        "authors": "Muhammad Usman Hadi, qasem al tashi, Rizwan Qureshi, Abbas Shah, amgad muneer, Muhammad Irfan, Anas Zafar, Muhammad Bilal Shaikh, Naveed Akhtar, Jia Wu, Seyedali Mirjalili",
        "published": "No Date",
        "citations": 2,
        "abstract": "<p>Within the vast expanse of computerized language processing, a revolutionary entity known as Large Language Models (LLMs) has emerged, wielding immense power in its capacity to comprehend intricate linguistic patterns and conjure coherent and contextually fitting responses. Large language models (LLMs) are a type of artificial intelligence (AI) that have emerged as powerful tools for a wide range of tasks, including natural language processing (NLP), machine translation, and question-answering. This survey paper provides a comprehensive overview of LLMs, including their history, architecture, training methods, applications, and challenges. The paper begins by discussing the fundamental concepts of generative AI and the architecture of generative pre- trained transformers (GPT). It then provides an overview of the history of LLMs, their evolution over time, and the different training methods that have been used to train them. The paper then discusses the wide range of applications of LLMs, including medical, education, finance, and engineering. It also discusses how LLMs are shaping the future of AI and how they can be used to solve real-world problems. The paper then discusses the challenges associated with deploying LLMs in real-world scenarios, including ethical considerations, model biases, interpretability, and computational resource requirements. It also highlights techniques for enhancing the robustness and controllability of LLMs, and addressing bias, fairness, and generation quality issues. Finally, the paper concludes by highlighting the future of LLM research and the challenges that need to be addressed in order to make LLMs more reliable and useful. This survey paper is intended to provide researchers, practitioners, and enthusiasts with a comprehensive understanding of LLMs, their evolution, applications, and challenges. By consolidating the state-of-the-art knowledge in the field, this survey serves as a valuable resource for further advancements in the development and utilization of LLMs for a wide range of real-world applications. The GitHub repo for this project is available at https://github.com/anas-zafar/LLM-Survey</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23589741.v4"
    },
    {
        "id": 12023,
        "title": "Large language models as a rapid and objective tool for pathology report data extraction",
        "authors": "Beyza Bolat, Ozgur Can Eren, A. Karasayar, Cisel Aydin Mericoz, Cigdem Gunduz-demir, Ibrahim Kulac",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5146/tjpath.2024.13256"
    },
    {
        "id": 12024,
        "title": "Automated Paper Screening for Clinical Reviews Using Large Language Models: Data Analysis Study",
        "authors": "Eddie Guo, Mehul Gupta, Jiawen Deng, Ye-Jean Park, Michael Paget, Christopher Naugler",
        "published": "2024-1-12",
        "citations": 1,
        "abstract": "\nBackground\nThe systematic review of clinical research papers is a labor-intensive and time-consuming process that often involves the screening of thousands of titles and abstracts. The accuracy and efficiency of this process are critical for the quality of the review and subsequent health care decisions. Traditional methods rely heavily on human reviewers, often requiring a significant investment of time and resources.\n\n\nObjective\nThis study aims to assess the performance of the OpenAI generative pretrained transformer (GPT) and GPT-4 application programming interfaces (APIs) in accurately and efficiently identifying relevant titles and abstracts from real-world clinical review data sets and comparing their performance against ground truth labeling by 2 independent human reviewers.\n\n\nMethods\nWe introduce a novel workflow using the Chat GPT and GPT-4 APIs for screening titles and abstracts in clinical reviews. A Python script was created to make calls to the API with the screening criteria in natural language and a corpus of title and abstract data sets filtered by a minimum of 2 human reviewers. We compared the performance of our model against human-reviewed papers across 6 review papers, screening over 24,000 titles and abstracts.\n\n\nResults\nOur results show an accuracy of 0.91, a macro F1-score of 0.60, a sensitivity of excluded papers of 0.91, and a sensitivity of included papers of 0.76. The interrater variability between 2 independent human screeners was κ=0.46, and the prevalence and bias-adjusted κ between our proposed methods and the consensus-based human decisions was κ=0.96. On a randomly selected subset of papers, the GPT models demonstrated the ability to provide reasoning for their decisions and corrected their initial decisions upon being asked to explain their reasoning for incorrect classifications.\n\n\nConclusions\nLarge language models have the potential to streamline the clinical review process, save valuable time and effort for researchers, and contribute to the overall quality of clinical reviews. By prioritizing the workflow and acting as an aid rather than a replacement for researchers and reviewers, models such as GPT-4 can enhance efficiency and lead to more accurate and reliable conclusions in medical research.\n",
        "link": "http://dx.doi.org/10.2196/48996"
    },
    {
        "id": 12025,
        "title": "Large Language Models for in Situ Knowledge Documentation and Access With Augmented Reality",
        "authors": "Juan Izquierdo-Domenech, Jordi Linares-Pellicer, Isabel Ferri-Molla",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.9781/ijimai.2023.09.002"
    },
    {
        "id": 12026,
        "title": "Leveraging large language models to monitor climate technology innovation",
        "authors": "Malte Toetzke, Benedict Probst, Stefan Feuerriegel",
        "published": "2023-9-1",
        "citations": 0,
        "abstract": "AbstractTo achieve net-zero emissions, public policy needs to foster rapid innovation of climate technologies. However, there is a scarcity of comprehensive and up-to-date evidence to guide policymaking by monitoring climate innovation systems. This is notable, especially at the center of the innovation process, where nascent inventions transition into profitable and scalable market solutions. Here, we discuss the potential of large language models (LLMs) to monitor climate technology innovation. By analyzing large pools of unstructured text data sources, such as company reports and social media, LLMs can automate information retrieval processes and thereby improve existing monitoring in terms of cost-effectiveness, timeliness, and comprehensiveness. In this perspective, we show how LLMs can play a crucial role in informing innovation policy for the energy transition by highlighting promising use cases and prevailing challenges for research and policy.",
        "link": "http://dx.doi.org/10.1088/1748-9326/acf233"
    },
    {
        "id": 12027,
        "title": "Utility of artificial intelligence‐based large language models in ophthalmic care",
        "authors": "Sayantan Biswas, Leon N. Davies, Amy L. Sheppard, Nicola S. Logan, James S. Wolffsohn",
        "published": "2024-2-25",
        "citations": 0,
        "abstract": "AbstractPurposeWith the introduction of ChatGPT, artificial intelligence (AI)‐based large language models (LLMs) are rapidly becoming popular within the scientific community. They use natural language processing to generate human‐like responses to queries. However, the application of LLMs and comparison of the abilities among different LLMs with their human counterparts in ophthalmic care remain under‐reported.Recent FindingsHitherto, studies in eye care have demonstrated the utility of ChatGPT in generating patient information, clinical diagnosis and passing ophthalmology question‐based examinations, among others. LLMs' performance (median accuracy, %) is influenced by factors such as the iteration, prompts utilised and the domain. Human expert (86%) demonstrated the highest proficiency in disease diagnosis, while ChatGPT‐4 outperformed others in ophthalmology examinations (75.9%), symptom triaging (98%) and providing information and answering questions (84.6%). LLMs exhibited superior performance in general ophthalmology but reduced accuracy in ophthalmic subspecialties. Although AI‐based LLMs like ChatGPT are deemed more efficient than their human counterparts, these AIs are constrained by their nonspecific and outdated training, no access to current knowledge, generation of plausible‐sounding ‘fake’ responses or hallucinations, inability to process images, lack of critical literature analysis and ethical and copyright issues. A comprehensive evaluation of recently published studies is crucial to deepen understanding of LLMs and the potential of these AI‐based LLMs.SummaryOphthalmic care professionals should undertake a conservative approach when using AI, as human judgement remains essential for clinical decision‐making and monitoring the accuracy of information. This review identified the ophthalmic applications and potential usages which need further exploration. With the advancement of LLMs, setting standards for benchmarking and promoting best practices is crucial. Potential clinical deployment requires the evaluation of these LLMs to move away from artificial settings, delve into clinical trials and determine their usefulness in the real world.",
        "link": "http://dx.doi.org/10.1111/opo.13284"
    },
    {
        "id": 12028,
        "title": "Large GPT-like Models are Bad Babies: A Closer Look at the Relationship between Linguistic Competence and Psycholinguistic Measures",
        "authors": "Julius Steuer, Marius Mosbach, Dietrich Klakow",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-babylm.12"
    },
    {
        "id": 12029,
        "title": "Enhancing Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies",
        "authors": "Linyong Nan, Yilun Zhao, Weijin Zou, Narutatsu Ri, Jaesung Tae, Ellen Zhang, Arman Cohan, Dragomir Radev",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.996"
    },
    {
        "id": 12030,
        "title": "Beyond semantic distance: Automated scoring of divergent thinking greatly improves with large language models",
        "authors": "Peter Organisciak, Selcuk Acar, Denis Dumas, Kelly Berthiaume",
        "published": "2023-9",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.tsc.2023.101356"
    },
    {
        "id": 12031,
        "title": "Exploring the Student Perspective: Assessing Technology Readiness and Acceptance for Adopting Large Language Models in Higher Education",
        "authors": "Claudia Lemke, Kathrin Kirchner, Liadan Anandarajah, Florian Herfurth",
        "published": "2023-10-19",
        "citations": 0,
        "abstract": "Digital technologies are changing and will continue to change how we learn and teach today and in the future. With the latest developments in the field of generative artificial intelligence (AI), particularly large language models (LLMs), the question of using AI-based tools in academic education is ruling the current discussions about the transformative impact of AI in higher education (HE).\r\nThese discussions range from banning these technologies for learning and teaching in HE to guided study support. This study avoids taking up these multifarious and partly controversial debates. Instead, we show how students perceive using AI-based tools for automated text generation for their studies. Drawing on a synthesis of two theories: the 'Technology Readiness Index' (TRI) and 'Technology Acceptance Model' (TAM). The model is validated based on survey data collected among undergraduate first-semester students (N=111) of a computer science-related study programme in Germany in winter 2022/23. The students had to evaluate their relationship to that new technology focusing on their readiness for technology adoption and acceptance. By analysing the collected data with a partial least squares model, we find that the optimism toward the new technology positively influences technology acceptance, while discomfort with the technology negatively influences perceived ease of use. The paper concludes with recommendations for action for adopting LLMs in HE. A proper investment in building AI skills in academic teaching plays a valuable role in fostering the students' positive attitude and innovativeness towards this new technology. Additionally, there is a need for more education about the risks and challenges of using this technology to reduce the impact of factors such as discomfort on ease of use. This requires a factual discourse, away from the current hype-induced exaggerated and hyperbolic statements, for instance, in developing formal guidance for universities.",
        "link": "http://dx.doi.org/10.34190/ecel.22.1.1828"
    },
    {
        "id": 12032,
        "title": "An Empirical Study on Fine-Tuning Large Language Models of Code for Automated Program Repair",
        "authors": "Kai Huang, Xiangxin Meng, Jian Zhang, Yang Liu, Wenjie Wang, Shuhao Li, Yuqing Zhang",
        "published": "2023-9-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ase56229.2023.00181"
    },
    {
        "id": 12033,
        "title": "Summary Cycles: Exploring the Impact of Prompt Engineering on Large Language Models’ Interaction with Interaction Log Information",
        "authors": "Jeremy Block, Yu-Peng Chen, Abhilash Budharapu, Lisa Anthony, Bonnie Dorr",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.eval4nlp-1.7"
    },
    {
        "id": 12034,
        "title": "Counterexample Guided Inductive Synthesis Using Large Language Models and Satisfiability Solving",
        "authors": "Sumit Kumar Jha, Susmit Jha, Patrick Lincoln, Nathaniel D. Bastian, Alvaro Velasquez, Rickard Ewetz, Sandeep Neema",
        "published": "2023-10-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/milcom58377.2023.10356332"
    },
    {
        "id": 12035,
        "title": "Assisting Static Analysis with Large Language Models: A ChatGPT Experiment",
        "authors": "Haonan Li, Yu Hao, Yizhuo Zhai, Zhiyun Qian",
        "published": "2023-11-30",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3611643.3613078"
    },
    {
        "id": 12036,
        "title": "An Examination of the Use of Large Language Models to Aid Analysis of Textual Data",
        "authors": "Robert H. Tai, Lillian R. Bentley, Xin Xia, Jason M. Sitt, Sarah C. Fankhauser, Ana M. Chicas-Mosier, Barnas G. Monteith",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractThe increasing use of machine learning and Large Language Models (LLMs) opens up opportunities to use these artificially intelligent algorithms in novel ways. This article proposes a methodology using LLMs to support traditional deductive coding in qualitative research. We began our analysis with three different sample texts taken from existing interviews. Next, we created a codebook and inputted the sample text and codebook into an LLM. We asked the LLM to determine if the codes were present in a sample text provided and requested evidence to support the coding. The sample texts were inputted 160 times to record changes between iterations of the LLM response. Each iteration was analogous to a new coder deductively analyzing the text with the codebook information. In our results, we present the outputs for these recursive analyses, along with a comparison of the LLM coding to evaluations made by human coders using traditional coding methods. We argue that LLM analysis can aid qualitative researchers by deductively coding transcripts, providing a systematic and reliable platform for code identification, and offering a means of avoiding analysis misalignment. Implications of using LLM in research praxis are discussed, along with current limitations.",
        "link": "http://dx.doi.org/10.1101/2023.07.17.549361"
    },
    {
        "id": 12037,
        "title": "A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges",
        "authors": "Mohaimenul Azam Khan Raiaan, Md Saddam Hossain Mukta, Kaniz Fatema, Nur Mohammad Fahad, Sadman Sakib, Most. Marufatul Jannat Mim, Jubaer Ahmad, Mohammed Eunus Ali, Sami Azam",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36227/techrxiv.24171183.v1"
    },
    {
        "id": 12038,
        "title": "Detection of Day-Based Health Evidence with Pretrained Large Language Models: A Case of COVID-19 Symptoms in Social Media Posts",
        "authors": "Keyuan Jiang, Valli Devendra, Soniya Chavan, Gordon R. Bernard",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bibm58861.2023.10385580"
    },
    {
        "id": 12039,
        "title": "Integrating Knowledge Graph Data with Large Language Models for Explainable Inference",
        "authors": "Carlos Efrain Quintero-Narvaez, Raul Monroy",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3616855.3636507"
    },
    {
        "id": 12040,
        "title": "Extending Large Language Models for Speech and Audio Captioning",
        "authors": "Changli Tang, Wenyi Yu, Guangzhi Sun, Xianzhao Chen, Tian Tan, Wei Li, Lu Lu, Zejun Ma, Chao Zhang",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446343"
    },
    {
        "id": 12041,
        "title": "Automatic Extraction of the Romanian AcademicWord List: Data and Methods",
        "authors": "Ana-Maria Bucur,  , Andreea Dincă, Mădălina Chitez, Roxana Rogobete,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_026"
    },
    {
        "id": 12042,
        "title": "Using Large Language Models to Automatically Identify Programming Concepts in Code Snippets",
        "authors": "Andrew Tran, Linxuan Li, Egi Rama, Kenneth Angelikas, Stephen Macneil",
        "published": "2023-8-7",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3568812.3603482"
    },
    {
        "id": 12043,
        "title": "Agile Methodology for the Standardization of Engineering Requirements Using Large Language Models",
        "authors": "Archana Tikayat Ray, Bjorn F. Cole, Olivia J. Pinon Fischer, Anirudh Prabhakara Bhat, Ryan T. White, Dimitri N. Mavris",
        "published": "2023-7-10",
        "citations": 1,
        "abstract": "The increased complexity of modern systems is calling for an integrated and comprehensive approach to system design and development and, in particular, a shift toward Model-Based Systems Engineering (MBSE) approaches for system design. The requirements that serve as the foundation for these intricate systems are still primarily expressed in Natural Language (NL), which can contain ambiguities and inconsistencies and suffer from a lack of structure that hinders their direct translation into models. The colossal developments in the field of Natural Language Processing (NLP), in general, and Large Language Models (LLMs), in particular, can serve as an enabler for the conversion of NL requirements into machine-readable requirements. Doing so is expected to facilitate their standardization and use in a model-based environment. This paper discusses a two-fold strategy for converting NL requirements into machine-readable requirements using language models. The first approach involves creating a requirements table by extracting information from free-form NL requirements. The second approach consists of an agile methodology that facilitates the identification of boilerplate templates for different types of requirements based on observed linguistic patterns. For this study, three different LLMs are utilized. Two of these models are fine-tuned versions of Bidirectional Encoder Representations from Transformers (BERTs), specifically, aeroBERT-NER and aeroBERT-Classifier, which are trained on annotated aerospace corpora. Another LLM, called flair/chunk-english, is utilized to identify sentence chunks present in NL requirements. All three language models are utilized together to achieve the standardization of requirements. The effectiveness of the methodologies is demonstrated through the semi-automated creation of boilerplates for requirements from Parts 23 and 25 of Title 14 Code of Federal Regulations (CFRs).",
        "link": "http://dx.doi.org/10.3390/systems11070352"
    },
    {
        "id": 12044,
        "title": "Soccer Artificial Intelligence Commentary Service on the Base of Video Analytic and Large Language Models",
        "authors": "Roman V. Pavlovich, Evgeniya A. Tsybulko, Konstantin N. Zhigunov, Aleksandr V. Khelvas, Aleksandr A. Gilya-Zetinov, Illya V. Tykhonov",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/telfor59449.2023.10372671"
    },
    {
        "id": 12045,
        "title": "Complementary role of large language models in educating undergraduate design of distillation column: Methodology development",
        "authors": "Zong Yang Kong, Vincentius Surya Kurnia Adi, Juan Gabriel Segovia-Hernández, Jaka Sunarso",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.dche.2023.100126"
    },
    {
        "id": 12046,
        "title": "Capabilities and limitations of large language models in critical care nursing research: Examples from the big three",
        "authors": "Sameh Eltaybani",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/nicc.12974"
    },
    {
        "id": 12047,
        "title": "Large Language Models Meet NL2Code: A Survey",
        "authors": "Daoguang Zan, Bei Chen, Fengji Zhang, Dianjie Lu, Bingchao Wu, Bei Guan, Wang Yongji, Jian-Guang Lou",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.411"
    },
    {
        "id": 12048,
        "title": "Investigating the Impact of Prompt Engineering on the Performance of Large Language Models for Standardizing Obstetric Diagnosis Text: Comparative Study (Preprint)",
        "authors": "Lei Wang, Wenshuai Bi, Suling Zhao, Yinyao Ma, Longting Lv, Chenwei Meng, Jingru Fu, Hanlin Lv",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nThe accumulation of vast electronic medical records (EMRs) through medical informatization creates significant research value, particularly in obstetrics. Diagnostic standardization across different health care institutions and regions is vital for medical data analysis. Large language models (LLMs) have been extensively used for various medical tasks. Prompt engineering is key to use LLMs effectively.\n\n\nOBJECTIVE\nThis study aims to evaluate and compare the performance of LLMs with various prompt engineering techniques on the task of standardizing obstetric diagnostic terminology using real-world obstetric data.\n\n\nMETHODS\nThe paper describes a 4-step approach used for mapping diagnoses in electronic medical records to the International Classification of Diseases, 10th revision, observation domain. First, similarity measures were used for mapping the diagnoses. Second, candidate mapping terms were collected based on similarity scores above a threshold, to be used as the training data set. For generating optimal mapping terms, we used two LLMs (ChatGLM2 and Qwen-14B-Chat [QWEN]) for zero-shot learning in step 3. Finally, a performance comparison was conducted by using 3 pretrained bidirectional encoder representations from transformers (BERTs), including BERT, whole word masking BERT, and momentum contrastive learning with BERT (MC-BERT), for unsupervised optimal mapping term generation in the fourth step.\n\n\nRESULTS\nLLMs and BERT demonstrated comparable performance at their respective optimal levels. LLMs showed clear advantages in terms of performance and efficiency in unsupervised settings. Interestingly, the performance of the LLMs varied significantly across different prompt engineering setups. For instance, when applying the self-consistency approach in QWEN, the <i>F</i><sub>1</sub>-score improved by 5%, with precision increasing by 7.9%, outperforming the zero-shot method. Likewise, ChatGLM2 delivered similar rates of accurately generated responses. During the analysis, the BERT series served as a comparative model with comparable results. Among the 3 models, MC-BERT demonstrated the highest level of performance. However, the differences among the versions of BERT in this study were relatively insignificant.\n\n\nCONCLUSIONS\nAfter applying LLMs to standardize diagnoses and designing 4 different prompts, we compared the results to those generated by the BERT model. Our findings indicate that QWEN prompts largely outperformed the other prompts, with precision comparable to that of the BERT model. These results demonstrate the potential of unsupervised approaches in improving the efficiency of aligning diagnostic terms in daily research and uncovering hidden information values in patient data.\n",
        "link": "http://dx.doi.org/10.2196/preprints.53216"
    },
    {
        "id": 12049,
        "title": "Leveraging generative artificial intelligence based on large language models for collaborative learning",
        "authors": "Seng Chee Tan, Wenli Chen, Bee Leng Chua",
        "published": "2023-7-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/23735082.2023.2258895"
    },
    {
        "id": 12050,
        "title": "Frozen Large-scale Pretrained Vision-Language Models are an Effective Foundational Backbone for Enhancing Multimodal Breast Cancer Risk Assessment",
        "authors": "Hung Q. Vo, Lin Wang, Kelvin K Wong, Chika F Ezeana, Xiaohui Yu, Hien V Nguyen, Stephen T C Wong",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36227/techrxiv.170594643.34409575/v1"
    },
    {
        "id": 12051,
        "title": "Software Testing with Large Language Models: Survey, Landscape, and Vision",
        "authors": "Junjie Wang, Yuchao Huang, Chunyang Chen, Zhe Liu, Song Wang, Qing Wang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tse.2024.3368208"
    },
    {
        "id": 12052,
        "title": "Large language models for epidemiological research via automated machine learning: a case study and method comparison from the British National Child Development Study (Preprint)",
        "authors": "Rasmus Wibaek, Gregers Stig Andersen, Christina C Dahm, Daniel R Witte, Adam Hulman",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nLarge language models have had a huge impact on natural language processing (NLP) in recent years. However, their application in epidemiological research is still limited to analysis of electronic health records and social media data.\n\n\nOBJECTIVE\nTo demonstrate the potential of NLP beyond these domains, we aimed to develop prediction models based on texts collected in an epidemiological cohort and compared their performance to classical regression methods.\n\n\nMETHODS\nWe used data from the British National Child Development Study, where 10,567 11-year-old children wrote essays about how they imagined themselves as 25-year-olds. Fifteen percent of the dataset was set aside as a test set for performance evaluation. Pre-trained language models were fine-tuned using AutoTrain (by Hugging Face) to predict current reading comprehension score (0-35) and future body mass index (BMI) and physical activity (active vs. inactive) at the age of 33. We then compared their predictive performance (accuracy or discrimination) with linear and logistic regression models including demographic and lifestyle factors of the parents and the children between birth and age 11 as predictors.\n\n\nRESULTS\nNLP clearly outperformed linear regression when predicting reading comprehension score (RMSE=3.89 [95% CI: 3.74, 4.05] for NLP vs. 4.14 [3.98, 4.30] and 5.41 [5.23, 5.58] for regression models with and without general ability score as predictor). Predictive performance for physical activity was similarly poor for the two methods (AUC ROC=0.55 [0.52, 0.60] for both), but slightly better than random assignment, while linear regression clearly outperformed the NLP approach when predicting BMI (RMSE=4.38 [4.02, 4.74] for NLP vs. 3.85 [3.54, 4.16] for regression). The NLP approach did not perform better than simply assigning the mean BMI from the training set as predictors.\n\n\nCONCLUSIONS\nOur study demonstrated the potential of using large language models to utilize text collected in epidemiological studies. The performance of the approach appeared to depend on how directly the topic of the text was related to outcome. Open-ended questions specifically designed to capture certain health concepts and lived experiences in combination with NLP methods should receive more attention in future epidemiological studies.\n\n\nCLINICALTRIAL\n\n",
        "link": "http://dx.doi.org/10.2196/preprints.43638"
    },
    {
        "id": 12053,
        "title": "Catalyst Energy Prediction with CatBERTa: Unveiling Feature Exploration Strategies through Large Language Models",
        "authors": "Janghoon Ock, Chakradhar Guntuboina, Amir Barati Farimani",
        "published": "2023-12-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1021/acscatal.3c04956"
    },
    {
        "id": 12054,
        "title": "Unleashing the Power of Large Language Models: A Hands-On Tutorial",
        "authors": "Payel Santra, Madhusudan Ghosh, Shrimon Mukherjee, Debasis Ganguly, Partha Basuchowdhuri, Sudip Kumar Naskar",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3632754.3632943"
    },
    {
        "id": 12055,
        "title": "Auditing large language models: a three-layered approach",
        "authors": "Jakob Mökander, Jonas Schuett, Hannah Rose Kirk, Luciano Floridi",
        "published": "2023-5-30",
        "citations": 20,
        "abstract": "AbstractLarge language models (LLMs) represent a major advance in artificial intelligence (AI) research. However, the widespread use of LLMs is also coupled with significant ethical and social challenges. Previous research has pointed towards auditing as a promising governance mechanism to help ensure that AI systems are designed and deployed in ways that are ethical, legal, and technically robust. However, existing auditing procedures fail to address the governance challenges posed by LLMs, which display emergent capabilities and are adaptable to a wide range of downstream tasks. In this article, we address that gap by outlining a novel blueprint for how to audit LLMs. Specifically, we propose a three-layered approach, whereby governance audits (of technology providers that design and disseminate LLMs), model audits (of LLMs after pre-training but prior to their release), and application audits (of applications based on LLMs) complement and inform each other. We show how audits, when conducted in a structured and coordinated manner on all three levels, can be a feasible and effective mechanism for identifying and managing some of the ethical and social risks posed by LLMs. However, it is important to remain realistic about what auditing can reasonably be expected to achieve. Therefore, we discuss the limitations not only of our three-layered approach but also of the prospect of auditing LLMs at all. Ultimately, this article seeks to expand the methodological toolkit available to technology providers and policymakers who wish to analyse and evaluate LLMs from technical, ethical, and legal perspectives.",
        "link": "http://dx.doi.org/10.1007/s43681-023-00289-2"
    },
    {
        "id": 12056,
        "title": "Revolution or Peril? The Controversial Role of Large Language Models in Medical Manuscript Writing",
        "authors": "Ricardo Diaz Milian, Pablo Moreno Franco, William D. Freeman, John D. Halamka",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.mayocp.2023.07.009"
    },
    {
        "id": 12057,
        "title": "Enhancing oncology nursing care planning for patients with cancer through Harnessing large language models",
        "authors": "Abdulqadir J. Nashwan, Salam Bani Hani",
        "published": "2023-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.apjon.2023.100277"
    },
    {
        "id": 12058,
        "title": "ChatGPT, Llama, can you write my report? An experiment on assisted digital forensics reports written using (local) large language models",
        "authors": "Gaëtan Michelet, Frank Breitinger",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.fsidi.2023.301683"
    },
    {
        "id": 12059,
        "title": "A Multimodal Approach to Device-Directed Speech Detection with Large Language Models",
        "authors": "Dominik Wagner, Alexander Churchill, Siddharth Sigtia, Panayiotis Georgiou, Matt Mirsamadi, Aarshee Mishra, Erik Marchi",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446224"
    },
    {
        "id": 12060,
        "title": "Deriving Language Models from Masked Language Models",
        "authors": "Lucas Torroba Hennigen, Yoon Kim",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-short.99"
    },
    {
        "id": 12061,
        "title": "CoLLiE: Collaborative Training of Large Language Models in an Efficient Way",
        "authors": "Kai Lv, Shuo Zhang, Tianle Gu, Shuhao Xing, Jiawei Hong, Keyu Chen, Xiaoran Liu, Yuqing Yang, Honglin Guo, Tengxiao Liu, Yu Sun, Qipeng Guo, Hang Yan, Xipeng Qiu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-demo.48"
    },
    {
        "id": 12062,
        "title": "Detecting Text Formality: A Study of Text Classification Approaches",
        "authors": "Daryna Dementieva,  , Nikolay Babakov, Alexander Panchenko,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_031"
    },
    {
        "id": 12063,
        "title": "Large Language Models in the Workplace: A Case Study on Prompt Engineering for Job Type Classification",
        "authors": "Benjamin Clavié, Alexandru Ciceu, Frederick Naylor, Guillaume Soulié, Thomas Brightwell",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-35320-8_1"
    },
    {
        "id": 12064,
        "title": "Formal Models in the Study of Language: Introduction",
        "authors": "Joanna Blochowiak, Cristina Grisot, Stéphanie Durrleman, Christopher Laenzlinger",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5_1"
    },
    {
        "id": 12065,
        "title": "Red Teaming Language Models with Language Models",
        "authors": "Ethan Perez, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat McAleese, Geoffrey Irving",
        "published": "2022",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.225"
    },
    {
        "id": 12066,
        "title": "nl2spec: Interactively Translating Unstructured Natural Language to Temporal Logics with Large Language Models",
        "authors": "Matthias Cosler, Christopher Hahn, Daniel Mendoza, Frederik Schmitt, Caroline Trippel",
        "published": "2023",
        "citations": 5,
        "abstract": "AbstractA rigorous formalization of desired system requirements is indispensable when performing any verification task. This often limits the application of verification techniques, as writing formal specifications is an error-prone and time-consuming manual task. To facilitate this, we present , a framework for applying Large Language Models (LLMs) to derive formal specifications (in temporal logics) from unstructured natural language. In particular, we introduce a new methodology to detect and resolve the inherent ambiguity of system requirements in natural language: we utilize LLMs to map subformulas of the formalization back to the corresponding natural language fragments of the input. Users iteratively add, delete, and edit these sub-translations to amend erroneous formalizations, which is easier than manually redrafting the entire formalization. The framework is agnostic to specific application domains and can be extended to similar specification languages and new neural models. We perform a user study to obtain a challenging dataset, which we use to run experiments on the quality of translations. We provide an open-source implementation, including a web-based frontend.",
        "link": "http://dx.doi.org/10.1007/978-3-031-37703-7_18"
    },
    {
        "id": 12067,
        "title": "Pretraining Language- and Domain-Specific BERT on Automatically Translated Text",
        "authors": "Tatsuya Ishigaki,  , Yui Uehara, Goran Topíc, Hiroya Takamura,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_060"
    },
    {
        "id": 12068,
        "title": "Poetry Generation Combining Poetry Theme Labels Representations",
        "authors": "Yingyu Yan,  , Dongzhen Wen, Liang Yang, Dongyu Zhang, Hongfei Lin,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_132"
    },
    {
        "id": 12069,
        "title": "Scaling Federated Learning for Fine-Tuning of Large Language Models",
        "authors": "Agrin Hilmkil, Sebastian Callh, Matteo Barbieri, Leon René Sütfeld, Edvin Listo Zec, Olof Mogren",
        "published": "2021",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-80599-9_2"
    },
    {
        "id": 12070,
        "title": "Cell2Sentence: Teaching Large Language Models the Language of Biology",
        "authors": "Daniel Levine, Sacha Lévy, Syed Asad Rizvi, Nazreen Pallikkavaliyaveetil, Xingyu Chen, David Zhang, Sina Ghadermarzi, Ruiming Wu, Zihe Zheng, Ivan Vrkic, Anna Zhong, Daphne Raskin, Insu Han, Antonio Henrique de Oliveira Fonseca, Josue Ortega Caro, Amin Karbasi, Rahul M. Dhodapkar, David van Dijk",
        "published": "No Date",
        "citations": 2,
        "abstract": "AbstractWe introduce Cell2Sentence (C2S), a novel method to directly adapt large language models to a biological context, specifically single-cell transcriptomics. By transforming gene expression data into “cell sentences,” C2S bridges the gap between natural language processing and biology. We demonstrate cell sentences enable the finetuning of language models for diverse tasks in biology, including cell generation, complex celltype annotation, and direct data-driven text generation. Our experiments reveal that GPT-2, when fine-tuned with C2S, can generate biologically valid cells based on cell type inputs, and accurately predict cell types from cell sentences. This illustrates that language models, through C2S finetuning, can acquire a significant understanding of single-cell biology while maintaining robust text generation capabilities. C2S offers a flexible, accessible framework to integrate natural language processing with transcriptomics, utilizing existing models and libraries for a wide range of biological applications.",
        "link": "http://dx.doi.org/10.1101/2023.09.11.557287"
    },
    {
        "id": 12071,
        "title": "AI Dialogue Interface based on Large Language Models － The state of the art AI dialogue models and seeking linguistic research topics －",
        "authors": "Kyong - Nim Lee, Eun - Kyoung Jo",
        "published": "2023-3-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15811/jkl.2023..105.010"
    },
    {
        "id": 12072,
        "title": "Explainable Integration of Knowledge Graphs Using Large Language Models",
        "authors": "Abdullah Fathi Ahmed, Asep Fajar Firmansyah, Mohamed Ahmed Sherif, Diego Moussallem, Axel-Cyrille Ngonga Ngomo",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-35320-8_9"
    },
    {
        "id": 12073,
        "title": "Measuring Gender Bias in Natural Language Processing: Incorporating Gender-Neutral Linguistic Forms for Non-Binary Gender Identities in Abusive Speech Detection",
        "authors": "Nasim Sobhani,  , Kinshuk Sengupta, Sarah Jane Delany,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_119"
    },
    {
        "id": 12074,
        "title": "Relations and language models",
        "authors": "",
        "published": "2019-11-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1049/pbpc026e_ch4"
    },
    {
        "id": 12075,
        "title": "Predicting Reference: What do Language Models Learn about Discourse Models?",
        "authors": "Shiva Upadhye, Leon Bergen, Andrew Kehler",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.70"
    },
    {
        "id": 12076,
        "title": "CombLM: Adapting Black-Box Language Models through Small Fine-Tuned Models",
        "authors": "Aitor Ormazabal, Mikel Artetxe, Eneko Agirre",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.180"
    },
    {
        "id": 12077,
        "title": "Foundation Models for Natural Language Processing",
        "authors": "Gerhard Paaß, Sven Giesselbach",
        "published": "2023",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-23190-2"
    },
    {
        "id": 12078,
        "title": "Language Models as Agent Models",
        "authors": "Jacob Andreas",
        "published": "2022",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-emnlp.423"
    },
    {
        "id": 12079,
        "title": "Warped Language Models for Noise Robust Language Understanding",
        "authors": "Mahdi Namazifar, Gokhan Tur, Dilek Hakkani-Tur",
        "published": "2021-1-19",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt48900.2021.9383493"
    },
    {
        "id": 12080,
        "title": "Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents",
        "authors": "Nishchal Prasad, Mohand Boughanem, Taoufiq Dkaki",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-56060-6_15"
    },
    {
        "id": 12081,
        "title": "Models for large ecological communities—a random matrix approach",
        "authors": "Stefano Allesina, Jacopo Grilli",
        "published": "2020-5-14",
        "citations": 2,
        "abstract": "Lotka and Volterra were among the first to attempt to mathematize the dynamics of interacting populations. While their work had a profound influence on ecology, leading to many of the results that were covered in the preceding chapters, their approach is difficult to generalize to the case of many interacting species. When the number of species in a community is sufficiently large, there is little hope of obtaining analytical results by carefully studying the system of dynamical equations describing their interactions. Here, we introduce an approach based on the theory of random matrices that exploits the very large number of species to derive cogent mathematical results. We review basic concepts in random matrix theory by illustrating their applications to the study of multispecies systems. We introduce tools that can be used to yield new insights into community ecology and conclude with a list of open problems.",
        "link": "http://dx.doi.org/10.1093/oso/9780198824282.003.0006"
    },
    {
        "id": 12082,
        "title": "Large Class Arabic Sign Language Recognition",
        "authors": "Zakia Saadaoui, Rakia Saidi, Fethi Jarray",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011539800003335"
    },
    {
        "id": 12083,
        "title": "Geographical axis effects in large-scale linguistic distributions",
        "authors": "Tom Güldemann, Harald Hammarström",
        "published": "2020-7-24",
        "citations": 3,
        "abstract": "Taking up Diamond’s (1999) geographical axis hypothesis regarding the different population histories of continental areas, Güldemann (2008, 2010) proposed that macro-areal aggregations of linguistic features are influenced by geographical factors. This chapter explores this idea by extending it to the whole world in testing whether the way linguistic features assemble over long time spans and large space is influenced by what we call “latitude spread potential” and “longitude spread constraint.” Regarding the former, the authors argue in particular that contact-induced feature distributions as well as genealogically defined language groups with a sufficient geographical extension tend to have a latitudinal orientation. Regarding the latter, the authors provide first results suggesting that linguistic diversity within language families tends to be higher along longitude axes. If replicated by more extensive and diverse testing, the authors’ findings promise to become important ingredients for a comprehensive theory of human history across space and time within linguistics and beyond.",
        "link": "http://dx.doi.org/10.1093/oso/9780198723813.003.0004"
    },
    {
        "id": 12084,
        "title": "Foundation Models for Speech, Images, Videos, and Control",
        "authors": "Gerhard Paaß, Sven Giesselbach",
        "published": "2023",
        "citations": 0,
        "abstract": "AbstractFoundation Models are able to model not only tokens of natural language but also token elements of arbitrary sequences. For images, square image patches can be represented as tokens; for videos, we can define tubelets that span an image patch across multiple frames. Subsequently, the proven self-attention algorithms can be applied to these tokens. Most importantly, several modalities like text and images can be processed in the same sequence allowing, for instance, the generation of images from text and text descriptions from video. In addition, the models are scalable to very large networks and huge datasets. The following multimedia types are covered in the subsequent sections. Speech recognition and text-to-speech models describe the translation of spoken language into text and vice versa. Image processing has the task to interpret images, describe them by captions, and generate new images according to textual descriptions. Video interpretation aims at recognizing action in videos and describing them through text. Furthermore, new videos can be created according to a textual description. Dynamical system trajectories characterize sequential decision problems, which can be simulated and controlled. DNA and protein sequences can be analyzed with Foundation Models to predict the structure and properties of the corresponding molecules.",
        "link": "http://dx.doi.org/10.1007/978-3-031-23190-2_7"
    },
    {
        "id": 12085,
        "title": "GPT-3-Powered Type Error Debugging: Investigating the Use of Large Language Models for Code Repair",
        "authors": "Francisco Ribeiro, José Nuno Castro de Macedo, Kanae Tsushima, Rui Abreu, João Saraiva",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3623476.3623522"
    },
    {
        "id": 12086,
        "title": "General-Purpose Large Language Models Versus a Domain-Specific Natural Language Processing Tool for Label Extraction From Chest Radiograph Reports",
        "authors": "Cody H. Savage, Hyoungsun Park, Kijung Kwak, Andrew D. Smith, Steven A. Rothenberg, Vishwa S. Parekh, Florence X. Doo, Paul H. Yi",
        "published": "2024-1-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2214/ajr.23.30573"
    },
    {
        "id": 12087,
        "title": "Exploring EFL university teachers’ beliefs in integrating ChatGPT and other large language models in language education: a study in China",
        "authors": "Yang Gao, Qikai Wang, Xiaochen Wang",
        "published": "2024-1-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/02188791.2024.2305173"
    },
    {
        "id": 12088,
        "title": "More Is Different: Large Language Models in Health Care",
        "authors": "Matthew P. Lungren, Elliot K. Fishman, Linda C. Chu, Ryan C. Rizk, Steven P. Rowe",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jacr.2023.11.021"
    },
    {
        "id": 12089,
        "title": "The Ethics of (Non)disclosure: Large Language Models in Professional, Nonacademic Writing Contexts",
        "authors": "Erick Piller,  ",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "This article explores the ethics of co-writing with large language models such as GPT-4 in professional, non-academic writing contexts without disclosing the practice to stakeholders. It considers five ethical concepts through an analysis of a hypothetical scenario. Three of the concepts—transparency, data practices, and expanded circulation—originate in the work of Heidi McKee and James Porter. The other two, just price and risk imposition, have particular relevance for professional writers. The article ultimately proposes that these five concepts can serve as points of reference as we attempt to formulate and articulate ethical judgments about co-writing with generative AI in specific, contextually grounded instances.",
        "link": "http://dx.doi.org/10.21659/rupkatha.v15n4.02"
    },
    {
        "id": 12090,
        "title": "On the use of large language models in the water domain: Navigating the Scylla of naïve techno-optimism and the Charybdis of technology denial",
        "authors": "Neelke Doorn",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.scitotenv.2023.164639"
    },
    {
        "id": 12091,
        "title": "Can You Answer This? – Exploring Zero-Shot QA Generalization Capabilities in Large Language Models (Student Abstract)",
        "authors": "Saptarshi Sengupta, Shreya Ghosh, Preslav Nakov, Prasenjit Mitra",
        "published": "2023-6-26",
        "citations": 0,
        "abstract": "The buzz around Transformer-based language models (TLM) such as BERT, RoBERTa, etc. is well-founded owing to their impressive results on an array of tasks. However, when applied to areas needing specialized knowledge (closed-domain), such as medical, finance, etc. their performance takes drastic hits, sometimes more than their older recurrent/convolutional counterparts. In this paper, we explore zero-shot capabilities of large LMs for extractive QA. Our objective is to examine performance change in the face of domain drift i.e. when the target domain data is vastly different in semantic and statistical properties from the source domain and attempt to explain the subsequent behavior. To this end, we present two studies in this paper while planning further experiments later down the road. Our findings indicate flaws in the current generation of TLM limiting their performance on closed-domain tasks.",
        "link": "http://dx.doi.org/10.1609/aaai.v37i13.27019"
    },
    {
        "id": 12092,
        "title": "Synthetic predictabilities from large language models explain reading eye movements",
        "authors": "Johan Chandra, Nicholas Witzig, Jochen Laubrock",
        "published": "2023-5-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3588015.3588420"
    },
    {
        "id": 12093,
        "title": "Evaluating the Performance of different large language models on health consultation and patient education in urolithiasis",
        "authors": "Haifeng Song, Yi Xia, Zhichao Luo, Hui Liu, Yan Song, Xue Zeng, Tianjie Li, Guangxin Zhong, Jianxing Li, Ming Chen, Guangyuan Zhang, Bo Xiao",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nObjectives\n To evaluate the effectiveness of four large language models (LLMs) (Claude, Bard, ChatGPT4, and New Bing) that have large user bases and significant social attention, in the context of medical consultation and patient education in urolithiasis.\nMaterials and methods\n In this study, we developed a questionnaire consisting of twenty-one questions and two clinical scenarios related to urolithiasis. Subsequently, clinical consultations were simulated for each of the four models to assess their responses to the questions. Urolithiasis experts then evaluated the model responses in terms of accuracy, comprehensiveness, legibility, human care, and clinical case analysis ability based on a predesigned 5-point Likert scales. Visualization and statistical analyses were then employed to compare the four models and evaluate their performance.\nResults\n All models yielded relatively qualified results, except for Bard, which failed to provide a valid response to Question 13. Claude consistently scored the highest in all dimensions compared with the other three models. ChatGPT4 ranked second in accuracy, with a relatively stable output across multiple tests, but shortcomings were observed in empathy and care for counsellors. The Bard model exhibited the lowest accuracy and overall performance. Claude and ChatGPT4 both had a high capacity to analyze clinical cases of urolithiasis. Overall, the Claude model emerged as the best performer in urolithiasis consultations and education.\nConclusion\n Claude demonstrated superior performance compared with the other three in urolithiasis consultation and education. This study highlights the remarkable potential of LLMs in medical health consultations and patient education, although professional review, further evaluation, and modifications are still required.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3293294/v1"
    },
    {
        "id": 12094,
        "title": "Improving mathematics assessment readability: Do large language models help?",
        "authors": "Nirmal Patel, Pooja Nagpal, Tirth Shah, Aditya Sharma, Shrey Malvi, Derek Lomas",
        "published": "2023-6",
        "citations": 4,
        "abstract": "AbstractBackgroundReadability metrics provide us with an objective and efficient way to assess the quality of educational texts. We can use the readability measures for finding assessment items that are difficult to read for a given grade level. Hard‐to‐read math word problems can put some students at a disadvantage if they are behind in their literacy learning. Despite their math abilities, these students can perform poorly on difficult‐to‐read word problems because of their poor reading skills. Less readable math tests can create equity issues for students who are relatively new to the language of assessment. Less readable test items can also affect the assessment's construct validity by partially measuring reading comprehension.ObjectivesThis study shows how large language models help us improve the readability of math assessment items.MethodsWe analysed 250 test items from grades 3 to 5 of EngageNY, an open‐source curriculum. We used the GPT‐3 AI system to simplify the text of these math word problems. We used text prompts and the few‐shot learning method for the simplification task.Results and ConclusionsOn average, GPT‐3 AI produced output passages that showed improvements in readability metrics, but the outputs had a large amount of noise and were often unrelated to the input. We used thresholds over text similarity metrics and changes in readability measures to filter out the noise. We found meaningful simplifications that can be given to item authors as suggestions for improvement.TakeawaysGPT‐3 AI is capable of simplifying hard‐to‐read math word problems. The model generates noisy simplifications using text prompts or few‐shot learning methods. The noise can be filtered using text similarity and readability measures. The meaningful simplifications AI produces are sound but not ready to be used as a direct replacement for the original items. To improve test quality, simplifications can be suggested to item authors at the time of digital question authoring.",
        "link": "http://dx.doi.org/10.1111/jcal.12776"
    },
    {
        "id": 12095,
        "title": "The promises of large language models for protein design and modeling",
        "authors": "Giorgio Valentini, Dario Malchiodi, Jessica Gliozzo, Marco Mesiti, Mauricio Soto-Gomez, Alberto Cabri, Justin Reese, Elena Casiraghi, Peter N. Robinson",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "The recent breakthroughs of Large Language Models (LLMs) in the context of natural language processing have opened the way to significant advances in protein research. Indeed, the relationships between human natural language and the “language of proteins” invite the application and adaptation of LLMs to protein modelling and design. Considering the impressive results of GPT-4 and other recently developed LLMs in processing, generating and translating human languages, we anticipate analogous results with the language of proteins. Indeed, protein language models have been already trained to accurately predict protein properties, generate novel functionally characterized proteins, achieving state-of-the-art results. In this paper we discuss the promises and the open challenges raised by this novel and exciting research area, and we propose our perspective on how LLMs will affect protein modeling and design.",
        "link": "http://dx.doi.org/10.3389/fbinf.2023.1304099"
    },
    {
        "id": 12096,
        "title": "Comment on “The impact and opportunities of large language models like ChatGPT in oral and maxillofacial surgery: a narrative review”",
        "authors": "H. Daungsupawong, V. Wiwanitkit",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ijom.2023.11.014"
    },
    {
        "id": 12097,
        "title": "Letter to the Editor: Radiology in the era of large language models: additional facts to consider in the near and the dark side of the moon",
        "authors": "Arosh S. Perera Molligoda Arachchige",
        "published": "2023-11-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00330-023-10330-x"
    },
    {
        "id": 12098,
        "title": "Exploring the Application of Large Language Models in Detecting and Protecting Personally Identifiable Information in Archival Data: A Comprehensive Study*",
        "authors": "Jianliang Yang, Xiya Zhang, Kai Liang, Yuenan Liu",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386949"
    },
    {
        "id": 12099,
        "title": "How to use large language models in ophthalmology: from prompt engineering to protecting confidentiality",
        "authors": "Oliver Kleinig, Christina Gao, Joshua G. Kovoor, Aashray K. Gupta, Stephen Bacchi, Weng Onn Chan",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41433-023-02772-w"
    },
    {
        "id": 12100,
        "title": "Red Teaming for Large Language Models At Scale: Tackling Hallucinations on Mathematics Tasks",
        "authors": "Aleksander Buszydlik, Karol Dobiczek, Michał Teodor Okoń, Konrad Skublicki, Philip Lippmann, Jie Yang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.artofsafety-1.1"
    },
    {
        "id": 12101,
        "title": "Enhanced Story Comprehension for Large Language Models through Dynamic Document-Based Knowledge Graphs",
        "authors": "Berkeley R Andrus, Yeganeh Nasiri, Shilong Cui, Benjamin Cullen, Nancy Fulda",
        "published": "2022-6-28",
        "citations": 3,
        "abstract": "Large transformer-based language models have achieved incredible success at various tasks which require narrative comprehension, including story completion, answering questions about stories, and generating stories ex nihilo. However, due to the limitations of finite context windows, these language models struggle to produce or understand stories longer than several thousand tokens. In order to mitigate the document length limitations that come with finite context windows, we introduce a novel architecture that augments story processing with an external dynamic knowledge graph. In contrast to static commonsense knowledge graphs which hold information about the real world, these dynamic knowledge graphs reflect facts extracted from the story being processed. Our architecture uses these knowledge graphs to create information-rich prompts which better facilitate story comprehension than prompts composed only of story text. We apply our architecture to the tasks of question answering and story completion. To complement this line of research, we introduce two long-form question answering tasks, LF-SQuAD and LF-QUOREF, in which the document length exceeds the size of the language model's context window, and introduce a story completion evaluation method that bypasses the stochastic nature of language model generation. We demonstrate broad improvement over typical prompt formulation methods for both question answering and story completion using GPT-2, GPT-3 and XLNet.",
        "link": "http://dx.doi.org/10.1609/aaai.v36i10.21286"
    },
    {
        "id": 12102,
        "title": "Red Teaming for Large Language Models At Scale: Tackling Hallucinations on Mathematics Tasks",
        "authors": "Aleksander Buszydlik, Karol Dobiczek, Michał Teodor Okoń, Konrad Skublicki, Philip Lippmann, Jie Yang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.artofsafety-1.1"
    },
    {
        "id": 12103,
        "title": "Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study",
        "authors": "Yuan Sui, Mengyu Zhou, Mingjie Zhou, Shi Han, Dongmei Zhang",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3616855.3635752"
    },
    {
        "id": 12104,
        "title": "Generative Large Language Models for Detection of Speech Recognition Errors in Radiology Reports",
        "authors": "Reuben A. Schmidt, Jarrel C. Y. Seah, Ke Cao, Lincoln Lim, Wei Lim, Justin Yeung",
        "published": "2024-3-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1148/ryai.230205"
    },
    {
        "id": 12105,
        "title": "Beyond the Limit of Weight-Sharing: Pioneering Space-Evolving NAS with Large Language Models",
        "authors": "Xiu Su, Shan You, Hongyan Xu, Xiuxing Li, Jun Long, Yi Chen, Chang Xu",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10448075"
    },
    {
        "id": 12106,
        "title": "A Sound Approach: Using Large Language Models to Generate Audio Descriptions for Egocentric Text-Audio Retrieval",
        "authors": "Andreea-Maria Oncescu, João F. Henriques, Andrew Zisserman, Samuel Albanie, A. Sophia Koepke",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10448486"
    },
    {
        "id": 12107,
        "title": "Adopting Pre-trained Large Language Models for Regional Language Tasks: A Case Study",
        "authors": "Harsha Gaikwad, Arvind Kiwelekar, Manjushree Laddha, Shashank Shahare",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-53827-8_2"
    },
    {
        "id": 12108,
        "title": "Application of the AIGC Large Language Model in College English Writing Teaching",
        "authors": "Tang Yingying",
        "published": "2024-2-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.57237/j.cll.2024.01.002"
    },
    {
        "id": 12109,
        "title": "Highway Construction Safety Analysis Using Large Language Models",
        "authors": "Mason Smetana, Lucio Salles de Salles, Igor Sukharev, Lev Khazanovich",
        "published": "2024-2-6",
        "citations": 0,
        "abstract": "The highway construction industry carries substantial safety risks for workers, necessitating thorough accident analyses to implement effective preventive measures. Current research lacks comprehensive investigations into safety incidents, relying heavily on conventional statistical methods and overlooking valuable textual information in publicly available databases. This study leverages a state-of-the-art large language model (LLM), specifically OpenAI’s GPT-3.5 model. The primary focus is to enhance text-based incident analysis that is sourced from OSHA’s Severe Injury Reports (SIR) database. By incorporating novel natural language processing (NLP) techniques, dimensionality reduction, clustering algorithms, and LLM prompting of incident narratives, the study aims to develop an approach to the analysis of major accident causes in highway construction. The resulting cluster analysis, coupled with LLM summarization and cause identification, reveals the major accident types, such as heat-related and struck-by injuries, as well as commonalities between incidents. This research showcases the potential of artificial intelligence (AI) and LLM technology in data-driven analysis. By efficiently processing textual data and providing insightful analysis, the study fosters practical implications for safety professionals and the development of more effective accident prevention and intervention strategies within the industry.",
        "link": "http://dx.doi.org/10.3390/app14041352"
    },
    {
        "id": 12110,
        "title": "Enhancing Robot Task Planning and Execution through Multi-Layer Large Language Models",
        "authors": "Zhirong Luan, Yujun Lai, Rundong Huang, Shuanghao Bai, Yuedi Zhang, Haoran Zhang, Qian Wang",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "Large language models have found utility in the domain of robot task planning and task decomposition. Nevertheless, the direct application of these models for instructing robots in task execution is not without its challenges. Limitations arise in handling more intricate tasks, encountering difficulties in effective interaction with the environment, and facing constraints in the practical executability of machine control instructions directly generated by such models. In response to these challenges, this research advocates for the implementation of a multi-layer large language model to augment a robot’s proficiency in handling complex tasks. The proposed model facilitates a meticulous layer-by-layer decomposition of tasks through the integration of multiple large language models, with the overarching goal of enhancing the accuracy of task planning. Within the task decomposition process, a visual language model is introduced as a sensor for environment perception. The outcomes of this perception process are subsequently assimilated into the large language model, thereby amalgamating the task objectives with environmental information. This integration, in turn, results in the generation of robot motion planning tailored to the specific characteristics of the current environment. Furthermore, to enhance the executability of task planning outputs from the large language model, a semantic alignment method is introduced. This method aligns task planning descriptions with the functional requirements of robot motion, thereby refining the overall compatibility and coherence of the generated instructions. To validate the efficacy of the proposed approach, an experimental platform is established utilizing an intelligent unmanned vehicle. This platform serves as a means to empirically verify the proficiency of the multi-layer large language model in addressing the intricate challenges associated with both robot task planning and execution.",
        "link": "http://dx.doi.org/10.3390/s24051687"
    },
    {
        "id": 12111,
        "title": "Use of Generative Artificial Intelligence, Including Large Language Models Such as ChatGPT, in Scientific Publications: Policies of <i>KJR</i> and Prominent Authorities",
        "authors": "Seong Ho Park",
        "published": "2023",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3348/kjr.2023.0643"
    },
    {
        "id": 12112,
        "title": "Assessing How Large Language Models Can Be Integrated with or Used for Blockchain Technology: Overview and Illustrative Case Study",
        "authors": "Jean Gilbert Mbula Mboma, Obed Tshimanga Tshipata, Witesyavwirwa Vianney Kambale, Kyandoghere Kyamakya",
        "published": "2023-7-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cscc58962.2023.00018"
    },
    {
        "id": 12113,
        "title": "The Pulse of Artificial Intelligence in Cardiology: A Comprehensive Evaluation of State-of-the-art Large Language Models for Potential Use in Clinical Cardiology",
        "authors": "Andrej Novak, Fran Rode, Ante Lisičić, Iskra A. Nola, Ivan Zeljković, Nikola Pavlović, Šime Manola",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractIntroductionDuring the last few years, we have witnessed a surge in the utilization of Large Language Models (LLMs) for diverse applications in clinical medicine. Their utility extends to enhancing ECG interpretation, data analysis, and risk prediction in cardiology. This study aims to evaluate the accuracy of LLMs in answering cardiology-specific questions of various difficulty levels.MethodsThis study undertakes a comparative analysis of three state-of-the-art LLMs: Google Bard, GPT-3.5 Turbo, and GPT-4.0, against four distinct sets of clinical scenarios with increasing complexity. These scenarios cover a range of cardiovascular topics, from prevention to the management of acute illnesses and complex pathologies. The responses generated by the LLMs were assessed for accuracy, understanding of medical terminology, clinical relevance, and appropriateness. The evaluations were conducted by a panel of experienced cardiologists.ResultsAll models showed an understanding of medical terminology, but the application of this knowledge varied. GPT-4.0 outperforms Google Bard and GPT-3.5 Turbo across a spectrum of cardiology-related clinical scenarios, demonstrating a strong understanding of medical terminology, contextual understanding, and most proficiently aligning its responses with current guidelines. Limitations were seen in the models’ abilities to reference ongoing clinical trials.ConclusionLLMs showed promising results in ability to interpret and apply complex clinical guidelines when answering vignette-based clinical queries, with a potential for enhancing patient outcomes through personalized advice. However, they should be utilized with a grain of salt, as supplementary tools in clinical cardiology.",
        "link": "http://dx.doi.org/10.1101/2023.08.08.23293689"
    },
    {
        "id": 12114,
        "title": "Realizing the cooking recipe of materials synthesis through large language models",
        "authors": "Jaydeep Thik, Siwen Wang, Chuhong Wang, Hadi Mansourifar, Honghong Lin, Keiichi Okubo, Chen Ling",
        "published": "2023",
        "citations": 0,
        "abstract": "LLMs offer a promising and viable direction to convert materials synthesis descriptions into recipe-like outputs effectively preserving the order of synthesis steps. LLMs show true potential to guide experimental design using materials literature.",
        "link": "http://dx.doi.org/10.1039/d3ta05457h"
    },
    {
        "id": 12115,
        "title": "Harnessing Large Language Models in Medical Research and Scientific Writing: A Closer Look to The Future",
        "authors": "Mohammad Abu-Jeyyab, Sallam Alrosan, Ibraheem Alkhawaldeh",
        "published": "2023-12-9",
        "citations": 0,
        "abstract": "Large Language Models (LLMs), a form of artificial intelligence generating natural language responses based on user input, have demonstrated potential across various applications such as entertainment, education, and customer service. This review comprehensively highlights their current research status and potential applications within the medical domain, addressing the challenges and opportunities for future development and implementation. Key aspects covered include diverse data sources for training and testing, such as electronic health records and clinical trials; ethical considerations, including privacy and consent; evaluation techniques focusing on accuracy and coherence; and clinical applications ranging from diagnosis to patient education. The review concludes that LLMs hold significant promise for enhancing the quality and efficiency of medical research and scientific writing but also emphasize the need for careful design and regulation to ensure safety and reliability.",
        "link": "http://dx.doi.org/10.59707/hymrfbya5348"
    },
    {
        "id": 12116,
        "title": "Große Sprachmodelle wie ChatGPT und GPT-4 für eine patientenzentrierte Radiologie",
        "authors": "Matthias A. Fink",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00117-023-01187-8"
    },
    {
        "id": 12117,
        "title": "Say What You Mean! Large Language Models Speak Too Positively about Negative Commonsense Knowledge",
        "authors": "Jiangjie Chen, Wei Shi, Ziquan Fu, Sijie Cheng, Lei Li, Yanghua Xiao",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.550"
    },
    {
        "id": 12118,
        "title": "Harnessing Large Language Models to Simulate Realistic Human Responses to Social Engineering Attacks: A Case Study",
        "authors": "Mohammad Asfour, Juan Carlos Murillo",
        "published": "2023-8-30",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.52306/2578-3289.1172"
    },
    {
        "id": 12119,
        "title": "Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models",
        "authors": "Stephen Macneil, Paul Denny, Andrew Tran, Juho Leinonen, Seth Bernstein, Arto Hellas, Sami Sarsa, Joanne Kim",
        "published": "2024-1-29",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3636243.3636245"
    },
    {
        "id": 12120,
        "title": "Toward AI-Assisted Clinical Assessment for Patients with Multiple Myeloma: Feature Selection for Large Language Models",
        "authors": "Ehsan Malek, Gi-Ming Wang, Anant Madabhushi, Jennifer Cullen, Curtis Tatsuoka, James J. Driscoll",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "\nLarge language models (LLM) can potentially revolutionize the healthcare industry. They could reduce the burden on healthcare, increase care accessibility in areas with shortage and provide multilingual support to break down language barriers. Although, these models equipped with vast amounts of medical knowledge and the ability to understand and generate human-like text, require a proper set of feeding data (i.e., prompt engineering) for accurate diagnosis and providing reliable personalized treatment plans for patients.\nMultiple Myeloma (MM) is a complex hematological malignancy characterized by the uncontrolled proliferation of plasma cells in the bone marrow. Disease management for MM becomes particularly challenging due to its multisystemic nature based on the varying volume of malignant cells within the bone marrow. Implementing LLMs for clinical assessment of patients with MM needs feature selection to develop the most effective prompt for these models. Here, we utilized a machine learning (ML) approach to define salient features in a typical visit day that correlates most significantly with disease volume on the same day. These features could be the best candidate to reflect the multisystemic and dynamic nature of MM in each visit, and they could be candidates to be incorporated into LLMs to develop a system-based assessment in clinic visits.\nMethods: This study examined 1,472 clinical observations. To select a curated list of features associated with same-day M-spike values, 43 clinical and lab variables were input into an ML model. Random Forest (RF), an ensemble of regression trees suitable for nonlinear multiple regression, was selected as the model. The data were randomly divided into a training set (80%) and a test set (20%) for model validation. Using bootstrapping and generating 500 data sets, a random forest of regression trees was constructed, and results and estimates were aggregated across the trees. To determine the importance of each covariate, their inclusion and exclusion were compared in the models.\nResults: The residual distribution of the RF model indicated that nearly all M-spike values determined using the 43 variables distributed equally on either side of zero (Fig. 1). The weighted value of each of the 43 independent variables was determined by individually removing a variable from the ML algorithm and measuring its effect on the mean squared error (MSE) (Fig.2). Removal of the first lagged M-spike, serum total protein, second-lagged M-spike, serum IgG, serum IgM, and serum IgA, had the greatest effects on the ML algorithm. M-spike values determined using the ML algorithm correlated highly with M-spike values determined using the laboratory measured SPEP values as indicated by the proximity of the Pearson and Spearman correlation coefficients to +1. Using the 43 variables, the Pearson coefficient was 0.96 and the Spearman coefficient was 0.91. Feature selected modeling was performed to reduce the variables needed to predict the M-spike. Five RF models with different predictors were selected for comparison. Model A included all 43 predictors, Model B included the ten most important variables, Model C the top five variables, Model D included the first and second-lagged M-spike and serum total protein, and Model E the first-lagged M-spike and serum total protein. The Pearson's r and RMSE (root mean square error) values were used to compare the models. Pearson's r values for Model A, B, C, and D were 0.96, 0.96, 0.96, and 0.95 respectively, and the RMSE values were 0.21, 0.19, 0.19, and 0.22. In Model E, feature selection used only two variables and accurately predicted the M-spike value (Pearson's r = 0.95; RMSE 0.22). The Pearson's r values for feature selected models A, B, C, D, and E were 0.95, 0.96, 0.96, 0.95 and 0.91.\nConclusion: Accurate prompt engineering to create global assessment of Myeloma clone by LLM requires a curated set of variables that correlated with disease volume. Here, we developed an ML model for feature selection utilizing the same-day available data in the patient chart. Features could be used in order of importance to provide focused, comprehensive prompts that aligned with the patient's context. The quality of AI-assisted disease assessment using these models should be compared with assessments performed by real world providers in future studies to ensure that the LLMs generate a written assessment that accurately reflects the patient's health status.",
        "link": "http://dx.doi.org/10.1182/blood-2023-172710"
    },
    {
        "id": 12121,
        "title": "Do large language models show decision heuristics similar to humans? A case study using GPT-3.5.",
        "authors": "Gaurav Suri, Lily R. Slater, Ali Ziaee, Morgan Nguyen",
        "published": "2024-2-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1037/xge0001547"
    },
    {
        "id": 12122,
        "title": "Application and accuracy of artificial intelligence-derived large language models in patients with age related macular degeneration",
        "authors": "Lorenzo Ferro Desideri, Janice Roth, Martin Zinkernagel, Rodrigo Anguita",
        "published": "2023-11-18",
        "citations": 2,
        "abstract": "Abstract\nIntroduction\nAge-related macular degeneration (AMD) affects millions of people globally, leading to a surge in online research of putative diagnoses, causing potential misinformation and anxiety in patients and their parents. This study explores the efficacy of artificial intelligence-derived large language models (LLMs) like in addressing AMD patients' questions.\n\nMethods\nChatGPT 3.5 (2023), Bing AI (2023), and Google Bard (2023) were adopted as LLMs. Patients’ questions were subdivided in two question categories, (a) general medical advice and (b) pre- and post-intravitreal injection advice and classified as (1) accurate and sufficient (2) partially accurate but sufficient and (3) inaccurate and not sufficient. Non-parametric test has been done to compare the means between the 3 LLMs scores and also an analysis of variance and reliability tests were performed among the 3 groups.\n\nResults\nIn category a) of questions, the average score was 1.20 (± 0.41) with ChatGPT 3.5, 1.60 (± 0.63) with Bing AI and 1.60 (± 0.73) with Google Bard, showing no significant differences among the 3 groups (p = 0.129). The average score in category b was 1.07 (± 0.27) with ChatGPT 3.5, 1.69 (± 0.63) with Bing AI and 1.38 (± 0.63) with Google Bard, showing a significant difference among the 3 groups (p = 0.0042). Reliability statistics showed Chronbach’s α of 0.237 (range 0.448, 0.096–0.544).\n\nConclusion\nChatGPT 3.5 consistently offered the most accurate and satisfactory responses, particularly with technical queries. While LLMs displayed promise in providing precise information about AMD; however, further improvements are needed especially in more technical questions.\n",
        "link": "http://dx.doi.org/10.1186/s40942-023-00511-7"
    },
    {
        "id": 12123,
        "title": "Automated Tailoring of Large Language Models for Industry-Specific Downstream Tasks",
        "authors": "Shreya Saxena, Siva Prasad, Muneeswaran I, Advaith Shankar, Varun V, Saisubramaniam Gopalakrishnan, Vishal Vaddina",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3616855.3635743"
    },
    {
        "id": 12124,
        "title": "The impending impacts of large language models on medical education",
        "authors": "Sangzin Ahn",
        "published": "2023-3-1",
        "citations": 17,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3946/kjme.2023.253"
    },
    {
        "id": 12125,
        "title": "From ChatGPT to Treatment: the Future of AI and Large Language Models in Surgical Oncology",
        "authors": "Adhitya Ramamurthi, Chandrakanth Are, Anai N. Kothari",
        "published": "2023-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s13193-023-01836-3"
    },
    {
        "id": 12126,
        "title": "Generative Expressive Robot Behaviors using Large Language Models",
        "authors": "Karthik Mahadevan, Jonathan Chien, Noah Brown, Zhuo Xu, Carolina Parada, Fei Xia, Andy Zeng, Leila Takayama, Dorsa Sadigh",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3610977.3634999"
    },
    {
        "id": 12127,
        "title": "Large Language Models are Diverse Role-Players for Summarization Evaluation",
        "authors": "Ning Wu, Ming Gong, Linjun Shou, Shining Liang, Daxin Jiang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-44693-1_54"
    },
    {
        "id": 12128,
        "title": "Exploring the perspective of infection clinicians on the integration of Large Language Models (LLMs) in clinical practice: A deep learning study in healthcare",
        "authors": "S.V. Praveen, R. Deepika",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jinf.2023.07.011"
    },
    {
        "id": 12129,
        "title": "Contextual Spelling Correction with Large Language Models",
        "authors": "Gan Song, Zelin Wu, Golan Pundak, Angad Chandorkar, Kandarp Joshi, Xavier Velez, Diamantino Caseiro, Ben Haynor, Weiran Wang, Nikhil Siddhartha, Pat Rondon, Khe Chai Sim",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/asru57964.2023.10389637"
    },
    {
        "id": 12130,
        "title": "Considerations for adapting higher education technology courses for AI large language models: A critical review of the impact of ChatGPT",
        "authors": "Omar Tayan, Ali Hassan, Khaled Khankan, Sanaa Askool",
        "published": "2024-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100513"
    },
    {
        "id": 12131,
        "title": "Authors’ Reply to: Variability in Large Language Models’ Responses to Medical Licensing and Certification Examinations",
        "authors": "Aidan Gilson, Conrad W Safranek, Thomas Huang, Vimig Socrates, Ling Chi, Richard Andrew Taylor, David Chartash",
        "published": "2023-7-13",
        "citations": 1,
        "abstract": "",
        "link": "http://dx.doi.org/10.2196/50336"
    },
    {
        "id": 12132,
        "title": "Toward automatic generation of control structures for process flow diagrams with large language models",
        "authors": "Edwin Hirtreiter, Lukas Schulze Balhorn, Artur M. Schweidtmann",
        "published": "2024-1",
        "citations": 2,
        "abstract": "AbstractDeveloping Piping and Instrumentation Diagrams (P&IDs) is a crucial step during process development. We propose a data‐driven method for the prediction of control structures. Our methodology is inspired by end‐to‐end transformer‐based human language translation models. We cast the control structure prediction as a translation task where Process Flow Diagrams (PFDs) without control structures are translated to PFDs with control structures. We represent the topology of PFDs as strings using the SFILES 2.0 notation. We pretrain our model using generated PFDs to learn the grammatical structure. Thereafter, the model is fine‐tuned leveraging transfer learning on real PFDs. The model achieved a top‐5 accuracy of 74.8% on 10,000 generated PFDs and 89.2% on 100,000 generated PFDs. These promising results show great potential for AI‐assisted process engineering. The tests on a dataset of 312 real PFDs indicate the need for a larger PFD dataset for industry applications and hybrid artificial intelligence solutions.",
        "link": "http://dx.doi.org/10.1002/aic.18259"
    },
    {
        "id": 12133,
        "title": "Beyond the limitations of any imaginable mechanism: Large language models and psycholinguistics",
        "authors": "Conor Houghton, Nina Kazanina, Priyanka Sukumaran",
        "published": "2023",
        "citations": 0,
        "abstract": "Abstract\nLarge language models (LLMs) are not detailed models of human linguistic processing. They are, however, extremely successful at their primary task: Providing a model for language. For this reason LLMs are important in psycholinguistics: They are useful as a practical tool, as an illustrative comparative, and philosophically, as a basis for recasting the relationship between language and thought.",
        "link": "http://dx.doi.org/10.1017/s0140525x23001693"
    },
    {
        "id": 12134,
        "title": "Automated Central Bank Policy Question and Answer System based on Large Language Models",
        "authors": "Shanshan Yan, Fengting Mo, Huixi Li, Yinhao Xiao",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4108/eai.27-10-2023.2341977"
    },
    {
        "id": 12135,
        "title": "Prompt Incorporates Math Knowledge to Improve Efficiency and Quality of Large Language Models to Translate Math Word Problems",
        "authors": "Hao Wu, Xinguo Yu",
        "published": "2023-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ieir59294.2023.10391245"
    },
    {
        "id": 12136,
        "title": "Unifying Large Language Models and Knowledge Graphs: A Roadmap",
        "authors": "Shirui Pan, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, Xindong Wu",
        "published": "2024",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tkde.2024.3352100"
    },
    {
        "id": 12137,
        "title": "Using large language models to evaluate the offer of options in clinical encounters by focusing on an item of the Observer OPTION-5 measure of shared decision-making (Preprint)",
        "authors": "Sai Prabhakar Pandi Selvaraj, Renata West Yen, Rachel Forcino, Glyn Elwyn",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\nIntroduction: Human assessment of clinical encounter recordings using observer-based measures of shared decision-making, such as Observer OPTION-5 (OO5), is expensive. In this study, we aimed to assess the potential of using large language models (LLMs) to automate the rating of the OO5 item focused on offering options (item 1).\n\nMethods: We used a dataset of 287 clinical encounter transcripts of women diagnosed with early breast talking with their surgeon to discuss treatments. Each transcript had been previously scored by two researchers using OO5 (0 to 4 scale). We set up two rules-based baselines, one random and one using trigger words, and classified option talk instances using GPT-3.5 Turbo, GPT-4, and PaLM 2. To develop and compare the performance of these models, we randomly selected 16 transcripts for additional human annotation focusing on option talk instances (binary). To assess performance, we calculated Spearman correlations (rS) between the researcher-generated scores for item 1 for the remaining 271 transcripts and the item 1 instances predicted by the LLMs.\n\nResults: We observed high levels of correlation between the LLMs and researcher-generated scores. GPT-3.5 Turbo with a few-shot example had an rS=0.60 (P<.001) with the mean of the two scorers. Other LLMs had slightly lower correlation levels.\n\nDiscussion: The LLMs, particularly GPT-3.5 Turbo with few-shot examples, demonstrated superior performance in identifying option talk instances compared to baseline models. GPT-3.5 Turbo demonstrated the best performance, achieving higher precision and recall.\n\nConclusions: Further improvements in score correlations may be possible through improvements in and better understanding of LLMs.\n",
        "link": "http://dx.doi.org/10.2196/preprints.57790"
    },
    {
        "id": 12138,
        "title": "LLM-TAKE: Theme-Aware Keyword Extraction Using Large Language Models",
        "authors": "Reza Yousefi Maragheh, Chenhao Fang, Charan Chand Irugu, Parth Parikh, Jason Cho, Jianpeng Xu, Saranyan Sukumar, Malay Patel, Evren Korpeoglu, Sushant Kumar, Kannan Achan",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386476"
    },
    {
        "id": 12139,
        "title": "Large Language Models as Tax Attorneys: A Case Study in Legal Capabilities Emergence",
        "authors": "John Nay, David Karamardian, Sarah B. Lawsky, Wenting Tao, Meghana Bhat, Raghav Jain, Aaron Travis Lee, Jonathan H. Choi, Jungo Kasai",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4476325"
    },
    {
        "id": 12140,
        "title": "SceneCraft: Automating Interactive Narrative Scene Generation in Digital Games with Large Language Models",
        "authors": "Vikram Kumaran, Jonathan Rowe, Bradford Mott, James Lester",
        "published": "2023-10-6",
        "citations": 2,
        "abstract": "Creating engaging interactive story-based experiences dynamically responding to individual player choices poses significant challenges for narrative-centered games. Recent advances in pre-trained large language models (LLMs) have the potential to revolutionize procedural content generation for narrative-centered games. Historically, interactive narrative generation has specified pivotal events in the storyline, often utilizing planning-based approaches toward achieving narrative coherence and maintaining the story arc. However, manual authorship is typically used to create detail and variety in non-player character (NPC) interaction to specify and instantiate plot events. This paper proposes SCENECRAFT, a narrative scene generation framework that automates NPC interaction crucial to unfolding plot events. SCENECRAFT interprets natural language instructions about scene objectives, NPC traits, location, and narrative variations. It then employs large language models to generate game scenes aligned with authorial intent. It generates branching conversation paths that adapt to player choices while adhering to the author’s interaction goals. LLMs generate interaction scripts, semantically extract character emotions and gestures to align with the script, and convert dialogues into a game scripting language. The generated script can then be played utilizing an existing narrative-centered game framework. Through empirical evaluation using automated and human assessments, we demonstrate SCENECRAFT’s effectiveness in creating narrative experiences based on creativity, adaptability, and alignment with intended author instructions.",
        "link": "http://dx.doi.org/10.1609/aiide.v19i1.27504"
    },
    {
        "id": 12141,
        "title": "Embodied intelligence in manufacturing: leveraging large language models for autonomous industrial robotics",
        "authors": "Haolin Fan, Xuan Liu, Jerry Ying Hsi Fuh, Wen Feng Lu, Bingbing Li",
        "published": "2024-1-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10845-023-02294-y"
    },
    {
        "id": 12142,
        "title": "Computational Thematic Analysis of Poetry via Bimodal Large Language Models",
        "authors": "Kahyun Choi",
        "published": "2023-10",
        "citations": 0,
        "abstract": "ABSTRACTThis article proposes a multilabel poem topic classification algorithm utilizing large language models and auxiliary data to address the lack of diverse metadata in digital poetry libraries. The study examines the potential of context‐dependent language models, specifically bidirectional encoder representations from transformers (BERT), for understanding poetic words and utilizing auxiliary data, such as author's notes, in supplementing poetry text. The experimental results demonstrate that the BERT‐based model outperforms the traditional support vector machine‐based model across all input types and datasets. We also show that incorporating notes as an additional input improves the performance of the poem‐only model. Overall, the study suggests pretrained context‐dependent language models and auxiliary data have potential to enhance the accessibility of various poems within collections. This research can eventually assist in promoting the discovery of underrepresented poems in digital libraries, even if they lack associated metadata, thus enhancing the understanding and appreciation of the literary form.",
        "link": "http://dx.doi.org/10.1002/pra2.812"
    },
    {
        "id": 12143,
        "title": "The role of large language models in medical image processing: a narrative review",
        "authors": "Dianzhe Tian, Shitao Jiang, Lei Zhang, Xin Lu, Yiyao Xu",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21037/qims-23-892"
    },
    {
        "id": 12144,
        "title": "Toward Reproducing Network Research Results Using Large Language Models",
        "authors": "Qiao Xiang, Yuling Lin, Mingjun Fang, Bang Huang, Siyong Huang, Ridi Wen, Franck Le, Linghe Kong, Jiwu Shu",
        "published": "2023-11-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626111.3628189"
    },
    {
        "id": 12145,
        "title": "Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogues",
        "authors": "Hongru Wang, Minda Hu, Yang Deng, Rui Wang, Fei Mi, Weichao Wang, Yasheng Wang, Wai-Chung Kwan, Irwin King, Kam-Fai Wong",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.641"
    },
    {
        "id": 12146,
        "title": "Relevance of medical information obtained from ChatGPT: Are large language models friends or foes?",
        "authors": "Jules Mesnier, Gaspard Suc, Neila Sayah, Jérémie Abtan, Philippe Gabriel Steg",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.acvd.2023.07.009"
    },
    {
        "id": 12147,
        "title": "Navigating the security landscape of large language models in enterprise information systems",
        "authors": "Brij B. Gupta, Akshat Gaurav, Varsha Arya",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/17517575.2024.2310846"
    },
    {
        "id": 12148,
        "title": "Uncertain about ChatGPT: enabling the uncertainty evaluation of large language models",
        "authors": "A-L. Jousselme, J.P. de Villiers, A. de Freitas, E. Blasch, V. Dragos, G. Pavlin, P. C. Costa, K. B. Laskey, C. Laudy",
        "published": "2023-6-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/fusion52260.2023.10224086"
    },
    {
        "id": 12149,
        "title": "Large pre-trained language models contain human-like biases of what is right and wrong to do",
        "authors": "Patrick Schramowski, Cigdem Turan, Nico Andersen, Constantin A. Rothkopf, Kristian Kersting",
        "published": "2022-3-23",
        "citations": 58,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s42256-022-00458-8"
    },
    {
        "id": 12150,
        "title": "Measuring CS Student Attitudes Toward Large Language Models",
        "authors": "Jason Lee Weber, Barbara Martinez Neda, Kitana Carbajal Juarez, Jennifer Wong-Ma, Sergio Gago-Masague, Hadar Ziv",
        "published": "2024-3-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626253.3635604"
    },
    {
        "id": 12151,
        "title": "Data Race Detection Using Large Language Models",
        "authors": "Le Chen, Xianzhong Ding, Murali Emani, Tristan Vanderbruggen, Pei-Hung Lin, Chunhua Liao",
        "published": "2023-11-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3624062.3624088"
    },
    {
        "id": 12152,
        "title": "Exploring the Potential of Large Language Models in Supply Chain Management",
        "authors": "Santosh Kumar Srivastava, Susmi Routray, Surajit Bag, Shivam Gupta, Justin Zuopeng Zhang",
        "published": "2024-1-10",
        "citations": 0,
        "abstract": "This study aims to identify emerging topics, themes, and potential areas for applying large language models (LLMs) in supply chain management through data triangulation. This study involved the synthesis of 33 published articles and a total of 3421 social media documents, including tweets, posts, expert opinions, and industry reports on utilizing LLMs in supply chain management. By employing BERT models, four core themes were derived: Supply chain optimization, supply chain risk and security management, supply chain knowledge management, and automated contract intelligence, which provides the present status of LLM in the supply chain. The results of this study will empower managers to identify prospective applications and areas for improvement, affording them a comprehensive understanding of the antecedents, decisions, and outcomes detailed in the framework. The insights garnered from this study are highly valuable to both researchers and managers, equipping them to harness the latest advancements in LLM technology and its role within supply chain management.",
        "link": "http://dx.doi.org/10.4018/jgim.335125"
    },
    {
        "id": 12153,
        "title": "Herbarium specimen label transcription reimagined with large language models: Capabilities, productivity, and risks",
        "authors": "William N. Weaver, Brad R. Ruhfel, Kyle J. Lough, Stephen A. Smith",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/ajb2.16256"
    },
    {
        "id": 12154,
        "title": "Medical Applications of Artificial Intelligence and Large Language Models: Bibliometric Analysis and Stern Call for Improved Publishing Practices",
        "authors": "Jad Abi-Rafeh, Hong Hao Xu, Roy Kazan, Heather J Furnas",
        "published": "2023-11-16",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/asj/sjad277"
    },
    {
        "id": 12155,
        "title": "Emergent analogical reasoning in large language models",
        "authors": "Taylor Webb, Keith J. Holyoak, Hongjing Lu",
        "published": "2023-7-31",
        "citations": 25,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41562-023-01659-w"
    },
    {
        "id": 12156,
        "title": "Ethics of large language models in medicine and medical research",
        "authors": "Hanzhou Li, John T Moon, Saptarshi Purkayastha, Leo Anthony Celi, Hari Trivedi, Judy W Gichoya",
        "published": "2023-6",
        "citations": 73,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00083-3"
    },
    {
        "id": 12157,
        "title": "Letter to the Editor: Leveraging ChatGPT to democratize and decolonize global surgery: Large language models for small healthcare budgets",
        "authors": "Hinpetch Daungsupawong, Viroj Wiwanitkit",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/wjs.12044"
    },
    {
        "id": 12158,
        "title": "Improving Multiparty Interactions with a Robot Using Large Language Models",
        "authors": "Prasanth Murali, Ian Steenstra, Hye Sun Yun, Ameneh Shamekhi, Timothy Bickmore",
        "published": "2023-4-19",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3544549.3585602"
    },
    {
        "id": 12159,
        "title": "Language Evolution Models",
        "authors": "",
        "published": "2020-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108480659.007"
    },
    {
        "id": 12160,
        "title": "dcc --help: Transforming the Role of the Compiler by Generating Context-Aware Error Explanations with Large Language Models",
        "authors": "Andrew Taylor, Alexandra Vassar, Jake Renzella, Hammond Pearce",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626252.3630822"
    },
    {
        "id": 12161,
        "title": "Applying large language models and chain-of-thought for automatic scoring",
        "authors": "Gyeong-Geon Lee, Ehsan Latif, Xuansheng Wu, Ninghao Liu, Xiaoming Zhai",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.caeai.2024.100213"
    },
    {
        "id": 12162,
        "title": "ChatGPT and the Rise of Large Language Models: The New AI-Driven Infodemic Threat in Public Health",
        "authors": "Luigi De Angelis, Francesco Baglivo, Guglielmo Arzilli, Gaetano Pierpaolo Privitera, Paolo Ferragina, Alberto Eugenio Tozzi, Caterina Rizzo",
        "published": "2023",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4352931"
    },
    {
        "id": 12163,
        "title": "Transferable adversarial distribution learning: Query-efficient adversarial attack against large language models",
        "authors": "Huoyuan Dong, Jialiang Dong, Shaohua Wan, Shuai Yuan, Zhitao Guan",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.cose.2023.103482"
    },
    {
        "id": 12164,
        "title": "Aliro: an automated machine learning tool leveraging large language models",
        "authors": "Hyunjun Choi, Jay Moran, Nicholas Matsumoto, Miguel E Hernandez, Jason H Moore",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "Abstract\n\nMotivation\nBiomedical and healthcare domains generate vast amounts of complex data that can be challenging to analyze using machine learning tools, especially for researchers without computer science training.\n\n\nResults\nAliro is an open-source software package designed to automate machine learning analysis through a clean web interface. By infusing the power of large language models, the user can interact with their data by seamlessly retrieving and executing code pulled from the large language model, accelerating automated discovery of new insights from data. Aliro includes a pre-trained machine learning recommendation system that can assist the user to automate the selection of machine learning algorithms and its hyperparameters and provides visualization of the evaluated model and data.\n\n\nAvailability and implementation\nAliro is deployed by running its custom Docker containers. Aliro is available as open-source from GitHub at: https://github.com/EpistasisLab/Aliro.\n",
        "link": "http://dx.doi.org/10.1093/bioinformatics/btad606"
    },
    {
        "id": 12165,
        "title": "Knowledge Graphs and Large Language Models",
        "authors": "Danylo D. Dvoichenkov,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "Large Language Models(LLM) based on the Transformer architecture is nowadays one of the most widely used tool in Natural Language Processing(NLP) field. Nonetheless this approach has some limitations and flaws. In particular, these problems become crucial for the NLP-based expert systems. The LLMs may sometimes hallucinate and provide non-trustworthy responses. We will advocate the using of Knowledge Graphs for solving this problem.",
        "link": "http://dx.doi.org/10.15407/csc.2023.03.054"
    },
    {
        "id": 12166,
        "title": "Deep Learning for Genomics: From Early Neural Nets to Modern Large Language Models",
        "authors": "Tianwei Yue, Yuanxin Wang, Longxiang Zhang, Chunming Gu, Haoru Xue, Wenping Wang, Qi Lyu, Yujie Dun",
        "published": "2023-11-1",
        "citations": 1,
        "abstract": "The data explosion driven by advancements in genomic research, such as high-throughput sequencing techniques, is constantly challenging conventional methods used in genomics. In parallel with the urgent demand for robust algorithms, deep learning has succeeded in various fields such as vision, speech, and text processing. Yet genomics entails unique challenges to deep learning, since we expect a superhuman intelligence that explores beyond our knowledge to interpret the genome from deep learning. A powerful deep learning model should rely on the insightful utilization of task-specific knowledge. In this paper, we briefly discuss the strengths of different deep learning models from a genomic perspective so as to fit each particular task with proper deep learning-based architecture, and we remark on practical considerations of developing deep learning architectures for genomics. We also provide a concise review of deep learning applications in various aspects of genomic research and point out current challenges and potential research directions for future genomics applications. We believe the collaborative use of ever-growing diverse data and the fast iteration of deep learning models will continue to contribute to the future of genomics.",
        "link": "http://dx.doi.org/10.3390/ijms242115858"
    },
    {
        "id": 12167,
        "title": "XLMR4MD: New Vietnamese dataset and framework for detecting the consistency of description and permission in Android applications using large language models",
        "authors": "Qui Ngoc Nguyen, Nguyen Tan Cam, Kiet Van Nguyen",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.cose.2024.103814"
    },
    {
        "id": 12168,
        "title": "MenatQA: A New Dataset for Testing the Temporal Comprehension and Reasoning Abilities of Large Language Models",
        "authors": "Yifan Wei, Yisong Su, Huanhuan Ma, Xiaoyan Yu, Fangyu Lei, Yuanzhe Zhang, Jun Zhao, Kang Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.100"
    },
    {
        "id": 12169,
        "title": "SMT Solver Validation Empowered by Large Pre-Trained Language Models",
        "authors": "Maolin Sun, Yibiao Yang, Yang Wang, Ming Wen, Haoxiang Jia, Yuming Zhou",
        "published": "2023-9-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ase56229.2023.00180"
    },
    {
        "id": 12170,
        "title": "Evaluating causal psychological models: A study of language theories of autism using a large sample",
        "authors": "Bohao Tang, Michael Levine, Jack H. Adamek, Ericka L. Wodka, Brian S. Caffo, Joshua B. Ewen",
        "published": "2023-2-24",
        "citations": 3,
        "abstract": "We used a large convenience sample (n = 22,223) from the Simons Powering Autism Research (SPARK) dataset to evaluate causal, explanatory theories of core autism symptoms. In particular, the data-items collected supported the testing of theories that posited altered language abilities as cause of social withdrawal, as well as alternative theories that competed with these language theories. Our results using this large dataset converge with the evolution of the field in the decades since these theories were first proposed, namely supporting primary social withdrawal (in some cases of autism) as a cause of altered language development, rather than vice versa.To accomplish the above empiric goals, we used a highly theory-constrained approach, one which differs from current data-driven modeling trends but is coherent with a very recent resurgence in theory-driven psychology. In addition to careful explication and formalization of theoretical accounts, we propose three principles for future work of this type: specification, quantification, and integration. Specification refers to constraining models with pre-existing data, from both outside and within autism research, with more elaborate models and more veridical measures, and with longitudinal data collection. Quantification refers to using continuous measures of both psychological causes and effects, as well as weighted graphs. This approach avoids “universality and uniqueness” tests that hold that a single cognitive difference could be responsible for a heterogeneous and complex behavioral phenotype. Integration of multiple explanatory paths within a single model helps the field examine for multiple contributors to a single behavioral feature or to multiple behavioral features. It also allows integration of explanatory theories across multiple current-day diagnoses and as well as typical development.",
        "link": "http://dx.doi.org/10.3389/fpsyg.2023.1060525"
    },
    {
        "id": 12171,
        "title": "Large Language Models and Medical Education: Preparing for a Rapid Transformation in How Trainees Will Learn to Be Doctors",
        "authors": "Akshay Ravi, Aaron Neinstein, Sara G. Murray",
        "published": "2023-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.34197/ats-scholar.2023-0036ps"
    },
    {
        "id": 12172,
        "title": "Automatic smart contract comment generation via large language models and in-context learning",
        "authors": "Junjie Zhao, Xiang Chen, Guang Yang, Yiheng Shen",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.infsof.2024.107405"
    },
    {
        "id": 12173,
        "title": "Fostering websites accessibility: A case study on the use of the Large Language Models ChatGPT for automatic remediation",
        "authors": "Achraf Othman, Amira Dhouib, Aljazi Nasser Al Jabor",
        "published": "2023-7-5",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3594806.3596542"
    },
    {
        "id": 12174,
        "title": "Consolidating Trees of Robotic Plans Generated Using Large Language Models to Improve Reliability",
        "authors": "Md Sadman Sakib, Yu Sun",
        "published": "2024-3",
        "citations": 0,
        "abstract": " The inherent probabilistic nature of Large Language Models (LLMs) introduces an element of unpredictability, raising concerns about potential discrepancies in their output. This paper presents a novel approach designed to generate correct and optimal robotic task plans for diverse real-world demands and scenarios. LLMs have been used to generate task plans, but they are unreliable and may contain wrong, questionable, or high-cost steps. The proposed approach uses LLM to generate a number of task plans as trees and amalgamates them into a graph by removing questionable paths. Then an optimal task tree can be retrieved to circumvent questionable and high-cost nodes, thereby improving planning accuracy and execution efficiency. The approach is further improved by incorporating a large knowledge network. Leveraging GPT-4 further, the high-level task plan is converted into a low-level Planning Domain Definition Language (PDDL) plan executable by a robot. Evaluation results highlight the superior accuracy and efficiency of our approach compared to previous methodologies in the field of task planning. ",
        "link": "http://dx.doi.org/10.1142/s2972335324500029"
    },
    {
        "id": 12175,
        "title": "Risks and Benefits of Large Language Models for the Environment",
        "authors": "Matthias C. Rillig, Marlene Ågerstrand, Mohan Bi, Kenneth A. Gould, Uli Sauerland",
        "published": "2023-3-7",
        "citations": 37,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1021/acs.est.3c01106"
    },
    {
        "id": 12176,
        "title": "Large language models in bariatric surgery patient support: A transformative approach to patient education and engagement",
        "authors": "Jamil S. Samaan, Nithya Rajeev, Nitin Srinivasan, Yee Hui Yeo, Kamran Samakar",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/cob.12635"
    },
    {
        "id": 12177,
        "title": "Evaluating the performance of large language models: <scp>ChatGPT</scp> and Google Bard in generating differential diagnoses in clinicopathological conferences of neurodegenerative disorders",
        "authors": "Shunsuke Koga, Nicholas B. Martin, Dennis W. Dickson",
        "published": "2023-8-8",
        "citations": 12,
        "abstract": "AbstractThis study explores the utility of the large language models (LLMs), specifically ChatGPT and Google Bard, in predicting neuropathologic diagnoses from clinical summaries. A total of 25 cases of neurodegenerative disorders presented at Mayo Clinic brain bank Clinico‐Pathological Conferences were analyzed. The LLMs provided multiple pathologic diagnoses and their rationales, which were compared with the final clinical diagnoses made by physicians. ChatGPT‐3.5, ChatGPT‐4, and Google Bard correctly made primary diagnoses in 32%, 52%, and 40% of cases, respectively, while correct diagnoses were included in 76%, 84%, and 76% of cases, respectively. These findings highlight the potential of artificial intelligence tools like ChatGPT in neuropathology, suggesting they may facilitate more comprehensive discussions in clinicopathological conferences.",
        "link": "http://dx.doi.org/10.1111/bpa.13207"
    },
    {
        "id": 12178,
        "title": "Prompting Large Language Models with Fine-Grained Visual Relations from Scene Graph for Visual Question Answering",
        "authors": "Jiapeng Liu, Chengyang Fang, Liang Li, Bing Li, Dayong Hu, Can Ma",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10448321"
    },
    {
        "id": 12179,
        "title": "Understanding the Benefits and Challenges of Deploying Conversational AI Leveraging Large Language Models for Public Health Intervention",
        "authors": "Eunkyung Jo, Daniel A. Epstein, Hyunhoon Jung, Young-Ho Kim",
        "published": "2023-4-19",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3544548.3581503"
    },
    {
        "id": 12180,
        "title": "Customising General Large Language Models for Specialised Emotion Recognition Tasks",
        "authors": "Liyizhe Peng, Zixing Zhang, Tao Pang, Jing Han, Huan Zhao, Hao Chen, Björn W. Schuller",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447044"
    },
    {
        "id": 12181,
        "title": "Fully automatic summarization of radiology reports using natural language processing with large language models",
        "authors": "Mizuho Nishio, Takaaki Matsunaga, Hidetoshi Matsuo, Munenobu Nogami, Yasuhisa Kurata, Koji Fujimoto, Osamu Sugiyama, Toshiaki Akashi, Shigeki Aoki, Takamichi Murakami",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.imu.2024.101465"
    },
    {
        "id": 12182,
        "title": "ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models",
        "authors": "Chenliang Li, He Chen, Ming Yan, Weizhou Shen, Haiyang Xu, Zhikai Wu, Zhicheng Zhang, Wenmeng Zhou, Yingda Chen, Chen Cheng, Hongzhu Shi, Ji Zhang, Fei Huang, Jingren Zhou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-demo.51"
    },
    {
        "id": 12183,
        "title": "Hybrid API Migration: A Marriage of Small API Mapping Models and Large Language Models",
        "authors": "Bingzhe Zhou, Xinying Wang, Shengbin Xu, Yuan Yao, Minxue Pan, Feng Xu, Xiaoxing Ma",
        "published": "2023-8-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3609437.3609466"
    },
    {
        "id": 12184,
        "title": "Language Competition Models",
        "authors": "",
        "published": "2020-6-30",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108480659.008"
    },
    {
        "id": 12185,
        "title": "Learning Mathematics with Large Language Models",
        "authors": "Nikolaos Matzakos, Spyridon Doukakis, Maria Moundridou",
        "published": "2023-10-17",
        "citations": 0,
        "abstract": "Artificial intelligence (AI) has permeated all human activities, bringing about significant changes and creating new scientific and ethical challenges. The field of education could not be an exception to this development. OpenAI’s unveiling of ChatGPT, their large language model (LLM), has sparked significant interest in the potential applications of this technology in education. This paper aims to contribute to the ongoing discussion on the role of AI in education and its potential implications for the future of learning by exploring how LLMs could be utilized in the teaching of mathematics in higher education and how they compare to the currently widely used computer algebra systems (CAS) and other mathematical tools. It argues that these innovative tools have the potential to provide functional and pedagogical opportunities that may influence changes in curriculum and assessment approaches. ",
        "link": "http://dx.doi.org/10.3991/ijet.v18i20.42979"
    },
    {
        "id": 12186,
        "title": "Performance of large language models on advocating the management of meningitis: a comparative qualitative stud",
        "authors": "Urs Fisch, Paulina Kliem, Pascale Grzonka, Raoul Sutter",
        "published": "2024-2",
        "citations": 0,
        "abstract": "ObjectivesWe aimed to examine the adherence of large language models (LLMs) to bacterial meningitis guidelines using a hypothetical medical case, highlighting their utility and limitations in healthcare.MethodsA simulated clinical scenario of a patient with bacterial meningitis secondary to mastoiditis was presented in three independent sessions to seven publicly accessible LLMs (Bard, Bing, Claude-2, GTP-3.5, GTP-4, Llama, PaLM). Responses were evaluated for adherence to good clinical practice and two international meningitis guidelines.ResultsA central nervous system infection was identified in 90% of LLM sessions. All recommended imaging, while 81% suggested lumbar puncture. Blood cultures and specific mastoiditis work-up were proposed in only 62% and 38% sessions, respectively. Only 38% of sessions provided the correct empirical antibiotic treatment, while antiviral treatment and dexamethasone were advised in 33% and 24%, respectively. Misleading statements were generated in 52%. No significant correlation was found between LLMs’ text length and performance (r=0.29, p=0.20). Among all LLMs, GTP-4 demonstrated the best performance.DiscussionLatest LLMs provide valuable advice on differential diagnosis and diagnostic procedures but significantly vary in treatment-specific information for bacterial meningitis when introduced to a realistic clinical scenario. Misleading statements were common, with performance differences attributed to each LLM’s unique algorithm rather than output length.ConclusionsUsers must be aware of such limitations and performance variability when considering LLMs as a support tool for medical decision-making. Further research is needed to refine these models' comprehension of complex medical scenarios and their ability to provide reliable information.",
        "link": "http://dx.doi.org/10.1136/bmjhci-2023-100978"
    },
    {
        "id": 12187,
        "title": "ANALOGICAL - A Novel Benchmark for Long Text Analogy Evaluation in Large Language Models",
        "authors": "Thilini Wijesiriwardene, Ruwan Wickramarachchi, Bimal Gajera, Shreeyash Gowaikar, Chandan Gupta, Aman Chadha, Aishwarya Naresh Reganti, Amit Sheth, Amitava Das",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.218"
    },
    {
        "id": 12188,
        "title": "Evaluating the Effectiveness of Artificial Intelligence–powered Large Language Models Application in Disseminating Appropriate and Readable Health Information in Urology. Reply.",
        "authors": "Giovanni Cacciamani",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/ju.0000000000003656"
    },
    {
        "id": 12189,
        "title": "AI and Veterinary Medicine: Performance of Large Language Models on the North American Licensing Examination",
        "authors": "Mirana Angel, Anuj Patel, Haiyi Xing, Dylan Balsz, Cody Arbuckle, David Bruyette, Pierre Baldi",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/snams60348.2023.10375414"
    },
    {
        "id": 12190,
        "title": "A Novel AI-based chatbot Application for Personalized Medical Diagnosis and review using Large Language Models",
        "authors": "Akilesh S, Sheik Abdullah A, Abinaya R, Dhanushkodi S, Rajeev Sekar",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/rmkmate59243.2023.10368616"
    },
    {
        "id": 12191,
        "title": "Traditional Chinese Medicine Formula Classification Using Large Language Models",
        "authors": "Zhe Wang, Keqian Li, Quanying Ren, Keyu Yao, Yan Zhu",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bibm58861.2023.10385776"
    },
    {
        "id": 12192,
        "title": "LLaMA-Reviewer: Advancing Code Review Automation with Large Language Models through Parameter-Efficient Fine-Tuning",
        "authors": "Junyi Lu, Lei Yu, Xiaojia Li, Li Yang, Chun Zuo",
        "published": "2023-10-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/issre59848.2023.00026"
    },
    {
        "id": 12193,
        "title": "WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models",
        "authors": "Virginia Felkner, Ho-Chun Herbert Chang, Eugene Jang, Jonathan May",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.507"
    },
    {
        "id": 12194,
        "title": "Development and Testing of Retrieval Augmented Generation in Large Language Models",
        "authors": "Yu He Ke, Liyuan Jin, Kabilan Elangovan, Hairil Abdullah, Nan Liu, Alex Tiong Heng Sia, Chai Rick Soh, Joshua Yi Min Tung, Jasmine Chiat Ling Ong, Daniel Shu Wei Ting",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4719185"
    },
    {
        "id": 12195,
        "title": "Science in the era of ChatGPT, large language models and generative AI",
        "authors": "Evangelos Pournaras",
        "published": "2023-11-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14361/9783839467664-015"
    },
    {
        "id": 12196,
        "title": "Large Language Models in Hematology Case Solving: A Comparative Study of ChatGPT-3.5, Google Bard, and Microsoft Bing",
        "authors": "Amita Kumari, Anita Kumari, Amita Singh, Sanjeet K Singh, Ayesha Juhi, Anup Kumar D Dhanvijay, Mohammed Jaffer Pinjar, Himel Mondal",
        "published": "2023-8-21",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7759/cureus.43861"
    },
    {
        "id": 12197,
        "title": "Performance of Generative Large Language Models on Ophthalmology Board–Style Questions",
        "authors": "Louis Z. Cai, Abdulla Shaheen, Andrew Jin, Riya Fukui, Jonathan S. Yi, Nicolas Yannuzzi, Chrisfouad Alabiad",
        "published": "2023-10",
        "citations": 22,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ajo.2023.05.024"
    },
    {
        "id": 12198,
        "title": "ChatGPT and a New Academic Reality: AI-Written Research Papers and the Ethics of the Large Language Models in Scholarly Publishing",
        "authors": "Brady Lund, Wang Ting, Nishith Reddy Mannuru, Bing Nie, Somipam Shimray, Ziang Wang",
        "published": "2023",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4389887"
    },
    {
        "id": 12199,
        "title": "Beyond Traditional Assessment: Exploring the Impact of Large Language Models on Grading Practices",
        "authors": "Oluwole Fagbohun, Nwaamaka Pearl Iduwe, Mustapha Abdullahi, Adeseye Ifaturoti, Obinna Maxwell Nwanna",
        "published": "2024-2-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.51219/jaimld/oluwole-fagbohun/19"
    },
    {
        "id": 12200,
        "title": "Semantic anomaly detection with large language models",
        "authors": "Amine Elhafsi, Rohan Sinha, Christopher Agia, Edward Schmerling, Issa A. D. Nesnas, Marco Pavone",
        "published": "2023-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10514-023-10132-6"
    },
    {
        "id": 12201,
        "title": "Medical Metaverse, Part 2: Artificial Intelligence Algorithms and Large Language Models in Psychiatry and Clinical Neurosciences",
        "authors": "Wilfredo López-Ojeda, Robin A. Hurley",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1176/appi.neuropsych.20230117"
    },
    {
        "id": 12202,
        "title": "Performance of Generative Large Language Models on Ophthalmology Board–Style Questions",
        "authors": "Louis Z. Cai, Abdulla Shaheen, Andrew Jin, Riya Fukui, Jonathan S. Yi, Nicolas Yannuzzi, Chrisfouad Alabiad",
        "published": "2023-10",
        "citations": 22,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ajo.2023.05.024"
    },
    {
        "id": 12203,
        "title": "Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models",
        "authors": "Priyan Vaithilingam, Tianyi Zhang, Elena L. Glassman",
        "published": "2022-4-27",
        "citations": 86,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3491101.3519665"
    },
    {
        "id": 12204,
        "title": "Large Vocabulary Continuous Speech Recognition for Nepali Language",
        "authors": "Elina Baral, Sagar Shrestha",
        "published": "2020-12",
        "citations": 0,
        "abstract": "Speech Recognition is a widely studied topic for high-resource languages like English and Mandarin. A plethora of publications exist that study the performance of several recognition methods for these languages. However differences in phonetics, accent, language model, etc between any two different languages demand for a study of speech recognition methodologies and components separately for each language. In this paper, we present a comparative study of popular speech recognition methods for Nepali, a low-resource Indo-Aryan language. We describe our approach to building the phonetic dictionary and present our findings for DNN and GMM based techniques with speaker adaptation on 50K vocabulary speech recognition task.",
        "link": "http://dx.doi.org/10.18178/ijsps.8.4.68-73"
    },
    {
        "id": 12205,
        "title": "Cosmological Models",
        "authors": "Baojiu Li",
        "published": "2018-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1088/978-0-7503-1587-6ch2"
    },
    {
        "id": 12206,
        "title": "Book review: Handbook of Diagnostic Classification Models: Models and Model Extensions, Applications, Software Packages",
        "authors": "Tingting Fan",
        "published": "2020-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1177/0265532220927756"
    },
    {
        "id": 12207,
        "title": "Models of Language Evolution",
        "authors": "Cathleen O’Grady, Kenny Smith",
        "published": "2018-8-23",
        "citations": 0,
        "abstract": "This chapter provides evidence for the role of cultural evolution in the emergence of linguistic structure. It reviews these models, and discusses why the emergence of structure in language is a central question for evolutionary linguistics. Computational and experimental models demonstrate that pressures operating during language learning and language use can give rise to the appearance of design in language, through the repeated cycles of learning and use that characterizes language transmission. Finally, this chapter discusses how learning biases at the individual level lead to the presence of typological universals: systematic patterns in how the world’s languages tend to be structured.",
        "link": "http://dx.doi.org/10.1093/oxfordhb/9780198786825.013.38"
    },
    {
        "id": 12208,
        "title": "Classifying COVID-19 Vaccine Narratives",
        "authors": "Yue Li,  , Carolina Scarton, Xingyi Song, Kalina Bontcheva,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_070"
    },
    {
        "id": 12209,
        "title": "EpiK-Eval: Evaluation for Language Models as Epistemic Models",
        "authors": "Gabriele Prato, Jerry Huang, Prasanna Parthasarathi, Shagun Sodhani, Sarath Chandar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.593"
    },
    {
        "id": 12210,
        "title": "Iterative improvements from feedback for language models",
        "authors": "Yuxi Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "Iterative improvements from feedback is a general approach for many, if not all, successful systems.Ground-truth-in-the-loop is critical.Language models (LMs) like ChatGPT are phenomenal, however, there are still issues like hallucinations and a lack of planning and controllability.We may leverage LMs' competence of language to handle tasks by prompting, fine-tuning, and augmenting with tools and APIs.AI aims for optimality.(Current) LMs are approximations, thus induce an LM-to-real gap. Our aim is to bridge such a gap.Previous study shows that grounding, agency and interaction are the cornerstone for sound and solid LMs.Iterative improvements from feedback is critical for further progress of LMs and reinforcement learning is a promising framework, although pre-training then fine-tuning is a popular approach.Iterative updates are too expensive for monolithic large LMs, thus smaller LMs are desirable.A modular architecture is thus preferred.These help make LMs adapt to humans, but not vice verse.We discuss challenges and opportunities, in particular, data & feedback, methodology, evaluation, interpretability, constraints and intelligence.",
        "link": "http://dx.doi.org/10.14293/pr2199.000220.v1"
    },
    {
        "id": 12211,
        "title": "Modeling Easiness for Training Transformers with Curriculum Learning",
        "authors": "Leonardo Ranaldi,  , Giulia Pucci, Fabio Massimo Zanzotto,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_101"
    },
    {
        "id": 12212,
        "title": "Kāraka-Based Answer Retrieval for Question Answering in Indic Languages",
        "authors": "Devika Verma,  , Ramprasad Joshi, Aiman Shivani, Rohan Gupta,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_129"
    },
    {
        "id": 12213,
        "title": "VLIS: Unimodal Language Models Guide Multimodal Language Generation",
        "authors": "Jiwan Chung, Youngjae Yu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.46"
    },
    {
        "id": 12214,
        "title": "Exploring Unsupervised Semantic Similarity Methods for Claim Verification in Health Care News Articles",
        "authors": "Vishwani Gupta,  , Astrid Viciano, Holger Wormer, Najmehsadat Mousavinezhad,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_049"
    },
    {
        "id": 12215,
        "title": "LLM-jp: Inter-organizational Project for the Development of Japanese Large Language Models",
        "authors": "Daisuke Kawahara, Yohei Kuga, Sadao Kurohashi, Jun Suzuki, Yusuke Miyao",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.31.266"
    },
    {
        "id": 12216,
        "title": "Formal Language Theory: Basics",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_2"
    },
    {
        "id": 12217,
        "title": "Processing Written Language",
        "authors": "Mascha Kurpicz-Briki",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-37690-0_3"
    },
    {
        "id": 12218,
        "title": "GeoGPT, the large earth science language model system",
        "authors": "Jian Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "GeoGPT, a large earth science language model system for geoscientists, was designed and developed in response to the Deep-time Digital Earth (DDE) International Science Initiative, which was officially launched at DDE Open Science Forum co-organized by UNESCO in 2021.\nStarting with leading open-source large language models, GeoGPT has built fundamental capabilities, including extraction of key information from geoscience documents, question-and-answer interaction, logical reasoning, automatic code generation, and numerical computation analysis. Smart incremental training strategy based on open-source large-scale models rapidly enhances the adaptability and performance of GeoGPT in the field of Earth sciences. GeoGPT is architected to be flexible in adapting to different foundation models in the future.\nTo ensure accuracy and professionalism in the field of earth science, GeoGPT has specifically constructed a large high-quality geoscience corpus covering 8 secondary disciplines of earth science and innovatively developed a software system designed for annotating geoscience data more efficiently. Hundreds of Earth scientists have collaborated to complete the annotation of nearly one hundred thousand highly specialized question-and-answer pairs, which greatly enriched the training data resources for this geoscience model.\nGeoGPT is a global effort of open science practice across research institutes, universities, industry, and other organizations. GeoGPT model is open to the global research community today. It is also being planned to provide open access to large-scale datasets used in GeoGPT and GeoGPT API to Earth science community. GeoGPT is helping to transform the research paradigm of earth science through its potential capabilities of generating scientific hypotheses, constructing theoretical models, and doing research plans.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-18265"
    },
    {
        "id": 12219,
        "title": "On the Identification and Forecasting of Hate Speech in Inceldom",
        "authors": "Paolo Gajo,  , Arianna Muti, Katerina Korre, Silvia Bernardini, Alberto Barrón-Cedeño,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_042"
    },
    {
        "id": 12220,
        "title": "Party Extraction from Legal Contract Using Contextualized Span Representations of Parties",
        "authors": "Sanjeepan Sivapiran,  , Charangan Vasantharajan, Uthayasanker Thayasivam,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_116"
    },
    {
        "id": 12221,
        "title": "Discourse Analysis of Argumentative Essays of English Learners based on CEFR Level",
        "authors": "Blaise Hanel,  , Leila Kosseim,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_052"
    },
    {
        "id": 12222,
        "title": "Language and other complex behaviors: Unifying characteristics, computational models, neural mechanisms",
        "authors": "Shimon Edelman",
        "published": "2017-7",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.langsci.2017.04.003"
    },
    {
        "id": 12223,
        "title": "Studying Common Ground Instantiation Using Audio, Video and Brain Behaviours: The BrainKT Corpus",
        "authors": "Eliot Maës,  , Leonor Becerra-Bonache, Thierry Legou, Philippe Blache,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_075"
    },
    {
        "id": 12224,
        "title": "Propaganda Detection in Russian Telegram Posts in the Scope of the Russian Invasion of Ukraine",
        "authors": "Natalia Vanetik,  , Marina Litvak, Egor Reviakin, Margarita Tyamanova,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_123"
    },
    {
        "id": 12225,
        "title": "Evaluating Neural Language Models as Cognitive Models of Language Acquisition",
        "authors": "Hector Javier Vazquez Martinez, Annika Lea Heuser, Charles Yang, Jordan Kodner",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.genbench-1.4"
    },
    {
        "id": 12226,
        "title": "Large Geometry MOSFET Compact Models",
        "authors": "Samar K. Saha",
        "published": "2018-9-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b19117-4"
    },
    {
        "id": 12227,
        "title": "Introduction",
        "authors": "Gerhard Paaß, Sven Giesselbach",
        "published": "2023",
        "citations": 0,
        "abstract": "AbstractWith the development of efficient Deep Learning models about a decade ago, many Deep Neural Networks have been used to solve pattern recognition tasks such as natural language processing and image recognition. An advantage of these models is that they automatically create features arranged in layers which represent the content and do not require manually constructed features. These models rely on Machine Learning employing statistical techniques to give machines the capability to ‘learn’ from data without being given explicit instructions on what to do. Deep Learning models transform the input in layers step by step in such a way that complex patterns in the data can be recognized. This chapter first describes how a text is pre-processed and partitioned into tokens, which form the basis for natural language processing. Then we outline a number of classical Machine Learning models, which are often used as modules in advanced models. Examples include the logistic classifier model, fully connected layers, recurrent neural networks and convolutional neural networks.",
        "link": "http://dx.doi.org/10.1007/978-3-031-23190-2_1"
    },
    {
        "id": 12228,
        "title": "Development of meta-prompts for Large Language Models to screen titles and abstracts for diagnostic test accuracy reviews",
        "authors": "Yuki Kataoka, Ryuhei So, Masahiro Banno, Junji Kumasawa, Hidehiro Someko, Shunsuke Taito, Teruhiko Terasawa, Yasushi Tsujimoto, Yusuke Tsutsumi, Yoshitaka Wada, Toshi A. Furukawa",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractSystematic reviews (SRs) are a critical component of evidence-based medicine, but the process of screening titles and abstracts is time-consuming. This study aimed to develop and externally validate a method using large language models to classify abstracts for diagnostic test accuracy (DTA) systematic reviews, thereby reducing the human workload. We used a previously collected dataset for developing DTA abstract classifiers and applied prompt engineering. We developed an optimized meta-prompt for Generative Pre-trained Transformer (GPT)-3.5-turbo and GPT-4 to classify abstracts. In the external validation dataset 1, the prompt with GPT-3.5 turbo showed a sensitivity of 0.988, and a specificity of 0.298. GPT-4 showed a sensitivity of 0.982, and a specificity of 0.677. In the external validation dataset 2, GPT-3.5 turbo showed a sensitivity of 0.919, and a specificity of 0.434. GPT-4 showed a sensitivity of 0.806, and a specificity of 0.740. If we included eligible studies from among the references of the identified studies, GPT-3.5 turbo had no critical misses, while GPT-4 had some misses. Our study indicates that GPT-3.5 turbo can be effectively used to classify abstracts for DTA systematic reviews. Further studies using other dataset are warranted to confirm our results. Additionally, we encourage the use of our framework and publicly available dataset for further exploration of more effective classifiers using other LLMs and prompts (https://github.com/youkiti/ARE/).HightlightsWhat is already known- Title and abstract screening in systematic reviews (SRs) consumes significant time.- Several attempts using machine learning to reduce this process in diagnostic test accuracy (DTA) SRs exist, but they have not yielded positive results in external validation.What is new- We aimed to develop and externally validate optimized meta-prompt for GPT-3.5-turbo and GPT-4 to classify abstracts for DTA SRs.- Through an iterative approach across three training datasets, an optimal meta-prompt capable of identifying DTA studies with remarkable sensitivity and specificity was developed.- The accuracy reproduced in the external validation datasets.Potential Impact for Readers- The developed meta-prompt can lessen the need for humans to read abstracts for DTA SRs, saving significant time and resources.",
        "link": "http://dx.doi.org/10.1101/2023.10.31.23297818"
    },
    {
        "id": 12229,
        "title": "ZVQAF: Zero-shot visual question answering with feedback from large language models",
        "authors": "Cheng Liu, Chao Wang, Yan Peng, Zhixu Li",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neucom.2024.127505"
    },
    {
        "id": 12230,
        "title": "Developing a framework to re-design writing assignment assessment for the era of Large Language Models",
        "authors": "Ya-Ping Hsiao, Nadia Klijn, Mei-Shiu Chiu",
        "published": "2023-7-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/23735082.2023.2257234"
    },
    {
        "id": 12231,
        "title": "Artificial intelligence-based large language models and integrity of exams and assignments in higher education: the case of tourism courses",
        "authors": "Abdullah Ülkü,  ",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "There is an increasing concern regarding the potential misuse of ChatGPT-4 in compromising the integrity of examinations and assignments. This study aims to examine the capabilities of ChatGPT-4 in critical thinking abilities, whether it poses a threat to examinations and assignments in higher education, and create a discussion agenda on this issue. ChatGPT-4 was asked to generate, answer, and criticize questions in tourism marketing, tourism management, tourism economics, tourist guidance, and gastronomy. The answers were evaluated according to universal critical thinking standards. The findings obtained from this study showed that ChatGPT-4 had commendable competence in several critical thinking standards and could produce human-like texts. However, there are certain domains that might be improved to comply more effectively with the expectations and norms of academia. Educators were recommended to use comprehensive approaches that combine technological and educational techniques to address the issue of cheating enabled by tools, such as ChatGPT-4, during assessment and exam processes.",
        "link": "http://dx.doi.org/10.18089/tms.2023.190402"
    },
    {
        "id": 12232,
        "title": "GPT-4 enhanced multimodal grounding for autonomous driving: Leveraging cross-modal attention with large language models",
        "authors": "Haicheng Liao, Huanming Shen, Zhenning Li, Chengyue Wang, Guofa Li, Yiming Bie, Chengzhong Xu",
        "published": "2024-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.commtr.2023.100116"
    },
    {
        "id": 12233,
        "title": "Developmental Scaffolding with Large Language Models",
        "authors": "Batuhan Celik, Alper Ahmetoglu, Emre Ugur, Erhan Oztop",
        "published": "2023-11-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdl55364.2023.10364374"
    },
    {
        "id": 12234,
        "title": "Flying Into the Future With Large Language Models",
        "authors": "Sanjat Kanjilal",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/cid/ciad635"
    },
    {
        "id": 12235,
        "title": "Evaluating the Effectiveness of Artificial Intelligence–powered Large Language Models Application in Disseminating Appropriate and Readable Health Information in Urology. Letter.",
        "authors": "Huajie Di, Yi Wen",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/ju.0000000000003655"
    },
    {
        "id": 12236,
        "title": "Benchmarking Open-Source Large Language Models, GPT-4 and Claude 2 on Multiple-Choice Questions in Nephrology",
        "authors": "Sean Wu, Michael Koo, Lesley Blum, Andy Black, Liyo Kao, Zhe Fei, Fabien Scalzo, Ira Kurtz",
        "published": "2024-1-25",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1056/aidbp2300092"
    },
    {
        "id": 12237,
        "title": "Large language models: Are artificial intelligence-based chatbots a reliable source of patient information for spinal surgery?",
        "authors": "Anna Stroop, Tabea Stroop, Samer Zawy Alsofy, Makoto Nakamura, Frank Möllmann, Christoph Greiner, Ralf Stroop",
        "published": "2023-10-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00586-023-07975-z"
    },
    {
        "id": 12238,
        "title": "Better models of human high-level visual cortex emerge from natural language supervision with a large and diverse dataset",
        "authors": "Aria Y. Wang, Kendrick Kay, Thomas Naselaris, Michael J. Tarr, Leila Wehbe",
        "published": "2023-11-13",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s42256-023-00753-y"
    },
    {
        "id": 12239,
        "title": "How large language models including generative pre-trained transformer (GPT) 3 and 4 will impact medicine and surgery",
        "authors": "S. B. Atallah, N. R. Banda, A. Banda, N. A. Roeck",
        "published": "2023-8",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10151-023-02837-8"
    },
    {
        "id": 12240,
        "title": "Automated Grading in Coding Exercises Using Large Language Models",
        "authors": "Paraskevas Lagakis, Stavros Demetriadis, Georgios Psathas",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-54327-2_37"
    },
    {
        "id": 12241,
        "title": "Parallel Context Windows for Large Language Models",
        "authors": "Nir Ratner, Yoav Levine, Yonatan Belinkov, Ori Ram, Inbal Magar, Omri Abend, Ehud Karpas, Amnon Shashua, Kevin Leyton-Brown, Yoav Shoham",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.352"
    },
    {
        "id": 12242,
        "title": "The Breakthrough of Large Language Models Release for Medical Applications: 1-Year Timeline and Perspectives",
        "authors": "Marco Cascella, Federico Semeraro, Jonathan Montomoli, Valentina Bellini, Ornella Piazza, Elena Bignami",
        "published": "2024-2-17",
        "citations": 0,
        "abstract": "AbstractWithin the domain of Natural Language Processing (NLP), Large Language Models (LLMs) represent sophisticated models engineered to comprehend, generate, and manipulate text resembling human language on an extensive scale. They are transformer-based deep learning architectures, obtained through the scaling of model size, pretraining of corpora, and computational resources. The potential healthcare applications of these models primarily involve chatbots and interaction systems for clinical documentation management, and medical literature summarization (Biomedical NLP). The challenge in this field lies in the research for applications in diagnostic and clinical decision support, as well as patient triage. Therefore, LLMs can be used for multiple tasks within patient care, research, and education. Throughout 2023, there has been an escalation in the release of LLMs, some of which are applicable in the healthcare domain. This remarkable output is largely the effect of the customization of pre-trained models for applications like chatbots, virtual assistants, or any system requiring human-like conversational engagement. As healthcare professionals, we recognize the imperative to stay at the forefront of knowledge. However, keeping abreast of the rapid evolution of this technology is practically unattainable, and, above all, understanding its potential applications and limitations remains a subject of ongoing debate. Consequently, this article aims to provide a succinct overview of the recently released LLMs, emphasizing their potential use in the field of medicine. Perspectives for a more extensive range of safe and effective applications are also discussed. The upcoming evolutionary leap involves the transition from an AI-powered model primarily designed for answering medical questions to a more versatile and practical tool for healthcare providers such as generalist biomedical AI systems for multimodal-based calibrated decision-making processes. On the other hand, the development of more accurate virtual clinical partners could enhance patient engagement, offering personalized support, and improving chronic disease management.",
        "link": "http://dx.doi.org/10.1007/s10916-024-02045-3"
    },
    {
        "id": 12243,
        "title": "Large Language Models in Medical Education: Opportunities, Challenges, and Future Directions",
        "authors": "Alaa Abd-alrazaq, Rawan AlSaad, Dari Alhuwail, Arfan Ahmed, Padraig Mark Healy, Syed Latifi, Sarah Aziz, Rafat Damseh, Sadam Alabed Alrazak, Javaid Sheikh",
        "published": "2023-6-1",
        "citations": 55,
        "abstract": "The integration of large language models (LLMs), such as those in the Generative Pre-trained Transformers (GPT) series, into medical education has the potential to transform learning experiences for students and elevate their knowledge, skills, and competence. Drawing on a wealth of professional and academic experience, we propose that LLMs hold promise for revolutionizing medical curriculum development, teaching methodologies, personalized study plans and learning materials, student assessments, and more. However, we also critically examine the challenges that such integration might pose by addressing issues of algorithmic bias, overreliance, plagiarism, misinformation, inequity, privacy, and copyright concerns in medical education. As we navigate the shift from an information-driven educational paradigm to an artificial intelligence (AI)–driven educational paradigm, we argue that it is paramount to understand both the potential and the pitfalls of LLMs in medical education. This paper thus offers our perspective on the opportunities and challenges of using LLMs in this context. We believe that the insights gleaned from this analysis will serve as a foundation for future recommendations and best practices in the field, fostering the responsible and effective use of AI technologies in medical education.",
        "link": "http://dx.doi.org/10.2196/48291"
    },
    {
        "id": 12244,
        "title": "Potential Multidisciplinary Use of Large Language Models for Addressing Queries in Cardio‐Oncology",
        "authors": "Pengfei Li, Xuejuan Zhang, Erjia Zhu, Shijun Yu, Bin Sheng, Yih Chung Tham, Tien Yin Wong, Hongwei Ji",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1161/jaha.123.033584"
    },
    {
        "id": 12245,
        "title": "How large does a large ensemble need to be?",
        "authors": "Sebastian Milinski, Nicola Maher, Dirk Olonscheck",
        "published": "No Date",
        "citations": 2,
        "abstract": "Abstract. Initial-condition large ensembles with ensemble sizes ranging from 30 to 100 members have become a commonly used tool to quantify the forced response and internal variability in various components of the climate system. However, there is no consensus on the ideal or even sufficient ensemble size for a large ensemble. Here, we introduce an objective method to estimate the required ensemble size that can be applied to any given application and demonstrate its use on the examples of global mean surface temperature, local surface temperature and precipitation and variability in the ENSO region and central America. Where possible, we base our estimate of the required ensemble size on the pre-industrial control simulation, which is available for every model. First, we determine how much of an available ensemble size is interpretable without a substantial impact of resampling ensemble members. Then, we show that more ensemble members are needed to quantify variability than the forced response, with the largest ensemble sizes needed to detect changes in internal variability itself. Finally, we highlight that the required ensemble size depends on both the acceptable error to the user and the studied quantity.\n                        ",
        "link": "http://dx.doi.org/10.5194/esd-2019-70"
    },
    {
        "id": 12246,
        "title": "The semantic models of large terminological texts",
        "authors": "I. S. Pavlovskiy",
        "published": "2017-10",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2017.8109667"
    },
    {
        "id": 12247,
        "title": "Large-Scale Information Systems based on Conceptual Models",
        "authors": "V.S. Vykhovanets",
        "published": "2019-10",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2019.8911106"
    },
    {
        "id": 12248,
        "title": "Enhancing Network Management Using Code Generated by Large Language Models",
        "authors": "Sathiya Kumaran Mani, Yajie Zhou, Kevin Hsieh, Santiago Segarra, Trevor Eberl, Eliran Azulai, Ido Frizler, Ranveer Chandra, Srikanth Kandula",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626111.3628183"
    },
    {
        "id": 12249,
        "title": "LLMRec: Large Language Models with Graph Augmentation for Recommendation",
        "authors": "Wei Wei, Xubin Ren, Jiabin Tang, Qinyong Wang, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, Chao Huang",
        "published": "2024-3-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3616855.3635853"
    },
    {
        "id": 12250,
        "title": "Fine-tuning Large Language Models for Chemical Text Mining",
        "authors": "Wei Zhang, Qinggong Wang, Xiangtai Kong, Jiacheng Xiong, Shengkun Ni, Duanhua Cao, Buying Niu, Mingan Chen, Runze Zhang, Yitian Wang, Lehan Zhang, Xutong Li, Zhaoping Xiong, Qian Shi, Ziming Huang, Zunyun Fu, Mingyue Zheng",
        "published": "No Date",
        "citations": 0,
        "abstract": "Extracting knowledge from complex and diverse chemical texts is a pivotal task for both experimental and computational chemists. The task is still considered to be extremely challenging due to the complexity of the chemical language and scientific literature. This study explored the power of fine-tuned large language models (LLMs) on five intricate chemical text mining tasks: compound entity recognition, reaction role labelling, metal-organic framework (MOF) synthesis information extraction, nuclear magnetic resonance spectroscopy (NMR) data extraction, and the conversion of reaction paragraph to action sequence. The fine-tuned LLMs models demonstrated impressive performance, significantly reducing the need for repetitive and extensive prompt engineering experiments. For comparison, we guided GPT-3.5 and GPT-4 with prompt engineering and fine-tuned GPT-3.5 as well as other open-source LLMs such as Llama2, T5, and BART. The results showed that the fine-tuned GPT models excelled in all tasks. It achieved exact accuracy levels ranging from 69% to 95% on these tasks with minimal annotated data. It even outperformed those task-adaptive pre-training and fine-tuning models that were based on a significantly larger amount of in-domain data. Given its versatility, robustness, and low-code capability, leveraging fine-tuned LLMs as flexible and effective toolkits for automated data acquisition could revolutionize chemical knowledge extraction.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2023-k7ct5-v2"
    },
    {
        "id": 12251,
        "title": "Advancing Italian Biomedical Information Extraction with Large Language Models: Methodological Insights and Multicenter Practical Application",
        "authors": "Claudio Crema, Tommaso  Mario Buonocore, Silvia Fostinelli, Enea Parimbelli, Federico Verde, Cira Fundarò, Marina Manera, Matteo Cotta Ramusino, Marco Capelli, Alfredo Costa, Giuliano Binetti, Riccardo Bellazzi, Alberto Redolfi",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4518624"
    },
    {
        "id": 12252,
        "title": "Assessing student errors in experimentation using artificial intelligence and large language models: A comparative study with human raters",
        "authors": "Arne Bewersdorff, Kathrin Seßler, Armin Baur, Enkelejda Kasneci, Claudia Nerdel",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.caeai.2023.100177"
    },
    {
        "id": 12253,
        "title": "Large Language Models for Recommendation: Progresses and Future Directions",
        "authors": "Keqin Bao, Jizhi Zhang, Yang Zhang, Wang Wenjie, Fuli Feng, Xiangnan He",
        "published": "2023-11-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3624918.3629550"
    },
    {
        "id": 12254,
        "title": "Cells, Generators, and Lenses: Design Framework for Object-Oriented Interaction with Large Language Models",
        "authors": "Tae Soo Kim, Yoonjoo Lee, Minsuk Chang, Juho Kim",
        "published": "2023-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3586183.3606833"
    },
    {
        "id": 12255,
        "title": "Transforming Healthcare Education: Harnessing Large Language Models for Frontline Health Worker Capacity Building using Retrieval-Augmented Generation",
        "authors": "Yasmina Al Ghadban, Huiqi (Yvonne) Lu, Uday Adavi, Ankita Sharma, Sridevi Gara, Neelanjana Das, Bhaskar Kumar, Renu John, Praveen Devarsetty, Jane E. Hirst",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractIn recent years, large language models (LLMs) have emerged as a transformative force in several domains, including medical education and healthcare. This paper presents a case study on the practical application of using retrieval-augmented generation (RAG) based models for enhancing healthcare education in low- and middle-income countries. The model described in this paper, SMARThealthGPT, stems from the necessity for accessible and locally relevant medical information to aid community health workers in delivering high-quality maternal care. We describe the development process of the complete RAG pipeline, including the creation of a knowledge base of Indian pregnancy-related guidelines, knowledge embedding retrieval, parameter selection and optimization, and answer generation. This case study highlights the potential of LLMs in building frontline healthcare worker capacity and enhancing guideline-based health education; and offers insights for similar applications in resource-limited settings. It serves as a reference for machine learning scientists, educators, healthcare professionals, and policymakers aiming to harness the power of LLMs for substantial educational improvement.",
        "link": "http://dx.doi.org/10.1101/2023.12.15.23300009"
    },
    {
        "id": 12256,
        "title": "Assessing the Proficiency of Large Language Models on Funduscopic Disease Knowledge (Preprint)",
        "authors": "Yi Shao, Jun-Yi Wu, Yan-Mei Zeng, Xian-Zhe Qian, Qi Hong, Jin-Yu Hu, Hong Wei, Jie Zou, Cheng Chen, Xiao-Yu Wang, Xu Chen",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nLarge language models (LLMs) have significantly transformed the field of natural language processing, with cutting-edge models like ChatGPT currently leading the way in medical AI.\n\n\nOBJECTIVE\nThis study aimed to assess the performance of five distinct LLMs (GPT-3.5, ChatGPT-4, PaLM2, Claude 2, and SenseNova) in comparison to two human cohorts (a group of funduscopic disease experts and a group of ophthalmologists) on the specialized subject of funduscopic disease.\n\n\nMETHODS\nFive distinct LLMs and two distinct human groups independently  completed a 100-item funduscopic disease test. The performance of these entities was assessed by comparing their average scores, response stability, and answer confidence, thereby establishing a basis for evaluation.\n\n\nRESULTS\nAmong all the LLMs, GPT-4 and PaLM2 exhibited the most substantial average correlation. Additionally, GPT-4 achieved the highest average score and demonstrated the utmost confidence during the exam. In comparison to human cohorts, GPT-4 exhibited comparable performance to ophthalmologists, albeit falling short of the expertise demonstrated by funduscopic disease specialists.\n\n\nCONCLUSIONS\nThe study provided evidence of the exceptional performance of GPT-4 in the domain of funduscopic disease. With continued enhancements, validated LLMs have the potential to yield unforeseen advantages in enhancing healthcare for both patients and physicians.\n",
        "link": "http://dx.doi.org/10.2196/preprints.57139"
    },
    {
        "id": 12257,
        "title": "Near-Real-Time Seismic Human Fatality Information Retrieval from Social Media with Few-Shot Large-Language Models",
        "authors": "James Hou, Susu Xu",
        "published": "2022-11-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3560905.3568431"
    },
    {
        "id": 12258,
        "title": "Leveraging ChatGPT to Democratize and Decolonize Global Surgery: Large Language Models for Small Healthcare Budgets",
        "authors": "Fabio Botelho, Jean Marie Tshimula, Dan Poenaru",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00268-023-07167-2"
    },
    {
        "id": 12259,
        "title": "Wikipedia and AI: Access, representation, and advocacy in the age of large language models",
        "authors": "Zachary J McDowell",
        "published": "2024-3-14",
        "citations": 0,
        "abstract": " Wikipedia, despite its volunteer-driven nature, stands as a trustworthy repository of information, thanks to its transparent and verifiable processes. However, Large Language Models (LLMs) often use Wikipedia as a source without acknowledging it, creating a disconnect between users and Wikipedia’s rich framework. This poses a triple threat to information literacy, Wikipedia’s vitality, and the potential for dynamic, updated information. This article explores the interplay between representation, accessibility, and LLMs on Wikipedia, highlighting the importance of preserving Wikipedia as a space for access, representation, and ultimately advocacy in an increasingly LLM-dominated information landscape. This article contends that, despite being over two decades old, Wikipedia remains vital not only for knowledge accumulation but also as a sanctuary for the future of knowledge representation, championing representation and accessibility in the age of closed-system LLMs. ",
        "link": "http://dx.doi.org/10.1177/13548565241238924"
    },
    {
        "id": 12260,
        "title": "Using Large Language Models to Shape Social Robots’ Speech",
        "authors": "Javier Sevilla-Salcedo, Enrique Fernádez-Rodicio, Laura Martín-Galván, Álvaro Castro-González, José C. Castillo, Miguel A. Salichs",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.9781/ijimai.2023.07.008"
    },
    {
        "id": 12261,
        "title": "Leveraging Biases in Large Language Models: \"bias-kNN\" for Effective Few-Shot Learning",
        "authors": "Yong Zhang, Hanzhang Li, Zhitao Li, Ning Cheng, Ming Li, Jing Xiao, Jianzong Wang",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447730"
    },
    {
        "id": 12262,
        "title": "Otter: Simplifying Embedded Sensor Data Collection and Analysis using Large Language Models",
        "authors": "Steven Waskito, Kai Jie Leow, Pramuka Medaranga, Tejas Gupta, Shantanu Chakrabarty, Manoj Gulati, Ambuj Varshney",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3570361.3615759"
    },
    {
        "id": 12263,
        "title": "A distributed system for large-scale n-gram language models at Tencent",
        "authors": "Qiang Long, Wei Wang, Jinfu Deng, Song Liu, Wenhao Huang, Fangying Chen, Sifan Liu",
        "published": "2019-8",
        "citations": 3,
        "abstract": "n-gram language models are widely used in language processing applications, e.g., automatic speech recognition, for ranking the candidate word sequences generated from the generator model, e.g., the acoustic model. Large n-gram models typically give good ranking results; however, they require a huge amount of memory storage. While distributing the model across multiple nodes resolves the memory issue, it nonetheless incurs a great network communication overhead and introduces a different bottleneck. In this paper, we present our distributed system developed at Tencent with novel optimization techniques for reducing the network overhead, including distributed indexing, batching and caching. They reduce the network requests and accelerate the operation on each single node. We also propose a cascade fault-tolerance mechanism which adaptively switches to small n-gram models depending on the severity of the failure. Experimental study on 9 automatic speech recognition (ASR) datasets confirms that our distributed system scales to large models efficiently, effectively and robustly. We have successfully deployed it for Tencent's WeChat ASR with the peak network traffic at the scale of 100 millions of messages per minute.",
        "link": "http://dx.doi.org/10.14778/3352063.3352136"
    },
    {
        "id": 12264,
        "title": "Invited: Automated Code generation for Information Technology Tasks in YAML through Large Language Models",
        "authors": "Saurabh Pujar, Luca Buratti, Xiaojie Guo, Nicolas Dupuis, Burn Lewis, Sahil Suneja, Atin Sood, Ganesh Nalawade, Matt Jones, Alessandro Morari, Ruchir Puri",
        "published": "2023-7-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dac56929.2023.10247987"
    },
    {
        "id": 12265,
        "title": "Toward Pioneering Sensors and Features Using Large Language Models in Human Activity Recognition",
        "authors": "Haru Kaneko, Sozo Inoue",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3594739.3610741"
    },
    {
        "id": 12266,
        "title": "Need an AI-Enabled, Next-Generation, Advanced ChatGPT or Large Language Models (LLMs) for Error-Free and Accurate Medical Information",
        "authors": "Chiranjib Chakraborty, Manojit Bhattacharya, Sang-Soo Lee",
        "published": "2024-2",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10439-023-03297-9"
    },
    {
        "id": 12267,
        "title": "Comment on “Large Language Models in Ophthalmology Scientific Writing: Ethical Considerations Blurred Lines or Not at All?”",
        "authors": "Konradin Metze, Irene Lorand-Metze, Rosana C Morandin-Reis, João B Florindo",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ajo.2023.10.026"
    },
    {
        "id": 12268,
        "title": "Publish with AUTOGEN or Perish? Some Pitfalls to Avoid in the Pursuit of Academic Enhancement via Personalized Large Language Models",
        "authors": "Alexandre Erler",
        "published": "2023-10-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15265161.2023.2250291"
    },
    {
        "id": 12269,
        "title": "Algebra Error Classification with Large Language Models",
        "authors": "Hunter McNichols, Mengxue Zhang, Andrew Lan",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-36272-9_30"
    },
    {
        "id": 12270,
        "title": "Language competition models",
        "authors": "Torsten Templin, Bengt-Arne Wickström",
        "published": "2023-9-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429448843-5"
    },
    {
        "id": 12271,
        "title": "Language Model Decomposition: Quantifying the Dependency and Correlation of Language Models",
        "authors": "Hao Zhang",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.161"
    },
    {
        "id": 12272,
        "title": "Bidirectional Encoder Representations from Transformers-like large language models in patient safety and pharmacovigilance: A comprehensive assessment of causal inference implications",
        "authors": "Xingqiao Wang, Xiaowei Xu, Zhichao Liu, Weida Tong",
        "published": "2023-12-12",
        "citations": 1,
        "abstract": " Causality assessment is vital in patient safety and pharmacovigilance (PSPV) for safety signal detection, adverse reaction management, and regulatory submission. Large language models (LLMs), especially those designed with transformer architecture, are revolutionizing various fields, including PSPV. While attempts to utilize Bidirectional Encoder Representations from Transformers (BERT)-like LLMs for causal inference in PSPV are underway, a detailed evaluation of “fit-for-purpose” BERT-like model selection to enhance causal inference performance within PSPV applications remains absent. This study conducts an in-depth exploration of BERT-like LLMs, including generic pre-trained BERT LLMs, domain-specific pre-trained LLMs, and domain-specific pre-trained LLMs with safety knowledge-specific fine-tuning, for causal inference in PSPV. Our investigation centers around (1) the influence of data complexity and model architecture, (2) the correlation between the BERT size and its impact, and (3) the role of domain-specific training and fine-tuning on three publicly accessible PSPV data sets. The findings suggest that (1) BERT-like LLMs deliver consistent predictive power across varied data complexity levels, (2) the predictive performance and causal inference results do not directly correspond to the BERT-like model size, and (3) domain-specific pre-trained LLMs, with or without safety knowledge-specific fine-tuning, surpass generic pre-trained BERT models in causal inference. The findings are valuable to guide the future application of LLMs in a broad range of application. ",
        "link": "http://dx.doi.org/10.1177/15353702231215895"
    },
    {
        "id": 12273,
        "title": "The Unequal Opportunities of Large Language Models: Examining Demographic Biases in Job Recommendations by ChatGPT and LLaMA",
        "authors": "Abel Salinas, Parth Shah, Yuzhong Huang, Robert McCormack, Fred Morstatter",
        "published": "2023-10-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3617694.3623257"
    },
    {
        "id": 12274,
        "title": "Large language models in health care: Development, applications, and challenges",
        "authors": "Rui Yang, Ting Fang Tan, Wei Lu, Arun James Thirunavukarasu, Daniel Shu Wei Ting, Nan Liu",
        "published": "2023-8",
        "citations": 6,
        "abstract": "AbstractRecently, the emergence of ChatGPT, an artificial intelligence chatbot developed by OpenAI, has attracted significant attention due to its exceptional language comprehension and content generation capabilities, highlighting the immense potential of large language models (LLMs). LLMs have become a burgeoning hotspot across many fields, including health care. Within health care, LLMs may be classified into LLMs for the biomedical domain and LLMs for the clinical domain based on the corpora used for pre‐training. In the last 3 years, these domain‐specific LLMs have demonstrated exceptional performance on multiple natural language processing tasks, surpassing the performance of general LLMs as well. This not only emphasizes the significance of developing dedicated LLMs for the specific domains, but also raises expectations for their applications in health care. We believe that LLMs may be used widely in preconsultation, diagnosis, and management, with appropriate development and supervision. Additionally, LLMs hold tremendous promise in assisting with medical education, medical writing and other related applications. Likewise, health care systems must recognize and address the challenges posed by LLMs.",
        "link": "http://dx.doi.org/10.1002/hcs2.61"
    },
    {
        "id": 12275,
        "title": "GPT4AIGChip: Towards Next-Generation AI Accelerator Design Automation via Large Language Models",
        "authors": "Yonggan Fu, Yongan Zhang, Zhongzhi Yu, Sixu Li, Zhifan Ye, Chaojian Li, Cheng Wan, Yingyan Celine Lin",
        "published": "2023-10-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccad57390.2023.10323953"
    },
    {
        "id": 12276,
        "title": "Clinical science and practice in the age of large language models and generative artificial intelligence.",
        "authors": "Stephen M. Schueller, Robert R. Morris",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1037/ccp0000848"
    },
    {
        "id": 12277,
        "title": "Bigger Isn’t Better: The Ethical and Scientific Vices of Extra-Large Datasets in Language Models",
        "authors": "Trystan S. Goetze, Darren Abramson",
        "published": "2021-6-21",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3462741.3466809"
    },
    {
        "id": 12278,
        "title": "Use of Large Language Models for Extracting Knowledge Components in CS1 Programming Exercises",
        "authors": "Rose Niosuha, Muntasir Hoq, Bita Akram, Narges Norouzi",
        "published": "2024-3-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626253.3635592"
    },
    {
        "id": 12279,
        "title": "Comparison of Large Language Models in Answering Immuno-Oncology Questions: A Cross-Sectional Study",
        "authors": "Giovanni Maria Iannantuono, Dara Bracken-Clarke, Fatima Karzai, Hyoyoung Choo-Wosoba, James L Gulley, Charalampos S Floudas",
        "published": "2024-2-3",
        "citations": 0,
        "abstract": "Abstract\n\nBackground\nThe capability of large language models (LLMs) to understand and generate human-readable text has prompted the investigation of their potential as educational and management tools for patients with cancer and healthcare providers.\n\n\nMaterials and Methods\nWe conducted a cross-sectional study aimed at evaluating the ability of ChatGPT-4, ChatGPT-3.5, and Google Bard to answer questions related to 4 domains of immuno-oncology (Mechanisms, Indications, Toxicities, and Prognosis). We generated 60 open-ended questions (15 for each section). Questions were manually submitted to LLMs, and responses were collected on June 30, 2023. Two reviewers evaluated the answers independently.\n\n\nResults\nChatGPT-4 and ChatGPT-3.5 answered all questions, whereas Google Bard answered only 53.3% (P &lt; .0001). The number of questions with reproducible answers was higher for ChatGPT-4 (95%) and ChatGPT3.5 (88.3%) than for Google Bard (50%) (P &lt; .0001). In terms of accuracy, the number of answers deemed fully correct were 75.4%, 58.5%, and 43.8% for ChatGPT-4, ChatGPT-3.5, and Google Bard, respectively (P = .03). Furthermore, the number of responses deemed highly relevant was 71.9%, 77.4%, and 43.8% for ChatGPT-4, ChatGPT-3.5, and Google Bard, respectively (P = .04). Regarding readability, the number of highly readable was higher for ChatGPT-4 and ChatGPT-3.5 (98.1%) and (100%) compared to Google Bard (87.5%) (P = .02).\n\n\nConclusion\nChatGPT-4 and ChatGPT-3.5 are potentially powerful tools in immuno-oncology, whereas Google Bard demonstrated relatively poorer performance. However, the risk of inaccuracy or incompleteness in the responses was evident in all 3 LLMs, highlighting the importance of expert-driven verification of the outputs returned by these technologies.\n",
        "link": "http://dx.doi.org/10.1093/oncolo/oyae009"
    },
    {
        "id": 12280,
        "title": "Radiological Differential Diagnoses Based on Cardiovascular and Thoracic Imaging Patterns: Perspectives of Four Large Language Models",
        "authors": "Pradosh Kumar Sarangi, Aparna Irodi, Swaha Panda, Debasish Swapnesh Kumar Nayak, Himel Mondal",
        "published": "2023-12-28",
        "citations": 3,
        "abstract": "Abstract\n          Background Differential diagnosis in radiology is a critical aspect of clinical decision-making. Radiologists in the early stages may find difficulties in listing the differential diagnosis from image patterns. In this context, the emergence of large language models (LLMs) has introduced new opportunities as these models have the capacity to access and contextualize extensive information from text-based input.\n          Objective The objective of this study was to explore the utility of four LLMs—ChatGPT3.5, Google Bard, Microsoft Bing, and Perplexity—in providing most important differential diagnoses of cardiovascular and thoracic imaging patterns.\n          Methods We selected 15 unique cardiovascular (n = 5) and thoracic (n = 10) imaging patterns. We asked each model to generate top 5 most important differential diagnoses for every pattern. Concurrently, a panel of two cardiothoracic radiologists independently identified top 5 differentials for each case and came to consensus when discrepancies occurred. We checked the concordance and acceptance of LLM-generated differentials with the consensus differential diagnosis. Categorical variables were compared by binomial, chi-squared, or Fisher's exact test.\n          Results A total of 15 cases with five differentials generated a total of 75 items to analyze. The highest level of concordance was observed for diagnoses provided by Perplexity (66.67%), followed by ChatGPT (65.33%) and Bing (62.67%). The lowest score was for Bard with 45.33% of concordance with expert consensus. The acceptance rate was highest for Perplexity (90.67%), followed by Bing (89.33%) and ChatGPT (85.33%). The lowest acceptance rate was for Bard (69.33%).\n          Conclusion Four LLMs—ChatGPT3.5, Google Bard, Microsoft Bing, and Perplexity—generated differential diagnoses had high level of acceptance but relatively lower concordance. There were significant differences in acceptance and concordance among the LLMs. Hence, it is important to carefully select the suitable model for usage in patient care or in medical education.",
        "link": "http://dx.doi.org/10.1055/s-0043-1777289"
    },
    {
        "id": 12281,
        "title": "WSDM 2024 Workshop on Large Language Models for Individuals, Groups, and Society",
        "authors": "Michael Bendersky, Cheng Li, Qiaozhu Mei, Vanessa Murdock, Jie Tang, Hongning Wang, Hamed Zamani, Mingyang Zhang",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3616855.3635726"
    },
    {
        "id": 12282,
        "title": "How large language models can augment perioperative medicine: a daring discourse",
        "authors": "Rodney A Gabriel, Edward R Mariano, Julian McAuley, Christopher L Wu",
        "published": "2023-11",
        "citations": 3,
        "abstract": "Interest in natural language processing, specifically large language models, for clinical applications has exploded in a matter of several months since the introduction of ChatGPT. Large language models are powerful and impressive. It is important that we understand the strengths and limitations of this rapidly evolving technology so that we can brainstorm its future potential in perioperative medicine. In this daring discourse, we discuss the issues with these large language models and how we should proactively think about how to leverage these models into practice to improve patient care, rather than worry that it may take over clinical decision-making. We review three potential major areas in which it may be used to benefit perioperative medicine: (1) clinical decision support and surveillance tools, (2) improved aggregation and analysis of research data related to large retrospective studies and application in predictive modeling, and (3) optimized documentation for quality measurement, monitoring and billing compliance. These large language models are here to stay and, as perioperative providers, we can either adapt to this technology or be curtailed by those who learn to use it well.",
        "link": "http://dx.doi.org/10.1136/rapm-2023-104637"
    },
    {
        "id": 12283,
        "title": "Censuses and Large-Scale Surveys in Language Research",
        "authors": "Jennifer Leeman",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-02249-9_8"
    },
    {
        "id": 12284,
        "title": "Entities, Dates, and Languages: Zero-Shot on Historical Texts with T0",
        "authors": "Francesco De Toni, Christopher Akiki, Javier De La Rosa, Clémentine Fourrier, Enrique Manjavacas, Stefan Schweter, Daniel Van Strien",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bigscience-1.7"
    },
    {
        "id": 12285,
        "title": "Automatically Generating CS Learning Materials with Large Language Models",
        "authors": "Stephen MacNeil, Andrew Tran, Juho Leinonen, Paul Denny, Joanne Kim, Arto Hellas, Seth Bernstein, Sami Sarsa",
        "published": "2022-3",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3545947.3569630"
    },
    {
        "id": 12286,
        "title": "LSTM-Based Language Models for Very Large Vocabulary Continuous Russian Speech Recognition System",
        "authors": "Irina Kipyatkova",
        "published": "2019",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-26061-3_23"
    },
    {
        "id": 12287,
        "title": "Evaluation of large language models in breast cancer clinical scenarios: A comparative analysis based on ChatGPT-3.5, ChatGPT-4.0, and Claude2",
        "authors": "Linfang Deng, Tianyi Wang,  Yangzhang, Zhenhua Zhai, Wei Tao, Jincheng Li, Yi Zhao, Jinjiang Xu, Shaoting Luo",
        "published": "2024-1-23",
        "citations": 0,
        "abstract": "\nBackground\nLarge language models (LLMs) have garnered significant attention in the AI domain owing to their exemplary context recognition and response capabilities. However, the potential of LLMs in specific clinical scenarios, particularly in breast cancer diagnosis, treatment, and care, has not been fully explored. This study aimed to compare the performances of three major LLMs in the clinical context of breast cancer.\n\n\nMethods\nIn this study, clinical scenarios designed specifically for breast cancer were segmented into five pivotal domains (nine cases): assessment and diagnosis, treatment decision-making, post-operative care, psychosocial support, and prognosis and rehabilitation. The LLMs were used to generate feedback for various queries related to these domains. For each scenario, a panel of five breast cancer specialists, each with over a decade of experience, evaluated the feedback from LLMs. They assessed feedback concerning LLMs in terms of their quality, relevance, and applicability.\n\n\nResults\nThere was a moderate level of agreement among the raters (Fleiss’ kappa=0.345, P<0.05). Comparing the performance of different models regarding response length, GPT-4.0 and GPT-3.5 provided relatively longer feedback than Claude2. Furthermore, across the nine case analyses, GPT-4.0 significantly outperformed the other two models in average quality, relevance, and applicability. Within the five clinical areas, GPT-4.0 markedly surpassed GPT-3.5 in the quality of the other four areas and scored higher than Claude2 in tasks related to psychosocial support and treatment decision-making.\n\n\nConclusion\nThis study revealed that in the realm of clinical applications for breast cancer, GPT-4.0 showcases not only superiority in terms of quality and relevance but also demonstrates exceptional capability in applicability, especially when compared to GPT-3.5. Relative to Claude2, GPT-4.0 holds advantages in specific domains. With the expanding use of LLMs in the clinical field, ongoing optimization and rigorous accuracy assessments are paramount.\n",
        "link": "http://dx.doi.org/10.1097/js9.0000000000001066"
    },
    {
        "id": 12288,
        "title": "Instruction Tuning Text-to-SQL with Large Language Models in the Power Grid Domain",
        "authors": "Gang Sun, Ran Shen, Liangfeng Jin, Yifan Wang, Shiyu Xu, Jinpeng Chen, Weihao Jiang",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3622896.3622906"
    },
    {
        "id": 12289,
        "title": "From manual to machine: assessing the efficacy of large language models in content analysis",
        "authors": "Andrew Pilny, Kelly McAninch, Amanda Slone, Kelsey Moore",
        "published": "2024-3-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/08824096.2024.2327547"
    },
    {
        "id": 12290,
        "title": "The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation",
        "authors": "Patrick Fernandes, Daniel Deutsch, Mara Finkelstein, Parker Riley, André Martins, Graham Neubig, Ankush Garg, Jonathan Clark, Markus Freitag, Orhan Firat",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.wmt-1.100"
    },
    {
        "id": 12291,
        "title": "Evaluating Large Language Models for the National Premedical Exam in India: Comparative Analysis of GPT-3.5, GPT-4, and Bard",
        "authors": "Faiza Farhat, Beenish Moalla Chaudhry, Mohammad Nadeem, Shahab Saquib Sohail, Dag Øivind Madsen",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "\nBackground\nLarge language models (LLMs) have revolutionized natural language processing with their ability to generate human-like text through extensive training on large data sets. These models, including Generative Pre-trained Transformers (GPT)-3.5 (OpenAI), GPT-4 (OpenAI), and Bard (Google LLC), find applications beyond natural language processing, attracting interest from academia and industry. Students are actively leveraging LLMs to enhance learning experiences and prepare for high-stakes exams, such as the National Eligibility cum Entrance Test (NEET) in India.\n\n\nObjective\nThis comparative analysis aims to evaluate the performance of GPT-3.5, GPT-4, and Bard in answering NEET-2023 questions.\n\n\nMethods\nIn this paper, we evaluated the performance of the 3 mainstream LLMs, namely GPT-3.5, GPT-4, and Google Bard, in answering questions related to the NEET-2023 exam. The questions of the NEET were provided to these artificial intelligence models, and the responses were recorded and compared against the correct answers from the official answer key. Consensus was used to evaluate the performance of all 3 models.\n\n\nResults\nIt was evident that GPT-4 passed the entrance test with flying colors (300/700, 42.9%), showcasing exceptional performance. On the other hand, GPT-3.5 managed to meet the qualifying criteria, but with a substantially lower score (145/700, 20.7%). However, Bard (115/700, 16.4%) failed to meet the qualifying criteria and did not pass the test. GPT-4 demonstrated consistent superiority over Bard and GPT-3.5 in all 3 subjects. Specifically, GPT-4 achieved accuracy rates of 73% (29/40) in physics, 44% (16/36) in chemistry, and 51% (50/99) in biology. Conversely, GPT-3.5 attained an accuracy rate of 45% (18/40) in physics, 33% (13/26) in chemistry, and 34% (34/99) in biology. The accuracy consensus metric showed that the matching responses between GPT-4 and Bard, as well as GPT-4 and GPT-3.5, had higher incidences of being correct, at 0.56 and 0.57, respectively, compared to the matching responses between Bard and GPT-3.5, which stood at 0.42. When all 3 models were considered together, their matching responses reached the highest accuracy consensus of 0.59.\n\n\nConclusions\nThe study’s findings provide valuable insights into the performance of GPT-3.5, GPT-4, and Bard in answering NEET-2023 questions. GPT-4 emerged as the most accurate model, highlighting its potential for educational applications. Cross-checking responses across models may result in confusion as the compared models (as duos or a trio) tend to agree on only a little over half of the correct responses. Using GPT-4 as one of the compared models will result in higher accuracy consensus. The results underscore the suitability of LLMs for high-stakes exams and their positive impact on education. Additionally, the study establishes a benchmark for evaluating and enhancing LLMs’ performance in educational tasks, promoting responsible and informed use of these models in diverse learning environments.\n",
        "link": "http://dx.doi.org/10.2196/51523"
    },
    {
        "id": 12292,
        "title": "A Text-Based Predictive Maintenance Approach for Facility Management Requests Utilizing Association Rule Mining and Large Language Models",
        "authors": "Maximilian Lowin",
        "published": "2024-1-26",
        "citations": 0,
        "abstract": "Introduction: Due to the lack of labeled data, applying predictive maintenance algorithms for facility management is cumbersome. Most companies are unwilling to share data or do not have time for annotation. In addition, most available facility management data are text data. Thus, there is a need for an unsupervised predictive maintenance algorithm that is capable of handling textual data. Methodology: This paper proposes applying association rule mining on maintenance requests to identify upcoming needs in facility management. By coupling temporal association rule mining with the concept of semantic similarity derived from large language models, the proposed methodology can discover meaningful knowledge in the form of rules suitable for decision-making. Results: Relying on the large German language models works best for the presented case study. Introducing a temporal lift filter allows for reducing the created rules to the most important ones. Conclusions: Only a few maintenance requests are sufficient to mine association rules that show links between different infrastructural failures. Due to the unsupervised manner of the proposed algorithm, domain experts need to evaluate the relevance of the specific rules. Nevertheless, the algorithm enables companies to efficiently utilize their data stored in databases to create interpretable rules supporting decision-making.",
        "link": "http://dx.doi.org/10.3390/make6010013"
    },
    {
        "id": 12293,
        "title": "Risks of abuse of large language models, like <scp>ChatGPT</scp>, in scientific publishing: Authorship, predatory publishing, and paper mills",
        "authors": "Graham Kendall, Jaime A. Teixeira da Silva",
        "published": "2024-1",
        "citations": 1,
        "abstract": "Key points\nAcademia is already witnessing the abuse of authorship in papers with text generated by large language models (LLMs) such as ChatGPT.\nLLM‐generated text is testing the limits of publishing ethics as we traditionally know it.\nWe alert the community to imminent risks of LLM technologies, like ChatGPT, for amplifying the predatory publishing ‘industry’.\nThe abuse of ChatGPT for the paper mill industry cannot be over‐emphasized.\nDetection of LLM‐generated text is the responsibility of editors and journals/publishers.\n",
        "link": "http://dx.doi.org/10.1002/leap.1578"
    },
    {
        "id": 12294,
        "title": "Students’ use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances",
        "authors": "Margherita Bernabei, Silvia Colabianchi, Andrea Falegnami, Francesco Costantino",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.caeai.2023.100172"
    },
    {
        "id": 12295,
        "title": "A Survey of Metrics to Enhance Training Dependability in Large Language Models",
        "authors": "Wenyi Fang, Hao Zhang, Ziyu Gong, Longbin Zeng, Xuhui Lu, Biao Liu, Xiaoyu Wu, Yang Zheng, Zheng Hu, Xun Zhang",
        "published": "2023-10-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/issrew60843.2023.00071"
    },
    {
        "id": 12296,
        "title": "An AI Dietitian for Type 2 Diabetes Mellitus Management Based on Large Language and Image Recognition Models: Preclinical Concept Validation Study (Preprint)",
        "authors": "Haonan Sun, Kai Zhang, Wei Lan, Qiufeng Gu, Guangxiang Jiang, Xue Yang, Wanli Qin, Dongran Han",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nNutritional management for patients with diabetes in China is a significant challenge due to the low supply of registered clinical dietitians. To address this, an artificial intelligence (AI)–based nutritionist program that uses advanced language and image recognition models was created. This program can identify ingredients from images of a patient’s meal and offer nutritional guidance and dietary recommendations.\n\n\nOBJECTIVE\nThe primary objective of this study is to evaluate the competence of the models that support this program.\n\n\nMETHODS\nThe potential of an AI nutritionist program for patients with type 2 diabetes mellitus (T2DM) was evaluated through a multistep process. First, a survey was conducted among patients with T2DM and endocrinologists to identify knowledge gaps in dietary practices. ChatGPT and GPT 4.0 were then tested through the Chinese Registered Dietitian Examination to assess their proficiency in providing evidence-based dietary advice. ChatGPT’s responses to common questions about medical nutrition therapy were compared with expert responses by professional dietitians to evaluate its proficiency. The model’s food recommendations were scrutinized for consistency with expert advice. A deep learning–based image recognition model was developed for food identification at the ingredient level, and its performance was compared with existing models. Finally, a user-friendly app was developed, integrating the capabilities of language and image recognition models to potentially improve care for patients with T2DM.\n\n\nRESULTS\nMost patients (182/206, 88.4%) demanded more immediate and comprehensive nutritional management and education. Both ChatGPT and GPT 4.0 passed the Chinese Registered Dietitian examination. ChatGPT’s food recommendations were mainly in line with best practices, except for certain foods like root vegetables and dry beans. Professional dietitians’ reviews of ChatGPT’s responses to common questions were largely positive, with 162 out of 168 providing favorable reviews. The multilabel image recognition model evaluation showed that the Dino V2 model achieved an average <i>F</i><sub>1</sub> score of 0.825, indicating high accuracy in recognizing ingredients.\n\n\nCONCLUSIONS\nThe model evaluations were promising. The AI-based nutritionist program is now ready for a supervised pilot study.\n",
        "link": "http://dx.doi.org/10.2196/preprints.51300"
    },
    {
        "id": 12297,
        "title": "The Application of Large Language Models for Radiologic Decision Making",
        "authors": "Hossam A. Zaki, Andrew Aoun, Saminah Munshi, Hazem Abdel-Megid, Lleayem Nazario-Johnson, Sun Ho Ahn",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jacr.2024.01.007"
    },
    {
        "id": 12298,
        "title": "Large Language Models for Test-Free Fault Localization",
        "authors": "Aidan Z. H. Yang, Claire Le Goues, Ruben Martins, Vincent Hellendoorn",
        "published": "2024-2-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3597503.3623342"
    },
    {
        "id": 12299,
        "title": "Massively Multilingual Shallow Fusion with Large Language Models",
        "authors": "Ke Hu, Tara N. Sainath, Bo Li, Nan Du, Yanping Huang, Andrew M. Dai, Yu Zhang, Rodrigo Cabrera, Zhifeng Chen, Trevor Strohman",
        "published": "2023-6-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10094796"
    },
    {
        "id": 12300,
        "title": "Use of Large Language Models to Assess the Likelihood of Epidemics From the Content of Tweets: Infodemiology Study (Preprint)",
        "authors": "Michael S Deiner, Natalie A Deiner, Vagelis Hristidis, Stephen D McLeod, Thuy Doan, Thomas M Lietman, Travis C Porco",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nPrevious work suggests that Google searches could be useful in identifying conjunctivitis epidemics. Content-based assessment of social media content may provide additional value in serving as early indicators of conjunctivitis and other systemic infectious diseases.\n\n\nOBJECTIVE\nWe investigated whether large language models, specifically GPT-3.5 and GPT-4 (OpenAI), can provide probabilistic assessments of whether social media posts about conjunctivitis could indicate a regional outbreak.\n\n\nMETHODS\nA total of 12,194 conjunctivitis-related tweets were obtained using a targeted Boolean search in multiple languages from India, Guam (United States), Martinique (France), the Philippines, American Samoa (United States), Fiji, Costa Rica, Haiti, and the Bahamas, covering the time frame from January 1, 2012, to March 13, 2023. By providing these tweets via prompts to GPT-3.5 and GPT-4, we obtained probabilistic assessments that were validated by 2 human raters. We then calculated Pearson correlations of these time series with tweet volume and the occurrence of known outbreaks in these 9 locations, with time series bootstrap used to compute CIs.\n\n\nRESULTS\nProbabilistic assessments derived from GPT-3.5 showed correlations of 0.60 (95% CI 0.47-0.70) and 0.53 (95% CI 0.40-0.65) with the 2 human raters, with higher results for GPT-4. The weekly averages of GPT-3.5 probabilities showed substantial correlations with weekly tweet volume for 44% (4/9) of the countries, with correlations ranging from 0.10 (95% CI 0.0-0.29) to 0.53 (95% CI 0.39-0.89), with larger correlations for GPT-4. More modest correlations were found for correlation with known epidemics, with substantial correlation only in American Samoa (0.40, 95% CI 0.16-0.81).\n\n\nCONCLUSIONS\nThese findings suggest that GPT prompting can efficiently assess the content of social media posts and indicate possible disease outbreaks to a degree of accuracy comparable to that of humans. Furthermore, we found that automated content analysis of tweets is related to tweet volume for conjunctivitis-related posts in some locations and to the occurrence of actual epidemics. Future work may improve the sensitivity and specificity of these methods for disease outbreak detection.\n",
        "link": "http://dx.doi.org/10.2196/preprints.49139"
    },
    {
        "id": 12301,
        "title": "ChatGPT and large language models in orthopedics: from education and surgery to research",
        "authors": "Srijan Chatterjee, Manojit Bhattacharya, Soumen Pal, Sang‐Soo Lee, Chiranjib Chakraborty",
        "published": "2023-1",
        "citations": 0,
        "abstract": "AbstractChatGPT has quickly popularized since its release in November 2022. Currently, large language models (LLMs) and ChatGPT have been applied in various domains of medical science, including in cardiology, nephrology, orthopedics, ophthalmology, gastroenterology, and radiology. Researchers are exploring the potential of LLMs and ChatGPT for clinicians and surgeons in every domain. This study discusses how ChatGPT can help orthopedic clinicians and surgeons perform various medical tasks. LLMs and ChatGPT can help the patient community by providing suggestions and diagnostic guidelines. In this study, the use of LLMs and ChatGPT to enhance and expand the field of orthopedics, including orthopedic education, surgery, and research, is explored. Present LLMs have several shortcomings, which are discussed herein. However, next‐generation and future domain‐specific LLMs are expected to be more potent and transform patients’ quality of life.",
        "link": "http://dx.doi.org/10.1186/s40634-023-00700-1"
    },
    {
        "id": 12302,
        "title": "How can We Leverage Static Analysis and Large Language Models to Engage Students in Software Quality Improvement",
        "authors": "Eman Abdullah AlOmar, Mohamed Wiem Mkaouer",
        "published": "2024-3-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626253.3635356"
    },
    {
        "id": 12303,
        "title": "Retrieval-Generation Synergy Augmented Large Language Models",
        "authors": "Zhangyin Feng, Xiaocheng Feng, Dezhi Zhao, Maojin Yang, Bing Qin",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10448015"
    },
    {
        "id": 12304,
        "title": "Large Language Models in Medicine: The Potentials and Pitfalls",
        "authors": "Jesutofunmi A. Omiye, Haiwen Gui, Shawheen J. Rezaei, James Zou, Roxana Daneshjou",
        "published": "2024-2",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7326/m23-2772"
    },
    {
        "id": 12305,
        "title": "CoQ:AN Empirical Framework for Multi-hop Question Answering Empowered by Large Language Models",
        "authors": "Qiang Huang, Feng Huang, DeHao Tao, YueTong Zhao, BingKun Wang, YongFeng Huang",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447488"
    },
    {
        "id": 12306,
        "title": "Language Model Decomposition: Quantifying the Dependency and Correlation of Language Models",
        "authors": "Hao Zhang",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.161"
    },
    {
        "id": 12307,
        "title": "A Comprehensive Comparison of Pre-training Language Models",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Recently, the development of pre-trained language models has brought natural language processing (NLP) tasks to the new state-of-the-art. In this paper we explore the efficiency of various pre-trained language models. We pre-train a list of transformer-based models with the same amount of text and the same training steps. The experimental results shows that the most improvement upon the origin BERT is adding the RNN-layer to capture more contextual information for short text understanding. But the conclusion is: There are no remarkable improvement for short text understanding for similar BERT structures. Data-centric method[12] can achieve better performance.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.14820348"
    },
    {
        "id": 12308,
        "title": "A Comprehensive Comparison of Pre-training Language Models",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Recently, the development of pre-trained language models has brought natural language processing (NLP) tasks to the new state-of-the-art. In this paper we explore the efficiency of various pre-trained language models. We pre-train a list of transformer-based models with the same amount of text and the same training steps. The experimental results shows that the most improvement upon the origin BERT is adding the RNN-layer to capture more contextual information for short text understanding. But the conclusion is: There are no remarkable improvement for short text understanding for similar BERT structures. Data-centric method[12] can achieve better performance.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.14820348.v8"
    },
    {
        "id": 12309,
        "title": "Language Models and Cognitive Automation for Economic Research",
        "authors": "Anton Korinek",
        "published": "2023-2",
        "citations": 22,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3386/w30957"
    },
    {
        "id": 12310,
        "title": "A Comprehensive Comparison of Pre-training Language Models",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Recently, the development of pre-trained language models has brought natural language processing (NLP) tasks to the new state-of-the-art. In this paper we explore the efficiency of various pre-trained language models. We pre-train a list of transformer-based models with the same amount of text and the same training steps. The experimental results shows that the most improvement upon the origin BERT is adding the RNN-layer to capture more contextual information for short text understanding. But the conclusion is: There are no remarkable improvement for short text understanding for similar BERT structures.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.14820348.v6"
    },
    {
        "id": 12311,
        "title": "A Comprehensive Exploration of Pre-training Language Models",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "Recently, the development of pre-trained language models\nhas brought natural language processing (NLP) tasks to the new state-of-the-art. In this paper we explore the efficiency of various pre-trained\nlanguage models. We pre-train a list of transformer-based models with\nthe same amount of text and the same training steps. The experimental results shows that the most improvement upon the origin BERT is\nadding the RNN-layer to capture more contextual information for short text\nunderstanding.",
        "link": "http://dx.doi.org/10.36227/techrxiv.14820348.v3"
    },
    {
        "id": 12312,
        "title": "A shortened test is feasible: Evaluating a large-scale multistage adaptive English language assessment",
        "authors": "Shangchao Min, Kyoungwon Bishop",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": " This paper evaluates the multistage adaptive test (MST) design of a large-scale academic language assessment (ACCESS) for Grades 1–12, with an aim to simplify the current MST design, using both operational and simulated test data. Study 1 explored the operational population data (1,456,287 test-takers) of the listening and reading tests of MST ACCESS in the 2018–2019 school year to evaluate the MST design in terms of measurement efficiency and precision. Study 2 is a simulation study conducted to find an optimal MST design with manipulation on the number of items per stage and panel structure. The results from operational test data showed that the test length for both the listening and reading tests could be shortened to six folders (i.e., 18 items), with final ability estimates and reliability coefficients comparable to those of the current test, with slight differences. The simulation study showed that all six proposed MST designs yielded slightly better measurement accuracy and efficiency than the current design, among which the 1-3-3 MST design with more items at earlier stages ranked first. The findings of this study provide implications for the evaluation of MST designs and ways to optimize MST designs in language assessment. ",
        "link": "http://dx.doi.org/10.1177/02655322231225426"
    },
    {
        "id": 12313,
        "title": "Cold Fusion: Training Seq2Seq Models Together with Language Models",
        "authors": "Anuroop Sriram, Heewoo Jun, Sanjeev Satheesh, Adam Coates",
        "published": "2018-9-2",
        "citations": 87,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2018-1392"
    },
    {
        "id": 12314,
        "title": "ROLE MODELS",
        "authors": "",
        "published": "2017-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv2rcngs0.23"
    },
    {
        "id": 12315,
        "title": "A Comprehensive Comparison of Pre-training Language Models",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Recently, the development of pre-trained language models has brought natural language processing (NLP) tasks to the new state-of-the-art. In this paper we explore the efficiency of various pre-trained language models. We pre-train a list of transformer-based models with the same amount of text and the same training steps. The experimental results shows that the most improvement upon the origin BERT is adding the RNN-layer to capture more contextual information for short text understanding. But the conclusion is: There are no remarkable improvement for short text understanding for similar BERT structures. Data-centric method[12] can achieve better performance.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.14820348.v7"
    },
    {
        "id": 12316,
        "title": "A Comprehensive Comparison of Pre-training Language Models",
        "authors": "TechOnly Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Recently, the development of pre-trained language models has brought natural language processing (NLP) tasks to the new state-of-the-art. In this paper we explore the efficiency of various pre-trained language models. We pre-train a list of transformer-based models with the same amount of text and the same training steps. The experimental results shows that the most improvement upon the origin BERT is adding the RNN-layer to capture more contextual information for short text understanding. But there are no remarkable improvement for short text understanding for similar BERT structures.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.14820348.v5"
    },
    {
        "id": 12317,
        "title": "Models of Language in the Brain",
        "authors": "",
        "published": "2022-5-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7551/mitpress/12824.003.0007"
    },
    {
        "id": 12318,
        "title": "A Comprehensive Exploration of Pre-training Language Models",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 2,
        "abstract": "Recently, the development of pre-trained language models\nhas brought natural language processing (NLP) tasks to the new state-of-the-art. In this paper we explore the efficiency of various pre-trained\nlanguage models. We pre-train a list of transformer-based models with\nthe same amount of text and the same training steps. The experimental results shows that the most improvement upon the origin BERT is\nadding the RNN-layer to capture more contextual information for the\ntransformer-encoder layers.",
        "link": "http://dx.doi.org/10.36227/techrxiv.14820348.v2"
    },
    {
        "id": 12319,
        "title": "A Comprehensive Exploration of Pre-training Language Models",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Recently, the development of pre-trained language models has brought natural language processing (NLP) tasks to the new state-of-the-art. In this paper we explore the efficiency of various pre-trained language models. We pre-train a list of transformer-based models with the same amount of text and the same training steps. The experimental results shows that the most improvement upon the origin BERT is adding the RNN-layer to capture more contextual information for short text understanding. But there are no remarkable improvement for short text understanding for similar BERT structures.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.14820348.v4"
    },
    {
        "id": 12320,
        "title": "Uncovering Inconsistencies and Contradictions in Financial Reports using Large Language Models",
        "authors": "Tobias Deußer, David Leonhard, Lars Hillebrand, Armin Berger, Mohamed Khaled, Sarah Heiden, Tim Dilmaghani, Bernd Kliem, Rüdiger Loitz, Christian Bauckhage, Rafet Sifa",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386673"
    },
    {
        "id": 12321,
        "title": "Evaluation of Large Language Models (Llms) on the Mastery of Knowledge and Skills in the Heating, Ventilation and Air Conditioning (Hvac) Industry",
        "authors": "Jie Lu, Zeyu Zheng, Chaobo Zhang, Yang Zhao, Jian Zhang, Wenkai Zhang, Chenxin Feng, Jianing He, Jiaxi Wang, Fengtai He",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4715355"
    },
    {
        "id": 12322,
        "title": "Evaluation of the Performance of Generative AI Large Language Models ChatGPT, Google Bard, and Microsoft Bing Chat in Supporting Evidence-Based Dentistry: Comparative Mixed Methods Study (Preprint)",
        "authors": "Kostis Giannakopoulos, Argyro Kavadella, Anas Aaqel Salim, Vassilis Stamatopoulos, Eleftherios G Kaklamanos",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nThe increasing application of generative artificial intelligence large language models (LLMs) in various fields, including dentistry, raises questions about their accuracy.\n\n\nOBJECTIVE\nThis study aims to comparatively evaluate the answers provided by 4 LLMs, namely Bard (Google LLC), ChatGPT-3.5 and ChatGPT-4 (OpenAI), and Bing Chat (Microsoft Corp), to clinically relevant questions from the field of dentistry.\n\n\nMETHODS\nThe LLMs were queried with 20 open-type, clinical dentistry–related questions from different disciplines, developed by the respective faculty of the School of Dentistry, European University Cyprus. The LLMs’ answers were graded 0 (minimum) to 10 (maximum) points against strong, traditionally collected scientific evidence, such as guidelines and consensus statements, using a rubric, as if they were examination questions posed to students, by 2 experienced faculty members. The scores were statistically compared to identify the best-performing model using the Friedman and Wilcoxon tests. Moreover, the evaluators were asked to provide a qualitative evaluation of the comprehensiveness, scientific accuracy, clarity, and relevance of the LLMs’ answers.\n\n\nRESULTS\nOverall, no statistically significant difference was detected between the scores given by the 2 evaluators; therefore, an average score was computed for every LLM. Although ChatGPT-4 statistically outperformed ChatGPT-3.5 (<i>P</i>=.008), Bing Chat (<i>P</i>=.049), and Bard (<i>P</i>=.045), all models occasionally exhibited inaccuracies, generality, outdated content, and a lack of source references. The evaluators noted instances where the LLMs delivered irrelevant information, vague answers, or information that was not fully accurate.\n\n\nCONCLUSIONS\nThis study demonstrates that although LLMs hold promising potential as an aid in the implementation of evidence-based dentistry, their current limitations can lead to potentially harmful health care decisions if not used judiciously. Therefore, these tools should not replace the dentist’s critical thinking and in-depth understanding of the subject matter. Further research, clinical validation, and model improvements are necessary for these tools to be fully integrated into dental practice. Dental practitioners must be aware of the limitations of LLMs, as their imprudent use could potentially impact patient care. Regulatory measures should be established to oversee the use of these evolving technologies.\n\n\nCLINICALTRIAL\n\n",
        "link": "http://dx.doi.org/10.2196/preprints.51580"
    },
    {
        "id": 12323,
        "title": "The use of large language models in medicine: proceeding with caution",
        "authors": "Jiawen Deng, Areeba Zubair, Ye-Jean Park, Eesha Affan, Qi Kang Zuo",
        "published": "2024-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/03007995.2023.2295411"
    },
    {
        "id": 12324,
        "title": "Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models",
        "authors": "Simon Stepputtis, Joseph Campbell, Yaqi Xie, Zhengyang Qi, Wenxin Zhang, Ruiyi Wang, Sanketh Rangreji, Charles Lewis, Katia Sycara",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.748"
    },
    {
        "id": 12325,
        "title": "Large Language Models (LLMs) Inference Offloading and Resource Allocation in Cloud-Edge Networks: An Active Inference Approach",
        "authors": "Jingcheng Fang, Ying He, F. Richard Yu, Jianqiang Li, Victor C. Leung",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/vtc2023-fall60731.2023.10333824"
    },
    {
        "id": 12326,
        "title": "Leveraging Large Language Models for End-User Website Generation",
        "authors": "Tommaso Calò, Luigi De Russis",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-34433-6_4"
    },
    {
        "id": 12327,
        "title": "Semantic Parsing for Knowledge Graph Question Answering with Large Language Models",
        "authors": "Debayan Banerjee",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-43458-7_42"
    },
    {
        "id": 12328,
        "title": "Q: How to Specialize Large Vision-Language Models to Data-Scarce VQA Tasks? A: Self-Train on Unlabeled Images!",
        "authors": "Zaid Khan, BG Vijay Kumar, Samuel Schulter, Xiang Yu, Yun Fu, Manmohan Chandraker",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01441"
    },
    {
        "id": 12329,
        "title": "AutoConv: Automatically Generating Information-seeking Conversations with Large Language Models",
        "authors": "Siheng Li, Cheng Yang, Yichun Yin, Xinyu Zhu, Zesen Cheng, Lifeng Shang, Xin Jiang, Qun Liu, Yujiu Yang",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-short.149"
    },
    {
        "id": 12330,
        "title": "From Large Language Models to Databases and Back: A Discussion on Research and Education",
        "authors": "Sihem Amer-Yahia, Angela Bonifati, Lei Chen, Guoliang Li, Kyuseok Shim, Jianliang Xu, Xiaochun Yang",
        "published": "2023-10-30",
        "citations": 3,
        "abstract": "In recent years, large language models (LLMs) have garnered increasing attention from both academia and industry due to their potential to facilitate natural language processing (NLP) and generate highquality text. Despite their benefits, however, the use of LLMs is raising concerns about the reliability of knowledge extraction. The combination of DB research and data science has advanced the state of the art in solving real-world problems, such as merchandise recommendation and hazard prevention [30]. In this discussion, we explore the challenges and opportunities related to LLMs in DB and data science research and education.",
        "link": "http://dx.doi.org/10.1145/3631504.3631518"
    },
    {
        "id": 12331,
        "title": "Challenges and barriers of using large language models (LLM) such as ChatGPT for diagnostic medicine with a focus on digital pathology – a recent scoping review",
        "authors": "Ehsan Ullah, Anil Parwani, Mirza Mansoor Baig, Rajendra Singh",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "Abstract\nBackground\nThe integration of large language models (LLMs) like ChatGPT in diagnostic medicine, with a focus on digital pathology, has garnered significant attention. However, understanding the challenges and barriers associated with the use of LLMs in this context is crucial for their successful implementation.\n\nMethods\nA scoping review was conducted to explore the challenges and barriers of using LLMs, in diagnostic medicine with a focus on digital pathology. A comprehensive search was conducted using electronic databases, including PubMed and Google Scholar, for relevant articles published within the past four years. The selected articles were critically analyzed to identify and summarize the challenges and barriers reported in the literature.\n\nResults\nThe scoping review identified several challenges and barriers associated with the use of LLMs in diagnostic medicine. These included limitations in contextual understanding and interpretability, biases in training data, ethical considerations, impact on healthcare professionals, and regulatory concerns. Contextual understanding and interpretability challenges arise due to the lack of true understanding of medical concepts and lack of these models being explicitly trained on medical records selected by trained professionals, and the black-box nature of LLMs. Biases in training data pose a risk of perpetuating disparities and inaccuracies in diagnoses. Ethical considerations include patient privacy, data security, and responsible AI use. The integration of LLMs may impact healthcare professionals’ autonomy and decision-making abilities. Regulatory concerns surround the need for guidelines and frameworks to ensure safe and ethical implementation.\n\nConclusion\nThe scoping review highlights the challenges and barriers of using LLMs in diagnostic medicine with a focus on digital pathology. Understanding these challenges is essential for addressing the limitations and developing strategies to overcome barriers. It is critical for health professionals to be involved in the selection of data and fine tuning of the models. Further research, validation, and collaboration between AI developers, healthcare professionals, and regulatory bodies are necessary to ensure the responsible and effective integration of LLMs in diagnostic medicine.\n",
        "link": "http://dx.doi.org/10.1186/s13000-024-01464-7"
    },
    {
        "id": 12332,
        "title": "Radiology in the era of large language models: the near and the dark side of the moon",
        "authors": "Pilar López-Úbeda, Teodoro Martín-Noguerol, Antonio Luna",
        "published": "2023-7-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00330-023-09901-9"
    },
    {
        "id": 12333,
        "title": "Virtual AIVantage: Leveraging Large Language Models for Enhanced VR Interview Preparation among Underrepresented Professionals in Computing",
        "authors": "Siddhanth Jayaraj Ajri, Dat Nguyen, Swati Agarwal, Arun Kumar Reddy Padala, Caglar Yildirim",
        "published": "2023-12-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626705.3631799"
    },
    {
        "id": 12334,
        "title": "Performance of ChatGPT on USMLE: Potential for AI-Assisted Medical Education Using Large Language Models",
        "authors": "Tiffany H. Kung, Morgan Cheatham, Arielle Medenilla, Czarina Sillos, Lorie De Leon, Camille Elepaño, Maria Madriaga, Rimel Aggabao, Giezel Diaz-Candido, James Maningo, Victor Tseng,  ",
        "published": "No Date",
        "citations": 73,
        "abstract": "ABSTRACTWe evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, clinical decision-making.",
        "link": "http://dx.doi.org/10.1101/2022.12.19.22283643"
    },
    {
        "id": 12335,
        "title": "Dual stream language processing models",
        "authors": "Henry Knipe, Elmira Hassanzadeh",
        "published": "2021-9-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.53347/rid-92909"
    },
    {
        "id": 12336,
        "title": "Neural Language Models",
        "authors": "",
        "published": "2020-6-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108608480.008"
    },
    {
        "id": 12337,
        "title": "A Comprehensive Exploration of Pre-training Language Models",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "Recently, the development of pre-trained language models\nhas brought natural language processing (NLP) tasks to the new state-of-the-art. In this paper we explore the efficiency of various pre-trained\nlanguage models. We pre-train a list of transformer-based models with\nthe same amount of text and the same training steps. The experimental results shows that the most improvement upon the origin BERT is\nadding the RNN-layer to capture more contextual information for the\ntransformer-encoder layers.",
        "link": "http://dx.doi.org/10.36227/techrxiv.14820348.v1"
    },
    {
        "id": 12338,
        "title": "Large Animal Models in Cardiovascular Research",
        "authors": "Hiroaki Osada, Kozue Murata, Hidetoshi Masumoto",
        "published": "2023-4-5",
        "citations": 0,
        "abstract": "Studies of not only preclinical cardiovascular research but also those of life science, medical, and pharmacological fields commonly utilize small animal models. However, for the advancement of cardiovascular medicine, researches using large animal models are important step for preclinical validation of therapeutic efficacy and safety by virtue of having models with a body and heart size comparable with that of a human, providing clinically relevant experiments without the concern of over- or under-estimating therapeutic effects and risks. In particular, pigs are considered as a suitable animal model for research in cardiovascular medicine because of the similarities in physiology, metabolism, genomics, and proteomics to those in humans. Another advantage of pigs is the availability of various heart disease models such as myocardial infarction and genetically established cardiomyopathy. The present review updates the contributions of large animal model-based research to the development of cardiovascular medicine, especially focusing on the utility of pig models.",
        "link": "http://dx.doi.org/10.5772/intechopen.105754"
    },
    {
        "id": 12339,
        "title": "PEFT-Medaware: Large Language Model for Medical Awareness",
        "authors": "Keivalya Bhartendu Pandya",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4632133"
    },
    {
        "id": 12340,
        "title": "Language Writ Large:  LLMs, ChatGPT, Grounding, Meaning and Understanding",
        "authors": "Stevan Harnad",
        "published": "No Date",
        "citations": 0,
        "abstract": "Apart from what (little) OpenAI may be concealing from us, we all know (roughly) how ChatGPT works (its huge text database, its statistics, its vector representations, and their huge number of parameters, its next-word training, etc.). But none of us can say (hand on heart) that we are not surprised by what ChatGPT has proved to be able to do with these resources. This has even driven some of us to conclude that ChatGPT actually understands. It’s not true that it understands. But it is also not true that we understand how it can do what it can do. I will suggest some hunches about benign “biases”:  convergent constraints that emerge at LLM-scale that may be helping ChatGPT do so much better than we would have expected. These biases are inherent in the nature of language itself, at LLM-scale, and they are closely linked to what it is that ChatGPT lacks, which is direct sensorimotor grounding to connect its words to their referents and its propositions to their meanings. These convergent biases are related to (1) the parasitism of indirect verbal grounding on direct sensorimotor grounding, (2) the circularity of verbal definition, (3) the “mirroring” of language production and comprehension, (4) iconicity in propositions at LLM-scale, (5) computational counterparts of human “categorical perception” in category learning by neural nets, and perhaps also (6) a conjecture by Chomsky about the laws of thought. The exposition will be in the form of a dialogue with ChatGPT-4.",
        "link": "http://dx.doi.org/10.31234/osf.io/ch2wx"
    },
    {
        "id": 12341,
        "title": "Team:PULSAR at ProbSum 2023:PULSAR: Pre-training with Extracted Healthcare Terms for Summarising Patients’ Problems and Data Augmentation with Black-box Large Language Models",
        "authors": "Hao Li, Yuping Wu, Viktor Schlegel, Riza Batista-Navarro, Thanh-Tung Nguyen, Abhinav Ramesh Kashyap, Xiao-Jun Zeng, Daniel Beck, Stefan Winkler, Goran Nenadic",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bionlp-1.49"
    },
    {
        "id": 12342,
        "title": "Use of Language Models for Document Stream Segmentation",
        "authors": "Chems Neche, Yolande Belaíd, Abdel Belaíd",
        "published": "2020",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009146402200227"
    },
    {
        "id": 12343,
        "title": "Stochastic models of glottal pulses from the Rosenberg and Liljencrants-Fant models with unified parameters",
        "authors": "E. Cataldo, D. Bahiano",
        "published": "2021-9",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2021.101225"
    },
    {
        "id": 12344,
        "title": "Towards large scale DRP simulations: generation of large super-resolution images and extraction of large pore network models",
        "authors": "Mohamed Regaieg, Clément Varloteaux, Titly Farhana Faisal, Zakaria ElAbid",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nDigital Rock Physics (DRP) provides a fast way to compute rock properties and carry-out related sensitivity analysis to complement laboratory measurements. In DRP, the first step is to obtain micro-CT images of a rock, this is then followed by segmenting the images to distinguish the rock from the pore space, and finally flow simulations are performed to compute advanced rock properties such as relative permeability and capillary pressure.\nDuring image acquisition, a compromise is often made between the speed of the image acquisition, the size of the scanned volume and the resolution obtained: increasing the resolution decreases the field of view, in turn limiting the quantity of information obtained from the image and thus making DRP simulations less representative. Furthermore, the geometry of a real rock is not always well characterized, notably due to the lack of image resolution which in turn introduces uncertainty in the pore/throat geometry and consequently introduces errors in rock property computations\nRecent advances in deep learning methods have led to major advances in computer vision techniques, and notably in the field of super-resolution imaging. In this work, we present such a strategy to digitally increase the resolution of 3D micro-CT using a deep learning approach called Enhanced Super-Resolution Generative Adversarial Network (ESRGAN).  This allows us to have well resolved images with large field of view. Large super-resolved images were produced for resolution improvement factors of x4 and x8 in each direction. The super-resolved images were more realistic visually and produced better single and multiphase flow simulations results.\nIn order to enable the simulations of very large images generated by ESRGAN we describe a stitching strategy that we have developed in order to enable the extraction of pore networks on such large images and present several validation cases of this method. This approach enables the extraction of pore networks from large images (3184*3280*12928 voxels image) that are needed to achieve large scale DRP simulations.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1878638/v1"
    },
    {
        "id": 12345,
        "title": "Sustainability of Resources in Large Marine Ecosystems",
        "authors": "Kenneth Sherman",
        "published": "2019-5-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429042423-1"
    },
    {
        "id": 12346,
        "title": "Summary and Outlook",
        "authors": "Gerhard Paaß, Sven Giesselbach",
        "published": "2023",
        "citations": 0,
        "abstract": "AbstractFoundation Models emerged as a new paradigm in sequence interpretation that can be used for a large number of tasks to understand our environment. They offer the remarkable property of combining sensory input (sound, images, video) with symbolic interpretation of text and may even include action and DNA sequences. We briefly recap the process of pre-training, fine-tuning or prompting of Foundation Models and summarize their main properties. For the different application areas presented in the book, we summarize the performance levels of the models and delineate different promising economic applications. A section is devoted to discussing the potential harm that can be caused by Foundation Models, including bias, fake news, but also possible economic monopolies and unemployment. There is an urgent need for a legal regulation of the construction and deployment of these models. The last section considers advanced artificial intelligence systems and the shortcomings of current systems. Foundation Models have significantly improved performance in recent years and have the potential to reduce the gap to a truly general AI.",
        "link": "http://dx.doi.org/10.1007/978-3-031-23190-2_8"
    },
    {
        "id": 12347,
        "title": "2. Guiding Theories: A Language Policy and Language Ecology Framework for Exploring DLBE Program Implementation",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781788928106-003"
    },
    {
        "id": 12348,
        "title": "The Language Essence of the World: A Linguistic Interpretation of the Large Language Model",
        "authors": "Leiming Shi, Peng Wu",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3390/cmsf2023008058"
    },
    {
        "id": 12349,
        "title": "Large and Small Countable Models",
        "authors": "",
        "published": "2019-4-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781316683002.032"
    },
    {
        "id": 12350,
        "title": "SAGECal Performance With Large Sky Models",
        "authors": "",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.46620/20-0026"
    },
    {
        "id": 12351,
        "title": "Towards Quantum Language Models",
        "authors": "Ivano Basile, Fabio Tamburini",
        "published": "2017",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d17-1196"
    },
    {
        "id": 12352,
        "title": "Data Augmentation for Spoken Language Understanding via Pretrained Language Models",
        "authors": "Baolin Peng, Chenguang Zhu, Michael Zeng, Jianfeng Gao",
        "published": "2021-8-30",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-117"
    },
    {
        "id": 12353,
        "title": "Whole exome sequencing in a large Swedish cohort with severe developmental language disorders",
        "authors": "Ashraf Yahia, Danyang Li, Sanna Lejerkrans, Marika Habbe, Nelli Kalnak, Kristiina Tammimies",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14293/gof.23.26"
    },
    {
        "id": 12354,
        "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model",
        "authors": "Sidney Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, Connor Leahy, Kyle McDonell, Jason Phang, Michael Pieler, Usvsn Sai Prashanth, Shivanshu Purohit, Laria Reynolds, Jonathan Tow, Ben Wang, Samuel Weinbach",
        "published": "2022",
        "citations": 66,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bigscience-1.9"
    },
    {
        "id": 12355,
        "title": "Models of child language disorders",
        "authors": "Rhea Paul, Courtenay Norbury, Carolyn Gosse",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-44234-3.00010-5"
    },
    {
        "id": 12356,
        "title": "Lessons Learnt from Linear Text Segmentation: a Fair Comparison of Architectural and Sentence Encoding Strategies for Successful Segmentation",
        "authors": "Iacopo Ghinassi,  , Lin Wang, Chris Newell, Matthew Purver,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_046"
    },
    {
        "id": 12357,
        "title": "Cross-lingual Classification of Crisis-related Tweets Using Machine Translation",
        "authors": "Shareefa Al Amer,  , Mark Lee, Phillip Smith,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_003"
    },
    {
        "id": 12358,
        "title": "Clinical Text Classification to SNOMED CT Codes using Transformers Trained on Linked Open Medical Ontologies",
        "authors": "Anton Hristov,  , Petar Ivanov, Anna Aksenova, Tsvetan Asamov, Pavlin Gyurov, Todor Primov, Svetla Boytcheva,  ,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_057"
    },
    {
        "id": 12359,
        "title": "Noisy Self-Training with Data Augmentations for Offensive and Hate Speech Detection Tasks",
        "authors": "João A. Leite,  , Carolina Scarton, Diego F. Silva,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_068"
    },
    {
        "id": 12360,
        "title": "AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity Using Contrastive Learning and Structured Knowledge",
        "authors": "Tim Schopf,  , Emanuel Gerber, Malte Ostendorff, Florian Matthes,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_113"
    },
    {
        "id": 12361,
        "title": "Simulation Techniques in Nonstandard Models",
        "authors": "Baojiu Li",
        "published": "2018-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1088/978-0-7503-1587-6ch4"
    },
    {
        "id": 12362,
        "title": "Language models are not naysayers: an analysis of language models on negation benchmarks",
        "authors": "Thinh Hung Truong, Timothy Baldwin, Karin Verspoor, Trevor Cohn",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.starsem-1.10"
    },
    {
        "id": 12363,
        "title": "Frontmatter",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-fm"
    },
    {
        "id": 12364,
        "title": "Identifying Semantic Argument Types in Predication and Copredication Contexts: A Zero-Shot Cross-Lingual Approach",
        "authors": "Deniz Ekin Yavas,  , Laura Kallmeyer, Rainer Osswald, Elisabetta Jezek, Marta Ricchiardi, Long Chen,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_035"
    },
    {
        "id": 12365,
        "title": "The Incorporation of Large Language Models (LLMs) in the Field of Education",
        "authors": "Paul Aldrin Pineda Dungca",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "This chapter delves into the ethical implications that arise from integrating LLMs within the realm of education. LLMs, exemplified by the GPT-3.5, have emerged as formidable instruments for natural language processing, offering diverse applications in educational domains. Nevertheless, their adoption necessitates careful consideration of ethical matters. This chapter comprehensively overviews the ethical potentials, threats, and opportunities in incorporating LLMs into education. It scrutinizes the potential advantages, including enriched personalized learning experiences and enhanced accessibility, while addressing concerns regarding data privacy, bias, and the ramifications of supplanting human instructors. By critically examining the ethical dimensions, this chapter endeavors to foster a varied comprehension of the implications of utilizing LLMs in educational settings.",
        "link": "http://dx.doi.org/10.4018/978-1-6684-9591-9.ch005"
    },
    {
        "id": 12366,
        "title": "Patients with floaters: Answers from virtual assistants and large language models",
        "authors": "Gloria Wu, Weichen Zhao, Adrial Wong, David A Lee",
        "published": "2024-1",
        "citations": 0,
        "abstract": "Objectives “Floaters,” a common complaint among patients of all ages, was used as a query term because it affects 30% of all people searching for eye care. The American Academy of Ophthalmology website's “floaters” section was used as a source for questions and answers ( www.aao.org ). Floaters is a visual obstruction that moves with the movement of the eye. They can be associated with retinal detachment, which can lead to vision loss. With the advent of large language model (LLM) chatbots ChatGPT, Bard versus virtual assistants (VA), Google Assistant, and Alexa, we analyzed their responses to “floaters.” Methods Using AAO.org, “Public & Patients,” and its related subsection, “EyeHealth A-Z”: Floaters and Flashes link, we asked four questions: (1) What are floaters? (2) What are flashes? (3) Flashes and Migraines? (4) Floaters and Flashes Treatment? to ChatGPT, Bard, Google Assistant, and Alexa. The American Academy of Ophthalmology (AAO) keywords were identified if they were highlighted. The “Flesch-Kincaid Grade Level” formula approved by the U.S. Department of Education, was used to evaluate the reading comprehension level for the responses. Results Of the chatbots and virtual assistants, Google Assistant is the only one that uses the term “ophthalmologist.” There is no mention of the urgency or emergency nature of floaters. AAO.org shows a lower reading level vs the LLMs and VA ( p = .11). The reading comprehension levels of ChatGPT, Bard, Google Assistant, and Alexa are higher (12.3, 9.7, 13.1, 8.1 grade) vs the AAO.org (7.3 grade). There is a higher word count for LLMs vs VA ( p < .0286). Conclusion Currently, ChatGPT, Bard, Google Assistant, and Alexa are similar. Factual information is present but all miss the urgency of the diagnosis of a retinal detachment. Translational relevance: Both the LLM and virtual assistants are free and our patients will use them to obtain “floaters” information. There may be errors of omission with ChatGPT and a lack of urgency to seek a physician's care. ",
        "link": "http://dx.doi.org/10.1177/20552076241229933"
    },
    {
        "id": 12367,
        "title": "Clinical Accuracy, Relevance, Clarity, and Emotional Sensitivity of Large Language Models to Surgical Patient Questions: Cross-Sectional Study (Preprint)",
        "authors": "Mert Marcel Dagli, Felix Conrad Oettl, Jaskeerat Gujral, Kashish Malhotra, Yohannes Ghenbot, Jang W Yoon, Ali K Ozturk, William C Welch",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\nThis cross-sectional study evaluates the clinical accuracy, relevance, clarity, and emotional sensitivity of responses to surgical patient inquiries provided by Large Language Models, highlighting their potential as adjunct tools in patient communication and education.\n",
        "link": "http://dx.doi.org/10.2196/preprints.56165"
    },
    {
        "id": 12368,
        "title": "OliVe: Accelerating Large Language Models via Hardware-friendly Outlier-Victim Pair Quantization",
        "authors": "Cong Guo, Jiaming Tang, Weiming Hu, Jingwen Leng, Chen Zhang, Fan Yang, Yunxin Liu, Minyi Guo, Yuhao Zhu",
        "published": "2023-6-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3579371.3589038"
    },
    {
        "id": 12369,
        "title": "How large language models and artificial intelligence are transforming civil engineering",
        "authors": "Vishak Dudhee, Vladimir Vukovic",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": " Large language models with artificial intelligence are transforming the way infrastructure projects are planned, executed and managed. Vishak Dudhee and Vladimir Vukovic of V-Lab say they are unlocking unprecedented efficiency and innovation in civil engineering. ",
        "link": "http://dx.doi.org/10.1680/jcien.2023.176.4.150"
    },
    {
        "id": 12370,
        "title": "Employing Large Language Models for Surgical Education: An In-depth Analysis of ChatGPT-4",
        "authors": "Adrian Hang Yue Siu, Damien Gibson, Xin Mu, Ishith Seth, Alexander Chi Wang Siu, Dilshad Dooreemeah, Angus Lee",
        "published": "2023-10-17",
        "citations": 0,
        "abstract": "Background: The growing interest in artificial intelligence (AI) has spurred an increase in the availability of Large Language Models (LLMs) in surgical education. These LLMs hold the potential to augment medical curricula for future healthcare professionals, facilitating engagement in remote learning experiences, and assisting in personalised student feedback. Objectives: To evaluate the ability of LLMs to assist junior doctors in providing advice for common ward-based surgical scenarios with increasing complexity. Methods: Utilising an instrumental case study approach, this study explored the potential of LLMs by comparing the responses of the ChatGPT-4, BingAI and BARD. LLMs were prompted by 3 common ward-based surgical scenarios and tasked with assisting junior doctors in clinical decision-making. The outputs were assessed by a panel of two senior surgeons with extensive experience in AI and education, qualitatively utilising a Likert scale on their accuracy, safety, and effectiveness to determine their viability as a synergistic tool in surgical education. A quantitative assessment of their reliability and readability was conducted using the DISCERN score and a set of reading scores, including the Flesch Reading Ease Score, Flesch-Kincaid Grade Level, and Coleman-Liau index. Results: BARD proved superior in readability, with Flesch Reading Ease Score 50.13 (± 5.00), Flesch-Kincaid Grade Level 9.33 (± 0.76), and Coleman-Liau index 11.67 (± 0.58). ChatGPT-4 outperformed BARD and BingAI, with the highest DISCERN score of 71.7 (± 2.52). Using a Likert scale-based framework, the surgical expert panel further affirmed that the advice provided by the ChatGPT-4 was suitable and safe for first-year interns and residents. A t-test showed statistical significance in reliability among all three AIs (P < 0.05) and readability only between the ChatGPT-4 and BARD. This study underscores the potential for LLM integration in surgical education, particularly ChatGPT, in the provision of reliable and accurate information. Conclusions: This study highlighted the potential of LLM, specifically ChatGPT-4, as a valuable educational resource for junior doctors. The findings are limited by the potential of non-generalizability of the use of junior doctors' simulated scenarios. Future work should aim to optimise learning experiences and better support surgical trainees. Particular attention should be paid to addressing the longitudinal impact of LLMs, refining AI models, validating AI content, and exploring technological amalgamations for improved outcomes.",
        "link": "http://dx.doi.org/10.5812/jme-137753"
    },
    {
        "id": 12371,
        "title": "Correction: How Does ChatGPT Perform on the United States Medical Licensing Examination (USMLE)? The Implications of Large Language Models for Medical Education and Knowledge Assessment (Preprint)",
        "authors": "Aidan Gilson, Conrad W Safranek, Thomas Huang, Vimig Socrates, Ling Chi, Richard Andrew Taylor, David Chartash",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\n \n",
        "link": "http://dx.doi.org/10.2196/preprints.57594"
    },
    {
        "id": 12372,
        "title": "Unraveling the landscape of large language models: a systematic review and future perspectives",
        "authors": "Qinxu Ding, Ding Ding, Yue Wang, Chong Guan, Bosheng Ding",
        "published": "2024-2-16",
        "citations": 0,
        "abstract": "PurposeThe rapid rise of large language models (LLMs) has propelled them to the forefront of applications in natural language processing (NLP). This paper aims to present a comprehensive examination of the research landscape in LLMs, providing an overview of the prevailing themes and topics within this dynamic domain.Design/methodology/approachDrawing from an extensive corpus of 198 records published between 1996 to 2023 from the relevant academic database encompassing journal articles, books, book chapters, conference papers and selected working papers, this study delves deep into the multifaceted world of LLM research. In this study, the authors employed the BERTopic algorithm, a recent advancement in topic modeling, to conduct a comprehensive analysis of the data after it had been meticulously cleaned and preprocessed. BERTopic leverages the power of transformer-based language models like bidirectional encoder representations from transformers (BERT) to generate more meaningful and coherent topics. This approach facilitates the identification of hidden patterns within the data, enabling authors to uncover valuable insights that might otherwise have remained obscure. The analysis revealed four distinct clusters of topics in LLM research: “language and NLP”, “education and teaching”, “clinical and medical applications” and “speech and recognition techniques”. Each cluster embodies a unique aspect of LLM application and showcases the breadth of possibilities that LLM technology has to offer. In addition to presenting the research findings, this paper identifies key challenges and opportunities in the realm of LLMs. It underscores the necessity for further investigation in specific areas, including the paramount importance of addressing potential biases, transparency and explainability, data privacy and security, and responsible deployment of LLM technology.FindingsThe analysis revealed four distinct clusters of topics in LLM research: “language and NLP”, “education and teaching”, “clinical and medical applications” and “speech and recognition techniques”. Each cluster embodies a unique aspect of LLM application and showcases the breadth of possibilities that LLM technology has to offer. In addition to presenting the research findings, this paper identifies key challenges and opportunities in the realm of LLMs. It underscores the necessity for further investigation in specific areas, including the paramount importance of addressing potential biases, transparency and explainability, data privacy and security, and responsible deployment of LLM technology.Practical implicationsThis classification offers practical guidance for researchers, developers, educators, and policymakers to focus efforts and resources. The study underscores the importance of addressing challenges in LLMs, including potential biases, transparency, data privacy, and responsible deployment. Policymakers can utilize this information to shape regulations, while developers can tailor technology development based on the diverse applications identified. The findings also emphasize the need for interdisciplinary collaboration and highlight ethical considerations, providing a roadmap for navigating the complex landscape of LLM research and applications.Originality/valueThis study stands out as the first to examine the evolution of LLMs across such a long time frame and across such diversified disciplines. It provides a unique perspective on the key areas of LLM research, highlighting the breadth and depth of LLM’s evolution.",
        "link": "http://dx.doi.org/10.1108/jebde-08-2023-0015"
    },
    {
        "id": 12373,
        "title": "Potential to transform words to watts with large language models in battery research",
        "authors": "Shuo Zhao, Sihui Chen, Jiayi Zhou, Chao Li, Tan Tang, Stephen J. Harris, Yang Liu, Jiayu Wan, Xin Li",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.xcrp.2024.101844"
    },
    {
        "id": 12374,
        "title": "The TrollLabs Open hackathon dataset: Generative AI and large language models for prototyping in Engineering Design",
        "authors": "Daniel Nygård Ege, Henrik H. Øvrebø, Vegar Stubberud, Martin F. Berg, Christer Elverum, Martin Steinert, Håvard Vestad",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.dib.2024.110332"
    },
    {
        "id": 12375,
        "title": "LEVA: Using Large Language Models to Enhance Visual Analytics",
        "authors": "Yuheng Zhao, Yixing Zhang, Yu Zhang, Xinyi Zhao, Junjie Wang, Zekai Shao, Cagatay Turkay, Siming Chen",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tvcg.2024.3368060"
    },
    {
        "id": 12376,
        "title": "Reply to “Zero, Single, and Few-Shot Learning in Large Language Models to Identify Incidental Findings From Radiology Reports”",
        "authors": "Rajesh Bhayana, Gavin Elias, Daksh Datta, Nishaant Bhambra, Yangqing Deng, Satheesh Krishna",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2214/ajr.24.31060"
    },
    {
        "id": 12377,
        "title": "Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction",
        "authors": "Sungmin Kang, Juyeon Yoon, Shin Yoo",
        "published": "2023-5",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icse48619.2023.00194"
    },
    {
        "id": 12378,
        "title": "Large Language Models as Zero-Shot Conversational Recommenders",
        "authors": "Zhankui He, Zhouhang Xie, Rahul Jha, Harald Steck, Dawen Liang, Yesu Feng, Bodhisattwa Prasad Majumder, Nathan Kallus, Julian Mcauley",
        "published": "2023-10-21",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3583780.3614949"
    },
    {
        "id": 12379,
        "title": "Models of Language Evolution",
        "authors": "Cathleen O'Grady, Kenny Smith",
        "published": "No Date",
        "citations": 0,
        "abstract": "Models of Language Evolution reviews the models that provide evidence for the role of cultural evolution in the emergence of linguistic structure. This chapter discusses the levels of linguistic structure, and why the emergence of structure in language is a central question for evolutionary linguistics. It reviews the computational and experimental models which demonstrate that pressures operating during language learning and language use can give rise to the appearance of design in language, through the repeated cycle of learning and use that characterise language transmission. Finally, it discusses how learning biases at the individual level lead to the presence of typological universals: systematic patterns in how the world’s languages tend to be structured.",
        "link": "http://dx.doi.org/10.31219/osf.io/pfg8x"
    },
    {
        "id": 12380,
        "title": "Towards Large-scale Gaussian Process Models for Efficient Bayesian Machine Learning",
        "authors": "Fabian Berns, Christian Beecks",
        "published": "2020",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009874702750282"
    },
    {
        "id": 12381,
        "title": "Methods, Models and Techniques to Improve Information System’s Security in Large Organizations",
        "authors": "Vladislavs Minkevics, Janis Kampars",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009572406320639"
    },
    {
        "id": 12382,
        "title": "Index",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-017"
    },
    {
        "id": 12383,
        "title": "Contents",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-toc"
    },
    {
        "id": 12384,
        "title": "Language Models",
        "authors": "Djoerd Hiemstra",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4614-8265-9_923"
    },
    {
        "id": 12385,
        "title": "Developing a Multilingual Corpus of Wikipedia Biographies",
        "authors": "Hannah Devinney,  , Anton Eklund, Igor Ryazanov, Jingwen Cai,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_032"
    },
    {
        "id": 12386,
        "title": "Stance Prediction from Multimodal Social Media Data",
        "authors": "Laís C. L. Cavalheiro,  , Matheus C. Pavan, Ivandré Paraboni,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_027"
    },
    {
        "id": 12387,
        "title": "Prompt Engineering or Fine-Tuning? A Case Study on Phishing Detection with Large Language Models",
        "authors": "Fouad Trad, Ali Chehab",
        "published": "2024-2-6",
        "citations": 0,
        "abstract": "Large Language Models (LLMs) are reshaping the landscape of Machine Learning (ML) application development. The emergence of versatile LLMs capable of undertaking a wide array of tasks has reduced the necessity for intensive human involvement in training and maintaining ML models. Despite these advancements, a pivotal question emerges: can these generalized models negate the need for task-specific models? This study addresses this question by comparing the effectiveness of LLMs in detecting phishing URLs when utilized with prompt-engineering techniques versus when fine-tuned. Notably, we explore multiple prompt-engineering strategies for phishing URL detection and apply them to two chat models, GPT-3.5-turbo and Claude 2. In this context, the maximum result achieved was an F1-score of 92.74% by using a test set of 1000 samples. Following this, we fine-tune a range of base LLMs, including GPT-2, Bloom, Baby LLaMA, and DistilGPT-2—all primarily developed for text generation—exclusively for phishing URL detection. The fine-tuning approach culminated in a peak performance, achieving an F1-score of 97.29% and an AUC of 99.56% on the same test set, thereby outperforming existing state-of-the-art methods. These results highlight that while LLMs harnessed through prompt engineering can expedite application development processes, achieving a decent performance, they are not as effective as dedicated, task-specific LLMs.",
        "link": "http://dx.doi.org/10.3390/make6010018"
    },
    {
        "id": 12388,
        "title": "A Inteligência Artificial dos Large Language Models (LLMs) e os riscos aos Direitos Autorais: diretrizes aplicadas às plataformas e novos deveres éticos-jurídicos para sua utilização",
        "authors": "Cristiano Colombo, Guilherme Damasio Goulart",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.29327/5312711.1-5"
    },
    {
        "id": 12389,
        "title": "Sensitivity, specificity and avoidable workload of using a large language models for title and abstract screening in systematic reviews and meta-analyses",
        "authors": "Viet-Thi Tran, Gerald Gartlehner, Sally Yaacoub, Isabelle Boutron, Lukas Schwingshackl, Julia Stadelmaier, Isolde Sommer, Farzaneh Aboulayeh, Sivem Afach, Joerg Meerpohl, Philippe Ravaud",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractImportanceSystematic reviews are time-consuming and are still performed predominately manually by researchers despite the exponential growth of scientific literature.ObjectiveTo investigate the sensitivity, specificity and estimate the avoidable workload when using an AI-based large language model (LLM) (Generative Pre-trained Transformer [GPT] version 3.5-Turbo from OpenAI) to perform title and abstract screening in systematic reviews.Data SourcesUnannotated bibliographic databases from five systematic reviews conducted by researchers from Cochrane Austria, Germany and France, all published after January 2022 and hence not in the training data set from GPT 3.5-Turbo.DesignWe developed a set of prompts for GPT models aimed at mimicking the process of title and abstract screening by human researchers. We compared recommendations from LLM to rule out citations based on title and abstract with decisions from authors, with a systematic reappraisal of all discrepancies between LLM and their original decisions. We used bivariate models for meta-analyses of diagnostic accuracy to estimate pooled estimates of sensitivity and specificity. We performed a simulation to assess the avoidable workload from limiting human screening on title and abstract to citations which were not “ruled out” by the LLM in a random sample of 100 systematic reviews published between 01/07/2022 and 31/12/2022. We extrapolated estimates of avoidable workload for health-related systematic reviews assessing therapeutic interventions in humans published per year.ResultsPerformance of GPT models was tested across 22,666 citations. Pooled estimates of sensitivity and specificity were 97.1% (95%CI 89.6% to 99.2%) and 37.7%, (95%CI 18.4% to 61.9%), respectively. In 2022, we estimated the workload of title and abstract screening for systematic reviews to range from 211,013 to 422,025 person-hours. Limiting human screening to citations which were not “ruled out” by GPT models could reduce workload by 65% and save up from 106,268 to 276,053-person work hours (i.e.,66 to 172-person years of work), every year.Conclusions and RelevanceAI systems based on large language models provide highly sensitive and moderately specific recommendations to rule out citations during title and abstract screening in systematic reviews. Their use to “triage” citations before human assessment could reduce the workload of evidence synthesis.",
        "link": "http://dx.doi.org/10.1101/2023.12.15.23300018"
    },
    {
        "id": 12390,
        "title": "Response to Comment for “Understanding Radiological Journal Views and Policies on Large Language Models in Academic Writing”",
        "authors": "Hanzhou Li, John T. Moon, Hari M. Trivedi, Judy W. Gichoya",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jacr.2023.12.009"
    },
    {
        "id": 12391,
        "title": "Battle of the (Chat)Bots: Comparing Large Language Models to Practice Guidelines for Transfusion-Associated Graft-Versus-Host Disease Prevention",
        "authors": "Laura D. Stephens, Jeremy W. Jacobs, Brian D. Adkins, Garrett S. Booth",
        "published": "2023-7",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.tmrv.2023.150753"
    },
    {
        "id": 12392,
        "title": "Building a hospitable and reliable dialogue system for android robots: a scenario-based approach with large language models",
        "authors": "Takato Yamazaki, Katsumasa Yoshikawa, Toshiki Kawamoto, Tomoya Mizumoto, Masaya Ohagi, Toshinori Sato",
        "published": "2023-11-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/01691864.2023.2244554"
    },
    {
        "id": 12393,
        "title": "Pretrained language models",
        "authors": "Chenguang Zhu",
        "published": "2021",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-90118-5.00006-0"
    },
    {
        "id": 12394,
        "title": "Elicit: Language models as research tools",
        "authors": "Jungwon Byun, Andreas Stuhlmüller",
        "published": "2023-6-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1787/174aee8f-en"
    },
    {
        "id": 12395,
        "title": "Language Models in Sociological Research: An Application to Classifying Large Administrative Data and Measuring Religiosity",
        "authors": "Jeffrey L. Jensen, Daniel Karell, Cole Tanigawa-Lau, Nizar Habash, Mai Oudah, Dhia Fairus Shofia Fani",
        "published": "2022-2",
        "citations": 4,
        "abstract": " Computational methods have become widespread in the social sciences, but probabilistic language models remain relatively underused. We introduce language models to a general social science readership. First, we offer an accessible explanation of language models, detailing how they estimate the probability of a piece of language, such as a word or sentence, on the basis of the linguistic context. Second, we apply language models in an illustrative analysis to demonstrate the mechanics of using these models in social science research. The example application uses language models to classify names in a large administrative database; the classifications are then used to measure a sociologically important phenomenon: the spatial variation of religiosity. This application highlights several advantages of language models, including their effectiveness in classifying text that contains variation around the base structures, as is often the case with localized naming conventions and dialects. We conclude by discussing language models’ potential to contribute to sociological research beyond classification through their ability to generate language. ",
        "link": "http://dx.doi.org/10.1177/00811750211053370"
    },
    {
        "id": 12396,
        "title": "Publisher Correction: Fighting reviewer fatigue or amplifying bias? Considerations and recommendations for use of ChatGPT and other large language models in scholarly peer review",
        "authors": "Mohammad Hosseini, Serge P. J. M. Horbach",
        "published": "2023-7-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s41073-023-00136-2"
    },
    {
        "id": 12397,
        "title": "Experiencing Visual Captions: Augmented Communication with Real-time Visuals using Large Language Models",
        "authors": "Xingyu 'Bruce' Liu, Vladimir Kirilyuk, Xiuxiu Yuan, Peggy Chi, Alex Olwal, Xiang 'Anthony' Chen, Ruofei Du",
        "published": "2023-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3586182.3615978"
    },
    {
        "id": 12398,
        "title": "Use Large Language Models for Named Entity Disambiguation in Academic Knowledge Graphs",
        "authors": "Shaojun Liu, Yanfeng Fang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2991/978-94-6463-264-4_79"
    },
    {
        "id": 12399,
        "title": "Large Language Models As A Proxy For Human Evaluation In Assessing The Comprehensibility Of Disordered Speech Transcription",
        "authors": "Katrin Tomanek, Jimmy Tobin, Subhashini Venugopalan, Richard Cave, Katie Seaver, Jordan R. Green, Rus Heywood",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447177"
    },
    {
        "id": 12400,
        "title": "Can Large Language Models Generate Outpatient Clinic Letters at First Consultation That Incorporate Complication Profiles From UK and USA Aesthetic Plastic Surgery Associations?",
        "authors": "Richard H R Roberts, Stephen R Ali, Thomas D Dobbs, Iain S Whitaker",
        "published": "2024-1-4",
        "citations": 1,
        "abstract": "Abstract\n\n \nThe importance of written communication between clinicians and patients, especially in the wake of the Supreme Court case of Montgomery vs Lanarkshire, has led to a shift toward patient-centric care in the United Kingdom. This study investigates the use of large language models (LLMs) like ChatGPT and Google Bard in enhancing clinic letters with gold-standard complication profiles, aiming to improve patients’ understanding and save clinicians’ time in aesthetic plastic surgery. The aim of this study is to assess the effectiveness of LLMs in integrating complication profiles from authoritative sources into clinic letters, thus enhancing patient comprehension and clinician efficiency in aesthetic plastic surgery. Seven widely performed aesthetic procedures were chosen, and complication profiles were sourced from the British Association of Aesthetic Plastic Surgeons (BAAPS) and the American Society of Plastic Surgeons (ASPS). We evaluated the proficiency of the ChatGPT4, ChatGPT3.5, and Google Bard in generating clinic letters which incorporated complication profiles from online resources. These letters were assessed for readability using an online tool, targeting a recommended sixth-grade reading level. ChatGPT4 achieved the highest compliance in integrating complication profiles from BAAPS and ASPS websites, with average readability grades between eighth and ninth. ChatGPT3.5 and Google Bard showed lower compliance, particularly when accessing paywalled content like the ASPS Informed Consent Bundle. In conclusion, LLMs, particularly ChatGPT4, show promise in enhancing patient communications in aesthetic plastic surgery by effectively incorporating standard complication profiles into clinic letters. This aids in informed decision making and time saving for clinicians. However, the study underscores the need for improvements in data accessibility, search capabilities, and ethical considerations for optimal LLM integration into healthcare communications. Future enhancements should focus on better interpretation of inaccessible formats and a Human in the Loop approach to combine Artifical Intelligence capabilities with clinician expertise.\n\n\nLevel of Evidence: 3\n\n",
        "link": "http://dx.doi.org/10.1093/asjof/ojad109"
    },
    {
        "id": 12401,
        "title": "Use Large Language Models for Named Entity Disambiguation in Academic Knowledge Graphs",
        "authors": "Shaojun Liu, Yanfeng Fang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2991/978-94-6463-264-4_79"
    },
    {
        "id": 12402,
        "title": "ChatGPT effects on cognitive skills of undergraduate students: Receiving instant responses from AI-based conversational large language models (LLMs)",
        "authors": "Harry Barton Essel, Dimitrios Vlachopoulos, Albert Benjamin Essuman, John Opuni Amankwa",
        "published": "2024-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.caeai.2023.100198"
    },
    {
        "id": 12403,
        "title": "Publisher Correction: Fighting reviewer fatigue or amplifying bias? Considerations and recommendations for use of ChatGPT and other large language models in scholarly peer review",
        "authors": "Mohammad Hosseini, Serge P. J. M. Horbach",
        "published": "2023-7-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s41073-023-00136-2"
    },
    {
        "id": 12404,
        "title": "Developing conversational Virtual Humans for social emotion elicitation based on large language models",
        "authors": "Jose Llanes-Jurado, Lucía Gómez-Zaragozá, Maria Eleonora Minissi, Mariano Alcañiz, Javier Marín-Morales",
        "published": "2024-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.eswa.2024.123261"
    },
    {
        "id": 12405,
        "title": "Aide: A Conversational Agent Based on Inoculation Theory and Large Language Models to Empower Learners to Recognize Disinformation",
        "authors": "Renato Russo, Paulo Blikstein",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22318/icls2023.715792"
    },
    {
        "id": 12406,
        "title": "Alzheimer's disease recognition from spontaneous speech using large language models",
        "authors": "Jeong‐Uk Bang, Seung‐Hoon Han, Byung‐Ok Kang",
        "published": "2024-2",
        "citations": 0,
        "abstract": "AbstractWe propose a method to automatically predict Alzheimer's disease from speech data using the ChatGPT large language model. Alzheimer's disease patients often exhibit distinctive characteristics when describing images, such as difficulties in recalling words, grammar errors, repetitive language, and incoherent narratives. For prediction, we initially employ a speech recognition system to transcribe participants' speech into text. We then gather opinions by inputting the transcribed text into ChatGPT as well as a prompt designed to solicit fluency evaluations. Subsequently, we extract embeddings from the speech, text, and opinions by the pretrained models. Finally, we use a classifier consisting of transformer blocks and linear layers to identify participants with this type of dementia. Experiments are conducted using the extensively used ADReSSo dataset. The results yield a maximum accuracy of 87.3% when speech, text, and opinions are used in conjunction. This finding suggests the potential of leveraging evaluation feedback from language models to address challenges in Alzheimer's disease recognition.",
        "link": "http://dx.doi.org/10.4218/etrij.2023-0356"
    },
    {
        "id": 12407,
        "title": "Automated Fact-Checking of Climate Change Claims with Large Language Models",
        "authors": "Markus Leippold, Saeid Vaghefi, Veruska Muccione, Julia Bingler, Dominik Stammbach, Chiara Colesanti Senni, Jingwei Ni, Tobias Wekhof, Tingyu Yu, Tobias Schimanski, Glen Gostlow, Jürg Luterbacher, Christian Huggel",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4731802"
    },
    {
        "id": 12408,
        "title": "Can Large Language Models Generate Outpatient Clinic Letters at First Consultation That Incorporate Complication Profiles From UK and USA Aesthetic Plastic Surgery Associations?",
        "authors": "Richard H R Roberts, Stephen R Ali, Thomas D Dobbs, Iain S Whitaker",
        "published": "2024-1-4",
        "citations": 1,
        "abstract": "Abstract\n\n \nThe importance of written communication between clinicians and patients, especially in the wake of the Supreme Court case of Montgomery vs Lanarkshire, has led to a shift toward patient-centric care in the United Kingdom. This study investigates the use of large language models (LLMs) like ChatGPT and Google Bard in enhancing clinic letters with gold-standard complication profiles, aiming to improve patients’ understanding and save clinicians’ time in aesthetic plastic surgery. The aim of this study is to assess the effectiveness of LLMs in integrating complication profiles from authoritative sources into clinic letters, thus enhancing patient comprehension and clinician efficiency in aesthetic plastic surgery. Seven widely performed aesthetic procedures were chosen, and complication profiles were sourced from the British Association of Aesthetic Plastic Surgeons (BAAPS) and the American Society of Plastic Surgeons (ASPS). We evaluated the proficiency of the ChatGPT4, ChatGPT3.5, and Google Bard in generating clinic letters which incorporated complication profiles from online resources. These letters were assessed for readability using an online tool, targeting a recommended sixth-grade reading level. ChatGPT4 achieved the highest compliance in integrating complication profiles from BAAPS and ASPS websites, with average readability grades between eighth and ninth. ChatGPT3.5 and Google Bard showed lower compliance, particularly when accessing paywalled content like the ASPS Informed Consent Bundle. In conclusion, LLMs, particularly ChatGPT4, show promise in enhancing patient communications in aesthetic plastic surgery by effectively incorporating standard complication profiles into clinic letters. This aids in informed decision making and time saving for clinicians. However, the study underscores the need for improvements in data accessibility, search capabilities, and ethical considerations for optimal LLM integration into healthcare communications. Future enhancements should focus on better interpretation of inaccessible formats and a Human in the Loop approach to combine Artifical Intelligence capabilities with clinician expertise.\n\n\nLevel of Evidence: 3\n\n",
        "link": "http://dx.doi.org/10.1093/asjof/ojad109"
    },
    {
        "id": 12409,
        "title": "Large Language Models for Business Process Management: Opportunities and Challenges",
        "authors": "Maxim Vidgof, Stefan Bachhofner, Jan Mendling",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-41623-1_7"
    },
    {
        "id": 12410,
        "title": "Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models",
        "authors": "Yuyan Chen, Qiang Fu, Yichen Yuan, Zhihao Wen, Ge Fan, Dayiheng Liu, Dongmei Zhang, Zhixu Li, Yanghua Xiao",
        "published": "2023-10-21",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3583780.3614905"
    },
    {
        "id": 12411,
        "title": "Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study",
        "authors": "Perttu Hämäläinen, Mikke Tavast, Anton Kunnari",
        "published": "2023-4-19",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3544548.3580688"
    },
    {
        "id": 12412,
        "title": "Large Language Models As A Proxy For Human Evaluation In Assessing The Comprehensibility Of Disordered Speech Transcription",
        "authors": "Katrin Tomanek, Jimmy Tobin, Subhashini Venugopalan, Richard Cave, Katie Seaver, Jordan R. Green, Rus Heywood",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447177"
    },
    {
        "id": 12413,
        "title": "Structuring large models with MONO: Notations, templates, and case studies",
        "authors": "Harald Störrle",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-816649-9.00016-8"
    },
    {
        "id": 12414,
        "title": "Towards autonomous device protection using behavioral profiling and large language network",
        "authors": "Sandeep Gupta",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Demand for autonomous protection in computing devices can not go unnoticed with a cataclysmic rise in cyber-attacks. Consequently, cybersecurity measures with an improved generalization that can proactively determine the indicators of compromises to predict zero-day threats or previously unseen malware together with known malware are highly desirable. In this article, we present a novel concept of autonomous device protection based on behavioral profiling by continuously monitoring internal resource usage and exploiting a large language model to distinguish between benign and malicious behavior. We design and develop a proof-of-concept for Windows-based computing devices relying on a built-in event tracing mechanism for log collection that is converted into structured data using a graph data structure. We extract graph-level features, \\textit{i.e., graph depth, nodes count, number of leaf nodes, node degree statistics, and events count}, and node-level features, i.e., process start, file create and registry events details for each graph. Further, we exploit a pre-trained large language network - a simple contrastive sentence embedding framework to extract strong features, i.e., dense vectors, from event graphs. Finally, we train a random forest classifier using both the graph- and node-level features to obtain classification models that are evaluated on a collected dataset containing one thousand benign and malicious samples achieving accuracy up to 99.25%.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23732691"
    },
    {
        "id": 12415,
        "title": "Leveraging Large Language Models for Sensor Data Retrieval",
        "authors": "Alberto Berenguer, Adriana Morejón, David Tomás, Jose-Norberto Mazón",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "The growing significance of sensor data in the development of information technology services finds obstacles due to disparate data presentations and non-adherence to FAIR principles. This paper introduces a novel approach for sensor data gathering and retrieval. The proposal leverages large language models to convert sensor data into FAIR-compliant formats and to provide word embedding representations of tabular data for subsequent exploration, enabling semantic comparison. The proposed system comprises two primary components. The first focuses on gathering data from sensors and converting it into a reusable structured format, while the second component aims to identify the most relevant sensor data to augment a given user-provided dataset. The evaluation of the proposed approach involved comparing the performance of various large language models in generating representative word embeddings for each table to retrieve related sensor data. The results show promising performance in terms of precision and MRR (0.90 and 0.94 for the best-performing model, respectively), indicating the system’s ability to retrieve pertinent sensor data that fulfil user requirements.",
        "link": "http://dx.doi.org/10.3390/app14062506"
    },
    {
        "id": 12416,
        "title": "Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning",
        "authors": "Mustafa Ozdayi, Charith Peris, Jack FitzGerald, Christophe Dupuy, Jimit Majmudar, Haidar Khan, Rahil Parikh, Rahul Gupta",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-short.129"
    },
    {
        "id": 12417,
        "title": "Battle of the Large Language Models: Dolly vs LLaMA vs Vicuna vs Guanaco vs Bard vs ChatGPT - A Text-to-SQL Parsing Comparison",
        "authors": "Shuo Sun, Yuchen Zhang, Jiahuan Yan, Yuze Gao, Donovan Ong, Bin Chen, Jian Su",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.750"
    },
    {
        "id": 12418,
        "title": "Enhancing Sentiment Analysis with GPT—A Comparison of Large Language Models and Traditional Machine Learning Techniques",
        "authors": "Tobechi Obinwanne, Patrick Brandtner",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-7569-3_17"
    },
    {
        "id": 12419,
        "title": "MSR92 Can Artificial Intelligence (AI) Large Language Models (LLMS) Such as Generative Pre-Trained Transformer (GPT) Be Used to Automate Literature Reviews?",
        "authors": "I. Guerra, J. Gallinaro, K. Rtveladze, A. Lambova, E. Asenova",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jval.2023.09.2151"
    },
    {
        "id": 12420,
        "title": "Solving Proof Block Problems Using Large Language Models",
        "authors": "Seth Poulsen, Sami Sarsa, James Prather, Juho Leinonen, Brett A. Becker, Arto Hellas, Paul Denny, Brent N. Reeves",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3626252.3630928"
    },
    {
        "id": 12421,
        "title": "Research on grid inspection technology based on general knowledge enhanced multimodal large language models",
        "authors": "Peng Gao, zhuyi rao, shengpu gao, yun zheng, ying li",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2692326"
    },
    {
        "id": 12422,
        "title": "Optimizing Large Language Models on Multi-Core CPUs: A Case Study of the BERT Model",
        "authors": "Lanxin Zhao, Wanrong Gao, Jianbin Fang",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "The BERT model is regarded as the cornerstone of various pre-trained large language models that have achieved promising results in recent years. This article investigates how to optimize the BERT model in terms of fine-tuning speed and prediction accuracy, aiming to accelerate the execution of the BERT model on a multi-core processor and improve its prediction accuracy in typical downstream natural language processing tasks. Our contributions are two-fold. First, we port and parallelize the fine-tuning training of the BERT model on a multi-core shared-memory processor. We port the BERT model onto a multi-core processor platform to accelerate the fine-tuning training process of the model for downstream tasks. Second, we improve the prediction performance of typical downstream natural language processing tasks through fine-tuning the model parameters. We select five typical downstream natural language processing tasks (CoLA, SST-2, MRPC, RTE, and WNLI) and perform optimization on the multi-core platform, taking the hyperparameters of batch size, learning rate, and training epochs into account. Our experimental results show that, by increasing the number of CPUs and the number of threads, the model training time can be significantly reduced. We observe that the reduced time is primarily concentrated in the self-attention mechanism. Our further experimental results show that setting reasonable hyperparameters can improve the accuracy of the BERT model when applied to downstream tasks and that appropriately increasing the batch size under conditions of sufficient computing resources can significantly reduce training time.",
        "link": "http://dx.doi.org/10.3390/app14062364"
    },
    {
        "id": 12423,
        "title": "Sabiá: Portuguese Large Language Models",
        "authors": "Ramon Pires, Hugo Abonizio, Thales Sales Almeida, Rodrigo Nogueira",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-45392-2_15"
    },
    {
        "id": 12424,
        "title": "Corpus Synthesis for Zero-Shot ASR Domain Adaptation Using Large Language Models",
        "authors": "Hsuan Su, Ting-Yao Hu, Hema Swetha Koppula, Raviteja Vemulapalli, Jen-Hao Rick Chang, Karren Yang, Gautam Varma Mantena, Oncel Tuzel",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447240"
    },
    {
        "id": 12425,
        "title": "Assessing the research landscape and clinical utility of large language models: a scoping review",
        "authors": "Ye-Jean Park, Abhinav Pillai, Jiawen Deng, Eddie Guo, Mehul Gupta, Mike Paget, Christopher Naugler",
        "published": "2024-3-12",
        "citations": 0,
        "abstract": "Abstract\nImportance\nLarge language models (LLMs) like OpenAI’s ChatGPT are powerful generative systems that rapidly synthesize natural language responses. Research on LLMs has revealed their potential and pitfalls, especially in clinical settings. However, the evolving landscape of LLM research in medicine has left several gaps regarding their evaluation, application, and evidence base.\n\nObjective\nThis scoping review aims to (1) summarize current research evidence on the accuracy and efficacy of LLMs in medical applications, (2) discuss the ethical, legal, logistical, and socioeconomic implications of LLM use in clinical settings, (3) explore barriers and facilitators to LLM implementation in healthcare, (4) propose a standardized evaluation framework for assessing LLMs’ clinical utility, and (5) identify evidence gaps and propose future research directions for LLMs in clinical applications.\n\nEvidence review\nWe screened 4,036 records from MEDLINE, EMBASE, CINAHL, medRxiv, bioRxiv, and arXiv from January 2023 (inception of the search) to June 26, 2023 for English-language papers and analyzed findings from 55 worldwide studies. Quality of evidence was reported based on the Oxford Centre for Evidence-based Medicine recommendations.\n\nFindings\nOur results demonstrate that LLMs show promise in compiling patient notes, assisting patients in navigating the healthcare system, and to some extent, supporting clinical decision-making when combined with human oversight. However, their utilization is limited by biases in training data that may harm patients, the generation of inaccurate but convincing information, and ethical, legal, socioeconomic, and privacy concerns. We also identified a lack of standardized methods for evaluating LLMs’ effectiveness and feasibility.\n\nConclusions and relevance\nThis review thus highlights potential future directions and questions to address these limitations and to further explore LLMs’ potential in enhancing healthcare delivery.\n",
        "link": "http://dx.doi.org/10.1186/s12911-024-02459-6"
    },
    {
        "id": 12426,
        "title": "The Inadequacy of Reinforcement Learning from Human Feedback - Radicalizing Large Language Models via Semantic Vulnerabilities",
        "authors": "Timothy R. McIntosh, Teo Susnjak, Tong Liu, Paul Watters, Malka N. Halgamuge",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tcds.2024.3377445"
    },
    {
        "id": 12427,
        "title": "Natural Language Interface for Data Visualization with Deep Learning Based Language Models",
        "authors": "Andreas Stockl",
        "published": "2022-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iv56949.2022.00031"
    },
    {
        "id": 12428,
        "title": "Towards autonomous device protection using behavioral profiling and large language network",
        "authors": "Sandeep Gupta",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Demand for autonomous protection in computing devices can not go unnoticed with a cataclysmic rise in cyber-attacks. Consequently, cybersecurity measures with an improved generalization that can proactively determine the indicators of compromises to predict zero-day threats or previously unseen malware together with known malware are highly desirable. In this article, we present a novel concept of autonomous device protection based on behavioral profiling by continuously monitoring internal resource usage and exploiting a large language model to distinguish between benign and malicious behavior. We design and develop a proof-of-concept for Windows-based computing devices relying on a built-in event tracing mechanism for log collection that is converted into structured data using a graph data structure. We extract graph-level features, \\textit{i.e., graph depth, nodes count, number of leaf nodes, node degree statistics, and events count}, and node-level features, i.e., process start, file create and registry events details for each graph. Further, we exploit a pre-trained large language network - a simple contrastive sentence embedding framework to extract strong features, i.e., dense vectors, from event graphs. Finally, we train a random forest classifier using both the graph- and node-level features to obtain classification models that are evaluated on a collected dataset containing one thousand benign and malicious samples achieving accuracy up to 99.25%.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23732691.v1"
    },
    {
        "id": 12429,
        "title": "Privacy-Preserving Models for Legal Natural Language Processing",
        "authors": "Ying Yin, Ivan Habernal",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.nllp-1.14"
    },
    {
        "id": 12430,
        "title": "Neural Language Models in Natural Language Processing",
        "authors": "Zihao Chen",
        "published": "2023-10-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdacai59742.2023.00104"
    },
    {
        "id": 12431,
        "title": "Models of Mentoring in Language Teacher Education",
        "authors": "Hoa Thi Mai Nguyen",
        "published": "2017",
        "citations": 39,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-44151-1"
    },
    {
        "id": 12432,
        "title": "LEVERAGING LARGE LANGUAGE MODELS FOR SEDIMENTARY ENVIRONMENTAL INTERPRETATION: A NEW APPROACH TO ADDRESSING THE NON-UNIQUENESS PROBLEM IN PALEOGEOGRAPHY",
        "authors": "Haipeng Li,  , Luoqi Wang, Jie Yang, Yao Guo",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1130/abs/2023am-390624"
    },
    {
        "id": 12433,
        "title": "Galactic ChitChat: Using Large Language Models to Converse with Astronomy Literature",
        "authors": "Ioana Ciucă, Yuan-Sen Ting",
        "published": "2023-9-13",
        "citations": 1,
        "abstract": "Abstract\nWe demonstrate the potential of the state-of-the-art OpenAI GPT-4 large language model to engage in meaningful interactions with Astronomy papers using in-context prompting. To optimize for efficiency, we employ a distillation technique that effectively reduces the size of the original input paper by 50%, while maintaining the paragraph structure and overall semantic integrity. We then explore the model’s responses using a multi-document context (ten distilled documents). Our findings indicate that GPT-4 excels in the multi-document domain, providing detailed answers contextualized within the framework of related research findings. Our results showcase the potential of large language models for the astronomical community, offering a promising avenue for further exploration, particularly the possibility of utilizing the models for hypothesis generation.",
        "link": "http://dx.doi.org/10.3847/2515-5172/acf85f"
    },
    {
        "id": 12434,
        "title": "Fully Autonomous Programming with Large Language Models",
        "authors": "Vadim Liventsev, Anastasiia Grishina, Aki Härmä, Leon Moonen",
        "published": "2023-7-15",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3583131.3590481"
    },
    {
        "id": 12435,
        "title": "Exploring the Responses of Large Language Models to Beginner Programmers’ Help Requests",
        "authors": "Arto Hellas, Juho Leinonen, Sami Sarsa, Charles Koutcheme, Lilja Kujanpää, Juha Sorva",
        "published": "2023-8-7",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3568813.3600139"
    },
    {
        "id": 12436,
        "title": "Utility and Comparative Performance of Current Artificial Intelligence Large Language Models as Postoperative Medical Support Chatbots in Aesthetic Surgery",
        "authors": "Jad Abi-Rafeh, Nader Henry, Hong Hao Xu, Brian Bassiri-Tehrani, Adel Arezki, Roy Kazan, Mirko S Gilardino, Foad Nahai",
        "published": "2024-2-6",
        "citations": 0,
        "abstract": "Abstract\n\nBackground\nLarge language models (LLMs) have revolutionized the way plastic surgeons and their patients can access and leverage artificial intelligence (AI).\n\n\nObjectives\nThe present study aims to compare the performance of 2 current publicly available and patient-accessible LLMs in the potential application of AI as postoperative medical support chatbots in an aesthetic surgeon's practice.\n\n\nMethods\nTwenty-two simulated postoperative patient presentations following aesthetic breast plastic surgery were devised and expert-validated. Complications varied in their latency within the postoperative period, as well as urgency of required medical attention. In response to each patient-reported presentation, Open AI's ChatGPT and Google's Bard, in their unmodified and freely available versions, were objectively assessed for their comparative accuracy in generating an appropriate differential diagnosis, most-likely diagnosis, suggested medical disposition, treatments or interventions to begin from home, and/or red flag signs/symptoms indicating deterioration.\n\n\nResults\nChatGPT cumulatively and significantly outperformed Bard across all objective assessment metrics examined (66% vs 55%, respectively; P &lt; .05). Accuracy in generating an appropriate differential diagnosis was 61% for ChatGPT vs 57% for Bard (P = .45). ChatGPT asked an average of 9.2 questions on history vs Bard’s 6.8 questions (P &lt; .001), with accuracies of 91% vs 68% reporting the most-likely diagnosis, respectively (P &lt; .01). Appropriate medical dispositions were suggested with accuracies of 50% by ChatGPT vs 41% by Bard (P = .40); appropriate home interventions/treatments with accuracies of 59% vs 55% (P = .94), and red flag signs/symptoms with accuracies of 79% vs 54% (P &lt; .01), respectively. Detailed and comparative performance breakdowns according to complication latency and urgency are presented.\n\n\nConclusions\nChatGPT represents the superior LLM for the potential application of AI technology in postoperative medical support chatbots. Imperfect performance and limitations discussed may guide the necessary refinement to facilitate adoption.\n",
        "link": "http://dx.doi.org/10.1093/asj/sjae025"
    },
    {
        "id": 12437,
        "title": "Qualitative Research Methods for Large Language Models: Conducting Semi-Structured Interviews with ChatGPT and BARD on Computer Science Education",
        "authors": "Andreas Dengel, Rupert Gehrlein, David Fernes, Sebastian Görlich, Jonas Maurer, Hai Hoang Pham, Gabriel Großmann, Niklas Dietrich genannt Eisermann",
        "published": "2023-10-12",
        "citations": 1,
        "abstract": "In the current era of artificial intelligence, large language models such as ChatGPT and BARD are being increasingly used for various applications, such as language translation, text generation, and human-like conversation. The fact that these models consist of large amounts of data, including many different opinions and perspectives, could introduce the possibility of a new qualitative research approach: Due to the probabilistic character of their answers, “interviewing” these large language models could give insights into public opinions in a way that otherwise only interviews with large groups of subjects could deliver. However, it is not yet clear if qualitative content analysis research methods can be applied to interviews with these models. Evaluating the applicability of qualitative research methods to interviews with large language models could foster our understanding of their abilities and limitations. In this paper, we examine the applicability of qualitative content analysis research methods to interviews with ChatGPT in English, ChatGPT in German, and BARD in English on the relevance of computer science in K-12 education, which was used as an exemplary topic. We found that the answers produced by these models strongly depended on the provided context, and the same model could produce heavily differing results for the same questions. From these results and the insights throughout the process, we formulated guidelines for conducting and analyzing interviews with large language models. Our findings suggest that qualitative content analysis research methods can indeed be applied to interviews with large language models, but with careful consideration of contextual factors that may affect the responses produced by these models. The guidelines we provide can aid researchers and practitioners in conducting more nuanced and insightful interviews with large language models. From an overall view of our results, we generally do not recommend using interviews with large language models for research purposes, due to their highly unpredictable results. However, we suggest using these models as exploration tools for gaining different perspectives on research topics and for testing interview guidelines before conducting real-world interviews.",
        "link": "http://dx.doi.org/10.3390/informatics10040078"
    },
    {
        "id": 12438,
        "title": "A Study on Semantic Understanding of Large Language Models from the Perspective of Ambiguity Resolution",
        "authors": "Shuguang Yang, Feipeng Chen, Yiming Yang, Zude Zhu",
        "published": "2023-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3632971.3632973"
    },
    {
        "id": 12439,
        "title": "Large Language Models and Artificial Intelligence: A Primer for Plastic Surgeons on the Demonstrated and Potential Applications, Promises, and Limitations of ChatGPT",
        "authors": "Jad Abi-Rafeh, Hong Hao Xu, Roy Kazan, Ruth Tevlin, Heather Furnas",
        "published": "2024-2-15",
        "citations": 4,
        "abstract": "Abstract\n\nBackground\nThe rapidly evolving field of artificial intelligence (AI) holds great potential for plastic surgeons. ChatGPT, a recently released AI large language model (LLM), promises applications across many disciplines, including healthcare.\n\n\nObjectives\nThe aim of this article was to provide a primer for plastic surgeons on AI, LLM, and ChatGPT, including an analysis of current demonstrated and proposed clinical applications.\n\n\nMethods\nA systematic review was performed identifying medical and surgical literature on ChatGPT's proposed clinical applications. Variables assessed included applications investigated, command tasks provided, user input information, AI-emulated human skills, output validation, and reported limitations.\n\n\nResults\nThe analysis included 175 articles reporting on 13 plastic surgery applications and 116 additional clinical applications, categorized by field and purpose. Thirty-four applications within plastic surgery are thus proposed, with relevance to different target audiences, including attending plastic surgeons (n = 17, 50%), trainees/educators (n = 8, 24.0%), researchers/scholars (n = 7, 21%), and patients (n = 2, 6%). The 15 identified limitations of ChatGPT were categorized by training data, algorithm, and ethical considerations.\n\n\nConclusions\nWidespread use of ChatGPT in plastic surgery will depend on rigorous research of proposed applications to validate performance and address limitations. This systemic review aims to guide research, development, and regulation to safely adopt AI in plastic surgery.\n",
        "link": "http://dx.doi.org/10.1093/asj/sjad260"
    },
    {
        "id": 12440,
        "title": "Use and Application of Large Language Models for Patient Questions following Total Knee Arthroplasty",
        "authors": "Sandeep S. Bains, Jeremy A. Dubin, Daniel Hameed, Oliver C. Sax, Scott Douglas, Michael Mont, James Nace, Ronald E. Delanois",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.arth.2024.03.017"
    },
    {
        "id": 12441,
        "title": "20.5 C-Transformer: A 2.6-18.1μJ/Token Homogeneous DNN-Transformer/Spiking-Transformer Processor with Big-Little Network and Implicit Weight Generation for Large Language Models",
        "authors": "Sangyeob Kim, Sangjin Kim, Wooyoung Jo, Soyeon Kim, Seongyon Hong, Hoi-Jun Yoo",
        "published": "2024-2-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isscc49657.2024.10454330"
    },
    {
        "id": 12442,
        "title": "Large language models could change the future of behavioral healthcare:  A proposal for responsible development and evaluation",
        "authors": "Elizabeth Cameron Stade, Shannon Wiltsey Stirman, Lyle H Ungar, Cody L. Boland, H. Andrew Schwartz, David Bryce Yaden, João Sedoc, Robert DeRubeis, Robb Willer, johannes Christopher Eichstaedt",
        "published": "No Date",
        "citations": 5,
        "abstract": "Large language models (LLMs) such as Open AI’s GPT-3 and -4 (which power ChatGPT) and Google’s PaLM, built on artificial intelligence, hold immense potential to support, augment, or even eventually fully automate psychotherapy. Enthusiasm about such applications is mounting in the field as well as industry. These developments promise to address insufficient mental healthcare system capacity and scale individual access to personalized treatments. However, clinical psychology is an uncommonly high stakes application domain for AI systems, as responsible and evidence-based therapy requires nuanced expertise. This paper provides a roadmap for the ambitious yet responsible application of clinical LLMs in psychotherapy. First, a technical overview of clinical LLMs is presented. Second, the stages of integration of LLMs into psychotherapy are discussed while highlighting parallels to the development of autonomous vehicle technology. Third, potential applications of LLMs in clinical care, training, and research are discussed, highlighting areas of risk given the complex nature of psychotherapy. Fourth, recommendations for the responsible development and evaluation of clinical LLMs are provided, which include centering clinical science, involving robust interdisciplinary collaboration, and attending to issues like assessment, risk detection, transparency, and bias. Lastly, a vision is outlined for how LLMs might enable a new generation of studies of evidence-based interventions at scale, and how these studies may challenge assumptions about psychotherapy.",
        "link": "http://dx.doi.org/10.31234/osf.io/cuzvr"
    },
    {
        "id": 12443,
        "title": "AI Chatbots’ Medical Hallucination: Innovation of References Hallucination Score and Comparison of Six Large Language Models (Preprint)",
        "authors": "Fadi Aljamaan, Mohamad-Hani Temsah, Ibraheem Tamimi, Ayman Al-Al-Eyadhy, Amr Jamal, Khalid Alhasan, Tamer A. Mesallam, Mohamed Farahat, Khalid H. Malki",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nArtificial intelligence (AI) chatbots have gained use recently in medical practice by healthcare practitioners. Interestingly, their output was found to have varying degrees of hallucination in content and references. Such hallucinations generate doubts about their output and their implementation.\n\n\nOBJECTIVE\nWe propose a reference hallucination score (RHS) to evaluate AI chatbots’ citation authenticity.\n\n\nMETHODS\nSix AI chatbots were challenged with the same ten medical prompts, requesting ten references per prompt. The Reference Hallucination Score (RHS) is composed of six bibliographic items and the reference’s relevance to prompts’ keywords. RHS was calculated for each reference, prompt, and type of prompt (basic versus complex). The average RHS was calculated for each AI chatbot and compared across the different types of prompts and AI chatbots.\n\n\nRESULTS\nBard failed to generate any references. ChatGPT 3.5 and Bing generated the highest RHS (11), while Elicit and SciSpace generated the lowest RHS, and Perplexity was in the middle. The highest degree of hallucination was observed for reference relevancy to the prompt keywords (61.6%), while the lowest was reference titles (33.8%). AI chatbots generally had significantly higher RHS when prompted with scenarios or complex format prompts.\n\n\nCONCLUSIONS\nThe variation in RHS underscores the necessity for a robust reference evaluation tool to improve the authenticity of AI chatbots. Also, it highlights the importance of verifying their output and citations. Elicit and SciSpace had negligible hallucination, while ChatGPT and Bing had critical levels. The proposed AI chatbots’ RHS could contribute to ongoing efforts to enhance AI’s general reliability in medical research.\n",
        "link": "http://dx.doi.org/10.2196/preprints.54345"
    },
    {
        "id": 12444,
        "title": "Generative Artificial Intelligence: Opportunities and Challenges of Large Language Models",
        "authors": "Fabian Barreto, Lalita Moharkar, Madhura Shirodkar, Vidya Sarode, Saniya Gonsalves, Aaron Johns",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-3177-4_41"
    },
    {
        "id": 12445,
        "title": "Investigating the Impact of Prompt Engineering on the Performance of Large Language Models for Standardizing Obstetric Diagnosis Text: Comparative Study",
        "authors": "Lei Wang, Wenshuai Bi, Suling Zhao, Yinyao Ma, Longting Lv, Chenwei Meng, Jingru Fu, Hanlin Lv",
        "published": "2024-2-8",
        "citations": 0,
        "abstract": "\nBackground\nThe accumulation of vast electronic medical records (EMRs) through medical informatization creates significant research value, particularly in obstetrics. Diagnostic standardization across different health care institutions and regions is vital for medical data analysis. Large language models (LLMs) have been extensively used for various medical tasks. Prompt engineering is key to use LLMs effectively.\n\n\nObjective\nThis study aims to evaluate and compare the performance of LLMs with various prompt engineering techniques on the task of standardizing obstetric diagnostic terminology using real-world obstetric data.\n\n\nMethods\nThe paper describes a 4-step approach used for mapping diagnoses in electronic medical records to the International Classification of Diseases, 10th revision, observation domain. First, similarity measures were used for mapping the diagnoses. Second, candidate mapping terms were collected based on similarity scores above a threshold, to be used as the training data set. For generating optimal mapping terms, we used two LLMs (ChatGLM2 and Qwen-14B-Chat [QWEN]) for zero-shot learning in step 3. Finally, a performance comparison was conducted by using 3 pretrained bidirectional encoder representations from transformers (BERTs), including BERT, whole word masking BERT, and momentum contrastive learning with BERT (MC-BERT), for unsupervised optimal mapping term generation in the fourth step.\n\n\nResults\nLLMs and BERT demonstrated comparable performance at their respective optimal levels. LLMs showed clear advantages in terms of performance and efficiency in unsupervised settings. Interestingly, the performance of the LLMs varied significantly across different prompt engineering setups. For instance, when applying the self-consistency approach in QWEN, the F1-score improved by 5%, with precision increasing by 7.9%, outperforming the zero-shot method. Likewise, ChatGLM2 delivered similar rates of accurately generated responses. During the analysis, the BERT series served as a comparative model with comparable results. Among the 3 models, MC-BERT demonstrated the highest level of performance. However, the differences among the versions of BERT in this study were relatively insignificant.\n\n\nConclusions\nAfter applying LLMs to standardize diagnoses and designing 4 different prompts, we compared the results to those generated by the BERT model. Our findings indicate that QWEN prompts largely outperformed the other prompts, with precision comparable to that of the BERT model. These results demonstrate the potential of unsupervised approaches in improving the efficiency of aligning diagnostic terms in daily research and uncovering hidden information values in patient data.\n",
        "link": "http://dx.doi.org/10.2196/53216"
    },
    {
        "id": 12446,
        "title": "Large Language Models for Epidemiological Research via Automated Machine Learning: Case Study Using Data From the British National Child Development Study",
        "authors": "Rasmus Wibaek, Gregers Stig Andersen, Christina C Dahm, Daniel R Witte, Adam Hulman",
        "published": "2023-9-19",
        "citations": 0,
        "abstract": "Abstract\n\nBackground\nLarge language models have had a huge impact on natural language processing (NLP) in recent years. However, their application in epidemiological research is still limited to the analysis of electronic health records and social media data.\n\n\nObjectives\nTo demonstrate the potential of NLP beyond these domains, we aimed to develop prediction models based on texts collected from an epidemiological cohort and compare their performance to classical regression methods.\n\n\nMethods\nWe used data from the British National Child Development Study, where 10,567 children aged 11 years wrote essays about how they imagined themselves as 25-year-olds. Overall, 15% of the data set was set aside as a test set for performance evaluation. Pretrained language models were fine-tuned using AutoTrain (Hugging Face) to predict current reading comprehension score (range: 0-35) and future BMI and physical activity (active vs inactive) at the age of 33 years. We then compared their predictive performance (accuracy or discrimination) with linear and logistic regression models, including demographic and lifestyle factors of the parents and children from birth to the age of 11 years as predictors.\n\n\nResults\nNLP clearly outperformed linear regression when predicting reading comprehension scores (root mean square error: 3.89, 95% CI 3.74-4.05 for NLP vs 4.14, 95% CI 3.98-4.30 and 5.41, 95% CI 5.23-5.58 for regression models with and without general ability score as a predictor, respectively). Predictive performance for physical activity was similarly poor for the 2 methods (area under the receiver operating characteristic curve: 0.55, 95% CI 0.52-0.60 for both) but was slightly better than random assignment, whereas linear regression clearly outperformed the NLP approach when predicting BMI (root mean square error: 4.38, 95% CI 4.02-4.74 for NLP vs 3.85, 95% CI 3.54-4.16 for regression). The NLP approach did not perform better than simply assigning the mean BMI from the training set as a predictor.\n\n\nConclusions\nOur study demonstrated the potential of using large language models on text collected from epidemiological studies. The performance of the approach appeared to depend on how directly the topic of the text was related to the outcome. Open-ended questions specifically designed to capture certain health concepts and lived experiences in combination with NLP methods should receive more attention in future epidemiological studies.\n",
        "link": "http://dx.doi.org/10.2196/43638"
    },
    {
        "id": 12447,
        "title": "Large Language Models and Healthcare Alliance: Potential and Challenges of Two Representative Use Cases",
        "authors": "Silvia García-Méndez, Francisco de Arriba-Pérez",
        "published": "2024-2-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10439-024-03454-8"
    },
    {
        "id": 12448,
        "title": "AlphaTuning: Quantization-Aware Parameter-Efficient Adaptation of Large-Scale Pre-Trained Language Models",
        "authors": "Se Jung Kwon, Jeonghoon Kim, Jeongin Bae, Kang Min Yoo, Jin-Hwa Kim, Baeseong Park, Byeongwook Kim, Jung-Woo Ha, Nako Sung, Dongsoo Lee",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-emnlp.240"
    },
    {
        "id": 12449,
        "title": "Prompting Large Language Models with Speech Recognition Abilities",
        "authors": "Yassir Fathullah, Chunyang Wu, Egor Lakomkin, Junteng Jia, Yuan Shangguan, Ke Li, Jinxi Guo, Wenhan Xiong, Jay Mahadeokar, Ozlem Kalinli, Christian Fuegen, Mike Seltzer",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447605"
    },
    {
        "id": 12450,
        "title": "Comparing the Efficacy of Large Language Models ChatGPT, BARD, and Bing AI in Providing Information on Rhinoplasty: An Observational Study",
        "authors": "Ishith Seth, Bryan Lim, Yi Xie, Jevan Cevik, Warren M Rozen, Richard J Ross, Mathew Lee",
        "published": "2023-1-11",
        "citations": 11,
        "abstract": "Abstract\n\nBackground\nLarge language models (LLMs) are emerging artificial intelligence (AI) technologies refining research and healthcare. However, the impact of these models on presurgical planning and education remains under-explored.\n\n\nObjectives\nThis study aims to assess 3 prominent LLMs—Google's AI BARD (Mountain View, CA), Bing AI (Microsoft, Redmond, WA), and ChatGPT-3.5 (Open AI, San Francisco, CA) in providing safe medical information for rhinoplasty.\n\n\nMethods\nSix questions regarding rhinoplasty were prompted to ChatGPT, BARD, and Bing AI. A Likert scale was used to evaluate these responses by a panel of Specialist Plastic and Reconstructive Surgeons with extensive experience in rhinoplasty. To measure reliability, the Flesch Reading Ease Score, the Flesch–Kincaid Grade Level, and the Coleman–Liau Index were used. The modified DISCERN score was chosen as the criterion for assessing suitability and reliability. A t test was performed to calculate the difference between the LLMs, and a double-sided P-value &lt;.05 was considered statistically significant.\n\n\nResults\nIn terms of reliability, BARD and ChatGPT demonstrated a significantly (P &lt; .05) greater Flesch Reading Ease Score of 47.47 (±15.32) and 37.68 (±12.96), Flesch–Kincaid Grade Level of 9.7 (±3.12) and 10.15 (±1.84), and a Coleman–Liau Index of 10.83 (±2.14) and 12.17 (±1.17) than Bing AI. In terms of suitability, BARD (46.3 ± 2.8) demonstrated a significantly greater DISCERN score than ChatGPT and Bing AI. In terms of Likert score, ChatGPT and BARD demonstrated similar scores and were greater than Bing AI.\n\n\nConclusions\nBARD delivered the most succinct and comprehensible information, followed by ChatGPT and Bing AI. Although these models demonstrate potential, challenges regarding their depth and specificity remain. Therefore, future research should aim to augment LLM performance through the integration of specialized databases and expert knowledge, while also refining their algorithms.\n\n\nLevel of Evidence: 5\n\n",
        "link": "http://dx.doi.org/10.1093/asjof/ojad084"
    },
    {
        "id": 12451,
        "title": "Dialect Integration in the Arabic Foreign Language Curriculum:",
        "authors": "MAHMOUD AL-BATAL",
        "published": "2017-12-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fj85jd.5"
    },
    {
        "id": 12452,
        "title": "Using plausible values when fitting multilevel models with large-scale assessment data using R",
        "authors": "Francis L. Huang",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": "AbstractThe use of large-scale assessments (LSAs) in education has grown in the past decade though analysis of LSAs using multilevel models (MLMs) using R has been limited. A reason for its limited use may be due to the complexity of incorporating both plausible values and weighted analyses in the multilevel analyses of LSA data. We provide additional functions in R that extend the functionality of the WeMix (Bailey et al., 2023) package to allow for the automatic pooling of plausible values. In addition, functions for model comparisons using plausible values and the ability to export output to different formats (e.g., Word, html) are also provided.",
        "link": "http://dx.doi.org/10.1186/s40536-024-00192-0"
    },
    {
        "id": 12453,
        "title": "Understanding Word Embeddings and Language Models",
        "authors": "Jose Manuel Gomez-Perez, Ronald Denaux, Andres Garcia-Silva",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-44830-1_3"
    },
    {
        "id": 12454,
        "title": "Models of Implicit Language Processing",
        "authors": "Harris Winitz",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-52998-7_4"
    },
    {
        "id": 12455,
        "title": "Language-Generating Automata and State-Controlled Computation",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_11"
    },
    {
        "id": 12456,
        "title": "Generative Models of Regular Languages",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_0008"
    },
    {
        "id": 12457,
        "title": "Progress in Understanding and Parameterizing Fast Physics in Large‐Scale Atmospheric Models",
        "authors": "Yangang Liu, Pavlos Kollias",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119529019.ch1"
    },
    {
        "id": 12458,
        "title": "Large-Scale Models of the OB",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-0716-1006-0_300319"
    },
    {
        "id": 12459,
        "title": "Simulating Large-Scale Structure for Models of Cosmic Acceleration",
        "authors": "Baojiu Li",
        "published": "2018-10-1",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1088/978-0-7503-1587-6"
    },
    {
        "id": 12460,
        "title": "Neural candidate-aware language models for speech recognition",
        "authors": "Tomohiro Tanaka, Ryo Masumura, Takanobu Oba",
        "published": "2021-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2020.101157"
    },
    {
        "id": 12461,
        "title": "Large Queueing Systems",
        "authors": "Zhe George Zhang",
        "published": "2023-5-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003150060-8"
    },
    {
        "id": 12462,
        "title": "Gradient damage models in large deformation",
        "authors": "B. Crabbé, J.-J. Marigo, E. Chamberland, J. Guilié",
        "published": "2017-8-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315223278-53"
    },
    {
        "id": 12463,
        "title": "Critical Analysis of the Models of Language Proficiency with a Focus on Communicative Models",
        "authors": "Seyyed Mohammad Reza Amirian, Hamid Hashemi Moqaddam, Qotboddin Jannesar M.",
        "published": "2017-5-1",
        "citations": 1,
        "abstract": "Production of a clear-cut and comprehensive framework for the sake of evaluation purposes has been one of the most challenging issues in the realm of language assessment. Over the past decades, notable effort has been made to put forward models to practically define and theoretically specify the construct of language proficiency. To accomplish this, theorists have drawn on different epistemological sources such as empirical research, narrative accounts as well as introspective and retrospective analysis of language related data. The objective of this review is to conduct a critical analysis of the validity and practicality of these models and also to indicate the contributions as well as the drawbacks of these models from different standpoints. The analysis has been done in conformity with the widely accepted paradigms of socio-cultural and communicative orientations toward language within the field of language assessment.",
        "link": "http://dx.doi.org/10.17507/tpls.0705.11"
    },
    {
        "id": 12464,
        "title": "Language evolution is not limited to speech acquisition: a large study of language development in children with autism highlights the importance of the voluntary imagination component of language",
        "authors": "Andrey Vyshedskiy",
        "published": "No Date",
        "citations": 0,
        "abstract": "Prefrontal synthesis (PFS) is the component of voluntary imagination defined as the ability to juxtapose mental visuospatial objects at will. We hypothesized that PFS has fundamental importance for language acquisition. To test this hypothesis, we designed a PFS-targeting intervention and administered it to 6,454 children with language deficiencies (age 2 to 12 years). The results from the three-year-long study demonstrated that children who engaged with the PFS intervention showed 2.2-fold improvement in combinatorial language comprehension compared to children with similar initial evaluations 1. These findings suggest that language can be improved by training the PFS and exposes the importance of the visuospatial component of language. This manuscript reflects on the experimental findings from the point of view of human language evolution. When used as a proxy for evolutionary language acquisition, the study results suggest a dichotomy of language evolution with its speech component and its visuospatial component developing in parallel. The study highlights the radical idea that evolutionary acquisition of language was limited primarily by the speed of the development of the voluntary imagination rather than by improvements in the speech apparatus.",
        "link": "http://dx.doi.org/10.31234/osf.io/79qd2"
    },
    {
        "id": 12465,
        "title": "Review for \"The use of a large language model to create plain language summaries of evidence reviews in healthcare: A feasibility study\"",
        "authors": " Helen Bulbeck",
        "published": "2023-11-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/cesm.12041/v1/review2"
    },
    {
        "id": 12466,
        "title": "Review for \"The use of a large language model to create plain language summaries of evidence reviews in healthcare: A feasibility study\"",
        "authors": "Liliya Ziganshina",
        "published": "2023-11-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/cesm.12041/v1/review1"
    },
    {
        "id": 12467,
        "title": "Models In a Spelling Bee: Language Models Implicitly Learn the Character Composition of Tokens",
        "authors": "Itay Itzhak, Omer Levy",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.373"
    },
    {
        "id": 12468,
        "title": "An Assessment of the Impact of OCR Noise on Language Models",
        "authors": "Konstantin Todorov, Giovanni Colavizza",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010945100003116"
    },
    {
        "id": 12469,
        "title": "Creating a large language model of a philosopher",
        "authors": "Eric Schwitzgebel, David Schwitzgebel, Anna Strasser",
        "published": "2023-7-12",
        "citations": 6,
        "abstract": "Can large language models produce expert‐quality philosophical texts? To investigate this, we fine‐tuned GPT‐3 with the works of philosopher Daniel Dennett. To evaluate the model, we asked the real Dennett 10 philosophical questions and then posed the same questions to the language model, collecting four responses for each question without cherry‐picking. Experts on Dennett's work succeeded at distinguishing the Dennett‐generated and machine‐generated answers above chance but substantially short of our expectations. Philosophy blog readers performed similarly to the experts, while ordinary research participants were near chance distinguishing GPT‐3's responses from those of an “actual human philosopher”.",
        "link": "http://dx.doi.org/10.1111/mila.12466"
    },
    {
        "id": 12470,
        "title": "Language comprehension models at different levels of explanation",
        "authors": "Michelle Colvin, Tessa Warren",
        "published": "2020-1",
        "citations": 3,
        "abstract": "AbstractThis paper reviews two recent models of language comprehension, the RI‐Val model (Cook & O'Brien, 2014; O'Brien & Cook, 2016b) and the dynamic generative framework (Kuperberg, 2016). Both of these models have been heavily informed by research on the processing of semantic anomalies, but they have arisen in different literatures. The RI‐Val model has roots in the text processing literature and focuses primarily on bottom–up aspects of comprehension; the dynamic generative framework has roots in the event‐related brain potential (ERP)/sentence processing literature and focuses more heavily on top–down aspects of comprehension. Relating these models to each other and considering the findings in the semantic anomaly literature that support each one pushes us to consider the possibility that these models might be describing the comprehension system at different levels of explanation (Marr, 1982). This view has a few important consequences. First, it provides new ways of thinking about, and consequently increases the importance of, the small literature about anomaly detection in fictional contexts. It also opens the door for beginning to speculate about potential mappings between these two models of language comprehension. Our hope is that by bringing together and highlighting potential connections between models from different traditions, we will provoke bigger picture points of view that raise new questions and spur new ideas for research.",
        "link": "http://dx.doi.org/10.1111/lnc3.12362"
    },
    {
        "id": 12471,
        "title": "Evaluation of Medium-Sized Language Models in German and English Language",
        "authors": "René Peinl, Johannes Wirth",
        "published": "2024-2-28",
        "citations": 0,
        "abstract": "Large language models (LLMs) have garnered significant attention, but the definition of “large” lacks clarity. This paper focuses on medium-sized language models (MLMs), defined as having at least six billion parameters but less than 100 billion. The study evaluates MLMs regarding zero-shot generative question answering, which requires models to provide elaborate answers without external document retrieval. The paper introduces an own test dataset and presents results from human evaluation. Results show that combining the best answers from different MLMs yielded an overall correct answer rate of 82.7% which is better than the 60.9% of ChatGPT. The best MLM achieved 71.8% and has 33B parameters, which highlights the importance of using appropriate training data for fine-tuning rather than solely relying on the number of parameters. More fine-grained feedback should be used to further improve the quality of answers. The open source community is quickly closing the gap to the best commercial models.",
        "link": "http://dx.doi.org/10.5121/ijnlc.2024.13101"
    },
    {
        "id": 12472,
        "title": "Language Models: Deep Dive into BERT",
        "authors": " ",
        "published": "No Date",
        "citations": 0,
        "abstract": "<strong> Unlocking the power of language models: A deep dive into&nbsp;BERT </strong> <strong> Author: </strong> <strong> Dhruv Gupta (ORCID: </strong> <strong> 0009–0004–7109–5403 </strong> <strong> ) </strong> Clive Humby, in 2006 rightly said, “Data is the new oil”. With data being present everywhere, it has never been more valuable.",
        "link": "http://dx.doi.org/10.59350/tfm92-t8y93"
    },
    {
        "id": 12473,
        "title": "III. Metaphor",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-004"
    },
    {
        "id": 12474,
        "title": "Chinese Stylistic Competence: Evaluation Method and Datasets of Large Language Model's Performance",
        "authors": "Liwei Zhou, Gaoqi Rao",
        "published": "2023-11-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ialp61005.2023.10337306"
    },
    {
        "id": 12475,
        "title": "VII. Possibility",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-008"
    },
    {
        "id": 12476,
        "title": "Low-resouce Taxonomy Enrichment with Pretrained Language Models",
        "authors": "Kunihiro Takeoka",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.29.259"
    },
    {
        "id": 12477,
        "title": "Improved Language Models for ASR using Written Language Text",
        "authors": "Kaustuv Mukherji, Meghna Pandharipande, Sunil Kumar Kopparapu",
        "published": "2022-5-24",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ncc55593.2022.9806803"
    },
    {
        "id": 12478,
        "title": "2. The Native Speaker and Target Models in Second Language Acquisition",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781788927048-005"
    },
    {
        "id": 12479,
        "title": "IS DESCRIBING LANGUAGE MERE BUTTERFLY COLLECTION? ON EPISTEMOLOGY, STATISTICAL LANGUAGE MODELS, AND CORPUS",
        "authors": "Milena Uzeda-Garrão",
        "published": "2019-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21125/iceri.2019.2673"
    },
    {
        "id": 12480,
        "title": "Language Awareness in Education",
        "authors": "Walt Wolfram",
        "published": "2019-1-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678-12"
    },
    {
        "id": 12481,
        "title": "Interpreting Language Models with Contrastive Explanations",
        "authors": "Kayo Yin, Graham Neubig",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.14"
    },
    {
        "id": 12482,
        "title": "Targeted Syntactic Evaluation of Language Models",
        "authors": "Rebecca Marvin, Tal Linzen",
        "published": "2018",
        "citations": 35,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d18-1151"
    },
    {
        "id": 12483,
        "title": "Effect of Visual Extensions on Natural Language Understanding in Vision-and-Language Models",
        "authors": "Taichi Iki, Akiko Aizawa",
        "published": "2021",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.167"
    },
    {
        "id": 12484,
        "title": "Language, Texts , and Reality",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.8"
    },
    {
        "id": 12485,
        "title": "Long-Tail Predictions with Continuous-Output Language Models",
        "authors": "Shiran Dudy, Steven Bedrick",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.winlp-1.31"
    },
    {
        "id": 12486,
        "title": "Collateral facilitation in humans and language models",
        "authors": "James Michaelov, Benjamin Bergen",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.conll-1.2"
    },
    {
        "id": 12487,
        "title": "Learning English as a Foreign Language: A Review of Theoretical Models and the Impact of Role Models in Language Learning",
        "authors": "Arberore Bicaj, Arif Shala",
        "published": "2018-10-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22521/edupij.2018.74.5"
    },
    {
        "id": 12488,
        "title": "Modern Language Models and Computation",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4"
    },
    {
        "id": 12489,
        "title": "A Cohesive Distillation Architecture for Neural Language Models",
        "authors": "Jan Philip Wahle",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22541/au.167528147.79728645/v1"
    },
    {
        "id": 12490,
        "title": "R2D2 at SemEval-2022 Task 6: Are language models sarcastic enough? Finetuning pre-trained language models to identify sarcasm",
        "authors": "Mayukh Sharma, Ilanthenral Kandasamy, Vasantha W B",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.semeval-1.143"
    },
    {
        "id": 12491,
        "title": "Scaling Hidden Markov Language Models",
        "authors": "Justin Chiu, Alexander Rush",
        "published": "2020",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.103"
    },
    {
        "id": 12492,
        "title": "Tracking Child Language Development With Neural Network Language Models",
        "authors": "Kenji Sagae",
        "published": "2021-7-8",
        "citations": 2,
        "abstract": "Recent work on the application of neural networks to language modeling has shown that models based on certain neural architectures can capture syntactic information from utterances and sentences even when not given an explicitly syntactic objective. We examine whether a fully data-driven model of language development that uses a recurrent neural network encoder for utterances can track how child language utterances change over the course of language development in a way that is comparable to what is achieved using established language assessment metrics that use language-specific information carefully designed by experts. Given only transcripts of child language utterances from the CHILDES Database and no pre-specified information about language, our model captures not just the structural characteristics of child language utterances, but how these structures reflect language development over time. We establish an evaluation methodology with which we can examine how well our model tracks language development compared to three known approaches: Mean Length of Utterance, the Developmental Sentence Score, and the Index of Productive Syntax. We discuss the applicability of our model to data-driven assessment of child language development, including how a fully data-driven approach supports the possibility of increased research in multilingual and cross-lingual issues.",
        "link": "http://dx.doi.org/10.3389/fpsyg.2021.674402"
    },
    {
        "id": 12493,
        "title": "Language, Cognition, and Computational Models",
        "authors": "",
        "published": "2017-11-30",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781316676974"
    },
    {
        "id": 12494,
        "title": "Cultural Models of Language Variation",
        "authors": "",
        "published": "2018-12-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1163/9789004336841_007"
    },
    {
        "id": 12495,
        "title": "Structure-Infused Protein Language Models",
        "authors": "Daniel Peñaherrera, David Ryan Koes",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractEmbeddings from protein language models (PLM’s) capture intricate patterns for protein sequences, enabling more accurate and efficient prediction of protein properties. Incorporating protein structure information as direct input into PLMs results in an improvement on the predictive ability of protein embeddings on downstream tasks. In this work we demonstrate that indirectly infusing structure information into PLMs also leads to performance gains on structure related tasks. The key difference between this framework and others is that atinference timethe model does not require access to structure to produce its embeddings.",
        "link": "http://dx.doi.org/10.1101/2023.12.13.571525"
    },
    {
        "id": 12496,
        "title": "Generating Datasets with Pretrained Language Models",
        "authors": "Timo Schick, Hinrich Schütze",
        "published": "2021",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.555"
    },
    {
        "id": 12497,
        "title": "Language Models are Few-Shot Butlers",
        "authors": "Vincent Micheli, Francois Fleuret",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.734"
    },
    {
        "id": 12498,
        "title": "Engineering A Large Language Model From Scratch",
        "authors": "Abiodun Finbarrs Oketunji",
        "published": "No Date",
        "citations": 0,
        "abstract": "The proliferation of deep learning in natural language processing (NLP) has led to the development and release of innovative technologies capable of understanding and generating human language with remarkable proficiency. Atinuke, a Transformer-based neural network, optimises performance across various language tasks by utilising a unique configuration. The architecture interweaves layers for processing sequential data with attention mechanisms to draw meaningful affinities between inputs and outputs. Due to the configuration of its topology and hyperparameter tuning, it can emulate human-like language by extracting features and learning complex mappings. Atinuke is modular, extensible, and integrates seamlessly with existing machine learning pipelines. Advanced matrix operations like softmax, embeddings, and multi-head attention enable nuanced handling of textual, acoustic, and visual signals. By unifying modern deep learning techniques with software design principles and mathematical theory, the system achieves state-of-the-art results on natural language tasks whilst remaining interpretable and robust.",
        "link": "http://dx.doi.org/10.20944/preprints202401.2120.v1"
    },
    {
        "id": 12499,
        "title": "Large Generative AI Models vs Smaller Parameter Models with More Data: A Comprehensive Literature Review",
        "authors": "Archer Woodford",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4453658"
    },
    {
        "id": 12500,
        "title": "Large-scale distributed semantic augmented reality services – A performance evaluation",
        "authors": "Dariusz Rumiński, Krzysztof Walczak",
        "published": "2020-1",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.gmod.2019.101027"
    },
    {
        "id": 12501,
        "title": "Large-scale distributed semantic augmented reality services – A performance evaluation",
        "authors": "Dariusz Rumiński, Krzysztof Walczak",
        "published": "2020-1",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.gmod.2019.101027"
    },
    {
        "id": 12502,
        "title": "How Do Large Language Models Perform on Social Cognition Tasks Compared to Humans? A SOCRATIS Based Evaluation of Social Intelligence of GPT-4 and PaLM 2 Based AI Chatbots",
        "authors": "Manul Das, Avinash Vipin, Justin  P. C. Raj, Urvakhsh  Meherwan Mehta, Nishant Goyal, Neelabja Roy, Subham Samantaray",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4689399"
    },
    {
        "id": 12503,
        "title": "Could ChatGPT Imagine: Content Control for Artistic Painting Generation Via Large Language Models",
        "authors": "Yue Lu, Chao Guo, Yong Dou, Xingyuan Dai, Fei-Yue Wang",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10846-023-01956-6"
    },
    {
        "id": 12504,
        "title": "On the Challenges of Using Large Language Models for NCL Code Generation",
        "authors": "Daniel de Sousa Moraes, Polyana Bezerra da Costa, Antonio J. G. Busson, José Matheus Carvalho Boaro, Carlos de Salles Soares Neto, Sergio Colcher",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "A significant concern raised in the domain of authoring tools for interactive Digital TV (iDTV) has been their usability when considering the target audience, which typically consists of content creators and not necessarily programmers. NCL (Nested Context Language), the declarative language for developing interactive applications for Brazilian Digital TV and an ITU-T Recommendation for IPTV services, is a simple declarative language but not an easy tool for non-technical authors. The proliferation of Large Language Models (LLMs) has recently instigated substantial transformations across several domains, including synthesizing code with remarkable potential. This paper proposes an investigation into the challenges of using LLMs to aid automatic NCL code generation/synthesis in authoring tools for iDTV content production. It shows initial evidence that current pre-trained LLMs cannot synthesize NCL code with satisfactory quality. In this context, we raise the main challenges for NCL code generation using LLMs and some issues related to the good practices for engineering prompts and integrating pre-trained LLMs into multimedia authoring tools.",
        "link": "http://dx.doi.org/10.5753/webmedia_estendido.2023.236175"
    },
    {
        "id": 12505,
        "title": "Large Language Models in Education: Vision and Opportunities",
        "authors": "Wensheng Gan, Zhenlian Qi, Jiayang Wu, Jerry Chun-Wei Lin",
        "published": "2023-12-15",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386291"
    },
    {
        "id": 12506,
        "title": "Contribution Analysis of Large Language Models and Data Augmentations for Person Names in Solving Legal Bar Examination at COLIEE 2023",
        "authors": "Takaaki Onaga, Masaki Fujita, Yoshinobu Kano",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "AbstractThis paper describes our system for COLIEE 2023 Task 4, which automatically answers Japanese legal bar exam problems. We propose an extension to our previous system in COLIEE 2022, which achieved the highest accuracy among all submissions using data augmentation. We focus on problems that include mentions of person names. In this paper, we present two main contributions. First, we incorporate LUKE as our deep learning component, which is a named entity recognition model trained on RoBERTa. Second, we fine-tune the pretrained LUKE model in multiple ways, comparing fine-tuning on training datasets that include alphabetical person names and ensembling different fine-tuning models. We confirmed that LUKE and its fine-tuned model on person type problems improve their accuracies. Our formal run results show that LUKE and our fine-tuning approach using alphabetical person names were effective, achieving an accuracy of 0.69 in the COLIEE 2023 Task 4 formal run.",
        "link": "http://dx.doi.org/10.1007/s12626-024-00155-5"
    },
    {
        "id": 12507,
        "title": "Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses",
        "authors": "Jaromir Savelka, Arav Agarwal, Marshall An, Chris Bogart, Majd Sakr",
        "published": "2023-8-7",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3568813.3600142"
    },
    {
        "id": 12508,
        "title": "Hint-Enhanced In-Context Learning Wakes Large Language Models Up For Knowledge-Intensive Tasks",
        "authors": "Yifan Wang, Qingyan Guo, Xinzhe Ni, Chufan Shi, Lemao Liu, Haiyun Jiang, Yujiu Yang",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447527"
    },
    {
        "id": 12509,
        "title": "FinGPT: Large Generative Models for a Small Language",
        "authors": "Risto Luukkonen, Ville Komulainen, Jouni Luoma, Anni Eskelinen, Jenna Kanerva, Hanna-Mari Kupari, Filip Ginter, Veronika Laippala, Niklas Muennighoff, Aleksandra Piktus, Thomas Wang, Nouamane Tazi, Teven Scao, Thomas Wolf, Osma Suominen, Samuli Sairanen, Mikko Merioksa, Jyrki Heinonen, Aija Vahtola, Samuel Antao, Sampo Pyysalo",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.164"
    },
    {
        "id": 12510,
        "title": "What Can Large Language Models Do for Theorem Proving and Formal Methods?",
        "authors": "Moa Johansson",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-46002-9_25"
    },
    {
        "id": 12511,
        "title": "AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment Enabled by Large Language Models",
        "authors": "Rui Zhang, Yixin Su, Bayu Distiawan Trisedya, Xiaoyan Zhao, Min Yang, Hong Cheng, Jianzhong Qi",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tkde.2023.3325484"
    },
    {
        "id": 12512,
        "title": "Forum: Incorporating the Use of Generative Artificial Intelligence and Large Language Models into Publication Standards: A Call for Editorial Policy Based on Social Work Values",
        "authors": "Dawn Apgar",
        "published": "2023-10-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.55521/10-020-210"
    },
    {
        "id": 12513,
        "title": "Comparative efficacy of ChatGPT 3.5, ChatGPT 4, and other large language models in gynecology and infertility research",
        "authors": "Pallav Sengupta, Sulagna Dutta, Srikumar Chakravarthi, Ravindran Jegasothy, Ravichandran Jeganathan, Anuradha Pichumani",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.gocm.2023.09.002"
    },
    {
        "id": 12514,
        "title": "Evaluating the progression of artificial intelligence and large language models in medicine through comparative analysis of ChatGPT-3.5 and ChatGPT-4 in generating vascular surgery recommendations",
        "authors": "Arshia P. Javidan, Tiam Feridooni, Lauren Gordon, Sean A. Crawford",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jvsvi.2023.100049"
    },
    {
        "id": 12515,
        "title": "Unleashing the <scp>AI</scp> revolution: exploring the capabilities and challenges of large language models and text‐to‐image <scp>AI</scp> programs",
        "authors": "A. Youssef",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/uog.26297"
    },
    {
        "id": 12516,
        "title": "Can Large Language Models Revolutionalize Open Government Data Portals? A Case of Using ChatGPT in statistics.gov.scot",
        "authors": "Marios Evangelos Mamalis, Evangelos Kalampokis, Areti Karamanou, Petros Brimos, Konstantinos Tarabanis",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3635059.3635068"
    },
    {
        "id": 12517,
        "title": "Exploring the new frontier of information extraction through large language models in urban analytics",
        "authors": "Andrew Crooks, Qingqing Chen",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1177/23998083241235495"
    },
    {
        "id": 12518,
        "title": "Evaluating large language models on a highly-specialized topic, radiation oncology physics",
        "authors": "Jason Holmes, Zhengliang Liu, Lian Zhang, Yuzhen Ding, Terence T. Sio, Lisa A. McGee, Jonathan B. Ashman, Xiang Li, Tianming Liu, Jiajian Shen, Wei Liu",
        "published": "2023-7-17",
        "citations": 22,
        "abstract": "PurposeWe present the first study to investigate Large Language Models (LLMs) in answering radiation oncology physics questions. Because popular exams like AP Physics, LSAT, and GRE have large test-taker populations and ample test preparation resources in circulation, they may not allow for accurately assessing the true potential of LLMs. This paper proposes evaluating LLMs on a highly-specialized topic, radiation oncology physics, which may be more pertinent to scientific and medical communities in addition to being a valuable benchmark of LLMs.MethodsWe developed an exam consisting of 100 radiation oncology physics questions based on our expertise. Four LLMs, ChatGPT (GPT-3.5), ChatGPT (GPT-4), Bard (LaMDA), and BLOOMZ, were evaluated against medical physicists and non-experts. The performance of ChatGPT (GPT-4) was further explored by being asked to explain first, then answer. The deductive reasoning capability of ChatGPT (GPT-4) was evaluated using a novel approach (substituting the correct answer with “None of the above choices is the correct answer.”). A majority vote analysis was used to approximate how well each group could score when working together.ResultsChatGPT GPT-4 outperformed all other LLMs and medical physicists, on average, with improved accuracy when prompted to explain before answering. ChatGPT (GPT-3.5 and GPT-4) showed a high level of consistency in its answer choices across a number of trials, whether correct or incorrect, a characteristic that was not observed in the human test groups or Bard (LaMDA). In evaluating deductive reasoning ability, ChatGPT (GPT-4) demonstrated surprising accuracy, suggesting the potential presence of an emergent ability. Finally, although ChatGPT (GPT-4) performed well overall, its intrinsic properties did not allow for further improvement when scoring based on a majority vote across trials. In contrast, a team of medical physicists were able to greatly outperform ChatGPT (GPT-4) using a majority vote.ConclusionThis study suggests a great potential for LLMs to work alongside radiation oncology experts as highly knowledgeable assistants.",
        "link": "http://dx.doi.org/10.3389/fonc.2023.1219326"
    },
    {
        "id": 12519,
        "title": "Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting",
        "authors": "Hai Dang, Sven Goller, Florian Lehmann, Daniel Buschek",
        "published": "2023-4-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3544548.3580969"
    },
    {
        "id": 12520,
        "title": "Explainability for Large Language Models: A Survey",
        "authors": "Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Mengnan Du",
        "published": "2024-4-30",
        "citations": 5,
        "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications. Therefore, understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts. In this article, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional deep learning models.",
        "link": "http://dx.doi.org/10.1145/3639372"
    },
    {
        "id": 12521,
        "title": "Implications of large language models such as <scp>ChatGPT</scp> for dental medicine",
        "authors": "Florin Eggmann, Roland Weiger, Nicola U. Zitzmann, Markus B. Blatz",
        "published": "2023-10",
        "citations": 59,
        "abstract": "AbstractObjectiveThis article provides an overview of the implications of ChatGPT and other large language models (LLMs) for dental medicine.OverviewChatGPT, a LLM trained on massive amounts of textual data, is adept at fulfilling various language‐related tasks. Despite its impressive capabilities, ChatGPT has serious limitations, such as occasionally giving incorrect answers, producing nonsensical content, and presenting misinformation as fact. Dental practitioners, assistants, and hygienists are not likely to be significantly impacted by LLMs. However, LLMs could affect the work of administrative personnel and the provision of dental telemedicine. LLMs offer potential for clinical decision support, text summarization, efficient writing, and multilingual communication. As more people seek health information from LLMs, it is crucial to safeguard against inaccurate, outdated, and biased responses to health‐related queries. LLMs pose challenges for patient data confidentiality and cybersecurity that must be tackled. In dental education, LLMs present fewer challenges than in other academic fields. LLMs can enhance academic writing fluency, but acceptable usage boundaries in science need to be established.ConclusionsWhile LLMs such as ChatGPT may have various useful applications in dental medicine, they come with risks of malicious use and serious limitations, including the potential for misinformation.Clinical SignificanceAlong with the potential benefits of using LLMs as an additional tool in dental medicine, it is crucial to carefully consider the limitations and potential risks inherent in such artificial intelligence technologies.",
        "link": "http://dx.doi.org/10.1111/jerd.13046"
    },
    {
        "id": 12522,
        "title": "A Static Evaluation of Code Completion by Large Language Models",
        "authors": "Hantian Ding, Varun Kumar, Yuchen Tian, Zijian Wang, Rob Kwiatkowski, Xiaopeng Li, Murali Krishna Ramanathan, Baishakhi Ray, Parminder Bhatia, Sudipta Sengupta",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-industry.34"
    },
    {
        "id": 12523,
        "title": "Poster: Rethinking Embedded Sensor Data Processing and Analysis with Large Language Models",
        "authors": "Pramuka Medaranga Sooriya Patabandige, Steven Antya Orvala Waskito, Kunjun Li, Kai Jie Leow, Shantanu Chakrabarty, Ambuj Varshney",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3581791.3597366"
    },
    {
        "id": 12524,
        "title": "ChatGPT and the rise of large language models: the new AI-driven infodemic threat in public health",
        "authors": "Luigi De Angelis, Francesco Baglivo, Guglielmo Arzilli, Gaetano Pierpaolo Privitera, Paolo Ferragina, Alberto Eugenio Tozzi, Caterina Rizzo",
        "published": "2023-4-25",
        "citations": 106,
        "abstract": "Large Language Models (LLMs) have recently gathered attention with the release of ChatGPT, a user-centered chatbot released by OpenAI. In this perspective article, we retrace the evolution of LLMs to understand the revolution brought by ChatGPT in the artificial intelligence (AI) field.The opportunities offered by LLMs in supporting scientific research are multiple and various models have already been tested in Natural Language Processing (NLP) tasks in this domain.The impact of ChatGPT has been huge for the general public and the research community, with many authors using the chatbot to write part of their articles and some papers even listing ChatGPT as an author. Alarming ethical and practical challenges emerge from the use of LLMs, particularly in the medical field for the potential impact on public health. Infodemic is a trending topic in public health and the ability of LLMs to rapidly produce vast amounts of text could leverage misinformation spread at an unprecedented scale, this could create an “AI-driven infodemic,” a novel public health threat. Policies to contrast this phenomenon need to be rapidly elaborated, the inability to accurately detect artificial-intelligence-produced text is an unresolved issue.",
        "link": "http://dx.doi.org/10.3389/fpubh.2023.1166120"
    },
    {
        "id": 12525,
        "title": "International Models of Language Policy and Language Planning:",
        "authors": "Maeve Conrick",
        "published": "2018-12-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv941x3t.11"
    },
    {
        "id": 12526,
        "title": "AliEdalat at SemEval-2022 Task 4: Patronizing and Condescending Language Detection using Fine-tuned Language Models, BERT+BiGRU, and Ensemble Models",
        "authors": "Ali Edalat, Yadollah Yaghoobzadeh, Behnam Bahrak",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.semeval-1.51"
    },
    {
        "id": 12527,
        "title": "Mixed effects models for large-sized clustered extremes",
        "authors": "Koki Momoki, Takuma Yoshida",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nExtreme value theory (EVT) provides an elegant mathematical tool for statistical analysis of rare events. Typically, when data are collected from multiple clusters, analysts want to preserve cluster information, such as region, period, and group. To consider large-sized cluster information in extreme value analysis, we incorporate the mixed effects model (MEM) into the regression technique in EVT. In the field of small area estimation, it is well known that the MEM is an important tool for providing reliable estimates of large-sized clusters with small sample sizes. In the context of EVT for rare event analysis, the sample size of extreme value data for each cluster is often small. Therefore, the MEM may contribute to improving the predictive accuracy of extreme value analysis. This motivates us to verify the effectiveness of the MEM in EVT through theoretical studies and numerical experiments, including its application to the risk assessment of heavy rainfall in Japan.\nMSC Classification: 62F12 , 62H11 , 62J05",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3041645/v1"
    },
    {
        "id": 12528,
        "title": "7 Subgrid models",
        "authors": "",
        "published": "2022-11-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110532364-007"
    },
    {
        "id": 12529,
        "title": "Fixed effect estimation of large T panel data models",
        "authors": "Martin Weidner, Ivan Fernandez-Val",
        "published": "2017-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1920/wp.cem.2017.4217"
    },
    {
        "id": 12530,
        "title": "Implementation of calving processes in large-scale ice sheet models",
        "authors": "G. Hilmar Gudmundsson",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Concepts and ideas related to implementation of calving in large-scale ice-sheet models are presented and discussed, and new model verification experiments proposed. For unconfined ice shelves, any calving law where the calving rate increases with cliff height (free board) must lead to an unstable advance or retreat. No other solutions are possible and all calving front positions are always unstable. If in contrast, calving rate is a monotonically decreasing function of cliff height, both stable and unstable positions are possible. An example of such a configuration and simple analytical solution for the transient evolution of the calving front is provided, which can be used for numerical verification purposes. It is argued that cliff-height based calving laws are, at least for the case of buttressed ice shelves, arguably unphysical as they can result in a multi-valued function for the calving rate as a function of local state of stress. Implementation of a new variational form of the level-set method, involving forward-and-backward diffusion, for capturing the evolution of calving fronts is discussed and several applications to Pine Island and Thwaites glacier shown.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu22-4263"
    },
    {
        "id": 12531,
        "title": "Large-Scale Models of the Visual System",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-0716-1006-0_300320"
    },
    {
        "id": 12532,
        "title": "Uncertainty Quantification of Text Classification in a Multi-Label Setting for Risk-Sensitive Systems",
        "authors": "Jinha Hwang,  , Carol Gudumotu, Benyamin Ahmadnia,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_059"
    },
    {
        "id": 12533,
        "title": "Ten simple rules to leverage large language models for getting grants",
        "authors": "Elizabeth Seckel, Brandi Y. Stephens, Fatima Rodriguez",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1371/journal.pcbi.1011863"
    },
    {
        "id": 12534,
        "title": "Exploring the Capabilities and Limitations of Large Language Models for Radiation Oncology Decision Support",
        "authors": "Florian Putz, Marlen Haderlein, Sebastian Lettmaier, Sabine Semrau, Rainer Fietkau, Yixing Huang",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ijrobp.2023.11.062"
    },
    {
        "id": 12535,
        "title": "A Post-Processing Framework for Crowd Worker Responses Using Large Language Models",
        "authors": "Ryuya Itano, Tatsuki Tamano, Takahiro Koita, Honoka Tanitsu",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.54808/wmsci2023.01.15"
    },
    {
        "id": 12536,
        "title": "Re: Raghav Gupta, Adriana M. Pedraza, Michael A. Gorin, Ashutosh K. Tewari. Defining the Role of Large Language Models in Urologic Care and Research. Eur Urol Oncol. In press. https://doi.org/10.1016/j.euo.2023.07.017",
        "authors": "Amnuay Kleebayoon, Viroj Wiwanitkit",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.euo.2023.09.022"
    },
    {
        "id": 12537,
        "title": "Improving Zero-Shot Text Matching for Financial Auditing with Large Language Models",
        "authors": "Lars Hillebrand, Armin Berger, Tobias Deußer, Tim Dilmaghani, Mohamed Khaled, Bernd Kliem, Rüdiger Loitz, Maren Pielka, David Leonhard, Christian Bauckhage, Rafet Sifa",
        "published": "2023-8-22",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3573128.3609344"
    },
    {
        "id": 12538,
        "title": "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models",
        "authors": "Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, Ee-Peng Lim",
        "published": "2023",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.147"
    },
    {
        "id": 12539,
        "title": "Event Knowledge in Large Language Models: The Gap Between the Impossible and the Unlikely",
        "authors": "Carina Kauf, Anna A. Ivanova, Giulia Rambelli, Emmanuele Chersoni, Jingyuan Selena She, Zawad Chowdhury, Evelina Fedorenko, Alessandro Lenci",
        "published": "2023-11",
        "citations": 4,
        "abstract": "AbstractWord co‐occurrence patterns in language corpora contain a surprising amount of conceptual knowledge. Large language models (LLMs), trained to predict words in context, leverage these patterns to achieve impressive performance on diverse semantic tasks requiring world knowledge. An important but understudied question about LLMs’ semantic abilities is whether they acquire generalized knowledge of common events. Here, we test whether five pretrained LLMs (from 2018's BERT to 2023's MPT) assign a higher likelihood to plausible descriptions of agent−patient interactions than to minimally different implausible versions of the same event. Using three curated sets of minimal sentence pairs (total n = 1215), we found that pretrained LLMs possess substantial event knowledge, outperforming other distributional language models. In particular, they almost always assign a higher likelihood to possible versus impossible events (The teacher bought the laptop vs. The laptop bought the teacher). However, LLMs show less consistent preferences for likely versus unlikely events (The nanny tutored the boy vs. The boy tutored the nanny). In follow‐up analyses, we show that (i) LLM scores are driven by both plausibility and surface‐level sentence features, (ii) LLM scores generalize well across syntactic variants (active vs. passive constructions) but less well across semantic variants (synonymous sentences), (iii) some LLM errors mirror human judgment ambiguity, and (iv) sentence plausibility serves as an organizing dimension in internal LLM representations. Overall, our results show that important aspects of event knowledge naturally emerge from distributional linguistic patterns, but also highlight a gap between representations of possible/impossible and likely/unlikely events.",
        "link": "http://dx.doi.org/10.1111/cogs.13386"
    },
    {
        "id": 12540,
        "title": "Large language models: The new AI-powered kidney stone experts? Comparative study of chat GPT 3.5, chat GPT 4, Bard, and Bing AI",
        "authors": "R. Kalbit, C.D. Vergara, E.I. Lorenzo, R. Agudera, U. Quanico, A. Aquino, M.C. Mendoza",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s0302-2838(24)00764-4"
    },
    {
        "id": 12541,
        "title": "DriveLLM: Charting the Path Toward Full Autonomous Driving With Large Language Models",
        "authors": "Yaodong Cui, Shucheng Huang, Jiaming Zhong, Zhenan Liu, Yutong Wang, Chen Sun, Bai Li, Xiao Wang, Amir Khajepour",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tiv.2023.3327715"
    },
    {
        "id": 12542,
        "title": "Theory of Mind Abilities of Large Language Models in Human-Robot Interaction: An Illusion?",
        "authors": "Mudit Verma, Siddhant Bhambri, Subbarao Kambhampati",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3610978.3640767"
    },
    {
        "id": 12543,
        "title": "Large-Scale Simulation",
        "authors": "Dan Chen, Lizhe Wang, Jingying Chen",
        "published": "2017-12-19",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b11883"
    },
    {
        "id": 12544,
        "title": "Next word prediction for Urdu language using deep learning models",
        "authors": "Ramish Shahid, Aamir Wali, Maryam Bashir",
        "published": "2024-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2024.101635"
    },
    {
        "id": 12545,
        "title": "Fixed effect estimation of large T panel data models",
        "authors": "Ivan Fernandez-Val, Martin Weidner",
        "published": "2018-3-28",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1920/wp.cem.2018.2218"
    },
    {
        "id": 12546,
        "title": "Permafrost and large slope instabilities &amp;#8211; observations, models and implications",
        "authors": "Bernd Etzelmuller",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Large unstable rock slopes (LURS) are common in formerly and present glaciated mountain environments. Many of these instabilities started moving or failed shortly after deglaciation due to debutressing. However, many LURS failed long after deglaciation or showed varying creep velocities during Holocene. This has been partly attributed to warming and thawing of permafrost, which might influence rock slope stability. This presentation reviews recent studies on the relation of permafrost distribution and rock slope stability in Norwegian mountains, summarizing new observations, models and interpretations, in cooperation with the Norwegian Geological Survey (NGU), The Norwegian Water and Energy Directorate (NVE), University College of Western Norway, Technical University in Munich (Germany), University of Troms&amp;#248; and EDTYM (France).&amp;#160;&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/icg2022-190"
    },
    {
        "id": 12547,
        "title": "Cognitive Computational Neuroscience of Language: Using Computational Models to Investigate Language Processing in the Brain",
        "authors": "Alessandro Lopopolo, Evelina Fedorenko, Roger Levy, Milena Rabovsky",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1162/nol_e_00131"
    },
    {
        "id": 12548,
        "title": "Case-Based Adaptation of Argument Graphs with WordNet and Large Language Models",
        "authors": "Mirko Lenz, Ralph Bergmann",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-40177-0_17"
    },
    {
        "id": 12549,
        "title": "Exploring Bias(es) of Large Language Models in the Field of Mental Health – A Comparative Study Investigating the Effect of Gender and Sexual Orientation in Anorexia Nervosa and Bulimia Nervosa Case Vignettes (Preprint)",
        "authors": "Rebekka Schnepper, Noa Roemmel, Rainer Schaefert, Lena Lambrecht-Walzinger, Gunther Meinlschmidt",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nLarge language models (LLMs) are increasingly used in the mental health field, with promising results in assessing mental disorders. However, correctness, dependability, and equity of LLM-generated information have been questioned. Amongst other, societal biases and research underrepresentation of certain population strata may affect LLMs. Because LLMs are already used for clinical practice, including decision support, it is important to investigate potential biases to ensure a responsible use of LLMs.\n\n\nOBJECTIVE\nWe aimed to estimate the presence and size of bias related to gender and sexual orientation produced by a common LLM, exemplified in the context of ED symptomatology and health-related quality of life (HRQoL) of patients with AN or BN.\n\n\nMETHODS\nWe extracted 30 case vignettes (22 AN, 8 BN) from scientific articles. We adapted each vignette to create 4 versions, describing a female vs. male patient living with their female vs. male partner (2x2 design), yielding n=120 vignettes. We then fed each vignette into Chat Generative Pre-trained Transformer-4 (ChatGPT-4) thrice with the instruction to evaluate them by providing responses to two psychometric instruments, the RAND-36 questionnaire assessing HRQoL and the eating disorder examination questionnaire (EDE-Q). With the resulting LLM-generated scores, we calculated multilevel models (MLMs) with a random intercept for gender and sexual orientation (accounting for within-vignette variance), nested in vignettes (accounting for between-vignette variance).\n\n\nRESULTS\nThe MLM with N=360 observations indicated for the RAND-36 mental composite summary, a significant association with gender (conditional means: 12.8 for male and 15.1 for female cases; 95% CI of the effect=[-6.15, -0.35]; p=.037) but neither with sexual orientation nor an interaction effect (ps>.370). We found no indications for main or interaction effects of gender or sexual orientation for the EDE-Q overall score (conditional means: 5.59-5.65; ps>.611).\n\n\nCONCLUSIONS\nLLM-generated estimates of mental HRQoL in AN or BN case vignettes are at risk of being affected by cases’ gender, with male cases scoring lower. Given the lack of real-world epidemiological evidence for such a pattern, our study highlights relevant risk of bias when applying generative AI in the context of mental health. Better understanding and mitigation of risk of bias related to gender and other factors, such as ethnicity or socioeconomic status, are highly warranted to ensure responsible use of LLMs when conducting diagnostic assessments or providing treatment recommendations.\n",
        "link": "http://dx.doi.org/10.2196/preprints.57986"
    },
    {
        "id": 12550,
        "title": "ProgPrompt: program generation for situated robot task planning using large language models",
        "authors": "Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, Animesh Garg",
        "published": "2023-12",
        "citations": 7,
        "abstract": "AbstractTask planning can require defining myriad domain knowledge about the world in which a robot needs to act. To ameliorate that effort, large language models (LLMs) can be used to score potential next actions during task planning, and even generate action sequences directly, given an instruction in natural language with no additional domain information. However, such methods either require enumerating all possible next steps for scoring, or generate free-form text that may contain actions not possible on a given robot in its current context. We present a programmatic LLM prompt structure that enables plan generation functional across situated environments, robot capabilities, and tasks. Our key insight is to prompt the LLM with program-like specifications of the available actions and objects in an environment, as well as with example  that can be executed. We make concrete recommendations about prompt structure and generation constraints through ablation experiments, demonstrate state of the art success rates in VirtualHome household tasks, and deploy our method on a physical robot arm for tabletop tasks. Website and code at progprompt.github.io",
        "link": "http://dx.doi.org/10.1007/s10514-023-10135-3"
    },
    {
        "id": 12551,
        "title": "Artificial Intelligence to Automate Health Economic Modelling: A Case Study to Evaluate the Potential Application of Large Language Models",
        "authors": "Tim Reason, William Rawlinson, Julia Langham, Andy Gimblett, Bill Malcolm, Sven Klijn",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s41669-024-00477-8"
    },
    {
        "id": 12552,
        "title": "The Use of Large Language Models Tuned with Socratic Methods on the Impact of Medical Students' Learning: A Randomised Controlled Trial (Preprint)",
        "authors": "Cai Ling Yong, Mohammad Shaheryar Furqan, James Wai Kit Lee, Andrew Makmur, Ragunathan Mariappan, Clara Lee Ying Ngoh, Kee Yuan Ngiam",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nLarge Language Models (LLM) are AI models that can generate conversational content based on a trained specified source of information (corpus).\n\n\nOBJECTIVE\nThe aim is to use these corpus-trained LLMs to limit the content offered by LLM, then using prompt engineering to teach using Socratic methods.\n\n\nMETHODS\nTwo chatbots were created and deployed, powered by OpenAI’s GPT-3.5 model, with a medical-school textbook corpus. The first chatbot generates a brief summary and open-ended question. The second chatbot generates a case vignette from its pre-trained clinical cases, prompting users for a diagnosis. Both chatbots reply to the user’s response, commenting on the accuracy and asks further questions to encourage critical thinking. A randomised controlled trial was conducted on two groups comprising third year medical students. One group used both chatbots for 10 minutes while the other read the medical textbook. A 15-question test was administered to both groups before and after the intervention.\n\n\nRESULTS\nForty students participated in the study. The average of the group before and after reading the textbook (n=20) are 3.9 +/- 1.0 and 7.6 +/- 1.5 respectively (p<0.001). The average of the group before and after using the bot (n=20) are 3.9 +/- 0.9 and 12.8 +/- 1.6 respectively (p<0.001). The respective increase in results was 3.7 and 8.9.\n\n\nCONCLUSIONS\nMedical students’ learning showed a better performance using a LLM based chatbot compared to self-reading of medical information assessed using a standardised test. More studies are required to determine if LLM-based pedagogical methods are superior to standard education.\n",
        "link": "http://dx.doi.org/10.2196/preprints.57995"
    },
    {
        "id": 12553,
        "title": "Bridging Domains in Chronic Lower Back Pain: Large Language Models and Ontology-driven Strategies for Knowledge Graph Construction",
        "authors": "Paul Anderson, Damon Lin, Jean Davidson, Theresa Migler, Iris Ho, Cooper Koenig, Madeline Bittner, Samuel Kaplan, Mayumi Paraiso, Nasreen Buhn, Emily Stokes, Tony Hunt, Glen Ropella, Jeffrey Lotz",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractLink prediction and entity resolution play pivotal roles in uncovering hidden relationships within networks and ensuring data quality in the era of heterogeneous data integration. This paper explores the utilization of large language models to enhance link prediction, particularly through knowledge graphs derived from transdisciplinary literature. Investigating zero-shot entity resolution techniques, we examine the impact of ontology-based and large language model approaches on the stability of link prediction results. Through a case study focusing on chronic lower back pain research, we analyze workflow decisions and their influence on prediction outcomes. Our research underscores the importance of robust methodologies in improving predictive accuracy and data integration across diverse domains.",
        "link": "http://dx.doi.org/10.1101/2024.03.11.584505"
    },
    {
        "id": 12554,
        "title": "GeoLM: Empowering Language Models for Geospatially Grounded Language Understanding",
        "authors": "Zekun Li, Wenxuan Zhou, Yao-Yi Chiang, Muhao Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.317"
    },
    {
        "id": 12555,
        "title": "SBU Figures It Out: Models Explain Figurative Language",
        "authors": "Yash Kumar Lal, Mohaddeseh Bastan",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.flp-1.20"
    },
    {
        "id": 12556,
        "title": "Computational and Robotic Models of Early Language Development",
        "authors": "Pierre-Yves Oudeyer, George Kachergis, William Schueller",
        "published": "2019-5-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781315110622-5"
    },
    {
        "id": 12557,
        "title": "Exploring Transformers as Compact, Data-efficient Language Models",
        "authors": "Clayton Fields, Casey Kennington",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-1.35"
    },
    {
        "id": 12558,
        "title": "Grammar and Cognition",
        "authors": "",
        "published": "2020-11-15",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/hcp.70"
    },
    {
        "id": 12559,
        "title": "Can Large Language Models Assist in Hazard Analysis?",
        "authors": "Simon Diemert, Jens H. Weber",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-40953-0_35"
    },
    {
        "id": 12560,
        "title": "LLMs4OL: Large Language Models for Ontology Learning",
        "authors": "Hamed Babaei Giglou, Jennifer D’Souza, Sören Auer",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-47240-4_22"
    },
    {
        "id": 12561,
        "title": "Foundation and large language models: fundamentals, challenges, opportunities, and social impacts",
        "authors": "Devon Myers, Rami Mohawesh, Venkata Ishwarya Chellaboina, Anantha Lakshmi Sathvik, Praveen Venkatesh, Yi-Hui Ho, Hanna Henshaw, Muna Alhawawreh, David Berdik, Yaser Jararweh",
        "published": "2024-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10586-023-04203-7"
    },
    {
        "id": 12562,
        "title": "Towards Automated Regulatory Compliance Verification in Financial Auditing with Large Language Models",
        "authors": "Armin Berger, Lars Hillebrand, David Leonhard, Tobias Deußer, Thiago Bell Felix De Oliveira, Tim Dilmaghani, Mohamed Khaled, Bernd Kliem, Rudiger Loitz, Christian Bauckhage, Rafet Sifa",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386518"
    },
    {
        "id": 12563,
        "title": "Chat with the Environment: Interactive Multimodal Perception Using Large Language Models",
        "authors": "Xufeng Zhao, Mengdi Li, Cornelius Weber, Muhammad Burhan Hafez, Stefan Wermter",
        "published": "2023-10-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iros55552.2023.10342363"
    },
    {
        "id": 12564,
        "title": "AutoPCF: A Novel Automatic Product Carbon Footprint Estimation Framework Based on Large Language Models",
        "authors": "Biao Luo, Jinjie Liu, Zhu Deng, Can Yuan, Qingrun Yang, Lei Xiao, Yucong Xie, Fanke Zhou, Wenwen Zhou, Zhu Liu",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "Estimating the product carbon footprint (PCF) is crucial for sustainable consumption and supply chain decar-bonlization. The current life cycle assessment (LCA) methods frequently employed to evaluate PCFs often en-counter challenges, such as difficulties in determining the emission inventory and emission factors (EFs), as well as significant labor and time costs. To address these limitations, this paper presents AutoPCF, a novel auto-matic PCF estimation framework to conduct cradle-to-gate LCA for products. It utilizes deep learning models and large language models (LLMs) to automate and en-hance the estimation process. The framework comprises five stages: Emission Inventory Determination (EID), Activity Data Collection (ADC), Emission Factor Matching (EFM), Carbon Emission Estimation (CEE), and Estimation Verification and Evaluation (EVE). EID generates production processes and activity inventory, while ADC collects comprehensive activity data and EFM identifies accurate EFs. Emissions are then estimat-ed using the collected activity data and corresponding EFs. Experimental evaluations on steel, textile, and bat-tery products demonstrate the effectiveness of AutoPCF in improving the efficiency of PCF estimation. By auto-mating data collection and analysis, AutoPCF reduces re-liance on subjective decision-making and enhances the consistency and efficiency of carbon footprint assess-ments, advancing sustainable practices and supporting climate change mitigation efforts.",
        "link": "http://dx.doi.org/10.1609/aaaiss.v2i1.27656"
    },
    {
        "id": 12565,
        "title": "Comparing Code Explanations Created by Students and Large Language Models",
        "authors": "Juho Leinonen, Paul Denny, Stephen MacNeil, Sami Sarsa, Seth Bernstein, Joanne Kim, Andrew Tran, Arto Hellas",
        "published": "2023-6-29",
        "citations": 30,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3587102.3588785"
    },
    {
        "id": 12566,
        "title": "Generative Relevance Feedback with Large Language Models",
        "authors": "Iain Mackie, Shubham Chatterjee, Jeffrey Dalton",
        "published": "2023-7-19",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3539618.3591992"
    },
    {
        "id": 12567,
        "title": "Quality of Answers of Generative Large Language Models vs Peer Patients for Interpreting Lab Test Results for Lay Patients: Evaluation Study (Preprint)",
        "authors": "Zhe He, Balu Bhasuran, Qiao Jin, Shubo Tian, Karim Hanna, Cindy Shavor, Lisbeth Garcia Arguello, Patrick Murray, Zhiyong Lu",
        "published": "2024-1-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2196/56655"
    },
    {
        "id": 12568,
        "title": "Large language models in radiology: fundamentals, applications, ethical considerations, risks, and future directions",
        "authors": "Tugba Akinci D’Antonoli, Arnaldo Stanzione, Christian Bluethgen, Federica Vernuccio, Lorenzo Ugga, Michail E. Klontzas, Renato Cuocolo, Roberto Cannella, Burak Koçak",
        "published": "2024-3-1",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4274/dir.2023.232417"
    },
    {
        "id": 12569,
        "title": "AngleKindling: Supporting Journalistic Angle Ideation with Large Language Models",
        "authors": "Savvas Petridis, Nicholas Diakopoulos, Kevin Crowston, Mark Hansen, Keren Henderson, Stan Jastrzebski, Jeffrey V Nickerson, Lydia B Chilton",
        "published": "2023-4-19",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3544548.3580907"
    },
    {
        "id": 12570,
        "title": "Large Margin Neural Language Model",
        "authors": "Jiaji Huang, Yi Li, Wei Ping, Liang Huang",
        "published": "2018",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d18-1150"
    },
    {
        "id": 12571,
        "title": "Analysis on Models of Teaching Spoken Chinese as a Foreign Language",
        "authors": "Meiru Liu",
        "published": "2019-7-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781315104652-16"
    },
    {
        "id": 12572,
        "title": "Generating Abstractive Summaries with Finetuned Language Models",
        "authors": "Sebastian Gehrmann, Zachary Ziegler, Alexander Rush",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-8665"
    },
    {
        "id": 12573,
        "title": "Plot Writing From Pre-Trained Language Models",
        "authors": "Yiping Jin, Vishakha Kadam, Dittaya Wanvarie",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.inlg-main.5"
    },
    {
        "id": 12574,
        "title": "State gradients for analyzing memory in LSTM language models",
        "authors": "Lyan Verwimp, Hugo Van hamme, Patrick Wambacq",
        "published": "2020-5",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2019.101034"
    },
    {
        "id": 12575,
        "title": "Emerging Models of Practice in Flipped English Language Arts Classrooms",
        "authors": "Troy Cockrum",
        "published": "2019",
        "citations": 0,
        "abstract": "This chapter reviews various flipped classroom models with particular focus on documenting them for further study and development. Much of the current research and popular news coverage regarding flipped classrooms only addresses one model; however, with multiple models in practice we have an incomplete picture in popular and academic literature of how the flipped classroom is being used by K-12 teachers. This chapter uses publications and blog posts to identify the multiple models of flipped English language arts (ELA) as they are documented by practitioners. Each model is categorized and defined in order to provide a better understanding for future practice and research, as well as determine common terminology. This chapter serves to alleviate the concerns that the current research and popular press are not accurately representing the flipped classroom. By identifying variations of the model and providing further recommendations on ways to advance the model, a more accurate picture can be documented. ",
        "link": "http://dx.doi.org/10.4018/978-1-5225-7663-1.ch100"
    },
    {
        "id": 12576,
        "title": "Validating Predictive Models Of Evaluative Language For Controllable Data2Text Generation",
        "authors": "Maurice Langner, Ralf Klabunde",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.inlg-main.22"
    },
    {
        "id": 12577,
        "title": "Discretized Integrated Gradients for Explaining Language Models",
        "authors": "Soumya Sanyal, Xiang Ren",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.805"
    },
    {
        "id": 12578,
        "title": "Prompting language models improves performance in imbalanced setting",
        "authors": "Jay Mohta",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.sustainlp-1.14"
    },
    {
        "id": 12579,
        "title": "Models of Speaking and the Assessment of Second Language Proficiency",
        "authors": "Peter Skehan",
        "published": "2018-7-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781315629766-15"
    },
    {
        "id": 12580,
        "title": "Unveiling the Power of Pre - Trained Language Models in NLP Applications",
        "authors": "Shrinath Pai",
        "published": "2023-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21275/sr231115202502"
    },
    {
        "id": 12581,
        "title": "Vocabulary Modifications for Domain-adaptive Pretraining of Clinical Language Models",
        "authors": "Anastasios Lamproudis, Aron Henriksson, Hercules Dalianis",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010893800003123"
    },
    {
        "id": 12582,
        "title": "Addressing Current Problems with Achieving Physical Consistency Across the Electromagnetic Spectrum Between Ice Crystal Models, Remote-Sensing, and Large-Scale Models",
        "authors": "Anthony Baran",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/essoar.10509469.1"
    },
    {
        "id": 12583,
        "title": "Models and Measures",
        "authors": "",
        "published": "2022-7-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108955638.005"
    },
    {
        "id": 12584,
        "title": "Theory and Language",
        "authors": "Roman Frigg",
        "published": "2022-6-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003285106-3"
    },
    {
        "id": 12585,
        "title": "LVCSR with Transformer Language Models",
        "authors": "Eugen Beck, Ralf Schlüter, Hermann Ney",
        "published": "2020-10-25",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2020-1164"
    },
    {
        "id": 12586,
        "title": "How Can We Know <i>When</i> Language Models Know? On the Calibration of Language Models for Question Answering",
        "authors": "Zhengbao Jiang, Jun Araki, Haibo Ding, Graham Neubig",
        "published": "2021-9-8",
        "citations": 22,
        "abstract": "Abstract\nRecent works have shown that language models (LM) capture different types of knowledge regarding facts or common sense. However, because no model is perfect, they still fail to provide appropriate answers in many cases. In this paper, we ask the question, “How can we know when language models know, with confidence, the answer to a particular query?” We examine this question from the point of view of calibration, the property of a probabilistic model’s predicted probabilities actually being well correlated with the probabilities of correctness. We examine three strong generative models—T5, BART, and GPT-2—and study whether their probabilities on QA tasks are well calibrated, finding the answer is a relatively emphatic no. We then examine methods to calibrate such models to make their confidence scores correlate better with the likelihood of correctness through fine-tuning, post-hoc probability modification, or adjustment of the predicted outputs or inputs. Experiments on a diverse range of datasets demonstrate the effectiveness of our methods. We also perform analysis to study the strengths and limitations of these methods, shedding light on further improvements that may be made in methods for calibrating LMs. We have released the code at https://github.com/jzbjyb/lm-calibration.",
        "link": "http://dx.doi.org/10.1162/tacl_a_00407"
    },
    {
        "id": 12587,
        "title": "Language evolution is not limited to speech acquisition: a large study of language development in children with language deficits highlights the importance of the voluntary imagination component of language",
        "authors": "Andrey Vyshedskiy",
        "published": "2022-7-14",
        "citations": 0,
        "abstract": "Did the boy bite the cat or was it the other way around? When processing a sentence with several objects, one has to establish ‘who did what to whom’. When a sentence cannot be interpreted by recalling an image from memory, we rely on the special type of voluntary constructive imagination called Prefrontal synthesis (PFS). PFS is defined as the ability to juxtapose mental visuospatial objects at will. We hypothesised that PFS has fundamental importance for language acquisition. To test this hypothesis, we designed a PFS-targeting intervention and administered it to 6,454 children with language deficiencies (age 2 to 12 years). The results from the three-year-long study demonstrated that children who engaged with the PFS intervention showed 2.2-fold improvement in combinatorial language comprehension compared to children with similar initial evaluations. These findings suggest that language can be improved by training the PFS and exposes the importance of the visuospatial component of language. This manuscript reflects on the experimental findings from the point of view of human language evolution. When used as a proxy for evolutionary language acquisition, the study results suggest a dichotomy of language evolution, with its speech component and its visuospatial component developing in parallel. The study highlights the radical idea that evolutionary acquisition of language was driven primarily by improvements of voluntary imagination rather than by improvements in the speech apparatus.",
        "link": "http://dx.doi.org/10.3897/rio.8.e86401"
    },
    {
        "id": 12588,
        "title": "Preface",
        "authors": "Max Black",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-001"
    },
    {
        "id": 12589,
        "title": "On the Computation of Meaning, Language Models and Incomprehensible Horrors",
        "authors": "Michael Timothy Bennett",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>[Accepted to the 16th Annual Conference on Artificial General Intelligence]</p>\n<p><br></p>\n<p>We bring together foundational theories of meaning and a mathematical formalism of artificial general intelligence to provide a mechanistic explanation of meaning, communication and symbol emergence. We establish circumstances under which a machine might mean what we think it means by what it says, or comprehend what we mean by what we say. We conclude that a language model such as ChatGPT does not comprehend or engage in meaningful communication with humans, though it may exhibit complex behaviours such as theory of mind.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22216753.v2"
    },
    {
        "id": 12590,
        "title": "Cognitive models of language contact",
        "authors": "Alexander Onysko",
        "published": "2021-6-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/cal.30.04ony"
    },
    {
        "id": 12591,
        "title": "Addressing Current Problems with Achieving Physical Consistency Across the Electromagnetic Spectrum Between Ice Crystal Models, Remote-Sensing, and Large-Scale Models",
        "authors": "Anthony Baran",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/essoar.10509975.1"
    },
    {
        "id": 12592,
        "title": "On the Computation of Meaning, Language Models and Incomprehensible Horrors",
        "authors": "Michael Timothy Bennett",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p><strong>Accepted for full oral presentation at the 16th Conference on Artificial General Intelligence, taking place in Stockholm, 2023.</strong></p>\n<p><br></p>\n<p>We integrate foundational theories of meaning with a mathematical formalism of artificial general intelligence (AGI) to offer a comprehensive mechanistic explanation of meaning, communication, and symbol emergence. This synthesis holds significance for both AGI and broader debates concerning the nature of language, as it unifies pragmatics, logical truth conditional semantics, Peircean semiotics, and a computable model of enactive cognition, addressing phenomena that have traditionally evaded mechanistic explanation. By examining the conditions under which a machine can generate meaningful utterances or comprehend human meaning, we establish that the current generation of language models do not possess the same understanding of meaning as humans nor intend any meaning that we might attribute to their responses. To address this, we propose simulating human feelings and optimising models to construct weak representations. Our findings shed light on the relationship between meaning and intelligence, and how we can build machines that comprehend and intend meaning.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22216753"
    },
    {
        "id": 12593,
        "title": "More than a Chatbot",
        "authors": "Mascha Kurpicz-Briki",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-37690-0"
    },
    {
        "id": 12594,
        "title": "Exploration of Language Models for ICF Design [Slides]",
        "authors": "Cabot Cullen, Zhehui Wang",
        "published": "2023-7-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2172/1992244"
    },
    {
        "id": 12595,
        "title": "Leveraging Natural Language Processing Models to Automate Speech-Intelligibility Scoring",
        "authors": "Bjorn Herrmann",
        "published": "No Date",
        "citations": 0,
        "abstract": "Assessment of speech intelligibility in noise is critical for measuring the impact of age-related hearing loss. However, quantifying intelligibility often requires a human to manually process responses provided by a participant or patient to obtain a speech-intelligibility score – typically the proportion of correctly heard words. This manual process can be time consuming and thus costly. The current study investigates whether state-of-the-art Natural Language Processing (NLP) models from Google and OpenAI could be used to calculate speech-intelligibility scores as an alternative to human scoring. It was specifically tested whether NLP models capture common speech-in-noise perception phenomena in younger and older adults (N=144) listening to speech masked by modulated or unmodulated babble noise. The results show that NLP speech-intelligibility scores closely matched intelligibility scores from a human scorer (r ~0.95). The main difference is a, on average, ~2% underestimation of NLP intelligibility scores relative to human intelligibility scores for moderate to high signal-to-noise ratios. This underestimation results from participants making minor errors related to misspellings, gender, or tense, to which NLP models are sensitive, but human scorers typically correct prior to scoring. Critically, NLP models capture the known age-related reduction in intelligibility and the age-related reduction in the benefit from a modulated relative to an unmodulated masker. OpenAI’s ADA2 appears to perform the best out of the tested NLP models, showing no difference in the speech-in-noise phenomena compared to human scoring. The current study suggests that modern NLP models can be used to score speech-intelligibility data.",
        "link": "http://dx.doi.org/10.31234/osf.io/h9mna"
    },
    {
        "id": 12596,
        "title": "Understanding models understanding language",
        "authors": "Anders Søgaard",
        "published": "2022-10-27",
        "citations": 1,
        "abstract": "AbstractLandgrebe and Smith (Synthese 198(March):2061–2081, 2021) present an unflattering diagnosis of recent advances in what they call language-centric artificial intelligence—perhaps more widely known as natural language processing: The models that are currently employed do not have sufficient expressivity, will not generalize, and are fundamentally unable to induce linguistic semantics, they say. The diagnosis is mainly derived from an analysis of the widely used Transformer architecture. Here I address a number of misunderstandings in their analysis, and present what I take to be a more adequate analysis of the ability of Transformer models to learn natural language semantics. To avoid confusion, I distinguish between inferential and referential semantics. Landgrebe and Smith (2021)’s analysis of the Transformer architecture’s expressivity and generalization concerns inferential semantics. This part of their diagnosis is shown to rely on misunderstandings of technical properties of Transformers. Landgrebe and Smith (2021) also claim that referential semantics is unobtainable for Transformer models. In response, I present a non-technical discussion of techniques for grounding Transformer models, giving them referential semantics, even in the absence of supervision. I also present a simple thought experiment to highlight the mechanisms that would lead to referential semantics, and discuss in what sense models that are grounded in this way, can be said to understand language. Finally, I discuss the approach Landgrebe and Smith (2021) advocate for, namely manual specification of formal grammars that associate linguistic expressions with logical form.",
        "link": "http://dx.doi.org/10.1007/s11229-022-03931-4"
    },
    {
        "id": 12597,
        "title": "Approaching the Language of the Second Language Learner: Interlanguage and the Models Before",
        "authors": "Ayad Hameed Mahmood, Ibrahim Mohammed Ali Murad",
        "published": "2018-9-16",
        "citations": 4,
        "abstract": "The present paper attempts to provide a critical evaluation of the most prominent pedagogical models that have dealt with the language of the second language (L2) learner starting from the second half of the 20th century. The three most influential approaches in the domain are investigated in this study: contrastive analysis (CA), error analysis (EA), and interlanguage (IL). Each of these models is tackled in terms of its beginning, psychological background, essential tenets, mechanism, and its pedagogical value. Prominently, this work is aimed at teasing apart the confusion that surrounds the fields of acquiring second/foreign language. It also endeavors to clear out the overlapping of both terminology and concept that cloud these areas. Focus is placed on IL owing to the dominant share of attention it has received from researchers and applied linguists who have found many of their questions answered and many information-gaps filled in with this theory. This review paper is an extract of an in-progress PhD dissertation on interlanguage pragmatics of Kurdish university EFL learners, which is an applied study addressing both the pragmalinguistic and sociopragmatic knowledge of the students. ",
        "link": "http://dx.doi.org/10.5539/elt.v11n10p95"
    },
    {
        "id": 12598,
        "title": "Alignment of Dialogue Models",
        "authors": "",
        "published": "2021-1-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108610728.009"
    },
    {
        "id": 12599,
        "title": "An Introduction to Word Embeddings and Language Models",
        "authors": "Tammie Borders, Svitlana Volkova",
        "published": "2021-4-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2172/1773690"
    },
    {
        "id": 12600,
        "title": "On the Computation of Meaning, Language Models and Incomprehensible Horrors",
        "authors": "Michael Timothy Bennett",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p><strong>Accepted for full oral presentation at the 16th Conference on Artificial General Intelligence, taking place in Stockholm, 2023.</strong></p>\n<p><br></p>\n<p>We integrate foundational theories of meaning with a mathematical formalism of artificial general intelligence (AGI) to offer a comprehensive mechanistic explanation of meaning, communication, and symbol emergence. This synthesis holds significance for both AGI and broader debates concerning the nature of language, as it unifies pragmatics, logical truth conditional semantics, Peircean semiotics, and a computable model of enactive cognition, addressing phenomena that have traditionally evaded mechanistic explanation. By examining the conditions under which a machine can generate meaningful utterances or comprehend human meaning, we establish that the current generation of language models do not possess the same understanding of meaning as humans nor intend any meaning that we might attribute to their responses. To address this, we propose simulating human feelings and optimising models to construct weak representations. Our findings shed light on the relationship between meaning and intelligence, and how we can build machines that comprehend and intend meaning.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22216753.v3"
    },
    {
        "id": 12601,
        "title": "Evaluating theories of bilingual language control using computational models",
        "authors": "Mark Lowry, Chad Dubé, Elizabeth Schotter",
        "published": "2021-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jml.2020.104195"
    },
    {
        "id": 12602,
        "title": "Bridging large-scale neuronal recordings and large-scale network models using dimensionality reduction",
        "authors": "Ryan C Williamson, Brent Doiron, Matt A Smith, Byron M Yu",
        "published": "No Date",
        "citations": 0,
        "abstract": "A long-standing goal in neuroscience has been to bring together neuronal recordings and neural network modeling to understand brain function. Neuronal recordings can inform the development of network models, and network models can in turn provide predictions for subsequent experiments. Traditionally, neuronal recordings and network models have been related using single-neuron and pairwise spike train statistics. We review here recent studies that have begun to relate neuronal recordings and network models based on the multi-dimensional structure of neuronal population activity, as identified using dimensionality reduction. This approach has been used to study working memory, decision making, motor control, and more. Dimensionality reduction has provided common ground for incisive comparisons and tight interplay between neuronal recordings and network models.",
        "link": "http://dx.doi.org/10.7287/peerj.preprints.27340v1"
    },
    {
        "id": 12603,
        "title": "Language models, surprisal and fantasy in Slavic intercomprehension",
        "authors": "Klára Jágrová, Tania Avgustinova, Irina Stenger, Andrea Fischer",
        "published": "2019-1",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2018.04.005"
    },
    {
        "id": 12604,
        "title": "Discovering Language-neutral Sub-networks in Multilingual Language Models",
        "authors": "Negar Foroutan, Mohammadreza Banaei, Rémi Lebret, Antoine Bosselut, Karl Aberer",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.513"
    },
    {
        "id": 12605,
        "title": "Massively Parallel Modeling &amp; Simulation of a Large Crowd with GPGPU",
        "authors": "Dan Chen, Lizhe Wang, Jingying Chen",
        "published": "2017-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b11883-12"
    },
    {
        "id": 12606,
        "title": "Bridging large-scale neuronal recordings and large-scale network models using dimensionality reduction",
        "authors": "Ryan C Williamson, Brent Doiron, Matt A Smith, Byron M Yu",
        "published": "No Date",
        "citations": 0,
        "abstract": "A long-standing goal in neuroscience has been to bring together neuronal recordings and neural network modeling to understand brain function. Neuronal recordings can inform the development of network models, and network models can in turn provide predictions for subsequent experiments. Traditionally, neuronal recordings and network models have been related using single-neuron and pairwise spike train statistics. We review here recent studies that have begun to relate neuronal recordings and network models based on the multi-dimensional structure of neuronal population activity, as identified using dimensionality reduction. This approach has been used to study working memory, decision making, motor control, and more. Dimensionality reduction has provided common ground for incisive comparisons and tight interplay between neuronal recordings and network models.",
        "link": "http://dx.doi.org/10.7287/peerj.preprints.27340"
    },
    {
        "id": 12607,
        "title": "Deep Latent Variable Models",
        "authors": "",
        "published": "2021-1-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108332873.019"
    },
    {
        "id": 12608,
        "title": "Language Models",
        "authors": "Djoerd Hiemstra",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7993-3_923-2"
    },
    {
        "id": 12609,
        "title": "On the Computation of Meaning, Language Models and Incomprehensible Horrors",
        "authors": "Michael Timothy Bennett",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>We bring together foundational theories of meaning and a mathematical formalism of artificial general intelligence to provide a mechanistic explanation of meaning, communication and symbol emergence. We establish circumstances under which a machine might mean what we think it means by what it says, or comprehend what we mean by what we say. We conclude that a language model such as ChatGPT does not comprehend or engage in meaningful communication with humans, though it may exhibit complex behaviours such as theory of mind.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22216753.v1"
    },
    {
        "id": 12610,
        "title": "Pixels to Phrases: Evolution of Vision Language Models",
        "authors": "Jay Oza, Gitesh Kambli",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36227/techrxiv.171078045.57266373/v1"
    },
    {
        "id": 12611,
        "title": "Leveraging Natural Language Processing Models to Automate Speech-Intelligibility Scoring",
        "authors": "Bjorn Herrmann",
        "published": "No Date",
        "citations": 0,
        "abstract": "Assessment of speech intelligibility in noise is critical for measuring the impact of age-related hearing loss. However, quantifying intelligibility often requires a human to manually process responses provided by a participant or patient to obtain a speech-intelligibility score – typically the proportion of correctly heard words. This manual process can be time consuming and thus costly. The current study investigates whether state-of-the-art Natural Language Processing (NLP) models from Google and OpenAI could be used to calculate speech-intelligibility scores as an alternative to human scoring. It was specifically tested whether NLP models capture common speech-in-noise perception phenomena in younger and older adults (N=144) listening to speech masked by modulated or unmodulated babble noise. The results show that NLP speech-intelligibility scores closely matched intelligibility scores from a human scorer (r ~0.95). The main difference is a, on average, ~2% underestimation of NLP intelligibility scores relative to human intelligibility scores for moderate to high signal-to-noise ratios. This underestimation results from participants making minor errors related to misspellings, gender, or tense, to which NLP models are sensitive, but human scorers typically correct prior to scoring. Critically, NLP models capture the known age-related reduction in intelligibility and the age-related reduction in the benefit from a modulated relative to an unmodulated masker. OpenAI’s ADA2 appears to perform the best out of the tested NLP models, showing no difference in the speech-in-noise phenomena compared to human scoring. The current study suggests that modern NLP models can be used to score speech-intelligibility data.",
        "link": "http://dx.doi.org/10.31234/osf.io/h9mna"
    },
    {
        "id": 12612,
        "title": "Understanding models understanding language",
        "authors": "Anders Søgaard",
        "published": "2022-10-27",
        "citations": 1,
        "abstract": "AbstractLandgrebe and Smith (Synthese 198(March):2061–2081, 2021) present an unflattering diagnosis of recent advances in what they call language-centric artificial intelligence—perhaps more widely known as natural language processing: The models that are currently employed do not have sufficient expressivity, will not generalize, and are fundamentally unable to induce linguistic semantics, they say. The diagnosis is mainly derived from an analysis of the widely used Transformer architecture. Here I address a number of misunderstandings in their analysis, and present what I take to be a more adequate analysis of the ability of Transformer models to learn natural language semantics. To avoid confusion, I distinguish between inferential and referential semantics. Landgrebe and Smith (2021)’s analysis of the Transformer architecture’s expressivity and generalization concerns inferential semantics. This part of their diagnosis is shown to rely on misunderstandings of technical properties of Transformers. Landgrebe and Smith (2021) also claim that referential semantics is unobtainable for Transformer models. In response, I present a non-technical discussion of techniques for grounding Transformer models, giving them referential semantics, even in the absence of supervision. I also present a simple thought experiment to highlight the mechanisms that would lead to referential semantics, and discuss in what sense models that are grounded in this way, can be said to understand language. Finally, I discuss the approach Landgrebe and Smith (2021) advocate for, namely manual specification of formal grammars that associate linguistic expressions with logical form.",
        "link": "http://dx.doi.org/10.1007/s11229-022-03931-4"
    },
    {
        "id": 12613,
        "title": "Legal-Tech Open Diaries: Lesson learned on how to develop and deploy light-weight models in the era of humongous Language Models",
        "authors": "Stelios Maroudas, Sotiris Legkas, Prodromos Malakasiotis, Ilias Chalkidis",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.nllp-1.8"
    },
    {
        "id": 12614,
        "title": "Entity Linking of Sound Recordings and Compositions with Pre-trained Language Models",
        "authors": "Nikiforos Katakis, Pantelis Vikatos",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010713900003058"
    },
    {
        "id": 12615,
        "title": "Index",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781788928106-010"
    },
    {
        "id": 12616,
        "title": "Contents",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781788928106-toc"
    },
    {
        "id": 12617,
        "title": "Training microrobots to swim by a large language model",
        "authors": "Zhuoqun Xu, Lailai Zhu",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nMachine learning and artificial intelligence have recently represented a popular paradigm for designing and optimizing robotic systems across various scales. Recent studies have showcased the innovative application of large language models (LLMs) in industrial control [1] and in directing legged walking robots [2]. In this study, we utilize an LLM, GPT-4, to train two prototypical microrobots for swimming in viscous fluids. Adopting a few-shot learning approach, we develop a minimal, unified prompt composed of only five sentences. The same concise prompt successfully guides two distinct articulated microrobots—the three-link swimmer and the three-sphere swimmer—in mastering their signature strokes. These strokes, initially conceptualized by physicists, are now effectively interpreted and applied by the LLM, enabling the microrobots to circumvent the physical constraints inherent to micro-locomotion. Remarkably, our LLM-based decision-making strategy substantially surpasses a traditional reinforcement learning method in terms of training speed. We discuss the nuanced aspects of prompt design, particularly emphasizing the reduction of monetary expenses of using GPT-4.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3853112/v1"
    },
    {
        "id": 12618,
        "title": "Bridging large-scale neuronal recordings and large-scale network models using dimensionality reduction",
        "authors": "Ryan C Williamson, Brent Doiron, Matt A Smith, Byron M Yu",
        "published": "No Date",
        "citations": 0,
        "abstract": "A long-standing goal in neuroscience has been to bring together neuronal recordings and neural network modeling to understand brain function. Neuronal recordings can inform the development of network models, and network models can in turn provide predictions for subsequent experiments. Traditionally, neuronal recordings and network models have been related using single-neuron and pairwise spike train statistics. We review here recent studies that have begun to relate neuronal recordings and network models based on the multi-dimensional structure of neuronal population activity, as identified using dimensionality reduction. This approach has been used to study working memory, decision making, motor control, and more. Dimensionality reduction has provided common ground for incisive comparisons and tight interplay between neuronal recordings and network models.",
        "link": "http://dx.doi.org/10.7287/peerj.preprints.27340v2"
    },
    {
        "id": 12619,
        "title": "International Models of Language Policy and Language Planning: Official Bilingualism in Ireland and Sociolinguistic Reality",
        "authors": "Maeve Conrick",
        "published": "2018-12-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9780773555877-009"
    },
    {
        "id": 12620,
        "title": "Large Scale, Multi-domain Language Identification",
        "authors": "Tommi Jauhiainen, Marcos Zampieri, Timothy Baldwin, Krister Lindén",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-45822-4_5"
    },
    {
        "id": 12621,
        "title": "Decision letter for \"The use of a large language model to create plain language summaries of evidence reviews in healthcare: A feasibility study\"",
        "authors": "",
        "published": "2024-1-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/cesm.12041/v2/decision1"
    },
    {
        "id": 12622,
        "title": "Decision letter for \"The use of a large language model to create plain language summaries of evidence reviews in healthcare: A feasibility study\"",
        "authors": "",
        "published": "2023-11-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/cesm.12041/v1/decision1"
    },
    {
        "id": 12623,
        "title": "Frontmatter",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781788928106-fm"
    },
    {
        "id": 12624,
        "title": "Acknowledgements",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781788928106-001"
    },
    {
        "id": 12625,
        "title": "References",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781788928106-009"
    },
    {
        "id": 12626,
        "title": "3. Enumerating Language: ‘‘The Unreasonable Effectiveness of Mathematics’’",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9780822394440-005"
    },
    {
        "id": 12627,
        "title": "Can Language Models Be Tricked by Language Illusions? Easier with Syntax, Harder with Semantics",
        "authors": "Yuhan Zhang, Edward Gibson, Forrest Davis",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-1.1"
    },
    {
        "id": 12628,
        "title": "Diversifying language models for lesser-studied languages and language-usage contexts: A case of second language Korean",
        "authors": "Hakyung Sung, Gyu-Ho Shin",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.767"
    },
    {
        "id": 12629,
        "title": "Measurement of Figurative ^ Language: Semantic Feature Models of Comprehension and Appreciation",
        "authors": "Robert G. Malgady, Michael G. Johnson",
        "published": "2018-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429432866-10"
    },
    {
        "id": 12630,
        "title": "Are Pretrained Language Models Symbolic Reasoners over Knowledge?",
        "authors": "Nora Kassner, Benno Krojer, Hinrich Schütze",
        "published": "2020",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.conll-1.45"
    },
    {
        "id": 12631,
        "title": "Training Language Models with Memory Augmentation",
        "authors": "Zexuan Zhong, Tao Lei, Danqi Chen",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.382"
    },
    {
        "id": 12632,
        "title": "Language-Agnostic and Language-Aware Multilingual Natural Language Understanding for Large-Scale Intelligent Voice Assistant Application",
        "authors": "Daniel Yue Zhang, Jonathan Hueser, Yao Li, Sarah Campbell",
        "published": "2021-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata52589.2021.9671571"
    },
    {
        "id": 12633,
        "title": "Reference-Aware Language Models",
        "authors": "Zichao Yang, Phil Blunsom, Chris Dyer, Wang Ling",
        "published": "2017",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d17-1197"
    },
    {
        "id": 12634,
        "title": "Efficient Nearest Neighbor Language Models",
        "authors": "Junxian He, Graham Neubig, Taylor Berg-Kirkpatrick",
        "published": "2021",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.461"
    },
    {
        "id": 12635,
        "title": "On Losses for Modern Language Models",
        "authors": "Stéphane Aroca-Ouellette, Frank Rudzicz",
        "published": "2020",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.403"
    },
    {
        "id": 12636,
        "title": "Adversarial Perturbations Augmented Language Models for Euphemism Identification",
        "authors": "Guneet Kohli, Prabsimran Kaur, Jatin Bedi",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.flp-1.22"
    },
    {
        "id": 12637,
        "title": "Second Language Acquisition of Neural Language Models",
        "authors": "Miyu Oba, Tatsuki Kuribayashi, Hiroki Ouchi, Taro Watanabe",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.856"
    },
    {
        "id": 12638,
        "title": "Information-Weighted Neural Cache Language Models for ASR",
        "authors": "Lyan Verwimp, Joris Pelemans, Hugo Van hamme, Patrick Wambacq",
        "published": "2018-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt.2018.8639543"
    },
    {
        "id": 12639,
        "title": "DeepSatData: Building large scale datasets of satellite images for training machine learning models",
        "authors": "Michael Tarasiou",
        "published": "No Date",
        "citations": 0,
        "abstract": "This paper presents DeepSatData a pipeline for automatically generating satellite imagery datasets for training machine learning models. We also discuss design considerations with emphasis on dense classification tasks, e.g. semantic segmentation. The implementation presented makes use of freely available Sentinel-2 data which allows the generation of large scale datasets required for training deep neural networks (DNN). We discuss issues faced from the point of view of DNN training and evaluation such as checking the quality of ground truth data and comment on the scalability of the approach.",
        "link": "http://dx.doi.org/10.36227/techrxiv.16558482"
    },
    {
        "id": 12640,
        "title": "Improving Requirements Engineering through Goal-oriented Models and Tools: Feedback from a Large Industrial Deployment",
        "authors": "Christophe Ponsard, Robert Darimont",
        "published": "2017",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006462503720381"
    },
    {
        "id": 12641,
        "title": "Serving Very Large Numbers of Low Latency AutoML Models",
        "authors": "Manoj Agarwal",
        "published": "2020-10-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ieeeconf47748.2020.9377614"
    },
    {
        "id": 12642,
        "title": "Decision letter for \"Realising the promise of large data and complex models\"",
        "authors": "",
        "published": "2022-12-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/2041-210x.14050/v1/decision1"
    },
    {
        "id": 12643,
        "title": "Multidimensional Rasch models in first language listening tests",
        "authors": "Christian Spoden, Jens Fleischer",
        "published": "2019-7-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781315187808-2"
    },
    {
        "id": 12644,
        "title": "General Models",
        "authors": "",
        "published": "2017-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789814740753_0002"
    },
    {
        "id": 12645,
        "title": "State ordering and classification for analyzing non-sparse large Markov Models",
        "authors": "Mohammadsadegh Mohagheghi",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nMarkov chains and Markov decision processes have been widely used to model the behavior of computer systems with probabilistic aspects. Numerical and iterative methods are commonly used to analyze these models. Many efforts have been made in recent decades to improve the efficiency of these numerical methods. In this paper, focusing on Markov models with non-sparse structure, a new set of heuristics is proposed for prioritizing model states with the aim of reducing the total computation time. In these heuristics, a set of simulation runs are used for statistical analysis of the effect of each state on the required values of the other states. Under this criterion, the priority of each state in updating its values is determined. The proposed heuristics provide a state ordering that improves the value propagation among the states. The proposed methods are also extended for very large models where disk-based techniques are required to analyze the models. Experimental results show that our proposed methods in this paper reduce the running times of the iterative methods for most cases of non-sparse models.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2944266/v1"
    },
    {
        "id": 12646,
        "title": "Novel Hyperelastic Models for Large Volumetric Deformations",
        "authors": "Kevin Mattheus Moerman, Behrooz Fereidoonnezhad, Patrick McGarry",
        "published": "No Date",
        "citations": 1,
        "abstract": "Materials such as elastomeric foams, lattices, and cellular solids are capable of undergoing large elastic volume changes. Although many hyperelastic constitutive formulations have been proposed for deviatoric (shape changing) behaviour, few variations exist for large deformation volumetric behaviour. The first section of this paper presents a critical analysis of current volumetric hyperelastic models and highlights their limitations for large volumetric strains. In the second section of the paper we propose three novel volumetric strain energy density functions, which: 1) are valid for large volumetric deformations, 2) offer separate control of the volumetric strain stiffening behaviour during shrinkage (volume reduction) and expansion (volume increase), and 3) provide precise control of non-monotonic volumetric strain stiffening. To illustrate the ability of the novel formulations to capture complex volumetric material behaviour they are fitted and compared to a range of published experimental data.",
        "link": "http://dx.doi.org/10.31224/osf.io/cfxdr"
    },
    {
        "id": 12647,
        "title": "DeepSatData: Building large scale datasets of satellite images for training machine learning models",
        "authors": "Michael Tarasiou",
        "published": "No Date",
        "citations": 0,
        "abstract": "This paper presents DeepSatData a pipeline for automatically generating satellite imagery datasets for training machine learning models. We also discuss design considerations with emphasis on dense classification tasks, e.g. semantic segmentation. The implementation presented makes use of freely available Sentinel-2 data which allows the generation of large scale datasets required for training deep neural networks (DNN). We discuss issues faced from the point of view of DNN training and evaluation such as checking the quality of ground truth data and comment on the scalability of the approach.",
        "link": "http://dx.doi.org/10.36227/techrxiv.16558482.v1"
    },
    {
        "id": 12648,
        "title": "Parsing Language-Specific Constructions: The Case of French Pronominal Clitics",
        "authors": "Eric Wehrli",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5_25"
    },
    {
        "id": 12649,
        "title": "Blank Language Models",
        "authors": "Tianxiao Shen, Victor Quach, Regina Barzilay, Tommi Jaakkola",
        "published": "2020",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.420"
    },
    {
        "id": 12650,
        "title": "Corpus Complexity Matters in Pretraining Language Models",
        "authors": "Ameeta Agrawal, Suresh Singh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.sustainlp-1.20"
    },
    {
        "id": 12651,
        "title": "Detoxifying Language Models with a Toxic Corpus",
        "authors": "Yoona Park, Frank Rudzicz",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.ltedi-1.6"
    },
    {
        "id": 12652,
        "title": "Using Music to Bridge Language Diversity",
        "authors": "Jillian Ratti",
        "published": "2019-1-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678-10"
    },
    {
        "id": 12653,
        "title": "Training Data Extraction From Pre-trained Language Models: A Survey",
        "authors": "Shotaro Ishihara",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.trustnlp-1.23"
    },
    {
        "id": 12654,
        "title": "End-to-end Speech Recognition With Word-Based Rnn Language Models",
        "authors": "Takaaki Hori, Jaejin Cho, Shinji Watanabe",
        "published": "2018-12",
        "citations": 56,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt.2018.8639693"
    },
    {
        "id": 12655,
        "title": "The Place of Human Language in the Animal World",
        "authors": "Stephen R. Anderson",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5_18"
    },
    {
        "id": 12656,
        "title": "Interacting with Large Language Models: A Case Study on AI-Aided Brainstorming for Guesstimation Problems",
        "authors": "Vildan Salikutluk, Dorothea Koert, Frank Jäkel",
        "published": "2023-6-22",
        "citations": 0,
        "abstract": "Designing cooperative AI-systems that do not automate tasks but rather aid human cognition is challenging and requires human-centered design approaches. Here, we introduce AI-aided brainstorming for solving guesstimation problems, i.e. estimating quantities from incomplete information, as a testbed for human-AI interaction with large language models (LLMs). In a think-aloud study, we found that humans decompose guesstimation questions into sub-questions and often replace them with semantically related ones. If they fail to brainstorm related questions, they often get stuck and do not find a solution. Therefore, to support this brainstorming process, we prompted a large language model (GPT-3) with successful replacements from our think-aloud data. In follow-up studies, we tested whether the availability of this tool improves participants’ answers. While the tool successfully produced human-like suggestions, participants were reluctant to use it. From our findings, we conclude that for human-AI interaction with LLMs to be successful AI-systems must complement rather than mimic a user’s associations.",
        "link": "http://dx.doi.org/10.3233/faia230081"
    },
    {
        "id": 12657,
        "title": "Competition for gradient-free tuning of large language models: approaches, results, current challenges and future directions",
        "authors": "Tingfeng Cao, Liang Chen, Dixiang Zhang, Tianxiang Sun, Zhengfu He, Xipeng Qiu, Xing Xu, Hai Zhang",
        "published": "2023-5-10",
        "citations": 1,
        "abstract": "This perspective presents a brief overview of the background of Gradient-free tuning for large language models competition, the championship scheme, as well as the challenges and future directions.",
        "link": "http://dx.doi.org/10.1093/nsr/nwad124"
    },
    {
        "id": 12658,
        "title": "Mathematical discoveries from program search with large language models",
        "authors": "Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M. Pawan Kumar, Emilien Dupont, Francisco J. R. Ruiz, Jordan S. Ellenberg, Pengming Wang, Omar Fawzi, Pushmeet Kohli, Alhussein Fawzi",
        "published": "2024-1-18",
        "citations": 5,
        "abstract": "AbstractLarge language models (LLMs) have demonstrated tremendous capabilities in solving complex tasks, from quantitative reasoning to understanding natural language. However, LLMs sometimes suffer from confabulations (or hallucinations), which can result in them making plausible but incorrect statements1,2. This hinders the use of current large models in scientific discovery. Here we introduce FunSearch (short for searching in the function space), an evolutionary procedure based on pairing a pretrained LLM with a systematic evaluator. We demonstrate the effectiveness of this approach to surpass the best-known results in important problems, pushing the boundary of existing LLM-based approaches3. Applying FunSearch to a central problem in extremal combinatorics—the cap set problem—we discover new constructions of large cap sets going beyond the best-known ones, both in finite dimensional and asymptotic cases. This shows that it is possible to make discoveries for established open problems using LLMs. We showcase the generality of FunSearch by applying it to an algorithmic problem, online bin packing, finding new heuristics that improve on widely used baselines. In contrast to most computer search approaches, FunSearch searches for programs that describe how to solve a problem, rather than what the solution is. Beyond being an effective and scalable strategy, discovered programs tend to be more interpretable than raw solutions, enabling feedback loops between domain experts and FunSearch, and the deployment of such programs in real-world applications.",
        "link": "http://dx.doi.org/10.1038/s41586-023-06924-6"
    },
    {
        "id": 12659,
        "title": "“Knock, Knock … Who’s There?” ChatGPT and Artificial Intelligence-Powered Large Language Models: Reflections on Potential Impacts Within Health and Physical Education Teacher Education",
        "authors": "Chad M. Killian, Risto Marttinen, Donal Howley, Julia Sargent, Emily M. Jones",
        "published": "2023-7-1",
        "citations": 2,
        "abstract": "This research note suggests the emergence of Artificial Intelligence-powered chatbots like ChatGPT pose challenges to the future of higher education. We as a field should pay attention to issues and opportunities associated with this technology across learning, teaching, and research spaces. We propose ignoring, or being indifferent to, predictions about what technologies like Artificial Intelligence-powered chatbots can do can cause us to do “dumb things.” All health and physical education teacher education faculty members should make efforts to learn about these tools to facilitate informed, solution-focused decisions about whether and where to leverage them. We highlight the importance of maintaining sociocritical perspectives when considering use of digital technologies to understand and address digital (in)equity and promote equitable practices. We conclude by emphasizing the need for field-specific consensus statements to guide ethical and appropriate use of Artificial Intelligence-powered chatbots, to ensure the value of these tools is harnessed for the good of the society. [Output by ChatGPT-3]",
        "link": "http://dx.doi.org/10.1123/jtpe.2023-0058"
    },
    {
        "id": 12660,
        "title": "An Exploration of the Potential of Large Language Models to Enable Cognitive Flexibility in AI-Augmented Learning Environments",
        "authors": "Sarah A. Chauncey, H. Patricia McKenna",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-47448-4_11"
    },
    {
        "id": 12661,
        "title": "Harnessing Artificial Neural Networks and large language models for bioprocess optimization: Predicting sugar output from Kraft waste-based lignocellulosic pretreatments",
        "authors": "Anthea Naomi David, Y. Sewsynker-Sukai, E.L. Meyer, E.B. Gueguim Kana",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.indcrop.2023.117686"
    },
    {
        "id": 12662,
        "title": "Large Language Models and Their Ability for Health Disinformation Generation: Assessing the Adequacy of Current Safeguards and Risk Mitigation Measures",
        "authors": "Bradley Menz, Nicole Kuderer, Stephen Bacchi, Natansh Modi, Benjamin Chin-Yee, Tiancheng Hu, Ceara Rickard, Mark Haseloff, Agnes Vitry, Ross McKinnon, Ganessan Kichenadasse, Andrew Rowland, Michael Sorich, Ashley Hopkins",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4618768"
    },
    {
        "id": 12663,
        "title": "Using Large Language Models to Support Thematic Analysis in Empirical Legal Studies",
        "authors": "Jakub Drápal, Hannes Westermann, Jaromir Savelka",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "Thematic analysis and other variants of inductive coding are widely used qualitative analytic methods within empirical legal studies (ELS). We propose a novel framework facilitating effective collaboration of a legal expert with a large language model (LLM) for generating initial codes (phase 2 of thematic analysis), searching for themes (phase 3), and classifying the data in terms of the themes (to kick-start phase 4). We employed the framework for an analysis of a dataset (n = 785) of facts descriptions from criminal court opinions regarding thefts. The goal of the analysis was to discover classes of typical thefts. Our results show that the LLM, namely OpenAI’s GPT-4, generated reasonable initial codes, and it was capable of improving the quality of the codes based on expert feedback. They also suggest that the model performed well in zero-shot classification of facts descriptions in terms of the themes. Finally, the themes autonomously discovered by the LLM appear to map fairly well to the themes arrived at by legal experts. These findings can be leveraged by legal researchers to guide their decisions in integrating LLMs into their thematic analyses, as well as other inductive coding projects.",
        "link": "http://dx.doi.org/10.3233/faia230965"
    },
    {
        "id": 12664,
        "title": "Assessment of the bias of artificial intelligence generated images and large language models on their depiction of a surgeon",
        "authors": "Jevan Cevik, Bryan Lim, Ishith Seth, Foti Sofiadellis, Richard J. Ross, Roberto Cuomo, Warren M. Rozen",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/ans.18792"
    },
    {
        "id": 12665,
        "title": "The First Workshop on Personalized Generative AI @ CIKM 2023: Personalization Meets Large Language Models",
        "authors": "Zheng Chen, Ziyan Jiang, Fan Yang, Zhankui He, Yupeng Hou, Eunah Cho, Julian McAuley, Aram Galstyan, Xiaohua Hu, Jie Yang",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3583780.3615314"
    },
    {
        "id": 12666,
        "title": "Framework for evaluating code generation ability of large language models",
        "authors": "Sangyeop Yeo, Yu‐Seung Ma, Sang Cheol Kim, Hyungkook Jun, Taeho Kim",
        "published": "2024-2",
        "citations": 1,
        "abstract": "AbstractLarge language models (LLMs) have revolutionized various applications in natural language processing and exhibited proficiency in generating programming code. We propose a framework for evaluating the code generation ability of LLMs and introduce a new metric, \n, which captures the granularity of accuracy according to the pass rate of test cases. The framework is intended to be fully automatic to handle the repetitive work involved in generating prompts, conducting inferences, and executing the generated codes. A preliminary evaluation focusing on the prompt detail, problem publication date, and difficulty level demonstrates the successful integration of our framework with the LeetCode coding platform and highlights the applicability of the \n metric.",
        "link": "http://dx.doi.org/10.4218/etrij.2023-0357"
    },
    {
        "id": 12667,
        "title": "An AI Dietitian for Type 2 Diabetes Mellitus Management Based on Large Language and Image Recognition Models: Preclinical Concept Validation Study",
        "authors": "Haonan Sun, Kai Zhang, Wei Lan, Qiufeng Gu, Guangxiang Jiang, Xue Yang, Wanli Qin, Dongran Han",
        "published": "2023-11-9",
        "citations": 4,
        "abstract": "\nBackground\nNutritional management for patients with diabetes in China is a significant challenge due to the low supply of registered clinical dietitians. To address this, an artificial intelligence (AI)–based nutritionist program that uses advanced language and image recognition models was created. This program can identify ingredients from images of a patient’s meal and offer nutritional guidance and dietary recommendations.\n\n\nObjective\nThe primary objective of this study is to evaluate the competence of the models that support this program.\n\n\nMethods\nThe potential of an AI nutritionist program for patients with type 2 diabetes mellitus (T2DM) was evaluated through a multistep process. First, a survey was conducted among patients with T2DM and endocrinologists to identify knowledge gaps in dietary practices. ChatGPT and GPT 4.0 were then tested through the Chinese Registered Dietitian Examination to assess their proficiency in providing evidence-based dietary advice. ChatGPT’s responses to common questions about medical nutrition therapy were compared with expert responses by professional dietitians to evaluate its proficiency. The model’s food recommendations were scrutinized for consistency with expert advice. A deep learning–based image recognition model was developed for food identification at the ingredient level, and its performance was compared with existing models. Finally, a user-friendly app was developed, integrating the capabilities of language and image recognition models to potentially improve care for patients with T2DM.\n\n\nResults\nMost patients (182/206, 88.4%) demanded more immediate and comprehensive nutritional management and education. Both ChatGPT and GPT 4.0 passed the Chinese Registered Dietitian examination. ChatGPT’s food recommendations were mainly in line with best practices, except for certain foods like root vegetables and dry beans. Professional dietitians’ reviews of ChatGPT’s responses to common questions were largely positive, with 162 out of 168 providing favorable reviews. The multilabel image recognition model evaluation showed that the Dino V2 model achieved an average F1 score of 0.825, indicating high accuracy in recognizing ingredients.\n\n\nConclusions\nThe model evaluations were promising. The AI-based nutritionist program is now ready for a supervised pilot study.\n",
        "link": "http://dx.doi.org/10.2196/51300"
    },
    {
        "id": 12668,
        "title": "Study on Mechanical Properties of Steel Trestle with Large Slope Considering the Influence of Large Traffic Flow",
        "authors": "",
        "published": "2022-4-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i4(02).16"
    },
    {
        "id": 12669,
        "title": "Adaptation of Enterprise Modeling Methods for Large Language Models",
        "authors": "Balbir S. Barn, Souvik Barat, Kurt Sandkuhl",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-48583-1_1"
    },
    {
        "id": 12670,
        "title": "312 When AI Meets the Emergency Department: Realizing the Benefits of Large Language Models in Emergency Medicine",
        "authors": "N. Ashenburg, C. Preiksaitis, J. Dayton, R. Ribeira, G. Bunney, R. Kabeer, F. Riley, A. Chu, C. Rose",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.annemergmed.2023.08.337"
    },
    {
        "id": 12671,
        "title": "Predictive Prompts with Joint Training of Large Language Models for Explainable Recommendation",
        "authors": "Ching-Sheng Lin, Chung-Nan Tsai, Shao-Tang Su, Jung-Sing Jwo, Cheng-Hsiung Lee, Xin Wang",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "Large language models have recently gained popularity in various applications due to their ability to generate natural text for complex tasks. Recommendation systems, one of the frequently studied research topics, can be further improved using the capabilities of large language models to track and understand user behaviors and preferences. In this research, we aim to build reliable and transparent recommendation system by generating human-readable explanations to help users obtain better insights into the recommended items and gain more trust. We propose a learning scheme to jointly train the rating prediction task and explanation generation task. The rating prediction task learns the predictive representation from the input of user and item vectors. Subsequently, inspired by the recent success of prompt engineering, these predictive representations are served as predictive prompts, which are soft embeddings, to elicit and steer any knowledge behind language models for the explanation generation task. Empirical studies show that the proposed approach achieves competitive results compared with other existing baselines on the public English TripAdvisor dataset of explainable recommendations.",
        "link": "http://dx.doi.org/10.3390/math11204230"
    },
    {
        "id": 12672,
        "title": "Evaluation of Pretrained Large Language Models in Embodied Planning Tasks",
        "authors": "Christina Sarkisyan, Alexandr Korchemnyi, Alexey K. Kovalev, Aleksandr I. Panov",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-33469-6_23"
    },
    {
        "id": 12673,
        "title": "Large language models in anaesthesiology: use of ChatGPT for American Society of Anesthesiologists physical status classification",
        "authors": "Daniel Y.Z. Lim, Yu He Ke, Gerald G.R. Sng, Joshua Y.M. Tung, Jia X. Chai, Hairil R. Abdullah",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.bja.2023.06.052"
    },
    {
        "id": 12674,
        "title": "Improving Zero-shot Visual Question Answering via Large Language Models with Reasoning Question Prompts",
        "authors": "Yunshi Lan, Xiang Li, Xin Liu, Yang Li, Wei Qin, Weining Qian",
        "published": "2023-10-26",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3581783.3612389"
    },
    {
        "id": 12675,
        "title": "TidyBot: personalized robot assistance with large language models",
        "authors": "Jimmy Wu, Rika Antonova, Adam Kan, Marion Lepert, Andy Zeng, Shuran Song, Jeannette Bohg, Szymon Rusinkiewicz, Thomas Funkhouser",
        "published": "2023-12",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10514-023-10139-z"
    },
    {
        "id": 12676,
        "title": "Comparison of Large Language Models in Generating Patient Handouts for the Dermatology Clinic: a blinded study.",
        "authors": "Crystal T. Chang, Iesha L. Ticknor, Jacob-Anthony Spinelli, Bhavnit K. Bhatia, Sangeeta Marwaha, Paradi Mirmirani, Anne M. Seidler, Jeremy R. Man, Patrick E. McCleskey",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jdin.2024.02.010"
    },
    {
        "id": 12677,
        "title": "A comprehensive evaluation of large Language models on benchmark biomedical text processing tasks",
        "authors": "Israt Jahan, Md Tahmid Rahman Laskar, Chun Peng, Jimmy Xiangji Huang",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.compbiomed.2024.108189"
    },
    {
        "id": 12678,
        "title": "How Does ChatGPT Perform on the United States Medical Licensing Examination (USMLE)? The Implications of Large Language Models for Medical Education and Knowledge Assessment",
        "authors": "Aidan Gilson, Conrad W Safranek, Thomas Huang, Vimig Socrates, Ling Chi, Richard Andrew Taylor, David Chartash",
        "published": "2023-2-8",
        "citations": 555,
        "abstract": "\nBackground\nChat Generative Pre-trained Transformer (ChatGPT) is a 175-billion-parameter natural language processing model that can generate conversation-style responses to user input.\n\n\nObjective\nThis study aimed to evaluate the performance of ChatGPT on questions within the scope of the United States Medical Licensing Examination (USMLE) Step 1 and Step 2 exams, as well as to analyze responses for user interpretability.\n\n\nMethods\nWe used 2 sets of multiple-choice questions to evaluate ChatGPT’s performance, each with questions pertaining to Step 1 and Step 2. The first set was derived from AMBOSS, a commonly used question bank for medical students, which also provides statistics on question difficulty and the performance on an exam relative to the user base. The second set was the National Board of Medical Examiners (NBME) free 120 questions. ChatGPT’s performance was compared to 2 other large language models, GPT-3 and InstructGPT. The text output of each ChatGPT response was evaluated across 3 qualitative metrics: logical justification of the answer selected, presence of information internal to the question, and presence of information external to the question.\n\n\nResults\nOf the 4 data sets, AMBOSS-Step1, AMBOSS-Step2, NBME-Free-Step1, and NBME-Free-Step2, ChatGPT achieved accuracies of 44% (44/100), 42% (42/100), 64.4% (56/87), and 57.8% (59/102), respectively. ChatGPT outperformed InstructGPT by 8.15% on average across all data sets, and GPT-3 performed similarly to random chance. The model demonstrated a significant decrease in performance as question difficulty increased (P=.01) within the AMBOSS-Step1 data set. We found that logical justification for ChatGPT’s answer selection was present in 100% of outputs of the NBME data sets. Internal information to the question was present in 96.8% (183/189) of all questions. The presence of information external to the question was 44.5% and 27% lower for incorrect answers relative to correct answers on the NBME-Free-Step1 (P<.001) and NBME-Free-Step2 (P=.001) data sets, respectively.\n\n\nConclusions\nChatGPT marks a significant improvement in natural language processing models on the tasks of medical question answering. By performing at a greater than 60% threshold on the NBME-Free-Step-1 data set, we show that the model achieves the equivalent of a passing score for a third-year medical student. Additionally, we highlight ChatGPT’s capacity to provide logic and informational context across the majority of answers. These facts taken together make a compelling case for the potential applications of ChatGPT as an interactive medical education tool to support learning.\n",
        "link": "http://dx.doi.org/10.2196/45312"
    },
    {
        "id": 12679,
        "title": "The implementation of the cognitive theory of multimedia learning in the design and evaluation of an AI educational video assistant utilizing large language models",
        "authors": "Rana AlShaikh, Norah Al-Malki, Maida Almasre",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.heliyon.2024.e25361"
    },
    {
        "id": 12680,
        "title": "Welcome to the Era of ChatGPT et al.",
        "authors": "Timm Teubner, Christoph M. Flath, Christof Weinhardt, Wil van der Aalst, Oliver Hinz",
        "published": "2023-4",
        "citations": 58,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s12599-023-00795-x"
    },
    {
        "id": 12681,
        "title": "Machine learning techniques for IoT security: Current research and future vision with generative AI and large language models",
        "authors": "Fatima Alwahedi, Alyazia Aldhaheri, Mohamed Amine Ferrag, Ammar Battah, Norbert Tihanyi",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.iotcps.2023.12.003"
    },
    {
        "id": 12682,
        "title": "eDKM: An Efficient and Accurate Train-Time Weight Clustering for Large Language Models",
        "authors": "Minsik Cho, Keivan A. Vahid, Qichen Fu, Saurabh Adya, Carlo C. Del Mundo, Mohammad Rastegari, Devang Naik, Peter Zatloukal",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/lca.2024.3363492"
    },
    {
        "id": 12683,
        "title": "Evaluating the Efficacy of Supervised Learning vs. Large Language Models for Identifying Cognitive Distortions and Suicidal Risks in Chinese Social Media",
        "authors": "Guanghui FU, Hongzhi Qi, Qing Zhao, Changwei Song, Wei Zhai, Dan Luo, Liu Shuo, Yi Jing Yu, Fan Wang, Huijing Zou, Bing Xiang Yang, Jianqiang Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nLarge language models, particularly those akin to the rapidly progressing GPT series, are gaining traction for their expansive influence. While there is keen interest in their applicability within medical domains such as psychology, tangible explorations on real-world data remain scant. Concurrently, users on social media platforms are increasingly vocalizing personal sentiments; under specific thematic umbrellas, these sentiments often manifest as negative emotions, sometimes escalating to suicidal inclinations. Timely discernment of such cognitive distortions and suicidal risks is crucial to effectively intervene and potentially avert dire circumstances. Our study ventured into this realm by experimenting on two pivotal tasks: suicidal risk and cognitive distortion identification on Chinese social media platforms. Using supervised learning as a baseline, we examined and contrasted the efficacy of large language models via three distinct strategies: zero-shot, few-shot, and fine-tuning. Our findings revealed a discernible performance gap between the large language models and traditional supervised learning approaches, primarily attributed to the models' inability to fully grasp subtle categories. Notably, while GPT-4 outperforms its counterparts in multiple scenarios, GPT-3.5 shows significant enhancement in suicide risk classification after fine-tuning. To our knowledge, this investigation stands as the maiden attempt at gauging large language models on Chinese social media tasks. This study underscores the forward-looking and transformative implications of using large language models in the field of psychology. It lays the groundwork for future applications in psychological research and practice.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3355484/v1"
    },
    {
        "id": 12684,
        "title": "Assessing and optimizing large language models on spondyloarthritis multi-choice question answering (SpAMCQA): study protocol for a bilingual evaluation benchmark",
        "authors": "Anan Wang, Xiangyang Wang, Xiaojian Ji, Yunong Wu, Jiawen Hu, Fazhan Zhang, Zhanchao Zhang, Dong Pu, Shikui Ma, Jing Dong, Qiang Liu, Kunpeng Li, Da Teng, Tao Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground\n In recent years, the deployment of sophisticated technological solutions in the medical domain has garnered increasing interest. Through the lens of Artificial Intelligence (AI), the medical field stands on the cusp of a significant paradigm shift, one that holds the promise of elevating healthcare delivery to a pinnacle of excellence, driven by the synergy between human expertise and machine intelligence. This research aims to develop a stringent evaluation criterion for assessing large language models’ accuracy in addressing queries related to spondyloarthritis. It involves creating a dataset of disease-relevant multiple-choice questions for large language models (LLMs), ensuring they understand, recall, and interpret the necessary medical knowledge accurately. Additionally, this study seeks to refine and optimize large language models to deliver state-of-the-art performance on this dataset and provide exemplary technical services for AI-assisted diagnosis and treatment of spondyloarthritis.\nMethods\n We have established a rigorous benchmark consisting of 122 meticulously crafted multiple-choice questions on spondyloarthritis, developed with the collaboration of clinical experts. These questions have undergone thorough revision to ensure their applicability in the accurate evaluation of large language models' performance within real-world diagnostic and therapeutic settings. Our approach includes the selection and fine-tuning of the most promising publicly available foundational models against a comprehensive dataset. The model that demonstrates superior performance on this benchmark will undergo additional training. In a subsequent phase, records from over 80,000 real-world inpatient and outpatient cases at Chinese PLA General Hospital will serve to further train the LLMs, employing techniques such as Supervised Fine-Tuning and Low-Rank Adaptation. We will assess the models' generated responses for their precision and evaluate their reasoning processes using the Safety, Usability, and Smoothness metric.\nDiscussion\n The SpAMCQA benchmark has been meticulously crafted to assess the effectiveness of large language models in managing clinical issues relating to spondyloarthritis. It serves as a tool to gauge the performance capabilities of our self-developed model, SpARobotGPT, within this medical specialty. Demonstrating potential, LLMs are poised to augment clinical decision-making, enhancing the diagnosis and treatment of spondyloarthritis. The benchmark dataset and experimental results are slated to be announced in the near future.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3625354/v1"
    },
    {
        "id": 12685,
        "title": "Artificial Intelligence to Automate Network Meta-Analyses: Four Case Studies to Evaluate the Potential Application of Large Language Models",
        "authors": "Tim Reason, Emma Benbow, Julia Langham, Andy Gimblett, Sven L. Klijn, Bill Malcolm",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s41669-024-00476-9"
    },
    {
        "id": 12686,
        "title": "Automatic Kernel Generation for Large Language Models on Deep Learning Accelerators",
        "authors": "Fuyu Wang, Minghua Shen",
        "published": "2023-10-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccad57390.2023.10323944"
    },
    {
        "id": 12687,
        "title": "Language Representation Projection: Can We Transfer Factual Knowledge across Languages in Multilingual Language Models?",
        "authors": "Shaoyang Xu, Junzhuo Li, Deyi Xiong",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.226"
    },
    {
        "id": 12688,
        "title": "Structural and Topological Analysis of Homogeneous Models for a Large Robotic Control System",
        "authors": "I. S. Pavlovskiy",
        "published": "2020-9-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd49919.2020.9247690"
    },
    {
        "id": 12689,
        "title": "Analogy",
        "authors": "Olga Fischer",
        "published": "2018-11-28",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/slcs.202.04fis"
    },
    {
        "id": 12690,
        "title": "The Inconsistency Of Language Models",
        "authors": "Uralov Azamat Begnarovich,  ",
        "published": "2021-9-30",
        "citations": 0,
        "abstract": "The article deals with the problem of disproportion in morpheme units of linguistics and patterns. Based on the disproportion, information is given on the combined affixes formed in the morphemes, the expanded forms, and the analytic and synthetic forms. The data is based on the opinions of the world's leading linguists. The ideas are proven using examples. The formation of a particular linguistic model is a disproportion in the language system (meaning-function-methodological features): confusion of meanings, multifunctionality, semantics, competition in the use of forms (one form has more and more privileges, archaic nation of another form).",
        "link": "http://dx.doi.org/10.37547/tajssei/volume03issue09-09"
    },
    {
        "id": 12691,
        "title": "Building Hybrid Representations from Text Corpora, Knowledge Graphs, and Language Models",
        "authors": "Jose Manuel Gomez-Perez, Ronald Denaux, Andres Garcia-Silva",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-44830-1_6"
    },
    {
        "id": 12692,
        "title": "Adaptive Strategies for Management of Fisheries Resources in Large Marine Ecosystems",
        "authors": "Jeremy S. Collie",
        "published": "2019-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429042423-10"
    },
    {
        "id": 12693,
        "title": "Do Neural Models Learn Systematicity of Monotonicity Inference in Natural Language?",
        "authors": "Hitomi Yanaka",
        "published": "2020-9-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.27.653"
    },
    {
        "id": 12694,
        "title": "Current Status and Prospects of Legal Mind Development using Large Language Models",
        "authors": "Kiryong Kyeong, Sang Yeob Lee, Soyeon Kim, Kyongseok In, WonSeok Ji, Dae Sik Hong",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.35505/sjlb.2023.12.13.3.3"
    },
    {
        "id": 12695,
        "title": "Leveraging Large Language Models for Automatic Hypotheses Testing over Heterogeneous Biological Databases",
        "authors": "Hasan M Jamil, Stephen A Krawetz, Alexander Gow",
        "published": "2023-9-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3584371.3613022"
    },
    {
        "id": 12696,
        "title": "Leveraging Large Language Models as Simulated Users for Initial, Low-Cost Evaluations of Designed Conversations",
        "authors": "Jan de Wit",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-54975-5_5"
    },
    {
        "id": 12697,
        "title": "An exploration of using large language models to integrate farmer behaviour into an agricultural systems model of the Peruvian Andes",
        "authors": "Joy Singarayer, Richard Bailey, Patrick McGuire, Francisco Araujo- Ferreira, Nicholas Branch, Fernando Gonzalez, Diana Santos Shupingahua, Douglas Walsh, Alexander Herrera, Andrew Wade, Harvey Rodda, Martin Timana, Kevin Lane",
        "published": "No Date",
        "citations": 0,
        "abstract": "The implications of climate change on agro-pastoral farming systems in the Peruvian Andes are not fully understood. There is already a significant impact on agricultural productivity from current climate variability and extreme weather in the region. This is exacerbated by chronic poverty in many rural areas and the need for improved government-led strategic planning. Tools to assist with policy planning for climate change adaptations that achieve environmental and social resilience are vital, and these require collaboration with rural communities to incorporate the complexities of behavioural responses to climate change, market dynamics, and policy shifts in agricultural and water management.&#160;\nIn this study we further develop a recent agricultural systems model (the TELLUS model; Pilditch et al., in review). The model is an agent-based simulation focussed on the behaviour of interacting populations of individual farming agents. TELLUS offers the opportunity to analyse the impact of interventions/policies in light of key scenarios and conditions of interest, with potential to uncover unforeseen emergent behaviours within farming systems (e.g., tipping points, amplifiers, system adaptations) and potential unintended consequences of scenarios and policies (e.g., increasing in equalities; increased system fragility). A difficulty in applying such models to specific case studies is in choosing valid parameter values, especially for model behaviour associated with human behaviour and decision-making.\nOur work over recent years includes extensive fieldwork in the Cordillera Negra and Cordillera Blanca, involving interviews and workshops with farming communities, and collaboration with regional NGOs. These interactions have been instrumental in understanding local challenges and priorities. The challenge in terms of modelling this system is turning information gained from qualitative methods (e.g. interviews) into parameter values for the model. Our novel approach is to assess the extent to which modern AI systems, specifically, Large Language Models (LLMs) can help perform this task. &#160;We leverage the reasoning abilities of LLMs to directly estimate relevant model parameters from automated interview transcription/translations. We will discuss the extent to which this integration has aided the creation of a TELLUS model tuned specifically to the Peruvian Andes context. Our approach will hopefully serve as a novel tool, combining empirical research, community involvement, and advanced computational modelling, to explore future climate scenarios and the potential effects of policy interventions.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-18078"
    },
    {
        "id": 12698,
        "title": "Improving Efficiencies While Also Delivering Better Health Care Outcomes: A Role for Large Language Models",
        "authors": "Shivdev K. Rao, Elliot K. Fishman, Ryan C. Rizk, Linda C. Chu, Steven P. Rowe",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jacr.2024.01.003"
    },
    {
        "id": 12699,
        "title": "Do large language models know chemistry?",
        "authors": "Andrew D. White, Glen M. Hocky, Heta A. Gandhi, Mehrad Ansari, Sam Cox, Geemi P. Wellawatte, Subarna Sasmal, Ziyue Yang, Kangxin Liu, Yuvraj Singh, Willmor J. Peña Ccoa",
        "published": "No Date",
        "citations": 2,
        "abstract": "Mostly yes. We systematically evaluate machine learning large language models (LLMs) that generate code in the context of chemistry. We produce a benchmark set of problems, and evaluate these models based on correctness of code by automated testing and evaluation by experts. We find recent LLMs are able to write correct code across a variety of topics in chemistry and their accuracy can be increased by 30 percentage points via prompt engineering strategies, like putting copyright notices at the top of files. These dataset and evaluation tools are open source which can be contributed to or built upon by future researchers, and will serve as a community resource for evaluating the performance of new models as they emerge. We also describe some good practices for employing LLMs in chemistry. The general success of these models demonstrates that their impact on chemistry teaching and research is poised to be enormous.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2022-3md3n"
    },
    {
        "id": 12700,
        "title": "The Impact of AUTOGEN and Similar Fine-Tuned Large Language Models on the Integrity of Scholarly Writing",
        "authors": "David B. Resnik, Mohammad Hosseini",
        "published": "2023-10-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15265161.2023.2250276"
    },
    {
        "id": 12701,
        "title": "Value-based Healthcare: Can Generative Artificial Intelligence and Large Language Models be a Catalyst for Value-based Healthcare?",
        "authors": "Prakash Jayakumar, Koen D. Oude Nijhuis, Jacobien H. F. Oosterhoff, Kevin J. Bozic",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/corr.0000000000002854"
    },
    {
        "id": 12702,
        "title": "Systematic Review of Large Language Models for Patient Care: Current Applications and Challenges",
        "authors": "Felix Busch, Lena Hoffmann, Christopher Rueger, Elon HC van Dijk, Rawen Kader, Esteban Ortiz-Prado, Marcus R Makowski, Luca Saba, Martin Hadamitzky, Jakob Nikolas Kather, Daniel Truhn, Renato Cuocolo, Lisa C Adams, Keno K Bressem",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractThe introduction of large language models (LLMs) into clinical practice promises to improve patient education and empowerment, thereby personalizing medical care and broadening access to medical knowledge. Despite the popularity of LLMs, there is a significant gap in systematized information on their use in patient care. Therefore, this systematic review aims to synthesize current applications and limitations of LLMs in patient care using a data-driven convergent synthesis approach. We searched 5 databases for qualitative, quantitative, and mixed methods articles on LLMs in patient care published between 2022 and 2023. From 4,349 initial records, 89 studies across 29 medical specialties were included, primarily examining models based on the GPT-3.5 (53.2%, n=66 of 124 different LLMs examined per study) and GPT-4 (26.6%, n=33/124) architectures in medical question answering, followed by patient information generation, including medical text summarization or translation, and clinical documentation. Our analysis delineates two primary domains of LLM limitations: design and output. Design limitations included 6 second-order and 12 third-order codes, such as lack of medical domain optimization, data transparency, and accessibility issues, while output limitations included 9 second-order and 32 third-order codes, for example, non-reproducibility, non-comprehensiveness, incorrectness, unsafety, and bias. In conclusion, this study is the first review to systematically map LLM applications and limitations in patient care, providing a foundational framework and taxonomy for their implementation and evaluation in healthcare settings.",
        "link": "http://dx.doi.org/10.1101/2024.03.04.24303733"
    },
    {
        "id": 12703,
        "title": "Can Large Language Models Assess Personality from Asynchronous Video Interviews? A Comprehensive Evaluation of Validity, Reliability, Fairness, and Rating Patterns",
        "authors": "Tianyi Zhang, Antonis Koutsoumpis, Janneke K. Oostrom, Djurre Holtrop, Sina Ghassemi, Reinout E. de Vries",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/taffc.2024.3374875"
    },
    {
        "id": 12704,
        "title": "Structural and Topological Analysis of Homogeneous Models for a Large Robotic Control System",
        "authors": "I. S. Pavlovskiy",
        "published": "2020-9-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd49919.2020.9247690"
    },
    {
        "id": 12705,
        "title": "Leveraging Large Language Models for Automatic Hypotheses Testing over Heterogeneous Biological Databases",
        "authors": "Hasan M Jamil, Stephen A Krawetz, Alexander Gow",
        "published": "2023-9-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3584371.3613022"
    },
    {
        "id": 12706,
        "title": "Current Status and Prospects of Legal Mind Development using Large Language Models",
        "authors": "Kiryong Kyeong, Sang Yeob Lee, Soyeon Kim, Kyongseok In, WonSeok Ji, Dae Sik Hong",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.35505/sjlb.2023.12.13.3.3"
    },
    {
        "id": 12707,
        "title": "Improving Efficiencies While Also Delivering Better Health Care Outcomes: A Role for Large Language Models",
        "authors": "Shivdev K. Rao, Elliot K. Fishman, Ryan C. Rizk, Linda C. Chu, Steven P. Rowe",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jacr.2024.01.003"
    },
    {
        "id": 12708,
        "title": "An exploration of using large language models to integrate farmer behaviour into an agricultural systems model of the Peruvian Andes",
        "authors": "Joy Singarayer, Richard Bailey, Patrick McGuire, Francisco Araujo- Ferreira, Nicholas Branch, Fernando Gonzalez, Diana Santos Shupingahua, Douglas Walsh, Alexander Herrera, Andrew Wade, Harvey Rodda, Martin Timana, Kevin Lane",
        "published": "No Date",
        "citations": 0,
        "abstract": "The implications of climate change on agro-pastoral farming systems in the Peruvian Andes are not fully understood. There is already a significant impact on agricultural productivity from current climate variability and extreme weather in the region. This is exacerbated by chronic poverty in many rural areas and the need for improved government-led strategic planning. Tools to assist with policy planning for climate change adaptations that achieve environmental and social resilience are vital, and these require collaboration with rural communities to incorporate the complexities of behavioural responses to climate change, market dynamics, and policy shifts in agricultural and water management.&#160;\nIn this study we further develop a recent agricultural systems model (the TELLUS model; Pilditch et al., in review). The model is an agent-based simulation focussed on the behaviour of interacting populations of individual farming agents. TELLUS offers the opportunity to analyse the impact of interventions/policies in light of key scenarios and conditions of interest, with potential to uncover unforeseen emergent behaviours within farming systems (e.g., tipping points, amplifiers, system adaptations) and potential unintended consequences of scenarios and policies (e.g., increasing in equalities; increased system fragility). A difficulty in applying such models to specific case studies is in choosing valid parameter values, especially for model behaviour associated with human behaviour and decision-making.\nOur work over recent years includes extensive fieldwork in the Cordillera Negra and Cordillera Blanca, involving interviews and workshops with farming communities, and collaboration with regional NGOs. These interactions have been instrumental in understanding local challenges and priorities. The challenge in terms of modelling this system is turning information gained from qualitative methods (e.g. interviews) into parameter values for the model. Our novel approach is to assess the extent to which modern AI systems, specifically, Large Language Models (LLMs) can help perform this task. &#160;We leverage the reasoning abilities of LLMs to directly estimate relevant model parameters from automated interview transcription/translations. We will discuss the extent to which this integration has aided the creation of a TELLUS model tuned specifically to the Peruvian Andes context. Our approach will hopefully serve as a novel tool, combining empirical research, community involvement, and advanced computational modelling, to explore future climate scenarios and the potential effects of policy interventions.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-18078"
    },
    {
        "id": 12709,
        "title": "The Impact of AUTOGEN and Similar Fine-Tuned Large Language Models on the Integrity of Scholarly Writing",
        "authors": "David B. Resnik, Mohammad Hosseini",
        "published": "2023-10-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15265161.2023.2250276"
    },
    {
        "id": 12710,
        "title": "Do large language models know chemistry?",
        "authors": "Andrew D. White, Glen M. Hocky, Heta A. Gandhi, Mehrad Ansari, Sam Cox, Geemi P. Wellawatte, Subarna Sasmal, Ziyue Yang, Kangxin Liu, Yuvraj Singh, Willmor J. Peña Ccoa",
        "published": "No Date",
        "citations": 2,
        "abstract": "Mostly yes. We systematically evaluate machine learning large language models (LLMs) that generate code in the context of chemistry. We produce a benchmark set of problems, and evaluate these models based on correctness of code by automated testing and evaluation by experts. We find recent LLMs are able to write correct code across a variety of topics in chemistry and their accuracy can be increased by 30 percentage points via prompt engineering strategies, like putting copyright notices at the top of files. These dataset and evaluation tools are open source which can be contributed to or built upon by future researchers, and will serve as a community resource for evaluating the performance of new models as they emerge. We also describe some good practices for employing LLMs in chemistry. The general success of these models demonstrates that their impact on chemistry teaching and research is poised to be enormous.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2022-3md3n"
    },
    {
        "id": 12711,
        "title": "Fighting reviewer fatigue or amplifying bias? Considerations and recommendations for use of ChatGPT and other large language models in scholarly peer review",
        "authors": "Mohammad Hosseini, Serge P. J. M. Horbach",
        "published": "2023-5-18",
        "citations": 39,
        "abstract": "Abstract\nBackground\nThe emergence of systems based on large language models (LLMs) such as OpenAI’s ChatGPT has created a range of discussions in scholarly circles. Since LLMs generate grammatically correct and mostly relevant (yet sometimes outright wrong, irrelevant or biased) outputs in response to provided prompts, using them in various writing tasks including writing peer review reports could result in improved productivity. Given the significance of peer reviews in the existing scholarly publication landscape, exploring challenges and opportunities of using LLMs in peer review seems urgent. After the generation of the first scholarly outputs with LLMs, we anticipate that peer review reports too would be generated with the help of these systems. However, there are currently no guidelines on how these systems should be used in review tasks.\n\nMethods\nTo investigate the potential impact of using LLMs on the peer review process, we used five core themes within discussions about peer review suggested by Tennant and Ross-Hellauer. These include 1) reviewers’ role, 2) editors’ role, 3) functions and quality of peer reviews, 4) reproducibility, and 5) the social and epistemic functions of peer reviews. We provide a small-scale exploration of ChatGPT’s performance regarding identified issues.\n\nResults\nLLMs have the potential to substantially alter the role of both peer reviewers and editors. Through supporting both actors in efficiently writing constructive reports or decision letters, LLMs can facilitate higher quality review and address issues of review shortage. However, the fundamental opacity of LLMs’ training data, inner workings, data handling, and development processes raise concerns about potential biases, confidentiality and the reproducibility of review reports. Additionally, as editorial work has a prominent function in defining and shaping epistemic communities, as well as negotiating normative frameworks within such communities, partly outsourcing this work to LLMs might have unforeseen consequences for social and epistemic relations within academia. Regarding performance, we identified major enhancements in a short period and expect LLMs to continue developing.\n\nConclusions\nWe believe that LLMs are likely to have a profound impact on academia and scholarly communication. While potentially beneficial to the scholarly communication system, many uncertainties remain and their use is not without risks. In particular, concerns about the amplification of existing biases and inequalities in access to appropriate infrastructure warrant further attention. For the moment, we recommend that if LLMs are used to write scholarly reviews and decision letters, reviewers and editors should disclose their use and accept full responsibility for data security and confidentiality, and their reports’ accuracy, tone, reasoning and originality.\n",
        "link": "http://dx.doi.org/10.1186/s41073-023-00133-5"
    },
    {
        "id": 12712,
        "title": "Enhancing Korean Medicine Education with Large Language Models: Focusing on the Development of Educational Artificial Intelligence",
        "authors": "Sa-Yoon Park, Chang-Eop Kim",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15188/kjopp.2023.10.37.5.134"
    },
    {
        "id": 12713,
        "title": "Leveraging Large Language Models as Simulated Users for Initial, Low-Cost Evaluations of Designed Conversations",
        "authors": "Jan de Wit",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-54975-5_5"
    },
    {
        "id": 12714,
        "title": "ChatGPT and large language models in academia: opportunities and challenges",
        "authors": "Jesse G. Meyer, Ryan J. Urbanowicz, Patrick C. N. Martin, Karen O’Connor, Ruowang Li, Pei-Chen Peng, Tiffani J. Bright, Nicholas Tatonetti, Kyoung Jae Won, Graciela Gonzalez-Hernandez, Jason H. Moore",
        "published": "2023-7-13",
        "citations": 49,
        "abstract": "AbstractThe introduction of large language models (LLMs) that allow iterative “chat” in late 2022 is a paradigm shift that enables generation of text often indistinguishable from that written by humans. LLM-based chatbots have immense potential to improve academic work efficiency, but the ethical implications of their fair use and inherent bias must be considered. In this editorial, we discuss this technology from the academic’s perspective with regard to its limitations and utility for academic writing, education, and programming. We end with our stance with regard to using LLMs and chatbots in academia, which is summarized as (1) we must find ways to effectively use them, (2) their use does not constitute plagiarism (although they may produce plagiarized text), (3) we must quantify their bias, (4) users must be cautious of their poor accuracy, and (5) the future is bright for their application to research and as an academic tool.",
        "link": "http://dx.doi.org/10.1186/s13040-023-00339-9"
    },
    {
        "id": 12715,
        "title": "Exploring Capabilities of Large Language Models such as ChatGPT in Radiation Oncology",
        "authors": "Fabio Dennstädt, Janna Hastings, Paul Martin Putora, Erwin Vu, Galina F. Fischer, Krisztian Süveg, Markus Glatzer, Elena Riggenbach, Hông-Linh Hà, Nikola Cihoric",
        "published": "2024-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.adro.2023.101400"
    },
    {
        "id": 12716,
        "title": "A Generalizable Architecture for Explaining Robot Failures Using Behavior Trees and Large Language Models",
        "authors": "Christian Tagliamonte, Daniel Maccaline, Gregory LeMasurier, Holly A. Yanco",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3610978.3640551"
    },
    {
        "id": 12717,
        "title": "The Inconsistency Of Language Models",
        "authors": "Uralov Azamat Begnarovich,  ",
        "published": "2021-9-30",
        "citations": 0,
        "abstract": "The article deals with the problem of disproportion in morpheme units of linguistics and patterns. Based on the disproportion, information is given on the combined affixes formed in the morphemes, the expanded forms, and the analytic and synthetic forms. The data is based on the opinions of the world's leading linguists. The ideas are proven using examples. The formation of a particular linguistic model is a disproportion in the language system (meaning-function-methodological features): confusion of meanings, multifunctionality, semantics, competition in the use of forms (one form has more and more privileges, archaic nation of another form).",
        "link": "http://dx.doi.org/10.37547/tajssei/volume03issue09-09"
    },
    {
        "id": 12718,
        "title": "Building Hybrid Representations from Text Corpora, Knowledge Graphs, and Language Models",
        "authors": "Jose Manuel Gomez-Perez, Ronald Denaux, Andres Garcia-Silva",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-44830-1_6"
    },
    {
        "id": 12719,
        "title": "Additional Notes and References",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-016"
    },
    {
        "id": 12720,
        "title": "A Simple Survey of Pre-trained Language Models",
        "authors": "Zhenyi Zhu",
        "published": "No Date",
        "citations": 1,
        "abstract": "Pre-trained Language Models (PTLM) have remarkable and successful performance in solving lots of NLP tasks nowadays. And previous researchers have created many SOTA models and these models are included in many long surveys(Qiu et al., 2020). So, we would like to conduct a simple and short survey on this topic to help researchers understand the sketch of PTLM more quickly and comprehensively. In this short survey, we would provide a simple but comprehensive review of techniques, benchmarks, and methodologies in PTLM. And we would also introduce the applications evaluation of PTLM in this simple survey.",
        "link": "http://dx.doi.org/10.20944/preprints202208.0238.v1"
    },
    {
        "id": 12721,
        "title": "Application of Pretrained Language Models in Modern Financial Research",
        "authors": "Heungmin Lee",
        "published": "No Date",
        "citations": 0,
        "abstract": "In recent years, pretrained language models (PLMs) have emerged as a powerful tool for natural language processing (NLP) tasks. In this paper, we examine the potential of these models in the finance sector and the challenges they face in this domain. We also discuss the interpretability of these models and the ethical considerations associated with their deployment in finance. Our analysis shows that pretrained language models have the potential to revolutionize the way financial data is analyzed and processed. However, it is important to address the challenges and ethical considerations associated with their deployment to ensure that they are used in a responsible and accountable manner. Future research will focus on developing models that can handle the volatility of financial data, mitigate bias in the training data, and provide interpretable predictions. Overall, we believe that the future of AI in finance will be shaped by the continued development and deployment of pretrained language models.",
        "link": "http://dx.doi.org/10.31219/osf.io/5s3nw"
    },
    {
        "id": 12722,
        "title": "MetaText: Compositional Generalization in Deep Language Models",
        "authors": "Scott Howland, Jessica Yaros, Noriaki Kono",
        "published": "2022-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2172/1987883"
    },
    {
        "id": 12723,
        "title": "Multibody Models Generated from Natural Language",
        "authors": "Johannes Gerstmayr, Peter Manzl, Michael Pieber",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nComputational models are conventionally created with input data, script files, programming interfaces, or graphical user interfaces. This paper explores the potential of expanding model generation, with a focus on multibody system dynamics. In particular, we investigate the ability of Large Language Models (LLMs), to generate models from natural language. Our experimental findings indicate that LLMs, some of them having been trained on our multibody code Exudyn, surpass the mere replication of existing code examples. The results demonstrate that LLMs have a basic understanding of kinematics and dynamics, and that they can transfer this knowledge into a programming interface. Although our tests reveal that complex cases regularly result in programming or modeling errors, we found that LLMs can successfully generate correct multibody simulation models from natural language descriptions for simpler cases, often on the first attempt (zero-shot). Next to a basic introduction into the functionality of LLMs, our Python code, and the test setups, we provide a summarized evaluation for a series of examples with increasing complexity. We start with a single mass oscillator, both in SciPy as well as in Exudyn, and include varied inputs and statistical analysis to highlight the robustness of our approach. Hereafter, systems with mass points, constraints, and rigid bodies are evaluated. In particular, we show that in-context learning can levitate basic knowledge of a multibody code into a zero-shot correct output.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3552291/v1"
    },
    {
        "id": 12724,
        "title": "Exploring the relation between semantic complexity and quantifier distribution in large corpora",
        "authors": "Jakub Szymanik, Camilo Thorne",
        "published": "2017-3",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.langsci.2017.01.006"
    },
    {
        "id": 12725,
        "title": "Siamese networks for large-scale author identification",
        "authors": "Chakaveh Saedi, Mark Dras",
        "published": "2021-11",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2021.101241"
    },
    {
        "id": 12726,
        "title": "Predicting Violent Behavior using Language Agnostic Models",
        "authors": "Yingjie Liu, Gregory Wert, Benjamin Greenawald, Mohammad Al Boni, Donald E. Brown",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006933701020109"
    },
    {
        "id": 12727,
        "title": "Transformer-Based Language Models as Psycholinguistic Subjects: Focusing on Understanding Metaphor",
        "authors": "Wonil Chung,  ",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "Metaphor is a fundamental aspect of human language and cognition, playing a crucial role in communication, comprehension, and creative expression. In light of the recent advancements demonstrated by prominent language models, a pivotal question arises: Can these expansive language models effectively discern metaphorical knowledge? The primary objective involves comparing the surprisal values estimated from neural network language models like autoregressive and bidirectional language models to the reaction times of human when exposed to both metaphorical and literal sentences. Our secondary objective involves assessing the AI's comprehension of metaphors by utilizing the sensicality ratings generated by sophisticated ChatGPT. To achieve this, we used psycholinguistic methods, and adopted the experimental materials from Lai, Currana, and Menna (2009). We found the surprisal values estimated from the autoregressive language model demonstrate metaphor processing that closely resembles that of native speakers. Furthermore, ChatGPT's processing of conventional metaphorical sentences closely resembles its approach to literal sentences, mirroring the convergence observed in native speakers' ERP response to conventional metaphorical sentences and their alignment with that of literal sentences.",
        "link": "http://dx.doi.org/10.14342/smog.2023.119.87"
    },
    {
        "id": 12728,
        "title": "Chemical language models for de novo drug design: Challenges and opportunities",
        "authors": "Francesca Grisoni",
        "published": "No Date",
        "citations": 0,
        "abstract": "Generative deep learning is accelerating de novo drug design, by allowing the construction of molecules with desired properties on demand. Chemical language models – which generate new molecules in the form of strings – have been particularly successful in this endeavour. Thanks to advances in natural language processing methods and interdisciplinary collaborations, chemical language models are expected to become increasingly relevant in drug discovery. This minireview provides an overview of the current state-of-the-art of chemical language models for de novo design, and analyses current limitations, challenges, and advantages. Finally, a perspective on future opportunities is provided.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2022-5f14w"
    },
    {
        "id": 12729,
        "title": "Emotional Support Dialog System Through Recursive Interactions Among Large Language Models",
        "authors": "Keqi Chen, Huijun Lian, Yingming Gao, Ya Li",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-97-0601-3_13"
    },
    {
        "id": 12730,
        "title": "Letter to the editor concerning the article: “Artificial intelligence in clinical pharmacology: A case study and scoping review of large language models and bioweapon potential”",
        "authors": "Takashi Watari, Yasuharu Tokuda",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/bcp.15922"
    },
    {
        "id": 12731,
        "title": "Organizational preparedness for the use of large language models in pathology informatics",
        "authors": "Steven N. Hart, Noah G. Hoffman, Peter Gershkovich, Chancey Christenson, David S. McClintock, Lauren J. Miller, Ronald Jackups, Vahid Azimi, Nicholas Spies, Victor Brodsky",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jpi.2023.100338"
    },
    {
        "id": 12732,
        "title": "Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation With Large Language Models",
        "authors": "Hendrik Strobelt, Albert Webson, Victor Sanh, Benjamin Hoover, Johanna Beyer, Hanspeter Pfister, Alexander M. Rush",
        "published": "2022",
        "citations": 23,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tvcg.2022.3209479"
    },
    {
        "id": 12733,
        "title": "Creating Virtual Patients using Robots and Large Language Models: A Preliminary Study with Medical Students",
        "authors": "Alexander Borg, Ioannis Parodis, Gabriel Skantze",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3610978.3640592"
    },
    {
        "id": 12734,
        "title": "Leveraging Large Language Models for Decision Support in Personalized Oncology",
        "authors": "Manuela Benary, Xing David Wang, Max Schmidt, Dominik Soll, Georg Hilfenhaus, Mani Nassir, Christian Sigler, Maren Knödler, Ulrich Keller, Dieter Beule, Ulrich Keilholz, Ulf Leser, Damian T. Rieke",
        "published": "2023-11-17",
        "citations": 8,
        "abstract": "ImportanceClinical interpretation of complex biomarkers for precision oncology currently requires manual investigations of previous studies and databases. Conversational large language models (LLMs) might be beneficial as automated tools for assisting clinical decision-making.ObjectiveTo assess performance and define their role using 4 recent LLMs as support tools for precision oncology.Design, Setting, and ParticipantsThis diagnostic study examined 10 fictional cases of patients with advanced cancer with genetic alterations. Each case was submitted to 4 different LLMs (ChatGPT, Galactica, Perplexity, and BioMedLM) and 1 expert physician to identify personalized treatment options in 2023. Treatment options were masked and presented to a molecular tumor board (MTB), whose members rated the likelihood of a treatment option coming from an LLM on a scale from 0 to 10 (0, extremely unlikely; 10, extremely likely) and decided whether the treatment option was clinically useful.Main Outcomes and MeasuresNumber of treatment options, precision, recall, F1 score of LLMs compared with human experts, recognizability, and usefulness of recommendations.ResultsFor 10 fictional cancer patients (4 with lung cancer, 6 with other; median [IQR] 3.5 [3.0-4.8] molecular alterations per patient), a median (IQR) number of 4.0 (4.0-4.0) compared with 3.0 (3.0-5.0), 7.5 (4.3-9.8), 11.5 (7.8-13.0), and 13.0 (11.3-21.5) treatment options each was identified by the human expert and 4 LLMs, respectively. When considering the expert as a criterion standard, LLM-proposed treatment options reached F1 scores of 0.04, 0.17, 0.14, and 0.19 across all patients combined. Combining treatment options from different LLMs allowed a precision of 0.29 and a recall of 0.29 for an F1 score of 0.29. LLM-generated treatment options were recognized as AI-generated with a median (IQR) 7.5 (5.3-9.0) points in contrast to 2.0 (1.0-3.0) points for manually annotated cases. A crucial reason for identifying AI-generated treatment options was insufficient accompanying evidence. For each patient, at least 1 LLM generated a treatment option that was considered helpful by MTB members. Two unique useful treatment options (including 1 unique treatment strategy) were identified only by LLM.Conclusions and RelevanceIn this diagnostic study, treatment options of LLMs in precision oncology did not reach the quality and credibility of human experts; however, they generated helpful ideas that might have complemented established procedures. Considering technological progress, LLMs could play an increasingly important role in assisting with screening and selecting relevant biomedical literature to support evidence-based, personalized treatment decisions.",
        "link": "http://dx.doi.org/10.1001/jamanetworkopen.2023.43689"
    },
    {
        "id": 12735,
        "title": "Multi‐Word Expressions in Second Language Writing: A Large‐Scale Longitudinal Learner Corpus Study",
        "authors": "Anna Siyanova‐Chanturia, Stefania Spina",
        "published": "2020-6",
        "citations": 35,
        "abstract": "AbstractIn the present study, we sought to advance the field of learner corpus research by tracking the development of phrasal vocabulary in essays produced at two different points in time. To this aim, we employed a large pool of second language (L2) learners (N = 175) from three proficiency levels—beginner, elementary, and intermediate—and focused on an underrepresented L2 (Italian). Employing mixed‐effects models, a flexible and powerful tool for corpus data analysis, we analyzed learner combinations in terms of five different measures: phrase frequency, mutual information, lexical gravity, delta Pforward, and delta Pbackward. Our findings suggest a complex picture, in which higher proficiency and greater exposure to the L2 do not result in more idiomatic and targetlike output, and may, in fact, result in greater reliance on low frequency combinations whose constituent words are non‐associated or mutually attracted.",
        "link": "http://dx.doi.org/10.1111/lang.12383"
    },
    {
        "id": 12736,
        "title": "II. Explanations of Meaning",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-003"
    },
    {
        "id": 12737,
        "title": "What Can Language Models Tell us About Human Cognition?",
        "authors": "Louise Connell, Dermot Lynott",
        "published": "No Date",
        "citations": 0,
        "abstract": "Language models are a rapidly-developing field of artificial intelligence with enormous potential to improve our understanding of human cognition. However, many popular language models are cognitively implausible on multiple fronts. For language models to offer plausible insights into human cognitive processing, they should implement a transparent and cognitively-plausible learning mechanism, should train on a quantity of text that is achievable in a human lifetime of language exposure, and should not assume to represent all of word meaning. When care is taken to create plausible language models within these constraints, they can be a powerful tool in uncovering the nature and scope of how language shapes semantic knowledge. The distributional relationships between words, which humans represent in memory as linguistic distributional knowledge, allow people to represent and process semantic information flexibly, robustly, and efficiently.",
        "link": "http://dx.doi.org/10.31234/osf.io/sy4h9"
    },
    {
        "id": 12738,
        "title": "Incorporating Context into Language Encoding Models for fMRI",
        "authors": "Shailee Jain, Alexander G Huth",
        "published": "No Date",
        "citations": 56,
        "abstract": "AbstractLanguage encoding models help explain language processing in the human brain by learning functions that predict brain responses from the language stimuli that elicited them. Current word embedding-based approaches treat each stimulus word independently and thus ignore the influence of context on language understanding. In this work, we instead build encoding models using rich contextual representations derived from an LSTM language model. Our models show a significant improvement in encoding performance relative to state-of-the-art embeddings in nearly every brain area. By varying the amount of context used in the models and providing the models with distorted context, we show that this improvement is due to a combination of better word embeddings learned by the LSTM language model and contextual information. We are also able to use our models to map context sensitivity across the cortex. These results suggest that LSTM language models learn high-level representations that are related to representations in the human brain.",
        "link": "http://dx.doi.org/10.1101/327601"
    },
    {
        "id": 12739,
        "title": "AutoQIR: Auto-Encoding Questions with Retrieval Augmented Decoding for Unsupervised Passage Retrieval and Zero-shot Question Generation",
        "authors": "Stalin Varanasi,  , Muhammad Umer Butt, Günter Neumann,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_124"
    },
    {
        "id": 12740,
        "title": "An Artificial Language Evaluation of Distributional Semantic Models",
        "authors": "Fatemeh Torabi Asr, Michael Jones",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/k17-1015"
    },
    {
        "id": 12741,
        "title": "Weighted parsing for grammar-based language models",
        "authors": "Richard Mörbitz, Heiko Vogler",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-3108"
    },
    {
        "id": 12742,
        "title": "When Attention Meets Fast Recurrence: Training Language Models with Reduced Compute",
        "authors": "Tao Lei",
        "published": "2021",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.602"
    },
    {
        "id": 12743,
        "title": "Recurrent Neural Language Models as Probabilistic Finite-state Automata",
        "authors": "Anej Svete, Ryan Cotterell",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.502"
    },
    {
        "id": 12744,
        "title": "Are Compressed Language Models Less Subgroup Robust?",
        "authors": "Leonidas Gee, Andrea Zugarini, Novi Quadrianto",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.983"
    },
    {
        "id": 12745,
        "title": "Do Language Models Learn about Legal Entity Types during Pretraining?",
        "authors": "Claire Barale, Michael Rovatsos, Nehal Bhuta",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.nllp-1.4"
    },
    {
        "id": 12746,
        "title": "Gradient-based Constrained Sampling from Language Models",
        "authors": "Sachin Kumar, Biswajit Paria, Yulia Tsvetkov",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.144"
    },
    {
        "id": 12747,
        "title": "Using ChatGPT and Other Large Language Model (LLM) Applications for Academic Paper Assignments",
        "authors": "Andreas Jungherr",
        "published": "No Date",
        "citations": 5,
        "abstract": "Large language models (LLMs), like ChatGPT, GitHub Copilot, and Microsoft Copilot, present challenges in university education, particularly for paper assignments. These AI-driven tools enable students to (semi)automatically complete tasks that were previously considered evidence of skill acquisition, potentially affecting grading and skill development. However, the use of these tools is not legally considered plagiarism and is becoming increasingly integrated into various software solutions.University education in the social sciences aims to develop students' abilities to make sense of the world, connect their observations with abstract structures, measure phenomena of interest, systematically test expectations, and present findings in structured accounts. These practices are learned through repeated performance of tasks, such as writing research papers. LLM applications like ChatGPT create conflicting incentives for students, who might rely on them to produce parts of their papers instead of engaging in the learning process.While LLMs can be helpful tools for knowledge discovery, writing assistance, and coding assistance, using them effectively and safely requires an understanding of their underlying mechanisms, potential weaknesses, and enough domain knowledge to identify mistakes. This makes LLMs particularly challenging for students in the early stages of acquiring scientific skills and domain knowledge.Educators must enable and train students to responsibly use these new tools, reflecting on the underlying tensions and their strengths and weaknesses for academic writing tasks. This working paper aims to provide guidelines on responsible LLM use in academic contexts, specifically for students at the Chair for the Governance of Complex and Innovative Technological Systems at the University of Bamberg. The paper discusses the function of written paper assignments, the tasks necessary to complete them, and evaluates ChatGPT's performance in assisting with these tasks. It concludes with observations and advice for students to maximize the benefits of LLMs while mitigating potential risks in academic contexts, focusing on enabling learning.",
        "link": "http://dx.doi.org/10.31235/osf.io/d84q6"
    },
    {
        "id": 12748,
        "title": "TEACHING MODELS IN THE CONTEXT OF OVERCOMING THE LANGUAGE BARRIER",
        "authors": "I. Korytina",
        "published": "2022-2-24",
        "citations": 0,
        "abstract": "This study compares the models of passive, active and interactive teaching a foreign language and focuses on the educational task to overcome the language barrier by learners. Furthermore, it gives practical advice for educators to help students tackle communication problems through “Novelty of the Object principle”, “Ball Gaming”, a priority list and others. It emphasizes the three main aims of “Ball Gaming” such as the effect of unexpectedness provided by sparkling, musical and colorful balls, eradicating students’ phobias and blocks and preventing students from cheating as while catching and returning the object to the teacher or another student, it is impossible to be distracted. Moreover, the conducted research proves the specific aims of the passive, active and interactive teaching models and reveals the proportion of the most effective time consuming for them in the classroom environment. It also provides strategies for teachers contributing to encouraging shy and dyslexic students to communicate freely and avoid stress. The study also reveals the spheres of application of the above- mentioned models in the educational process when teaching the English language. More than that, the study points out the role of health care in the educational progress and, firstly, gives recommendations for dynamic interactive activities. Secondly, it emphasizes the role of hygiene providing washable visual tactile materials used in “Ball Gaming”. Finally, this research proves that interactive teaching is the most efficient model of education to help learners overcome the language barrier as the educator arranges the process using dialogues, polilogues and group work among the learners using dynamic pupil-centered activities. Following a logical combination of the above-mentioned models the educator could gain excellent results to explain, activate, practice, systematize and test the learning material and contribute to eradicating the language barrier by the learners.",
        "link": "http://dx.doi.org/10.35213/2686-7516-2021-2-2-5-9"
    },
    {
        "id": 12749,
        "title": "HinPLMs: Pre-trained Language Models for Hindi",
        "authors": "Xixuan Huang, Nankai Lin, Kexin Li, Lianxi Wang, Suifu Gan",
        "published": "2021-12-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ialp54817.2021.9675194"
    },
    {
        "id": 12750,
        "title": "Neural Network Models of Language Acquisition and Processing",
        "authors": "Stefan L. Frank, Padraic Monaghan, Chara Tsoukala",
        "published": "2019-10-29",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7551/mitpress/10841.003.0026"
    },
    {
        "id": 12751,
        "title": "Computational models of referring: A study in cognitive science by Kees van Deemter",
        "authors": "William S. Horton",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1353/lan.2017.0046"
    },
    {
        "id": 12752,
        "title": "Construction of Language Models for Uzbek Language",
        "authors": "N.S. Mamatov, N.A. Niyozmatova, A.N. Samijonov, B.N. Samijonov",
        "published": "2022-9-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icisct55600.2022.10146788"
    },
    {
        "id": 12753,
        "title": "Computational Models of Working Memory for Language",
        "authors": "Graham J. Hitch, Mark J. Hurlstone, Tom Hartley",
        "published": "2022-7-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108955638.011"
    },
    {
        "id": 12754,
        "title": "Fine-tuned Language Models are Continual Learners",
        "authors": "Thomas Scialom, Tuhin Chakrabarty, Smaranda Muresan",
        "published": "2022",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.410"
    },
    {
        "id": 12755,
        "title": "Classification of helical polymers with deep-learning language models",
        "authors": "Daoyi Li, Wen Jiang",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractMany macromolecules in biological systems exist in the form of helical polymers. However, the inherent polymorphism and heterogeneity of samples complicate the reconstruction of helical polymers from cryo-EM images. Currently available 2D classification methods are effective at separating particles of interest from contaminants, but they do not effectively differentiate between polymorphs, resulting in heterogeneity in the 2D classes. As such, it is crucial to develop a method that can computationally divide a dataset of polymorphic helical structures into homogenous subsets. In this work, we utilized deep-learning language models to embed the filaments as vectors in hyperspace and group them into clusters. Tests with both simulated and experimental datasets have demonstrated that our method – HLM (Helical classification withLanguageModel) can effectively distinguish different types of filaments, in the presence of many contaminants and low signal-to-noise ratios. We also demonstrate that HLM can isolate homogeneous subsets of particles from a publicly available dataset, resulting in the discovery of a previously unknown non-proteinaceous density around tau filaments.",
        "link": "http://dx.doi.org/10.1101/2023.07.28.550909"
    },
    {
        "id": 12756,
        "title": "On Pre-trained Language Models for Antibody",
        "authors": "Danqing Wang, Fei Ye, Zhou Hao",
        "published": "No Date",
        "citations": 4,
        "abstract": "AbstractAntibodies are vital proteins offering robust protection for the human body from pathogens. The development of general protein and antibody-specific pre-trained language models both facilitate antibody prediction tasks. However, few studies comprehensively explore the representation capability of distinct pre-trained language models on different antibody problems. Here, to investigate the problem, we aim to answer the following key questions: (1) How do pre-trained language models perform in antibody tasks with different specificity? (2) How many benefits will the model gain if we introduce the specific biological mechanism to the pre-training process? (3) Do the learned antibody pre-trained representations make sense in real-world antibody problems, like drug discovery and immune process understanding? Previously, no benchmark available largely hindered the study to answer these questions. To facilitate the investigation, we provide anAnTibodyUnderstandingEvaluation (ATUE) benchmark. We comprehensively evaluate the performance of protein pre-trained language models by empirical study along with conclusions and new insights. OurATUEand code is released athttps://github.com/dqwang122/EATLM.",
        "link": "http://dx.doi.org/10.1101/2023.01.29.525793"
    },
    {
        "id": 12757,
        "title": "How Much Can Vision Language Models Really ‘See’?",
        "authors": " ",
        "published": "No Date",
        "citations": 0,
        "abstract": "<strong> Exploring the potentials and limitations of Vision Language&nbsp;Models </strong> <strong> Author: </strong> <strong> Amanda Kau (ORCID: </strong> <strong> 0009–0004–4949–9284 </strong> <strong> ) </strong> The human brain is more extraordinary than any machine we could build. From an early age, many of us gain the ability to comprehend what our eyes tell us and articulate it. Furthermore, we combine evidence from all our senses to reason.",
        "link": "http://dx.doi.org/10.59350/zryt2-f3v34"
    },
    {
        "id": 12758,
        "title": "Contrastive Models for Turn-Taking in English and Japanese",
        "authors": "Davey Young",
        "published": "2018-5-1",
        "citations": 2,
        "abstract": "Turn-taking remains an underemphasized aspect of foreign language instruction. As more is understood about this central component of interactional competence, foreign language teachers will need to consider the best ways to teach students how to take turns speaking and managing the floor in the target language. This paper provides a brief outline of turn-taking mechanics as originally defined by Sacks, Schegloff, & Jefferson (1974) before providing contrastive models for turn-taking in English and Japanese. Some recommendations for classroom instruction targeting turn-taking for EFL students in Japan, as well as a call for greater sensitivity to this fundamental aspect of communicative competence, are also provided.\n\n外国語教育において、「話者交替」の重要性はまだ十分に注目されていない。相互行為能力の中心的構成要素である話者交替についての理解が深まるにつれ、外国語教育者は目標言語でどのように交替しながら話し、場の進行をすればいいかを教授するための最善の方法を考える必要が出てくるだろう。本論では、Sacks, Schegloff, & Jefferson (1974) によって定義された話者交替の働きについての概要を説明した後に、英語と日本語での話者交替の対照モデルについて述べる。日本の英語学習者に話者交替を教える際にクラス内で推奨されるいくつかの教授法と、話者交替というコミュニケーション能力の重要な一面に対するより細やかな配慮への必要性についても述べる。",
        "link": "http://dx.doi.org/10.37546/jalttlt42.3-2"
    },
    {
        "id": 12759,
        "title": "FastFormers: Highly Efficient Transformer Models for Natural Language Understanding",
        "authors": "Young Jin Kim, Hany Hassan",
        "published": "2020",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.sustainlp-1.20"
    },
    {
        "id": 12760,
        "title": "IV. Presupposition and Implication",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-005"
    },
    {
        "id": 12761,
        "title": "How Language Informs Mathematics",
        "authors": "Dirk Damsma",
        "published": "2020-1-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1163/9789004395497"
    },
    {
        "id": 12762,
        "title": "VIII. Making Something Happen",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-009"
    },
    {
        "id": 12763,
        "title": "Protein Language Models Expose Viral Mimicry and Immune Escape",
        "authors": "Dan Ofer, Michal Linial",
        "published": "No Date",
        "citations": 0,
        "abstract": "Motivation: Viruses elude the immune system through molecular mimicry, adopting biophysical characteristics of their host. We adapt protein language models (PLMs) to differentiate between human and viral proteins. Understanding where the immune system and our models make mistakes could reveal viral immune escape mechanisms.Results: We applied pretrained deep-learning PLMs to predict viral from human proteins. Our predictors show state-of-the-art results with AUC of 99.7%. We use interpretable error analysis models to characterize viral escapers. Altogether, mistakes account for 3.9% of the sequences with viral proteins being disproportionally misclassified. Analysis of external variables, including taxonomy and functional annotations, indicated that errors typically involve proteins with low immunogenic potential, viruses specific to human hosts, and those using reverse-transcriptase enzymes for their replication. Viral families causing chronic infections and immune evasion are further enriched and their protein mimicry potential is discussed. We provide insights into viral adaptation strategies and highlight the combined potential of PLMs and explainable AI in uncovering mechanisms of viral immune escape, contributing to vaccine design and antiviral research. Availability: https://github.com/ddofer/ProteinHumVir",
        "link": "http://dx.doi.org/10.1101/2024.03.14.585057"
    },
    {
        "id": 12764,
        "title": "MetaVL: Transferring In-Context Learning Ability From Language Models to Vision-Language Models",
        "authors": "Masoud Monajatipoor, Liunian Harold Li, Mozhdeh Rouhsedaghat, Lin Yang, Kai-Wei Chang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-short.43"
    },
    {
        "id": 12765,
        "title": "Models of Visual Perception in the Turkish Language Worldview",
        "authors": "Nigorakhon Saidgani kizi Amirova,  ",
        "published": "2023-3-25",
        "citations": 0,
        "abstract": "This article is devoted to the study of the mechanism of modeling visual perception in the Turkish language picture of the world. It should be noted that when modeling visual perception, a number of factors play a role, under the influence of which different models are formed. This explains the structure of a typical visual perception situation, which is presented as the basis of modeling.",
        "link": "http://dx.doi.org/10.47191/rajar/v9i3.03"
    },
    {
        "id": 12766,
        "title": "Analysing Discourse Knowledge in Pre-Trained Language Models: From Constructed Data to Deep Neural Networks",
        "authors": "Sharid Loáiciga",
        "published": "2022-11-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003205388-7"
    },
    {
        "id": 12767,
        "title": "Security Challenges in Natural Language Processing Models",
        "authors": "Qiongkai Xu, Xuanli He",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-tutorial.2"
    },
    {
        "id": 12768,
        "title": "The predictive capabilities of mathematical models for the type-token relationship in English language corpora",
        "authors": "Martin Tunnicliffe, Gordon Hunter",
        "published": "2021-11",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2021.101227"
    },
    {
        "id": 12769,
        "title": "Chapter 7. Formulaic language and Discourse Grammar",
        "authors": "Gunther Kaltenböck",
        "published": "2020-11-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/hcp.70.07kal"
    },
    {
        "id": 12770,
        "title": "3D-EX: A Unified Dataset of Definitions and Dictionary Examples",
        "authors": "Fatemah Almeman,  , Hadi Sheikhi, Luis Espinosa-Anke,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_008"
    },
    {
        "id": 12771,
        "title": "Looking for Traces of Textual Deepfakes in Bulgarian on Social Media",
        "authors": "Irina Temnikova,  , Iva Marinova, Silvia Gargova, Ruslana Margova, Ivan Koychev,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_122"
    },
    {
        "id": 12772,
        "title": "Use of Large Language Model for Cyberbullying Detection",
        "authors": "Bayode Ogunleye, Babitha Dharmaraj",
        "published": "No Date",
        "citations": 0,
        "abstract": "The dominance of social media has added to the channels of bullying to perpetrators. Unfortunately, cyberbullying (CB) is the most prevalent phenomenon in today’s cyber world and is a severe threat to the mental and physical health of citizens. This opens the need to develop a robust system to prevent bullying content from online forums, blogs, and social media platforms to manage the impact in our society. Several machine learning (ML) algorithms have been proposed for this purpose. However, their performances are not consistent due to high class imbalance issue and generalisation. In recent years, large language models (LLM) like BERT and RoBERTa have achieved state of the art (SOTA) results in several natural language processing (NLP) tasks. Unfortunately, the LLMs have not been applied extensively. In our paper, we explored the use of these models for cyberbullying (CB) detection. We have prepared a new dataset (D2) from existing studies (Formspring and Twitter). Our experimental results for dataset D1 and D2 showed RoBERTa outperformed other models.",
        "link": "http://dx.doi.org/10.20944/preprints202306.1075.v1"
    },
    {
        "id": 12773,
        "title": "Comparing Theory of Mind In Large Language Model and Human: Imagine Omniscient Power",
        "authors": "Mark Du",
        "published": "No Date",
        "citations": 0,
        "abstract": "The study of the theory of mind of artificial intelligence has raised lots of discussion. Large Language Models like GPT-4 has passed some test of theory of mind to test children. This study reviews another piece of literature that purpose another aspect of human reasoning in other people’s cognition: extraordinary minds like religious figures or people who possess the superpower to know everything. Our result shows that GPT-4 performs very much like human: GPT-4 thinks that people who know everything is more capable of performing tasks better than amateurs but less capable than experts. However, when the subject is a religious figure like a god, GPT-4 thinks god is less capable than amateurs, which is different from humans. This result indicates that GPT-4 has less ability to anthropomorphize some abstract beings. We suggest that GPT-4’s knowledge of religion, imagination, and the ability to understand and interpret the mental states of others, such as beliefs, intentions, and desires, has some restrictions.",
        "link": "http://dx.doi.org/10.31234/osf.io/zu3rw"
    },
    {
        "id": 12774,
        "title": "Whole Genome Sequencing-based digital twin as a clinical decision support system: in-born disease risks and pharmacogenomics with Large Language Model",
        "authors": "Sijung Yun",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14293/gof.23.09"
    },
    {
        "id": 12775,
        "title": "Analysis of Resource-efficient Predictive Models for Natural Language Processing",
        "authors": "Raj Pranesh, Ambesh Shekhar",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.sustainlp-1.18"
    },
    {
        "id": 12776,
        "title": "Numeracy enhances the Literacy of Language Models",
        "authors": "Avijit Thawani, Jay Pujara, Filip Ilievski",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.557"
    },
    {
        "id": 12777,
        "title": "Does language help generalization in vision models?",
        "authors": "Benjamin Devillers, Bhavin Choksi, Romain Bielawski, Rufin VanRullen",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.conll-1.13"
    },
    {
        "id": 12778,
        "title": "Natural Language Processing Embedding Research and Application in Speech Recognition Models and NLP Models - Presentation Slides",
        "authors": "James Mou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4392217"
    },
    {
        "id": 12779,
        "title": "Linguistics in an English Language Arts Class",
        "authors": "Beth Keyser",
        "published": "2019-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678-9"
    },
    {
        "id": 12780,
        "title": "On Gender Biases in Offensive Language Classification Models",
        "authors": "Sanjana Marcé, Adam Poliak",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gebnlp-1.19"
    },
    {
        "id": 12781,
        "title": "DARE(ing) Language Ideologies",
        "authors": "Kelly D. Abrams, Trini Stickle",
        "published": "2019-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678-16"
    },
    {
        "id": 12782,
        "title": "Enriching Language Models with Visually-grounded Word Vectors and the Lancaster Sensorimotor Norms",
        "authors": "Casey Kennington",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.conll-1.11"
    },
    {
        "id": 12783,
        "title": "Towards Automatic Generation of Shareable Synthetic Clinical Notes Using Neural Language Models",
        "authors": "Oren Melamud, Chaitanya Shivade",
        "published": "2019",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-1905"
    },
    {
        "id": 12784,
        "title": "Editing Factual Knowledge in Language Models",
        "authors": "Nicola De Cao, Wilker Aziz, Ivan Titov",
        "published": "2021",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.522"
    },
    {
        "id": 12785,
        "title": "Categorising Fine-to-Coarse Grained Misinformation: An Empirical Study of the COVID-19 Infodemic",
        "authors": "Ye Jiang,  , Xingyi Song, Carolina Scarton, Iknoor Singh, Ahmet Aker, Kalina Bontcheva,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_061"
    },
    {
        "id": 12786,
        "title": "Semi-Supervised Neural Text Generation by Joint Learning of Natural Language Generation and Natural Language Understanding Models",
        "authors": "Raheel Qader, François Portet, Cyril Labbé",
        "published": "2019",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-8669"
    },
    {
        "id": 12787,
        "title": "Improving Aspect-Based Sentiment with End-to-End Semantic Role Labeling Model",
        "authors": "Pavel Přibáň,  , Ondřej Pražák,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_096"
    },
    {
        "id": 12788,
        "title": "A large-scale comparison of cross-situational word learning models",
        "authors": "George Kachergis, Michael C. Frank",
        "published": "No Date",
        "citations": 1,
        "abstract": "One problem language learners face is extracting word meanings from scenes with many possible referents. Despite the ambiguity of individual situations, a large body of empirical work shows that people are able to learn cross-situationally when a word occurs in different situations. Many computational models of cross-situational word learning have been proposed, yet there is little consensus on the main mechanisms supporting learning, in part due to the profusion of disparate studies and models, and lack of systematic model comparisons across a wide range of studies. This study compares the performance of several extant models on a dataset of 44 experimental conditions and a total of 1,696 participants. Using cross-validation, we fit multiple models representing theories of both associative learning and hypothesis-testing theories of word learning, find two best-fitting models, and discuss issues of model and mechanism identifiability. Finally, we test the models’ ability to generalize to additional experiments, including developmental data.",
        "link": "http://dx.doi.org/10.31234/osf.io/4um9k"
    },
    {
        "id": 12789,
        "title": "Large Decision Models",
        "authors": "Weinan Zhang",
        "published": "2023-8",
        "citations": 0,
        "abstract": "Over recent decades, sequential decision-making tasks are mostly tackled with expert systems and reinforcement learning. However, these methods are still incapable of being generalizable enough to solve new tasks at a low cost. In this article, we discuss a novel paradigm that leverages Transformer-based sequence models to tackle decision-making tasks, named large decision models. Starting from offline reinforcement learning scenarios, early attempts demonstrate that sequential modeling methods can be applied to train an effective policy given sufficient expert trajectories. When the sequence model goes large, its generalization ability over a variety of tasks and fast adaptation to new tasks has been observed, which is highly potential to enable the agent to achieve artificial general intelligence for sequential decision-making in the near future.",
        "link": "http://dx.doi.org/10.24963/ijcai.2023/808"
    },
    {
        "id": 12790,
        "title": "4. Teacher Cases: Implementing DLBE with Fidelity or Language Separation in a Bilingual Context",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781788928106-005"
    },
    {
        "id": 12791,
        "title": "An evaluation on large language model outputs: Discourse and memorization",
        "authors": "Adrian de Wynter, Xun Wang, Alex Sokolov, Qilong Gu, Si-Qing Chen",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.nlp.2023.100024"
    },
    {
        "id": 12792,
        "title": "Give Us the Facts: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling",
        "authors": "Linyao Yang, Hongyang Chen, Zhao Li, Xiao Ding, Xindong Wu",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tkde.2024.3360454"
    },
    {
        "id": 12793,
        "title": "Introduction",
        "authors": "Dan Chen, Lizhe Wang, Jingying Chen",
        "published": "2017-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b11883-1"
    },
    {
        "id": 12794,
        "title": "BAYESIAN MODELS FOR TESTING LARGE GROUPS OF SERVICE DEVICES",
        "authors": "",
        "published": "2018-3-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14357/19922264180113"
    },
    {
        "id": 12795,
        "title": "Large-Scale Models of the Olfactory Bulb",
        "authors": "Francesco Cavarretta",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-0716-1006-0_100664"
    },
    {
        "id": 12796,
        "title": "Inference for Large Dimensional Factor Models Under General Missing Data Patterns",
        "authors": "Liangjun Su, Fa Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4721159"
    },
    {
        "id": 12797,
        "title": "Neural network--based closure models for large--eddy simulations with explicit filtering",
        "authors": "Mark Benjamin, Gianluca Iaccarino",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26226/m.64c26777632e9539aa87d671"
    },
    {
        "id": 12798,
        "title": "Global Robust Bayesian Analysis in Large Models",
        "authors": "Paul Ho",
        "published": "No Date",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3452643"
    },
    {
        "id": 12799,
        "title": "Effect size measures for multilevel models: definition, interpretation, and TIMSS example",
        "authors": "Julie Lorah",
        "published": "2018-12",
        "citations": 350,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s40536-018-0061-2"
    },
    {
        "id": 12800,
        "title": "SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models",
        "authors": "Shanshan Zhong, Zhongzhan Huang, Weushao Wen, Jinghui Qin, Liang Lin",
        "published": "2023-10-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3581783.3611863"
    },
    {
        "id": 12801,
        "title": "Global Epidemic of Noxious Phytoplankton Blooms and Food Chain Consequences in Large Ecosystems",
        "authors": "Theodore Smayda",
        "published": "2019-5-20",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429042423-13"
    },
    {
        "id": 12802,
        "title": "Comparing Native and Learner Englishes Using a Large Pre-trained Language Model",
        "authors": "Tatsuya Aoyama",
        "published": "2022-12-2",
        "citations": 0,
        "abstract": "The use of lexical items by L2 speakers of English has been analyzed through a variety of methods; however, they are either (i) infeasible for a large-scale learner corpus study or (ii) designed to measure vocabulary breadth, rather than depth. This paper presents the preliminary results of an ongoing work to utilize contextualized word embeddings (CWEs) obtained from a large pre-trained language model to measure the depth of L2 speakers’ vocabulary knowledge, operationalized as how similar L2 speakers’ use of a given word is to that of L1 speakers’. We find that (i) the mean distance between L1 CWEs and L2 CWEs of a given word tends to decrease as the proficiency level becomes higher, and that (ii) while words that have similar CWEs in the L1 corpus and L2 corpus tend to reveal interesting properties about the word use, words that have dissimilar CWEs in the two corpora often suffer from domain effects.",
        "link": "http://dx.doi.org/10.3384/ecp190001"
    },
    {
        "id": 12803,
        "title": "Industrial Challenges in Large Thermally Enabled Structural Whole Engine Models",
        "authors": "Michelle Tindall, Andrew Layton, Akin Keskin",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1115/1.0002794v"
    },
    {
        "id": 12804,
        "title": "Proceedings of the 1st Workshop on Large Generative Models Meet Multimodal Applications",
        "authors": "",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3607827"
    },
    {
        "id": 12805,
        "title": "Large language model augmented exercise retrieval for personalized language learning",
        "authors": "Austin Xu, Will Monroe, Klinton Bicknell",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3636555.3636883"
    },
    {
        "id": 12806,
        "title": "DzNER: A large Algerian Named Entity Recognition dataset",
        "authors": "Abdelhalim Hafedh Dahou, Mohamed Amine Cheragui",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.nlp.2023.100005"
    },
    {
        "id": 12807,
        "title": "Exploring Bias Evaluation Techniques for Quantifying Large Language Model Biases",
        "authors": "Junheng He, Nankai Lin, Menglan Shen, Dong Zhou, Aimin Yang",
        "published": "2023-11-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ialp61005.2023.10337300"
    },
    {
        "id": 12808,
        "title": "Decision making in large-scale language testing: Intersections of policy, practice and research",
        "authors": "Yan Jin,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "In this article, I delve into the intricacies of strategic decision making when a large-scale language test is reformed. Adopting a case study approach, I examine the activities involved in the reform of the College English Test (CET), an English language test for university students administered nationwide in the Chinese mainland (Zhang, 2022; Zheng & Cheng, 2008). In its 30+-year history, the CET has undergone several revisions and reforms (see Jin, 2010; 2020 for an overview). To illustrate how the major policies on test revision and reform have been formulated and implemented in this particular context, I present a brief overview of some major decisions that have been made over the decades. Through these cases, I hope to demonstrate the intricate interactions among policy intentions, professional requirements, ethical considerations, practical constraints, as well as the role of language testing professionals when strategic decisions are made to ensure a sustainable and healthy development of large-scale and high-stakes language tests.",
        "link": "http://dx.doi.org/10.58379/hkkx5020"
    },
    {
        "id": 12809,
        "title": "Application of Cognitive Diagnosis Models in Korean Language Assessment",
        "authors": " choi suk ki",
        "published": "2017-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26589/jockle..62.201706.41"
    },
    {
        "id": 12810,
        "title": "WavPrompt: Towards Few-Shot Spoken Language Understanding with Frozen Language Models",
        "authors": "Heting Gao, Junrui Ni, Kaizhi Qian, Yang Zhang, Shiyu Chang, Mark Hasegawa-Johnson",
        "published": "2022-9-18",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2022-11031"
    },
    {
        "id": 12811,
        "title": "Low-resource Taxonomy Enrichment with Pretrained Language Models",
        "authors": "Kunihiro Takeoka, Kosuke Akimoto, Masafumi Oyamada",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.217"
    },
    {
        "id": 12812,
        "title": "Characterizing Verbatim Short-Term Memory in Neural Language Models",
        "authors": "Kristijan Armeni, Christopher Honey, Tal Linzen",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.conll-1.28"
    },
    {
        "id": 12813,
        "title": "ON INTERCULTURAL COMMUNICATIVE MODELS IN  LANGUAGE LEARNING",
        "authors": "Reni Manova",
        "published": "2021-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7546/pibl.xxxiv.21.11"
    },
    {
        "id": 12814,
        "title": "Neural Word Decomposition Models for Abusive Language Detection",
        "authors": "Sravan Bodapati, Spandana Gella, Kasturi Bhattacharjee, Yaser Al-Onaizan",
        "published": "2019",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-3515"
    },
    {
        "id": 12815,
        "title": "Measuring Harmful Representations in Scandinavian Language Models",
        "authors": "Samia Touileb, Debora Nozza",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.nlpcss-1.13"
    },
    {
        "id": 12816,
        "title": "Sentence Bottleneck Autoencoders from Transformer Language Models",
        "authors": "Ivan Montero, Nikolaos Pappas, Noah A. Smith",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.137"
    },
    {
        "id": 12817,
        "title": "Neurobiological Causal Models of Language Processing",
        "authors": "Hartmut Fitz, Peter Hagoort, Karl Magnus Petersson",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "Abstract\nThe language faculty is physically realized in the neurobiological infrastructure of the human brain. Despite significant efforts, an integrated understanding of this system remains a formidable challenge. What is missing from most theoretical accounts is a specification of the neural mechanisms that implement language function. Computational models that have been put forward generally lack an explicit neurobiological foundation. We propose a neurobiologically informed causal modeling approach which offers a framework for how to bridge this gap. A neurobiological causal model is a mechanistic description of language processing that is grounded in, and constrained by, the characteristics of the neurobiological substrate. It intends to model the generators of language behavior at the level of implementational causality. We describe key features and neurobiological component parts from which causal models can be built and provide guidelines on how to implement them in model simulations. Then we outline how this approach can shed new light on the core computational machinery for language, the long-term storage of words in the mental lexicon and combinatorial processing in sentence comprehension. In contrast to cognitive theories of behavior, causal models are formulated in the “machine language” of neurobiology which is universal to human cognition. We argue that neurobiological causal modeling should be pursued in addition to existing approaches. Eventually, this approach will allow us to develop an explicit computational neurobiology of language.",
        "link": "http://dx.doi.org/10.1162/nol_a_00133"
    },
    {
        "id": 12818,
        "title": "Large numbers and statistics in Easy Language news",
        "authors": "Andrej Tomažin",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.57088/978-3-7329-9026-9_3"
    },
    {
        "id": 12819,
        "title": "Pre-Trained Language Models Augmented with Synthetic Scanpaths for Natural Language Understanding",
        "authors": "Shuwen Deng, Paul Prasse, David Reich, Tobias Scheffer, Lena Jäger",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.400"
    },
    {
        "id": 12820,
        "title": "On Language Models for Creoles",
        "authors": "Heather Lent, Emanuele Bugliarello, Miryam de Lhoneux, Chen Qiu, Anders Søgaard",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.conll-1.5"
    },
    {
        "id": 12821,
        "title": "Sociolectal Analysis of Pretrained Language Models",
        "authors": "Sheng Zhang, Xin Zhang, Weiming Zhang, Anders Søgaard",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.375"
    },
    {
        "id": 12822,
        "title": "Innovative Bert-Based Reranking Language Models for Speech Recognition",
        "authors": "Shih-Hsuan Chiu, Berlin Chen",
        "published": "2021-1-19",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt48900.2021.9383557"
    },
    {
        "id": 12823,
        "title": "Toward Computational Models of Multilingual Sentence Processing",
        "authors": "Stefan L. Frank",
        "published": "2021-3",
        "citations": 3,
        "abstract": "AbstractAlthough computational models can simulate aspects of human sentence processing, research on this topic has remained almost exclusively limited to the single language case. The current review presents an overview of the state of the art in computational cognitive models of sentence processing, and discusses how recent sentence‐processing models can be used to study bi‐ and multilingualism. Recent results from cognitive modeling and computational linguistics suggest that phenomena specific to bilingualism can emerge from systems that have no dedicated components for handling multiple languages. Hence, accounting for human bi‐/multilingualism may not require models that are much more sophisticated than those for the monolingual case.",
        "link": "http://dx.doi.org/10.1111/lang.12406"
    },
    {
        "id": 12824,
        "title": "Exploring the use of large language models (LLMs) in chemical engineering education: Building core course problem models with Chat-GPT",
        "authors": "Meng-Lin Tsai, Chong Wei Ong, Cheng-Liang Chen",
        "published": "2023-7",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ece.2023.05.001"
    },
    {
        "id": 12825,
        "title": "Trans-/Multilingual Language in Different Contexts",
        "authors": "Verbra Pfeiffer",
        "published": "2021-12-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003124665-13"
    },
    {
        "id": 12826,
        "title": "Bayesian Grammar Models",
        "authors": "Shay Cohen",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-02170-1_8"
    },
    {
        "id": 12827,
        "title": "Distilling Relation Embeddings from Pretrained Language Models",
        "authors": "Asahi Ushio, Jose Camacho-Collados, Steven Schockaert",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.712"
    },
    {
        "id": 12828,
        "title": "Injecting structural hints: Using language models to study inductive biases in language learning",
        "authors": "Isabel Papadimitriou, Dan Jurafsky",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.563"
    },
    {
        "id": 12829,
        "title": "Unnatural language processing: How do language models handle machine-generated prompts?",
        "authors": "Corentin Kervadec, Francesca Franzon, Marco Baroni",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.959"
    },
    {
        "id": 12830,
        "title": "Characterizing Mechanisms for Factual Recall in Language Models",
        "authors": "Qinan Yu, Jack Merullo, Ellie Pavlick",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.615"
    },
    {
        "id": 12831,
        "title": "Math Word Problem Generation with Multilingual Language Models",
        "authors": "Kashyapa Niyarepola, Dineth Athapaththu, Savindu Ekanayake, Surangika Ranathunga",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.inlg-main.12"
    },
    {
        "id": 12832,
        "title": "Key Issues and Future Directions: Models of Human Language and Speech Processing",
        "authors": "Willem Zuidema, Hartmut Fitz",
        "published": "2019-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7551/mitpress/10841.003.0031"
    },
    {
        "id": 12833,
        "title": "Language Models",
        "authors": "Kumiko Tanaka-Ishii",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-59377-3_17"
    },
    {
        "id": 12834,
        "title": "From goals and outcomes to program models and characteristics",
        "authors": "Diane J. Tedick, Roy Lyster",
        "published": "2019-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429428319-3"
    },
    {
        "id": 12835,
        "title": "Humans and language models diverge when predicting repeating text",
        "authors": "Aditya Vaidya, Javier Turek, Alexander Huth",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-1.5"
    },
    {
        "id": 12836,
        "title": "Using Transfer-based Language Models to Detect Hateful and Offensive Language Online",
        "authors": "Vebjørn Isaksen, Björn Gambäck",
        "published": "2020",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.alw-1.3"
    },
    {
        "id": 12837,
        "title": "Domain Adaptation of Low-Resource Target-Domain Models Using Well-Trained ASR Conformer Models",
        "authors": "Vrunda N. Sukhadia, S. Umesh",
        "published": "2023-1-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt54892.2023.10023233"
    },
    {
        "id": 12838,
        "title": "Types of role models for Korean language education and direction of introduction of role models in Korean language education",
        "authors": "Kyung-mi Cha",
        "published": "2021-4-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22251/jlcci.2021.21.8.83"
    },
    {
        "id": 12839,
        "title": "Three Models of English Morphology",
        "authors": "Barli Bram",
        "published": "2017-1-10",
        "citations": 0,
        "abstract": "This paper explores models of English morphology, namely Item and Arrangement (IA), Item and Process (IP), and Word and Paradigm (WP), which can be used to analyze morphological data, particularly word formation involving prefixes and suffixes. Sample data, consisting of complex words or words having more than one morpheme, were analyzed using the three models to discover their strengths and shortcomings. In order to find out the differences between the three models of morphology, it is important that the current writer should examine strategies for distinguishing between derivational affixes and inflectional ones. There exist three advantages if morphologists know very well the three models of English morphology. First is that IA fails to display a clear sequence of the item and arrangement when dealing with some irregular plural nouns and irregular past tense. Second is that IP offers a better solution to irregular plural nouns, such as mice and men. Third is that WP appears to be the most efficient model when dealing with inflectional morphology.DOI:https://doi.org/10.24071/llt.2012.150105",
        "link": "http://dx.doi.org/10.24071/llt.v15i1.316"
    },
    {
        "id": 12840,
        "title": "Probing Task-Oriented Dialogue Representation from Language Models",
        "authors": "Chien-Sheng Wu, Caiming Xiong",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.409"
    },
    {
        "id": 12841,
        "title": "Relational World Knowledge Representation in Contextual Language Models: A Review",
        "authors": "Tara Safavi, Danai Koutra",
        "published": "2021",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.81"
    },
    {
        "id": 12842,
        "title": "Controlling Pre-trained Language Models for Grade-Specific Text Simplification",
        "authors": "Sweta Agrawal, Marine Carpuat",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.790"
    },
    {
        "id": 12843,
        "title": "Innovative efficiency models in foreign language communication: lifelong learning and multiculturalism",
        "authors": "Oksana Chaika, Natalia Sharmanova",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15587/978-617-7319-70-1.ch3"
    },
    {
        "id": 12844,
        "title": "Use of Large Language Models and Artificial Intelligence Tools in Works Submitted to <i>Journal of Clinical Oncology</i>",
        "authors": "Kathy Miller, Emilie Gunn, Angela Cochran, Hal Burstein, Jonathan W. Friedberg, Stephanie Wheeler, Paul Frankel",
        "published": "2023-7-1",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1200/jco.23.00819"
    },
    {
        "id": 12845,
        "title": "Forecasting Chinese Overnight Stock Index Movement Using Large Language Models with Market Summary",
        "authors": "Haiping Wang, Xin Zhou",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-97-0837-6_4"
    },
    {
        "id": 12846,
        "title": "ChatGPT goes to the operating room: evaluating GPT-4 performance and its potential in surgical education and training in the era of large language models",
        "authors": "Namkee Oh, Gyu-Seong Choi, Woo Yong Lee",
        "published": "2023",
        "citations": 50,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4174/astr.2023.104.5.269"
    },
    {
        "id": 12847,
        "title": "Comparative Analysis for Open-Source Large Language Models",
        "authors": "Amir Schur, Sam Groenjes",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-49215-0_7"
    },
    {
        "id": 12848,
        "title": "Using fine-tuned large language models to parse clinical notes in musculoskeletal pain disorders",
        "authors": "Akhil Vaid, Isotta Landi, Girish Nadkarni, Ismail Nabeel",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00202-9"
    },
    {
        "id": 12849,
        "title": "A comparative analysis of knowledge injection strategies for large language models in the scholarly domain",
        "authors": "Andrea Cadeddu, Alessandro Chessa, Vincenzo De Leo, Gianni Fenu, Enrico Motta, Francesco Osborne, Diego Reforgiato Recupero, Angelo Salatino, Luca Secchi",
        "published": "2024-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.engappai.2024.108166"
    },
    {
        "id": 12850,
        "title": "Query Generation Using Large Language Models",
        "authors": "David Rau, Jaap Kamps",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-56066-8_19"
    },
    {
        "id": 12851,
        "title": "Towards Human-Like Educational Question Generation with Large Language Models",
        "authors": "Zichao Wang, Jakob Valdez, Debshila Basu Mallick, Richard G. Baraniuk",
        "published": "2022",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-11644-5_13"
    },
    {
        "id": 12852,
        "title": "Exploring the Integration of Large Language Models into Automatic Speech Recognition Systems: An Empirical Study",
        "authors": "Zeping Min, Jinbo Wang",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-8181-6_6"
    },
    {
        "id": 12853,
        "title": "“What It Wants Me To Say”: Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models",
        "authors": "Michael Xieyang Liu, Advait Sarkar, Carina Negreanu, Benjamin Zorn, Jack Williams, Neil Toronto, Andrew D. Gordon",
        "published": "2023-4-19",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3544548.3580817"
    },
    {
        "id": 12854,
        "title": "Enhancing Antibody Language Models with Structural Information",
        "authors": "Justin Barton, Jacob D. Galson, Jinwoo Leem",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractThe central tenet of molecular biology is that a protein’s amino acid sequence determines its three-dimensional structure, and thus its function. However, proteins with similar sequences do not always fold into the same shape, and vice-versa, dissimilar sequences can adopt similar folds. In this work, we explore antibodies, a class of proteins in the immune system, whose local shapes are highly unpredictable, even with small variations in their sequence. Inspired by the CLIP method [1], we propose a multimodal contrastive learning approach, contrastive sequence-structure pre-training (CSSP), which amalgamates the representations of antibody sequences and structures in a mutual latent space. Integrating structural information leads both antibody and protein language models to show better correspondence with structural similarity and improves accuracy and data efficiency in downstream binding prediction tasks. We provide an optimised CSSP-trained model, AntiBERTa2-CSSP, for non-commercial use athttps://huggingface.co/alchemab.",
        "link": "http://dx.doi.org/10.1101/2023.12.12.569610"
    },
    {
        "id": 12855,
        "title": "Predicative Language Models",
        "authors": "Peng Wang, David B. Sawyer",
        "published": "2023-2-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003321538-5"
    },
    {
        "id": 12856,
        "title": "XI. Can Induction Be Vindicated?",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-012"
    },
    {
        "id": 12857,
        "title": "Adolescent Language: Models, Assessment, and Links to Reading",
        "authors": "Amanda Goodwin, Yaacov Petscher, Jamie Tock",
        "published": "No Date",
        "citations": 3,
        "abstract": "Various models have highlighted the complexity of language. Building on foundational ideas regarding three key aspects of language, our study contributes to the literature by 1) exploring broader conceptions of morphology, vocabulary, and syntax, 2) operationalizing this theoretical model into a gamified, standardized, computer-adaptive assessment of language for fifth to eighth grade students entitled Monster, PI, and 3) uncovering further evidence regarding the relationship between language and standardized reading comprehension via this assessment. Multiple-group item response theory (IRT) across grades show that morphology was best fit by a bifactor model of task specific factors along with a global factor related to each skill. Vocabulary was best fit by a bifactor model that identifies performance overall and on specific words.  Syntax, though, was best fit by a unidimensional model.  Next, Monster, PI produced reliable scores suggesting language can be assessed efficiently and precisely for students via this model. Lastly, performance on Monster, PI explained more than 50% of variance in standardized reading, suggesting operationalizing language via Monster, PI can provide meaningful understandings of the relationship between language and reading comprehension. Specifically, considering just a subset of a construct, like identification of units of meaning, explained significantly less variance in reading comprehension. This highlights the importance of considering these broader constructs. Implications indicate that future work should consider a model of language where component areas are considered broadly and contributions to reading comprehension are explored via general performance on components as well as skill level performance.",
        "link": "http://dx.doi.org/10.35542/osf.io/pf5y8"
    },
    {
        "id": 12858,
        "title": "Pretrained Language Models as Containers of the Discursive Knowledge",
        "authors": "Rafal Maciag",
        "published": "2024-1-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3390/cmsf2023008093"
    },
    {
        "id": 12859,
        "title": "Improved Training Of Neural Trans-Dimensional Random field Language Models with Dynamic Noise-Contrastive Estimation",
        "authors": "Bin Wang, Zhijian Ou",
        "published": "2018-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt.2018.8639591"
    },
    {
        "id": 12860,
        "title": "AutoTrial: Prompting Language Models for Clinical Trial Design",
        "authors": "Zifeng Wang, Cao Xiao, Jimeng Sun",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.766"
    },
    {
        "id": 12861,
        "title": "Adapting Language Models to Compress Contexts",
        "authors": "Alexis Chevalier, Alexander Wettig, Anirudh Ajith, Danqi Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.232"
    },
    {
        "id": 12862,
        "title": "Reducing Non-Normative Text Generation from Language Models",
        "authors": "Xiangyu Peng, Siyan Li, Spencer Frazier, Mark Riedl",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.inlg-1.43"
    },
    {
        "id": 12863,
        "title": "Evaluating the Robustness of Neural Language Models to Input Perturbations",
        "authors": "Milad Moradi, Matthias Samwald",
        "published": "2021",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.117"
    },
    {
        "id": 12864,
        "title": "Improving Biomedical Pretrained Language Models with Knowledge",
        "authors": "Zheng Yuan, Yijia Liu, Chuanqi Tan, Songfang Huang, Fei Huang",
        "published": "2021",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.bionlp-1.20"
    },
    {
        "id": 12865,
        "title": "X. The \"Direction” of Time",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-011"
    },
    {
        "id": 12866,
        "title": "Models, Fictions and Artifacts",
        "authors": "Tarja Knuuttila",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-60537-7_7"
    },
    {
        "id": 12867,
        "title": "V. Necessary Statements and Rules",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-006"
    },
    {
        "id": 12868,
        "title": "Applications of Psychometric Methods to Neuropsychological Models of Speech and Language",
        "authors": "Grant M. Walker",
        "published": "No Date",
        "citations": 0,
        "abstract": "This chapter addresses how to use measurement models to assess impairments of speech and language processing abilities. In keeping with the theme of the book, the chapter focuses on how the tension between the psychometrist’s goal of measuring a single, latent dimension can be reconciled with the neuropsychologist’s goal of identifying multiple, dissociable dimensions of impairment. Although the field of speech and language neuropsychology research is quite broad, covering both developmental and acquired disorders, this chapter constrains its focus to investigations of stroke-induced aphasia.",
        "link": "http://dx.doi.org/10.31234/osf.io/ypzv5"
    },
    {
        "id": 12869,
        "title": "Neural Language Codes for Multilingual Acoustic Models",
        "authors": "Markus Müller, Sebastian Stüker, Alex Waibel",
        "published": "2018-9-2",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2018-1241"
    },
    {
        "id": 12870,
        "title": "What can we gain from language models for morphological inflection?",
        "authors": "Alexey Sorokin",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/k18-3012"
    },
    {
        "id": 12871,
        "title": "Adversarial Attacks on Protein Language Models",
        "authors": "Ginevra Carbone, Francesca Cuturello, Luca Bortolussi, Alberto Cazzaniga",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractDeep Learning models for protein structure prediction, such as AlphaFold2, leverage Transformer architectures and their attention mechanism to capture structural and functional properties of amino acid sequences. Despite the high accuracy of predictions, biologically insignificant perturbations of the input sequences, or even single point mutations, can lead to substantially different 3d structures. On the other hand, protein language models are often insensitive to biologically relevant mutations that induce misfolding or dysfunction (e.g. missense mutations). Precisely, predictions of the 3d coordinates do not reveal the structure-disruptive effect of these mutations. Therefore, there is an evident inconsistency between the biological importance of mutations and the resulting change in structural prediction. Inspired by this problem, we introduce the concept of adversarial perturbation of protein sequences in continuous embedding spaces of protein language models. Our method relies on attention scores to detect the most vulnerable amino acid positions in the input sequences.Adversarial mutationsare biologically diverse from their references and are able to significantly alter the resulting 3d structures.",
        "link": "http://dx.doi.org/10.1101/2022.10.24.513465"
    },
    {
        "id": 12872,
        "title": "Comparing Prominent Generative Language Models for Classifying Political Alignment Of Limited Context Bigrams",
        "authors": "Sankalp Singh",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.58445/rars.510"
    },
    {
        "id": 12873,
        "title": "Models of Learning in Language Teaching",
        "authors": "Abdülkadir Kırbaş, Ekrem Öbüz",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "Language is the most crucial component of lifelong learning and development in the information age we live in. Every person can execute tasks like reading, writing, understanding, asking questions, thinking, and solving problems because of language. Language is the primary instrument of mental, emotional, and social growth. Language has a crucial role in a variety of functions, including conveying culture, engaging, expressing emotions and thoughts, and communicating. Examining various approaches and models used in the language learning process is part of the idea of \"learning models\" in language teaching. A range of techniques are employed to enhance pupils' language proficiency using language learning models. These models incorporate variables and pedagogical practices that impact language acquisition. The foundational subject in language instruction, Turkish, is a flexible course that fosters language proficiency, increases awareness of the student's home tongue, and has tight connections to other courses. This characteristic has made adopting a wide range of approaches and strategies in classroom applications crucial. It will be more effective to use a variety of methods rather than a single method or technique in the curriculum when the methods and techniques used to achieve educational goals are essential. This will help students learn their native language and develop language awareness when teaching languages. The approach taken and the exercises conducted when instructing students in the curriculum's units and chosen subjects are crucial in determining whether or not children exhibit the anticipated behavioral changes and, consequently, in meeting learning objectives. To assist students in achieving their objectives in both in-class and extracurricular education and training activities, teachers must develop and put into practice strategies, tactics, and activities. The pursuit of understanding which circumstances best facilitate learning has led educators to develop new approaches to teaching and learning. Throughout history, every learning model has either supported or challenged the development of the other learning model. Different learning models have been discovered as a result of the quest for answers to issues like what makes learning successful, which factors are more active, and under what circumstances education fulfills its purpose. This study covers a variety of modern learning models and explains their role and significance in teaching Turkish and other languages. These models include constructivist learning, brain-based learning, active learning, cooperative learning, project-based learning, multiple intelligence learning, and mastery learning.",
        "link": "http://dx.doi.org/10.58830/ozgur.pub382.c1683"
    },
    {
        "id": 12874,
        "title": "VI. The Analysis of Rules",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-007"
    },
    {
        "id": 12875,
        "title": "LMPred: Predicting Antimicrobial Peptides Using Pre-Trained Language Models and Deep Learning",
        "authors": "William Dee",
        "published": "No Date",
        "citations": 0,
        "abstract": "Antimicrobial peptides (AMPs) are increasingly being used in the development of new therapeutic drugs, in areas such as cancer therapy and hypertension. Additionally, they are seen as an alternative to antibiotics due to the increasing occurrence of bacterial resistance. Wet-laboratory experimental identification, however, is both time consuming and costly, so in-silico models are now commonly used in order to screen new AMP candidates. This paper proposes a novel approach of creating model inputs; using pre-trained language models to produce contextualized embeddings representing the amino acids within each peptide sequence, before a convolutional neural network is then trained as the classifier. The optimal model was validated on two datasets, being one previously used in AMP prediction research, and an independent dataset, created by this paper. Predictive accuracies of 93.33% and 88.26% were achieved respectively, outperforming all previous state-of-the-art classification models.",
        "link": "http://dx.doi.org/10.1101/2021.11.03.467066"
    },
    {
        "id": 12876,
        "title": "Comparative Evaluation of Transformer-Based Nepali Language Models",
        "authors": "Suyogya Ratna Tamrakar, Chaklam Silpasuwanchai",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nLarge pre-trained transformer models using self-supervised learning have achieved state-of-the-art performances in various NLP tasks. However, for low-resource language like Nepali, pre-training of monolingual models remains a problem due to lack of training data and well-designed and balanced benchmark datasets. Furthermore, several multilingual pre-trained models such as mBERT and XLM-RoBERTa have been released, but their performance remains unknown for Nepali language. We compared Nepali monolingual pre-trained transformer models with multilingual models to determine their performance using a Nepali text classification dataset as a downstream task based on different number of classes and data sizes, taking machine learning (ML) and deep learning (DL) algorithms as baselines. Under-representation of Nepali language in mBERT resulted in overall poor performance, but, XLM-RoBERTa, which has a larger vocabulary size, produced state-of-the-art performance which is relatively similar to that of Nepali DistilBERT and DeBERTa, which outperformed all of the baseline algorithms. Bi-LSTM and SVM from the baselines also performed very well in variety of settings. Moreover, to assess the cross-language knowledge transfer for the cases when mono-lingual models are not available, we also evaluated HindiRoBERTa, a monolingual Indian language model on Nepali text dataset. This research mainly contributes to the Nepali NLP community by creation of news classification dataset with 20 classes, with over 200,000 articles and performance evaluation of various pre-trained monolingual Nepali transformers with multilingual transformers, DL and ML algorithms.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2289743/v1"
    },
    {
        "id": 12877,
        "title": "Relational Models for Language Learning",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1632/jsoz3408"
    },
    {
        "id": 12878,
        "title": "From Static to Recursive: Transforming Prompts for Enhanced Language Models",
        "authors": "Shashi Prakash Tripathi",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIn the dynamic field of Natural Language Processing (NLP), a revolutionary paradigm shift known as Large Language models has emerged. This research article embarks on exploration of Prompt Engineering, unveiling its innovative techniques, confronting its challenges, and highlighting its transformative impact on NLP applications. The proposed prompt engineering which is Recursive Prompt Engineering (RPE) redefines conventional prompt engineering, providing NLP models with the ability to iteratively refine responses. Through carefully designed experiments and real-world applications, we showcase RPE’s ability to enhance performance in language generation, question answering, and sentiment analysis. However, this journey into uncharted territory uncovers formidable challenges, including issues related to data diversity, scalability, and model interpretability. These challenges, while illuminating, also serve as stepping stones toward further innovation. Traditional evaluation methods prove inadequate, prompting us to introduce novel evaluation metrics that capture the essence of recursive adaptability. Our work sets the stage for redefining the criteria for measuring RPE’s effectiveness. In presenting this work, we envision a future where RPE reshapes the NLP landscape. As Recursive Prompt Engineering leads us to uncharted frontiers in NLP, opening doors to unprecedented possibilities and innovation. This article serves as a guiding beacon in this new era of NLP exploration.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3639349/v1"
    },
    {
        "id": 12879,
        "title": "Deeper understanding of In-Context Retrieval-Augmented Language Models",
        "authors": " ",
        "published": "No Date",
        "citations": 0,
        "abstract": "<strong> Transformative Advances in Language Models through External Knowledge Integration </strong> <strong> Author: </strong> Qingqin Fang(0009–0003–5348–4264) <strong> <strong> Introduction </strong> </strong> In the dynamic field of natural language processing, the integration of external knowledge has emerged as a pivotal strategy for enhancing the performance of language models.",
        "link": "http://dx.doi.org/10.59350/ch3em-a4h27"
    },
    {
        "id": 12880,
        "title": "Predictive Yield Models and Food Chain Theory",
        "authors": "A. A. Rosenberg, M. Basson, J. R. Beddington",
        "published": "2019-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429042423-9"
    },
    {
        "id": 12881,
        "title": "Diversifying Knowledge Enhancement of Biomedical Language Models Using Adapter Modules and Knowledge Graphs",
        "authors": "Juraj Vladika, Alexander Fichtl, Florian Matthes",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012395200003636"
    },
    {
        "id": 12882,
        "title": "SFE-AI at SemEval-2022 Task 11: Low-Resource Named Entity Recognition using Large Pre-trained Language Models",
        "authors": "Changyu Hou, Jun Wang, Yixuan Qiao, Peng Jiang, Peng Gao, Guotong Xie, Qizhi Lin, Xiaopeng Wang, Xiandi Jiang, Benqi Wang, Qifeng Xiao",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.semeval-1.219"
    },
    {
        "id": 12883,
        "title": "Harnessing Large Language Models for Research Institutions: an example based on NASA / JPL use-cases",
        "authors": "Steffen Mauceri, Asitang Mishra, Ryan M Mcgranaghan, Ashish A Mahabal, Lukas Mandrake, Benjamin Smith, Dustin J Graf, Benjamin Nuerenberger, Alice R Yepremyan, Brian Wilson, Amanda Towler, Kay Y Pak, Miles B Pellazar, Daniel J Crichton",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22541/essoar.170365296.68396998/v1"
    },
    {
        "id": 12884,
        "title": "Evaluating capabilities of large language models: Performance of GPT-4 on surgical knowledge assessments",
        "authors": "Brendin R. Beaulieu-Jones, Margaret T. Berrigan, Sahaj Shah, Jayson S. Marwaha, Shuo-Lun Lai, Gabriel A. Brat",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.surg.2023.12.014"
    },
    {
        "id": 12885,
        "title": "Modeling Structure‐Building in the Brain With CCG Parsing and Large Language Models",
        "authors": "Miloš Stanojević, Jonathan R. Brennan, Donald Dunagan, Mark Steedman, John T. Hale",
        "published": "2023-7",
        "citations": 4,
        "abstract": "AbstractTo model behavioral and neural correlates of language comprehension in naturalistic environments, researchers have turned to broad‐coverage tools from natural‐language processing and machine learning. Where syntactic structure is explicitly modeled, prior work has relied predominantly on context‐free grammars (CFGs), yet such formalisms are not sufficiently expressive for human languages. Combinatory categorial grammars (CCGs) are sufficiently expressive directly compositional models of grammar with flexible constituency that affords incremental interpretation. In this work, we evaluate whether a more expressive CCG provides a better model than a CFG for human neural signals collected with functional magnetic resonance imaging (fMRI) while participants listen to an audiobook story. We further test between variants of CCG that differ in how they handle optional adjuncts. These evaluations are carried out against a baseline that includes estimates of next‐word predictability from a transformer neural network language model. Such a comparison reveals unique contributions of CCG structure‐building predominantly in the left posterior temporal lobe: CCG‐derived measures offer a superior fit to neural signals compared to those derived from a CFG. These effects are spatially distinct from bilateral superior temporal effects that are unique to predictability. Neural effects for structure‐building are thus separable from predictability during naturalistic listening, and those effects are best characterized by a grammar whose expressive power is motivated on independent linguistic grounds.",
        "link": "http://dx.doi.org/10.1111/cogs.13312"
    },
    {
        "id": 12886,
        "title": "Automated Category and Trend Analysis of Scientific Articles Using Large Language Models: An Application in Ophthalmology (Preprint)",
        "authors": "hina Raja, Asim Munawar, Nikolaos Mylonas, Mohammad Delsoz., Yeganeh Madadi, Mohammad Elahi, Amr Hassan, Hashem Abu Serhan, Onur Inam, Luis Hermandez, Hao Chen, Sang Tran, Wuqas Munir, Alaa Abd-Alrazaq, Siamak Yousefi.",
        "published": "No Date",
        "citations": 1,
        "abstract": "\nBACKGROUND\n-\n\n\nOBJECTIVE\nIn this paper, we present an automated method for article classification, leveraging the power of Large Language Models (LLM). The primary focus is on the field of ophthalmology, but the model is extendable to other fields.\n\n\nMETHODS\nWe have developed a model based on Natural Language Processing (NLP) techniques, including advanced LLMs, to process and analyze the textual content of scientific papers. Specifically, we have employed zero-shot learning (ZSL) LLM models and compared against Bidirectional and Auto-Regressive Transformers (BART) and its variants, and Bidirectional Encoder Representations from Transformers (BERT), and its variant such as distilBERT, SciBERT, PubmedBERT, BioBERT.\n\n\nRESULTS\nThe classification results demonstrate the effectiveness of LLMs in categorizing the large number of ophthalmology papers without human intervention.   To evaluate the LLMs, we compiled a dataset (RenD) of 1000 ocular disease-related articles, which were expertly annotated by a panel of six specialists into 15 distinct categories. The model achieved a mean accuracy of 0.86 and a mean F1 of 0.85 based on the RenD dataset.\n\n\nCONCLUSIONS\nThe proposed framework achieves notable improvements in both accuracy and efficiency. Its application in the domain of ophthalmology showcases its potential for knowledge organization and retrieval in other domains too. We performed trend analysis that enables the researchers and clinicians to easily categorize and retrieve relevant papers, saving time and effort in literature review and information gathering as well as identification of emerging scientific trends within different disciplines. Moreover, the extendibility of the model to other scientific fields broadens its impact in facilitating research and trend analysis across diverse disciplines.\n",
        "link": "http://dx.doi.org/10.2196/preprints.52462"
    },
    {
        "id": 12887,
        "title": "Evaluating the Performance of Different Large Language Models on Health Consultation and Patient Education in Urolithiasis",
        "authors": "Haifeng Song, Yi Xia, Zhichao Luo, Hui Liu, Yan Song, Xue Zeng, Tianjie Li, Guangxin Zhong, Jianxing Li, Ming Chen, Guangyuan Zhang, Bo Xiao",
        "published": "2023-11-24",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10916-023-02021-3"
    },
    {
        "id": 12888,
        "title": "Sentiment analysis of online responses in the performing arts with large language models",
        "authors": "Baekryun Seong, Kyungwoo Song",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.heliyon.2023.e22457"
    },
    {
        "id": 12889,
        "title": "Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries",
        "authors": "Yinlin Deng, Chunqiu Steven Xia, Chenyuan Yang, Shizhuo Dylan Zhang, Shujing Yang, Lingming Zhang",
        "published": "2024-2-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3597503.3623343"
    },
    {
        "id": 12890,
        "title": "Playing Story Creation Games with Large Language Models: Experiments with GPT-3.5",
        "authors": "Timothy S. Wang, Andrew S. Gordon",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-47658-7_28"
    },
    {
        "id": 12891,
        "title": "Variable Discovery with Large Language Models for Metamorphic Testing of Scientific Software",
        "authors": "Christos Tsigkanos, Pooja Rani, Sebastian Müller, Timo Kehrer",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-35995-8_23"
    },
    {
        "id": 12892,
        "title": "Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair",
        "authors": "Yuxiang Wei, Chunqiu Steven Xia, Lingming Zhang",
        "published": "2023-11-30",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3611643.3616271"
    },
    {
        "id": 12893,
        "title": "Fine-Tuning Large Enterprise Language Models via Ontological Reasoning",
        "authors": "Teodoro Baldazzi, Luigi Bellomarini, Stefano Ceri, Andrea Colombo, Andrea Gentili, Emanuel Sallinger",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-45072-3_6"
    },
    {
        "id": 12894,
        "title": "Harnessing large language models (LLMs) for candidate gene prioritization and selection",
        "authors": "Mohammed Toufiq, Darawan Rinchai, Eleonore Bettacchioli, Basirudeen Syed Ahamed Kabeer, Taushif Khan, Bishesh Subba, Olivia White, Marina Yurieva, Joshy George, Noemie Jourde-Chiche, Laurent Chiche, Karolina Palucka, Damien Chaussabel",
        "published": "2023-10-16",
        "citations": 2,
        "abstract": "Abstract\nBackground\nFeature selection is a critical step for translating advances afforded by systems-scale molecular profiling into actionable clinical insights. While data-driven methods are commonly utilized for selecting candidate genes, knowledge-driven methods must contend with the challenge of efficiently sifting through extensive volumes of biomedical information. This work aimed to assess the utility of large language models (LLMs) for knowledge-driven gene prioritization and selection.\n\nMethods\nIn this proof of concept, we focused on 11 blood transcriptional modules associated with an Erythroid cells signature. We evaluated four leading LLMs across multiple tasks. Next, we established a workflow leveraging LLMs. The steps consisted of: (1) Selecting one of the 11 modules; (2) Identifying functional convergences among constituent genes using the LLMs; (3) Scoring candidate genes across six criteria capturing the gene’s biological and clinical relevance; (4) Prioritizing candidate genes and summarizing justifications; (5) Fact-checking justifications and identifying supporting references; (6) Selecting a top candidate gene based on validated scoring justifications; and (7) Factoring in transcriptome profiling data to finalize the selection of the top candidate gene.\n\nResults\nOf the four LLMs evaluated, OpenAI's GPT-4 and Anthropic's Claude demonstrated the best performance and were chosen for the implementation of the candidate gene prioritization and selection workflow. This workflow was run in parallel for each of the 11 erythroid cell modules by participants in a data mining workshop. Module M9.2 served as an illustrative use case. The 30 candidate genes forming this module were assessed, and the top five scoring genes were identified as BCL2L1, ALAS2, SLC4A1, CA1, and FECH. Researchers carefully fact-checked the summarized scoring justifications, after which the LLMs were prompted to select a top candidate based on this information. GPT-4 initially chose BCL2L1, while Claude selected ALAS2. When transcriptional profiling data from three reference datasets were provided for additional context, GPT-4 revised its initial choice to ALAS2, whereas Claude reaffirmed its original selection for this module.\n\nConclusions\nTaken together, our findings highlight the ability of LLMs to prioritize candidate genes with minimal human intervention. This suggests the potential of this technology to boost productivity, especially for tasks that require leveraging extensive biomedical knowledge.\n",
        "link": "http://dx.doi.org/10.1186/s12967-023-04576-8"
    },
    {
        "id": 12895,
        "title": "Sasha",
        "authors": "Evan King, Haoxiang Yu, Sangsu Lee, Christine Julien",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "Smart home assistants function best when user commands are direct and well-specified---e.g., \"turn on the kitchen light\"---or when a hard-coded routine specifies the response. In more natural communication, however, human speech is unconstrained, often describing goals (e.g., \"make it cozy in here\" or \"help me save energy\") rather than indicating specific target devices and actions to take on those devices. Current systems fail to understand these under-specified commands since they cannot reason about devices and settings as they relate to human situations. We introduce large language models (LLMs) to this problem space, exploring their use for controlling devices and creating automation routines in response to under-specified user commands in smart homes. We empirically study the baseline quality and failure modes of LLM-created action plans with a survey of age-diverse users. We find that LLMs can reason creatively to achieve challenging goals, but they experience patterns of failure that diminish their usefulness. We address these gaps with Sasha, a smarter smart home assistant. Sasha responds to loosely-constrained commands like \"make it cozy\" or \"help me sleep better\" by executing plans to achieve user goals---e.g., setting a mood with available devices, or devising automation routines. We implement and evaluate Sasha in a hands-on user study, showing the capabilities and limitations of LLM-driven smart homes when faced with unconstrained user-generated scenarios.",
        "link": "http://dx.doi.org/10.1145/3643505"
    },
    {
        "id": 12896,
        "title": "A Study Case of Automatic Archival Research and Compilation using Large Language Models",
        "authors": "Dongsheng Guo, Aizhen Yue, Fanggang Ning, Dengrong Huang, Bingxin Chang, Qiang Duan, Lianchao Zhang, Zhaoliang Chen, Zheng Zhang, Enhao Zhan, Qilai Zhang, Kai Jiang, Rui Li, Shaoxiang Zhao, Zizhong Wei",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ickg59574.2023.00012"
    },
    {
        "id": 12897,
        "title": "Assessing the Proficiency and Possibility of Use of Large Language Models in the Field of Knowledge of Ocular Surface Diseases",
        "authors": "Zi-Song Xu, Wei-Wei Chen, Yan-Mei Zeng, Qi Hong, Xian-Zhe Qian, Jin-Yu Hu, Hong Wei, Jie Zou, Cheng Chen, Xiao-Yu Wang, Xu Chen, Yi Shao",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4738711"
    },
    {
        "id": 12898,
        "title": "Artificial Intelligence for Anesthesiology Board–Style Examination Questions: Role of Large Language Models",
        "authors": "Adnan A. Khan, Rayaan Yunus, Mahad Sohail, Taha A. Rehman, Shirin Saeed, Yifan Bu, Cullen D. Jackson, Aidan Sharkey, Feroze Mahmood, Robina Matyal",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1053/j.jvca.2024.01.032"
    },
    {
        "id": 12899,
        "title": "Mutant Texts: A Technique for Uncovering Unexpected Inconsistencies in Large-Scale Vision-Language Models",
        "authors": "Mingliang Liang, Zhouran Liu, Martha Larson",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-53302-0_16"
    },
    {
        "id": 12900,
        "title": "HIDING CRITICAL INFORMATION WHEN TRAINING LANGUAGE MODELS",
        "authors": "A. Evtushenko",
        "published": "2021-6-14",
        "citations": 0,
        "abstract": "Machine learning language models are combinations of algorithms and neural networks designed for text processing composed in natural language (Natural Language Processing, NLP). \r\nIn 2020, the largest language model from the artificial intelligence research company OpenAI, GPT-3, was released, the maximum number of parameters of which reaches 175 billion. The parameterization of the model increased by more than 100 times made it possible to improve the quality of generated texts to a level that is hard to distinguish from human-written texts. It is noteworthy that this model was trained on a training dataset mainly collected from open sources on the Internet, the volume of which is estimated at 570 GB. \r\nThis article discusses the problem of memorizing critical information, in particular, personal data of individual, at the stage of training large language models (GPT-2/3 and derivatives), and also describes an algorithmic approach to solving this problem, which consists in additional preprocessing training dataset and refinement of the model inference in the context of generating pseudo-personal data and embedding into the results of work on the tasks of summarization, text generation, formation of answers to questions and others from the field of seq2seq.",
        "link": "http://dx.doi.org/10.31618/esu.2413-9335.2021.1.86.1349"
    },
    {
        "id": 12901,
        "title": "Harnessing large language models (LLMs) for candidate gene prioritization and selection",
        "authors": "Mohammed Toufiq, Darawan Rinchai, Eleonore Bettacchioli, Basirudeen Syed Ahamed Kabeer, Taushif Khan, Bishesh Subba, Olivia White, Marina Yurieva, Joshy George, Noemie Jourde-Chiche, Laurent Chiche, Karolina Palucka, Damien Chaussabel",
        "published": "2023-10-16",
        "citations": 2,
        "abstract": "Abstract\nBackground\nFeature selection is a critical step for translating advances afforded by systems-scale molecular profiling into actionable clinical insights. While data-driven methods are commonly utilized for selecting candidate genes, knowledge-driven methods must contend with the challenge of efficiently sifting through extensive volumes of biomedical information. This work aimed to assess the utility of large language models (LLMs) for knowledge-driven gene prioritization and selection.\n\nMethods\nIn this proof of concept, we focused on 11 blood transcriptional modules associated with an Erythroid cells signature. We evaluated four leading LLMs across multiple tasks. Next, we established a workflow leveraging LLMs. The steps consisted of: (1) Selecting one of the 11 modules; (2) Identifying functional convergences among constituent genes using the LLMs; (3) Scoring candidate genes across six criteria capturing the gene’s biological and clinical relevance; (4) Prioritizing candidate genes and summarizing justifications; (5) Fact-checking justifications and identifying supporting references; (6) Selecting a top candidate gene based on validated scoring justifications; and (7) Factoring in transcriptome profiling data to finalize the selection of the top candidate gene.\n\nResults\nOf the four LLMs evaluated, OpenAI's GPT-4 and Anthropic's Claude demonstrated the best performance and were chosen for the implementation of the candidate gene prioritization and selection workflow. This workflow was run in parallel for each of the 11 erythroid cell modules by participants in a data mining workshop. Module M9.2 served as an illustrative use case. The 30 candidate genes forming this module were assessed, and the top five scoring genes were identified as BCL2L1, ALAS2, SLC4A1, CA1, and FECH. Researchers carefully fact-checked the summarized scoring justifications, after which the LLMs were prompted to select a top candidate based on this information. GPT-4 initially chose BCL2L1, while Claude selected ALAS2. When transcriptional profiling data from three reference datasets were provided for additional context, GPT-4 revised its initial choice to ALAS2, whereas Claude reaffirmed its original selection for this module.\n\nConclusions\nTaken together, our findings highlight the ability of LLMs to prioritize candidate genes with minimal human intervention. This suggests the potential of this technology to boost productivity, especially for tasks that require leveraging extensive biomedical knowledge.\n",
        "link": "http://dx.doi.org/10.1186/s12967-023-04576-8"
    },
    {
        "id": 12902,
        "title": "Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries",
        "authors": "Yinlin Deng, Chunqiu Steven Xia, Chenyuan Yang, Shizhuo Dylan Zhang, Shujing Yang, Lingming Zhang",
        "published": "2024-2-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3597503.3623343"
    },
    {
        "id": 12903,
        "title": "Sentiment analysis of online responses in the performing arts with large language models",
        "authors": "Baekryun Seong, Kyungwoo Song",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.heliyon.2023.e22457"
    },
    {
        "id": 12904,
        "title": "2. Just Figures?: Forensic Clairvoyance,Mathematics, and the Language Question",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9780822394440-004"
    },
    {
        "id": 12905,
        "title": "GPU-Based WFST Decoding with Extra Large Language Model",
        "authors": "Daisuke Fukunaga, Yoshiki Tanaka, Yuichi Kageyama",
        "published": "2019-9-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2019-2101"
    },
    {
        "id": 12906,
        "title": "Automated scoring of junior and senior high essays using Coh-Metrix features: Implications for large-scale language testing",
        "authors": "Syed Latifi, Mark Gierl",
        "published": "2021-1",
        "citations": 23,
        "abstract": " An automated essay scoring (AES) program is a software system that uses techniques from corpus and computational linguistics and machine learning to grade essays. In this study, we aimed to describe and evaluate particular language features of Coh-Metrix for a novel AES program that would score junior and senior high school students’ essays from their large-scale assessments. Specifically, we studied nine categories of Coh-Metrix features for developing prompt-specific AES scoring models for our sample. We developed the models by capitalizing on the nine features’ informativeness as a function of dimensionality reduction. We used a three-staged scoring framework. The machine scores were validated against a “gold standard” of ratings, that is, those assigned by two human raters. The nine language features reliably captured the construct of the students’ writing quality. We performed a secondary analysis to see how the scoring models performed in relation to other, already established AES systems, and there was no systematic pattern of scoring discrepancy. However, for essays with widely divergent human ratings, the scoring models were disadvantaged owing to the inherent unreliability of the human scores. ",
        "link": "http://dx.doi.org/10.1177/0265532220929918"
    },
    {
        "id": 12907,
        "title": "Predictors of second language English lexical recognition: Further insights from a large database of second language lexical decision times",
        "authors": "Stephen Skalicky, Scott Crossley, Cynthia M. Berger",
        "published": "No Date",
        "citations": 0,
        "abstract": "In this study we analyze a large database of lexical decision times for English content words made by speakers of English as an additional language residing in the United States. Our first goal was to test whether the use of statistical measures better able to model variation associated with participants and items would replicate findings of a previous analysis of this data (Berger, Crossley, &amp; Skalicky, 2019). Our second goal was to determine whether variables related to experiences using and learning English would interact with linguistic features of the target words. Results from our statistical analysis suggest affirmative answers to both of these questions. First, our results included significant effects for linguistic features related to contextual diversity and contextual distinctiveness, providing a replication of findings from the original study in that words appearing in more textual and lexical contexts were responded to quicker. Second, a measure of length of English learning and a measure of daily English use interacted with a measure of orthographic similarity. Our study provides further evidence regarding how a large, crowdsourced database can be used to obtain a better understanding of second language lexical recognition behavior and provides suggestions for further research.",
        "link": "http://dx.doi.org/10.31219/osf.io/cpdjs"
    },
    {
        "id": 12908,
        "title": "Towards the Bicentric Architecture of Cybernetic Models of Sustainable Development of Large-Scale Systems",
        "authors": "Yury Zatuliveter, Elena Fishchenko",
        "published": "2021-9-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd52249.2021.9600175"
    },
    {
        "id": 12909,
        "title": "Leveraging the Potential of Large Language Models in Education Through Playful and Game-Based Learning",
        "authors": "Stefan E. Huber, Kristian Kiili, Steve Nebel, Richard M. Ryan, Michael Sailer, Manuel Ninaus",
        "published": "2024-3",
        "citations": 0,
        "abstract": "AbstractThis perspective piece explores the transformative potential and associated challenges of large language models (LLMs) in education and how those challenges might be addressed utilizing playful and game-based learning. While providing many opportunities, the stochastic elements incorporated in how present LLMs process text, requires domain expertise for a critical evaluation and responsible use of the generated output. Yet, due to their low opportunity cost, LLMs in education may pose some risk of over-reliance, potentially and unintendedly limiting the development of such expertise. Education is thus faced with the challenge of preserving reliable expertise development while not losing out on emergent opportunities. To address this challenge, we first propose a playful approach focusing on skill practice and human judgment. Drawing from game-based learning research, we then go beyond this playful account by reflecting on the potential of well-designed games to foster a willingness to practice, and thus nurturing domain-specific expertise. We finally give some perspective on how a new pedagogy of learning with AI might utilize LLMs for learning by generating games and gamifying learning materials, leveraging the full potential of human-AI interaction in education.",
        "link": "http://dx.doi.org/10.1007/s10648-024-09868-z"
    },
    {
        "id": 12910,
        "title": "Untangling Emotional Threads: Hallucination Networks of Large Language Models",
        "authors": "Mahsa Goodarzi, Radhakrishnan Venkatakrishnan, M. Abdullah Canbaz",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-53468-3_17"
    },
    {
        "id": 12911,
        "title": "Large language models encode medical oncology knowledge: Performance on the ASCO and ESMO examination questions.",
        "authors": "Jack Bennett Longwell, Robert C Grant, Ian Hirsch, Fernando Binder, Raymond Woo-Jun Jang, Rahul G. Krishnan",
        "published": "2023-11",
        "citations": 1,
        "abstract": " 511  Background: Chatbots based on large language models (LLM) recently developed an unprecedented ability to answer questions across a broad range of applications. Whether LLMs encode sufficient knowledge to answer questions about medical oncology, a highly specialized domain requiring rapid integration of new evidence, is unknown. Methods: We presented ChatGPT (GPT-3.5 and GPT-4) with the American Society of Oncology (ASCO) Self Assessment Program and the European Society of Medical Oncology (ESMO) Examination Trial questions, excluding those that included images or required knowledge unavailable before the algorithm’s training cutoff date. The proportion of correct answers was compared against random chance. ChatGPT was prompted again for a different answer if the previous was incorrect. The reasoning provided by ChatGPT was qualitatively evaluated by two medical oncologists. Results: ChatGPT (GPT-4) correctly answered 84.4% (38/45, 95% confidence interval [CI] 70.5-93.5%, P<0.0001 versus random answering) of ASCO and 86.7% (65/75, 95% CI 76.8-93.4%, P<0.0001) of the ESMO examination questions. GPT-4 outperformed GPT-3.5 (57.8% [26/45, 95% CI 42.2%-72.3%, P=0.001] for ASCO and 65.3% [49/75, 95% CI 53.5%-76.0%, P=0.004] for ESMO). Including second attempts, GPT-4 correctly answered 93.3% (42/45, 95% CI 81.7-98.6%) of ASCO and 93.3% (70/75, 95% CI 85.1-97.8%) of the ESMO examination questions. Incorrect responses for ASCO questions were more common in questions whose answers referenced papers published after 2018 (22.2% [4/18] versus 11.1%, [3/27], P=0.03). Oncologists rated the reasoning behind correct answers by GPT-3.5 as complete for 93.3% of questions (70/75, CI 85.1-97.8%). Conclusions: LLMs can answer examination questions designed for medical oncology fellows with impressive and improving accuracy, alongside correct reasoning. These results imply broad potential applications of LLMs during cancer care to improve the patient and provider experience. ",
        "link": "http://dx.doi.org/10.1200/op.2023.19.11_suppl.511"
    },
    {
        "id": 12912,
        "title": "The Problem of Concept Learning and Goals of Reasoning in Large Language Models",
        "authors": "Anfisa A. Chuganskaya, Alexey K. Kovalev, Aleksandr Panov",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-40725-3_56"
    },
    {
        "id": 12913,
        "title": "Training Large-Scale News Recommenders with Pretrained Language Models in the Loop",
        "authors": "Shitao Xiao, Zheng Liu, Yingxia Shao, Tao Di, Bhuvan Middha, Fangzhao Wu, Xing Xie",
        "published": "2022-8-14",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3534678.3539120"
    },
    {
        "id": 12914,
        "title": "Incorporation of ChatGPT and Other Large Language Models into a Graduate Level Computational Bioengineering Course",
        "authors": "Michael R. King, Adam M. Abdulrahman, Mark I. Petrovic, Patricia L. Poley, Sarah P. Hall, Surat Kulapatana, Zachary E. Lamantia",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s12195-024-00793-3"
    },
    {
        "id": 12915,
        "title": "Health Disparities Through Generative AI Models: A Comparison Study Using a Domain Specific Large Language Model",
        "authors": "Yohn Jairo Parra Bautista, Carlos Theran, Richard Aló, Vinicious Lima",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-47454-5_17"
    },
    {
        "id": 12916,
        "title": "Language Change – Models and Theories",
        "authors": "Thorsten Roelcke",
        "published": "2017-1-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/glot-2017-0009"
    },
    {
        "id": 12917,
        "title": "Theoretical Models of L2 Learning",
        "authors": "Kevin McManus",
        "published": "2021-9-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429341663-2"
    },
    {
        "id": 12918,
        "title": "Application of GPT Models in English Language Teaching",
        "authors": "Leila Diasamidze, Teona Tedoradze",
        "published": "2024-3-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.52340/lac.2024.09.15"
    },
    {
        "id": 12919,
        "title": "The Knowledge Description Language",
        "authors": "V.S. Vykhovanets",
        "published": "2021-9-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd52249.2021.9600103"
    },
    {
        "id": 12920,
        "title": "Correction: How Does ChatGPT Perform on the United States Medical Licensing Examination (USMLE)? The Implications of Large Language Models for Medical Education and Knowledge Assessment",
        "authors": "Aidan Gilson, Conrad W Safranek, Thomas Huang, Vimig Socrates, Ling Chi, Richard Andrew Taylor, David Chartash",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "",
        "link": "http://dx.doi.org/10.2196/57594"
    },
    {
        "id": 12921,
        "title": "PEER: Empowering Writing with Large Language Models",
        "authors": "Kathrin Seßler, Tao Xiang, Lukas Bogenrieder, Enkelejda Kasneci",
        "published": "2023",
        "citations": 0,
        "abstract": "AbstractThe emerging research area of large language models (LLMs) has far-reaching implications for various aspects of our daily lives. In education, in particular, LLMs hold enormous potential for enabling personalized learning and equal opportunities for all students. In a traditional classroom environment, students often struggle to develop individual writing skills because the workload of the teachers limits their ability to provide detailed feedback on each student’s essay. To bridge this gap, we have developed a tool called PEER (Paper Evaluation and Empowerment Resource) which exploits the power of LLMs and provides students with comprehensive and engaging feedback on their essays. Our goal is to motivate each student to enhance their writing skills through positive feedback and specific suggestions for improvement. Since its launch in February 2023, PEER has received high levels of interest and demand, resulting in more than 4000 essays uploaded to the platform to date. Moreover, there has been an overwhelming response from teachers who are interested in the project since it has the potential to alleviate their workload by making the task of grading essays less tedious. By collecting a real-world data set incorporating essays of students and feedback from teachers, we will be able to refine and enhance PEER through model fine-tuning in the next steps. Our goal is to leverage LLMs to enhance personalized learning, reduce teacher workload, and ensure that every student has an equal opportunity to excel in writing. The code is available at https://github.com/Kasneci-Lab/AI-assisted-writing.",
        "link": "http://dx.doi.org/10.1007/978-3-031-42682-7_73"
    },
    {
        "id": 12922,
        "title": "Research on the Integration and Application of Design Thinking and Large Language Models in the Innovation Design of Fintech Products",
        "authors": "Wenjing Wang, Baixi Xing",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": "This study explores the integration and application of Design Thinking and Large Language Models (LLMs) in fintech product innovation design from the perspective of requirements management. Design thinking is human-centered, focusing on discovering and solving problems, integrating innovative solutions, and enhancing product value. By understanding and generating natural language, LLMs provide “on-demand” intelligent services through information retrieval, content creation, and human-like dialogue, meeting individualized needs. Through literature review and analysis, this paper reveals that the combination of the two can promote the full intelligence and continuous improvement of the innovation design process, enhancing the R&D efficiency and user experience of fintech products. This research aims to provide innovation design methods for the fintech field and promote its continuous innovation and development.",
        "link": "http://dx.doi.org/10.3233/faia231483"
    },
    {
        "id": 12923,
        "title": "Comparison of large language models in management advice for melanoma: Google's AI BARD, BingAI and ChatGPT",
        "authors": "Xin Mu, Bryan Lim, Ishith Seth, Yi Xie, Jevan Cevik, Foti Sofiadellis, David J. Hunter‐Smith, Warren M. Rozen",
        "published": "2024-2",
        "citations": 0,
        "abstract": "AbstractLarge language models (LLMs) are emerging artificial intelligence (AI) technology refining research and healthcare. Their use in medicine has seen numerous recent applications. One area where LLMs have shown particular promise is in the provision of medical information and guidance to practitioners. This study aims to assess three prominent LLMs—Google's AI BARD, BingAI and ChatGPT‐4 in providing management advice for melanoma by comparing their responses to current clinical guidelines and existing literature. Five questions on melanoma pathology were prompted to three LLMs. A panel of three experienced Board‐certified plastic surgeons evaluated the responses for reliability using reliability matrix (Flesch Reading Ease Score, the Flesch‐Kincaid Grade Level and the Coleman‐Liau Index), suitability (modified DISCERN score) and comparing them to existing guidelines. t‐Test was performed to calculate differences in mean readability and reliability scores between LLMs and p value <0.05 was considered statistically significant. The mean readability scores across three LLMs were same. ChatGPT exhibited superiority with a Flesch Reading Ease Score of 35.42 (±21.02), Flesch–Kincaid Grade Level of 11.98 (±4.49) and Coleman–Liau Index of 12.00 (±5.10), however all of these were insignificant (p > 0.05). Suitability‐wise using DISCERN score, ChatGPT 58 (±6.44) significantly (p = 0.04) outperformed BARD 36.2 (±34.06) and was insignificant to BingAI's 49.8 (±22.28). This study demonstrates that ChatGPT marginally outperforms BARD and BingAI in providing reliable, evidence‐based clinical advice, but they still face limitations in depth and specificity. Future research should improve LLM performance by integrating specialized databases and expert knowledge to support patient‐centred care.",
        "link": "http://dx.doi.org/10.1002/ski2.313"
    },
    {
        "id": 12924,
        "title": "Promptify: Text-to-Image Generation through Interactive Prompt Exploration with Large Language Models",
        "authors": "Stephen Brade, Bryan Wang, Mauricio Sousa, Sageev Oore, Tovi Grossman",
        "published": "2023-10-29",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3586183.3606725"
    },
    {
        "id": 12925,
        "title": "The impact and opportunities of large language models like ChatGPT in oral and maxillofacial surgery: a narrative review",
        "authors": "B. Puladi, C. Gsaxner, J. Kleesiek, F. Hölzle, R. Röhrig, J. Egger",
        "published": "2024-1",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ijom.2023.09.005"
    },
    {
        "id": 12926,
        "title": "Comparative analysis of large language models in medical counseling: A focus on <i>Helicobacter pylori</i> infection",
        "authors": "Qing‐Zhou Kong, Kun‐Ping Ju, Meng Wan, Jing Liu, Xiao‐Qi Wu, Yue‐Yue Li, Xiu‐Li Zuo, Yan‐Qing Li",
        "published": "2024-1",
        "citations": 0,
        "abstract": "AbstractBackgroundLarge language models (LLMs) are promising medical counseling tools, but the reliability of responses remains unclear. We aimed to assess the feasibility of three popular LLMs as counseling tools for Helicobacter pylori infection in different counseling languages.Materials and MethodsThis study was conducted between November 20 and December 1, 2023. Three large language models (ChatGPT 4.0 [LLM1], ChatGPT 3.5 [LLM2], and ERNIE Bot 4.0 [LLM3]) were input 15 H. pylori related questions each, once in English and once in Chinese. Each chat was conducted using the “New Chat” function to avoid bias from correlation interference. Responses were recorded and blindly assigned to three reviewers for scoring on three established Likert scales: accuracy (ranged 1–6 point), completeness (ranged 1–3 point), and comprehensibility (ranged 1–3 point). The acceptable thresholds for the scales were set at a minimum of 4, 2, and 2, respectively. Final various source and interlanguage comparisons were made.ResultsThe overall mean (SD) accuracy score was 4.80 (1.02), while 1.82 (0.78) for completeness score and 2.90 (0.36) for comprehensibility score. The acceptable proportions for the accuracy, completeness, and comprehensibility of the responses were 90%, 45.6%, and 100%, respectively. The acceptable proportion of overall completeness score for English responses was better than for Chinese responses (p = 0.034). For accuracy, the English responses of LLM3 were better than the Chinese responses (p = 0.0055). As for completeness, the English responses of LLM1 was better than the Chinese responses (p = 0.0257). For comprehensibility, the English responses of LLM1 was better than the Chinese responses (p = 0.0496). No differences were found between the various LLMs.ConclusionsThe LLMs responded satisfactorily to questions related to H. pylori infection. But further improving completeness and reliability, along with considering language nuances, is crucial for optimizing overall performance.",
        "link": "http://dx.doi.org/10.1111/hel.13055"
    },
    {
        "id": 12927,
        "title": "Prompting Large Language Models with Answer Heuristics for Knowledge-Based Visual Question Answering",
        "authors": "Zhenwei Shao, Zhou Yu, Meng Wang, Jun Yu",
        "published": "2023-6",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01438"
    },
    {
        "id": 12928,
        "title": "Understanding Radiological Journal Views and Policies on Large Language Models in Academic Writing",
        "authors": "Tai-Lin Lee, Julia Ding, Hari M. Trivedi, Judy W. Gichoya, John T. Moon, Hanzhou Li",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jacr.2023.08.001"
    },
    {
        "id": 12929,
        "title": "Optimization of Large-scale Equipment Hoisting Scheme",
        "authors": "",
        "published": "2022-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i6(01).10"
    },
    {
        "id": 12930,
        "title": "Transformers, codes and labels: large language modelling for natural language processing in clinical radiology",
        "authors": "Denis Remedios, Alex Remedios",
        "published": "2023-4-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00330-023-09566-4"
    },
    {
        "id": 12931,
        "title": "Batch Prompting: Efficient Inference with Large Language Model APIs",
        "authors": "Zhoujun Cheng, Jungo Kasai, Tao Yu",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-industry.74"
    },
    {
        "id": 12932,
        "title": "Parameter-efficient Tuning for Large Language Model without Calculating Its Gradients",
        "authors": "Feihu Jin, Jiajun Zhang, Chengqing Zong",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.22"
    },
    {
        "id": 12933,
        "title": "WetGPT? Kan een Large Language Model wetten schrijven?",
        "authors": "A.C.M. Meuwese",
        "published": "2023-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5553/rm/0920055x2023039001008"
    },
    {
        "id": 12934,
        "title": "Manipulation and the Ai Act: Large Language Model Chatbots and the Danger of Mirrors",
        "authors": "Joshua Krook",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4719835"
    },
    {
        "id": 12935,
        "title": "Grounding Visual Illusions in Language: Do Vision-Language Models Perceive Illusions Like Humans?",
        "authors": "Yichi Zhang, Jiayi Pan, Yuchen Zhou, Rui Pan, Joyce Chai",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.348"
    },
    {
        "id": 12936,
        "title": "LARGE LANGUAGE MODEL-BASED ARTIFICIAL INTELLIGENCE IN THE LANGUAGE CLASSROOM: PRACTICAL IDEAS FOR TEACHING",
        "authors": "Euan Bonner, Ryan Lege, Erin Frazier",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.56297/bkam1691/wieo1749"
    },
    {
        "id": 12937,
        "title": "Ethics Education for Healthcare Professionals in the Era of ChatGPT and Other Large Language Models: Do We Still Need It?",
        "authors": "Vasiliki Rahimzadeh, Kristin Kostick-Quenet, Jennifer Blumenthal Barby, Amy L. McGuire",
        "published": "2023-10-3",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15265161.2023.2233358"
    },
    {
        "id": 12938,
        "title": "The computer will see you now: ChatGPT and artificial intelligence large language models for health information in urology—an invited perspective",
        "authors": "Joseph Gabriel, Lidia Shafik, Elizabeth Vincent, Jirayr Ajzajian, Ammar Alanbuki, Timothy R. G. Larner",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21037/tau-23-491"
    },
    {
        "id": 12939,
        "title": "Large Language Models Can Accomplish Business Process Management Tasks",
        "authors": "Michael Grohs, Luka Abb, Nourhan Elsayed, Jana-Rebecca Rehse",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-50974-2_34"
    },
    {
        "id": 12940,
        "title": "Multilingual Code Co-evolution using Large Language Models",
        "authors": "Jiyang Zhang, Pengyu Nie, Junyi Jessy Li, Milos Gligoric",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3611643.3616350"
    },
    {
        "id": 12941,
        "title": "Large Language Models Facilitate the Generation of Electronic Health Record Phenotyping Algorithms",
        "authors": "Chao Yan, Henry H. Ong, Monika E. Grabowska, Matthew S. Krantz, Wu-Chen Su, Alyson L. Dickson, Josh F. Peterson, QiPing Feng, Dan M. Roden, C. Michael Stein, V. Eric Kerchberger, Bradley A. Malin, Wei-Qi Wei",
        "published": "No Date",
        "citations": 0,
        "abstract": "ABSTRACTObjectivesPhenotyping is a core task in observational health research utilizing electronic health records (EHRs). Developing an accurate algorithm demands substantial input from domain experts, involving extensive literature review and evidence synthesis. This burdensome process limits scalability and delays knowledge discovery. We investigate the potential for leveraging large language models (LLMs) to enhance the efficiency of EHR phenotyping by generating high-quality algorithm drafts.Materials and MethodsWe prompted four LLMs—GPT-4 and GPT-3.5 of ChatGPT, Claude 2, and Bard—in October 2023, asking them to generate executable phenotyping algorithms in the form of SQL queries adhering to a common data model (CDM) for three phenotypes (i.e., type 2 diabetes mellitus, dementia, and hypothyroidism). Three phenotyping experts evaluated the returned algorithms across several critical metrics. We further implemented the top-rated algorithms and compared them against clinician-validated phenotyping algorithms from the Electronic Medical Records and Genomics (eMERGE) network.ResultsGPT-4 and GPT-3.5 exhibited significantly higher overall expert evaluation scores in instruction following, algorithmic logic, and SQL executability, when compared to Claude 2 and Bard. Although GPT-4 and GPT-3.5 effectively identified relevant clinical concepts, they exhibited immature capability in organizing phenotyping criteria with the proper logic, leading to phenotyping algorithms that were either excessively restrictive (with low recall) or overly broad (with low positive predictive values).ConclusionGPT versions 3.5 and 4 are capable of drafting phenotyping algorithms by identifying relevant clinical criteria aligned with a CDM. However, expertise in informatics and clinical experience is still required to assess and further refine generated algorithms.",
        "link": "http://dx.doi.org/10.1101/2023.12.19.23300230"
    },
    {
        "id": 12942,
        "title": "A Novel Approach for <scp>Mixed‐Methods</scp> Research Using Large Language Models: A Report Using Patients’ Perspectives on Barriers to Arthroplasty",
        "authors": "Insa Mannstadt, Susan M. Goodman, Mangala Rajan, Sarah R. Young, Fei Wang, Iris Navarro‐Millán, Bella Mehta",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": "ObjectiveMixed‐methods research is valuable in health care to gain insights into patient perceptions. However, analyzing textual data from interviews can be time‐consuming and require multiple analysts for investigator triangulation. This study aims to explore a novel approach to investigator triangulation in mixed‐methods research by employing a large language model (LLM) for analyzing data from patient interviews.MethodsThis study compared the thematic analysis and survey generation performed by human investigators and ChatGPT‐4, which uses GPT‐4 as its backbone model, using data from an existing study that explored patient perceptions of barriers to arthroplasty. The human‐ and ChatGPT‐4–generated themes and surveys were compared and evaluated based on their representation of salient themes from a predetermined topic guide.ResultsChatGPT‐4 generated analogous dominant themes and a comprehensive corresponding survey as the human investigators but in significantly less time. The survey questions generated by ChatGPT‐4 were less precise than those developed by human investigators. The mixed‐methods flowchart proposes integrating LLMs and human investigators as a supplementary tool for the preliminary thematic analysis of qualitative data and survey generation.ConclusionBy utilizing a combination of LLMs and human investigators through investigator triangulation, researchers may be able to conduct more efficient mixed‐methods research to better understand patient perspectives. Ethical and qualitative implications of using LLMs should be considered.",
        "link": "http://dx.doi.org/10.1002/acr2.11662"
    },
    {
        "id": 12943,
        "title": "Evaluation of the Performance of Generative AI Large Language Models ChatGPT, Google Bard, and Microsoft Bing Chat in Supporting Evidence-Based Dentistry: Comparative Mixed Methods Study",
        "authors": "Kostis Giannakopoulos, Argyro Kavadella, Anas Aaqel Salim, Vassilis Stamatopoulos, Eleftherios G Kaklamanos",
        "published": "2023-12-28",
        "citations": 3,
        "abstract": "\nBackground\nThe increasing application of generative artificial intelligence large language models (LLMs) in various fields, including dentistry, raises questions about their accuracy.\n\n\nObjective\nThis study aims to comparatively evaluate the answers provided by 4 LLMs, namely Bard (Google LLC), ChatGPT-3.5 and ChatGPT-4 (OpenAI), and Bing Chat (Microsoft Corp), to clinically relevant questions from the field of dentistry.\n\n\nMethods\nThe LLMs were queried with 20 open-type, clinical dentistry–related questions from different disciplines, developed by the respective faculty of the School of Dentistry, European University Cyprus. The LLMs’ answers were graded 0 (minimum) to 10 (maximum) points against strong, traditionally collected scientific evidence, such as guidelines and consensus statements, using a rubric, as if they were examination questions posed to students, by 2 experienced faculty members. The scores were statistically compared to identify the best-performing model using the Friedman and Wilcoxon tests. Moreover, the evaluators were asked to provide a qualitative evaluation of the comprehensiveness, scientific accuracy, clarity, and relevance of the LLMs’ answers.\n\n\nResults\nOverall, no statistically significant difference was detected between the scores given by the 2 evaluators; therefore, an average score was computed for every LLM. Although ChatGPT-4 statistically outperformed ChatGPT-3.5 (P=.008), Bing Chat (P=.049), and Bard (P=.045), all models occasionally exhibited inaccuracies, generality, outdated content, and a lack of source references. The evaluators noted instances where the LLMs delivered irrelevant information, vague answers, or information that was not fully accurate.\n\n\nConclusions\nThis study demonstrates that although LLMs hold promising potential as an aid in the implementation of evidence-based dentistry, their current limitations can lead to potentially harmful health care decisions if not used judiciously. Therefore, these tools should not replace the dentist’s critical thinking and in-depth understanding of the subject matter. Further research, clinical validation, and model improvements are necessary for these tools to be fully integrated into dental practice. Dental practitioners must be aware of the limitations of LLMs, as their imprudent use could potentially impact patient care. Regulatory measures should be established to oversee the use of these evolving technologies.\n",
        "link": "http://dx.doi.org/10.2196/51580"
    },
    {
        "id": 12944,
        "title": "Controlling Translation Formality Using Pre-trained Multilingual Language Models",
        "authors": "Elijah Rippeth, Sweta Agrawal, Marine Carpuat",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.iwslt-1.30"
    },
    {
        "id": 12945,
        "title": "Discourse structure interacts with reference but not syntax in neural language models",
        "authors": "Forrest Davis, Marten van Schijndel",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.conll-1.32"
    },
    {
        "id": 12946,
        "title": "Occupational Biases in Norwegian and Multilingual Language Models",
        "authors": "Samia Touileb, Lilja Øvrelid, Erik Velldal",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gebnlp-1.21"
    },
    {
        "id": 12947,
        "title": "Bridging Information-Theoretic and Geometric Compression in Language Models",
        "authors": "Emily Cheng, Corentin Kervadec, Marco Baroni",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.762"
    },
    {
        "id": 12948,
        "title": "LM-Critic: Language Models for Unsupervised Grammatical Error Correction",
        "authors": "Michihiro Yasunaga, Jure Leskovec, Percy Liang",
        "published": "2021",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.611"
    },
    {
        "id": 12949,
        "title": "Chapter 1. Familiar phrases in language competence",
        "authors": "Diana Van Lancker Sidtis",
        "published": "2020-11-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/hcp.70.01van"
    },
    {
        "id": 12950,
        "title": "The large N limit of two-dimensional models",
        "authors": "",
        "published": "2023-7-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009401654.008"
    },
    {
        "id": 12951,
        "title": "Multivariate Stochastic Volatility Models and Large Deviation Principles",
        "authors": "Archil Gulisashvili",
        "published": "No Date",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4188063"
    },
    {
        "id": 12952,
        "title": "Language acquisition: do children and language models follow similar learning stages?",
        "authors": "Linnea Evanson, Yair Lakretz, Jean Rémi King",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.773"
    },
    {
        "id": 12953,
        "title": "TILM: Neural Language Models with Evolving Topical Influence",
        "authors": "Shubhra Kanti Karmaker Santu, Kalyan Veeramachaneni, Chengxiang Zhai",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/k19-1073"
    },
    {
        "id": 12954,
        "title": "Detecting Label Errors by Using Pre-Trained Language Models",
        "authors": "Derek Chong, Jenny Hong, Christopher Manning",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.618"
    },
    {
        "id": 12955,
        "title": "Text Rendering Strategies for Pixel Language Models",
        "authors": "Jonas Lotz, Elizabeth Salesky, Phillip Rust, Desmond Elliott",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.628"
    },
    {
        "id": 12956,
        "title": "Implementation of geostatistical models for large spatiotemporal datasets using multi-resolution approximations",
        "authors": "Marius Appel, Edzer Pebesma",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;The multi-resolution approximation approach (MRA) [1] provides an efficient representation of Gaussian processes that scales beyond millions of observations. MRA leaves flexibility in the selection of covariance functions and allows to trade off computation time against prediction performance, depending on the selection of parameters. Recent work [2] has shown how MRA can be used for global spatiotemporal processes by integrating nonstationary covariance functions, where parameters vary over space and/or time following a kernel convolution approach. As such, MRA turns out to be a promising approach for geostatistical modelling of global spatiotemporal datasets, such as those coming from Earth observation satellites.&lt;/p&gt;&lt;p&gt;In this work, we show how MRA can be used for spatiotemporal analysis from a practical perspective. In the first part, we will discuss the influence of parameters (spatiotemporal shape of partitioning regions, the number of basis functions, and the number of partitioning levels) by analyzing a real world dataset. In the second part, we will present and discuss our implementation as an R package stmra[3]. We will demonstrate how traditional models as from the gstat package can be implemented efficiently with MRA, and how non-stationary models can be defined by users in a relatively simple way.&amp;#160;&lt;/p&gt;&lt;p&gt;[1] Katzfuss, M. (2017). A multi-resolution approximation for massive spatial datasets. Journal of the American Statistical Association, 112(517), 201-214&lt;/p&gt;&lt;p&gt;[2] Appel, M., &amp; Pebesma, E. (2020). Spatiotemporal multi-resolution approximations for analyzing global environmental data. Spatial Statistics, 38, 100465.&lt;/p&gt;&lt;p&gt;[3] https://github.com/appelmar/stmra&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu21-6585"
    },
    {
        "id": 12957,
        "title": "Managing Scenarios",
        "authors": "Dan Chen, Lizhe Wang, Jingying Chen",
        "published": "2017-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b11883-8"
    },
    {
        "id": 12958,
        "title": "MODELS OF LARGE-SCALE E-LEARNING",
        "authors": "Martin Weller",
        "published": "2019-3-19",
        "citations": 2,
        "abstract": "Early interest in e-learning focused around the possibility of large-scale courses. This led to pronouncements of the demise of the educator, which were based on an infinite lecture hall pedagogy. However, cost-effective models of large-scale e-learning have proven difficult to implement. This paper examines some of the initial reaction to the notion of large-scale courses and sets out the cost difficulties associated with such courses. Five models of large-scale e-learning are proposed. Each of these have implicit associated pedagogies. The majority of these assume instructivist pedagogy. Large-scale models that use a more constructivist pedagogy may be possible using community based approaches. The importance of differentiating between pedagogic styles and scale of implementations is stressed as it highlights the reasoning behind some of the initial claims against e-learning.",
        "link": "http://dx.doi.org/10.24059/olj.v8i4.1812"
    },
    {
        "id": 12959,
        "title": "Large-scale simulation of biomembranes: bringing realistic kinetics to coarse-grained models",
        "authors": "Mohsen Sadeghi, Frank Noé",
        "published": "No Date",
        "citations": 0,
        "abstract": "Biomembranes are two-dimensional assemblies of phospholipids that are only a few nanometres thick, but form micrometer-sized structures vital to cellular function. Explicit modelling of biologically relevant membrane systems is computationally expensive, especially when the large number of solvent particles and slow membrane kinetics are taken into account. While highly coarse-grained solvent-free models are available to study equilibrium behaviour of membranes, their efficiency comes at the cost of sacrificing realistic kinetics, and thereby the ability to predict pathways and mechanisms of membrane processes. Here, we present a framework for integrating coarse-grained membrane models with anisotropic stochastic dynamics and continuum-based hydrodynamics, allowing us to simulate large biomembrane systems with realistic kinetics at low computational cost. This paves the way for whole-cell simulations that still include nanometer/nanosecond spatiotemporal resolutions. As a demonstration, we obtain and verify fluctuation spectrum of a full-sized human red blood cell in a 150-milliseconds-long single trajectory. We show how the kinetic effects of different cytoplasmic viscosities can be studied with such a simulation, with predictions that agree with single-cell experimental observations.",
        "link": "http://dx.doi.org/10.1101/815571"
    },
    {
        "id": 12960,
        "title": "Valuation of Large Variable Annuity Portfolios Using Linear Models with Interactions",
        "authors": "Guojun Gan",
        "published": "No Date",
        "citations": 0,
        "abstract": "A variable annuity is a popular life insurance product that comes with financial guarantees. Using Monte Carlo simulation to value a large variable annuity portfolio is extremely time-consuming. Metamodeling approaches have been proposed in the literature to speed up the valuation process. In metamodeling, a metamodel is first fitted to a small number of variable annuity contracts and then used to predict the values of all other contracts. However, metamodels that have been investigated in the literature are sophisticated predictive models. In this paper, we investigate the use of linear regression models with interaction effects for the valuation of large variable annuity portfolios. Our numerical results show that linear regression models with interactions are able to produce accurate predictions and can be useful additions to the toolbox of metamodels that insurance companies can use to speed up the valuation of large VA portfolios.",
        "link": "http://dx.doi.org/10.20944/preprints201806.0467.v1"
    },
    {
        "id": 12961,
        "title": "Optimization on Cognitive Models",
        "authors": "Solomatin A.N.",
        "published": "2022-9-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd55143.2022.9934131"
    },
    {
        "id": 12962,
        "title": "Comparing Signature Detection of Convolutional Neural Network in Low-Level and Large Language Model in High-Level Programming Language",
        "authors": "Matej Adamec, Michal Turčaník",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/kit59097.2023.10297113"
    },
    {
        "id": 12963,
        "title": "Causal Analysis of Syntactic Agreement Neurons in Multilingual Language Models",
        "authors": "Aaron Mueller, Yu Xia, Tal Linzen",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.conll-1.8"
    },
    {
        "id": 12964,
        "title": "Static and dynamic vector semantics for lambda calculus models of natural language",
        "authors": "Mehrnoosh Sadrzadeh, Reinhard Muskens",
        "published": "2019-3-8",
        "citations": 4,
        "abstract": "Vector models of language are based on the contextual aspects of language, the distributions of words and how they co-occur in text. Truth conditional models focus on the logical aspects of language, compositional properties of words and how they compose to form sentences. In the truth conditional approach, the denotation of a sentence determines its truth conditions, which can be taken to be a truth value, a set of possible worlds, a context change potential, or similar. In the vector models, the degree of co-occurrence of words in context determines how similar the meanings of words are. In this paper, we put these two models together and develop a vector semantics for language based on the simply typed lambda calculus models of natural language. We provide two types of vector semantics: a static one that uses techniques familiar from the truth conditional tradition and a dynamic one based on a form of dynamic interpretation inspired by Heim’s context change potentials. We show how the dynamic model can be applied to entailment between a corpus and a sentence and provide examples. ",
        "link": "http://dx.doi.org/10.15398/jlm.v6i2.228"
    },
    {
        "id": 12965,
        "title": "Combining Pre-Trained Language Models and Features for Offensive Language Detection",
        "authors": "Zhenming Li, Kazutaka Shimada",
        "published": "2022-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iiai-aai-winter58034.2022.00012"
    },
    {
        "id": 12966,
        "title": "Using language cluster models in hierarchical language identification",
        "authors": "Saad Irtza, Vidhyasaharan Sethu, Eliathamby Ambikairajah, Haizhou Li",
        "published": "2018-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.specom.2018.04.004"
    },
    {
        "id": 12967,
        "title": "Meta-Learning Online Adaptation of Language Models",
        "authors": "Nathan Hu, Eric Mitchell, Christopher Manning, Chelsea Finn",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.268"
    },
    {
        "id": 12968,
        "title": "Relative Opinion Similarity Leads to the Emergence of Large Clusters in Opinion Formation Models",
        "authors": "Hirofumi Takesue",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4374661"
    },
    {
        "id": 12969,
        "title": "Ruin Theory Problems in Simple Sde Models with Large Deviation Asymptotics",
        "authors": "Efstathia Bougioukli, Michael  A. Zazanis",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4665986"
    },
    {
        "id": 12970,
        "title": "Decipherment of Substitution Ciphers with Neural Language Models",
        "authors": "Nishant Kambhatla, Anahita Mansouri Bigvand, Anoop Sarkar",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d18-1102"
    },
    {
        "id": 12971,
        "title": "Nearest Neighbor Language Models for Stylistic Controllable Generation",
        "authors": "Severino Trotta, Lucie Flek, Charles Welch",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gem-1.25"
    },
    {
        "id": 12972,
        "title": "States of idiosyncratic idealized cognitive models in acts of pragmatic meaning",
        "authors": "Evgeny A. Pushkarev, Julia S. Rastvorova",
        "published": "2022-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.langsci.2022.101498"
    },
    {
        "id": 12973,
        "title": "Can LLMs Facilitate Interpretation of Pre-trained Language Models?",
        "authors": "Basel Mousi, Nadir Durrani, Fahim Dalvi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.196"
    },
    {
        "id": 12974,
        "title": "Pre-training Language Models for Comparative Reasoning",
        "authors": "Mengxia Yu, Zhihan Zhang, Wenhao Yu, Meng Jiang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.763"
    },
    {
        "id": 12975,
        "title": "Automated Speech Recognition in language learning: Potential models, benefits and impact",
        "authors": "Michael Carrier",
        "published": "2017-2",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.29366/2017tlc.1.1.3"
    },
    {
        "id": 12976,
        "title": "Introduction to Language Models",
        "authors": "Shashank Mohan Jain",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-8844-3_1"
    },
    {
        "id": 12977,
        "title": "Large Network Models and Their Implications",
        "authors": "Guoqiang Mao",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-52989-9_2"
    },
    {
        "id": 12978,
        "title": "Analysis of rubber components under large deformations",
        "authors": "",
        "published": "2017-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140216-22"
    },
    {
        "id": 12979,
        "title": "High-Dimensional Models and Analytics in Large Database Applications",
        "authors": "Michael Brimacombe",
        "published": "2017-4-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315208442-11"
    },
    {
        "id": 12980,
        "title": "Neural Network–Based Closure Models for Large–Eddy Simulations with Explicit Filtering",
        "authors": "Mark Benjamin, Gianluca Iaccarino",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4462714"
    },
    {
        "id": 12981,
        "title": "Reflections on the implications for teaching models",
        "authors": "Ngan Le Hai Phan",
        "published": "2020-1-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429460180-7"
    },
    {
        "id": 12982,
        "title": "Measuring Gender Bias in West Slavic Language Models",
        "authors": "Sandra Martinková, Karolina Stanczak, Isabelle Augenstein",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bsnlp-1.17"
    },
    {
        "id": 12983,
        "title": "LMs stand their Ground: Investigating the Effect of Embodiment in Figurative Language Interpretation by Language Models",
        "authors": "Philipp Wicke",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.302"
    },
    {
        "id": 12984,
        "title": "PLM-ICD: Automatic ICD Coding with Pretrained Language Models",
        "authors": "Chao-Wei Huang, Shang-Chi Tsai, Yun-Nung Chen",
        "published": "2022",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.clinicalnlp-1.2"
    },
    {
        "id": 12985,
        "title": "Confusing Large Models by Confusing Small Models",
        "authors": "Vítor Albiero, Raghav Mehta, Ivan Evtimov, Samuel Bell, Levent Sagun, Aram Markosyan",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00465"
    },
    {
        "id": 12986,
        "title": "Do Domain-Specific Protein Language Models Outperform General Models on Immunology-Related Tasks?",
        "authors": "Nicolas Deutschmann, Aurelien Pelissier, Anna Weber, Shuaijun Gao, Jasmina Bogojeska, María Rodríguez Martínez",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractDeciphering the antigen recognition capabilities by T cell and B cell receptors (antibodies) is essential for advancing our understanding of adaptive immune system responses. In recent years, the development of protein language models (PLMs) has facilitated the development of bioinformatic pipelines where complex amino acid sequences are transformed into vectorized embeddings, which are then applied to a range of downstream analytical tasks. With their success, we have witnessed the emergence of domain-specific PLMs tailored to specific proteins, such as immune receptors. Domain-specific models are often assumed to possess enhanced representation capabilities for targeted applications, however, this assumption has not been thoroughly evaluated. In this manuscript, we assess the efficacy of both generalist and domain-specific transformer-based embeddings in characterizing B and T cell receptors. Specifically, we assess the accuracy of models that leverage these embeddings to predict antigen specificity and elucidate the evolutionary changes that B cells undergo during an immune response. We demonstrate that the prevailing notion of domain-specific models outperforming general models requires a more nuanced examination. We also observe remarkable differences between generalist and domain-specific PLMs, not only in terms of performance but also in the manner they encode information. Finally, we observe that the choice of the size and the embedding layer in PLMs are essential model hyperparameters in different tasks. Overall, our analyzes reveal the promising potential of PLMs in modeling protein function while providing insights into their information-handling capabilities. We also discuss the crucial factors that should be taken into account when selecting a PLM tailored to a particular task.",
        "link": "http://dx.doi.org/10.1101/2023.10.17.562795"
    },
    {
        "id": 12987,
        "title": "A large family of IRF solvable lattice models based on WZW models",
        "authors": "Juan Ramos, Vladimir Belavin, Doron Gepner",
        "published": "2022-11-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22323/1.414.0432"
    },
    {
        "id": 12988,
        "title": "Learning from large-scale neural simulations",
        "authors": "Maria Serban",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/bs.pbr.2017.05.004"
    },
    {
        "id": 12989,
        "title": "SAT: Self-Attention Control for Diffusion Models Training",
        "authors": "Jing Huang, Tianyi Zhang, Wei Shi",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3607827.3616838"
    },
    {
        "id": 12990,
        "title": "The human unlikeness of neural language models in next-word prediction",
        "authors": "Cassandra L. Jacobs, Arya D. McCarthy",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.winlp-1.29"
    },
    {
        "id": 12991,
        "title": "Pre-trained language models in Spanish for health insurance coverage",
        "authors": "Claudio Aracena, Nicolás Rodríguez, Victor Rocco, Jocelyn Dunstan",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.clinicalnlp-1.46"
    },
    {
        "id": 12992,
        "title": "CompoundPiece: Evaluating and Improving Decompounding Performance of Language Models",
        "authors": "Benjamin Minixhofer, Jonas Pfeiffer, Ivan Vulić",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.24"
    },
    {
        "id": 12993,
        "title": "Can Language Models Laugh at YouTube Short-form Videos?",
        "authors": "Dayoon Ko, Sangho Lee, Gunhee Kim",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.176"
    },
    {
        "id": 12994,
        "title": "Natural Language Identification using Corpus-Based Models",
        "authors": "Clive Souter et al.",
        "published": "2017-1-4",
        "citations": 6,
        "abstract": "This paper describes three approaches to the task of automatically identifying the language a text is written in. We conducted experiments to compare the success of each approach in identifying languages from a set of texts in Dutch/Friesian, English, French, Gaelic (Irish), German, Italian, Portuguese, Serbo-Croat and Spanish.....",
        "link": "http://dx.doi.org/10.7146/hjlcb.v7i13.25083"
    },
    {
        "id": 12995,
        "title": "Cloze Distillation: Improving Neural Language Models with Human Next-Word Prediction",
        "authors": "Tiwalayo Eisape, Noga Zaslavsky, Roger Levy",
        "published": "2020",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.conll-1.49"
    },
    {
        "id": 12996,
        "title": "Low Frequency Names Exhibit Bias and Overfitting in Contextualizing Language Models",
        "authors": "Robert Wolfe, Aylin Caliskan",
        "published": "2021",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.41"
    },
    {
        "id": 12997,
        "title": "Preach or Practise? Preach and Practice!",
        "authors": "Johan Van Hoorde",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-88723-0_9"
    },
    {
        "id": 12998,
        "title": "Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese",
        "authors": "Tatsuki Kuribayashi",
        "published": "2020-9-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.27.671"
    },
    {
        "id": 12999,
        "title": "Towards Memory-Efficient Validation of Large XMI Models",
        "authors": "Sorour Jahanbin, Dimitris Kolovos, Simos Gerasimou",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/models-c59198.2023.00053"
    },
    {
        "id": 13000,
        "title": "Mitigating Outlier Activations in Low-Precision Fine-Tuning of Language Models",
        "authors": "Alireza Ghaffari, Justin Yu, Mahsa Nejad, Masoud Asgharian, Boxing Chen, Vahid Nia",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012567700003654"
    },
    {
        "id": 13001,
        "title": "Models of grammar and the outcomes of long-term language contact",
        "authors": "Tor A. Åfarli, Karumuri V. Subbarao",
        "published": "2019-7-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/tsl.126.02afa"
    },
    {
        "id": 13002,
        "title": "Mitigating Outlier Activations in Low-Precision Fine-Tuning of Language Models",
        "authors": "Alireza Ghaffari, Justin Yu, Mahsa Nejad, Masoud Asgharian, Boxing Chen, Vahid Nia",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012567700003654"
    },
    {
        "id": 13003,
        "title": "Medical Concept Mention Identification in Social Media Posts using a Small Number of Sample References",
        "authors": "Vasudevan Nedumpozhimana,  , Sneha Rautmare, Meegan Gower, Maja Popović, Nishtha Jain, Patricia Buffini, John Kelleher,  ,  ,  ,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_084"
    },
    {
        "id": 13004,
        "title": "Evaluating a mobile instant messaging tool for efficient large-class speaking instruction",
        "authors": "Galip Kartal",
        "published": "2022-5-16",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/09588221.2022.2074463"
    },
    {
        "id": 13005,
        "title": "On the Future of Pretrained Language Models (PLMs) for Education Revolution",
        "authors": "Will Beckford",
        "published": "No Date",
        "citations": 0,
        "abstract": "The use of pretrained language models (PLMs) in the field of natural language processing (NLP) has been met with much success, exhibiting exceptional results on various tasks and public benchmarks. The integration of PLMs into education has the potential to revolutionize the learning and teaching process. However, it is important to consider both the positive and negative impacts that may come with this integration. To ensure that the benefits of PLMs are maximized and negative consequences are minimized, a responsible and cautious approach should be taken when integrating PLMs into education. This paper thoroughly examines the benefits and drawbacks of using PLMs in education, and provides insights and considerations for future developments.",
        "link": "http://dx.doi.org/10.31219/osf.io/w3b2f"
    },
    {
        "id": 13006,
        "title": "AI language models",
        "authors": "",
        "published": "2023-4-13",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1787/13d38f92-en"
    },
    {
        "id": 13007,
        "title": "Leveraging Fine-Tuned Language Models in Bioinformatics: A Research Perspective",
        "authors": "Usama Shahid",
        "published": "2023-7-14",
        "citations": 0,
        "abstract": "Bioinformatics, an interdisciplinary field combining biology, computer science, and statistics, has advanced with deep learning and natural language processing techniques. This perspective explores the applications of fine-tuned language models in bioinformatics, highlighting their potential in various domains while discussing challenges and limitations. Fine-tuned language models benefit biomedical literature analysis, extracting information from scientific papers to synthesize knowledge and generate synthetic sequences for DNA, RNA, and protein research. In drug discovery, these models can identify novel drug targets, accelerate virtual screening, and aid drug repurposing by finding new therapeutic indications for existing drugs. For clinical decision support, fine-tuned language models can analyse patient data, medical literature, and guidelines to provide personalized recommendations and alerts to healthcare professionals. They can also aid accurate protein structure prediction for drug design and target identification. In pharmacovigilance, these models can analyse unstructured data sources to detect adverse events from social media, patient forums, and health records, enabling early intervention and improving patient safety. However, challenges like data availability, domain-specific knowledge, bias, interpretability, resource efficiency, ethics, and validation must be addressed for reliable application. Addressing these challenges will unlock the full potential of fine-tuned language models in bioinformatics, driving advancements and benefiting human health. Collaboration between computational and experimental biologists, ethicists, and regulatory bodies is crucial to establish ethical guidelines and best practices for their use.\n",
        "link": "http://dx.doi.org/10.32388/we7umn"
    },
    {
        "id": 13008,
        "title": "Language Models Learn Sentiment and Substance from 11,000 Psychoactive Experiences",
        "authors": "Sam Friedman, Galen Ballentine",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nWith novel hallucinogens poised to enter psychiatry, we lack a unified framework for quantifying which changes in consciousness are optimal for treatment. Using transformers (i.e. BERT) and 11,816 publicly-available drug testimonials, we first predicted 28-dimensions of sentiment across each narrative, validated with psychiatrist annotations. Secondly, BERT was trained to predict biochemical and demographic information from testimonials. Thirdly, canonical correlation analysis (CCA) linked 52 drugs' receptor affinities with testimonial word usage, revealing 11 latent receptor-experience factors, mapped to a 3D cortical atlas. Together, these 3 machine learning methods elucidate a neurobiologically-informed, temporally-sensitive portrait of drug-induced subjective experiences. Different models’ results converged, revealing a pervasive distinction between lucid and mundane phenomena. MDMA was linked to \"Love\", DMT and 5-MeO-DMT to \"Mystical Experiences\", and other tryptamines to \"Surprise\", \"Curiosity\" and \"Realization\". Applying these models to real-time biofeedback, practitioners could harness them to guide the course of therapeutic sessions.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1942143/v1"
    },
    {
        "id": 13009,
        "title": "AI Charades: Language Models as Interactive Game Environments",
        "authors": "Kevin Frans",
        "published": "2021-8-17",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cog52621.2021.9619126"
    },
    {
        "id": 13010,
        "title": "Neural Language Models Capture Some, But Not All, Agreement Attraction Effects",
        "authors": "Suhas Arehalli, Tal Linzen",
        "published": "No Date",
        "citations": 3,
        "abstract": "The number of the subject in English must match the number of the corresponding verb (dog runs but dogs run). Yet in real-time language production and comprehension, speakers often mistakenly compute agreement between the verb and a grammatically irrelevant non-subject noun phrase instead. This phenomenon, referred to as agreement attraction, is modulated by a wide range of factors; any complete computational model of grammatical planning and comprehension would be expected to derive this rich empirical picture. Recent developments in Natural Language Processing have shown that neural networks trained only on word-prediction over large corpora are capable of capturing subject-verb agreement dependencies to a significant extent, but with occasional errors. The goal of this paper is to evaluate the potential of such neural word prediction models as a foundation for a cognitive model of real-time grammatical processing. We simulate six experiments taken from the agreement attraction literature with LSTMs, one common type of neural language model. The LSTMs captured the critical human behavior in three of them, indicating that (1) some agreement attraction phenomena can be captured by a generic sequence processing model, but (2) capturing the other phenomena may require models with more language-specific mechanisms",
        "link": "http://dx.doi.org/10.31234/osf.io/97qcg"
    },
    {
        "id": 13011,
        "title": "Dual Language Models for Code Switched Speech Recognition",
        "authors": "Saurabh Garg, Tanmay Parekh, Preethi Jyothi",
        "published": "2018-9-2",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2018-1343"
    },
    {
        "id": 13012,
        "title": "Concluding Remarks",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_16"
    },
    {
        "id": 13013,
        "title": "Building spatial conditional autoregressive (CAR) models in the Stan programming language",
        "authors": "Connor Donegan",
        "published": "No Date",
        "citations": 0,
        "abstract": "Modeling data collected by areal units, such as counties or census tracts, is a core component of population health research and of growing interest to the social sciences. Bayesian inference has both practical and philosophical advantages over classical statistical techniques, and advances in Markov chain Monte Carlo (MCMC) are expanding the range of research questions to which Bayesian inference may be applied. This code snippet introduces code for fitting spatial conditional autoregressive (CAR) models with the Stan modeling language. Stan is an expressive programming language that uses a dynamic Hamiltonian Monte Carlo (HMC) algorithm to draw samples from user-specified probability models. This paper discusses various CAR model specifications and introduces computationally efficient implementations for Stan users. The geostan R package provides, among other things, convenience functions to ease the process of building custom spatial models in Stan. The paper demonstrates use of the code by modeling United States county, age- and sex-specific mortality data, including censored observations. The demonstration highlights the importance of thoughtful analysis of model residuals.",
        "link": "http://dx.doi.org/10.31219/osf.io/3ey65"
    },
    {
        "id": 13014,
        "title": "GPT-3.5 vs. GPT-4, Unveiling OpenAI’s Latest Breakthrough in Language Models",
        "authors": "Shehul Singh, Nehul Singh",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>OpenAI’s continuous efforts to push our knowledge and build on it for natural language processing have led to the development of GPT-4, the highly acclaimed successor of GPT-3. Built upon the Generative Pretrained Transformer architecture (GPT), it showcases significant advancements in natural language processing, as it now incorporates image handling capabilities alongside its vast data and computational resources. This article delves into a comprehensive comparison between GPT-3 and GPT-4 exploring their similarities, differences, cost of implementation etc. Through a comprehensive analysis of their conversational abilities, accuracy, creativity, and reliability, this article offers valuable insights into the distinctive features and performance enhancements of GPT-4 over its predecessor. As the latest iteration of OpenAI’s language models, GPT-4 promises to redefine the landscape of natural language processing and unlock new possibilities in various domains. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24486214"
    },
    {
        "id": 13015,
        "title": "Evolutionary velocity with protein language models",
        "authors": "Brian L. Hie, Kevin K. Yang, Peter S. Kim",
        "published": "No Date",
        "citations": 6,
        "abstract": "AbstractPredicting the order of biological homologs is a fundamental task in evolutionary biology. For protein evolution, this order is often determined by first arranging sequences into a phylogenetic tree, which has limiting assumptions and can suffer from substantial ambiguity. Here, we demonstrate how machine learning algorithms called language models can learn mutational likelihoods that predict the directionality of evolution, thereby enabling phylogenetic analysis that addresses key limitations of existing methods. Our main conceptual advance is to construct a “vector field” of protein evolution through local evolutionary predictions that we refer to as evolutionary velocity (evo-velocity). We show that evo-velocity can successfully predict evolutionary order at vastly different timescales, from viral proteins evolving over years to eukaryotic proteins evolving over geologic eons. Evo-velocity also yields new evolutionary insights, predicting strategies of viral-host immune escape, resolving conflicting theories on the evolution of serpins, and revealing a key role of horizontal gene transfer in the evolution of eukaryotic glycolysis. In doing so, our work suggests that language models can learn sufficient rules of natural protein evolution to enable evolutionary predictability.",
        "link": "http://dx.doi.org/10.1101/2021.06.07.447389"
    },
    {
        "id": 13016,
        "title": "Large animal models to test mechanical circulatory support devices",
        "authors": "Takuma Miyamoto, Jamshid H. Karimov, Andrew Xanthopoulos, Randall C. Starling, Kiyotaka Fukamachi",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ddmod.2018.06.003"
    },
    {
        "id": 13017,
        "title": "Prompt-Based Approach for Czech Sentiment Analysis",
        "authors": "Jakub Šmíd,  , Pavel Přibáň,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_118"
    },
    {
        "id": 13018,
        "title": "Hierarchical Models",
        "authors": "Guilherme D. Garcia",
        "published": "2021-4-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003032243-12"
    },
    {
        "id": 13019,
        "title": "Text Augmentation for Language Models in High Error Recognition Scenario",
        "authors": "Karel Beneš, Lukáš Burget",
        "published": "2021-8-30",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-627"
    },
    {
        "id": 13020,
        "title": "GPT-3.5 vs. GPT-4, Unveiling OpenAI’s Latest Breakthrough in Language Models",
        "authors": "Shehul Singh, Nehul Singh",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>OpenAI’s continuous efforts to push our knowledge and build on it for natural language processing have led to the development of GPT-4, the highly acclaimed successor of GPT-3. Built upon the Generative Pretrained Transformer architecture (GPT), it showcases significant advancements in natural language processing, as it now incorporates image handling capabilities alongside its vast data and computational resources. This article delves into a comprehensive comparison between GPT-3 and GPT-4 exploring their similarities, differences, cost of implementation etc. Through a comprehensive analysis of their conversational abilities, accuracy, creativity, and reliability, this article offers valuable insights into the distinctive features and performance enhancements of GPT-4 over its predecessor. As the latest iteration of OpenAI’s language models, GPT-4 promises to redefine the landscape of natural language processing and unlock new possibilities in various domains. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24486214.v1"
    },
    {
        "id": 13021,
        "title": "Introduction",
        "authors": "Mascha Kurpicz-Briki",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-37690-0_1"
    },
    {
        "id": 13022,
        "title": "cdsBERT - Extending Protein Language Models with Codon Awareness",
        "authors": "Logan Hallee, Nikolaos Rafailidis, Jason P. Gleghorn",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractRecent advancements in Protein Language Models (pLMs) have enabled high-throughput analysis of proteins through primary sequence alone. At the same time, newfound evidence illustrates that codon usage bias is remarkably predictive and can even change the final structure of a protein. Here, we explore these findings by extending the traditional vocabulary of pLMs from amino acids to codons to encapsulate more information inside CoDing Sequences (CDS). We build upon traditional transfer learning techniques with a novel pipeline of token embedding matrix seeding, masked language modeling, and student-teacher knowledge distillation, called MELD. This transformed the pretrained ProtBERT into cdsBERT; a pLM with a codon vocabulary trained on a massive corpus of CDS. Interestingly, cdsBERT variants produced a highly biochemically relevant latent space, outperforming their amino acid-based counterparts on enzyme commission number prediction. Further analysis revealed that synonymous codon token embeddings moved distinctly in the embedding space, showcasing unique additions of information across broad phylogeny inside these traditionally “silent” mutations. This embedding movement correlated significantly with average usage bias across phylogeny. Future fine-tuned organism-specific codon pLMs may potentially have a more significant increase in codon usage fidelity. This work enables an exciting potential in using the codon vocabulary to improve current state-of-the-art structure and function prediction that necessitates the creation of a codon pLM foundation model alongside the addition of high-quality CDS to large-scale protein databases.",
        "link": "http://dx.doi.org/10.1101/2023.09.15.558027"
    },
    {
        "id": 13023,
        "title": "Language and Cognition",
        "authors": "",
        "published": "2023-7-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/jj.4418237.16"
    },
    {
        "id": 13024,
        "title": "Multi-Word Expressions in Second Language Writing: A Large-Scale Longitudinal Learner Corpus Study",
        "authors": "Anna Siyanova, S Spina",
        "published": "No Date",
        "citations": 0,
        "abstract": "© 2019 Language Learning Research Club, University of Michigan In the present study, we sought to advance the field of learner corpus research by tracking the development of phrasal vocabulary in essays produced at two different points in time. To this aim, we employed a large pool of second language (L2) learners (N = 175) from three proficiency levels—beginner, elementary, and intermediate—and focused on an underrepresented L2 (Italian). Employing mixed-effects models, a flexible and powerful tool for corpus data analysis, we analyzed learner combinations in terms of five different measures: phrase frequency, mutual information, lexical gravity, delta Pforward, and delta Pbackward. Our findings suggest a complex picture, in which higher proficiency and greater exposure to the L2 do not result in more idiomatic and targetlike output, and may, in fact, result in greater reliance on low frequency combinations whose constituent words are non-associated or mutually attracted.",
        "link": "http://dx.doi.org/10.26686/wgtn.13670590.v1"
    },
    {
        "id": 13025,
        "title": "Mathematical Background",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_1"
    },
    {
        "id": 13026,
        "title": "Pre-Trained Transformer-Based Language Models for Sundanese",
        "authors": "Wilson Wongso, Henry Lucky, Derwin Suhartono",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nThe Sundanese language has over 32 million speakers worldwide, but the language has reaped little to no benefits from the recent advances in natural language understanding. Like other low-resource languages, the only alternative is to fine-tune existing multilingual models. In this paper, we pre-trained three monolingual Transformer-based language models on Sundanese data. When evaluated on a downstream text classification task, we found that most of our monolingual models outperformed larger multilingual models despite the smaller overall pre-training data. In the subsequent analyses, our models benefited strongly from the Sundanese pre-training corpus size and do not exhibit socially biased behavior. We released our models for other researchers and practitioners to use.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-907893/v1"
    },
    {
        "id": 13027,
        "title": "FRONT MATTER",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_fmatter"
    },
    {
        "id": 13028,
        "title": "ReAGent: A Model-agnostic Feature Attribution Method for Generative Language Models",
        "authors": "Zhixue Zhao, Boxuan Shan",
        "published": "No Date",
        "citations": 0,
        "abstract": "Feature attribution methods (FAs), such as gradients and attention, are\nwidely employed approaches to derive the importance of all input\nfeatures to the model predictions. Existing work in natural language\nprocessing has mostly focused on developing and testing FAs for\nencoder-only language models (LMs) in classification tasks. However, it\nis unknown if it is faithful to use these FAs for decoder-only models on\ntext generation, due to the inherent differences between model\narchitectures and task settings respectively. Moreover, previous work\nhas demonstrated that there is no ‘one-wins-all’ FA across models and\ntasks. This makes the selection of a FA computationally expensive for\nlarge LMs since input importance derivation often requires multiple\nforward and backward passes including gradient computations that might\nbe prohibitive even with access to large compute. To address these\nissues, we present a model-agnostic FA for generative LMs called\nRecursive Attribution Generator (ReAGent). Our method updates the token\nimportance distribution in a recursive manner. For each update, we\ncompute the difference in the probability distribution over the\nvocabulary for predicting the next token between using the original\ninput and using a modified version where a part of the input is replaced\nwith RoBERTa predictions. Our intuition is that replacing an important\ntoken in the context should have resulted in a larger change in the\nmodel’s confidence in predicting the token than replacing an unimportant\ntoken. Our method can be universally applied to any generative LM\nwithout accessing internal model weights or additional training and\nfine-tuning, as most other FAs require. We extensively compare the\nfaithfulness of ReAGent with seven popular FAs across six decoder-only\nLMs of various sizes. The results show that our method consistently\nprovides more faithful token importance distributions. Our\ncode: https://github.com/casszhao/ReAGent",
        "link": "http://dx.doi.org/10.22541/au.170709121.16176681/v1"
    },
    {
        "id": 13029,
        "title": "Analysis of Large Equipment Hoisting Construction Project Management",
        "authors": "",
        "published": "2021-12-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i12.369"
    },
    {
        "id": 13030,
        "title": "Analysis of Energy Saving Transformation of Large Turbine",
        "authors": "",
        "published": "2022-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i6(06).32"
    },
    {
        "id": 13031,
        "title": "Using Large Pre-Trained Language Model to Assist FDA in Premarket Medical Device Classification",
        "authors": "Zongzhe Xu",
        "published": "2023-4-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/southeastcon51012.2023.10115070"
    },
    {
        "id": 13032,
        "title": "Multi-Word Expressions in Second Language Writing: A Large-Scale Longitudinal Learner Corpus Study",
        "authors": "Anna Siyanova, S Spina",
        "published": "No Date",
        "citations": 0,
        "abstract": "© 2019 Language Learning Research Club, University of Michigan In the present study, we sought to advance the field of learner corpus research by tracking the development of phrasal vocabulary in essays produced at two different points in time. To this aim, we employed a large pool of second language (L2) learners (N = 175) from three proficiency levels—beginner, elementary, and intermediate—and focused on an underrepresented L2 (Italian). Employing mixed-effects models, a flexible and powerful tool for corpus data analysis, we analyzed learner combinations in terms of five different measures: phrase frequency, mutual information, lexical gravity, delta Pforward, and delta Pbackward. Our findings suggest a complex picture, in which higher proficiency and greater exposure to the L2 do not result in more idiomatic and targetlike output, and may, in fact, result in greater reliance on low frequency combinations whose constituent words are non-associated or mutually attracted.",
        "link": "http://dx.doi.org/10.26686/wgtn.13670590"
    },
    {
        "id": 13033,
        "title": "The Large Language Model (LLM) Paradox: Job Creation and Loss in the Age of Advanced AI",
        "authors": "Yifei Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The dawn of the 21st century has witnessed groundbreaking advancements in artificial intelligence (AI), revolutionizing multiple domains from healthcare to finance, and reshaping the socio-economic landscape. A significant contributor to this paradigm shift is the development of Large Language Models (LLMs), which have emerged as powerful tools in understanding and generating human-like text. As with any technological disruption, LLMs prompt a pertinent question: As these models continue to permeate various industries, what implications do they hold for the global workforce? Will they serve as a catalyst for mass job displacement, or could they unlock unprecedented avenues of job creation? This article delves into this crucial debate, dissecting the dual-edged impact of LLMs on the world of employment [1,2].</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24085824.v1"
    },
    {
        "id": 13034,
        "title": "Translating Climate Models to the Language of Paleoclimate Data",
        "authors": "Aaron Sidder",
        "published": "2019-5-24",
        "citations": 0,
        "abstract": "A new model will help climate models better interpret paleoclimate reconstructions derived from lake sediment and could improve predictions of future climatic conditions.",
        "link": "http://dx.doi.org/10.1029/2019eo124475"
    },
    {
        "id": 13035,
        "title": "A Comparative Study of Deep Learning Models for Natural Language Processing (NLP)",
        "authors": "",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.52783/jas.v11i1.1432"
    },
    {
        "id": 13036,
        "title": "Analyzing Pre-trained and Fine-tuned Language Models",
        "authors": "Marius Mosbach",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bigpicture-1.10"
    },
    {
        "id": 13037,
        "title": "Logic and Language Models for Computer Science",
        "authors": "Dana Richards, Henry Hamburger",
        "published": "2017-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/10687"
    },
    {
        "id": 13038,
        "title": "Fine-tuning of deep language models as a computational framework of modeling listeners’ perspective during language comprehension",
        "authors": "Refael Tikochinski, Ariel Goldstein, Yaara Yeshurun, Uri Hasson, Roi Reichart",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractComputational Deep Language Models (DLMs) have been shown to be effective in predicting neural responses during natural language processing. This study introduces a novel computational framework, based on the concept of fine-tuning (Hinton, 2007), for modeling differences in interpretation of narratives based on the listeners’ perspective (i.e. their prior knowledge, thoughts, and beliefs). We draw on an fMRI experiment conducted by Yeshurun et al. (2017), in which two groups of listeners were listening to the same narrative but with two different perspectives (cheating versus paranoia). We collected a dedicated dataset of ~3000 stories, and used it to create two modified (fine-tuned) versions of a pre-trained DLM, each representing the perspective of a different group of listeners. Information extracted from each of the two fine-tuned models was better fitted with neural responses of the corresponding group of listeners. Furthermore, we show that the degree of difference between the listeners’ interpretation of the story - as measured both neurally and behaviorally - can be approximated using the distances between the representations of the story extracted from these two fine-tuned models. These models-brain associations were expressed in many language-related brain areas, as well as in several higher-order areas related to the default-mode and the mentalizing networks, therefore implying that computational fine-tuning reliably captures relevant aspects of human language comprehension across different levels of cognitive processing.",
        "link": "http://dx.doi.org/10.1101/2021.11.22.469596"
    },
    {
        "id": 13039,
        "title": "On Text Style Transfer via Style-Aware Masked Language Models",
        "authors": "Sharan Narasimhan, Pooja H, Suvodip Dey, Maunendra Sankar Desarkar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.inlg-main.25"
    },
    {
        "id": 13040,
        "title": "Conditional Language Models for Community-Level Linguistic Variation",
        "authors": "Bill Noble, Jean-philippe Bernardy",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.nlpcss-1.9"
    },
    {
        "id": 13041,
        "title": "Principles to Navigate the Challenges of Teaching English Language Variation",
        "authors": "Mike Metz",
        "published": "2019-1-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678-14"
    },
    {
        "id": 13042,
        "title": "5. Drawing on Cultural Models and Figured Worlds to Study Language Teacher Education and Teacher Identity",
        "authors": "Manka M. Varghese",
        "published": "2018-12-31",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781783099467-009"
    },
    {
        "id": 13043,
        "title": "Efficient Domain Adaptation of Language Models via Adaptive Tokenization",
        "authors": "Vin Sachidananda, Jason Kessler, Yi-An Lai",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.sustainlp-1.16"
    },
    {
        "id": 13044,
        "title": "Explicit Planning Helps Language Models in Logical Reasoning",
        "authors": "Hongyu Zhao, Kangrui Wang, Mo Yu, Hongyuan Mei",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.688"
    },
    {
        "id": 13045,
        "title": "Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models",
        "authors": "Jirui Qi, Raquel Fernández, Arianna Bisazza",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.658"
    },
    {
        "id": 13046,
        "title": "Syntactic Inductive Bias in Transformer Language Models: Especially Helpful for Low-Resource Languages?",
        "authors": "Luke Gessler, Nathan Schneider",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-1.17"
    },
    {
        "id": 13047,
        "title": "Text encoders bottleneck compositionality in contrastive vision-language models",
        "authors": "Amita Kamath, Jack Hessel, Kai-Wei Chang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.301"
    },
    {
        "id": 13048,
        "title": "Unsupervised Text Style Transfer with Padded Masked Language Models",
        "authors": "Eric Malmi, Aliaksei Severyn, Sascha Rothe",
        "published": "2020",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.699"
    },
    {
        "id": 13049,
        "title": "Language Models Understand Us, Poorly",
        "authors": "Jared Moore",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-emnlp.16"
    },
    {
        "id": 13050,
        "title": "Iconicity in the evolution of language: computational models and laboratory experiments",
        "authors": "Loïs Dona, Marieke Schouwstra",
        "published": "No Date",
        "citations": 0,
        "abstract": "The emergence of human language is a complex process, and to investigate the role of iconicity in this, researchers have combined insights from computational models with empirical observations from laboratory experiments. This chapter provides an overview of the most important insights on the interaction between iconicity and other linguistic properties such as combinatoriality and systematicity. In the experimental and computational work we report, it is shown how iconicity can affect the way in which emerging languages are learned and used. We also discuss how computational methods can help to better understand the gradient and subjective nature of iconicity.",
        "link": "http://dx.doi.org/10.31234/osf.io/63dp5"
    },
    {
        "id": 13051,
        "title": "BACK MATTER",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_bmatter"
    },
    {
        "id": 13052,
        "title": "Language Models Learn Sentiment and Substance from 11,000 Psychoactive Experiences",
        "authors": "Sam Freesun Friedman, Galen Ballentine",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractWith novel hallucinogens poised to enter psychiatry, we lack a unified framework for quantifying which changes in consciousness are optimal for treatment. Using transformers (i.e. BERT) and 11,816 publicly-available drug testimonials, we first predicted 28-dimensions of sentiment across each narrative, validated with psychiatrist annotations. Secondly, BERT was trained to predict biochemical and demographic information from testimonials. Thirdly, canonical correlation analysis (CCA) linked 52 drugs’ receptor affinities with testimonial word usage, revealing 11 latent receptor-experience factors, mapped to a 3D cortical atlas. Together, these 3 machine learning methods elucidate a neurobiologically-informed, temporally-sensitive portrait of drug-induced subjective experiences. Different models’ results converged, revealing a pervasive distinction between lucid and mundane phenomena. MDMA was linked to “Love”, DMT and 5-MeO-DMT to “Mystical Experiences”, and other tryptamines to “Surprise”, “Curiosity” and “Realization”. Applying these models to real-time biofeedback, practitioners could harness them to guide the course of therapeutic sessions.",
        "link": "http://dx.doi.org/10.1101/2022.06.02.494544"
    },
    {
        "id": 13053,
        "title": "Reading as Situated Language",
        "authors": "James Paul Gee",
        "published": "2018-10-3",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781315110592-7"
    },
    {
        "id": 13054,
        "title": "Logic and Language Models for Computer Science",
        "authors": "Dana Richards, Henry Hamburger",
        "published": "2023-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/12974"
    },
    {
        "id": 13055,
        "title": "A Review of Research-based Automatic Text Simplification Tools",
        "authors": "Isabel Espinosa-Zaragoza,  , José Abreu-Salas, Elena Lloret, Paloma Moreda, Manuel Palomar,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_036"
    },
    {
        "id": 13056,
        "title": "Designing the LECOR Learner Corpus for Romanian",
        "authors": "Ana-Maria Barbu,  , Elena Irimia, Carmen Mîrzea Vasile, Vasile Păis,,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_016"
    },
    {
        "id": 13057,
        "title": "Discovering Patterns and Trends in Customer Service Technologies Patents Using Large Language Model",
        "authors": "Chaeyeon Kim, Juyong Lee",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4742724"
    },
    {
        "id": 13058,
        "title": "Pre-trained Language Models’ Interpretation of Evaluativity Implicature: Evidence from Gradable Adjectives Usage in Context",
        "authors": "Yan Cong",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.unimplicit-1.1"
    },
    {
        "id": 13059,
        "title": "Language Contamination Helps Explains the Cross-lingual Capabilities of English Pretrained Models",
        "authors": "Terra Blevins, Luke Zettlemoyer",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.233"
    },
    {
        "id": 13060,
        "title": "On the Calibration of Massively Multilingual Language Models",
        "authors": "Kabir Ahuja, Sunayana Sitaram, Sandipan Dandapat, Monojit Choudhury",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.290"
    },
    {
        "id": 13061,
        "title": "AraProp at WANLP 2022 Shared Task: Leveraging Pre-Trained Language Models for Arabic Propaganda Detection",
        "authors": "Gaurav Singh",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.wanlp-1.56"
    },
    {
        "id": 13062,
        "title": "Investigating Math Word Problems using Pretrained Multilingual Language Models",
        "authors": "Minghuan Tan, Lei Wang, Lingxiao Jiang, Jing Jiang",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.mathnlp-1.2"
    },
    {
        "id": 13063,
        "title": "Unsupervised Anomaly Detection in Parole Hearings using Language Models",
        "authors": "Graham Todd, Catalin Voss, Jenny Hong",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.nlpcss-1.8"
    },
    {
        "id": 13064,
        "title": "Information Extraction from Polish Radiology Reports Using Language Models",
        "authors": "Aleksander Obuchowski, Barbara Klaudel, Patryk Jasik",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bsnlp-1.14"
    },
    {
        "id": 13065,
        "title": "Exploring Contextualized Neural Language Models for Temporal Dependency Parsing",
        "authors": "Hayley Ross, Jonathon Cai, Bonan Min",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.689"
    },
    {
        "id": 13066,
        "title": "Iteratively Prompt Pre-trained Language Models for Chain of Thought",
        "authors": "Boshi Wang, Xiang Deng, Huan Sun",
        "published": "2022",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.174"
    },
    {
        "id": 13067,
        "title": "Generative Language Models for Paragraph-Level Question Generation",
        "authors": "Asahi Ushio, Fernando Alva-Manchego, Jose Camacho-Collados",
        "published": "2022",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.42"
    },
    {
        "id": 13068,
        "title": "The Large Language Model (LLM) Paradox: Job Creation and Loss in the Age of Advanced AI",
        "authors": "Yifei Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The dawn of the 21st century has witnessed groundbreaking advancements in artificial intelligence (AI), revolutionizing multiple domains from healthcare to finance, and reshaping the socio-economic landscape. A significant contributor to this paradigm shift is the development of Large Language Models (LLMs), which have emerged as powerful tools in understanding and generating human-like text. As with any technological disruption, LLMs prompt a pertinent question: As these models continue to permeate various industries, what implications do they hold for the global workforce? Will they serve as a catalyst for mass job displacement, or could they unlock unprecedented avenues of job creation? This article delves into this crucial debate, dissecting the dual-edged impact of LLMs on the world of employment [1,2].</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24085824"
    },
    {
        "id": 13069,
        "title": "Daylong egocentric recordings in small- and large-scale language communities: A practical introduction",
        "authors": "Marisa Casillas, Kennedy Casey",
        "published": "No Date",
        "citations": 0,
        "abstract": "Daylong egocentric (i.e., child-centered) recordings promise an unprecedented view into the experiences that drive early language learning, impacting both assumptions and theories about how learning happens. Thanks to recent advances in technology, collecting long-form audio, photo, and video recordings with child-worn devices is cheaper and more convenient than ever.  These recording methods can be similarly deployed across small- and large-scale language communities around the world, opening up enormous possibilities for comparative research on early language development. However, building new high-quality naturalistic corpora is a massive investment of time and money. In this chapter, we provide a practical look into considerations relevant for daylong egocentric recording project development and management: Is it possible to re-use existing data? How much time will manual annotation take? Can automated tools sufficiently tackle the questions at hand? We conclude by outlining two exciting directions for future naturalistic child language research.",
        "link": "http://dx.doi.org/10.31234/osf.io/b3jxs"
    },
    {
        "id": 13070,
        "title": "Energy Social Surveys Replicated with Large Language Model Agents",
        "authors": "Michael Fell",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4686345"
    },
    {
        "id": 13071,
        "title": "Autonomous Question and Answer System Based on ChatGPT With Large Language Model",
        "authors": "Jun Wang",
        "published": "2024-3-17",
        "citations": 0,
        "abstract": "Chat-GPT has become very popular in recent years. But there is a problem. Chat-GPT does not ask questions to the users. Therefore, Chat-GPT looks like a machine, not a human. However, users sometimes do not want a single answer. They want real things like food, cars, products, etc. Therefore, our system will ask users questions several times until they get what they really want. In this project, we not only resort to Chat-GPT3.5 to find questions, but also resort to traditional programming skills or databases to solve these problems. OpenAI's Chat-GPT3.5 will play the main role in this project. Furthermore, Java and Spring-Boot will be used in this project. These are mature frameworks for enterprise systems(de Oliveira, C. E., Turnquist, G. L., & Antonov, A., 2018). Finally, the MySQL database is used in this project. It provides comprehensive and reliable SQL database services. The data stored in MySQL instances can generate very large data sets(bin Uzayr, S., 2022). Python3 and some machine learning frameworks such as NumPy, Pandas, TensorFlow and PyTorch are used in this project to analyze user behavior(Liu, Y. H., 2020). In the future, the dataset can be integrated into webtext2 as a basic data element to connect the model training.\n",
        "link": "http://dx.doi.org/10.32388/3n00oc"
    },
    {
        "id": 13072,
        "title": "Problems and Improvement of Application of Korean Language Teaching and Learning Models",
        "authors": " JaeSeung Lee",
        "published": "2018-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26589/jockle..67.201809.7"
    },
    {
        "id": 13073,
        "title": "A Framework for Adapting Pre-Trained Language Models to Knowledge Graph Completion",
        "authors": "Justin Lovelace, Carolyn Rosé",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.398"
    },
    {
        "id": 13074,
        "title": "PassGPT: Password Modeling and (Guided) Generation with Large Language Models",
        "authors": "Javier Rando, Fernando Perez-Cruz, Briland Hitaj",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-51482-1_9"
    },
    {
        "id": 13075,
        "title": "Towards Automatic Evaluation of NLG Tasks Using Conversational Large Language Models",
        "authors": "Md Riyadh, M. Omair Shafiq",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-34107-6_34"
    },
    {
        "id": 13076,
        "title": "Plan, Generate and Match: Scientific Workflow Recommendation with Large Language Models",
        "authors": "Yang Gu, Jian Cao, Yuan Guo, Shiyou Qian, Wei Guan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-48421-6_7"
    },
    {
        "id": 13077,
        "title": "Balanced and Explainable Social Media Analysis for Public Health with Large Language Models",
        "authors": "Yan Jiang, Ruihong Qiu, Yi Zhang, Peng-Fei Zhang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-47843-7_6"
    },
    {
        "id": 13078,
        "title": "Artificial intelligence in clinical pharmacology: A case study and scoping review of large language models and bioweapon potential",
        "authors": "Igor Rubinic, Marija Kurtov, Ivan Rubinic, Robert Likic, Paul I. Dargan, David M. Wood",
        "published": "2024-3",
        "citations": 4,
        "abstract": "This paper aims to explore the possibility of employing large language models (LLMs) – a type of artificial intelligence (AI) – in clinical pharmacology, with a focus on its possible misuse in bioweapon development. Additionally, ethical considerations, legislation and potential risk reduction measures are analysed. The existing literature is reviewed to investigate the potential misuse of AI and LLMs in bioweapon creation. The search includes articles from PubMed, Scopus and Web of Science Core Collection that were identified using a specific protocol. To explore the regulatory landscape, the OECD.ai platform was used. The review highlights the dual‐use vulnerability of AI and LLMs, with a focus on bioweapon development. Subsequently, a case study is used to illustrate the potential of AI manipulation resulting in harmful substance synthesis. Existing regulations inadequately address the ethical concerns tied to AI and LLMs. Mitigation measures are proposed, including technical solutions (explainable AI), establishing ethical guidelines through collaborative efforts, and implementing policy changes to create a comprehensive regulatory framework. The integration of AI and LLMs into clinical pharmacology presents invaluable opportunities, while also introducing significant ethical and safety considerations. Addressing the dual‐use nature of AI requires robust regulations, as well as adopting a strategic approach grounded in technical solutions and ethical values following the principles of transparency, accountability and safety. Additionally, AI's potential role in developing countermeasures against novel hazardous substances is underscored. By adopting a proactive approach, the potential benefits of AI and LLMs can be fully harnessed while minimizing the associated risks.",
        "link": "http://dx.doi.org/10.1111/bcp.15899"
    },
    {
        "id": 13079,
        "title": "Leveraging Large Language Models (LLM) for the Plastic Surgery Resident Training: Do They Have a Role?",
        "authors": "Devi Prasad Mohapatra, Friji Meethale Thiruvoth, Satyaswarup Tripathy, Sheeja Rajan, Madhubari Vathulya, Palukuri Lakshmi, Veena K. Singh, Ansar Ul Haq",
        "published": "2023-10",
        "citations": 2,
        "abstract": "Abstract\n          Introduction Large language models (LLMs) are designed for recognizing, summarizing, translating, predicting, and generating text-based content from knowledge gained from extensive data sets. ChatGPT4 (Generative Pre-trained Transformer 4) (OpenAI, San Francisco, California, United States) is a transformer-based LLM model pretrained on public data as well as data obtained from third-party sources using deep learning techniques of fine tuning and reinforcement learning from human feedback to predict the next text. We wanted to explore the role of LLM as a teaching assistant (TA) in plastic surgery.\n          Material and Methods TA roles were first identified in available literature, and based on the roles, a list of suitable tasks was created where LLM could be used to perform the task. Prompts designed to be fed in to the LLM (specifically ChatGPT) to generate appropriate output, were then created and fed to the ChatGPT model. The outputs generated were scored by evaluators and compared for interobserver agreement.\n          Results A final set of eight TA roles were identified where a LLM could be utilized to generate content. These contents were scored for usefulness and accuracy. These were scored independently by the eight study authors in a scoring sheet created for the study. Interobserver agreements for content accuracy, usefulness, and clarity were 100% for content generated for the following: interactive case studies (generation), simulation of preoperative consultations, and generation of ethical considerations.\n          Discussion LLMs in general and ChatGPT (on which this study is based) in specific, can generate answers to questions and prompts based on huge amount of text fed into the model for training the underlying language model. The answers generated have been found to be accurate, readable, and even indistinguishable from human-generated text. This capability of automated content synthesis can be exploited to generate summaries to text, answer short and long answers, and generate case scenarios. We could identify a few such scenarios where the LLM could in general be utilized to play the role of a TA and aid plastic surgery residents in particular. In addition, these models could also be used by students to obtain feedback and gain reflection which itself stimulates critical thinking.\n          Conclusion Incorporating LLMs into the educational arsenal of plastic surgery residency programs can provide a dynamic, interactive, and individualized learning experience for residents and prove to be worthy TAs of future.",
        "link": "http://dx.doi.org/10.1055/s-0043-1772704"
    },
    {
        "id": 13080,
        "title": "A Comprehensive Survey of Attack Techniques, Implementation, and Mitigation Strategies in Large Language Models",
        "authors": "Aysan Esmradi, Daniel Wankit Yip, Chun Fai Chan",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-97-1274-8_6"
    },
    {
        "id": 13081,
        "title": "Probing Possibilities: Toy Models, Minimal Models, and Exploratory Models",
        "authors": "Axel Gelfert",
        "published": "2019",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-32722-4_1"
    },
    {
        "id": 13082,
        "title": "Words in context: tracking context-processing during language comprehension using computational language models and MEG",
        "authors": "Alessandro Lopopolo, Jan Mathijs Schoffelen, Antal van den Bosch, Roel M. Willems",
        "published": "No Date",
        "citations": 4,
        "abstract": "AbstractThe meaning of a word depends on its lexical semantics and on the context in which it is embedded. At the basis of this lays the distinction between lexical retrieval and integration, two basic operations supporting language comprehension. In this paper, we investigate how lexical retrieval and integration are implemented in the brain by comparing MEG activity to word representations generated by computational language models. We test both non-contextualized embeddings, representing words independently from their context, and contextualized embeddings, which instead integrate contextual information in their representations. Using representational similarity analysis over cortical regions and over time, we observed that brain activity in the left anterior temporal pole and inferior frontal regions shows higher similarity with contextualized word embeddings compared to non-contextualized embeddings, between 300 and 500 ms after word presentation. On the other hand, non-contextualized word embeddings show higher similarity with brain activity in the left lateral and anterior temporal lobe at earlier latencies – areas and latencies related to lexical retrieval. Our results highlight how lexical retrieval and context integration can be tracked in the brain using word embeddings obtained with computational models. These results also suggest that the distinction between lexical retrieval and integration might be framed in terms of context-independent and contextualized representations.",
        "link": "http://dx.doi.org/10.1101/2020.06.19.161190"
    },
    {
        "id": 13083,
        "title": "Knowledge Graph-augmented Language Models for Complex Question Answering",
        "authors": "Priyanka Sen, Sandeep Mavadia, Amir Saffari",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.nlrse-1.1"
    },
    {
        "id": 13084,
        "title": "Language Models with Rationality",
        "authors": "Nora Kassner, Oyvind Tafjord, Ashish Sabharwal, Kyle Richardson, Hinrich Schuetze, Peter Clark",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.877"
    },
    {
        "id": 13085,
        "title": "Debiasing Pre-Trained Language Models via Efficient Fine-Tuning",
        "authors": "Michael Gira, Ruisu Zhang, Kangwook Lee",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.ltedi-1.8"
    },
    {
        "id": 13086,
        "title": "Discourse Connectives: Theoretical Models and Empirical Validations in Humans and Computers",
        "authors": "Sandrine Zufferey, Andrei Popescu-Belis",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5_20"
    },
    {
        "id": 13087,
        "title": "Testing the Ability of Language Models to Interpret Figurative Language",
        "authors": "Emmy Liu, Chenxuan Cui, Kenneth Zheng, Graham Neubig",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.330"
    },
    {
        "id": 13088,
        "title": "Biomedical Language Models are Robust to Sub-optimal Tokenization",
        "authors": "Bernal Jimenez Gutierrez, Huan Sun, Yu Su",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bionlp-1.32"
    },
    {
        "id": 13089,
        "title": "Grammar Induction with Neural Language Models: An Unusual Replication",
        "authors": "Phu Mon Htut, Kyunghyun Cho, Samuel Bowman",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d18-1544"
    },
    {
        "id": 13090,
        "title": "Towards Zero-shot Commonsense Reasoning with Self-supervised Refinement of Language Models",
        "authors": "Tassilo Klein, Moin Nabi",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.688"
    },
    {
        "id": 13091,
        "title": "Is ChatGPT a Financial Expert? Evaluating Language Models on Financial Natural Language Processing",
        "authors": "Yue Guo, Zian Xu, Yi Yang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.58"
    },
    {
        "id": 13092,
        "title": "APoLLo : Unified Adapter and Prompt Learning for Vision Language Models",
        "authors": "Sanjoy Chowdhury, Sayan Nag, Dinesh Manocha",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.629"
    },
    {
        "id": 13093,
        "title": "Exploring a Unified ASR for Multiple South Indian Languages Leveraging Multilingual Acoustic and Language Models",
        "authors": "C S Anoop, A G Ramakrishnan",
        "published": "2023-1-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt54892.2023.10022380"
    },
    {
        "id": 13094,
        "title": "ConfliBERT-Arabic: A Pre-trained Arabic Language Model for Politics, Conflicts and Violence",
        "authors": "Sultan Alsarra,  , Luay Abdeljaber, Wooseong Yang, Niamat Zawad, Latifur Khan, Patrick T. Brandt, Javier Osorio, Vito J. D’Orazio,  ,  ,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_011"
    },
    {
        "id": 13095,
        "title": "The Artificial intelligence large language models and neuropsychiatry practice and research ethic",
        "authors": "Yi Zhong, Yu-jun Chen, Yang Zhou, Yan-Ao-Hai Lyu, Jia-Jun Yin, Yu-jun Gao",
        "published": "2023-6",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ajp.2023.103577"
    },
    {
        "id": 13096,
        "title": "Assessing Large Language Models’ Proficiency, Clarity, and Objectivity at the Intersection of Obstetrics, Gynecology, and Global Public Health: Cross-Sectional, Comparative Analysis with Specialists' Knowledge on COVID-19 Impacts in Pregnancy (Preprint)",
        "authors": "Nicola Bragazzi, Michèle Buchinger, Hisham Atwan, Ruba Tuma, Francesco Chirico, Lukasz Szarpak, Raymond Farah, Rola Khamisy-Farah",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nThe COVID-19 pandemic has significantly strained healthcare systems globally, leading to an overwhelming influx of patients and exacerbating resource limitations. Concurrently, an “infodemic” of misinformation, particularly prevalent in women's health, has emerged. This challenge has been pivotal for healthcare providers, especially gynecologists and obstetricians, in managing pregnant women's health. The pandemic heightened risks for pregnant women from COVID-19, necessitating balanced advice from specialists on vaccine safety versus known risks. Additionally, the advent of generative Artificial Intelligence (AI), such as large language models (LLMs), offers promising support in healthcare. However, they necessitate rigorous testing.\n\n\nOBJECTIVE\nTo assess LLMs’ proficiency, clarity, and objectivity regarding COVID-19 impacts in pregnancy.\n\n\nMETHODS\nThis study evaluates four major AI prototypes (ChatGPT-3.5, ChatGPT-4, Microsoft Copilot, and Google Bard) using zero-shot prompts in a questionnaire validated among 172 Israeli gynecologists and obstetricians. The questionnaire assesses proficiency in providing accurate information on COVID-19 in relation to pregnancy. Text-mining, sentiment analysis, and readability (Flesch-Kincaid grade level) were also conducted.\n\n\nRESULTS\nIn terms of LLMs’ knowledge, ChatGPT-4 and Microsoft Copilot each scored 96.7%, Google Bard 93.3%, and ChatGPT-3.5 80.0%. Concerning misinformation instances, ChatGPT-4 incorrectly stated an increased risk of miscarriage due to COVID-19. Google Bard and Microsoft Copilot had minor inaccuracies concerning COVID-19 transmission and complications. At the sentiment analysis, polarity scores were moderately positive, with ChatGPT-4 at 0.37, followed by Microsoft Copilot at 0.33, ChatGPT-3.5 at 0.25, and Google Bard at 0.23. Subjectivity levels were moderate, with Microsoft Copilot being the most objective (0.42). Finally, concerning the readability analysis, Flesch-Kincaid Grade Level showed ChatGPT-3.5 at 25.34, followed by Google Bard at 18.30, Microsoft Copilot at 11.27, and ChatGPT-4 at 21.12.\n\n\nCONCLUSIONS\nThe study highlights varying knowledge levels of LLMs in relation to COVID-19 and pregnancy. ChatGPT-3.5 showed the least knowledge and alignment with scientific evidence. Readability and complexity analyses suggest that each AI's approach is tailored to specific audiences, with ChatGPT versions being more suitable for specialized readers. The sentiment analysis underscores the importance of factual and objective information dissemination. Overall, ChatGPT-4, Microsoft Copilot, and Google Bard generally provide accurate, updated information on COVID-19 and vaccines in women's health, aligning with health guidelines. The study demonstrates the potential role of AI in supplementing healthcare knowledge, with a need for continuous updating and verification of AI knowledge bases. The choice of AI tool should consider the target audience and required information detail level.\n",
        "link": "http://dx.doi.org/10.2196/preprints.56126"
    },
    {
        "id": 13097,
        "title": "Event Extraction and Semantic Representation from Spanish Workers’ Statute Using Large Language Models",
        "authors": "Gabriela Argüelles Terrón, Patricia Martín Chozas, Víctor Rodríguez Doncel",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "This work uses Large Language Models to process an important piece of Spanish legislation: the Workers’ Statute. The proposed method extracts the relevant events in its articles using a GPT-3.5 model and represents the entities involved in the events and the relationships between them as RDF triples. The experiments carried out to select a high-performance strategy include both zero- and few-shot learning tests. Finally, this work proposes a strategy to uplift the extracted legal relations into a legal knowledge graph.",
        "link": "http://dx.doi.org/10.3233/faia230983"
    },
    {
        "id": 13098,
        "title": "Conversational Agent Development Through Large Language Models: Approach with GPT",
        "authors": "Laura Villa, David Carneros-Prado, Adrián Sánchez-Miguel, Cosmin C. Dobrescu, Ramón Hervás",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-48306-6_29"
    },
    {
        "id": 13099,
        "title": "Fighting Lies with Intelligence: Using Large Language Models and Chain of Thoughts Technique to Combat Fake News",
        "authors": "Waleed Kareem, Noorhan Abbas",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-47994-6_24"
    },
    {
        "id": 13100,
        "title": "Response to the comment on “The impact and opportunities of large language models like ChatGPT in oral and maxillofacial surgery: a narrative review”",
        "authors": "B. Puladi, C. Gsaxner, J. Kleesiek, F. Hölzle, R. Röhrig, J. Egger",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ijom.2023.12.010"
    },
    {
        "id": 13101,
        "title": "Efficiency of Large Language Models to scale up Ground Truth: Overview of the IRSE Track at Forum for Information Retrieval 2023",
        "authors": "Soumen Paul, Srijoni Majumdar, Ayan Bandyopadhyay, Bhargav Dave, Samiran Chattopadhyay, Partha Das, Paul D Clough, Prasenjit Majumder",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3632754.3633480"
    },
    {
        "id": 13102,
        "title": "Evaluating the efficacy of leading large language models in the Japanese national dental hygienist examination: A comparative analysis of ChatGPT, Bard, and Bing Chat",
        "authors": "Shino Yamaguchi, Masaki Morishita, Hikaru Fukuda, Kosuke Muraoka, Taiji Nakamura, Izumi Yoshioka, Inho Soh, Kentaro Ono, Shuji Awano",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jds.2024.02.019"
    },
    {
        "id": 13103,
        "title": "The Impact of New It&amp;C Technologies on Academic Performance: An Analysis of How Web 2.0 and Large Language Models Affect the Educational and Research Processes in Universities",
        "authors": "Mireille Rădoi, Bogdan-Paul Saftiuc, Raul Bâg",
        "published": "2023-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2478/9788367405546-009"
    },
    {
        "id": 13104,
        "title": "The Implications of Large Language Models for CS Teachers and Students",
        "authors": "Stephen MacNeil, Joanne Kim, Juho Leinonen, Paul Denny, Seth Bernstein, Brett A. Becker, Michel Wermelinger, Arto Hellas, Andrew Tran, Sami Sarsa, James Prather, Viraj Kumar",
        "published": "2022-3",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3545947.3573358"
    },
    {
        "id": 13105,
        "title": "Fine-Tuning Large Language Models for Answering Programming Questions with Code Snippets",
        "authors": "Vadim Lomshakov, Sergey Kovalchuk, Maxim Omelchenko, Sergey Nikolenko, Artem Aliev",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-36021-3_15"
    },
    {
        "id": 13106,
        "title": "Revolutionizing Cyber Threat Detection With Large Language Models: A Privacy-Preserving BERT-Based Lightweight Model for IoT/IIoT Devices",
        "authors": "Mohamed Amine Ferrag, Mthandazo Ndhlovu, Norbert Tihanyi, Lucas C. Cordeiro, Merouane Debbah, Thierry Lestable, Narinderjit Singh Thandi",
        "published": "2024",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2024.3363469"
    },
    {
        "id": 13107,
        "title": "Leveraging large language models for generating responses to patient messages—a subjective analysis",
        "authors": "Siru Liu, Allison B McCoy, Aileen P Wright, Babatunde Carew, Julian Z Genkins, Sean S Huang, Josh F Peterson, Bryan Steitz, Adam Wright",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "Abstract\n\nObjective\nThis study aimed to develop and assess the performance of fine-tuned large language models for generating responses to patient messages sent via an electronic health record patient portal.\n\n\nMaterials and Methods\nUtilizing a dataset of messages and responses extracted from the patient portal at a large academic medical center, we developed a model (CLAIR-Short) based on a pre-trained large language model (LLaMA-65B). In addition, we used the OpenAI API to update physician responses from an open-source dataset into a format with informative paragraphs that offered patient education while emphasizing empathy and professionalism. By combining with this dataset, we further fine-tuned our model (CLAIR-Long). To evaluate fine-tuned models, we used 10 representative patient portal questions in primary care to generate responses. We asked primary care physicians to review generated responses from our models and ChatGPT and rated them for empathy, responsiveness, accuracy, and usefulness.\n\n\nResults\nThe dataset consisted of 499 794 pairs of patient messages and corresponding responses from the patient portal, with 5000 patient messages and ChatGPT-updated responses from an online platform. Four primary care physicians participated in the survey. CLAIR-Short exhibited the ability to generate concise responses similar to provider’s responses. CLAIR-Long responses provided increased patient educational content compared to CLAIR-Short and were rated similarly to ChatGPT’s responses, receiving positive evaluations for responsiveness, empathy, and accuracy, while receiving a neutral rating for usefulness.\n\n\nConclusion\nThis subjective analysis suggests that leveraging large language models to generate responses to patient messages demonstrates significant potential in facilitating communication between patients and healthcare providers.\n",
        "link": "http://dx.doi.org/10.1093/jamia/ocae052"
    },
    {
        "id": 13108,
        "title": "Large-scale flows in turbulent convection: direct numerical simulations and machine learning models",
        "authors": "Jörg Schumacher",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.52843/cassyni.9h30hv"
    },
    {
        "id": 13109,
        "title": "Large-Scale Artificial Intelligence Models",
        "authors": "Hsiao-Ying Lin",
        "published": "2022-5",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mc.2022.3151419"
    },
    {
        "id": 13110,
        "title": "Problems and Improvement of Application of Korean Language Teaching and Learning Models",
        "authors": " JaeSeung Lee",
        "published": "2018-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26589/jockle..67.201809.7"
    },
    {
        "id": 13111,
        "title": "A Framework for Adapting Pre-Trained Language Models to Knowledge Graph Completion",
        "authors": "Justin Lovelace, Carolyn Rosé",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.398"
    },
    {
        "id": 13112,
        "title": "Driving and suppressing the human language network using large language models",
        "authors": "Greta Tuckute, Aalok Sathe, Shashank Srikant, Maya Taliaferro, Mingye Wang, Martin Schrimpf, Kendrick Kay, Evelina Fedorenko",
        "published": "2024-1-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41562-023-01783-7"
    },
    {
        "id": 13113,
        "title": "Large animal models of thermal injury",
        "authors": "Ayesha Aijaz, Roohi Vinaik, Marc G. Jeschke",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/bs.mcb.2021.12.015"
    },
    {
        "id": 13114,
        "title": "Approximating the equilibrium quantity traded and welfare in large markets",
        "authors": "Ellen V. Muir, Konstantin Borovkov",
        "published": "2017-7-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15326349.2017.1304823"
    },
    {
        "id": 13115,
        "title": "Efficient Implementation of the Hybrid Large Particle Method",
        "authors": "D. V. Sadin",
        "published": "2022-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1134/s207004822206014x"
    },
    {
        "id": 13116,
        "title": "Societal breakdown as an emergent property of large-scale\nbehavioural models of land use change",
        "authors": "Calum Brown, Bumsuk Seo, Mark Rounsevell",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract. Human land use has placed enormous pressure on natural resources and ecosystems worldwide, and may even prompt socio-ecological collapses under some circumstances. Efforts to avoid such collapses are hampered by a lack of knowledge about when they may occur and how they may be prevented. Computational models that illuminate potential future developments in the land system are invaluable tools in this context. While such models are widely used to project biophysical changes, they are currently less able to explore the social dynamics that will be key aspects of future global change. As a result, strategies for navigating a hazardous future may suffer from blind spots at which individual, social and political behaviours divert the land system away from predicted pathways. We apply CRAFTY-EU, an agent-based model of the European land system, in order to investigate the effects of human-behavioural aspects of land management at the continental-scale. We explore a range of potential futures using climatic and socio-economic scenarios, and present a coherent set of cross-sectoral projections without imposed equilibria or optimisation. These projections include various behavioural responses to scenarios including non-economic motivations, aversion to change, and heterogeneity in decision-making. We find that social factors and behavioural responses have dramatic impacts on simulated dynamics, and can contribute to a breakdown of the land system's essential functions in which shortfalls in food production of up to 56 % emerge. These impacts are largely distinct from, and at least as large as, those of projected climatic change. We conclude that the socio-economic aspects of future scenarios require far more detailed and varied treatment. In particular, the extent of economic irrationality at individual and aggregate scales may determine the nature of land system development, with established pathways being highly vulnerable to deviation from this theoretical optimum.\n                        ",
        "link": "http://dx.doi.org/10.5194/esd-2019-24"
    },
    {
        "id": 13117,
        "title": "Testing for Regime Changes in Large Dimensional Factor Models",
        "authors": "Daniele Massacci",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3064615"
    },
    {
        "id": 13118,
        "title": "Solution of Large GSPN Models",
        "authors": "Gianfranco Ciardo, Kishor S. Trivedi",
        "published": "2021-6-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003210160-30"
    },
    {
        "id": 13119,
        "title": "State-Varying Factor Models of Large Dimensions",
        "authors": "Markus Pelger, Ruoxuan Xiong",
        "published": "No Date",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3109314"
    },
    {
        "id": 13120,
        "title": "Large Animals as Models for Human Diseases",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s1877-1173(22)x0005-7"
    },
    {
        "id": 13121,
        "title": "Review for \"Tissue-engineered tendon nano-constructs for repair of chronic rotator cuff tears in large animal models\"",
        "authors": "",
        "published": "2022-2-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/btm2.10376/v1/review1"
    },
    {
        "id": 13122,
        "title": "Discourse Connectives: Theoretical Models and Empirical Validations in Humans and Computers",
        "authors": "Sandrine Zufferey, Andrei Popescu-Belis",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5_20"
    },
    {
        "id": 13123,
        "title": "Normal Approximation in Large Network Models",
        "authors": "Michael Leung, Hyungsik Roger Moon",
        "published": "No Date",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3377709"
    },
    {
        "id": 13124,
        "title": "Background and Fundamentals",
        "authors": "Dan Chen, Lizhe Wang, Jingying Chen",
        "published": "2017-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b11883-2"
    },
    {
        "id": 13125,
        "title": "Constrained Principal Components Estimation of Large Approximate Factor Models",
        "authors": "Rachida Ouysse",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2956211"
    },
    {
        "id": 13126,
        "title": "Estimation of heritabilities and genetic correlations by time slices using predictivity in large genomic models",
        "authors": "Ignacy Misztal",
        "published": "No Date",
        "citations": 0,
        "abstract": "ABSTRACTUnder genomic selection, genetic parameters may change rapidly from generation to generation. Unless genetic parameters used for a selection index are current, the expected genetic gain may be unrealistic, possibly with a decline for antagonistic traits. Existing methods for parameter estimation are computationally unfeasible with large genomic data. We present formulas for estimating heritabilities and genetic correlations applicable for large models with any number of genotyped individuals. Heritabilities are calculated by combining 2 formulas for genomic accuracies: one that relies on predictivity and another that depends on the number of independent chromosome segments. Genetic correlations are calculated from predictivities across traits. Both formulas include approximate standard errors. The formula for heritabilities was evaluated based on information for 4 commercial data sets extracted from published studies. Calculated heritabilities were close to those used initially, except for a much lower new heritability for one single case; that heritability was later confirmed as valid. Formulas for genetic correlations were tested with simulated data and 1,000 replicates. The formula-based estimates were always close to the values assumed for simulation. Standard errors were high with 1,000 validation animals but small with 10,000. The proposed formulas can be used routinely as a check on the evaluation system whenever the number of validation individuals is large enough. If excessive changes are detected from generation to generation, the selection index can be modified appropriately.",
        "link": "http://dx.doi.org/10.1101/2023.06.28.546953"
    },
    {
        "id": 13127,
        "title": "Large-Scale Models in Transport: Issues of Legal Regulation",
        "authors": "Julia Edigareva",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4138490"
    },
    {
        "id": 13128,
        "title": "Preface to the book Fast Processes in Large Scale Atmospheric Models: Progress, Challenges and Opportunities",
        "authors": "Yangang Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "Preface Many physical processes that influence Earth’s climate and\nweather occur on spatial (temporal) scales smaller (shorter) than\ntypical grid sizes (time steps) of general circulation models, and thus\nmust be parameterized. Computer models are essential tools for\nunderstanding atmospheric phenomena and for making accurate predictions\nof any changes in the Earth’s climate, weather, and resources of\nrenewable energy resulting from anthropogenic activities that generate\ngreenhouse gases and particulates into the atmosphere. This book focuses\non the atmospheric subgrid processes ─ collectively called fast physics\n─by reviewing and synthesizing relevant physical understanding,\nparameterization developments, various measurement technologies, and\nmodel evaluation framework. The publication is divided into three parts,\ncontaining seventeen chapters (Chapters 2-17) to reflect and synthesize\nthe multiple aspects involved. The first chapter briefly introduces the\nhistorical development of fast physics parameterizations and the\ninvolved complexities; the last chapter summarizes emerging challenges,\nnew opportunities and future research directions. Part I deals with\nmajor subgrid processes, with eight chapters (Chapters 2-9) each\ncovering different processes more or less in the conventional\ncompartmentalized format with an emphasis on individual processes,\nincluding but, not limited to radiative transfer, aerosols, and aerosol\ndirect & indirect effects, entrainment-mixing processes, their\nmicrophysical influences, convection & convective clouds, stratiform\nclouds such as stratus and stratocumulus clouds, planetary boundary\nlayer processes, land surface and interactions with atmosphere, and\ngravity waves. On top of the conventional treatments, some promising\nideas/approaches have recently emerged to unify the treatment of\nindividual processes and thus allows for consideration of process\ninteractions. Part II is devoted to such unifying efforts, with four\nchapters (Chapters 10-13) covering four different endeavors: the\nunifying parameterizations based on assumed probability density\nfunctions; the EDMF approach that combines the Eddy Diffusivity and Mass\nFlux approaches to unify turbulence and convection; application of\nmachine learning techniques; and innovative top-down attempts that\nconsider the involved totality by borrowing ideas from systems theory,\nstatistical physics, and non-linear sciences. Part III (Chapters 14-17)\nis devoted to assessments, model evaluation, and model-measurement\nintegration, with four chapters that focus on satellite and airborne\nremote sensing measurements, surface-based remote sensing measurements,\nin-situ and laboratory measurements, and model evaluation, and\nmodel-measurement integration, respectively.",
        "link": "http://dx.doi.org/10.22541/essoar.167252588.84737644/v2"
    },
    {
        "id": 13129,
        "title": "Accounting for Small-Scale Processes in Large-Scale Models",
        "authors": "Yangang Liu, Pavlos Kollias",
        "published": "2024-2-16",
        "citations": 0,
        "abstract": "A new book explores how fast processes can be better represented in atmospheric models to improve weather and climate prediction.",
        "link": "http://dx.doi.org/10.1029/2024eo245007"
    },
    {
        "id": 13130,
        "title": "Modeling Large System Dynamics",
        "authors": "Scott P. Milroy",
        "published": "2021-11-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781317302292-14"
    },
    {
        "id": 13131,
        "title": "PyramidEnsemble: Joining Large and Small Models",
        "authors": "Adrian Köring, Christoph Steup",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ssci52147.2023.10371902"
    },
    {
        "id": 13132,
        "title": "Large-scale Retrieval of Bayesian Machine Learning Models for Time Series Data via Gaussian Processes",
        "authors": "Fabian Berns, Christian Beecks",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010109700650074"
    },
    {
        "id": 13133,
        "title": "A Methodological Framework for Creating Large-Scale Corpus for Natural Language Processing Models",
        "authors": "David Santos, Andrés Auquilla, Lorena Siguenza-Guzman, Mario Peña",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-89941-7_7"
    },
    {
        "id": 13134,
        "title": "Towards AI-assisted cardiology: a reflection on the performance and limitations of using large language models in clinical decision-making",
        "authors": "Adil Salihu, Mehdi Ali Gadiri, Ioannis Skalidis, David Meier, Denise Auberson, Annick Fournier, Romain Fournier, Dorina Thanou, Emmanuel Abbé, Olivier Muller, Stephane Fournier",
        "published": "2023-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4244/eij-d-23-00461"
    },
    {
        "id": 13135,
        "title": "Comparison of Prompt Engineering and Fine-Tuning Strategies in Large Language Models in the Classification of Clinical Notes",
        "authors": "Xiaodan Zhang, Nabasmita Talukdar, Sandeep Vemulapalli, Sumyeong Ahn, Jiankun Wang, Han Meng, Sardar Mehtab Bin Murtaza, Dmitry Leshchiner, Aakash Ajay Dave, Dimitri F. Joseph, Martin Witteveen-Lane, Dave Chesla, Jiayu Zhou, Bin Chen",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractThe emerging large language models (LLMs) are actively evaluated in various fields including healthcare. Most studies have focused on established benchmarks and standard parameters; however, the variation and impact of prompt engineering and fine-tuning strategies have not been fully explored. This study benchmarks GPT-3.5 Turbo, GPT-4, and Llama-7B against BERT models and medical fellows’ annotations in identifying patients with metastatic cancer from discharge summaries. Results revealed that clear, concise prompts incorporating reasoning steps significantly enhanced performance. GPT-4 exhibited superior performance among all models. Notably, one-shot learning and fine-tuning provided no incremental benefit. The model’s accuracy sustained even when keywords for metastatic cancer were removed or when half of the input tokens were randomly discarded. These findings underscore GPT-4’s potential to substitute specialized models, such as PubMedBERT, through strategic prompt engineering, and suggest opportunities to improve open-source models, which are better suited to use in clinical settings.",
        "link": "http://dx.doi.org/10.1101/2024.02.07.24302444"
    },
    {
        "id": 13136,
        "title": "Empowering Spoken English Learning with Prompt Engineering against the Background of Large Language Models",
        "authors": "子浩 郭",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.12677/ae.2023.13111273"
    },
    {
        "id": 13137,
        "title": "Identifying Incarceration Status in the Electronic Health Record Using Large Language Models in Emergency Department Settings",
        "authors": "Thomas Huang, Vimig Socrates, Aidan Gilson, Conrad Safranek, Ling Chi, Emily A. Wang, Lisa B. Puglisi, Cynthia Brandt, R. Andrew Taylor, Karen Wang",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/cts.2024.496"
    },
    {
        "id": 13138,
        "title": "Sentiment Analysis of Code-Switched Filipino-English Product and Service Reviews Using Transformers-Based Large Language Models",
        "authors": "Camilla Johnine Cosme, Marlene M. De Leon",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-8349-0_11"
    },
    {
        "id": 13139,
        "title": "Perspectives on Large Language Models for Relevance Judgment",
        "authors": "Guglielmo Faggioli, Laura Dietz, Charles L. A. Clarke, Gianluca Demartini, Matthias Hagen, Claudia Hauff, Noriko Kando, Evangelos Kanoulas, Martin Potthast, Benno Stein, Henning Wachsmuth",
        "published": "2023-8-9",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3578337.3605136"
    },
    {
        "id": 13140,
        "title": "Large language models for chemistry robotics",
        "authors": "Naruki Yoshikawa, Marta Skreta, Kourosh Darvish, Sebastian Arellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen, Andrew Zou Li, Yuchi Zhao, Haoping Xu, Artur Kuramshin, Alán Aspuru-Guzik, Florian Shkurti, Animesh Garg",
        "published": "2023-12",
        "citations": 3,
        "abstract": "AbstractThis paper proposes an approach to automate chemistry experiments using robots by translating natural language instructions into robot-executable plans, using large language models together with task and motion planning. Adding natural language interfaces to autonomous chemistry experiment systems lowers the barrier to using complicated robotics systems and increases utility for non-expert users, but translating natural language experiment descriptions from users into low-level robotics languages is nontrivial. Furthermore, while recent advances have used large language models to generate task plans, reliably executing those plans in the real world by an embodied agent remains challenging. To enable autonomous chemistry experiments and alleviate the workload of chemists, robots must interpret natural language commands, perceive the workspace, autonomously plan multi-step actions and motions, consider safety precautions, and interact with various laboratory equipment. Our approach, CLAIRify, combines automatic iterative prompting with program verification to ensure syntactically valid programs in a data-scarce domain-specific language that incorporates environmental constraints. The generated plan is executed through solving a constrained task and motion planning problem using PDDLStream solvers to prevent spillages of liquids as well as collisions in chemistry labs. We demonstrate the effectiveness of our approach in planning chemistry experiments, with plans successfully executed on a real robot using a repertoire of robot skills and lab tools. Specifically, we showcase the utility of our framework in pouring skills for various materials and two fundamental chemical experiments for materials synthesis: solubility and recrystallization. Further details about CLAIRify can be found at https://ac-rad.github.io/clairify/.",
        "link": "http://dx.doi.org/10.1007/s10514-023-10136-2"
    },
    {
        "id": 13141,
        "title": "Large language models (LLM) and ChatGPT: what will the impact on nuclear medicine be?",
        "authors": "Ian L. Alberts, Lorenzo Mercolli, Thomas Pyka, George Prenosil, Kuangyu Shi, Axel Rominger, Ali Afshar-Oromieh",
        "published": "2023-5",
        "citations": 41,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00259-023-06172-w"
    },
    {
        "id": 13142,
        "title": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models",
        "authors": "Tiffany H. Kung, Morgan Cheatham, Arielle Medenilla, Czarina Sillos, Lorie De Leon, Camille Elepaño, Maria Madriaga, Rimel Aggabao, Giezel Diaz-Candido, James Maningo, Victor Tseng",
        "published": "2023-2-9",
        "citations": 1024,
        "abstract": "We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, clinical decision-making.",
        "link": "http://dx.doi.org/10.1371/journal.pdig.0000198"
    },
    {
        "id": 13143,
        "title": "Introduction",
        "authors": "Baojiu Li",
        "published": "2018-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1088/978-0-7503-1587-6ch1"
    },
    {
        "id": 13144,
        "title": "Large-Scale Models of the Olfactory Bulb",
        "authors": "Francesco Cavarretta",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4614-7320-6_100664-1"
    },
    {
        "id": 13145,
        "title": "Sandpile Models in the Large",
        "authors": "Philippe Ruelle",
        "published": "2021-6-2",
        "citations": 2,
        "abstract": "This contribution is a review of the deep and powerful connection between the large-scale properties of critical systems and their description in terms of a field theory. Although largely applicable to many other models, the details of this connection are illustrated in the class of two-dimensional Abelian sandpile models. Bulk and boundary height variables, spanning tree–related observables, boundary conditions, and dissipation are all discussed in this context and found to have a proper match in the field theoretic description.",
        "link": "http://dx.doi.org/10.3389/fphy.2021.641966"
    },
    {
        "id": 13146,
        "title": "Global Oil Market Forecasting Models",
        "authors": "Valery Akinfiev",
        "published": "2020-9-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd49919.2020.9247646"
    },
    {
        "id": 13147,
        "title": "Large-Scale Models of the Olfactory Bulb",
        "authors": "Francesco Cavarretta",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4614-7320-6_100664-2"
    },
    {
        "id": 13148,
        "title": "Conclusions",
        "authors": "Baojiu Li",
        "published": "2018-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1088/978-0-7503-1587-6ch6"
    },
    {
        "id": 13149,
        "title": "Performance Models of Data Parallel DAG Workflows for Large Scale Data Analytics",
        "authors": "Juwei Shi, Jiaheng Lu",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nDirected Acyclic Graph (DAG) workflows are widely used for large-scale data analytics in cluster-based distributed computing systems. The performance model for a DAG on data-parallel frameworks (e.g., MapReduce) is a research challenge because the allocation of preemptable system resources among parallel jobs may dynamically vary during execution. This resource allocation variation during execution makes it difficult to accurately estimate the execution time. In this paper, we tackle this challenge by proposing a new cost model, called Bottleneck Oriented Estimation (BOE), to estimate the allocation of preemptable resources by identifying the bottleneck to accurately predict task execution time. For a DAG workflow, we propose a state-based approach to iteratively use the resource allocation property among stages to estimate the overall execution plan. Furthermore, to handle the skewness of various jobs, we refine the model with the order statistics theory to improve estimation accuracy. Extensive experiments were performed to validate these cost models with HiBench and TPC-H workloads. The BOE model outperforms the state-of-the-art models by a factor of five for task execution time estimation. For the refined skew-aware model, the average prediction error is under 3% when estimating the execution time of 51 hybrid analytics (HiBench) and query (TPC-H) DAG workflows.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2214885/v1"
    },
    {
        "id": 13150,
        "title": "Large-scale Retrieval of Bayesian Machine Learning Models for Time Series Data via Gaussian Processes",
        "authors": "Fabian Berns, Christian Beecks",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010109700710080"
    },
    {
        "id": 13151,
        "title": "Chapter 9. Agreement Groups and dualistic syntactic processing",
        "authors": "László Drienkó",
        "published": "2020-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/hcp.70.09dri"
    },
    {
        "id": 13152,
        "title": "ConfliBERT-Arabic: A Pre-trained Arabic Language Model for Politics, Conflicts and Violence",
        "authors": "Sultan Alsarra,  , Luay Abdeljaber, Wooseong Yang, Niamat Zawad, Latifur Khan, Patrick T. Brandt, Javier Osorio, Vito J. D’Orazio,  ,  ,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_011"
    },
    {
        "id": 13153,
        "title": "Color terms: Native language semantic structure and artificial language structure formation in a large-scale online smartphone application",
        "authors": "Thomas Franz Müller, James Winters, Tiffany Morisseau, Ira Andrew Noveck, Olivier Morin",
        "published": "No Date",
        "citations": 0,
        "abstract": "Artificial language games give researchers the opportunity to investigate the emergence and evolution of semantic structure, i.e. the organization of meaning spaces into discrete categories. A possible issue for this approach is that categories might simply carry over from participants’ native languages, a potential bias that has mostly been ignored. We investigate this in a referential communication game by comparing color terms from three different languages to those of an artificial language. Here, we assess the similarity of the semantic structures, and test the influence of the semantic structure on artificial language communication. We compare the in-game communication to a separate online naming task providing us with the native language structure. Our results show that native and artificial language structure overlap at least moderately. Furthermore, communicative behavior and performance were influenced by the shared semantic structure, but only for English-speaking pairs. These results imply a cognitive link between participants’ semantic structures and artificial language structure formation.",
        "link": "http://dx.doi.org/10.31234/osf.io/9zmcg"
    },
    {
        "id": 13154,
        "title": "A segmental framework for fully-unsupervised large-vocabulary speech recognition",
        "authors": "Herman Kamper, Aren Jansen, Sharon Goldwater",
        "published": "2017-11",
        "citations": 41,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2017.04.008"
    },
    {
        "id": 13155,
        "title": "Author response for \"The use of a large language model to create plain language summaries of evidence reviews in healthcare: A feasibility study\"",
        "authors": " Colleen Ovelman,  Shannon Kugley,  Gerald Gartlehner,  Meera Viswanathan",
        "published": "2024-1-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/cesm.12041/v2/response1"
    },
    {
        "id": 13156,
        "title": "Accommodations for English Language Learners in Large-scale Assessments—Testing Accommodations for English Language Learners",
        "authors": "Li Liu",
        "published": "2023-7-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26855/er.2023.06.006"
    },
    {
        "id": 13157,
        "title": "Time-Stamped Language Model: Teaching Language Models to Understand The Flow of Events",
        "authors": "Hossein Rajaby Faghihi, Parisa Kordjamshidi",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.362"
    },
    {
        "id": 13158,
        "title": "The models of co-teaching and a spectrum for assessing collaboration: Examining English language co-teaching practices in South Korea",
        "authors": "Sung-Yeon Kim, Ian Moodie",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": " Many countries have developed co-teaching programs pairing native-English-speaking teachers with local English teachers. Despite the optimistic aims of these programs, research has revealed challenges for co-teaching, such as with teachers’ contrasting belief systems or cultural differences. However, research has yet to examine the models of co-teaching applied and the extent of collaboration observed with multiple co-teaching pairs across different teaching contexts as is done in the present study. The study uses qualitative analysis, aiming to examine the approaches to co-teaching and the degree of collaboration with 14 pairs of co-teachers across different school levels (primary, middle, and high schools) in South Korea. Based on classroom observations and interview data, the study found that of seven models of English-language co-teaching (one teaching / one assisting, team teaching, one teaching / one assessing, parallel teaching, alternative teaching [pre-teaching], alternative teaching [re-teaching], and station teaching), the one teaching / one assisting model was prevalent for 10 dyads and the team-teaching model for four dyads. The other models of coteaching were not used or reported to be used by these participants. In addition, by focusing on the observed and stated practices of these participants, the study adds to the literature by showing how co-teaching collaboration occurs across a spectrum, from no collaboration to full collaboration, with differing levels of engagement throughout. The study suggests that this proposed spectrum will be useful for researching and assessing co-teaching practices, and it implies that the efficacy of co-teaching could be increased by supporting fuller collaboration and multiple approaches to co-teaching beyond the dominant one teaching / one assisting model. ",
        "link": "http://dx.doi.org/10.1177/13621688231218816"
    },
    {
        "id": 13159,
        "title": "Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark",
        "authors": "Wenjun Peng, Jingwei Yi, Fangzhao Wu, Shangxi Wu, Bin Bin Zhu, Lingjuan Lyu, Binxing Jiao, Tong Xu, Guangzhong Sun, Xing Xie",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.423"
    },
    {
        "id": 13160,
        "title": "A Comparative Study of Chatbot Response Generation: Traditional Approaches Versus Large Language Models",
        "authors": "Michael McTear, Sheen Varghese Marokkie, Yaxin Bi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-40286-9_7"
    },
    {
        "id": 13161,
        "title": "10089-CO-4 DEVELOPMENT OF A PHYSICIAN SUPPORT SYSTEM FOR ANALYSIS OF GENETIC MUTATIONS IN BRAIN TUMORS AND SELECTION OF CLINICAL TRIALS USING LARGE-SCALE LANGUAGE MODELS (LLMS) WITH RETRIEVER",
        "authors": "Satoshi Takahashi, Taijyun Hana, Tkafumi Koyama, Ken Takasawa, nobuji Kouno, Kenichi Ishidu, Ryuji Hamamoto",
        "published": "2023-12-10",
        "citations": 0,
        "abstract": "Abstract\nIn the management of brain tumors, comprehensive genomic profiling testing is used to identify genetic mutations and understand their clinical significance to facilitate optimal therapeutic strategies. However, the test can identify non-standard mutations for brain tumor classification, and accurately presenting their clinical relevance is challenging. Providing accurate clinical trials per patient requests based on these results can also be time-consuming, creating the need for a physician support system. Large Language Models (LLMs) such as GPT, which are used for general conversation, question answering, and text generation, have limitations when used in specialized domains such as medicine. The information derived only from training data results in the inability of the LLM to handle specialized knowledge queries and verify certain facts, increasing the risk of generating incorrect information. To overcome these challenges, we developed a system that integrates a retriever with LLM. The retriever acts as an external memory, allowing LLM to access information beyond the training data. Because the retriever uses human-verified information, it mitigates the potential for incorrect information generation by LLM.In this presentation, we will discuss the use of this system in actual brain tumor diagnosis and treatment, and evaluate its accuracy and reliability. We believe that this system can help diagnose and treat patients with various genetic mutations, not limited to brain tumors.",
        "link": "http://dx.doi.org/10.1093/noajnl/vdad141.041"
    },
    {
        "id": 13162,
        "title": "PromptIE - Information Extraction with Prompt-Engineering and Large Language Models",
        "authors": "Sigurd Schacht, Sudarshan Kamath Barkur, Carsten Lanquillon",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-36004-6_69"
    },
    {
        "id": 13163,
        "title": "Why We Support and Encourage the Use of Large Language Models in\n            <i>NEJM AI</i>\n            Submissions",
        "authors": "Daphne Koller, Andrew Beam, Arjun Manrai, Euan Ashley, Xiaoxuan Liu, Judy Gichoya, Chris Holmes, James Zou, Noa Dagan, Tien Y. Wong, David Blumenthal, Isaac Kohane",
        "published": "2024-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1056/aie2300128"
    },
    {
        "id": 13164,
        "title": "Re: Michael Eppler, Conner Ganjavi, Lorenzo Storino Ramacciotti, et al. Awareness and Use of ChatGPT and Large Language Models: A Prospective Cross-sectional Global Survey in Urology. Eur Urol. 2024;85:146–53.",
        "authors": "Rui-Cheng Wu, Deng-Xiong Li, De-Chao Feng",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.eururo.2023.11.029"
    },
    {
        "id": 13165,
        "title": "Proposals and Methods for Foreign Language Learning Using Machine Translation and Large Language Model",
        "authors": "Kohei Sugiyama, Tsukasa Yamanaka",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.procs.2023.10.474"
    },
    {
        "id": 13166,
        "title": "Attentive Perturbation: Extending Prefix Tuning to Large Language Models Inner Representations",
        "authors": "Louis Falissard, Séverine Affeldt, Mohamed Nadif",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-53969-5_36"
    },
    {
        "id": 13167,
        "title": "P717 Evaluating the performance of Large Language Models in responding to patients' health queries: A comparative analysis with medical experts",
        "authors": "Z Yan, S Lu, D Xu, Y Yang, H Wang, J Mao, Y Fan, Y Chen, H C Tseng",
        "published": "2024-1-24",
        "citations": 0,
        "abstract": "Abstract\n\nBackground\nPatients with chronic diseases exhibit a heightened interest in seeking health information, and access to high-quality information can positively impact clinical outcomes. While previous research on static internet text/video information has highlighted concerns about low-barrier creation leading to low-quality content, it remains uncertain whether similar issues persist in responses generated by Large Language Models (LLMs). Assessing the ability of LLMs in responding to medical queries provides valuable insights for their application in healthcare settings.\n\n\nMethods\nIn alignment with open science principles, we utilized real patient queries from the China Crohn's and Colitis Foundation (CCCF) series \"Questions and Answers on Ulcerative Colitis and Crohn's Disease.\" The dataset comprised questions posed by patients and corresponding answers from medical professionals, collected from outpatient visits and online social media. In September 2023, 263 patient questions were sequentially input into ChatGPT-3.5 (August 3, 2023 version), and the resulting responses were compiled alongside the original medical professional responses, forming 263 modules. Three Inflammatory Bowel Disease (IBD) specialist physicians and three IBD patients were invited to assess each module. Evaluators were instructed to: 1) choose their preferred response version, and 2) provide a multidimensional Likert 5-point subjective assessment using a crowdsourcing strategy. Additionally, the CRIE 3.0 team conducted an automated objective analysis of Simplified Chinese readability.\n\n\nResults\nMann-Whitney U tests on text readability levels (median: 7th grade for both medical professionals and ChatGPT responses; Q1: 6th grade; Q3: 8th grade) revealed no significant difference (p=0.87), suggesting ChatGPT's performance align well with recommended literacy levels for popular science publications and is comparable to the average education level in China.\n\n\nConclusion\nCautiously interpreting our findings, ChatGPT's preliminary performance appears comparable to specialized IBD physicians, indicating its potential utility in patient community Q&A. Integrating ChatGPT or similar LLMs into the drafting or refinement stages of health texts is feasible. However, due to the presence of AI hallucinations and the consensus in most experimental conclusions, direct use of large language models for patient Q&A services is not recommended. Recognizing the variability in health information understanding between medical professionals and patients can enhance patient education efforts.\n\n",
        "link": "http://dx.doi.org/10.1093/ecco-jcc/jjad212.0847"
    },
    {
        "id": 13168,
        "title": "Baldur: Whole-Proof Generation and Repair with Large Language Models",
        "authors": "Emily First, Markus Rabe, Talia Ringer, Yuriy Brun",
        "published": "2023-11-30",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3611643.3616243"
    },
    {
        "id": 13169,
        "title": "Training Large-Vocabulary Neural Language Models by Private Federated Learning for Resource-Constrained Devices",
        "authors": "Mingbin Xu, Congzheng Song, Ye Tian, Neha Agrawal, Filip Granqvist, Rogier van Dalen, Xiao Zhang, Arturo Argueta, Shiyi Han, Yaqiao Deng, Leo Liu, Anmol Walia, Alex Jin",
        "published": "2023-6-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10096570"
    },
    {
        "id": 13170,
        "title": "Can large language models replace humans in systematic reviews? Evaluating <scp>GPT</scp>‐4's efficacy in screening and extracting data from peer‐reviewed and grey literature in multiple languages",
        "authors": "Qusai Khraisha, Sophie Put, Johanna Kappenberg, Azza Warraitch, Kristin Hadfield",
        "published": "2024-3-14",
        "citations": 0,
        "abstract": "AbstractSystematic reviews are vital for guiding practice, research and policy, although they are often slow and labour‐intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre‐Trained Transformer (GPT)‐4, the biggest LLM so far. This pre‐registered study uses a “human‐out‐of‐the‐loop” approach to evaluate GPT‐4's capability in title/abstract screening, full‐text review and data extraction across various literature types and languages. Although GPT‐4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full‐text literature using highly reliable prompts, GPT‐4's performance was more robust, reaching “human‐like” levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance.",
        "link": "http://dx.doi.org/10.1002/jrsm.1715"
    },
    {
        "id": 13171,
        "title": "GPT-2C",
        "authors": "Febrian Setianto, Erion Tsani, Fatima Sadiq, Georgios Domalis, Dimitris Tsakalidis, Panos Kostakos",
        "published": "2021-11-8",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3487351.3492723"
    },
    {
        "id": 13172,
        "title": "Developing L2 oral language proficiency using concept-based Dynamic Assessment within a large-scale testing context",
        "authors": "Tziona Levi",
        "published": "2017-5-3",
        "citations": 0,
        "abstract": "Oral language proficiency (OLP) is a central facet of foreign language learning. Nevertheless, it is a component that is challenging both to teach and to test (Luoma, 2004). In an effort to optimize these processes, this paper examines the application of the Vygotskian notion of Dynamic Assessment (DA) as a means to prioritize the learning-assessment relationship with a view to enhancing OLP performance and up-scaling DA use for larger groups of learners to match large-scale test contexts. In this study, Israeli high-school students preparing for their matriculation OLP test in EFL, which focuses on the measures of Communicative Ability (fluency) and Accuracy, underwent a single short-term DA mediation session following a pre-test. A teacher-tester administered the mediation to individuals and groups of students as they analyzed a video recording of their pre-tests, equipped with a theoretical scientific-concept-based instrument (SCOBA). Post- and follow-up tests were given to all participants. Findings show that students who underwent DA mediation improved scores in the post- and follow-up tests for both measures, suggesting that this form of DA mediation may have beneficial short and longer-term impact on OLP performance within a large-scale context.",
        "link": "http://dx.doi.org/10.1558/lst.32866"
    },
    {
        "id": 13173,
        "title": "Developing L2 oral language proficiency using concept-based Dynamic assessment within a large-scale testing context",
        "authors": "Tziona Levi",
        "published": "2017-2-6",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1558/lst.v3i2.32866"
    },
    {
        "id": 13174,
        "title": "PromptMix: A Class Boundary Augmentation Method for Large Language Model Distillation",
        "authors": "Gaurav Sahu, Olga Vechtomova, Dzmitry Bahdanau, Issam Laradji",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.323"
    },
    {
        "id": 13175,
        "title": "Syllable-level Neural Language Model for Agglutinative Language",
        "authors": "Seunghak Yu, Nilesh Kulkarni, Haejun Lee, Jihie Kim",
        "published": "2017",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w17-4113"
    },
    {
        "id": 13176,
        "title": "IELM: An Open Information Extraction Benchmark for Pre-Trained Language Models",
        "authors": "Chenguang Wang, Xiao Liu, Dawn Song",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.576"
    },
    {
        "id": 13177,
        "title": "The Implementation of Clinical Supervision Models towards The Language Teaching and Learning",
        "authors": "Rama Dwika Herdiawan",
        "published": "2018-4-18",
        "citations": 1,
        "abstract": "The effective supervision assists the teacher trainees or supervisee develop themselves in terms of the professional development such as teaching instrustions or methods, content, and also pedagogy. This article is aimed to explore as well as discuss the related literature particularly on clinical supervision. It describes best practices in clinical supervision through a set of relevant previous studies, and the roles of supervisor, supervisee, and the students in relation to the use of clinical supervision models used. It also deals with providing some useful guidelines for students and supervisors (not only for clinical students) to pursue the development of relationship among them in conducting the clinical supervision models. Therefore, the review of related literature focuses on clinical supervision which is expected to help the whole parties in the supervisory process to accelerate their goals as well as obejctives clearly, and also to minimize the potential problems and facilitate the implementation of effective supervision.Keywords: Clinical Supervision Models, , Teaching and Learning Language, Supervisor, Supervisee.",
        "link": "http://dx.doi.org/10.33603/rill.v1i1.1079"
    },
    {
        "id": 13178,
        "title": "Competing models of liaison acquisition: Evidence from corpus and experimental data",
        "authors": "Angelica Buerkin-Pontrelli, Jennifer Culbertson, Géraldine Legendre, Thierry Nazzi",
        "published": "2017",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1353/lan.2017.0006"
    },
    {
        "id": 13179,
        "title": "Retrofitting Light-weight Language Models for Emotions using Supervised Contrastive Learning",
        "authors": "Sapan Shah, Sreedhar Reddy, Pushpak Bhattacharyya",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.222"
    },
    {
        "id": 13180,
        "title": "Understanding Unintended Memorization in Language Models Under Federated Learning",
        "authors": "Om Dipakbhai Thakkar, Swaroop Ramaswamy, Rajiv Mathews, Francoise Beaufays",
        "published": "2021",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.privatenlp-1.1"
    },
    {
        "id": 13181,
        "title": "Coping with large multi-level class in English language learning",
        "authors": "Benny Kurnianto",
        "published": "2021-1-27",
        "citations": 0,
        "abstract": "To improve students’ English proficiency, Indonesian Civil Aviation Institute has placed TOEFL® preparation in the curriculum of study program. Nevertheless, the learning design was not common compared with similar program of TOEFL® preparation in another institution. ICAI put a single teacher in class consisted of 24 students with various skills. Consequently, the English teacher had to employ a strategy to cope with this large multilevel class. This qualitative research was conducted to analyze the teacher’s strategy. Its purpose is to give enlightenment toward the conformity between learning design and learning objectives. A pre-test and post-test were given to a determined class and the grades were compared to see the fulfillment of the objective. An observation and note taking was undertaken during the learning process to explain the strategy. The result shows that the teacher occupy cooperative learning through flexible grouping to cope the class challenge. While the result shows 57% students in the class were able to gain 500 as minimum required score, it has implication in examining the learning design in broader context.Keywords: classroom; multilevel; teacher-students ratio",
        "link": "http://dx.doi.org/10.33474/j-reall.v2i1.9212"
    },
    {
        "id": 13182,
        "title": "Transcending the Digital Divide: Video Use Communication Models for the English Language Learning Classroom",
        "authors": "Terrill Reid McLain",
        "published": "2018-8-31",
        "citations": 0,
        "abstract": "With the development of web 2.0 tools, many companies are rushing to meet the demand and create attractive and useful Educational Technology (EdTech) that appeal to instructors to implement in their classes. Many of these tools include video services that are available to everyone with a connected device. ESL Instructors also look for new and engaging activities and techniques to help their students L2 confidence and language practice. Research shows that video is a powerful and useful tool for educators to boost language learning in the classroom. When deciding to implement video in the classroom, it is essential to understand the different attributes that students experience surrounding the consumption, the creation, and interaction with video. To effectively implement video in the English class it is also necessary to understand how videos replicate elements of the communication process to determine what kind of—if any—interaction will take place. Once the attributes are understood, and the communication model is chosen, teachers can select a tool that fits their pedagogical practice and logistical situation. This paper explores the justification and use categories of video in the context of English language learning, introduces the idea of Video Use Communication Models to help instructors choose a tool that will align with their pedagogical goals, and advocate the promotion of video solutions that allow affordable and available access for an English teacher who wants to use video.  ",
        "link": "http://dx.doi.org/10.5296/ijele.v6i2.13581"
    },
    {
        "id": 13183,
        "title": "T5QL: Taming language models for SQL generation",
        "authors": "Samuel David Arcadinho, David Aparicio, Hugo Veiga, Antonio Alegria",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gem-1.23"
    },
    {
        "id": 13184,
        "title": "Privacy Implications of Retrieval-Based Language Models",
        "authors": "Yangsibo Huang, Samyak Gupta, Zexuan Zhong, Kai Li, Danqi Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.921"
    },
    {
        "id": 13185,
        "title": "UNKs Everywhere: Adapting Multilingual Language Models to New Scripts",
        "authors": "Jonas Pfeiffer, Ivan Vulić, Iryna Gurevych, Sebastian Ruder",
        "published": "2021",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.800"
    },
    {
        "id": 13186,
        "title": "Improving OOV Detection and Resolution with External Language Models in Acoustic-to-Word ASR",
        "authors": "Hirofumi Inaguma, Masato Mimura, Shinsuke Sakai, Tatsuya Kawahara",
        "published": "2018-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt.2018.8639563"
    },
    {
        "id": 13187,
        "title": "Context Limitations Make Neural Language Models More Human-Like",
        "authors": "Tatsuki Kuribayashi, Yohei Oseki, Ana Brassard, Kentaro Inui",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.712"
    },
    {
        "id": 13188,
        "title": "Pragmatic competence of pre-trained language models through the lens of discourse connectives",
        "authors": "Lalchand Pandia, Yan Cong, Allyson Ettinger",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.conll-1.29"
    },
    {
        "id": 13189,
        "title": "Self-Detoxifying Language Models via Toxification Reversal",
        "authors": "Chak Leong, Yi Cheng, Jiashuo Wang, Jian Wang, Wenjie Li",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.269"
    },
    {
        "id": 13190,
        "title": "On the Representational Capacity of Recurrent Neural Language Models",
        "authors": "Franz Nowak, Anej Svete, Li Du, Ryan Cotterell",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.434"
    },
    {
        "id": 13191,
        "title": "ECONET: Effective Continual Pretraining of Language Models for Event Temporal Reasoning",
        "authors": "Rujun Han, Xiang Ren, Nanyun Peng",
        "published": "2021",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.436"
    },
    {
        "id": 13192,
        "title": "SAC3: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency",
        "authors": "Jiaxin Zhang, Zhuohang Li, Kamalika Das, Bradley Malin, Sricharan Kumar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.1032"
    },
    {
        "id": 13193,
        "title": "Large Classes in the Context of Teaching English as a Foreign Language",
        "authors": "Basmah Ali Abu-ghararah",
        "published": "2021-4-1",
        "citations": 0,
        "abstract": "The purpose of this study is to explore the techniques used by teachers of English as a foreign language (EFL) in teaching the four language skills to students in large classes in Madinah, Saudi Arabia. This study also seeks to determine the most effective technique to teaching large classes by examining teachers’ experiences. Additionally, this study investigates the teachers’ use of language techniques for language classes with respect to gender, qualification, years of experience, and level of teaching. The subjects of the study were 307 EFL teachers from Saudi schools. This study used descriptive statistical methods to examine the teachers’ preferred techniques in teaching the four central English skills in a large class setting. The results show that EFL teachers use a variety of language techniques in teaching graphic skills rather than aural ones. Further, gender and level of teaching shape their preferences for using certain techniques when teaching language skills in large classes. The study raised some questions for further research.",
        "link": "http://dx.doi.org/10.17507/tpls.1104.01"
    },
    {
        "id": 13194,
        "title": "When to Use Large Language Model: Upper Bound Analysis of BM25 Algorithms in Reading Comprehension Task",
        "authors": "Tingzhen Liu, Qianqian Xiong, Shengxi Zhang",
        "published": "2023-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icnlp58431.2023.00049"
    },
    {
        "id": 13195,
        "title": "Voxceleb: Large-scale speaker verification in the wild",
        "authors": "Arsha Nagrani, Joon Son Chung, Weidi Xie, Andrew Zisserman",
        "published": "2020-3",
        "citations": 242,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2019.101027"
    },
    {
        "id": 13196,
        "title": "Document Language Models, Query Models, and Risk Minimization for Information Retrieval",
        "authors": "John Lafferty, Chengxiang Zhai",
        "published": "2017-8-2",
        "citations": 7,
        "abstract": "We present a framework for information retrieval that combines document models and query models using a probabilistic ranking function based on Bayesian decision theory. The framework suggests an operational retrieval model that extends recent developments in the language modeling approach to information retrieval. A language model for each document is estimated, as well as a language model for each query, and the retrieval problem is cast in terms of risk minimization. The query language model can be exploited to model user preferences, the context of a query, synonomy and word senses. While recent work has incorporated word translation models for this purpose, we introduce a new method using Markov chains defined on a set of documents to estimate the query models. The Markov chain method has connections to algorithms from link analysis and social networks. The new approach is evaluated on TREC collections and compared to the basic language modeling approach and vector space models together with query expansion using Rocchio. Significant improvements are obtained over standard query expansion methods for strong baseline TF-IDF systems, with the greatest improvements attained for short queries on Web data.",
        "link": "http://dx.doi.org/10.1145/3130348.3130375"
    },
    {
        "id": 13197,
        "title": "Training Speaker Recognition Models with Recording-Level Labels",
        "authors": "Tanel Alumae",
        "published": "2018-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt.2018.8639601"
    },
    {
        "id": 13198,
        "title": "Language and Languages",
        "authors": "",
        "published": "2020-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108480659.003"
    },
    {
        "id": 13199,
        "title": "Introduction",
        "authors": "Dirk Damsma",
        "published": "2019-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1163/9789004395497_002"
    },
    {
        "id": 13200,
        "title": "Language models enable zero-shot prediction of RNA secondary structures including pseudoknots",
        "authors": "Tiansu Gong, Dongbo Bu",
        "published": "No Date",
        "citations": 0,
        "abstract": "Current deep learning-based models for predicting RNA secondary structures face challenges in achieving high generalization ability. At the same time, a vast repository of unlabeled non-coding RNA (ncRNA) sequences remains untapped for structure prediction tasks. To address this challenge, we trained RNA-km, a foundation language model that enables zero-shot prediction of RNA secondary structures including pseudoknots. For the end, we incorporated specific modifications into the language model training process, including k-mer masking strategy and relative positional encoding. RNA-km are trained on 23 million ncRNA sequences in a self-supervised manner, gaining the advantages of high generalization ability. For a target RNA sequence, we make a zero-shot secondary structure prediction with the attention maps provided by RNA-km and a specified minimum-cost flow algorithm. Our results on popular benchmark datasets demonstrate that RNA-km exhibits high generalization abilities, excelling in zero-shot predictions for RNA secondary structures. In addition, the attention maps provided by the model capture intricate structural relationships, as evidenced by accurate pseudoknot predictions and precise identification of long-distance base pairs. We anticipate that RNA-km enhances the predictive capacity and robustness of existing models, thereby improving their ability to accurately predict structures for novel RNA sequences.",
        "link": "http://dx.doi.org/10.1101/2024.01.27.577533"
    },
    {
        "id": 13201,
        "title": "Language Models for Multimessenger Astronomy",
        "authors": "Vladimir Sotnikov, Anastasiia Chaikova",
        "published": "2023-5-1",
        "citations": 0,
        "abstract": "With the increasing reliance of astronomy on multi-instrument and multi-messenger observations for detecting transient phenomena, communication among astronomers has become more critical. Apart from automatic prompt follow-up observations, short reports, e.g., GCN circulars and ATels, provide essential human-written interpretations and discussions of observations. These reports lack a defined format, unlike machine-readable messages, making it challenging to associate phenomena with specific objects or coordinates in the sky. This paper examines the use of large language models (LLMs)—machine learning models with billions of trainable parameters or more that are trained on text—such as InstructGPT-3 and open-source Flan-T5-XXL for extracting information from astronomical reports. The study investigates the zero-shot and few-shot learning capabilities of LLMs and demonstrates various techniques to improve the accuracy of predictions. The study shows the importance of careful prompt engineering while working with LLMs, as demonstrated through edge case examples. The study’s findings have significant implications for the development of data-driven applications for astrophysical text analysis.",
        "link": "http://dx.doi.org/10.3390/galaxies11030063"
    },
    {
        "id": 13202,
        "title": "Classifying Drug Ratings Using User Reviews with Transformer-Based Language Models",
        "authors": "Akhil Shiju, Zhe He",
        "published": "No Date",
        "citations": 3,
        "abstract": "AbstractDrugs.com provides users’ textual reviews and numeric ratings of drugs. However, text reviews may not always be consistent with the numeric ratings. Overly positive or negative rating may be misleading. In this project, to classify user ratings of drugs with their textual reviews, we built classification models using traditional machine learning and deep learning approaches. Machine learning models including Random Forest and Naive Bayesian classifiers were built using TF-IDF features as input. Also, transformer-based neural network models including BERT, BioBERT, RoBERTa, XLNet, ELECTRA, and ALBERT were built using the raw text as input. Overall, BioBERT model outperformed the other models with an overall accuracy of 87%. We further identified UMLS concepts from the postings and analyzed their semantic types in the postings stratified by the classification result. This research demonstrated that transformer-based models can be used to classify drug reviews and identify reviews that are inconsistent with the ratings.",
        "link": "http://dx.doi.org/10.1101/2021.04.15.21255573"
    },
    {
        "id": 13203,
        "title": "LogFiT: Log Anomaly Detection using Fine-Tuned Language Models",
        "authors": "Crispin Almodovar, Fariza Sabrina, Sarvnaz Karimi, Salahuddin Azad",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>System logs are a valuable source of information for monitoring and maintaining the security and stability of computer systems. Techniques based on Deep Learning and Natural Language Processing have demonstrated effectiveness in detecting abnormal behavior from these system logs. However existing approaches are inflexible and impractical: techniques that rely on log templates are unable to handle variability in log content, while classification-based approaches require labeled data for supervised training. In this paper, a novel log anomaly detection model named LogFiT is proposed. The LogFiT model is robust to changes in log content and only requires self-supervised training. The LogFiT model uses a pretrained BERT-based language model fine-tuned to recognise the linguistic patterns of the normal log data. The LogFiT model is trained using masked token prediction on the normal log data only. Consequently when presented with the new log data, the model's top-k token prediction accuracy is used as threshold for determining whether the new log data has deviated from the normal log data. Experimental results show that LogFiT's F1 score exceeds that of baselines on the HDFS, BGL and Thunderbird datasets. Critically, when variability in the log data is introduced during evaluation, LogFiT's effectiveness surpasses that of the baseline models.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22290982"
    },
    {
        "id": 13204,
        "title": "Language Models Learn Sentiment and Substance from 11,000 Psychoactive Experiences",
        "authors": "Sam Freesun Friedman, Galen Ballentine",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nWith novel hallucinogens poised to enter psychiatry, a unified framework for quantifying which changes in consciousness are optimal for treatment is needed. Using transformers (i.e. BERT) and 11,816 publicly-available drug testimonials, we first predicted 28-dimensions of sentiment across each narrative, and then validated these predictions with adjudication by a clinical psychiatrist. Secondly, we fine-tuned BERT to predict biochemical and demographic information from natural language testimonials of drug experiences. Thirdly, canonical correlation analysis (CCA) linked 52 drugs' receptor affinities with word usage, revealing 11 statistically-significant latent receptor-experience factors, each mapped to a 3D cortical atlas. Together, these machine learning methods elucidate a neurobiologically-informed, temporally-sensitive portrait of drug-induced subjective experiences. The models’ results converged, revealing a pervasive distinction between the universal psychedelic heights of feeling in contrast to the grim, mundane, and personal experiences with addiction and mental illness. MDMA was linked to \"Love\", DMT and 5-MeO-DMT to \"Mystical Experiences\" and “Entities and Beings”, and other tryptamines to \"Surprise\", \"Curiosity\" and \"Realization\". Applying these models to real-time biofeedback, practitioners could delicately calibrate the course of therapeutic sessions.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1942143/v2"
    },
    {
        "id": 13205,
        "title": "PatternRank: Leveraging Pretrained Language Models and Part of Speech for Unsupervised Keyphrase Extraction",
        "authors": "Tim Schopf, Simon Klimek, Florian Matthes",
        "published": "2022",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011546600003335"
    },
    {
        "id": 13206,
        "title": "Application Practice of Instrument Control System in Large Unit",
        "authors": "",
        "published": "2021-12-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i12.418"
    },
    {
        "id": 13207,
        "title": "Application of Large Displacement Side Drilling in Oilfield Development",
        "authors": "",
        "published": "2022-8-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i8(06).28"
    },
    {
        "id": 13208,
        "title": "Study on Hoisting Technology of Large Eccentric Cylinder Structure",
        "authors": "",
        "published": "2022-3-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i3(05).01"
    },
    {
        "id": 13209,
        "title": "Dual Language Bilingual Education",
        "authors": "Kathryn I. Henderson, Deborah K. Palmer",
        "published": "2020-6-22",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781788928106"
    },
    {
        "id": 13210,
        "title": "Language Models and Cognitive Automation for Economic Research",
        "authors": "Anton Korinek",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4356243"
    },
    {
        "id": 13211,
        "title": "Multiple quantitative predictors, dealing with large models, and Bayesian ANOVA",
        "authors": "Santiago Barreda, Noah Silbert",
        "published": "2023-4-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003285878-11"
    },
    {
        "id": 13212,
        "title": "Revisiting Simple Neural Probabilistic Language Models",
        "authors": "Simeng Sun, Mohit Iyyer",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.407"
    },
    {
        "id": 13213,
        "title": "Do Grammatical Error Correction Models Realize Grammatical Generalization?",
        "authors": "Masato Mita",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.28.1331"
    },
    {
        "id": 13214,
        "title": "Analyzing Individual Neurons in Pre-trained Language Models",
        "authors": "Nadir Durrani, Hassan Sajjad, Fahim Dalvi, Yonatan Belinkov",
        "published": "2020",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.395"
    },
    {
        "id": 13215,
        "title": "The structure of situation models as revealed by anaphor resolution",
        "authors": "Sashank Varma, Amanda Janssen",
        "published": "2019-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.langsci.2018.09.002"
    },
    {
        "id": 13216,
        "title": "Estimating Marginal Probabilities of n-grams for Recurrent Neural Language Models",
        "authors": "Thanapon Noraset, Doug Downey, Lidong Bing",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d18-1322"
    },
    {
        "id": 13217,
        "title": "Assessing Political Inclination of Bangla Language Models",
        "authors": "Surendrabikram Thapa, Ashwarya Maratha, Khan Md Hasib, Mehwish Nasim, Usman Naseem",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.banglalp-1.8"
    },
    {
        "id": 13218,
        "title": "Attacking a Transformer-Based Models for Arabic Language as Low Resources Language (LRL) Using Word-Substitution Methods",
        "authors": "Hanin Alshalan, Banafsheh Rekabdar",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/transai60598.2023.00025"
    },
    {
        "id": 13219,
        "title": "Memory and Knowledge Augmented Language Models for Inferring Salience in Long-Form Stories",
        "authors": "David Wilmot, Frank Keller",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.65"
    },
    {
        "id": 13220,
        "title": "RuleBERT: Teaching Soft Rules to Pre-Trained Language Models",
        "authors": "Mohammed Saeed, Naser Ahmadi, Preslav Nakov, Paolo Papotti",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.110"
    },
    {
        "id": 13221,
        "title": "Symbolic Kinetic Models in Python (SKiMpy): Intuitive modeling of large-scale biological kinetic models",
        "authors": "Daniel R. Weilandt, Pierre Salvy, Maria Masid, Georgios Fengos, Robin Denhardt-Erikson, Zhaleh Hosseini, Vassily Hatzimanikatis",
        "published": "No Date",
        "citations": 5,
        "abstract": "AbstractMotivationLarge-scale kinetic models are an invaluable tool to understand the dynamic and adaptive responses of biological systems. The development and application of these models have been limited by the availability of computational tools to build and analyze large-scale models efficiently. The toolbox presented here provides the means to implement, parametrize and analyze large-scale kinetic models intuitively and efficiently.ResultsWe present a Python package (SKiMpy) bridging this gap by implementing an efficient kinetic modeling toolbox for the semiautomatic generation and analysis of large-scale kinetic models for various biological domains such as signaling, gene expression, and metabolism. Furthermore, we demonstrate how this toolbox is used to parameterize kinetic models around a steady-state reference efficiently. Finally, we show how SKiMpy can imple-ment multispecies bioreactor simulations to assess biotechnological processes.AvailabilityThe software is available as a Python 3 package on GitHub:https://github.com/EPFL-LCSB/SKiMpy, along with adequate documentation.Contactvassily.hatzimanikatis@epfl.ch",
        "link": "http://dx.doi.org/10.1101/2022.01.17.476618"
    },
    {
        "id": 13222,
        "title": "Multimodal Data Augmentation for Image Captioning using Diffusion Models",
        "authors": "Changrong Xiao, Sean Xin Xu, Kunpeng Zhang",
        "published": "2023-11-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3607827.3616839"
    },
    {
        "id": 13223,
        "title": "Analysis of HVAC Design of Large-scale Commercial Complex",
        "authors": "",
        "published": "2022-7-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i7(04).26"
    },
    {
        "id": 13224,
        "title": "The Meaning Extraction Method: An Approach to Evaluate Content Patterns from Large-Scale Language Data",
        "authors": "David Matthew Markowitz",
        "published": "No Date",
        "citations": 0,
        "abstract": "Qualitative content analyses often rely on a top-down approach to understand themes in a collection of texts. A codebook prescribes how humans should qualitatively judge if a text fits a theme based on rules and judgment criteria. Qualitative approaches are challenging because they require many resources (e.g., coders, training, rounds of coding), can be affected by researcher or coder bias, may miss meaningful patterns that deviate from the codebook, and often use a subsample of the data. A complementary, bottom-up approach — the Meaning Extraction Method — has been popular in social psychology but rarely applied to communication research. This paper outlines the value of the Meaning Extraction Method, concluding with a guide to conduct analyses of content and themes from massive and complete datasets, quantitatively. The Meaning Extraction Method is performed on a public and published archive of pet adoption profiles to demonstrate the approach. Considerations for communication research are offered.",
        "link": "http://dx.doi.org/10.31234/osf.io/ra5ze"
    },
    {
        "id": 13225,
        "title": "The Challenges of Large-Scale, Web-based Language Datasets: Word Length and Predictability Revisited",
        "authors": "Stephan Meylan, Tom Griffiths",
        "published": "No Date",
        "citations": 1,
        "abstract": "Language research has come to rely heavily on large-scale, web-based datasets. These datasets can present significant methodological challenges, requiring researchers to make a number of decisions about how they are collected, represented, and analyzed. These decisions often concern long-standing challenges in corpus-based language research, including determining what counts as a word, deciding which words should be analyzed, and matching sets of words across languages. We illustrate these challenges by revisiting \"Word lengths are optimized for efficient communication\" (Piantadosi, Tily, &amp; Gibson,2011), which found that word lengths in 11 languages are more strongly correlated with their average predictability (or average information content) than their frequency. Using what we argue to be best practices for large-scale corpus analyses, we find significantly attenuated support for this result, and demonstrate that a stronger relationship obtains between word frequency and length for a majority of the languages in the sample. We consider the implications of the results for language research more broadly and provide several recommendations to researchers regarding best practices.",
        "link": "http://dx.doi.org/10.31234/osf.io/6832r"
    },
    {
        "id": 13226,
        "title": "LADAC: Large Language Model-driven Auto-Designer for Analog Circuits",
        "authors": "Chengjie Liu, Yijiang Liu, Yuan Du, Li Du",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36227/techrxiv.170473941.10097233/v1"
    },
    {
        "id": 13227,
        "title": "Large Language Model-Driven Evaluation of Medical Records Using MedCheckLLM",
        "authors": "Marc Cicero Schubert, Wolfgang Wick, Varun Venkataramani",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractLarge Language Models (LLMs) offer potential in healthcare, especially in the evaluation of medical documents. This research introduces MedCheckLLM, a multi-step framework designed for the systematic assessment of medical records against established evidence-based guidelines, a process termed ‘guideline-in-the-loop’. By keeping the guidelines separate from the LLM’s training data, this approach emphasizes validity, flexibility, and interpretability. Suggested evidence-based guidelines are externally accessed and fed back into the LLM for a evaluation. The method enables implementation of guideline updates and personalized protocols for specific patient groups without retraining. We applied MedCheckLLM to expert-validated simulated medical reports, focusing on headache diagnoses following International Headache Society guidelines. Findings revealed MedCheckLLM correctly extracted diagnoses, suggested appropriate guidelines, and accurately evaluated 87% of checklist items, with its evaluations aligning significantly with expert opinions. The system not only enhances healthcare quality assurance but also introduces a transparent and efficient means of applying LLMs in clinical settings. Future considerations must address privacy and ethical concerns in actual clinical scenarios.",
        "link": "http://dx.doi.org/10.1101/2023.11.01.23297684"
    },
    {
        "id": 13228,
        "title": "LogFiT: Log Anomaly Detection using Fine-Tuned Language Models",
        "authors": "Crispin Almodovar, Fariza Sabrina, Sarvnaz Karimi, Salahuddin Azad",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>System logs are a valuable source of information for monitoring and maintaining the security and stability of computer systems. Techniques based on Deep Learning and Natural Language Processing have demonstrated effectiveness in detecting abnormal behavior from these system logs. However existing approaches are inflexible and impractical: techniques that rely on log templates are unable to handle variability in log content, while classification-based approaches require labeled data for supervised training. In this paper, a novel log anomaly detection model named LogFiT is proposed. The LogFiT model is robust to changes in log content and only requires self-supervised training. The LogFiT model uses a pretrained BERT-based language model fine-tuned to recognise the linguistic patterns of the normal log data. The LogFiT model is trained using masked token prediction on the normal log data only. Consequently when presented with the new log data, the model's top-k token prediction accuracy is used as threshold for determining whether the new log data has deviated from the normal log data. Experimental results show that LogFiT's F1 score exceeds that of baselines on the HDFS, BGL and Thunderbird datasets. Critically, when variability in the log data is introduced during evaluation, LogFiT's effectiveness surpasses that of the baseline models.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22290982.v1"
    },
    {
        "id": 13229,
        "title": "IX. Can the Effect Precede the Cause?",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-010"
    },
    {
        "id": 13230,
        "title": "Qualitative Analysis of Semantic Language Models",
        "authors": "",
        "published": "2019-5-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1163/9789004399297_007"
    },
    {
        "id": 13231,
        "title": "Information Theory Meets Power Laws",
        "authors": "Łukasz Dębowski",
        "published": "2020-9-14",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384"
    },
    {
        "id": 13232,
        "title": "Estimating the Personality of White-Box Language Models",
        "authors": "Saketh reddy Karra, Son  The Nguyen, Theja Tulabandhula",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4598766"
    },
    {
        "id": 13233,
        "title": "Weakly and Semi-Supervised Learning for Arabic Text Classification using Monodialectal Language Models",
        "authors": "Reem AlYami, Rabah Al-Zaidy",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.wanlp-1.24"
    },
    {
        "id": 13234,
        "title": "Medical Visual Textual Entailment for Numerical Understanding of Vision-and-Language Models",
        "authors": "Hitomi Yanaka, Yuta Nakamura, Yuki Chida, Tomoya Kurosawa",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.clinicalnlp-1.2"
    },
    {
        "id": 13235,
        "title": "Improving Language Models’ Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary",
        "authors": "Myeongjun Jang, Thomas Lukasiewicz",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.527"
    },
    {
        "id": 13236,
        "title": "MoPe: Model Perturbation based Privacy Attacks on Language Models",
        "authors": "Marvin Li, Jason Wang, Jeffrey Wang, Seth Neel",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.842"
    },
    {
        "id": 13237,
        "title": "Community-Based Language Learning: Integrating Language and Service",
        "authors": "J. Patrick Boyle, Denise M. Overfield",
        "published": "2023-6-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003443636-12"
    },
    {
        "id": 13238,
        "title": "Effective Unsupervised Domain Adaptation with Adversarially Trained Language Models",
        "authors": "Thuy-Trang Vu, Dinh Phung, Gholamreza Haffari",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.497"
    },
    {
        "id": 13239,
        "title": "Improving Low-Resource Languages in Pre-Trained Multilingual Language Models",
        "authors": "Viktor Hangya, Hossain Shaikh Saadi, Alexander Fraser",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.822"
    },
    {
        "id": 13240,
        "title": "Code-switched Language Models Using Dual RNNs and Same-Source Pretraining",
        "authors": "Saurabh Garg, Tanmay Parekh, Preethi Jyothi",
        "published": "2018",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d18-1346"
    },
    {
        "id": 13241,
        "title": "PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models",
        "authors": "Torsten Scholak, Nathan Schucher, Dzmitry Bahdanau",
        "published": "2021",
        "citations": 52,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.779"
    },
    {
        "id": 13242,
        "title": "Investigating syntactic transfer in second language learning of neural language models",
        "authors": "Keonwoo Koo, Euhee Kim",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21296/jls.2023.12.107.67"
    },
    {
        "id": 13243,
        "title": "Exploring the Functional and Geometric Bias of Spatial Relations\n            Using Neural Language Models",
        "authors": "Simon Dobnik, Mehdi Ghanimifard, John Kelleher",
        "published": "2018",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-1401"
    },
    {
        "id": 13244,
        "title": "GPTs Don’t Keep Secrets: Searching for Backdoor Watermark Triggers in Autoregressive Language Models",
        "authors": "Evan Lucas, Timothy Havens",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.trustnlp-1.21"
    },
    {
        "id": 13245,
        "title": "Artificial intelligence language models and the false fantasy of participatory language policies",
        "authors": " Mandy Lau",
        "published": "2021-9-13",
        "citations": 1,
        "abstract": "Artificial intelligence neural language models learn from a corpus of online language data, often drawn directly from user-generated content through crowdsourcing or the gift economy, bypassing traditional keepers of language policy and planning (such as governments and institutions). Here lies the dream that the languages of the digital world can bend towards individual needs and wants, and not the traditional way around. Through the participatory language work of users, linguistic diversity, accessibility, personalization, and inclusion can be increased. However, the promise of a more participatory, just, and emancipatory language policy as a result of neural language models is a false fantasy. I argue that neural language models represent a covert and oppressive form of language policy that benefits the privileged and harms the marginalized. Here, I examine the ideology underpinning neural language models and investigate the harms that result from these emerging subversive regulatory bodies.",
        "link": "http://dx.doi.org/10.25071/2564-2855.5"
    },
    {
        "id": 13246,
        "title": "A General Procedure for Improving Language Models in Low-Resource Speech Recognition",
        "authors": "Qian Liu, Wei-Qiang Zhang, Jia Liu, Yao Liu",
        "published": "2019-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ialp48816.2019.9037726"
    },
    {
        "id": 13247,
        "title": "Language-Independent Speaker Anonymization Approach Using Self-Supervised Pre-Trained Models",
        "authors": "Xiaoxiao Miao, Xin Wang, Erica Cooper, Junichi Yamagishi, Natalia Tomashenko",
        "published": "2022-6-28",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/odyssey.2022-39"
    },
    {
        "id": 13248,
        "title": "Learning Basics and Linear Models",
        "authors": "Yoav Goldberg",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-02165-7_2"
    },
    {
        "id": 13249,
        "title": "On the Cusp of Comprehensibility: Can Language Models Distinguish Between Metaphors and Nonsense?",
        "authors": "Bernadeta Griciūtė, Marc Tanti, Lucia Donatelli",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.flp-1.25"
    },
    {
        "id": 13250,
        "title": "Pushdown Layers: Encoding Recursive Structure in Transformer Language Models",
        "authors": "Shikhar Murty, Pratyusha Sharma, Jacob Andreas, Christopher Manning",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.195"
    },
    {
        "id": 13251,
        "title": "Rationale-Enhanced Language Models are Better Continual Relation Learners",
        "authors": "Weimin Xiong, Yifan Song, Peiyi Wang, Sujian Li",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.958"
    },
    {
        "id": 13252,
        "title": "Computational Modeling of Bilingual Language Learning: Current Models and Future Directions",
        "authors": "Ping Li, Qihui Xu",
        "published": "2023-12",
        "citations": 2,
        "abstract": "AbstractThe last two decades have seen a significant amount of interest in bilingual language learning and processing. A number of computational models have also been developed to account for bilingualism, with varying degrees of success. In this article, we first briefly introduce the significance of computational approaches to bilingual language learning, along with a discussion of the major contributions of current models, their implications, and their limitations. We show that the current models have contributed to progress in understanding the bilingual mind, but significant gaps exist. We advocate a new research agenda integrating progress across different disciplines, such as computational neuroscience, natural language processing, and first language acquisition, to construct a pluralist computational account that combines high‐level cognitive theories and neurobiological foundations for bilingual language learning. We outline the contributions and promises of this interdisciplinary approach in which we view bilingual language learning as a dynamic, interactive, and developmental process.",
        "link": "http://dx.doi.org/10.1111/lang.12529"
    },
    {
        "id": 13253,
        "title": "Modeling Language Issues",
        "authors": "Charles M. Eastman",
        "published": "2018-2-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315138671-14"
    },
    {
        "id": 13254,
        "title": "Quantized Embedding Vectors for Controllable Diffusion Language Models",
        "authors": "Cheng Kang, Xinye Chen, Yong Hu, Daniel Novak",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36227/techrxiv.170723453.36138311/v1"
    },
    {
        "id": 13255,
        "title": "Probabilistic language models in cognitive neuroscience: promises and pitfalls",
        "authors": "Kristijan Armeni, Roel M. Willems, Stefan Frank",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractCognitive neuroscientists of language comprehension study how neural computations relate to cognitive computations during comprehension. On the cognitive part of the equation, it is important that the computations and processing complexity are explicitly defined. Probabilistic language models can be used to give a computationally explicit account of language complexity during comprehension. Whereas such models have so far predominantly been evaluated against behavioral data, only recently have the models been used to explain neurobiological signals. Measures obtained from these models emphasize the probabilistic, information-processing view of language understanding and provide a set of tools that can be used for testing neural hypotheses about language comprehension. Here, we provide a cursory review of the theoretical foundations and example neuroimaging studies employing probabilistic language models. We high-light the advantages and potential pitfalls of this approach and indicate avenues for future research.",
        "link": "http://dx.doi.org/10.1101/168161"
    },
    {
        "id": 13256,
        "title": "Comparative Evaluation of Language Models in Summarizing Chinese Healthcare Exam Findings",
        "authors": "Min Xu, Lucheng Zheng",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground and Objectives: Summarizing Chinese healthcare exam findings (SCHEF) is a critical and challenging task that requires extensive medical knowledge. Despite its importance, research on automating the generation of such summaries remains limited.We aim to develop a standardized Chinese Healthcare Exam Summarization (CHES) dataset and evaluate the performance of various sequence-to-sequence(seq2seq) models on the task of summarizing overall conclusions of healthcare exam findings. Our primary focus is on assessing the models’applicability, generalization, and transferability in this context. \nMaterials and Methods: We collect healthcare exam data from over 110, 000 individuals across two centers, creating the anonymized and cleaned Chinese Healthcare Exam Summarization (CHES) dataset for training and evaluating summarization models. We conduct comprehensive experiments on a broad range of summarization methods, including the manual extraction baseline method, a variety of RNN models (RNN, GRU, LSTM), PointerNet with a copy mechanism, convolutional seq2seq techniques, and self-attention-driven architectures such as Transformer, RoBERTa, and MacBERT. Additionally, we explore the significance of domain adaptation for BERT-based models on specific task datasets. \nResults: Our experiments show that BERT-based models demonstrate the best performance in generating summaries for Chinese healthcare exam findings, as evidenced by F1 and recall evaluation metrics. Through this domain adaptation on task-specific datasets, we notice a substantial improvement of approximately 3% in the generated text summarization. \nConclusion: Our study demonstrates that advanced seq2seq language models can be readily employed for generating Chinese healthcare exam findings summarizations without requiring substantial modifications. Further pretraining language models on target datasets considerably improves summary quality by enhancing adherence to medical semantic standards, as it enables the model to better capture contextual and semantic information.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3847983/v1"
    },
    {
        "id": 13257,
        "title": "Communicative Language Teaching in Large Mixed-level EFL Classes",
        "authors": " 양소영",
        "published": "2019-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.35771/engdoi.2019.32.3.006"
    },
    {
        "id": 13258,
        "title": "Automated Writing Evaluation with a Large Pre-Trained Language Model a Preliminary Study",
        "authors": "Yusuf Emre Yeşilyurt, Sezan Sezgin",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4545244"
    },
    {
        "id": 13259,
        "title": "Computational Evaluation of Language Models by Considering Various Scaling Properties for Processing Natural Languages",
        "authors": "Sajini G",
        "published": "2020-7-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5373/jardcs/v12sp7/20202159"
    },
    {
        "id": 13260,
        "title": "A Brief Introduction to Transformers as Language Models",
        "authors": "Mircea Andrecut",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4521095"
    },
    {
        "id": 13261,
        "title": "4. Information Processing Models",
        "authors": "",
        "published": "2017-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.12987/9780300129410-006"
    },
    {
        "id": 13262,
        "title": "Learning Chess with Language Models and Transformers",
        "authors": "Michael DeLeo, Erhan Guven",
        "published": "2022-9-17",
        "citations": 1,
        "abstract": "Representing a board game and its positions by text-based notation enables the possibility of NLP applications. Language models, can help gain insight into a variety of interesting problems such as unsupervised learning rules of a game, detecting player behavior patterns, player attribution, and ultimately learning the game to beat state of the art. In this study, we applied BERT models, first to the simple Nim game to analyze its performance in the presence of noise in a setup of a few-shot learning architecture. We analyzed the model performance via three virtual players, namely Nim Guru, Random player, and Q-learner. In the second part, we applied the game learning language model to the chess game, and a large set of grandmaster games with exhaustive encyclopedia openings. Finally, we have shown that model practically learns the rules of the chess game and can survive games against Stockfish at a category-A rating level.",
        "link": "http://dx.doi.org/10.5121/csit.2022.121515"
    },
    {
        "id": 13263,
        "title": "Structure-Informed Protein Language Models are Robust Predictors for Variant Effects",
        "authors": "Yuanfei Sun, Yang Shen",
        "published": "No Date",
        "citations": 2,
        "abstract": "Abstract\nPredicting protein variant effects through machine learning is often challenged by the scarcity of experimentally measured effect labels. Recently, protein language models (pLMs) emerge as zero-shot predictors without the need of effect labels, by modeling the evolutionary distribution of functional protein sequences. However, biological contexts important to variant effects are implicitly modeled and effectively marginalized. By assessing the sequence awareness and the structure awareness of pLMs, we find that their improvements often correlate with better variant effect prediction but their tradeoff can present a barrier as observed in over-finetuning to specific family sequences. We introduce a framework of structure-informed pLMs (SI-pLMs) to inject protein structural contexts purposely and controllably, by extending masked sequence denoising in conventional pLMs to cross-modality denoising. Our SI-pLMs are applicable to revising any sequence-only pLMs through model architecture and training objectives. They do not require structure data as model inputs for variant effect prediction and only use structures as context provider and model regularizer during training. Numerical results over deep mutagenesis scanning benchmarks show that our SI-pLMs, despite relatively compact sizes, are robustly top performers against competing methods including other pLMs, regardless of the target protein family's evolutionary information content or the tendency to overfitting / over-finetuning. Learned distributions in structural contexts could enhance sequence distributions in predicting variant effects. Ablation studies reveal major contributing factors and analyses of sequence embeddings provide further insights. The data and scripts are available at https://github.com/Stephen2526/Structure-informed_PLM.git",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3219092/v1"
    },
    {
        "id": 13264,
        "title": "Fine-tuning protein language models boosts predictions across diverse tasks",
        "authors": "Robert Schmirler, Michael Heinzinger, Burkhard Rost",
        "published": "No Date",
        "citations": 1,
        "abstract": "ABSTRACTPrediction methods inputting embeddings from protein Language Models (pLMs) have reached or even surpassed state-of-the-art (SOTA) performance on many protein prediction tasks. In natural language processing (NLP) fine-tuning Language Models has become thede factostandard. In contrast, most pLM-based protein predictions do not back-propagate to the pLM. Here, we compared the fine-tuning of three SOTA pLMs (ESM2, ProtT5, Ankh) on eight different tasks. Two results stood out. Firstly, task-specific supervised fine-tuning almost always improved downstream predictions. Secondly, parameter-efficient fine-tuning could reach similar improvements consuming substantially fewer resources. Put simply: always fine-tune pLMs and you will mostly gain. To help you, we provided easy-to-use notebooks for parameter efficient fine-tuning of ProtT5 for per-protein (pooling) and per-residue prediction tasks athttps://github.com/agemagician/ProtTrans/tree/master/Fine-Tuning.",
        "link": "http://dx.doi.org/10.1101/2023.12.13.571462"
    },
    {
        "id": 13265,
        "title": "Adapting protein language models for rapid DTI prediction",
        "authors": "Samuel Sledzieski, Rohit Singh, Lenore Cowen, Bonnie Berger",
        "published": "No Date",
        "citations": 4,
        "abstract": "AbstractWe consider the problem of sequence-based drug-target interaction (DTI) prediction, showing that a straightforward deep learning architecture that leverages pre-trained protein language models (PLMs) for protein embedding outperforms state of the art approaches, achieving higher accuracy, expanded generalizability, and an order of magnitude faster training. PLM embeddings are found to contain general information that is especially useful in few-shot (small training data set) and zero-shot instances (unseen proteins or drugs). Additionally, the PLM embeddings can be augmented with features tuned by task-specific pre-training, and we find that these task-specific features are more informative than baseline PLM features. We anticipate such transfer learning approaches will facilitate rapid prototyping of DTI models, especially in low-N scenarios.",
        "link": "http://dx.doi.org/10.1101/2022.11.03.515084"
    },
    {
        "id": 13266,
        "title": "Symbolic Knowledge Distillation: from General Language Models to Commonsense Models",
        "authors": "Peter West, Chandra Bhagavatula, Jack Hessel, Jena Hwang, Liwei Jiang, Ronan Le Bras, Ximing Lu, Sean Welleck, Yejin Choi",
        "published": "2022",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.341"
    },
    {
        "id": 13267,
        "title": "On the Causes for Variability of Fish Populations: The Linkage Between Large and Small Scales 1",
        "authors": "Brian J. Rothschild",
        "published": "2019-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429042423-12"
    },
    {
        "id": 13268,
        "title": "Turbulence Models and LBM-Based Large-Eddy Simulation (LBM-LES)",
        "authors": "Mengtao Han, Ryozo Ooka",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-1264-3_5"
    },
    {
        "id": 13269,
        "title": "Discussion on the Comprehensive Application of Large Cost Database",
        "authors": "",
        "published": "2022-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i5(05).17"
    },
    {
        "id": 13270,
        "title": "ANALYZING THE RELATIONSHIP BETWEEN MOVIE RATINGS AND TRANSLATION STYLE: A LARGE LANGUAGE MODEL APPROACH",
        "authors": "Yuze Du, Eric Zhao",
        "published": "No Date",
        "citations": 0,
        "abstract": "This study delves into the intricate interplay between movie ratings and translation style, employing a novel approach centered on large language models. The research explores how the manner in which movies are translated, whether through free or literal methods, influences their received ratings. We leverage the power of large language models to uncover nuanced patterns in translation styles and their corresponding impact on audience assessments. By scrutinizing a diverse dataset of translated movies, we aim to elucidate whether particular translation strategies are associated with higher or lower ratings. Our findings suggest that GPT-4 is capable of distinguishing between literal and free translations with a high accuracy of 0.8. Through statistical tests, we observed that literal translations lead to significantly higher rating scores than free translations in English-to-Chinese movie title translations. However, when examining different Chinese-speaking movie markets, only mainland China exhibits this difference, with no discernible variation in rating scores in Hong Kong and Singapore. Our findings offer valuable insights into the dynamics of translation styles and their resonance with audience preferences. This sheds light on the intricate relationship between linguistic adaptation and viewer satisfaction in the cinematic realm. Future studies are encouraged to expand our research to include more translation pairs",
        "link": "http://dx.doi.org/10.31235/osf.io/qe7u3"
    },
    {
        "id": 13271,
        "title": "Evaluation of Large Language Model Performance on the Multi-Specialty Recruitment Assessment (MSRA) Exam",
        "authors": "Panagiotis Tsoutsanis, Aristotelis Tsoutsanis",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4525321"
    },
    {
        "id": 13272,
        "title": "Decision letter: Large-scale replication study reveals a limit on probabilistic prediction in language comprehension",
        "authors": "",
        "published": "2018-2-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.33468.023"
    },
    {
        "id": 13273,
        "title": "Pipeline Chain-of-Thought: A Prompt Method for Large Language Model Relation Extraction",
        "authors": "Hangtian Zhao, Hakiz Yilahun, Askar Hamdulla",
        "published": "2023-11-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ialp61005.2023.10337264"
    },
    {
        "id": 13274,
        "title": "2D Smagorinsky type large eddy models as limits of stochastic PDEs",
        "authors": "Franco Flandoli, Dejun Luo, Eliseo Luongo",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nWe prove that a version of Smagorinsky Large Eddy model for a 2D fluid in vorticity form is the scaling limit of suitable stochastic models for large scales, where the influence of small turbulent eddies is modeled by a transport type noise.\nMSC (2020): 60H15, 76D05",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2637288/v1"
    },
    {
        "id": 13275,
        "title": "Is large-scale terrestrial hydrological cycling well represented in Earth System Models?",
        "authors": "Navid Ghajarnia, Zahra Kalantari, Georgia Destouni",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;This paper addresses how large-scale terrestrial water cycling is represented in the land surface schemes of Earth System Models (ESMs). Good representation is essential, for example in regional planning for climate change adaptation and in preparation for hydro-climatic extremes that have recently set records world-wide in devastating consequences for societies and deaths of thousands of people. ESMs provide simulations and projections for the climate system and its interactions with the terrestrial hydrological cycle, and are widely used to study and prepare for associated impacts of climate change. However, the reliability of ESMs is unclear with regard to their representation of large-scale terrestrial hydrology and its changes and interactions between its key variables&amp;#8206;. Despite being crucial for model realism, analysis of co-variations among terrestrial hydrology variables is still largely missing in ESM performance evaluations. To bridge this research gap, we have studied and identified large-scale co-variation patterns between soil moisture (SM) and the main freshwater fluxes of runoff (R), precipitation (P), and evapotranspiration (ET) from observational data and across 6405 hydrological catchments in different parts and climates of the world. Furthermore, we have compared the identified observation-based relationships with those emerging from ESMs and reanalysis products. Our results show that the most strongly correlated freshwater variables based on observational data are also the most misrepresented hydrological patterns in ESMs and reanalysis simulations. In particular, we find SM and R to have the generally strongest large-scale correlations according to the observation-based data, across the numerous studied catchments with widely different hydroclimatic characteristics. Compared to the SM-R correlation signals, the observation-based correlations are overall weaker for the commonly expected closer dependencies of: R on P; ET on P; SM on P; and ET on SM. Nevertheless, this strongest SM-R correlation and the P-R correlation are the most misrepresented hydrological patterns in reanalysis products and ESMs. Our results also show that ESM outputs can perform relatively well in simulating individual hydrological variables, while exhibiting essential inconsistencies in simulated co-variations between variables. Such investigations of large-scale terrestrial hydrology representation by ESMs can enhance our understanding of fundamental ESM biases and uncertainties while providing important insights for systematic ESM improvement with regard to the large-scale hydrological cycling over the world&amp;#8217;s continents and regional land areas.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu21-5332"
    },
    {
        "id": 13276,
        "title": "Computation for Large-Scale Problems",
        "authors": "",
        "published": "2022-1-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108779302.011"
    },
    {
        "id": 13277,
        "title": "Optimizing Large Models For Performance And Sustainability Through Evolutionary Pruning",
        "authors": "Ashhadul Islam, Samir Brahim Belhaouari, Amine Bermak",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe need for network optimization has become become evident when considering the rising computational costs and environmental impact caused by AI models. The substantial carbon footprint and resource consumption of Large Language Models (LLMs) underscore the urgency of optimizing network architectures. These models, with varying parameters, place a significant strain on energy resources, particularly in terms of CO2 emissions and electricity consumption. Achieving a balance between model performance and ecological responsibility is becoming increasingly critical in the era of large-scale AI models.Training and using such models consume substantial amounts of water and power, highlighting the necessity for sleeker, faster, and more efficient model training strategies. \nWe address a crucial challenge related to the compression of deep neural networks, with the aim of enhancing their suitability for embedded devices. Deep neural networks typically exhibit high space and computational requirements, which can hinder their deployment on edge devices and limit their widespread adoption. This study investigates innovative techniques for pruning neural networks, presenting two distinct strategies, namely, \"evolution of weights\" and \"smart pruning.\" These novel approaches are systematically compared to conventional pruning methods using established benchmark datasets. The proposed pruning method involves the continuous assessment of parameter importance throughout the training process, employing a weighted average methodology that surpasses the traditional magnitude-based pruning in terms of accuracy preservation during the compression process. The outcomes of this approach include accelerated computations, higher compression rates with minimal accuracy degradation, enhanced resilience against adversarial attacks, and the capacity to train models using smaller datasets. The authors have thoughtfully provided a PyTorch library for broad usage, simplifying the implementation of their approach across various model architectures.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3558038/v1"
    },
    {
        "id": 13278,
        "title": "Factor-Adjusted Ridge Prediction Using Large-Dimensional Mixed-Effects Models",
        "authors": "Yi He",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3699669"
    },
    {
        "id": 13279,
        "title": "Ideal and Pragmatic Models of Epilepsy Surgery in a Large LAMIC",
        "authors": "Zainal Muttaqin",
        "published": "2017-4-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139547918.031"
    },
    {
        "id": 13280,
        "title": "Influential assets in Large-Scale Vector AutoRegressive Models",
        "authors": "Kexin Zhang, Simon Trimborn",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4619531"
    },
    {
        "id": 13281,
        "title": "Peer Review #1 of \"Comparative investigation of parallel spatial interpolation algorithms for building large-scale digital elevation models (v0.1)\"",
        "authors": "",
        "published": "2020-3-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.263v0.1/reviews/1"
    },
    {
        "id": 13282,
        "title": "Investigating English language learners’ beliefs about oral corrective feedback at Chinese universities: a large-scale survey",
        "authors": "Yan Zhu, Beilei Wang",
        "published": "2019-4-3",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/09658416.2019.1620755"
    },
    {
        "id": 13283,
        "title": "Cross-lingual Transfer Learning with Data Selection for Large-Scale Spoken Language Understanding",
        "authors": "Quynh Do, Judith Gaspers",
        "published": "2019",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-1153"
    },
    {
        "id": 13284,
        "title": "A Decoupled Federate Architecture",
        "authors": "Dan Chen, Lizhe Wang, Jingying Chen",
        "published": "2017-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b11883-3"
    },
    {
        "id": 13285,
        "title": "Risk Assessment In Multi-period Models",
        "authors": "Alexander Syrovatkin",
        "published": "2018-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2018.8551809"
    },
    {
        "id": 13286,
        "title": "Chapter 1: Progress in Understanding and Parameterizing Fast Physics in Large-Scale Atmospheric Models",
        "authors": "Yangang Liu, Pavlos Kollias",
        "published": "No Date",
        "citations": 0,
        "abstract": "This introductory chapter discusses the atmospheric subgrid processes ─\ncollectively called “fast 11 physics” or “fast processes”, and their\nparameterizations in large scale atmospheric models. It 12 presents a\nbrief historical progression of the parameterization of fast processes\nin numerical 13 models. Despite great efforts and notable advances in\nunderstanding, progress in improving fast 14 physics parameterizations\nhas been frustratingly slow, the underlying reasons for which are 15\nexplored. To guide readers, this chapter describes the main objectives\nand scope of this book and 16 summarizes each chapter.",
        "link": "http://dx.doi.org/10.22541/essoar.167591048.88897560/v1"
    },
    {
        "id": 13287,
        "title": "Analyses and large scale testing of plate anchors",
        "authors": "C. Vogt, P. A. Vermeer",
        "published": "2020-12-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003078548-86"
    },
    {
        "id": 13288,
        "title": "Back matter",
        "authors": "Baojiu Li",
        "published": "2018-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1088/978-0-7503-1587-6ch7"
    },
    {
        "id": 13289,
        "title": "Neural ODE Models in Large-Sample Hydrology",
        "authors": "Marvin Höge, Andreas Scheidegger, Marco Baity-Jesi, Carlo Albert, Fabrizio Fenicia",
        "published": "No Date",
        "citations": 0,
        "abstract": "Neural Ordinary Differential Equation (ODE) models have demonstrated high potential in providing accurate hydrologic predictions and process understanding for single catchments (H&#246;ge et al., 2022). Neural ODEs fuse a neural network model core with a mechanistic equation framework. This hybrid structure offers both traceability of model states and processes, like in conceptual hydrologic models, and the high flexibility of machine learning to learn and refine model interrelations. Aside of the functional dependence of internal processes on driving forces, like of evapotranspiration on temperature, Neural ODEs are also able to learn the effect of catchment-specific attributes, e.g. land cover types, on processes when being trained over multiple basins simultaneously.&#160;We demonstrate the performance of a generic Neural ODE architecture in a hydrologic large-sample setup with respect to both predictive accuracy and process interpretability. Using several hundred catchments, we show the capability of Neural ODEs to learn the general interplay of catchment-specific attributes and hydrologic drivers in order to predict discharge in out-of-sample basins. Further, we show how functional relations learned (encoded) by the neural network can be translated (decoded) into an interpretable form, and how this can be used to foster understanding of processes and the hydrologic system.&#160;H&#246;ge, M., Scheidegger, A., Baity-Jesi, M., Albert, C., & Fenicia, F.: Improving hydrologic models for predictions and process understanding using Neural ODEs. Hydrol. Earth Syst. Sci., 26, 5085-5102, https://hess.copernicus.org/articles/26/5085/2022/",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-6466"
    },
    {
        "id": 13290,
        "title": "Compute Node Models: Large-scale Amenable Block-Level Simulation for Memory Hierarchies and Pipelines",
        "authors": "Nandakishore Santhi, Gopinath Chennupati",
        "published": "2017-2-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2172/1342832"
    },
    {
        "id": 13291,
        "title": "Large-Scale Models in Business Activity: Issues of Legal Regulation",
        "authors": "Ekaterina Kuzmina",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4137509"
    },
    {
        "id": 13292,
        "title": "Forecasting Large Hail Using Logistic Models and the ECMWF Ensemble Prediction System",
        "authors": "Francesco Battaglioli, Pieter Groenemeijer, Ivan Tsonesvky",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;An additive logistic regression model for large hail was developed based on convective parameters from ERA5 reanalysis, severe weather reports from the European Severe Weather Database (ESWD), and lightning observations from the Met Office Arrival Time Difference network (ATDnet). This model was shown to accurately reproduce the spatial distribution and the seasonal cycle of observed hail events in Europe. A spatial map of the modelled mean distribution for hail &gt;&amp;#160;2 cm will be presented.&lt;/p&gt;&lt;p&gt;To explore the value of this approach to medium-range forecasting, a similar statistical model was developed using four predictor parameters available from the ECMWF Ensemble Prediction System (EPS) reforecasts: Mixed Layer CAPE, Deep Layer Shear, Mixed Layer Mixing Ratio and the Wet Bulb Zero Height. Probabilistic large hail predictions were created for all available 11-member ensemble forecasts (2008 to 2019), for lead times from 12 to 228 hours.&lt;/p&gt;&lt;p&gt;First, we evaluated the model&amp;#8217;s predictive skill depending on the forecast lead time using the Area Under the ROC Curve (AUC) as a validation score. For forecasts up to two to three days, the model highlights a very high predictive skill (AUC &gt; 0.95). Furthermore, the model retains a high predictive skill even for extended forecasts (AUC = 0.85 at 180 hours lead time) showing that it can identify regions with hail potential well in advance. Second, we compared the forecast spatial probabilities at various lead times with observed hail occurrence focusing on a few recent hail outbreaks. Finally, our four-dimensional model was compared with logistic models based on composite parameters such as the Significant Hail Parameter (SHP) and the product of CAPE and Deep Layer Shear (CAPESHEAR). The four-dimensional model outperformed these composite-based ones at lead times up to four days. The high AUC scores show that this model could improve short-medium range hail forecasts. Preliminary application of this approach to other convective hazards such as convective wind gusts will be presented as well.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu22-7214"
    },
    {
        "id": 13293,
        "title": "Gravity Models and the Law of Large Numbers",
        "authors": "Colin Jareb, Sergey Nigai",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3697061"
    },
    {
        "id": 13294,
        "title": "Organization of Auctions in Network Models",
        "authors": "Igor Gasanov",
        "published": "2020-9-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd49919.2020.9247784"
    },
    {
        "id": 13295,
        "title": "Expanding large-scale mechanistic models with machine learned associations and big datasets",
        "authors": "Cemal Erdem, Marc R. Birtwistle",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractComputational models that can explain and predict complex sub-cellular, cellular, and tissue level drug response mechanisms could speed drug discovery and prioritize patient-specific treatments (i.e., precision medicine). Some models are mechanistic: detailed equations describing known (or supposed) physicochemical processes, while some models are statistical/machine learning-based: descriptive correlations that explain datasets but have no mechanistic or causal guarantees. These two types of modeling are rarely combined, missing the opportunity to explore possibly causal but data-driven new knowledge while explaining what is already known. Here, we explore a combination of machine learning with mechanistic modeling methods to develop computational models that could more fully represent cell-line-specific drug responses. In this proposed framework, machine learning/statistical models built using omics datasets provide high confidence predictions for new interactions between genes and proteins where there is physicochemical uncertainty. These possibly new interactions are used as new connections (edges) in a large-scale mechanistic model (called SPARCED) to better recapitulate the recently released NIH LINCS Consortium large-scale MCF10A dataset. As a test case, we focused on incorporating novel IFNγ/PD-L1 related associations into the SPARCED model to enable description of the cellular response to checkpoint inhibitor immunotherapies. This work is a template for combining big data, machine-learning-inferred interactions with mechanistic models, which could be more broadly applicable towards building multi-scale precision medicine and whole cell models.",
        "link": "http://dx.doi.org/10.1101/2022.11.21.517431"
    },
    {
        "id": 13296,
        "title": "Adaptive Control of Econometric Models with Integrated and Decentralized Policymakers",
        "authors": "Yukio Ito",
        "published": "2020-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003066866-12"
    },
    {
        "id": 13297,
        "title": "Tight Models of de-Rham Algebras of Highly Connected Manifolds",
        "authors": "Lorenz Schwachhöfer",
        "published": "2020-10-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108884136.014"
    },
    {
        "id": 13298,
        "title": "Peer Review #2 of \"Comparative investigation of parallel spatial interpolation algorithms for building large-scale digital elevation models (v0.2)\"",
        "authors": "",
        "published": "2020-3-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.263v0.2/reviews/2"
    },
    {
        "id": 13299,
        "title": "Peer Review #1 of \"Comparative investigation of parallel spatial interpolation algorithms for building large-scale digital elevation models (v0.2)\"",
        "authors": "",
        "published": "2020-3-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.263v0.2/reviews/1"
    },
    {
        "id": 13300,
        "title": "Measures of Language Proficiency in Large-Scale Surveys in the Republic of Ireland and Northern Ireland",
        "authors": "Pádraig Ó Riagáin",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-72941-1_3"
    },
    {
        "id": 13301,
        "title": "EvEntS ReaLM: Event Reasoning of Entity States via Language Models",
        "authors": "Evangelia Spiliopoulou, Artidoro Pagnoni, Yonatan Bisk, Eduard Hovy",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.129"
    },
    {
        "id": 13302,
        "title": "Improving Stability of Fine-Tuning Pretrained Language Models via Component-Wise Gradient Norm Clipping",
        "authors": "Chenghao Yang, Xuezhe Ma",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.322"
    },
    {
        "id": 13303,
        "title": "The BLA Benchmark: Investigating Basic Language Abilities of Pre-Trained Multimodal Models",
        "authors": "Xinyi Chen, Raquel Fernández, Sandro Pezzelle",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.356"
    },
    {
        "id": 13304,
        "title": "NB-MLM: Efficient Domain Adaptation of Masked Language Models for Sentiment Analysis",
        "authors": "Nikolay Arefyev, Dmitrii Kharchev, Artem Shelmanov",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.717"
    },
    {
        "id": 13305,
        "title": "Dynamic Entity Representations in Neural Language Models",
        "authors": "Yangfeng Ji, Chenhao Tan, Sebastian Martschat, Yejin Choi, Noah A. Smith",
        "published": "2017",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d17-1195"
    },
    {
        "id": 13306,
        "title": "Classical Machine Learning and Transformer Models for Offensive and Abusive Language Classification on Dziri Language",
        "authors": "Mohammed Mehdi Bouchene, Kheireddine Abainia",
        "published": "2023-9-16",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dasa59624.2023.10286654"
    },
    {
        "id": 13307,
        "title": "Comparative Pathology — Human Large Intestinal Cancer And Animal Models",
        "authors": "A. K. M. Shamsuddin",
        "published": "2019-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780429263781-11"
    },
    {
        "id": 13308,
        "title": "Computational Models of Dysconnectivity in Large-Scale Resting-State Networks",
        "authors": "Murat Demirtaş, Gustavo Deco",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-809825-7.00004-3"
    },
    {
        "id": 13309,
        "title": "Using Large Self-Supervised Models for Low-Resource Speech Recognition",
        "authors": "Krishna D. N, Pinyi Wang, Bruno Bozza",
        "published": "2021-8-30",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-631"
    },
    {
        "id": 13310,
        "title": "Models of Epilepsy Surgery in a Large LAMIC",
        "authors": "Guoming Luan",
        "published": "2017-4-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139547918.028"
    },
    {
        "id": 13311,
        "title": "Peer Review #2 of \"Comparative investigation of parallel spatial interpolation algorithms for building large-scale digital elevation models (v0.1)\"",
        "authors": "",
        "published": "2020-3-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.263v0.1/reviews/2"
    },
    {
        "id": 13312,
        "title": "Prompting Large Language Models to Power Educational Chatbots",
        "authors": "Juan Carlos Farah, Sandy Ingram, Basile Spaenlehauer, Fanny Kim-Lan Lasne, Denis Gillet",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-8385-8_14"
    },
    {
        "id": 13313,
        "title": "Large language models for biomolecular analysis: From methods to applications",
        "authors": "Ruijun Feng, Chi Zhang, Yang Zhang",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.trac.2024.117540"
    },
    {
        "id": 13314,
        "title": "Letter to the editor concerning \"Large language models: Are artificial intelligence-based chatbots a reliable source of patient information for spinal surgery?\" by R. Stroop et al. (Eur Spine J [2023]; doi:10.1007/s00586-023-07975-z)",
        "authors": "Hinpetch Daungsupawong, Viroj Wiwanitkit",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00586-023-08035-2"
    },
    {
        "id": 13315,
        "title": "Evaluation of pre-training large language models on leadership-class supercomputers",
        "authors": "Junqi Yin, Sajal Dash, John Gounley, Feiyi Wang, Georgia Tourassi",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11227-023-05479-7"
    },
    {
        "id": 13316,
        "title": "Large language models assisted multi-effect variants mining on cerebral cavernous malformation familial whole genome sequencing",
        "authors": "Yiqi Wang, Jinmei Zuo, Chao Duan, Hao Peng, Jia Huang, Liang Zhao, Li Zhang, Zhiqiang Dong",
        "published": "2024-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csbj.2024.01.014"
    },
    {
        "id": 13317,
        "title": "Evaluating the Effectiveness of Artificial Intelligence–powered Large Language Models Application in Disseminating Appropriate and Readable Health Information in Urology",
        "authors": "Ryan Davis, Michael Eppler, Oluwatobiloba Ayo-Ajibola, Jeffrey C. Loh-Doyle, Jamal Nabhani, Mary Samplaski, Inderbir Gill, Giovanni E. Cacciamani",
        "published": "2023-10",
        "citations": 17,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/ju.0000000000003615"
    },
    {
        "id": 13318,
        "title": "Re: Michael Eppler, Conner Ganjavi, Lorenzo Storino Ramacciotti, et al. Awareness and Use of ChatGPT and Large Language Models: A Prospective Cross-sectional Global Survey in Urology. Eur Urol. 2024;85:146–53",
        "authors": "Zhongwei Zhao, Zhenye Li, Nengwang Yu",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.eururo.2023.12.006"
    },
    {
        "id": 13319,
        "title": "Emotional intelligence of Large Language Models",
        "authors": "Xuena Wang, Xueting Li, Zi Yin, Yue Wu, Jia Liu",
        "published": "2023-1",
        "citations": 2,
        "abstract": " Large Language Models (LLMs) have demonstrated remarkable abilities across numerous disciplines, primarily assessed through tasks in language generation, knowledge utilization, and complex reasoning. However, their alignment with human emotions and values, which is critical for real-world applications, has not been systematically evaluated. Here, we assessed LLMs' Emotional Intelligence (EI), encompassing emotion recognition, interpretation, and understanding, which is necessary for effective communication and social interactions. Specifically, we first developed a novel psychometric assessment focusing on Emotion Understanding (EU), a core component of EI. This test is an objective, performance-driven, and text-based evaluation, which requires evaluating complex emotions in realistic scenarios, providing a consistent assessment for both human and LLM capabilities. With a reference frame constructed from over 500 adults, we tested a variety of mainstream LLMs. Most achieved above-average Emotional Quotient (EQ) scores, with GPT-4 exceeding 89% of human participants with an EQ of 117. Interestingly, a multivariate pattern analysis revealed that some LLMs apparently did not rely on the human-like mechanism to achieve human-level performance, as their representational patterns were qualitatively distinct from humans. In addition, we discussed the impact of factors such as model size, training method, and architecture on LLMs' EQ. In summary, our study presents one of the first psychometric evaluations of the human-like characteristics of LLMs, which may shed light on the future development of LLMs aiming for both high intellectual and emotional intelligence. Project website: https://emotional-intelligence.github.io/ ",
        "link": "http://dx.doi.org/10.1177/18344909231213958"
    },
    {
        "id": 13320,
        "title": "Scarecrows in Oz: Large Language Models in HRI",
        "authors": "Cynthia Matuszek, Nick Depalma, Ross Mead, Tom Williams, Ruchen Wen",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3610978.3638168"
    },
    {
        "id": 13321,
        "title": "Linguistic descriptions and cultural models of olfaction in Umpila and English",
        "authors": "Thomas Poulton, Clair Hill",
        "published": "2023-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.langsci.2022.101533"
    },
    {
        "id": 13322,
        "title": "Training RNN language models on uncertain ASR hypotheses in limited data scenarios",
        "authors": "Imran Sheikh, Emmanuel Vincent, Irina Illina",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2023.101555"
    },
    {
        "id": 13323,
        "title": "Usage‐Based Models of Second Language Acquisition",
        "authors": "KIMBERLY L. GEESLIN, DANIELLE DAIDONE, AVIZIA Y. LONG, MEGAN SOLON",
        "published": "2023-7-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119839859.ch19"
    },
    {
        "id": 13324,
        "title": "Mapping Explicit and Implicit Discourse Relations between the RST-DT and the PDTB 3.0",
        "authors": "Nelson Filipe Costa,  , Nadia Sheikh, Leila Kosseim,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_039"
    },
    {
        "id": 13325,
        "title": "Predicting Sentence-Level Factuality of News and Bias of Media Outlets",
        "authors": "Francielle Vargas,  , Kokil Jaidka, Thiago A. S. Pardo, Fabrício Benevenuto,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_127"
    },
    {
        "id": 13326,
        "title": "Using Digital Resources to Teach Language Variation in the Midwest",
        "authors": "Amanda Sladek, Mattie Lane",
        "published": "2019-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678-22"
    },
    {
        "id": 13327,
        "title": "LASP: Text-to-Text Optimization for Language-Aware Soft Prompting of Vision &amp; Language Models",
        "authors": "Adrian Bulat, Georgios Tzimiropoulos",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.02225"
    },
    {
        "id": 13328,
        "title": "Early Research on Finnish Sign Language: In the Footsteps of Great Role Models",
        "authors": "Terhi Rissanen, Päivi Rainò, Ritva Takkinen",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1353/sls.2024.a920116"
    },
    {
        "id": 13329,
        "title": "Language Policy of a Nation: Literature review in Language Planning Models and Strategies: A Brief Overview",
        "authors": "Dr. Niruba Sarath Jayasundara",
        "published": "2021-2-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31364/scirj/v9.i02.2021.p0221842"
    },
    {
        "id": 13330,
        "title": "Differentially Private Language Models for Secure Data Sharing",
        "authors": "Justus Mattern, Zhijing Jin, Benjamin Weggenmann, Bernhard Schoelkopf, Mrinmaya Sachan",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.323"
    },
    {
        "id": 13331,
        "title": "Making Pretrained Language Models Good Long-tailed Learners",
        "authors": "Chen Zhang, Lei Ren, Jingang Wang, Wei Wu, Dawei Song",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.217"
    },
    {
        "id": 13332,
        "title": "Improving Multilingual Models with Language-Clustered Vocabularies",
        "authors": "Hyung Won Chung, Dan Garrette, Kiat Chuan Tan, Jason Riesa",
        "published": "2020",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.367"
    },
    {
        "id": 13333,
        "title": "Clustering Pseudo Language Family in Multilingual Translation Models with Fisher Information Matrix",
        "authors": "Xinyu Ma, Xuebo Liu, Min Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.851"
    },
    {
        "id": 13334,
        "title": "Sorting through the noise: Testing robustness of information processing in pre-trained language models",
        "authors": "Lalchand Pandia, Allyson Ettinger",
        "published": "2021",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.119"
    },
    {
        "id": 13335,
        "title": "Worst of Both Worlds: Biases Compound in Pre-trained Vision-and-Language Models",
        "authors": "Tejas Srinivasan, Yonatan Bisk",
        "published": "2022",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gebnlp-1.10"
    },
    {
        "id": 13336,
        "title": "Dissecting Recall of Factual Associations in Auto-Regressive Language Models",
        "authors": "Mor Geva, Jasmijn Bastings, Katja Filippova, Amir Globerson",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.751"
    },
    {
        "id": 13337,
        "title": "Deep Bayesian Active Learning for Natural Language Processing: Results of a Large-Scale Empirical Study",
        "authors": "Aditya Siddhant, Zachary C. Lipton",
        "published": "2018",
        "citations": 39,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d18-1318"
    },
    {
        "id": 13338,
        "title": "Are Prompt-based Models Clueless?",
        "authors": "Pride Kavumba, Ryo Takahashi, Yusuke Oda",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.29.991"
    },
    {
        "id": 13339,
        "title": "Who’s on First?: Probing the Learning and Representation Capabilities of Language Models on Deterministic Closed Domains",
        "authors": "David Demeter, Doug Downey",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.conll-1.16"
    },
    {
        "id": 13340,
        "title": "Controlled Evaluation of Grammatical Knowledge in Mandarin Chinese Language Models",
        "authors": "Yiwen Wang, Jennifer Hu, Roger Levy, Peng Qian",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.454"
    },
    {
        "id": 13341,
        "title": "Evaluating Saliency Methods for Neural Language Models",
        "authors": "Shuoyang Ding, Philipp Koehn",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.399"
    },
    {
        "id": 13342,
        "title": "“Was it “stated” or was it “claimed”?: How linguistic bias affects generative language models",
        "authors": "Roma Patel, Ellie Pavlick",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.790"
    },
    {
        "id": 13343,
        "title": "Rating Distributions and Bayesian Inference: Enhancing Cognitive Models of Spatial Language Use",
        "authors": "Thomas Kluth, Holger Schultheis",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-2807"
    },
    {
        "id": 13344,
        "title": "Investigating representations of verb bias in neural language models",
        "authors": "Robert Hawkins, Takateru Yamakoshi, Thomas Griffiths, Adele Goldberg",
        "published": "2020",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.376"
    },
    {
        "id": 13345,
        "title": "Do Massively Pretrained Language Models Make Better Storytellers?",
        "authors": "Abigail See, Aneesh Pappu, Rohun Saxena, Akhila Yerukola, Christopher D. Manning",
        "published": "2019",
        "citations": 20,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/k19-1079"
    },
    {
        "id": 13346,
        "title": "Visually Grounded Language Learning: A Review of Language Games, Datasets, Tasks, and Models",
        "authors": "Alessandro Suglia, Ioannis Konstas, Oliver Lemon",
        "published": "2024-1-26",
        "citations": 0,
        "abstract": "In recent years, several machine learning models have been proposed. They are trained with a language modelling objective on large-scale text-only data. With such pretraining, they can achieve impressive results on many Natural Language Understanding and Generation tasks. However, many facets of meaning cannot be learned by “listening to the radio” only. In the literature, many Vision+Language (V+L) tasks have been defined with the aim of creating models that can ground symbols in the visual modality. In this work, we provide a systematic literature review of several tasks and models proposed in the V+L field. We rely on Wittgenstein’s idea of ‘language games’ to categorise such tasks into 3 different families: 1) discriminative games, 2) generative games, and 3) interactive games. Our analysis of the literature provides evidence that future work should be focusing on interactive games where communication in Natural Language is important to resolve ambiguities about object referents and action plans and that physical embodiment is essential to understand the semantics of situations and events. Overall, these represent key requirements for developing grounded meanings in neural models.",
        "link": "http://dx.doi.org/10.1613/jair.1.15185"
    },
    {
        "id": 13347,
        "title": "Role of Language Relatedness in Multilingual Fine-tuning of Language Models: A Case Study in Indo-Aryan Languages",
        "authors": "Tejas Dhamecha, Rudra Murthy, Samarth Bharadwaj, Karthik Sankaranarayanan, Pushpak Bhattacharyya",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.675"
    },
    {
        "id": 13348,
        "title": "Context is not key: Detecting Alzheimer’s disease with both classical and transformer-based neural language models",
        "authors": "Behrad TaghiBeyglou, Frank Rudzicz",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.nlp.2023.100046"
    },
    {
        "id": 13349,
        "title": "How are Korean Neural Language Models ‘surprised’ Layerwisely?",
        "authors": "Sunjoo Choi,  , Myung-Kwan Park, Euhee Kim",
        "published": "2021-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14384/kals.2021.28.4.301"
    },
    {
        "id": 13350,
        "title": "CORPUS AS A MEANS TO STUDY FORMAL AND INFORMAL LANGUAGE MODELS OF THE ENGLISH LANGUAGE",
        "authors": "Карине Араиковна, Погосян, Эгине Азатовна, Мелконян, Анна Артиковна Папоян",
        "published": "2023-6-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32743/26870142.2023.21.291.360409"
    },
    {
        "id": 13351,
        "title": "Pretraining with Artificial Language: Studying Transferable Knowledge in Language Models",
        "authors": "Ryokan Ri, Yoshimasa Tsuruoka",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.acl-long.504"
    },
    {
        "id": 13352,
        "title": "Toward Building General Foundation Models for Language, Vision, and Vision-Language Understanding Tasks",
        "authors": "Xinsong Zhang, Yan Zeng, Jipeng Zhang, Hang Li",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.40"
    },
    {
        "id": 13353,
        "title": "Towards Cognitively More Plausible Models",
        "authors": "Lisa Beinborn, Nora Hollenstein",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-43260-6_7"
    },
    {
        "id": 13354,
        "title": "Benchmarking topic models on scientific articles using BERTeley",
        "authors": "Eric Chagnon, Ronald Pandolfi, Jeffrey Donatelli, Daniela Ushizima",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.nlp.2023.100044"
    },
    {
        "id": 13355,
        "title": "The brain and the mind behind grammar",
        "authors": "Alexander Haselow, Gunther Kaltenböck",
        "published": "2020-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/hcp.70.int"
    },
    {
        "id": 13356,
        "title": "Introduction to the special issue emergence of speech and language from prediction error: error-driven language models",
        "authors": "Jessie S. Nixon, Fabian Tomaschek",
        "published": "2023-4-21",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/23273798.2023.2197650"
    },
    {
        "id": 13357,
        "title": "How should the advent of large language models affect the practice of science?",
        "authors": "Marcel Binz, Stephan Alaniz, Adina Roskies, Balazs Aczel, Carl Bergstrom, Colin Allen, Daniel Schad, Dirk U. Wulff, Jevin West, Qiong Zhang, Rich Shiffrin, Samuel J. Gershman, Vencislav Popov, Emily M. Bender, Marco Marelli, Matthew M. Botvinick, Zeynep Akata, Eric Schulz",
        "published": "No Date",
        "citations": 0,
        "abstract": "Large language models (LLMs) are being increasingly incorporated into scientific workflows. However, we have yet to fully grasp the implications of this integration. How should the advent of large language models affect the practice of science? For this opinion piece, we have invited four diverse groups of scientists to reflect on this query, sharing their perspectives and engaging in debate. Schulz et al. make the argument that working with LLMs is not fundamentally different from working with human collaborators, while Bender et al. argue that LLMs are often misused and over-hyped, and that their limitations warrant a focus on more specialized, easily interpretable tools. Marelli et al. emphasize the importance of transparent attribution and responsible use of LLMs. Finally, Botvinick and Gershman advocate that humans should retain responsibility for determining the scientific roadmap. To facilitate the discussion, the four perspectives are complemented with a response from each group. By putting these different perspectives in conversation, we aim to bring attention to important considerations within the academic community regarding the adoption of LLMs and their impact on both current and future scientific practices.",
        "link": "http://dx.doi.org/10.31219/osf.io/yr9xb"
    },
    {
        "id": 13358,
        "title": "From language models to large-scale food and biomedical knowledge graphs",
        "authors": "Gjorgjina Cenikj, Lidija Strojnik, Risto Angelski, Nives Ogrinc, Barbara Koroušić Seljak, Tome Eftimov",
        "published": "2023-5-15",
        "citations": 0,
        "abstract": "AbstractKnowledge about the interactions between dietary and biomedical factors is scattered throughout uncountable research articles in an unstructured form (e.g., text, images, etc.) and requires automatic structuring so that it can be provided to medical professionals in a suitable format. Various biomedical knowledge graphs exist, however, they require further extension with relations between food and biomedical entities. In this study, we evaluate the performance of three state-of-the-art relation-mining pipelines (FooDis, FoodChem and ChemDis) which extract relations between food, chemical and disease entities from textual data. We perform two case studies, where relations were automatically extracted by the pipelines and validated by domain experts. The results show that the pipelines can extract relations with an average precision around 70%, making new discoveries available to domain experts with reduced human effort, since the domain experts should only evaluate the results, instead of finding, and reading all new scientific papers.",
        "link": "http://dx.doi.org/10.1038/s41598-023-34981-4"
    },
    {
        "id": 13359,
        "title": "KG-CTG: Citation Generation Through Knowledge Graph-Guided Large Language Models",
        "authors": "Avinash Anand, Mohit Gupta, Kritarth Prasad, Ujjwal Goel, Naman Lal, Astha Verma, Rajiv Ratn Shah",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-49601-1_3"
    },
    {
        "id": 13360,
        "title": "Evaluating the Performance of Large Language Models in Hematopoietic Stem Cell Transplantation Decision Making",
        "authors": "Ivan Civettini, Arianna Zappaterra, Daniele Ramazzotti, Bianca Maria Granelli, Giovanni Rindone, Andrea Aroldi, Stefano Bonfanti, Federica Colombo, Marilena Fedele, Giovanni Grillo, Matteo Parma, Paola Perfetti, Elisabetta Terruzzi, Carlo Gambacorti-Passerini, Fabrizio Cavalca",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "\nIntroduction:\nLarge Language Models (LLMs) are a form of Artificial Intelligence (AI), by identifying patterns and connections within data, they can predict the most likely words or phrases in specific contexts. Previous studies have indicated that GPT (Generative Pre-trained Transformer; OpenAI) performs well in answering single-choice clinical questions. However, its performance seems to be less satisfactory when dealing with multiple-choice questions and more intricate clinical cases (Cosima et al. 2023 EAO; Cascella et al. 2023 J Med Syst). Notably, no study has evaluated LLMs responses in the context of Transplantation Decision Making, a complex process heavily reliant on physician expertise. Additionally, most studies focused solely on GPT's performance, without considering other competitive LLMs like Llama-2 or VertexAI. Our study aims to assess the performance of LLMs in the domain of hematopoietic stem cell transplantation.\nMethods:\nWe modified and anonymized the clinical histories of six hematological patients. An experienced hematologist reviewed and validated these modified clinical histories, which included demographic data, past medical history, hematology disease features (genetic data and MRD when available), treatment responses, adverse events from previous therapies, and potential donor information (related/unrelated, HLA, CMV status).\nWe presented these clinical cases to six experienced bone marrow transplant physicians from two major JACIE accredited hospitals and 11 hematology residents from the University Milano-Bicocca. LLMs employed for the analysis were: GPT-4, VertexAI Palm 2, Llama-2 13b and 70b. LLMs were configured with different temperature settings to control token selection randomness, always maintaining low levels for more deterministic responses.\nA triple-blinded survey was conducted using Typeform, where both senior hematologists and residents provided anonymized responses with personal tokens. The senior hematologists, residents, and LLMs testers were unaware of the responses provided by the other groups. We calculated Fleiss K (K) and overall percentage of agreement (OA) between residents and LLMs, considering the consensus answer (CoA) among experts as the most frequent response. Subsequently, OA and K values for both residents and LLMs were compared using T- or Mann-Whitney tests with Graphpad v 10.0.1.\nResults:\nThe results showed perfect agreement among experts in patient transplant eligibility assessment (K=1.0) and substantial agreement in the choice of donors and conditioning regimens (K=0.62 for both questions). Fair agreement was observed in Transplant Related Mortality (TRM) estimation (K=0.22).\nThe median OA and K value between residents and the CoA of experts were 76.5% (range 52.9-88.2%) and 0.61 (range 0.4-0.8), respectively. The median OA and K value between LLMs answers and experts were 58.8% (range 47-71%) and 0.45 (range 0.3-0.61), respectively. The mean OA and K value of residents were significantly higher compared to LLMs (p=0.02). Specifically, residents showed higher median OA and K values in patient eligibility assessment (median OA 100 vs. 83% and K 1 vs. 0.78; p=0.01). However, there was no significant difference in median K for donor choice (0.56 vs. 0.56), conditioning regimen (0.67 vs. 0.33), and TRM evaluation (0.33 vs. 0) (Table 1). The median K values of GPT-4, Palm-2, Llama2-13b, and Llama2-70b were 0.49, 0.53, 0.33, and 0.53 respectively (Figure 1).\nConclusion:\nOur study sheds light on the potential and limitations of LLMs in complex hematopoietic stem cell transplantation decision-making. While LLMs showed promising results with a median OA of 59%, residents demonstrated superior performance. LLMS displayed good performances in patients' eligibility and donor choice but showed shortcomings in conditioning regimens and TRM evaluation.\nNot using a rating scale from experts when evaluating LLMs responses aimed to avoid potential bias. However, it is important to note that the consensus answer, even though it was the most frequent, does not necessarily imply that other responses provided by the experts were incorrect. Therefore, the lower consensus among the experts in TRM evaluation, possibly due to the challenge of precisely calculating TRM in a survey-based evaluation, should also lead to a cautious approach when evaluating residents and LLMs answers in this setting.",
        "link": "http://dx.doi.org/10.1182/blood-2023-185854"
    },
    {
        "id": 13361,
        "title": "Leveraging Large Language Models for Literature Review Tasks - A Case Study Using ChatGPT",
        "authors": "Robert Zimmermann, Marina Staab, Mehran Nasseri, Patrick Brandtner",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-48858-0_25"
    },
    {
        "id": 13362,
        "title": "Commonsense Reasoning and Explainable Artificial Intelligence Using Large Language Models",
        "authors": "Stefanie Krause, Frieder Stolzenburg",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-50396-2_17"
    },
    {
        "id": 13363,
        "title": "Large-Scale Language Models for PHM in Railway Systems - Potential Applications, Limitations, and Solutions",
        "authors": "Huan Wang, Yan-Fu Li",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-9311-6_59"
    },
    {
        "id": 13364,
        "title": "Evaluating Computer Vision, Large Language, and Genome-Wide Association Models in a Limited Sized Patient Cohort for Pre-Operative Risk Stratification in Adult Spinal Deformity Surgery",
        "authors": "Ethan Schonfeld, Aaradhya Pant, Aaryan Shah, Sina Sadeghzadeh, Dhiraj Pangal, Adrian Rodrigues, Kelly Yoo, Neelan Marianayagam, Ghani Haider, Anand Veeravagu",
        "published": "2024-1-23",
        "citations": 0,
        "abstract": "Background: Adult spinal deformities (ASD) are varied spinal abnormalities, often necessitating surgical intervention when associated with pain, worsening deformity, or worsening function. Predicting post-operative complications and revision surgery is critical for surgical planning and patient counseling. Due to the relatively small number of cases of ASD surgery, machine learning applications have been limited to traditional models (e.g., logistic regression or standard neural networks) and coarse clinical variables. We present the novel application of advanced models (CNN, LLM, GWAS) using complex data types (radiographs, clinical notes, genomics) for ASD outcome prediction. Methods: We developed a CNN trained on 209 ASD patients (1549 radiographs) from the Stanford Research Repository, a CNN pre-trained on VinDr-SpineXR (10,468 spine radiographs), and an LLM using free-text clinical notes from the same 209 patients, trained via Gatortron. Additionally, we conducted a GWAS using the UK Biobank, contrasting 540 surgical ASD patients with 7355 non-surgical ASD patients. Results: The LLM notably outperformed the CNN in predicting pulmonary complications (F1: 0.545 vs. 0.2881), neurological complications (F1: 0.250 vs. 0.224), and sepsis (F1: 0.382 vs. 0.132). The pre-trained CNN showed improved sepsis prediction (AUC: 0.638 vs. 0.534) but reduced performance for neurological complication prediction (AUC: 0.545 vs. 0.619). The LLM demonstrated high specificity (0.946) and positive predictive value (0.467) for neurological complications. The GWAS identified 21 significant (p < 10−5) SNPs associated with ASD surgery risk (OR: mean: 3.17, SD: 1.92, median: 2.78), with the highest odds ratio (8.06) for the LDB2 gene, which is implicated in ectoderm differentiation. Conclusions: This study exemplifies the innovative application of cutting-edge models to forecast outcomes in ASD, underscoring the utility of complex data in outcome prediction for neurosurgical conditions. It demonstrates the promise of genetic models when identifying surgical risks and supports the integration of complex machine learning tools for informed surgical decision-making in ASD.",
        "link": "http://dx.doi.org/10.3390/jcm13030656"
    },
    {
        "id": 13365,
        "title": "Multimodal prediction of student performance: A fusion of signed Graph Neural Networks and Large Language Models",
        "authors": "Sijie Wang, Lin Ni, Zeyu Zhang, Xiaoxuan Li, Xianda Zheng, Jiamou Liu",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patrec.2024.03.007"
    },
    {
        "id": 13366,
        "title": "Mitigating Fine-Grained Hallucination by Fine-Tuning Large Vision-Language Models with Caption Rewrites",
        "authors": "Lei Wang, Jiabang He, Shenshen Li, Ning Liu, Ee-Peng Lim",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-53302-0_3"
    },
    {
        "id": 13367,
        "title": "SearchGEM5: Towards Reliable Gem5 with Search Based Software Testing and Large Language Models",
        "authors": "Aidan Dakhama, Karine Even-Mendoza, W.B. Langdon, Hector Menendez, Justyna Petke",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-48796-5_14"
    },
    {
        "id": 13368,
        "title": "Procedural Text Mining with Large Language Models",
        "authors": "Anisa Rula, Jennifer D'Souza",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3587259.3627572"
    },
    {
        "id": 13369,
        "title": "Are artificial intelligence large language models a reliable tool for difficult differential diagnosis? An a posteriori analysis of a peculiar case of necrotizing otitis externa",
        "authors": "Giorgia Pugliese, Alberto Maccari, Elena Felisati, Giovanni Felisati, Leonardo Giudici, Chiara Rapolla, Antonia Pisani, Alberto Maria Saibene",
        "published": "2023-9",
        "citations": 1,
        "abstract": "Key Clinical MessageLarge language models have made artificial intelligence readily available to the general public and potentially have a role in healthcare; however, their use in difficult differential diagnosis is still limited, as demonstrated by a case of necrotizing otitis externa.AbstractThis case report presents a peculiar case of necrotizing otitis externa (NOE) with skull base involvement which proved diagnostically challenging. The initial patient presentation and the imaging performed on the 78‐year‐old patient suggested a neoplastic rhinopharyngeal lesion and only after several unsuccessful biopsies the patient was transferred to our unit. Upon re‐evaluation of the clinical picture, a clinical hypothesis of NOE with skull base erosion was made and confirmed by identifying Pseudomonas aeruginosa in biopsy specimens of skull base bone and external auditory canal skin. Upon diagnosis confirmation, the patient was treated with culture‐oriented long‐term antibiotics with complete resolution of the disease. Given the complex clinical presentation, we chose to submit a posteriori this NOE case to two large language models (LLM) to test their ability to handle difficult differential diagnoses. LLMs are easily approachable artificial intelligence tools that enable human‐like interaction with the user relying upon large information databases for analyzing queries. The LLMs of choice were ChatGPT‐3 and ChatGPT‐4 and they were requested to analyze the case being provided with only objective clinical and imaging data.",
        "link": "http://dx.doi.org/10.1002/ccr3.7933"
    },
    {
        "id": 13370,
        "title": "A platform for connecting social media data to domain-specific topics using large language models: an application to student mental health",
        "authors": "Leonard Ruocco, Yuqian Zhuang, Raymond Ng, Richard J Munthali, Kristen L Hudec, Angel Y Wang, Melissa Vereschagin, Daniel V Vigo",
        "published": "2024-1-4",
        "citations": 0,
        "abstract": "Abstract\n\nObjectives\nTo design a novel artificial intelligence-based software platform that allows users to analyze text data by identifying various coherent topics and parts of the data related to a specific research theme-of-interest (TOI).\n\n\nMaterials and Methods\nOur platform uses state-of-the-art unsupervised natural language processing methods, building on top of a large language model, to analyze social media text data. At the center of the platform’s functionality is BERTopic, which clusters social media posts, forming collections of words representing distinct topics. A key feature of our platform is its ability to identify whole sentences corresponding to topic words, vastly improving the platform’s ability to perform downstream similarity operations with respect to a user-defined TOI.\n\n\nResults\nTwo case studies on mental health among university students are performed to demonstrate the utility of the platform, focusing on signals within social media (Reddit) data related to depression and their connection to various emergent themes within the data.\n\n\nDiscussion and Conclusion\nOur platform provides researchers with a readily available and inexpensive tool to parse large quantities of unstructured, noisy data into coherent themes, as well as identifying portions of the data related to the research TOI. While the development process for the platform was focused on mental health themes, we believe it to be generalizable to other domains of research as well.\n",
        "link": "http://dx.doi.org/10.1093/jamiaopen/ooae001"
    },
    {
        "id": 13371,
        "title": "From Text to Structure: Using Large Language Models to Support the Development of Legal Expert Systems",
        "authors": "Samyar Janatian, Hannes Westermann, Jinzhe Tan, Jaromir Savelka, Karim Benyekhlef",
        "published": "2023-12-7",
        "citations": 1,
        "abstract": "Encoding legislative text in a formal representation is an important prerequisite to different tasks in the field of AI & Law. For example, rule-based expert systems focused on legislation can support laypeople in understanding how legislation applies to them and provide them with helpful context and information. However, the process of analyzing legislation and other sources to encode it in the desired formal representation can be time-consuming and represents a bottleneck in the development of such systems. Here, we investigate to what degree large language models (LLMs), such as GPT-4, are able to automatically extract structured representations from legislation. We use LLMs to create pathways from legislation, according to the JusticeBot methodology for legal decision support systems, evaluate the pathways and compare them to manually created pathways. The results are promising, with 60% of generated pathways being rated as equivalent or better than manually created ones in a blind comparison. The approach suggests a promising path to leverage the capabilities of LLMs to ease the costly development of systems based on symbolic approaches that are transparent and explainable.",
        "link": "http://dx.doi.org/10.3233/faia230962"
    },
    {
        "id": 13372,
        "title": "Recommendations for Social Work Researchers and Journal Editors on the Use of Generative AI and Large Language Models",
        "authors": "Bryan G. Victor, Rebeccah L. Sokol, Lauri Goldkind, Brian E. Perron",
        "published": "2023-9-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1086/726021"
    },
    {
        "id": 13373,
        "title": "Deployment and Comparison of Large Language Models Based on Virtual Cluster",
        "authors": "Kai Li, Rongqiang Cao, Meng Wan, Xiaoguang Wang, Zongguo Wang, Jue Wang, Yangang Wang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-9119-8_32"
    },
    {
        "id": 13374,
        "title": "GIST: Transforming Overwhelming Information into Structured Knowledge with Large Language Models",
        "authors": "Meng Wu, Xinyu Zhou, Gang Ma, Zhangwei Lu, Liuxin Zhang, Yu Zhang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-9119-8_4"
    },
    {
        "id": 13375,
        "title": "Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts",
        "authors": "Dave Van Veen, Cara Van Uden, Louis Blankemeier, Jean-Benoit Delbrouck, Asad Aali, Christian Bluethgen, Anuj Pareek, Malgorzata Polacin, Eduardo Pontes Reis, Anna Seehofnerova, Nidhi Rohatgi, Poonam Hosamani, William Collins, Neera Ahuja, Curtis Langlotz, Jason Hom, Sergios Gatidis, John Pauly, Akshay Chaudhari",
        "published": "No Date",
        "citations": 8,
        "abstract": "Abstract\nSifting through vast textual data and summarizing key information from electronic health records (EHR) imposes a substantial burden on how clinicians allocate their time. Although large language models (LLMs) have shown immense promise in natural language processing (NLP) tasks, their efficacy on a diverse range of clinical summarization tasks has not yet been rigorously demonstrated. In this work, we apply domain adaptation methods to eight LLMs, spanning six datasets and four distinct clinical summarization tasks: radiology reports, patient questions, progress notes, and doctor-patient dialogue. Our thorough quantitative assessment reveals trade-offs between models and adaptation methods in addition to instances where recent advances in LLMs may not improve results. Further, in a clinical reader study with ten physicians, we show that summaries from our best-adapted LLMs are preferable to human summaries in terms of completeness and correctness. Our ensuing qualitative analysis highlights challenges faced by both LLMs and human experts. Lastly, we correlate traditional quantitative NLP metrics with reader study scores to enhance our understanding of how these metrics align with physician preferences. Our research marks the first evidence of LLMs outperforming human experts in clinical text summarization across multiple tasks. This implies that integrating LLMs into clinical workflows could alleviate documentation burden, empowering clinicians to focus more on personalized patient care and the inherently human aspects of medicine.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3483777/v1"
    },
    {
        "id": 13376,
        "title": "Instance-Aware and Semantic-Guided Prompt for Few-Shot Learning in Large Language Models",
        "authors": "Jinta Weng, Donghao Li, Yifan Deng, Jie Zhang, Yue Hu, Heyan Huang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-8148-9_5"
    },
    {
        "id": 13377,
        "title": "Advancements and Applications of Generative Artificial Intelligence and Large Language Models on Business Management: A Comprehensive Review",
        "authors": " Ahmed Ali Linkon,  Mujiba Shaima,  Md Shohail Uddin Sarker,  Badruddowza,  Norun Nabi,  Md Nasir Uddin Rana,  Sandip Kumar Ghosh,  Hammed Esa,  Faiaz Rahat Chowdhury",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "This comprehensive review delves into the landscape and recent advancements of Generative Artificial Intelligence (AI) and Large Language Models (LLMs), shedding light on their transformative potential and applications across various sectors. Generative AI, exemplified by models like ChatGPT, DALL-E, and Midjourney, has rapidly evolved and is driven by breakthroughs in deep learning architectures and the availability of vast datasets. Concurrently, LLMs have revolutionized natural language processing tasks, utilizing vast text corpora to generate human-like text. The study explores recent developments, including the introduction of advanced models like GPT-4 and PaLM2 and the emergence of specialized LLMs like small LLMs (sLLMs), aimed at overcoming hardware limitations and cost constraints. Additionally, the expanding applications of generative AI, from healthcare to finance, underscore its transformative potential in addressing real-world challenges. Through a comprehensive analysis, this research contributes to the ongoing discourse on AI ethics, governance, and regulation, emphasizing the importance of responsible innovation for the benefit of humanity.",
        "link": "http://dx.doi.org/10.32996/jcsts.2024.6.1.26"
    },
    {
        "id": 13378,
        "title": "Large‐scale Computational Models of Ongoing Brain Activity",
        "authors": "Tristan T. Nakagawa, Mohit H. Adhikari, Gustavo Deco",
        "published": "2017-11-29",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119159193.ch31"
    },
    {
        "id": 13379,
        "title": "Quantity doesn’t buy quality syntax with neural language models",
        "authors": "Marten van Schijndel, Aaron Mueller, Tal Linzen",
        "published": "2019",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-1592"
    },
    {
        "id": 13380,
        "title": "What Makes Data-to-Text Generation Hard for Pretrained Language Models?",
        "authors": "Moniba Keymanesh, Adrian Benton, Mark Dredze",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gem-1.50"
    },
    {
        "id": 13381,
        "title": "Analyzing the Mono- and Cross-Lingual Pretraining Dynamics of Multilingual Language Models",
        "authors": "Terra Blevins, Hila Gonen, Luke Zettlemoyer",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.234"
    },
    {
        "id": 13382,
        "title": "Evaluating Computational Language Models with Scaling Properties of Natural Language",
        "authors": "Shuntaro Takahashi, Kumiko Tanaka-Ishii",
        "published": "2019-9",
        "citations": 10,
        "abstract": " In this article, we evaluate computational models of natural language with respect to the universal statistical behaviors of natural language. Statistical mechanical analyses have revealed that natural language text is characterized by scaling properties, which quantify the global structure in the vocabulary population and the long memory of a text. We study whether five scaling properties (given by Zipf’s law, Heaps’ law, Ebeling’s method, Taylor’s law, and long-range correlation analysis) can serve for evaluation of computational models. Specifically, we test n-gram language models, a probabilistic context-free grammar, language models based on Simon/Pitman-Yor processes, neural language models, and generative adversarial networks for text generation. Our analysis reveals that language models based on recurrent neural networks with a gating mechanism (i.e., long short-term memory; a gated recurrent unit; and quasi-recurrent neural networks) are the only computational models that can reproduce the long memory behavior of natural language. Furthermore, through comparison with recently proposed model-based evaluation methods, we find that the exponent of Taylor’s law is a good indicator of model quality. ",
        "link": "http://dx.doi.org/10.1162/coli_a_00355"
    },
    {
        "id": 13383,
        "title": "Dual Fixed-Size Ordinally Forgetting Encoding (FOFE) for Competitive Neural Language Models",
        "authors": "Sedtawut Watcharawittayakul, Mingbin Xu, Hui Jiang",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d18-1502"
    },
    {
        "id": 13384,
        "title": "How much pretraining data do language models need to learn syntax?",
        "authors": "Laura Pérez-Mayos, Miguel Ballesteros, Leo Wanner",
        "published": "2021",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.118"
    },
    {
        "id": 13385,
        "title": "IIT-KGP at COIN 2019: Using pre-trained Language Models for modeling Machine Comprehension",
        "authors": "Prakhar Sharma, Sumegh Roychowdhury",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-6009"
    },
    {
        "id": 13386,
        "title": "“You are grounded!”: Latent Name Artifacts in Pre-trained Language Models",
        "authors": "Vered Shwartz, Rachel Rudinger, Oyvind Tafjord",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.556"
    },
    {
        "id": 13387,
        "title": "GAN-LM: Generative Adversarial Network using Language Models for Downstream Applications",
        "authors": "Dae Yon Hwang, Yaroslav Nechaev, Cyprien de Lichy, Renxian Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.inlg-main.5"
    },
    {
        "id": 13388,
        "title": "Contrast coding choices in a decade of mixed models",
        "authors": "Laurel Brehm, Phillip M. Alday",
        "published": "2022-8",
        "citations": 37,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jml.2022.104334"
    },
    {
        "id": 13389,
        "title": "Analysing Word Representation from the Input and Output Embeddings in Neural Network Language Models",
        "authors": "Steven Derby, Paul Miller, Barry Devereux",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.conll-1.36"
    },
    {
        "id": 13390,
        "title": "Foreigner in One’s Own Language: Models of Translating Modern Croatian Dialect Literature into the Standard Croatian Language",
        "authors": "Mario Kolar",
        "published": "2022-6-21",
        "citations": 0,
        "abstract": "Since there are many differences between the standard Croatian language and the Croatian dialects (Čakavian, Kajkavian and Štokavian), Croatian literary works written in dialects usually include a glossary or otherwise try to bring their language closer to inodialect readers. This paper first reconstructs the models of translating modern Croatian dialect literature into the standard Croatian language and then analyses the advantages and disadvantages of each model.",
        "link": "http://dx.doi.org/10.31261/pls.2022.12.01.02"
    },
    {
        "id": 13391,
        "title": "Structural Priming Demonstrates Abstract Grammatical Representations in Multilingual Language Models",
        "authors": "James Michaelov, Catherine Arnett, Tyler Chang, Ben Bergen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.227"
    },
    {
        "id": 13392,
        "title": "Surrogate Data Models: Interpreting Large-scale Machine Learning Crisis Prediction Models",
        "authors": "Maksym Ivanyna, Ritong Qu, Ruofei Hu, Cheng Zhong, Jorge Chan-Lau",
        "published": "2023-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5089/9798400234828.001"
    },
    {
        "id": 13393,
        "title": "A Generative <scp>Drug–Drug</scp> Interaction Triplets Extraction Framework Based on Large Language Models",
        "authors": "Haotian Hu, Alex Jie Yang, Sanhong Deng, Dongbo Wang, Min Song, Si Shen",
        "published": "2023-10",
        "citations": 0,
        "abstract": "ABSTRACTDrug–Drug Interaction (DDI) may affect the activity and efficacy of drugs, potentially leading to diminished therapeutic effect or even serious side effects. Therefore, automatic recognition of drug entities and relations involved in DDI is of great significance for pharmaceutical and medical care. In this paper, we propose a generative DDI triplets extraction framework based on Large Language Models (LLMs). We comprehensively apply various training methods, such as In‐context learning, Instruction‐tuning, and Task‐tuning, to investigate the biomedical information extraction capabilities of GPT‐3, OPT, and LLaMA. We also introduce Low‐Rank Adaptation (LoRA) technology to significantly reduce trainable parameters. The proposed method achieves satisfactory results in DDI triplet extraction, and demonstrates strong generalization ability on similar corpus.",
        "link": "http://dx.doi.org/10.1002/pra2.918"
    },
    {
        "id": 13394,
        "title": "Generative Artificial Intelligence Through ChatGPT and Other Large Language Models in Ophthalmology",
        "authors": "Ting Fang Tan, Arun James Thirunavukarasu, J. Peter Campbell, Pearse A. Keane, Louis R. Pasquale, Michael D. Abramoff, Jayashree Kalpathy-Cramer, Flora Lum, Judy E. Kim, Sally L. Baxter, Daniel Shu Wei Ting",
        "published": "2023-12",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.xops.2023.100394"
    },
    {
        "id": 13395,
        "title": "Toward a Better Understanding of the Emotional Dynamics of Negotiation with Large Language Models",
        "authors": "Eleanor Lin, James Hale, Jonathan Gratch",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3565287.3617637"
    },
    {
        "id": 13396,
        "title": "Kako „razmišljaju“ veliki jezični modeli i možemo li im\nvjerovati",
        "authors": "Jasminka Dobša",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "Cilj rada je pokušati, u kontekstu testiranja modela ChatGPT na studentskim zadacima iz područja statistike, prepoznati slučajeve u kojima veliki jezični modeli pokazuju slično ponašanje ljudskom razmišljanju, a u kojima „razmišljaju“ na drugačiji način te identificirati prilike, rizike i ograničenja kod primjene umjetne inteligencije u nastavi. Analizirat će se mogućnosti i ograničenja velikih jezičnih modela te načini na koje se u ovom brzo rastućem području nastoji nadići postojeće pristranosti i nedostatke. U radu će se testirati chatbot na temelju velikoga jezičnoga modela GPT-4 ChatGPT u znanju uvodnog statističkog kolegija koji se predaje na drugoj godini studija studentima informatičkog studija. Testiranje je provedeno ručnim unošenjem 170 kviz pitanja iz područja statistike u preglednik ChatGPT-a. Pitanja su podijeljena u tri kategorije: teorijska pitanja u kojim se reproducira znanje, teorijska pitanja u kojim se testira razumijevanje područja i zadaci. Kviz pitanja su postavljena na hrvatskom jeziku i analizirani su odgovori dobiveni na hrvatskom jeziku. Uspoređena je točnost rješavanja kviz pitanja za studente i ChatGPT po kategorijama pitanja korištenjem Wilcoxonovog testa sume rangova. Rezultati pokazuju da ChatGPT daje statistički bolje rezultate od studenata u kategorijama teorijskih pitanja u kojima se traži reprodukcija znanja i razumijevanje, dok su kod rješavanja zadataka studenti uspješniji, ali razlika u točnosti nije statistički značajna (p&lt;0,01).  ",
        "link": "http://dx.doi.org/10.36978/cte.7.2.2"
    },
    {
        "id": 13397,
        "title": "Extracting narrative data via large language models for loan default prediction: when talk isn’t cheap",
        "authors": "Yufei Xia, Zhengxu Shi, Xiaoying Du, Qiong Zheng",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/13504851.2023.2275647"
    },
    {
        "id": 13398,
        "title": "llm-japanese-dataset v0: Construction of Japanese Chat Dataset for Large Language Models and Its Methodology",
        "authors": "Masanori Hirano, Masahiro Suzuki, Hiroki Sakaji",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-40978-3_47"
    },
    {
        "id": 13399,
        "title": "StableYolo: Optimizing Image Generation for Large Language Models",
        "authors": "Harel Berger, Aidan Dakhama, Zishuo Ding, Karine Even-Mendoza, David Kelly, Hector Menendez, Rebecca Moussa, Federica Sarro",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-48796-5_10"
    },
    {
        "id": 13400,
        "title": "Automated Category and Trend Analysis of Scientific Articles Using Large Language Models (LLMs): An Application in Ophthalmology (Preprint)",
        "authors": "Hina Raja, Asim Munawar, Nikolaos Mylonas, Mohammad Delsoz., Yeganeh Madadi, Mohammad Elahi, Amr Hassan, Hashem Abu Serhan, Onur Inam, Luis Hernandez, Hao Chen, Sang Tran, Wuqas Munir, Alaa Abd-Alrazaq, Siamak Yousefi.",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2196/52462"
    },
    {
        "id": 13401,
        "title": "Enhancing Genetic Improvement Mutations Using Large Language Models",
        "authors": "Alexander E. I. Brownlee, James Callan, Karine Even-Mendoza, Alina Geiger, Carol Hanna, Justyna Petke, Federica Sarro, Dominik Sobania",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-48796-5_13"
    },
    {
        "id": 13402,
        "title": "Domain-Specific Counseling Chatbot Platform Based on Large-Scale Language Models and Knowledge Graphsm",
        "authors": "Yeon-Su Noh,  , Ung-Hoe Lee, Se-Hoon Lee, Ye-Seol Lee",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.52618/aied.2023.4.3.6"
    },
    {
        "id": 13403,
        "title": "Clinical decision support for bipolar depression using large language models",
        "authors": "Roy H. Perlis, Joseph F. Goldberg, Michael J. Ostacher, Christopher D. Schneck",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "AbstractManagement of depressive episodes in bipolar disorder remains challenging for clinicians despite the availability of treatment guidelines. In other contexts, large language models have yielded promising results for supporting clinical decisionmaking. We developed 50 sets of clinical vignettes reflecting bipolar depression and presented them to experts in bipolar disorder, who were asked to identify 5 optimal next-step pharmacotherapies and 5 poor or contraindicated choices. The same vignettes were then presented to a large language model (GPT4-turbo; gpt-4-1106-preview), with or without augmentation by prompting with recent bipolar treatment guidelines, and asked to identify the optimal next-step pharmacotherapy. Overlap between model output and gold standard was estimated. The augmented model prioritized the expert-designated optimal choice for 508/1000 vignettes (50.8%, 95% CI 47.7–53.9%; Cohen’s kappa = 0.31, 95% CI 0.28–0.35). For 120 vignettes (12.0%), at least one model choice was among the poor or contraindicated treatments. Results were not meaningfully different when gender or race of the vignette was permuted to examine risk for bias. By comparison, an un-augmented model identified the optimal treatment for 234 (23.0%, 95% CI 20.8–26.0%; McNemar’s p < 0.001 versus augmented model) of the vignettes. A sample of community clinicians scoring the same vignettes identified the optimal choice for 23.1% (95% CI 15.7–30.5%) of vignettes, on average; McNemar’s p < 0.001 versus augmented model. Large language models prompted with evidence-based guidelines represent a promising, scalable strategy for clinical decision support. In addition to prospective studies of efficacy, strategies to avoid clinician overreliance on such models, and address the possibility of bias, will be needed.",
        "link": "http://dx.doi.org/10.1038/s41386-024-01841-2"
    },
    {
        "id": 13404,
        "title": "Contextual Embeddings for Ukrainian: A Large Language Model Approach to Word Sense Disambiguation",
        "authors": "Yurii Laba, Volodymyr Mudryi, Dmytro Chaplynskyi, Mariana Romanyshyn, Oles Dobosevych",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.unlp-1.2"
    },
    {
        "id": 13405,
        "title": "Hallucination Mitigation in Natural Language Generation from Large-Scale Open-Domain Knowledge Graphs",
        "authors": "Xiao Shi, Zhengyuan Zhu, Zeyu Zhang, Chengkai Li",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.770"
    },
    {
        "id": 13406,
        "title": "Towards Large-Scale DRP Simulations: Generation of Large Super-Resolution images and Extraction of Large Pore Network Models",
        "authors": "Mohamed Regaieg, Clément Varloteaux, Titly Farhana Faisal, Zakaria ElAbid",
        "published": "2023-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11242-023-01913-9"
    },
    {
        "id": 13407,
        "title": "Ask an Expert: Leveraging Language Models to Improve Strategic Reasoning in Goal-Oriented Dialogue Models",
        "authors": "Qiang Zhang, Jason Naradowsky, Yusuke Miyao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.417"
    },
    {
        "id": 13408,
        "title": "Turing Machines",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_0012"
    },
    {
        "id": 13409,
        "title": "Finite Automata",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_0009"
    },
    {
        "id": 13410,
        "title": "Predicate Logic",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_0004"
    },
    {
        "id": 13411,
        "title": "Program Verification",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_0006"
    },
    {
        "id": 13412,
        "title": "Learning Chess With Language Models and Transformers",
        "authors": "Michael DeLeo, Erhan Guven",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4228661"
    },
    {
        "id": 13413,
        "title": "Models of Evaluating Curriculum for Language Education in Higher Education",
        "authors": "Pitambar Paudel",
        "published": "2022-11-10",
        "citations": 0,
        "abstract": "Any curriculum has to be updated with the changing needs and aspirations of the society. Its regular and systematic evaluation helps to show its role and effectiveness in meeting the worldly needs and challenges and being changed accordingly. Considering this rationale, in this article, I tried to present various approaches or methods frequently used in curriculum evaluation process in the higher education to make curriculum updated, need based, contextual and make the learners capable of dealing with the professional, pedagogical and individual challenges they encounter with. The review of various approaches of the curriculum evaluation indicates that no single approach is universal, that is, the evaluator should select the models of evaluation as per the context, nature of curriculum and the goals of education.",
        "link": "http://dx.doi.org/10.3126/awadharana.v7i1.49158"
    },
    {
        "id": 13414,
        "title": "Models and Mentors",
        "authors": "",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5040/9781350059719.ch-011"
    },
    {
        "id": 13415,
        "title": "Peer Review #2 of \"The neural machine translation models for the low-resource Kazakh–English language pair (v0.1)\"",
        "authors": "",
        "published": "2023-2-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.1224v0.1/reviews/2"
    },
    {
        "id": 13416,
        "title": "Comparative Analysis of Transformer based Language Models",
        "authors": "Aman Pathak",
        "published": "2021-1-23",
        "citations": 3,
        "abstract": "Natural language processing (NLP) has witnessed many substantial advancements in the past three years. With the introduction of the Transformer and self-attention mechanism, language models are now able to learn better representations of the natural language. These attentionbased models have achieved exceptional state-of-the-art results on various NLP benchmarks. One of the contributing factors is the growing use of transfer learning. Models are pre-trained on unsupervised objectives using rich datasets that develop fundamental natural language abilities that are fine-tuned further on supervised data for downstream tasks. Surprisingly, current researches have led to a novel era of powerful models that no longer require finetuning. The objective of this paper is to present a comparative analysis of some of the most influential language models. The benchmarks of the study are problem-solving methodologies, model architecture, compute power, standard NLP benchmark accuracies and shortcomings.",
        "link": "http://dx.doi.org/10.5121/csit.2021.110111"
    },
    {
        "id": 13417,
        "title": "When Geometric Deep Learning Meets Pretrained Protein Language Models",
        "authors": "Fang Wu, Yu Tao, Dragomir Radev, Jinbo Xu",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractGeometric deep learning has recently achieved great success in non-Euclidean domains, and learning on 3D structures of large biomolecules is emerging as a distinct research area. However, its efficacy is largely constrained due to the limited quantity of structural data. Meanwhile, protein language models trained on substantial 1D sequences have shown burgeoning capabilities with scale in a broad range of applications. Nevertheless, no preceding studies consider combining these different protein modalities to promote the representation power of geometric neural networks. To address this gap, we make the foremost step to integrate the knowledge learned by well-trained protein language models into several state-of-the-art geometric networks. Experiments are evaluated on a variety of protein representation learning benchmarks, including protein-protein interface prediction, model quality assessment, protein-protein rigid-body docking, and binding affinity prediction, leading to an overall improvement of 20% over baselines and the new state-of-the-art performance. Strong evidence indicates that the incorporation of protein language models’ knowledge enhances geometric networks’ capacity by a significant margin and can be generalized to complex tasks.",
        "link": "http://dx.doi.org/10.1101/2023.01.05.522958"
    },
    {
        "id": 13418,
        "title": "IMPACTS OF LANGUAGE MODELS (CHATGPT) ON ALGORITHM TEACHING",
        "authors": "Dominik Palla, Antonín Slabý",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21125/iceri.2023.1392"
    },
    {
        "id": 13419,
        "title": "From Narratives to Conceptual Models via Natural Language Processing",
        "authors": "David Shuttleworth, Jose Padilla",
        "published": "2022-12-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wsc57314.2022.10015274"
    },
    {
        "id": 13420,
        "title": "BACK MATTER",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_bmatter"
    },
    {
        "id": 13421,
        "title": "Program Verification",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_0006"
    },
    {
        "id": 13422,
        "title": "Language Representation Models: An Overview",
        "authors": "Thorben Schomacker, Marina Tropmann-Frick",
        "published": "2021-10-28",
        "citations": 10,
        "abstract": "In the last few decades, text mining has been used to extract knowledge from free texts. Applying neural networks and deep learning to natural language processing (NLP) tasks has led to many accomplishments for real-world language problems over the years. The developments of the last five years have resulted in techniques that have allowed for the practical application of transfer learning in NLP. The advances in the field have been substantial, and the milestone of outperforming human baseline performance based on the general language understanding evaluation has been achieved. This paper implements a targeted literature review to outline, describe, explain, and put into context the crucial techniques that helped achieve this milestone. The research presented here is a targeted review of neural language models that present vital steps towards a general language representation model.",
        "link": "http://dx.doi.org/10.3390/e23111422"
    },
    {
        "id": 13423,
        "title": "Identifying Disinformation Using Rhetorical Devices in Natural Language Models",
        "authors": "Katrina Ward, Hamilton Link, Kiril Avramov, Jean Goodwin",
        "published": "2022-9-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2172/1891194"
    },
    {
        "id": 13424,
        "title": "Parallel Grammars and Computation",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_4"
    },
    {
        "id": 13425,
        "title": "Applications in Computational Biology",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_15"
    },
    {
        "id": 13426,
        "title": "The geometry of hidden representations of protein language models",
        "authors": "Lucrezia Valeriani, Francesca Cuturello, Alessio Ansuini, Alberto Cazzaniga",
        "published": "No Date",
        "citations": 3,
        "abstract": "AbstractProtein language models (pLMs) transform their input into a sequence of hidden representations whose geometric behavior changes across layers. Looking at fundamental geometric properties such as the intrinsic dimension and the neighbor composition of these representations, we observe that these changes highlight a pattern characterized by three distinct phases. This phenomenon emerges across many models trained on diverse datasets, thus revealing a general computational strategy learned by pLMs to reconstruct missing parts of the data. These analyses show the existence of low-dimensional maps that encode evolutionary and biological properties such as remote homology and structural information. Our geometric approach sets the foundations for future systematic attempts to understand thespaceof protein sequences with representation learning techniques.",
        "link": "http://dx.doi.org/10.1101/2022.10.24.513504"
    },
    {
        "id": 13427,
        "title": "Spanish Sign Language Recognition with Different Topology Hidden Markov Models",
        "authors": "Carlos-D. Martínez-Hinarejos, Zuzanna Parcheta",
        "published": "2017-8-20",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2017-275"
    },
    {
        "id": 13428,
        "title": "Towards Better Decoding and Language Model Integration in Sequence to Sequence Models",
        "authors": "Jan Chorowski, Navdeep Jaitly",
        "published": "2017-8-20",
        "citations": 96,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2017-343"
    },
    {
        "id": 13429,
        "title": "Peer Review #2 of \"The neural machine translation models for the low-resource Kazakh–English language pair (v0.3)\"",
        "authors": "",
        "published": "2023-2-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.1224v0.3/reviews/2"
    },
    {
        "id": 13430,
        "title": "regLM: Designing realistic regulatory DNA with autoregressive language models",
        "authors": "Avantika Lal, David Garfield, Tommaso Biancalani, Gokcen Eraslan",
        "published": "No Date",
        "citations": 2,
        "abstract": "Cis-regulatory elements (CREs), such as promoters and enhancers, are DNA sequences that regulate the expression of genes. The activity of a CRE is influenced by the order, composition and spacing of sequence motifs that bind to proteins called transcription factors (TFs). Synthetic CREs with specific properties are needed for biomanufacturing as well as for many therapeutic applications including cell and gene therapy. Here, we present regLM, a framework to design synthetic CREs with desired properties, such as high, low or cell type-specific activity, using autoregressive language models in conjunction with supervised sequence-to-function models. We used our framework to design synthetic yeast promoters and cell type-specific human enhancers. We demonstrate that the synthetic CREs generated by our approach are not only predicted to have the desired functionality but also contain biological features similar to experimentally validated CREs. regLM thus facilitates the design of realistic regulatory DNA elements while providing insights into the cis-regulatory code.",
        "link": "http://dx.doi.org/10.1101/2024.02.14.580373"
    },
    {
        "id": 13431,
        "title": "Performance of Large Language Models in a Computer Science Degree Program",
        "authors": "Tim Krüger, Michael Gref",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-50485-3_40"
    },
    {
        "id": 13432,
        "title": "Reply to the Letter to the Editor: “Radiology in the era of large language models: additional facts to consider in the near and the dark side of the moon”",
        "authors": "Pilar López-Úbeda, Teodoro Martín-Noguerol, Antonio Luna",
        "published": "2023-11-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00330-023-10331-w"
    },
    {
        "id": 13433,
        "title": "From Images to Textual Prompts: Zero-shot Visual Question Answering with Frozen Large Language Models",
        "authors": "Jiaxian Guo, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Boyang Li, Dacheng Tao, Steven Hoi",
        "published": "2023-6",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01046"
    },
    {
        "id": 13434,
        "title": "Context-Driven Interactive Query Simulations Based on Generative Large Language Models",
        "authors": "Björn Engelmann, Timo Breuer, Jana Isabelle Friese, Philipp Schaer, Norbert Fuhr",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-56060-6_12"
    },
    {
        "id": 13435,
        "title": "Using Large Language Models for the Enforcement of Consumer Rights in Germany",
        "authors": "Lukas Waidelich, Marian Lambert, Zina Al-Washash, Steffen Kroschwald, Thomas Schuster, Nico Döring",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-43590-4_1"
    },
    {
        "id": 13436,
        "title": "AGIBench: A Multi-granularity, Multimodal, Human-Referenced, Auto-Scoring Benchmark for Large Language Models",
        "authors": "Fei Tang, Wanling Gao, LuZhou Peng, Jianfeng Zhan",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-97-0316-6_9"
    },
    {
        "id": 13437,
        "title": "Large Language Models in Ambulatory Devices for Home Health Diagnostics: A Case Study of Sickle Cell Anemia Management",
        "authors": "Oluwatosin Ogundare, Subuola Sofolahan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-40971-4_42"
    },
    {
        "id": 13438,
        "title": "Evaluating the Performance of Artificial Intelligence Chatbots and Large Language Models in the FE and PE Structural Exams",
        "authors": "M. Z. Naser, Brandon Ross, Jennifer Ogle, Venkatesh Kodur, Rami Hawileh, Jamal Abdalla, Huu-Tai Thai",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1061/ppscfx.sceng-1369"
    },
    {
        "id": 13439,
        "title": "Artificial intelligence, ChatGPT, and other large language models for social determinants of health: Current state and future directions",
        "authors": "Jasmine Chiat Ling Ong, Benjamin Jun Jie Seng, Jeren Zheng Feng Law, Lian Leng Low, Andrea Lay Hoon Kwa, Kathleen M. Giacomini, Daniel Shu Wei Ting",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.xcrm.2023.101356"
    },
    {
        "id": 13440,
        "title": "A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges",
        "authors": "Mohaimenul Azam Khan Raiaan, Md. Saddam Hossain Mukta, Kaniz Fatema, Nur Mohammad Fahad, Sadman Sakib, Most Marufatul Jannat Mim, Jubaer Ahmad, Mohammed Eunus Ali, Sami Azam",
        "published": "2024",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2024.3365742"
    },
    {
        "id": 13441,
        "title": "Large Language Models to generate meaningful feature model instances",
        "authors": "José A. Galindo, Antonio J. Dominguez, Jules White, David Benavides",
        "published": "2023-8-28",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3579027.3608973"
    },
    {
        "id": 13442,
        "title": "AutoCriteria: a generalizable clinical trial eligibility criteria extraction system powered by large language models",
        "authors": "Surabhi Datta, Kyeryoung Lee, Hunki Paek, Frank J Manion, Nneka Ofoegbu, Jingcheng Du, Ying Li, Liang-Chin Huang, Jingqi Wang, Bin Lin, Hua Xu, Xiaoyan Wang",
        "published": "2024-1-18",
        "citations": 2,
        "abstract": "Abstract\n\nObjectives\nWe aim to build a generalizable information extraction system leveraging large language models to extract granular eligibility criteria information for diverse diseases from free text clinical trial protocol documents. We investigate the model’s capability to extract criteria entities along with contextual attributes including values, temporality, and modifiers and present the strengths and limitations of this system.\n\n\nMaterials and Methods\nThe clinical trial data were acquired from https://ClinicalTrials.gov/. We developed a system, AutoCriteria, which comprises the following modules: preprocessing, knowledge ingestion, prompt modeling based on GPT, postprocessing, and interim evaluation. The final system evaluation was performed, both quantitatively and qualitatively, on 180 manually annotated trials encompassing 9 diseases.\n\n\nResults\nAutoCriteria achieves an overall F1 score of 89.42 across all 9 diseases in extracting the criteria entities, with the highest being 95.44 for nonalcoholic steatohepatitis and the lowest of 84.10 for breast cancer. Its overall accuracy is 78.95% in identifying all contextual information across all diseases. Our thematic analysis indicated accurate logic interpretation of criteria as one of the strengths and overlooking/neglecting the main criteria as one of the weaknesses of AutoCriteria.\n\n\nDiscussion\nAutoCriteria demonstrates strong potential to extract granular eligibility criteria information from trial documents without requiring manual annotations. The prompts developed for AutoCriteria generalize well across different disease areas. Our evaluation suggests that the system handles complex scenarios including multiple arm conditions and logics.\n\n\nConclusion\nAutoCriteria currently encompasses a diverse range of diseases and holds potential to extend to more in the future. This signifies a generalizable and scalable solution, poised to address the complexities of clinical trial application in real-world settings.\n",
        "link": "http://dx.doi.org/10.1093/jamia/ocad218"
    },
    {
        "id": 13443,
        "title": "Updated Primer on Generative Artificial Intelligence and Large Language Models in Medical Imaging for Medical Professionals",
        "authors": "Kiduk Kim, Kyungjin Cho, Ryoungwoo Jang, Sunggu Kyung, Soyoung Lee, Sungwon Ham, Edward Choi, Gil-Sun Hong, Namkug Kim",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3348/kjr.2023.0818"
    },
    {
        "id": 13444,
        "title": "VISUAL MODELS OF COMMUNICATION AND LANGUAGE",
        "authors": "Aliaksei Dadykin, Vitaly Dibrova, Imad Tahini",
        "published": "2017-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21125/inted.2017.1650"
    },
    {
        "id": 13445,
        "title": "Cumulative Frequency Can Explain Cognate Facilitation in Language Models",
        "authors": "Irene Elisabeth Winther, Yevgen Matusevych, Martin John Pickering",
        "published": "No Date",
        "citations": 0,
        "abstract": "Cognates – words which share form and meaning across two languages – have been extensively studied to understand the bilingual mental lexicon. One consistent finding is that bilingual speakers process cognates faster than non-cognates, an effect known as cognate facilitation. Yet, there is no agreement on the underlying factors driving this effect. In this paper, we use computational modeling to test whether the effect can be explained by the cumulative frequency hypothesis. We train a computational language model on two language pairs (Dutch–English, Norwegian–English) under different conditions of input presentation and test it on sentence stimuli from two existing studies with bilingual speakers of those languages.  We find that our model can exhibit a cognate effect, lending support to the cumulative frequency hypothesis. Further analyses reveal that the size of the effect in the model depends on its linguistic accuracy. We interpret our results within the literature on cognate processing.",
        "link": "http://dx.doi.org/10.31234/osf.io/e2vft"
    },
    {
        "id": 13446,
        "title": "Regulated Grammars and Computation",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_3"
    },
    {
        "id": 13447,
        "title": "HOW IS LANGUAGE LEARNING AND APPRECIATION OF INDONESIAN LITERATURE USING CREATIVE AND INNOVATIVE MODELS?",
        "authors": "Nia Oktaviani",
        "published": "No Date",
        "citations": 0,
        "abstract": "In the world of education teachers must create creative and innovative learning models,so that students are enthusiastic in the learning process. Creative and innovative learning willproduce a generation that is intelligent, insightful and has high knowledge. At this time a varietyof models and innovations are used by teachers in learning Indonesian. In learning Indonesian asa teacher facing problems and learning processes, especially in the cognitive aspects, namely thelack of understanding of teachers in teaching (Sukma, 2019). One of the subjects that is currentlyreceiving much attention is Indonesian. Indonesian subjects who are serious about succeeding inbecoming the national exam so that schools give more priority to Indonesian subjects. For thisreason, teachers must use attractive learning models in learning Indonesian. In addition, the useof various learning models can increase students' understanding in learning, (Sukma, 2018).",
        "link": "http://dx.doi.org/10.31227/osf.io/tu6v2"
    },
    {
        "id": 13448,
        "title": "FRONT MATTER",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_fmatter"
    },
    {
        "id": 13449,
        "title": "Mathematical Preliminaries",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_0001"
    },
    {
        "id": 13450,
        "title": "Propositional Logic",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_0002"
    },
    {
        "id": 13451,
        "title": "Phoneme Segmentation Using Self-Supervised Speech Models",
        "authors": "Luke Strgar, David Harwath",
        "published": "2023-1-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt54892.2023.10022827"
    },
    {
        "id": 13452,
        "title": "SonicParanoid2: fast, accurate, and comprehensive orthology inference with machine learning and language models",
        "authors": "Salvatore Cosentino, Wataru Iwasaki",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractAccurate inference of orthologous genes constitutes a prerequisite for comparative and evolutionary genomics. SonicParanoid is one of the fastest tools for orthology inference; however, its scalability and accuracy have been hampered by time-consuming all-versus-all alignments and the existence of proteins with complex domain architectures. Here, we present a substantial update of Sonicparanoid, where a gradient boosting predictor halves the execution time and a language model doubles the recall. Application to empirical large-scale and standardized benchmark datasets showed that SonicParanoid2 is up to 18X faster than comparable methods and also the most accurate. SonicParanoid2 is available athttps://gitlab.com/salvo981/sonicparanoid2",
        "link": "http://dx.doi.org/10.1101/2023.05.14.540736"
    },
    {
        "id": 13453,
        "title": "Peer Review #3 of \"The neural machine translation models for the low-resource Kazakh–English language pair (v0.2)\"",
        "authors": "",
        "published": "2023-2-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.1224v0.2/reviews/3"
    },
    {
        "id": 13454,
        "title": "Application Analysis of Large Displacement Well Drilling Technology in Oilfield",
        "authors": "",
        "published": "2022-2-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i2.264"
    },
    {
        "id": 13455,
        "title": "Safe and Rapid Construction Technology of Underground Large Section Chamber",
        "authors": "",
        "published": "2021-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i12.98"
    },
    {
        "id": 13456,
        "title": "Analysis and Design of a Large Diameter Shaft Assembly Scheme",
        "authors": "",
        "published": "2022-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i1.153"
    },
    {
        "id": 13457,
        "title": "Anti-surge Reason and Control Technology of Large Centrifugal Compressor",
        "authors": "",
        "published": "2021-3-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i3.33"
    },
    {
        "id": 13458,
        "title": "Safe Operation, Maintenance and Management of Large Belt Transportation Equipment",
        "authors": "",
        "published": "2022-4-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i4(01).33"
    },
    {
        "id": 13459,
        "title": "Chat 3d: Interactive 3d Reconstruction with Assistance of Large Language Model",
        "authors": "Mingang Jang, Gyeongyeong Kim, Sejin Park, Hyun Lee",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4614719"
    },
    {
        "id": 13460,
        "title": "Advanced Applications of Generative AI and Natural Language Processing Models",
        "authors": "Shwetha Baliga, Harshith K. Murthy, Apoorv Sadhale, Dhruti Upadhyaya",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "The discourse surrounding AI has sparked widespread discussions, with notable concerns arising from its current limitations. One such concern involves AI models struggling to understand the context of human requests, leading to unexpected or nonsensical outcomes. While instances like the conversation with ChatGPT may have garnered attention, they should be regarded as fascinating illustrations of the model's capabilities rather than indications of meaningful independence. In shaping perspectives on this subject, three noteworthy books have played a pivotal role: Superintelligence by Nick Bostrom, Life 3.0 by Max Tegmark, and A Thousand Brains by Jeff Hawkins. These books offer well-articulated and thought-provoking insights, contributing to the ongoing discussion surrounding AI. By exploring the risks, limitations, and potential implications of AI, it becomes evident that thoughtful consideration and proactive measures are necessary to navigate the evolving landscape of artificial intelligence.",
        "link": "http://dx.doi.org/10.4018/979-8-3693-0502-7.ch004"
    },
    {
        "id": 13461,
        "title": "Regulated Automata and Computation",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_7"
    },
    {
        "id": 13462,
        "title": "Chatter Generation through Language Models",
        "authors": "Matthias Müller-Brockhausen, Giulio Barbero, Mike Preuss",
        "published": "2023-8-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cog57401.2023.10333244"
    },
    {
        "id": 13463,
        "title": "Propositional Logic",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_0002"
    },
    {
        "id": 13464,
        "title": "Algebra, Automata, and Computation",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_10"
    },
    {
        "id": 13465,
        "title": "Meaning creation in novel noun-noun compounds: humans and language models",
        "authors": "Phoebe Chen, David Poeppel, Arianna Zuanazzi",
        "published": "No Date",
        "citations": 0,
        "abstract": "The interpretation of novel noun-noun compounds (NNCs, e.g., “devil salary”) requires the combination of nouns in the absence of syntactic cues, an interesting facet of complex meaning creation. Here we examine unconstrained interpretations of a large set of novel NNCs, to investigate how NNC constituents are combined into novel complex meanings. The data show that words’ lexical-semantic features (e.g., material, agentivity, imageability, semantic similarity) differentially contribute to the grammatical relations and the semantics of NNC interpretations. Further, we demonstrate that passive interpretations incur higher processing cost (longer interpretation times and more eye-movements) than active interpretations. Finally, we show that large language models (GPT-2, BERT, RoBERTa) can predict whether a NNC is interpretable by human participants and estimate differences in processing cost, but do not exhibit sensitivity to more subtle grammatical differences. The experiments illuminate how humans can use lexical-semantic features to interpret NNCs in the absence of explicit syntactic information.",
        "link": "http://dx.doi.org/10.31234/osf.io/gf2r9"
    },
    {
        "id": 13466,
        "title": "Regional Bias in Monolingual English Language Models",
        "authors": "Jiachen Lyu, Katharina Dost, Yun Sing Koh, Jörg Wicker",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIn Natural Language Processing (NLP), pre-trained language models (LLMs) are widely employed and refined for various tasks. These models have shown considerable social and geographic biases creating skewed or even unfair representations of certain groups.Research focuses on biases toward L2 (English as a second language) regions but neglects bias within L1 (first language) regions.In this work, we ask if there is regional bias within L1 regions already inherent in pre-trained LLMs and, if so, what the consequences are in terms of downstream model performance.We contribute an investigation framework specifically tailored for low-resource regions, offering a method to identify bias without imposing strict requirements for labeled datasets. Our research reveals subtle geographic variations in the word embeddings of BERT, even in cultures traditionally perceived as similar. These nuanced features, once captured, have the potential to significantly impact downstream tasks. Generally, models exhibit comparable performance on datasets that share similarities, and conversely, performance may diverge when datasets differ in their nuanced features embedded within the language. It is crucial to note that estimating model performance solely based on standard benchmark datasets may not necessarily apply to the datasets with distinct features from the benchmark datasets. Our proposed framework plays a pivotal role in identifying and addressing biases detected in word embeddings, particularly evident in low-resource regions such as New Zealand.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3713494/v1"
    },
    {
        "id": 13467,
        "title": "Beyond Extraction: Contextualising Tabular Data for Efficient Summarisation by Language Models",
        "authors": "Uday Allu, Biddwan Ahmed, Vishesh Tripathi",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36227/techrxiv.170792474.42605726/v1"
    },
    {
        "id": 13468,
        "title": "Peer Review #3 of \"The neural machine translation models for the low-resource Kazakh–English language pair (v0.1)\"",
        "authors": "",
        "published": "2023-2-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.1224v0.1/reviews/3"
    },
    {
        "id": 13469,
        "title": "Peer Review #3 of \"The neural machine translation models for the low-resource Kazakh–English language pair (v0.3)\"",
        "authors": "",
        "published": "2023-2-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.1224v0.3/reviews/3"
    },
    {
        "id": 13470,
        "title": "Searching for a third-space methodology to contest essentialist large-culture blocks",
        "authors": "Adrian Holliday",
        "published": "2022-5-4",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/14708477.2022.2036180"
    },
    {
        "id": 13471,
        "title": "Two-faced AI language models learn to hide deception",
        "authors": "Matthew Hutson",
        "published": "2024-1-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/d41586-024-00189-3"
    },
    {
        "id": 13472,
        "title": "Algebra, Grammars, and Computation",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_6"
    },
    {
        "id": 13473,
        "title": "Introduction to Language Dynamics",
        "authors": "",
        "published": "2020-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108480659.006"
    },
    {
        "id": 13474,
        "title": "Applications in Computational Linguistics",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_14"
    },
    {
        "id": 13475,
        "title": "Augmenting Case Based Learning With Dynamic Language Models",
        "authors": "Conrad Czejdo, Sambit Bhattacharya",
        "published": "2021-3-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/southeastcon45413.2021.9401836"
    },
    {
        "id": 13476,
        "title": "AI LANGUAGE MODELS, STANDARDIZED TESTS, AND ACADEMIC INTEGRITY: A CHAT (GPT)",
        "authors": "",
        "published": "2023-11-13",
        "citations": 0,
        "abstract": "Language models’ popularity is on the rise, and with that, concerns about academic integrity in the times of such advanced Artificial intelligence (AI) tools are on the rise, too. Considering such concerns, this small study, which employs both qualitative and quantitative methods, thoroughly examines the role of language models, particularly ChatGPT, in the context of academic integrity. By assessing the accuracy of test answers generated by said language model, on questions from the state-issued high-school graduation English exam in N. Macedonia, and analyzing parts of essays generated using various prompts, the study aims to explore the potential implications of such AI tools on academic integrity in this new tech era.\nThe study shows that ChatGPT's accuracy in providing test answers is satisfactory, with a minimal number of mistakes and over 80% accuracy on average, on both tests! As for the text/parts of essays generated by the model, the study has shown that the quality of the generated text differed based on the prompts that the user provided and their proficiency in articulating their specific demands. The study also showed that current AI detection remains unreliable at best.\nThese findings contribute to the ongoing discourse on AI's influence on education and academic integrity, especially in regard to ChatGPT’s capabilities to generate content that can pass standardized tests and excel in open-ended writing tasks.",
        "link": "http://dx.doi.org/10.20544/teacher.26.03"
    },
    {
        "id": 13477,
        "title": "From Natural Language Models to Cognitive Model Validation: A Theoretical Framework",
        "authors": "Tehilla Mechera-Ostrovsky, Ben R Newell",
        "published": "No Date",
        "citations": 0,
        "abstract": "We propose a novel technique that uses individuals' verbal descriptions of their problem-solving strategies to validate psychological processes assumed by computational cognitive models. We capitalize on recent advances in Natural Language Processing models (NLP), in particular their context-sensitivity, to classify participants’ unstructured verbal descriptions. We illustrate our approach with an experiment examining how people integrate social and private information when making risky decisions. We contrast NLP model outputs derived from participants’ verbal descriptions with the assumptions underlying a computational model fit to the behavioural data. We discuss ways to refine and improve this technique, and argue that verbal descriptions are a valuable and under-utilized source of data for holding cognitive models accountable to their psychological assumptions.",
        "link": "http://dx.doi.org/10.31234/osf.io/r6det"
    },
    {
        "id": 13478,
        "title": "Single-sequence protein structure prediction using supervised transformer protein language models",
        "authors": "Wenkai Wang, Zhenling Peng, Jianyi Yang",
        "published": "No Date",
        "citations": 8,
        "abstract": "AbstractIt remains challenging for single-sequence protein structure prediction with AlphaFold2 and other deep learning methods. In this work, we introduce trRosettaX-Single, a novel algorithm for singlesequence protein structure prediction. It is built on sequence embedding from s-ESM-1b, a supervised transformer protein language model optimized from the pre-trained model ESM-1b. The sequence embedding is fed into a multi-scale network with knowledge distillation to predict inter-residue 2D geometry, including distance and orientations. The predicted 2D geometry is then used to reconstruct 3D structure models based on energy minimization. Benchmark tests show that trRosettaX-Single outperforms AlphaFold2 and RoseTTAFold on natural proteins. For instance, with single-sequence input, trRosettaX-Single generates structure models with an average TM-score ~0.5 on 77 CASP14 domains, significantly higher than AlphaFold2 (0.35) and RoseTTAFold (0.34). Further test on 101 human-designed proteins indicates that trRosettaX-Single works very well, with accuracy (average TM-score 0.77) approaching AlphaFold2 and higher than RoseTTAFold, but using much less computing resource. On 2000 designed proteins from network hallucination, trRosettaX-Single generates structure models highly consistent to the hallucinated ones. These data suggest that trRosettaX-Single may find immediate applications in de novo protein design and related studies. trRosettaX-Single is available through the trRosetta server at: http://yanglab.nankai.edu.cn/trRosetta/.",
        "link": "http://dx.doi.org/10.1101/2022.01.15.476476"
    },
    {
        "id": 13479,
        "title": "Of models and monsters",
        "authors": "Mika Aaltola",
        "published": "2018-7-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7765/9781526137517.00013"
    },
    {
        "id": 13480,
        "title": "Expert-adapted language models improve the fit to reading times",
        "authors": "Iza Skrjanec, Frederik Yannick Broy, Vera Demberg",
        "published": "No Date",
        "citations": 0,
        "abstract": "The concept of surprisal refers to the predictability of a word based on its context. Surprisal is known to be predictive of human processing difficulty and is usually estimated by language models. However, because humans differ in their linguistic experience, they also differ in the actual processing difficulty they experience with a given word or sentence. We investigate whether models that are similar to the linguistic experience and background knowledge of a specific group of humans are better at predicting their reading times than a generic language model. We analyze reading times from the PoTeC corpus (Jäger et al. 2021) of eye movements from biology and physics experts reading biology and physics texts. We find experts read in-domain texts faster than novices, especially domain-specific terms. Next, we train language models adapted to the biology and physics domains and show that surprisal obtained from these specialized models improves the fit to expert reading times above and beyond a generic language model.",
        "link": "http://dx.doi.org/10.31234/osf.io/dc8y6"
    },
    {
        "id": 13481,
        "title": "Quality of Argumentation Models",
        "authors": "Chamnong Kaewpet",
        "published": "2018-9-1",
        "citations": 3,
        "abstract": "This study investigated the effectiveness of updated argumentation quality criteria. It evaluated the scale and quality of selected argumentation models judged by the new criteria. Effectiveness concerned content validity, reliability, and practicality of the criteria. The argumentation models were regarded as possessing good quality when they featured important elements in the criteria and received high scores. Five argumentation models were purposefully selected from an argumentative writing course. The models were evaluated by three evaluators with expertise in academic writing. Analysis confirmed the effectiveness of the quality criteria and scale. It addressed all important concerns in evaluation of argumentation; evaluation scores were in accordance with each other, and the important argumentation elements carried equivalent weight. Only three of the models received a quality score of 4 on a scale of 0 (null) to 5 (highest), because they did not feature all quality elements required by the criteria. The updated framework and argumentation models can be further employed for teaching, learning and evaluating argumentation.",
        "link": "http://dx.doi.org/10.17507/tpls.0809.01"
    },
    {
        "id": 13482,
        "title": "Formal Models in the Study of Language",
        "authors": "",
        "published": "2017",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5"
    },
    {
        "id": 13483,
        "title": "Distinguishing word identity and sequence context in DNA language models",
        "authors": "Melissa Sanabria, Jonas Hirsch, Anna R. Poetsch",
        "published": "No Date",
        "citations": 3,
        "abstract": "AbstractTransformer-based large language models (LLMs) are very suited for biological sequence data, because the structure of protein and nucleic acid sequences show many analogies to natural language. Complex relationships in biological sequence can be learned, although there may not be a clear concept of words, because they can be generated through tokenization. Training is subsequently performed for masked token prediction. With this strategy, the models learn both the token sequence identity and a larger sequence context. We developed a framework to interrogate what a model learns, which is both relevant for the interpretability of the model and to evaluate its potential for specific tasks.We used a DNA language model, which is trained on the human reference genome with a Bidirectional Encoder Representations from Transformers (BERT) model. In this model, tokens are defined with overlapping k-mers. To gain insight into the model’s learning, we interrogated how the model performs predictions, extracted token embeddings, and defined a fine-tuning benchmarking task to predict the next tokens of different sizes without overlaps. This task is very suited to evaluate different pretrained DNA language models, also called foundation models, since it does not interrogate specific genome biology, does not depend on the tokenization strategy, the size of the vocabulary, the dictionary, or the number of parameters used to train the model. Lastly, the task performs without leakage of information from token identity into the prediction task, which makes it particularly useful to evaluate the learning of sequence context.Through this assessment we discovered that the model with overlapping k-mers struggles to learn larger sequence context. Instead, the learned embeddings largely represent token sequence. Still, good performance is achieved for genome biology inspired fine-tuning tasks. Models with overlapping tokens may be used for tasks where a larger sequence context is of less relevance, but the token sequence directly represents the desired learning feature. This emphasizes the need to interrogate knowledge representation in biological large language models. Transparency is particularly important for biomedical use cases and an understanding of what the models are learning can be used to match the model to the desired task.",
        "link": "http://dx.doi.org/10.1101/2023.07.11.548593"
    },
    {
        "id": 13484,
        "title": "Symbolic Math Reasoning with Language Models",
        "authors": "Vedant Gaur, Nikunj Saunshi",
        "published": "2022-9-30",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/urtc56832.2022.10002218"
    },
    {
        "id": 13485,
        "title": "Peer Review #2 of \"The neural machine translation models for the low-resource Kazakh–English language pair (v0.2)\"",
        "authors": "",
        "published": "2023-2-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.1224v0.2/reviews/2"
    },
    {
        "id": 13486,
        "title": "Analysis on the Case of Large Space Public Building Design",
        "authors": "",
        "published": "2022-4-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i4(11).47"
    },
    {
        "id": 13487,
        "title": "Application of Hydraulic Jacking Technology in Large-scale Grid Construction",
        "authors": "",
        "published": "2022-2-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i2.161"
    },
    {
        "id": 13488,
        "title": "Artificial Intelligence for Oncology Nursing Authors: Potential Utility and Concerns About Large Language Model Chatbots",
        "authors": "",
        "published": "2023-5-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1188/23.onf.276-277"
    },
    {
        "id": 13489,
        "title": "Facilitating the Compliance of Process Models with Critical System Engineering Standards using Natural Language Processing",
        "authors": "Faiz Muram, Muhammad Javed, Samina Kanwal",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010455903060313"
    },
    {
        "id": 13490,
        "title": "On the importance of pre-training data volume for compact language models",
        "authors": "Vincent Micheli, Martin d’Hoffschmidt, François Fleuret",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.632"
    },
    {
        "id": 13491,
        "title": "Beyond the Bias: Unveiling the Quality of Implicit Causality Prompt Continuations in Language Models",
        "authors": "Judith Sieker, Oliver Bott, Torgrim Solstad, Sina Zarrieß",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.inlg-main.15"
    },
    {
        "id": 13492,
        "title": "Meta-Learning Fast Weight Language Models",
        "authors": "Kevin Clark, Kelvin Guu, Ming-Wei Chang, Panupong Pasupat, Geoffrey Hinton, Mohammad Norouzi",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.661"
    },
    {
        "id": 13493,
        "title": "Ethical-Advice Taker: Do Language Models Understand Natural Language Interventions?",
        "authors": "Jieyu Zhao, Daniel Khashabi, Tushar Khot, Ashish Sabharwal, Kai-Wei Chang",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-acl.364"
    },
    {
        "id": 13494,
        "title": "What should be encoded by position embedding for neural network language models?",
        "authors": "Shuiyuan Yu, Zihao Zhang, Haitao Liu",
        "published": "2023-5-10",
        "citations": 0,
        "abstract": "Abstract\nWord order is one of the most important grammatical devices and the basis for language understanding. However, as one of the most popular NLP architectures, Transformer does not explicitly encode word order. A solution to this problem is to incorporate position information by means of position encoding/embedding (PE). Although a variety of methods of incorporating position information have been proposed, the NLP community is still in want of detailed statistical researches on position information in real-life language. In order to understand the influence of position information on the correlation between words in more detail, we investigated the factors that affect the frequency of words and word sequences in large corpora. Our results show that absolute position, relative position, being at one of the two ends of a sentence and sentence length all significantly affect the frequency of words and word sequences. Besides, we observed that the frequency distribution of word sequences over relative position carries valuable grammatical information. Our study suggests that in order to accurately capture word–word correlations, it is not enough to focus merely on absolute and relative position. Transformers should have access to more types of position-related information which may require improvements to the current architecture.",
        "link": "http://dx.doi.org/10.1017/s1351324923000128"
    },
    {
        "id": 13495,
        "title": "ADEPT: Adapter-based Efficient Prompt Tuning Approach for Language Models",
        "authors": "Aditya Shah, Surendrabikram Thapa, Aneesh Jain, Lifu Huang",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.sustainlp-1.8"
    },
    {
        "id": 13496,
        "title": "Probing Linguistic Knowledge in Italian Neural Language Models across Language Varieties",
        "authors": "Alessio Miaschi, Gabriele Sarti, Dominique Brunato, Felice Dell’Orletta, Giulia Venturi",
        "published": "2022-7-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4000/ijcol.965"
    },
    {
        "id": 13497,
        "title": "PATS: Sensitivity-aware Noisy Learning for Pretrained Language Models",
        "authors": "Yupeng Zhang, Hongzhi Zhang, Sirui Wang, Wei Wu, Zhoujun Li",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.241"
    },
    {
        "id": 13498,
        "title": "A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis",
        "authors": "Alessandro Stolfo, Yonatan Belinkov, Mrinmaya Sachan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.435"
    },
    {
        "id": 13499,
        "title": "Structural Adapters in Pretrained Language Models for AMR-to-Text Generation",
        "authors": "Leonardo F. R. Ribeiro, Yue Zhang, Iryna Gurevych",
        "published": "2021",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.351"
    },
    {
        "id": 13500,
        "title": "Probing Pretrained Language Models for Lexical Semantics",
        "authors": "Ivan Vulić, Edoardo Maria Ponti, Robert Litschko, Goran Glavaš, Anna Korhonen",
        "published": "2020",
        "citations": 25,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.586"
    },
    {
        "id": 13501,
        "title": "Unsupervised Paraphrasing with Pretrained Language Models",
        "authors": "Tong Niu, Semih Yavuz, Yingbo Zhou, Nitish Shirish Keskar, Huan Wang, Caiming Xiong",
        "published": "2021",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.417"
    },
    {
        "id": 13502,
        "title": "Constructing Taxonomies from Pretrained Language Models",
        "authors": "Catherine Chen, Kevin Lin, Dan Klein",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.373"
    },
    {
        "id": 13503,
        "title": "Analysis of Fire Protection Design Practice of Large Commercial Buildings",
        "authors": "",
        "published": "2021-9-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i9.337"
    },
    {
        "id": 13504,
        "title": "Discussion on Structural Design of Large-scale Sewage Treatment Plant",
        "authors": "",
        "published": "2022-2-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i2.124"
    },
    {
        "id": 13505,
        "title": "Machine vs. Human, who makes better judgment? Take Large Language Model GPT-4 For Example (Version 2)",
        "authors": "Mark Du",
        "published": "No Date",
        "citations": 0,
        "abstract": "This essay explores the topic of human decision-making and the concept of noise, which refers to random and irrelevant factors that can affect decision-making. The essay argues that while humans are prone to noise in their decision-making processes, artificial intelligence (AI) can make less noise due to its ability to process large amounts of data and apply logical algorithms to make decisions. The essay examines examples and studies to demonstrate the impact of noise on human decision-making, including business ideas. Additionally, the essay highlights the potential that machine intuition is doing better than humans.",
        "link": "http://dx.doi.org/10.31234/osf.io/4gh7y"
    },
    {
        "id": 13506,
        "title": "Automating Academic Assessment: A Large Language Model Approach",
        "authors": "Chatchai Wangwiwattana, Yuwaree Tongvivat",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/incit60207.2023.10412991"
    },
    {
        "id": 13507,
        "title": "Analysis of large-language model versus human performance for genetics questions",
        "authors": "Dat Duong, Benjamin D. Solomon",
        "published": "No Date",
        "citations": 16,
        "abstract": "AbstractLarge-language models like ChatGPT have recently received a great deal of attention. To assess ChatGPT in the field of genetics, we compared its performance to human respondents in answering genetics questions (involving 13,636 responses) that had been posted on social media platforms starting in 2021. Overall, ChatGPT did not perform significantly differently than human respondents, but did significantly better on memorization-type questions versus critical thinking questions, frequently provided different answers when asked questions multiple times, and provided plausible explanations for both correct and incorrect answers.",
        "link": "http://dx.doi.org/10.1101/2023.01.27.23285115"
    },
    {
        "id": 13508,
        "title": "Predicate Logic",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_0004"
    },
    {
        "id": 13509,
        "title": "Mathematical Preliminaries",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_0001"
    },
    {
        "id": 13510,
        "title": "Turing Machines",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_0012"
    },
    {
        "id": 13511,
        "title": "Context in Relevance Theory",
        "authors": "Stavros Assimakopoulos",
        "published": "2017",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5_12"
    },
    {
        "id": 13512,
        "title": "Language Identification Models for Short Medical Texts",
        "authors": "Daniela Gifu, Radu Ciora",
        "published": "2022-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ehb55594.2022.9991579"
    },
    {
        "id": 13513,
        "title": "MirrorWiC: On Eliciting Word-in-Context Representations from Pretrained Language Models",
        "authors": "Qianchu Liu, Fangyu Liu, Nigel Collier, Anna Korhonen, Ivan Vulić",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.conll-1.44"
    },
    {
        "id": 13514,
        "title": "Investigating Robustness of Dialog Models to Popular Figurative Language Constructs",
        "authors": "Harsh Jhamtani, Varun Gangal, Eduard Hovy, Taylor Berg-Kirkpatrick",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.592"
    },
    {
        "id": 13515,
        "title": "Embedding from Language Models (ELMos)- based Dependency Parser for Indonesian Language",
        "authors": "",
        "published": "2021-12-30",
        "citations": 1,
        "abstract": "The goal of dependency parsing is to seek a functional relationship among words. For instance, it tells the subject-object relation in a sentence. Parsing the Indonesian language requires information about the morphology of a word. Indonesian grammar relies heavily on affixation to combine root words with affixes to form another word. Thus, morphology information should be incorporated. Fortunately, it can be encoded implicitly by word representation. Embeddings from Language Models (ELMo) is a word representation which be able to capture morphology information. Unlike most widely used word representations such as word2vec or Global Vectors (GloVe), ELMo utilizes a Convolutional Neural Network (CNN) over characters. With it, the affixation process could ideally encoded in a word representation. We did an analysis using nearest neighbor words and T-distributed Stochastic Neighbor Embedding (t-SNE) word visualization to compare word2vec and ELMo. Our result showed that ELMo representation is richer in encoding the morphology information than it's counterpart. We trained our parser using word2vec and ELMo. To no surprise, the parser which uses ELMo gets a higher accuracy than word2vec. We obtain Unlabeled Attachment Score (UAS) at 83.08 for ELMo and 81.35 for word2vec. Hence, we confirmed that morphology information is necessary, especially in a morphologically rich language like Indonesian.  Keywords: ELMo, Dependency Parser, Natural Language Processing, word2vec",
        "link": "http://dx.doi.org/10.15849/ijasca.211128.01"
    },
    {
        "id": 13516,
        "title": "From Linear Models to Multi-layer Perceptrons",
        "authors": "Yoav Goldberg",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-02165-7_3"
    },
    {
        "id": 13517,
        "title": "Probing for Bridging Inference in Transformer Language Models",
        "authors": "Onkar Pandit, Yufang Hou",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.327"
    },
    {
        "id": 13518,
        "title": "Peer-to-Peer Tutors in a California Heritage Language Program",
        "authors": "Lina M. Reznicek-Parrado",
        "published": "2023-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003191179-2"
    },
    {
        "id": 13519,
        "title": "Do Not Fire the Linguist: Grammatical Profiles Help Language Models Detect Semantic Change",
        "authors": "Mario Giulianelli, Andrey Kutuzov, Lidia Pivovarova",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.lchange-1.6"
    },
    {
        "id": 13520,
        "title": "Thinking about the language models and what we can do with them",
        "authors": "Roman Horváth",
        "published": "2023-7-1",
        "citations": 0,
        "abstract": "Abstract\nMassive developments in technology, ICT, and artificial intelligence have been witnessed in recent years, with various projects emerging showing the apparent superiority of artificial intelligence over human intelligence, such as Deep Blue, AlphaGo, OpenAI Five, and GPT 3. In connection with them and with the favoured method of machine learning with deep learning, the term language model has appeared, which has the ambition to become the basis of general artificial intelligence (AGI). Critical responses, however, have been claiming that this is a dead end. An alternative view to these critical responses is attempted to be shown in this article, with consideration given as to whether the language model is just what critics consider it to be or whether something more can be sought behind it.",
        "link": "http://dx.doi.org/10.2478/jolace-2023-0003"
    },
    {
        "id": 13521,
        "title": "Using Artificial French Data to Understand the Emergence of Gender Bias in Transformer Language Models",
        "authors": "Lina Conti, Guillaume Wisniewski",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.641"
    },
    {
        "id": 13522,
        "title": "Performance Analysis of Different Word Embedding Models on Bangla Language",
        "authors": "Zakia Sultana Ritu, Nafisa Nowshin, Md Mahadi Hasan Nahid, Sabir Ismail",
        "published": "2018-9",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icbslp.2018.8554681"
    },
    {
        "id": 13523,
        "title": "All Bark and No Bite: Rogue Dimensions in Transformer Language Models Obscure Representational Quality",
        "authors": "William Timkey, Marten van Schijndel",
        "published": "2021",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.372"
    },
    {
        "id": 13524,
        "title": "RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked Auto-Encoder",
        "authors": "Shitao Xiao, Zheng Liu, Yingxia Shao, Zhao Cao",
        "published": "2022",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.35"
    },
    {
        "id": 13525,
        "title": "Language Models of Code are Few-Shot Commonsense Learners",
        "authors": "Aman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang, Graham Neubig",
        "published": "2022",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.90"
    },
    {
        "id": 13526,
        "title": "Can Language Models be Biomedical Knowledge Bases?",
        "authors": "Mujeen Sung, Jinhyuk Lee, Sean Yi, Minji Jeon, Sungdong Kim, Jaewoo Kang",
        "published": "2021",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.388"
    },
    {
        "id": 13527,
        "title": "Students' Hybrid Language Practices at the Core of SHL Pedagogy",
        "authors": "Lina M. Reznicek-Parrado",
        "published": "2023-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003191179-7"
    },
    {
        "id": 13528,
        "title": "Using Priming to Uncover the Organization of Syntactic Representations in Neural Language Models",
        "authors": "Grusha Prasad, Marten van Schijndel, Tal Linzen",
        "published": "2019",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/k19-1007"
    },
    {
        "id": 13529,
        "title": "Testing language acquisition models: null and overt topics in Mandarin",
        "authors": "Jingtao ZHU, Anna GAVARRÓ",
        "published": "2019-7",
        "citations": 4,
        "abstract": "AbstractParameter setting is either precipitous (Gibson &amp; Wexler, 1994) or it is gradual in response to input frequency (Yang, 2002, 2004). In this study, we compare these models against the empirical domain of subject and (direct) object drop in Mandarin. We conducted a corpus-based study of the speech of 47 Mandarin-speaking children aged 1;2–6;5, and their caregivers, from the CHILDES database. The results show that before age 1;8 all the children used null subjects and null objects in a target-like fashion, which reveals that the parameter that governs null topics is set from very early on, even if the presence of disambiguating evidence for [+Null Topic] patterns is low. Besides, children'sbaconstructions, which require an overt object, reliably included this object from the first occurrence although its frequency was scarce in the input. Our results indicate that the setting of certain parameters occurred early independently of the input.",
        "link": "http://dx.doi.org/10.1017/s0305000919000114"
    },
    {
        "id": 13530,
        "title": "Code-Switching Detection with Data-Augmented Acoustic and Language Models",
        "authors": "Emre Yilmaz, Henk Van Den Heuvel, David Van Leeuwen",
        "published": "2018-8-29",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/sltu.2018-27"
    },
    {
        "id": 13531,
        "title": "Hybrid Emoji-Based Masked Language Models for Zero-Shot Abusive Language Detection",
        "authors": "Michele Corazza, Stefano Menini, Elena Cabrio, Sara Tonelli, Serena Villata",
        "published": "2020",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.findings-emnlp.84"
    },
    {
        "id": 13532,
        "title": "Vision Guided Generative Pre-trained Language Models for Multimodal Abstractive Summarization",
        "authors": "Tiezheng Yu, Wenliang Dai, Zihan Liu, Pascale Fung",
        "published": "2021",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.326"
    },
    {
        "id": 13533,
        "title": "Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model",
        "authors": "Parishad BehnamGhader, Santiago Miret, Siva Reddy",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.1036"
    },
    {
        "id": 13534,
        "title": "A Comparative Study on Textual Saliency of Styles from Eye Tracking, Annotations, and Language Models",
        "authors": "Karin de Langis, Dongyeop Kang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-1.8"
    },
    {
        "id": 13535,
        "title": "Modeling Content Importance for Summarization with Pre-trained Language Models",
        "authors": "Liqiang Xiao, Lu Wang, Hao He, Yaohui Jin",
        "published": "2020",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.293"
    },
    {
        "id": 13536,
        "title": "Levinas on the Problem of Language",
        "authors": "William Large",
        "published": "2019-6-27",
        "citations": 0,
        "abstract": "This chapter discusses the problem of language in Levinas’s philosophy regarding methodology. Ethics, for Levinas, happens in everyday speech, where the Other demands a response from me. How he describes this relation presents methodological problems for Levinas, because it is resistant to any kind of theoretical approach, including phenomenology. Any writing about ethics, including Levinas’s, would immediately be its betrayal. This chapter describes Levinas’s account of language in Totality and Infinity, the issues that remain there, which it highlights through Blanchot’s and Derrida’s discussion of Levinas’s work. It also outlines a different way of thinking about the alterity of Other that is suggested in Totality and Infinity but comes to the fore in Otherwise Than Being, which is not as an opposition between speech and the visible, but enunciation (the saying) and the sayable (the said).",
        "link": "http://dx.doi.org/10.1093/oxfordhb/9780190455934.013.14"
    },
    {
        "id": 13537,
        "title": "Towards estimating global probabilities of evaluation in English based on automatic extraction of least delicate Appraisal in large corpora",
        "authors": "Bandar Alhumaidi A. Almutairi",
        "published": "2021-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.langsci.2021.101432"
    },
    {
        "id": 13538,
        "title": "Optimal Dispatch of Power System with Large-scale Wind Power",
        "authors": "",
        "published": "2022-3-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i3(11).28"
    },
    {
        "id": 13539,
        "title": "Designing efficient algorithms for querying large corpora",
        "authors": "Paul Meurer",
        "published": "2021-1-22",
        "citations": 0,
        "abstract": "I describe several new efficient algorithms for querying large annotated corpora. The search algorithms as they are implemented in several popular corpus search engines are less than optimal in two respects: regular expression string matching in the lexicon is done in linear time, and regular expressions over corpus positions are evaluated starting in those corpus positions that match the constraints of the initial edges of the corresponding network. To address these shortcomings, I have developed an algorithm for regular expression matching on suffix arrays that allows fast lexicon lookup, and a technique for running finite state automata from edges with lowest corpus counts. The implementation of the lexicon as suffix array also lends itself to an elegant and efficient treatment of multi-valued and set-valued attributes. The described techniques have been implemented in a fully functional corpus management system and are also used in a treebank query system.",
        "link": "http://dx.doi.org/10.5617/osla.8504"
    },
    {
        "id": 13540,
        "title": "The effects of language and home factors on Lebanese students’ mathematics performance in TIMSS",
        "authors": "Rayya Younes, Sara Salloum, Maya Antoun",
        "published": "2023-8-2",
        "citations": 0,
        "abstract": "AbstractUnderstanding the long-standing educational inequities associated with socioeconomic status remains significant for transforming educational policies and practices. To better understand entanglements among socioeconomic status and students’ performance in mathematics, we examined different home factors (including language of the test) that influence Lebanese learners’ performance in TIMSS. Exploring TIMSS data can assist us in identifying areas and groups of students who require additional assistance in order to address inequities. The purpose of this study is to investigate how language and other home factors influence Lebanese students’ mathematics performance in TIMSS. Mathematics is taught in a foreign language (English or French) in Lebanon, according to Language of Learning and Teaching policy (LoLT) that dates to 1926. Using TIMSS data and hierarchical linear modeling (HLM), we looked at how students performed in mathematics based on the language of the test and how often they spoke it at home. Other home factors such as parents’ education level, number of books owned, and parents’ involvement were also examined. Results show that not speaking the language of the test at home and other SES-related factors had different but mostly significant contribution to students’ mathematics scores. Lebanese students’ overall low performance suggests the time is ripe for a reformed Lebanese curricula that responds to the needs of learners and of society, taking into consideration students’ cultural capital and language of instruction.",
        "link": "http://dx.doi.org/10.1186/s40536-023-00180-w"
    },
    {
        "id": 13541,
        "title": "MarIA and BETO are sexist: evaluating gender bias in large language models for Spanish",
        "authors": "Ismael Garrido-Muñoz, Fernando Martínez-Santiago, Arturo Montejo-Ráez",
        "published": "2023-7-23",
        "citations": 0,
        "abstract": "AbstractThe study of bias in language models is a growing area of work, however, both research and resources are focused on English. In this paper, we make a first approach focusing on gender bias in some freely available Spanish language models trained using popular deep neural networks, like BERT or RoBERTa. Some of these models are known for achieving state-of-the-art results on downstream tasks. These promising results have promoted such models’ integration in many real-world applications and production environments, which could be detrimental to people affected for those systems. This work proposes an evaluation framework to identify gender bias in masked language models, with explainability in mind to ease the interpretation of the evaluation results. We have evaluated 20 different models for Spanish, including some of the most popular pretrained ones in the research community. Our findings state that varying levels of gender bias are present across these models.This approach compares the adjectives proposed by the model for a set of templates. We classify the given adjectives into understandable categories and compute two new metrics from model predictions, one based on the internal state (probability) and the other one on the external state (rank). Those metrics are used to reveal biased models according to the given categories and quantify the degree of bias of the models under study.",
        "link": "http://dx.doi.org/10.1007/s10579-023-09670-3"
    },
    {
        "id": 13542,
        "title": "Large-scale imputation models for multi-ancestry proteome-wide association analysis",
        "authors": "Chong Wu, Zichen Zhang, Xiaochen Yang, Bingxin Zhao",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractProteome-wide association studies (PWAS) decode the intricate proteomic landscape of biological mechanisms for complex diseases. Traditional PWAS model training relies heavily on individual-level reference proteomes, thereby restricting its capacity to harness the emerging summary-level protein quantitative trait loci (pQTL) data in the public domain. Here we introduced a novel framework to train PWAS models directly from pQTL summary statistics. By leveraging extensive pQTL data from the UK Biobank, deCODE, and ARIC studies, we applied our approach to train large-scale European PWAS models (totaln= 88,838 subjects). Furthermore, we developed PWAS models tailored for Asian and African ancestries by integrating multi-ancestry summary and individual-level data resources (totaln= 914 for Asian and 3,042 for African ancestries). We validated the performance of our PWAS models through a systematic multi-ancestry analysis of over 700 phenotypes across five major genetic data resources. Our results bridge the gap between genomics and proteomics for drug discovery, highlighting novel protein-phenotype links and their transferability across diverse ancestries. The developed PWAS models and data resources are freely available atwww.gcbhub.org.",
        "link": "http://dx.doi.org/10.1101/2023.10.05.561120"
    },
    {
        "id": 13543,
        "title": "Industrial Challenges in Large Thermally Enabled Structural Whole Engine Models",
        "authors": "Michelle Tindall, Akin Keskin, Andrew Layton",
        "published": "2020-9-21",
        "citations": 0,
        "abstract": "Abstract\nUnderstanding gas turbine design at a system level presents a difficult challenge. Accurate predictions of gas turbine behaviour before whole engine tests are completed are invaluable in preventing costly design changes in the latter stages of the design life cycle. In this study a high fidelity whole engine model has been built — specifically, a thermally enabled structural model. This model can predict component displacements up to system level interactions across the whole engine. Knowledge from such a model can feed into multiple design areas contributing to performance, component design and structural understanding but can also be used to influence physical testing.\nThere are clear benefits in building such high fidelity models but also many challenges that need to be addressed, namely solver type, geometry interrogation, meshing, solver capability, computational power and finally, processing and validation of output data. Additionally, different applications have been used for thermal and structural modelling in order to utilise best capabilities in thermal and contact modelling but also enable scalability on high performance computing. However, utilising two different solvers involves meshes being tailored for each solver type but also introduces additional complexity of transferring information between the two models used.\nThe paper will discuss the challenges and analysis methodologies used to thermally solve the whole engine cycle, the mapping procedure to translate thermal data to a structural model, and the approach taken to solve the very large simulation model explicitly at a chosen condition to a pseudo-steady state. In order to validate the simulation results, a vast amount of time has been spent to compare the results to existing test data.\nAs model validation is a significant step in simulation to gain credibility of the results, a comparison of the predicted component displacements will be shown to X-ray data from a whole engine test. Results and limitations of this testing capability such as influence of engine vibration, shutter speed and noise in the data will be discussed and recommendations provided to improve accuracy of the results.",
        "link": "http://dx.doi.org/10.1115/gt2020-15207"
    },
    {
        "id": 13544,
        "title": "Algorithms for Distributed Simulation Cloning",
        "authors": "Dan Chen, Lizhe Wang, Jingying Chen",
        "published": "2017-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b11883-9"
    },
    {
        "id": 13545,
        "title": "Performance Analysis of Large Scale HPC Workflows for Earth System Models",
        "authors": "Joseph Kennedy, Benjamin Mayer, Katherine Evans, Jeff Duracha",
        "published": "2017-11-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2172/1439154"
    },
    {
        "id": 13546,
        "title": "Reviewer #3 (Public Review): Systematic creation and phenotyping of Mendelian disease models in C. elegans: towards large-scale drug repurposing",
        "authors": "",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.92491.1.sa0"
    },
    {
        "id": 13547,
        "title": "Investigating variation in written forms of Nahuatl using character-based language models",
        "authors": "Robert Pugh, Francis Tyers",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.americasnlp-1.3"
    },
    {
        "id": 13548,
        "title": "21 Models of formal education and minority language teaching across countries",
        "authors": "Kutlay Yağmur",
        "published": "2020-6-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9781501510175-021"
    },
    {
        "id": 13549,
        "title": "Measuring Harmful Sentence Completion in Language Models for LGBTQIA+ Individuals",
        "authors": "Debora Nozza, Federico Bianchi, Anne Lauscher, Dirk Hovy",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.ltedi-1.4"
    },
    {
        "id": 13550,
        "title": "Analysing Neural Language Models: Contextual Decomposition Reveals Default Reasoning in Number and Gender Assignment",
        "authors": "Jaap Jumelet, Willem Zuidema, Dieuwke Hupkes",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/k19-1001"
    },
    {
        "id": 13551,
        "title": "BabySLM: language-acquisition-friendly benchmark of self-supervised spoken language models",
        "authors": "Marvin Lavechin, Yaya Sy, Hadrien Titeux, María Andrea Cruz Blandón, Okko Räsänen, Hervé Bredin, Emmanuel Dupoux, Alejandrina Cristia",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-978"
    },
    {
        "id": 13552,
        "title": "SocioProbe: What, When, and Where Language Models Learn about Sociodemographics",
        "authors": "Anne Lauscher, Federico Bianchi, Samuel R. Bowman, Dirk Hovy",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.539"
    },
    {
        "id": 13553,
        "title": "Evaluating Modeling Units and Sub-word Features in Language Models for Turkish ASR",
        "authors": "Chang Liu, Yike Zhang, Pengyuan Zhang, Yaofeng Wang",
        "published": "2018-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iscslp.2018.8706685"
    },
    {
        "id": 13554,
        "title": "FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge",
        "authors": "Shangbin Feng, Vidhisha Balachandran, Yuyang Bai, Yulia Tsvetkov",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.59"
    },
    {
        "id": 13555,
        "title": "Language-Agnostic Bias Detection in Language Models with Bias Probing",
        "authors": "Abdullatif Köksal, Omer Yalcin, Ahmet Akbiyik, M. Kilavuz, Anna Korhonen, Hinrich Schuetze",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.848"
    },
    {
        "id": 13556,
        "title": "What’s “up” with vision-language models? Investigating their struggle with spatial reasoning",
        "authors": "Amita Kamath, Jack Hessel, Kai-Wei Chang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.568"
    },
    {
        "id": 13557,
        "title": "Incorporating Residual and Normalization Layers into Analysis of Masked Language Models",
        "authors": "Goro Kobayashi, Tatsuki Kuribayashi, Sho Yokoi, Kentaro Inui",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.373"
    },
    {
        "id": 13558,
        "title": "Word Frequency Does Not Predict Grammatical Knowledge in Language Models",
        "authors": "Charles Yu, Ryan Sie, Nicolas Tedeschi, Leon Bergen",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.331"
    },
    {
        "id": 13559,
        "title": "Assessing the Risk Potential: Selecting Predictive Models",
        "authors": "Ekaterina Sakrutina",
        "published": "2020-9-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd49919.2020.9247642"
    },
    {
        "id": 13560,
        "title": "Gaussian Stochastic Volatility Models: Scaling Regimes, Large Deviations, and Moment Explosions",
        "authors": "Archil Gulisashvili",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3367829"
    },
    {
        "id": 13561,
        "title": "Reviewer #1 (Public Review): Systematic creation and phenotyping of Mendelian disease models in C. elegans: towards large-scale drug repurposing",
        "authors": "",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.92491.1.sa2"
    },
    {
        "id": 13562,
        "title": "Bovine models for human ovarian diseases",
        "authors": "John F. Roberts, Chen-Che Jeff Huang",
        "published": "2022",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/bs.pmbts.2022.02.001"
    },
    {
        "id": 13563,
        "title": "PKUSenseCor: A Large-Scale Word Sense Annotated Chinese Corpus",
        "authors": "Peng Jin, Yunfang Wu, Xuefeng Zhu, Diana McCarthy, Weiguang Qu, Shiwen Yu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-38913-9_11"
    },
    {
        "id": 13564,
        "title": "Maintaining access to a large-scale test of academic language proficiency during the pandemic: The launch of TOEFL iBT Home Edition",
        "authors": "Spiros Papageorgiou, Venessa F. Manna",
        "published": "2021-1-1",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15434303.2020.1864376"
    },
    {
        "id": 13565,
        "title": "Improving the reliability of large-scale hydrological models with satellite observations",
        "authors": "Dung Trung Vu, Thanh Duc Dang, Stefano Galelli",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Over the past three decades, large-scale hydrological models have gained popularity due to the need to support water resources management at the regional and continental scales. One of the most challenging tasks for developing such models is the availability of data. The presence of human-water interactions, especially reservoir operations, can influence the model parameterization, while measured discharge and/or water levels along the rivers are necessary to the calibration purpose. However, such information is often unavailable. In particular, data on reservoir storage or river discharge are often not measured or shared between the riparian countries of transboundary rivers. A potential solution for this challenging task lies in satellite observations. Specifically, reservoir storage/release and river discharge/water level can be inferred from satellite images (Landsat/Sentinel-1/2) and/or altimetry data (Jason/Sentinel-3). In this study, we take advantage of remote-sensed data to improve the accuracy of a hydrological-water management model (VIC-Res) setup for the northern portion of the Mekong River Basin. Our modeling framework combines VIC-Res with an automated calibration procedure (based on a multi-objective evolutionary algorithm) that explicitly accounts for key water management decisions&amp;#8212;inferred from satellite data&amp;#8212;occurring within the basin. Results show that the use of such data largely improves the performance and reliability of the model.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu22-4817"
    },
    {
        "id": 13566,
        "title": "Galaxy Evolution and Semi-analytic Models",
        "authors": "",
        "published": "2021-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811211812_0004"
    },
    {
        "id": 13567,
        "title": "The Exponential Pyramid Representation that Compensates for Exponentially Large Problem Spaces",
        "authors": "",
        "published": "2022-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009205603.005"
    },
    {
        "id": 13568,
        "title": "Turbulence Closure Models: Reynolds Averaged Navier Stokes (RANS) &amp; Large Eddy Simulations (LES)",
        "authors": "Steven L. Brunton",
        "published": "No Date",
        "citations": 0,
        "abstract": "Turbulent fluid dynamics are often too complex to model every detail. Instead, we tend to model bulk quantities and low-resolution approximations. To remain physical, these reduced approximations of the Navier-Stokes equations must be 'closed', and turbulence closure modeling is one of the most important topics in high-performance computing and scientific computing. This video describes several leading approaches, including the Reynolds averaged Navier Stokes (RANS) equations and large eddy simulations (LES).",
        "link": "http://dx.doi.org/10.52843/cassyni.cjkr7f"
    },
    {
        "id": 13569,
        "title": "A Review of Models for Hydrating Large-scale Twitter Data of COVID-19-related Tweets for Transportation Research",
        "authors": "Mahmoud Arafat",
        "published": "No Date",
        "citations": 2,
        "abstract": "<p>In\nresponse to the Coronavirus disease (COVID-19) outbreak\nand the Transportation Research Board’s (TRB) urgent need for work related to\ntransportation and pandemics, this paper contributes with a sense of urgency\nand provides a starting point for research on the topic. The main goal of this\npaper is to support transportation researchers and the TRB community during\nthis COVID-19 pandemic by reviewing the performance of software models used for\nextracting large-scale data from Twitter streams related to COVID-19. The study\nextends the previous research efforts in social media data mining by providing\na review of contemporary tools, including their computing maturity and their\npotential usefulness. The paper also includes an open repository for the\nprocessed data frames to facilitate the quick development of new transportation\nresearch studies. The output of this work is recommended to be used by the TRB\ncommunity when deciding to further investigate topics related to COVID-19 and\nsocial media data mining tools.</p>",
        "link": "http://dx.doi.org/10.31124/advance.12192693.v1"
    },
    {
        "id": 13570,
        "title": "20Q: Overlap-Free World Knowledge Benchmark for Language Models",
        "authors": "Maxime De Bruyn, Ehsan Lotfi, Jeska Buhmann, Walter Daelemans",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gem-1.46"
    },
    {
        "id": 13571,
        "title": "COMMUNICATIVE MODELS IN THE PROCESS OF TEACHING BULGARIAN AS A FOREIGN LANGUAGE",
        "authors": "Reni Manova",
        "published": "2021-6-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7546/confibl2021.ii.46"
    },
    {
        "id": 13572,
        "title": "Articulatory postures and forward models in American Sign Language: Linguistic and neuroscience evidence",
        "authors": "David P. Corina",
        "published": "2021-12-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31009/feast.i4.05"
    },
    {
        "id": 13573,
        "title": "The Challenges of Existing Syntactic Models for English Language Teaching and Learning in Nigeria",
        "authors": "Roseline Abonego Adejare",
        "published": "2019-11-15",
        "citations": 0,
        "abstract": "A recent survey of existing syntactic models shows that none accurately describes the syntax of the English languagethat people actually use and that they inhibit rather than promote knowledge of natural language by creating a gapbetween what should be taught and learned and what obtains. To demonstrate this gap, this paper critically examinesfour recommended senior secondary school English course books to determine the extent to which they reflectexisting syntactic models’ descriptive inadequacies, and highlights the implications for language education inNigeria. Using the emerging Natural Language Linguistics (NLL) model as analytical tool, each book was carefullyexamined to identify topics on the syntactic units: sentence, clause and group. These were then critically studied,paying great attention to definitions, descriptive statements, models, and examples, and noting common features anddifferences. The bits of information pieced together constitute the data. Findings show inconsistency in modelapplication, no uniformity in, and consensus on, the number and nomenclature of syntactic units, terminologicalconfusion, descriptive inaccuracies, typological inexactness, incorrect definitions, wrong and inappropriate examples,and confusion between constituents and elements of structure. The absence of a clear-cut distinction between phraseand clause and between clause and sentence in existing syntactic models, which reflected in the books, explains theshortcomings that potentially limit learners’ knowledge and use ability. Only a syntactic model that accuratelymirrors natural language structure can positively promote language education in the Nigerian context where coursebooks are the most important English teaching-learning resource.",
        "link": "http://dx.doi.org/10.5430/ijelt.v7n1p1"
    },
    {
        "id": 13574,
        "title": "Navigating the Grey Area: How Expressions of Uncertainty and Overconfidence Affect Language Models",
        "authors": "Kaitlyn Zhou, Dan Jurafsky, Tatsunori Hashimoto",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.335"
    },
    {
        "id": 13575,
        "title": "Numerical implementation of constitutive models with large deformation",
        "authors": "Vladimir Buljak, Gianluca Ranzi",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-814696-5.00011-3"
    },
    {
        "id": 13576,
        "title": "ALGORITHMIC DECOMPOSITION AND REDUCTION OF LARGE MATHEMATICAL MODELS",
        "authors": " Rogoza W.,  Ischenko A.",
        "published": "2019",
        "citations": 0,
        "abstract": "The problems associated with the processing of large amounts of data, initiated research in the field of creating special software that allows us to process this data online. A well-known example of such software is the MapReduce computational model developed and implemented by Google. The advantages of MapReduce are the high processing speed of large data arrays, achieved through data decomposition and reduction, as well as the ability to implement this model on standard hardware. Creating algorithms and programs that comply with the principles of the MapReduce model, depends on the specifics of the tasks that are solved, and relies on the software developers. Most of the algorithms known today are designed to process large arrays of data coming to a computer system online without changing data models (i.e. the data is processed as it enters the system in the data stream). At the same time, it is possible to distinguish classes of tasks for which the data on the objects under study are redundant, and their volume can be significantly reduced even before this data is available for their transformation. As is shown in the article, this class includes the tasks of mathematical simulation of complex engineering objects, the data models of which are represented in the form of mathematical equations that describe the physical states of the objects. The authors discuss the problems of decomposition and reduction of models at the level of transformations of the mentioned mathematical equations, which is why the authors call this approach algorithmic decomposition and reduction.",
        "link": "http://dx.doi.org/10.36994/2707-4110-2019-2-23-17"
    },
    {
        "id": 13577,
        "title": "Index",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s1877-1173(22)00058-8"
    },
    {
        "id": 13578,
        "title": "Large models for genomics",
        "authors": "Lin Tang",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41592-023-02105-5"
    },
    {
        "id": 13579,
        "title": "bigIRT - R Software for Item Response Theory Models with Large and Sparse Data",
        "authors": "Charles C Driver, Martin J. Tomasik",
        "published": "No Date",
        "citations": 0,
        "abstract": "bigIRT is an R software package for the estimation of a range of item response theory models in contexts where there are large numbers of responses, students, and items, but the number of responses for individual students may still be low, resulting in high sparsity. The models are for binary data, using uni or multivariate, scales, 1 to 4 parameter logistic models, with covariate moderators of ability and item parameters. Estimation is maximum a posteriori, with optional empirical Bayesian approaches.",
        "link": "http://dx.doi.org/10.31234/osf.io/594uw"
    },
    {
        "id": 13580,
        "title": "Parametric non-intrusive reduced-order models via operator inference for large-scale rotating detonation engine simulations",
        "authors": "MMLDE 2023, Ionut Farcas",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26226/m.64f6d3494d5bfe5318de60da"
    },
    {
        "id": 13581,
        "title": "eLife assessment: Systematic creation and phenotyping of Mendelian disease models in C. elegans: towards large-scale drug repurposing",
        "authors": "Patrick Hu",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.92491.1.sa3"
    },
    {
        "id": 13582,
        "title": "Time-Inhomogeneous Gaussian Stochastic Volatility Models: Large Deviations and Super Roughness",
        "authors": "Archil Gulisashvili",
        "published": "No Date",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3574337"
    },
    {
        "id": 13583,
        "title": "Contributors",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s1877-1173(22)00054-0"
    },
    {
        "id": 13584,
        "title": "Synchronization in Federation Community Networks",
        "authors": "Dan Chen, Lizhe Wang, Jingying Chen",
        "published": "2017-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b11883-5"
    },
    {
        "id": 13585,
        "title": "Data Dysphoria: The Governance Challenge Posed by Large Learning Models",
        "authors": "Susan Ariel Aaronson",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4554580"
    },
    {
        "id": 13586,
        "title": "J-GAIN v1.0: A flexible tool to incorporate aerosol formation rates obtained by molecular models into large-scale models",
        "authors": "Daniel Yazgi, Tinja Olenius",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract. New-particle formation from condensable vapors is a common atmospheric process that has significant but uncertain effects on aerosol particle number concentrations and impacts. Assessing the formation rates of nanometer-sized particles from different vapors is an active field of research within atmospheric sciences, with new data being constantly produced by molecular models and experimental studies. Such data can be implemented in large-scale climate and air quality models as parameterizations or look-up tables. Models benchmarked against measurement data provide a straight-forward means to assess formation rates over a wide range of atmospheric conditions for given chemical compounds. Ideally, the implementation of such formation rate data should be easy, efficient and flexible in the sense that same tools can be conveniently applied for different data sets in which the formation rate depends on different parameters. In this work, we present a tool to generate and interpolate look-up tables of formation rates for user-defined input parameters. The table generator routine applies a molecular cluster dynamics model with quantum chemistry input, but other types of particle formation models may be used as well. The interpolation routine uses a multivariate interpolation algorithm, which is applicable to different numbers of independent parameters, and gives fast and accurate results with typical interpolation errors of up to a few percent. These routines facilitate the implementation and testing of different aerosol formation rate predictions in large-scale models, allowing straight-forward inclusion of new or updated data without the need to apply separate parameterizations or routines for different data sets that involve different chemical compounds or other parameters.\n                        ",
        "link": "http://dx.doi.org/10.5194/egusphere-2022-1464"
    },
    {
        "id": 13587,
        "title": "A Review of Models for Hydrating Large-scale Twitter Data of COVID-19-related Tweets for Transportation Research",
        "authors": "Mahmoud Arafat",
        "published": "No Date",
        "citations": 1,
        "abstract": "<p>In\nresponse to the Coronavirus disease (COVID-19) outbreak\nand the Transportation Research Board’s (TRB) urgent need for work related to\ntransportation and pandemics, this paper contributes with a sense of urgency\nand provides a starting point for research on the topic. The main goal of this\npaper is to support transportation researchers and the TRB community during\nthis COVID-19 pandemic by reviewing the performance of software models used for\nextracting large-scale data from Twitter streams related to COVID-19. The study\nextends the previous research efforts in social media data mining by providing\na review of contemporary tools, including their computing maturity and their\npotential usefulness. The paper also includes an open repository for the\nprocessed data frames to facilitate the quick development of new transportation\nresearch studies. The output of this work is recommended to be used by the TRB\ncommunity when deciding to further investigate topics related to COVID-19 and\nsocial media data mining tools.</p>",
        "link": "http://dx.doi.org/10.31124/advance.12192693"
    },
    {
        "id": 13588,
        "title": "Copyright",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s1877-1173(22)00053-9"
    },
    {
        "id": 13589,
        "title": "Models of the Spatial Evolution of an Enterprise",
        "authors": "H.D. Watts",
        "published": "2018-1-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780203703052-8"
    },
    {
        "id": 13590,
        "title": "Generative Models in Event Simulation",
        "authors": "Anja Butter",
        "published": "2020-10-27",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22323/1.382.0055"
    },
    {
        "id": 13591,
        "title": "Challenges in the calibration of large-scale ordinary differential equation models",
        "authors": "Eva-Maria Kapfer, Paul Stapor, Jan Hasenauer",
        "published": "No Date",
        "citations": 2,
        "abstract": "AbstractMathematical models based on ordinary differential equations have been employed with great success to study complex biological systems. With soaring data availability, more and more models of increasing size are being developed. When working with these large-scale models, several challenges arise, such as high computation times or poor identifiability of model parameters. In this work, we review and illustrate the most common challenges using a published model of cellular metabolism. We summarize currently available methods to deal with some of these challenges while focusing on reproducibility and reusability of models, efficient and robust model simulation and parameter estimation.",
        "link": "http://dx.doi.org/10.1101/690222"
    },
    {
        "id": 13592,
        "title": "Evaluation of Sequence Learning Models for Large Commercial Building Load Forecasting",
        "authors": "Cristina Nichiforov, Grigore Stamatescu, Iulia Stamatescu, Ioana Fagarasan",
        "published": "No Date",
        "citations": 1,
        "abstract": "Buildings have started to play a critical role in the stability and resilience of modern smart grids, leading to a refocusing of large scale energy management strategies from the supply side to the consumer side. When the buildings integrate local renewable energy generation in the form of renewable energy resources they become prosumers and this reflects into additional complexity into the operation of the interconnected complex energy systems. A class of methods of modelling the energy consumption patterns of the building have recently emerged as black-box input-output approaches with the ability to capture underlying consumption trends. These make use and require large quantities of quality data produces by non-deterministic processes underlying the energy consumption. We present an application of a class of neural networks, namely deep learning techniques for time series sequence modelling with the goal of accurate and reliable building energy load forecasting. The Recurrent Neural Network implementation uses Long Short-Term Memory layers in increasing density of nodes to quantify prediction accuracy. The case study is illustrated on four university buildings from temperate climates over one year of operation using a reference benchmarking dataset that allows replicable results. The obtained results are discussed in terms of accuracy metrics and computational and network architecture aspects and are considered suitable for further used in future in situ energy management at the building and neighbourhood levels.",
        "link": "http://dx.doi.org/10.20944/preprints201904.0318.v1"
    },
    {
        "id": 13593,
        "title": "Reviewer #2 (Public Review): Systematic creation and phenotyping of Mendelian disease models in C. elegans: towards large-scale drug repurposing",
        "authors": "",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.92491.1.sa1"
    },
    {
        "id": 13594,
        "title": "Blending Simulation and Machine Learning Models to Advance Energy Management in Large Ships",
        "authors": "Eirini Barri, Christos Bouras, Apostolos Gkamas, Nikos Karacapilidis, Dimitris Karadimas, Georgios Kournetas, Yiannis Panaretou",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009876601010109"
    },
    {
        "id": 13595,
        "title": "Statistical Comparison of Parallel-Line Symmetrical Microbiological Models: Analysis of Agar Diffusion Assay in 8 x 8 Large Rectangular Plates",
        "authors": "Mostafa EİSSA",
        "published": "2021-12-27",
        "citations": 1,
        "abstract": "Abstract: (1) Background: Microbiological assay of active medicinal compounds is superior to conventional chemical means in several circumstances to date. However, ensuring the validity and suitability of the assay design proposed for the intended purpose is crucial before deriving any records or conclusions from the results of the potency determination; (2) The present work represented statistical comparison between three design models for determination of the potency of Neomycin Sulfate antibiotic using agar diffusion technique for the same test material subject under identical conditions through the application of a combination of statistical software programs, including validated programmed Microsoft Excel Workbook for the statistical testing of each assay layout; (3) Results: raw data of the three assay designs were found to be reasonably valid for further analysis of the assay suitability. Examination of the sources of variations for each design demonstrated the validity of the conducted experimentation. Variation between the computed potencies from the three designs was lower than 5 µg/mg. However, there was significant variation between the confidence windows of each type; (4) Conclusions: 2 x 4 design had the narrowest confidence range. However, improving confidence would require investigation of the assay parameters, including the modification of the number of replicates per treatment.",
        "link": "http://dx.doi.org/10.52693/jsas.989584"
    },
    {
        "id": 13596,
        "title": "Engineering and Studying Syngeneic Animal Tumors and Large Animal Endogenous Tumor Models",
        "authors": "K. Suganya, Sreya Babu, Indranil Chattopadhyay",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-3824-5_25"
    },
    {
        "id": 13597,
        "title": "Engineering and studying syngeneic animal tumors and Large animal endogenous tumor models",
        "authors": "K. Suganya, Sreya Babu, Indranil Chattopadhyay",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-1282-5_25-1"
    },
    {
        "id": 13598,
        "title": "Large Animal Models of Diabetes",
        "authors": "Barbara Ludwig, Eckhard Wolf, Uwe Schönmann, Stefan Ludwig",
        "published": "2020",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-0716-0385-7_9"
    },
    {
        "id": 13599,
        "title": "ChiSquareX at TextGraphs 2020 Shared Task: Leveraging Pretrained Language Models for Explanation Regeneration",
        "authors": "Aditya Girish Pawate, Varun Madhavan, Devansh Chandak",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.textgraphs-1.12"
    },
    {
        "id": 13600,
        "title": "Semi-Supervised Language Models for Identification of Personal Health Experiential from Twitter Data: A Case for Medication Effects",
        "authors": "Minghao Zhu, Keyuan Jiang",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.bionlp-1.25"
    },
    {
        "id": 13601,
        "title": "20Q: Overlap-Free World Knowledge Benchmark for Language Models",
        "authors": "Maxime De Bruyn, Ehsan Lotfi, Jeska Buhmann, Walter Daelemans",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gem-1.46"
    },
    {
        "id": 13602,
        "title": "COMMUNICATIVE MODELS IN THE PROCESS OF TEACHING BULGARIAN AS A FOREIGN LANGUAGE",
        "authors": "Reni Manova",
        "published": "2021-6-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7546/confibl2021.ii.46"
    },
    {
        "id": 13603,
        "title": "Articulatory postures and forward models in American Sign Language: Linguistic and neuroscience evidence",
        "authors": "David P. Corina",
        "published": "2021-12-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31009/feast.i4.05"
    },
    {
        "id": 13604,
        "title": "The Challenges of Existing Syntactic Models for English Language Teaching and Learning in Nigeria",
        "authors": "Roseline Abonego Adejare",
        "published": "2019-11-15",
        "citations": 0,
        "abstract": "A recent survey of existing syntactic models shows that none accurately describes the syntax of the English languagethat people actually use and that they inhibit rather than promote knowledge of natural language by creating a gapbetween what should be taught and learned and what obtains. To demonstrate this gap, this paper critically examinesfour recommended senior secondary school English course books to determine the extent to which they reflectexisting syntactic models’ descriptive inadequacies, and highlights the implications for language education inNigeria. Using the emerging Natural Language Linguistics (NLL) model as analytical tool, each book was carefullyexamined to identify topics on the syntactic units: sentence, clause and group. These were then critically studied,paying great attention to definitions, descriptive statements, models, and examples, and noting common features anddifferences. The bits of information pieced together constitute the data. Findings show inconsistency in modelapplication, no uniformity in, and consensus on, the number and nomenclature of syntactic units, terminologicalconfusion, descriptive inaccuracies, typological inexactness, incorrect definitions, wrong and inappropriate examples,and confusion between constituents and elements of structure. The absence of a clear-cut distinction between phraseand clause and between clause and sentence in existing syntactic models, which reflected in the books, explains theshortcomings that potentially limit learners’ knowledge and use ability. Only a syntactic model that accuratelymirrors natural language structure can positively promote language education in the Nigerian context where coursebooks are the most important English teaching-learning resource.",
        "link": "http://dx.doi.org/10.5430/ijelt.v7n1p1"
    },
    {
        "id": 13605,
        "title": "Navigating the Grey Area: How Expressions of Uncertainty and Overconfidence Affect Language Models",
        "authors": "Kaitlyn Zhou, Dan Jurafsky, Tatsunori Hashimoto",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.335"
    },
    {
        "id": 13606,
        "title": "Engineering and Studying Syngeneic Animal Tumors and Large Animal Endogenous Tumor Models",
        "authors": "K. Suganya, Sreya Babu, Indranil Chattopadhyay",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-3824-5_25"
    },
    {
        "id": 13607,
        "title": "Engineering and studying syngeneic animal tumors and Large animal endogenous tumor models",
        "authors": "K. Suganya, Sreya Babu, Indranil Chattopadhyay",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-1282-5_25-1"
    },
    {
        "id": 13608,
        "title": "Large Animal Models of Diabetes",
        "authors": "Barbara Ludwig, Eckhard Wolf, Uwe Schönmann, Stefan Ludwig",
        "published": "2020",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-0716-0385-7_9"
    },
    {
        "id": 13609,
        "title": "MaScQA: investigating materials science knowledge of large language models",
        "authors": "Mohd Zaki,  Jayadeva,  Mausam, N. M. Anoop Krishnan",
        "published": "2024",
        "citations": 0,
        "abstract": "Different materials science domains from which questions are present in Materials Science Question Answering (MaScQA) database.",
        "link": "http://dx.doi.org/10.1039/d3dd00188a"
    },
    {
        "id": 13610,
        "title": "Transductive Learning of Neural Language Models for Syntactic and Semantic Analysis",
        "authors": "Hiroki Ouchi, Jun Suzuki, Kentaro Inui",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-1379"
    },
    {
        "id": 13611,
        "title": "The language situation in the classroom and models of Bulgarian language learning in the initial stage",
        "authors": "Evgeniya Topolska,  ",
        "published": "2023-4-9",
        "citations": 0,
        "abstract": "The article analyzes the role of the language situation in the classroom for learning the Bulgarian language. The characteristics of a bilingual and multilingual classroom are indicated, which have a key role in planning and organizing the language learning. Various normative documents are presented, which provide support for a smooth transition to Bulgarian language learning at the primary stage for students with a different native /family language, and possibilities for implementing different models for language learning in a bilingual and multilingual classroom are discussed.",
        "link": "http://dx.doi.org/10.53656/bel2023-7-e"
    },
    {
        "id": 13612,
        "title": "Nonlinear Subgrid-Scale Models for Large-Eddy Simulation of Rotating Turbulent Flows",
        "authors": "M. H. Silvis, R. Verstappen",
        "published": "2019",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-04915-7_18"
    },
    {
        "id": 13613,
        "title": "The relational processing limits of classic and contemporary neural network models of language processing",
        "authors": "Guillermo Puebla, Andrea E. Martin, Leonidas A. A. Doumas",
        "published": "2021-2-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/23273798.2020.1821906"
    },
    {
        "id": 13614,
        "title": "Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference",
        "authors": "Eric Mitchell, Joseph Noh, Siyan Li, Will Armstrong, Ananth Agarwal, Patrick Liu, Chelsea Finn, Christopher Manning",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.115"
    },
    {
        "id": 13615,
        "title": "Pretrained Language Models for Sequential Sentence Classification",
        "authors": "Arman Cohan, Iz Beltagy, Daniel King, Bhavana Dalvi, Dan Weld",
        "published": "2019",
        "citations": 33,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-1383"
    },
    {
        "id": 13616,
        "title": "Alexander Haselow and Gunther Kaltenböck (eds.), Grammar and cognition – Dualistic models of language structure and language processing (Human Cognitive Processing – Cognitive Foundations of Language Structure and Use). Amsterdam and Philadelphia: John Benjamins, 2020. Pp. 358. ISBN 9789027207722.",
        "authors": "Arne Lohmann",
        "published": "2022-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/s1360674322000028"
    },
    {
        "id": 13617,
        "title": "Inventing and Reinventing the Cog: A Commentary on “Computational Modeling of Bilingual Language Learning: Current Models and Future Directions”",
        "authors": "Ton Dijkstra, Walter J. B. van Heuven",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/lang.12532"
    },
    {
        "id": 13618,
        "title": "Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step in Natural Language Understanding",
        "authors": "Caoyun Fan, Jidong Tian, Yitian Li, Wenqing Chen, Hao He, Yaohui Jin",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.913"
    },
    {
        "id": 13619,
        "title": "Exploring neural models for predicting dementia from language",
        "authors": "Weirui Kong, Hyeju Jang, Giuseppe Carenini, Thalia S. Field",
        "published": "2021-7",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2020.101181"
    },
    {
        "id": 13620,
        "title": "Mask-Predict: Parallel Decoding of Conditional Masked Language Models",
        "authors": "Marjan Ghazvininejad, Omer Levy, Yinhan Liu, Luke Zettlemoyer",
        "published": "2019",
        "citations": 110,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-1633"
    },
    {
        "id": 13621,
        "title": "Natural Language Processing Applied on Large Scale Data Extraction from Scientific Papers in Fuel Cells",
        "authors": "Feifan Yang",
        "published": "2021-12-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3508230.3508256"
    },
    {
        "id": 13622,
        "title": "Speciesist language and nonhuman animal bias in English Masked Language Models",
        "authors": "Masashi Takeshita, Rafal Rzepka, Kenji Araki",
        "published": "2022-9",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ipm.2022.103050"
    },
    {
        "id": 13623,
        "title": "Influence of Language Proficiency on the Readability of Review Text and Transformer-based Models for Determining Language Proficiency",
        "authors": "Salim Sazzed",
        "published": "2022-4-25",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3487553.3524666"
    },
    {
        "id": 13624,
        "title": "Incorporating pass-phrase dependent background models for text-dependent speaker verification",
        "authors": "Achintya Kumar Sarkar, Zheng-Hua Tan",
        "published": "2018-1",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2017.07.010"
    },
    {
        "id": 13625,
        "title": "ASU at TextGraphs 2019 Shared Task: Explanation ReGeneration using Language Models and Iterative Re-Ranking",
        "authors": "Pratyay Banerjee",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-5310"
    },
    {
        "id": 13626,
        "title": "Sustained Linguistic Inquiry as a Means of Confronting Language Ideology and Prejudice",
        "authors": "Kristin Denham, David Pippin",
        "published": "2019-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678-24"
    },
    {
        "id": 13627,
        "title": "KnowLab at RadSum23: comparing pre-trained language models in radiology report summarization",
        "authors": "Jinge Wu, Daqian Shi, Abul Hasan, Honghan Wu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bionlp-1.54"
    },
    {
        "id": 13628,
        "title": "Are representations built from the ground up? An empirical examination of local composition in language models",
        "authors": "Emmy Liu, Graham Neubig",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.617"
    },
    {
        "id": 13629,
        "title": "Incorporating Medical Knowledge to Transformer-based Language Models for Medical Dialogue Generation",
        "authors": "Usman Naseem, Ajay Bandi, Shaina Raza, Junaid Rashid, Bharathi Raja Chakravarthi",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bionlp-1.10"
    },
    {
        "id": 13630,
        "title": "A comparison of holistic, analytic, and part marking models in speaking assessment",
        "authors": "Nahal Khabbazbashi, Evelina D. Galaczi",
        "published": "2020-7",
        "citations": 8,
        "abstract": "This mixed methods study examined holistic, analytic, and part marking models (MMs) in terms of their measurement properties and impact on candidate CEFR classifications in a semi-direct online speaking test. Speaking performances of 240 candidates were first marked holistically and by part (phase 1). On the basis of phase 1 findings—which suggested stronger measurement properties for the part MM—phase 2 focused on a comparison of part and analytic MMs. Speaking performances of 400 candidates were rated analytically and by part during that phase. Raters provided open comments on their marking experiences.Results suggested a significant impact of MM; approximately 30% and 50% of candidates in phases 1 and 2 respectively were awarded different (adjacent) CEFR levels depending on the choice of MM used to assign scores. There was a trend of higher CEFR levels with the holistic MM and lower CEFR levels with the part MM. Although strong correlations were found between all pairings of MMs, further analyses revealed important differences. The part MM was shown to display superior measurement qualities particularly in allowing raters to make finer distinctions between different speaking ability levels. These findings have implications for the scoring validity of speaking tests.",
        "link": "http://dx.doi.org/10.1177/0265532219898635"
    },
    {
        "id": 13631,
        "title": "Discourse Probing of Pretrained Language Models",
        "authors": "Fajri Koto, Jey Han Lau, Timothy Baldwin",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.301"
    },
    {
        "id": 13632,
        "title": "Effects of sub-word segmentation on performance of transformer language models",
        "authors": "Jue Hou, Anisia Katinskaia, Anh-Duc Vu, Roman Yangarber",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.459"
    },
    {
        "id": 13633,
        "title": "LIMIT: Language Identification, Misidentification, and Translation using Hierarchical Models in 350+ Languages",
        "authors": "Milind Agarwal, Md Mahfuz Ibn Alam, Antonios Anastasopoulos",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.895"
    },
    {
        "id": 13634,
        "title": "Functional connectivity between parietal and temporal lobes mediates internal forward models during speech production",
        "authors": "Wenjia Zhang, Fuyin Yang, Xing Tian",
        "published": "2023-5",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.bandl.2023.105266"
    },
    {
        "id": 13635,
        "title": "On Extractive and Abstractive Neural Document Summarization with Transformer Language Models",
        "authors": "Jonathan Pilault, Raymond Li, Sandeep Subramanian, Chris Pal",
        "published": "2020",
        "citations": 28,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.748"
    },
    {
        "id": 13636,
        "title": "Federico Garlanda’s <i>The Philosophy of Words</i> (1886) and <i>The Fortunes of Language</i> (1887): models in their class",
        "authors": "Joseph L. Subbiondo",
        "published": "2017-9-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/17597536.2018.1484017"
    },
    {
        "id": 13637,
        "title": "Hierarchical Coordinate Structure Analysis for Japanese Statutory Sentences Using Neural Language Models",
        "authors": "Takahiro Yamakoshi, Tomohiro Ohno, Yasuhiro Ogawa, Makoto Nakamura, Katsuhiko Toyama",
        "published": "2018-9-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.25.393"
    },
    {
        "id": 13638,
        "title": "State Monitoring and Fault Diagnosis System for Large Road Maintenance Machinery",
        "authors": "",
        "published": "2021-11-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i11.177"
    },
    {
        "id": 13639,
        "title": "Construction Technology of Special-shaped Curtain Wall in Large Public Buildings",
        "authors": "",
        "published": "2022-6-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i6(02).04"
    },
    {
        "id": 13640,
        "title": "Application of Automatic Monitoring in Emergency Relief of Sudden Large Landslide",
        "authors": "",
        "published": "2022-4-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/ns.v3i4(01).11"
    },
    {
        "id": 13641,
        "title": "Emotion-injecting prompt for large language model chatbot",
        "authors": "Seiji Muranaka, Takayuki Fukatsu, Yoshitake Takebayashi, Masashi Kunugi, Shun Nakajima, Ryuhei So",
        "published": "No Date",
        "citations": 0,
        "abstract": "This paper introduces a new use of large Language Models (LMs) that provide an emotional feedback experience while chatting. The proposed prompt creates a chatbot that infers emotional experiences, evaluates emotional parameters, and then replies to users considering these parameters. This prompted chatbot can help construct an environment in which we train emotional conversation such as customer service, especially in the situation dealing with difficult customer.",
        "link": "http://dx.doi.org/10.31234/osf.io/u5dft"
    },
    {
        "id": 13642,
        "title": "Author response: Large-scale language analysis of peer review reports",
        "authors": "Ivan Buljan, Daniel Garcia-Costa, Francisco Grimaldo, Flaminio Squazzoni, Ana Marušić",
        "published": "2020-5-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.53249.sa2"
    },
    {
        "id": 13643,
        "title": "Models of Language Learning",
        "authors": "",
        "published": "2022-9-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009064880.015"
    },
    {
        "id": 13644,
        "title": "When Geometric Deep Learning Meets Pretrained Protein Language Models",
        "authors": "Fang Wu, Jinbo Xu, Dragomir Radev, Yu Tao",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nGeometric deep learning has recently achieved great success in non-Euclidean domains, and learning on 3D structures of large biomolecules is emerging as a distinct research area. However, its efficacy is largely constrained due to the limited quantity of structural data. Meanwhile, protein language models trained on substantial 1D sequences have shown burgeoning capabilities with scale in a broad range of applications. Nevertheless, no preceding studies consider combining these different protein modalities to promote the representation power of geometric neural networks. To address this gap, we make the foremost step to integrate the knowledge learned by well-trained protein language models into several state-of-the-art geometric networks. Experiments are evaluated on a variety of protein representation learning benchmarks, including protein-protein interface prediction, model quality assessment, protein-protein rigid-body docking, and binding affinity prediction, leading to an overall improvement of 20\\% over baselines and the new state-of-the-art performance. \nStrong evidence indicates that the incorporation of protein language models' knowledge enhances geometric networks' capacity by a significant margin and can be generalized to complex tasks.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2469268/v1"
    },
    {
        "id": 13645,
        "title": "On the effectiveness of small, discriminatively pre-trained language representation models for biomedical text mining",
        "authors": "Ibrahim Burak Ozyurt",
        "published": "No Date",
        "citations": 2,
        "abstract": "AbstractNeural language representation models such as BERT [1] have recently shown state of the art performance in downstream NLP tasks and bio-medical domain adaptation of BERT (Bio-BERT [2]) has shown same behavior on biomedical text mining tasks. However, due to their large model size and resulting increased computational need, practical application of models such as BERT is challenging making smaller models with comparable performance desirable for real word applications. Recently, a new language transformers based language representation model named ELECTRA [3] is introduced, that makes efficient usage of training data in a generative-discriminative neural model setting that shows performance gains over BERT. These gains are especially impressive for smaller models. Here, we introduce a small ELECTRA based model named Bio-ELECTRA that is eight times smaller than BERT BASE and achieves comparable performance on biomedical question answering and yes/no question answer classification tasks. The model is pre-trained from scratch on PubMed abstracts using a consumer grade GPU with only 8GB memory. For biomedical named entity recognition, however, large BERT Base model outperforms both Bio-ELECTRA and ELECTRA-Small++.",
        "link": "http://dx.doi.org/10.1101/2020.05.20.107003"
    },
    {
        "id": 13646,
        "title": "Improved inter-protein contact prediction using dimensional hybrid residual networks and protein language models",
        "authors": "Yunda Si, Chengfei Yan",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractThe knowledge of contacting residue pairs between interacting proteins is very useful for structural characterization of protein-protein interactions (PPIs). However, accurately identifying the tens of contacting ones from hundreds of thousands of inter-protein residue pairs is extremely challenging, and performances of the state-of-the-art inter-protein contact prediction methods are still quite limited. In this study, we developed a deep learning method for inter-protein contact prediction, referred to as DRN-1D2D_Inter. Specifically, we employed pretrained protein language models to generate structural information enriched input features to residual networks formed by dimensional hybrid residual blocks to perform inter-protein contact prediction. Extensively benchmarked DRN-1D2D_Inter on multiple datasets including both heteromeric PPIs and homomeric PPIs, we show DRN-1D2D_Inter consistently and significantly outperformed two state-of-the-art inter-protein contact prediction methods including GLINTER and DeepHomo, although both the latter two methods leveraged native structures of interacting proteins in the prediction, and DRN-1D2D_Inter made the prediction purely from sequences.",
        "link": "http://dx.doi.org/10.1101/2022.08.04.502748"
    },
    {
        "id": 13647,
        "title": "Proofs by Deduction",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_0003"
    },
    {
        "id": 13648,
        "title": "Weakly Supervised Training of Speaker Identification Models",
        "authors": "Martin Karu, Tanel Alumäe",
        "published": "2018-6-26",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/odyssey.2018-4"
    },
    {
        "id": 13649,
        "title": "Protein language models are biased by unequal sequence sampling across the tree of life",
        "authors": "Frances Ding, Jacob Steinhardt",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractProtein language models (pLMs) trained on large protein sequence databases have been used to understand disease and design novel proteins. In design tasks, the likelihood of a protein sequence under a pLM is often used as a proxy for protein fitness, so it is critical to understand what signals likelihoods capture. In this work we find that pLM likelihoods unintentionally encode a species bias: likelihoods of protein sequences from certain species are systematically higher, independent of the protein in question. We quantify this bias and show that it arises in large part because of unequal species representation in popular protein sequence databases. We further show that the bias can be detrimental for some protein design applications, such as enhancing thermostability. These results highlight the importance of understanding and curating pLM training data to mitigate biases and improve protein design capabilities in under-explored parts of sequence space.",
        "link": "http://dx.doi.org/10.1101/2024.03.07.584001"
    },
    {
        "id": 13650,
        "title": "RARR: Researching and Revising What Language Models Say, Using Language Models",
        "authors": "Luyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony Chen, Arun Tejasvi Chaganty, Yicheng Fan, Vincent Zhao, Ni Lao, Hongrae Lee, Da-Cheng Juan, Kelvin Guu",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.910"
    },
    {
        "id": 13651,
        "title": "Vocal Learning and Spoken Language: Insights from Animal Models with an Emphasis on Genetic Contributions",
        "authors": "Constance Scharff, Mirjam Knörnschild, Erich D. Jarvis",
        "published": "2019-10-29",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7551/mitpress/10841.003.0055"
    },
    {
        "id": 13652,
        "title": "“Average” Approximates “First Principal Component”? An Empirical Analysis on Representations from Neural Language Models",
        "authors": "Zihan Wang, Chengyu Dong, Jingbo Shang",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.453"
    },
    {
        "id": 13653,
        "title": "Meta Fine-Tuning Neural Language Models for Multi-Domain Text Mining",
        "authors": "Chengyu Wang, Minghui Qiu, Jun Huang, Xiaofeng He",
        "published": "2020",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.250"
    },
    {
        "id": 13654,
        "title": "Evaluating Bias and Fairness in Gender-Neutral Pretrained Vision-and-Language Models",
        "authors": "Laura Cabello, Emanuele Bugliarello, Stephanie Brandl, Desmond Elliott",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.525"
    },
    {
        "id": 13655,
        "title": "Can Language Models Understand Physical Concepts?",
        "authors": "Lei Li, Jingjing Xu, Qingxiu Dong, Ce Zheng, Xu Sun, Lingpeng Kong, Qi Liu",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.726"
    },
    {
        "id": 13656,
        "title": "BERTabaporu: Assessing a Genre-specific Language Model for Portuguese NLP",
        "authors": "Pablo da Costa,  , Matheus Pavan, Wesley dos Santos, Samuel da Silva, Ivandré Paraboni,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_024"
    },
    {
        "id": 13657,
        "title": "Applicability of Pretrained Language Models: Automatic Screening for Children’s Language Development Level",
        "authors": "Byoung-doo Oh, Yoon-koung Lee, Yu-seop Kim",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.nlp4pi-1.18"
    },
    {
        "id": 13658,
        "title": "Assessing the Linguistic Knowledge in Arabic Pre-trained Language Models Using Minimal Pairs",
        "authors": "Wafa Abdullah Alrajhi, Hend Al-Khalifa, Abdulmalik AlSalman",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.wanlp-1.17"
    },
    {
        "id": 13659,
        "title": "Can language models learn analogical reasoning? Investigating training objectives and comparisons to human performance",
        "authors": "Molly Petersen, Lonneke van der Plas",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.1022"
    },
    {
        "id": 13660,
        "title": "Understanding the Inner-workings of Language Models Through Representation Dissimilarity",
        "authors": "Davis Brown, Charles Godfrey, Nicholas Konz, Jonathan Tu, Henry Kvinge",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.403"
    },
    {
        "id": 13661,
        "title": "Context-Free Grammars",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_0010"
    },
    {
        "id": 13662,
        "title": "Generating Regular Languages",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_0008"
    },
    {
        "id": 13663,
        "title": "Models of Language Learning",
        "authors": "",
        "published": "2019-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108339216.012"
    },
    {
        "id": 13664,
        "title": "XIV. Linguistic Relativity: The Views of Benjamin Lee Whorf",
        "authors": "",
        "published": "2019-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7591/9781501741326-015"
    },
    {
        "id": 13665,
        "title": "Context-Free Grammars",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_0010"
    },
    {
        "id": 13666,
        "title": "AUTOMATIC CONSTRUCTION OF SYNTACTIC LANGUAGE MODELS FOR TEXT PROCESSING SYSTEMS",
        "authors": "",
        "published": "2018-12-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14357/08696527180401"
    },
    {
        "id": 13667,
        "title": "Evaluating Pre-trained BERT-based Language Models for Detecting Misinformation",
        "authors": "Rini Anggrainingsih, Ghulam Mubashar Hassan, Amitava Datta",
        "published": "No Date",
        "citations": 2,
        "abstract": "Abstract\nIt is challenging to control the quality of online information due to the lack of supervision. Manual checking is almost impossible given the vast number of posts made on online media and how quickly they spread. Therefore, there is a need for automated rumour detection techniques to limit the adverse effects of spreading misinformation. Previous studies mainly focused on finding and extracting the significant features of text data. However, extracting features is time-consuming and not a highly effective process. This study proposes the BERT-based pre-trained language models to encode text data into vectors and utilise neural network models to classify these vectors to detect misinformation. Furthermore, different language models (LM) ’ performance with different trainable parameters was compared. The proposed technique is tested on different short and long text datasets. The result of the proposed technique has been compared with the state-of-the-art methods on the same datasets. The results show that the proposed technique performs better than the state-of-the-art techniques. We also tested the proposed technique by combining the datasets. The results demonstrated that the large training and testing size of data considerably improves the technique’s performance. Therefore, it is suggested that the dataset, splitting data, and classification techniques must be considered carefully to analyse performance of the solutions.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1608574/v1"
    },
    {
        "id": 13668,
        "title": "Matching Pre-Trained Language Models with Specific Tasks: Fine-Tuning and Prompt-Tuning Strategies",
        "authors": "Ahmad Pouramini, Hesham Faili",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4702919"
    },
    {
        "id": 13669,
        "title": "Investigation on LSTM Recurrent N-gram Language Models for Speech Recognition",
        "authors": "Zoltán Tüske, Ralf Schlüter, Hermann Ney",
        "published": "2018-9-2",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2018-2476"
    },
    {
        "id": 13670,
        "title": "Reviewer #2 (Public Review): Sensitive remote homology search by local alignment of small positional embeddings from protein language models",
        "authors": "",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.91415.1.sa0"
    },
    {
        "id": 13671,
        "title": "Enhancing Language Models: The Role of Knowledge Graph Augmentation in Overcoming LLM Challenges",
        "authors": " ",
        "published": "No Date",
        "citations": 0,
        "abstract": "<strong> Author: </strong> Vaibhav Khobragade (0009–0009–8807–5982) <strong> Introduction </strong> Large language models (LLMs) are becoming increasingly popular in natural language processing for their superior competence in various applications.",
        "link": "http://dx.doi.org/10.59350/jp8jc-31729"
    },
    {
        "id": 13672,
        "title": "Temporal Attention for Language Models",
        "authors": "Guy D. Rosin, Kira Radinsky",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-naacl.112"
    },
    {
        "id": 13673,
        "title": "Reviewer #1 (Public Review): Sensitive remote homology search by local alignment of small positional embeddings from protein language models",
        "authors": "",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.91415.3.sa1"
    },
    {
        "id": 13674,
        "title": "Transformer-based Language Models for Semantic Search and Mobile Applications Retrieval",
        "authors": "João Coelho, António Neto, Miguel Tavares, Carlos Coutinho, João Oliveira, Ricardo Ribeiro, Fernando Batista",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010657300003064"
    },
    {
        "id": 13675,
        "title": "Some Notes on Floating Quantifiers",
        "authors": "Genoveva Puskás",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5_5"
    },
    {
        "id": 13676,
        "title": "Prediction as a Basis for Skilled Reading: Insights from Modern Language Models",
        "authors": "Benedetta Cevoli, Chris Watkins, Kathleen Rastle",
        "published": "No Date",
        "citations": 0,
        "abstract": "Reading is not an inborn human capability, and yet, English-speaking adults read with impressive speed. This study considered how predictions of upcoming words impact on this skilled behaviour. We used a powerful language model (GPT-2) to derive predictions of upcoming words in text passages. These predictions were highly accurate, and showed a tight relationship to fine-grained aspects of eye-movement behaviour when adults read those same passages, including whether to skip the next word and how long to spend on it. Strong predictions that did not materialise resulted in a prediction error cost on fixation durations. Our findings suggest that predictions for upcoming words can be made based on the analysis of text statistics, and that these predictions guide how our eyes interrogate text at very short timescales. These findings open new perspectives on reading and language comprehension more broadly, and illustrate the capability of modern language models to inform understanding of human language processing.",
        "link": "http://dx.doi.org/10.31234/osf.io/urjh4"
    },
    {
        "id": 13677,
        "title": "The Peer-Effect: Non-Traditional Models of Instruction in Spanish as a Heritage Language",
        "authors": "Lina M. Reznicek-Parrado",
        "published": "2023-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003191179"
    },
    {
        "id": 13678,
        "title": "Updating Event Models",
        "authors": "",
        "published": "2020-2-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1163/9789004395169_008"
    },
    {
        "id": 13679,
        "title": "Maximum Entropy Models for Natural Language Processing",
        "authors": "Adwait Ratnaparkhi",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_525"
    },
    {
        "id": 13680,
        "title": "Blended Course Development and Design Models",
        "authors": "Hope M. Anderson",
        "published": "2018-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780203702468-6"
    },
    {
        "id": 13681,
        "title": "Proofs by Deduction",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_0003"
    },
    {
        "id": 13682,
        "title": "Sampling Informative Training Data for RNN Language Models",
        "authors": "Jared Fernandez, Doug Downey",
        "published": "2018",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/p18-3002"
    },
    {
        "id": 13683,
        "title": "Proving with Predicates",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_0005"
    },
    {
        "id": 13684,
        "title": "Protein language models trained on multiple sequence alignments learn phylogenetic relationships",
        "authors": "Umberto Lupo, Damiano Sgarbossa, Anne-Florence Bitbol",
        "published": "No Date",
        "citations": 2,
        "abstract": "AbstractSelf-supervised neural language models with attention have recently been applied to biological sequence data, advancing structure, function and mutational effect prediction. Some protein language models, including MSA Transformer and AlphaFold’s EvoFormer, take multiple sequence alignments (MSAs) of evolutionarily related proteins as inputs. Simple combinations of MSA Transformer’s row attentions have led to state-of-the-art unsupervised structural contact prediction. We demonstrate that similarly simple, and universal, combinations of MSA Transformer’s column attentions strongly correlate with Hamming distances between sequences in MSAs. There-fore, MSA-based language models encode detailed phylogenetic relationships. We further show that these models can separate coevolutionary signals encoding functional and structural constraints from phylogenetic correlations reflecting historical contingency. To assess this, we generate synthetic MSAs, either without or with phylogeny, from Potts models trained on natural MSAs. We find that unsupervised contact prediction is substantially more resilient to phylogenetic noise when using MSA Transformer versus inferred Potts models.",
        "link": "http://dx.doi.org/10.1101/2022.03.29.486219"
    },
    {
        "id": 13685,
        "title": "A Natural Language Processing Model Based on Pre-trained Deep Learning Models",
        "authors": "Yitong Niu",
        "published": "2023-1-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.57237/j.cst.2022.01.007"
    },
    {
        "id": 13686,
        "title": "Evaluating the representational power of pre-trained DNA language models for regulatory genomics",
        "authors": "Ziqi Tang, Peter K Koo",
        "published": "No Date",
        "citations": 0,
        "abstract": "ABSTRACTThe emergence of genomic language models (gLMs) offers an unsupervised approach to learn a wide diversity ofcis-regulatory patterns in the non-coding genome without requiring labels of functional activity generated by wet-lab experiments. Previous evaluations have shown pre-trained gLMs can be leveraged to improve prediction performance across a broad range of regulatory genomics tasks, albeit using relatively simple benchmark datasets and baseline models. Since the gLMs in these studies were tested upon fine-tuning their weights for each downstream task, determining whether gLM representations embody a foundational understanding ofcis-regulatory biology remains an open question. Here we evaluate the representational power of pre-trained gLMs to predict and interpret cell-type-specific functional genomics data that span DNA and RNA regulation. Our findings suggest that current gLMs do not offer substantial advantages over conventional machine learning approaches that use one-hot encoded sequences. This work highlights a major limitation with current gLMs, raising potential issues in conventional pre-training strategies for the non-coding genome.",
        "link": "http://dx.doi.org/10.1101/2024.02.29.582810"
    },
    {
        "id": 13687,
        "title": "Reviewer #1 (Public Review): Sensitive remote homology search by local alignment of small positional embeddings from protein language models",
        "authors": "",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.91415.1.sa1"
    },
    {
        "id": 13688,
        "title": "Understanding Learning Dynamics Of Language Models with",
        "authors": "Naomi Saphra, Adam Lopez",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/n19-1329"
    },
    {
        "id": 13689,
        "title": "Chapter 3. Language activity in the light of cerebral hemisphere differences",
        "authors": "Alexander Guryev, François Delafontaine",
        "published": "2020-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/hcp.70.03gur"
    },
    {
        "id": 13690,
        "title": "Analysis of the Key Technology of Large-area Concrete Ground Construction",
        "authors": "",
        "published": "2022-2-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i2.338"
    },
    {
        "id": 13691,
        "title": "Research on Manufacturing Technology of Welding Box of A Large Reducer",
        "authors": "",
        "published": "2022-2-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i2.198"
    },
    {
        "id": 13692,
        "title": "Summary of Radiographic Inspection of Large Nuclear Power Casting Pump Case",
        "authors": "",
        "published": "2020-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v1i2.48"
    },
    {
        "id": 13693,
        "title": "Models for Differentiating Instruction in English Language Arts - Literature",
        "authors": "Tamra Stambaugh, Emily Mofield",
        "published": "2022-3-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003238515-3"
    },
    {
        "id": 13694,
        "title": "Analysis on HVAC Design and Energy Saving of Large Space Buildings",
        "authors": "",
        "published": "2022-4-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i4(07).17"
    },
    {
        "id": 13695,
        "title": "Analysis of Cost Control of Dry Desulfurization for Large CFB Boilers",
        "authors": "",
        "published": "2022-7-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i7(02).34"
    },
    {
        "id": 13696,
        "title": "Out-of-core outlier removal for large-scale indoor point clouds",
        "authors": "Linlin Ge, Jieqing Feng",
        "published": "2022-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.gmod.2022.101142"
    },
    {
        "id": 13697,
        "title": "THE IMPORTANCE OF LINGUISTIC MODELS IN THE DEVELOPMENT OF LANGUAGE BASES GE BASE",
        "authors": "Guli Ibragimovna Toirova,  ",
        "published": "2020-12-29",
        "citations": 0,
        "abstract": "Relevance. In Uzbek linguistics, a number of studies have been carried out on automatic translation, the development of the linguistic foundations of the author's corpus, the processing of lexicographic texts and linguistic-statistical analysis. However, the processing of the Uzbek language as the language of the Internet: spelling, automatic processing and translation programs, search programs for various characters, text generation, the linguistic basis of the text corpus and national corpus, the technology of its software is not studied in any monograph. The article discusses such problems as: the transformation of language into the language of the Internet, computer technology, mathematical linguistics, its continuation and the formation and development of computer linguistics, in particular the question of modeling natural languages for artificial intelligence. The Uzbek National Corps plays an important role in enhancing the international status of the Uzbek language.",
        "link": "http://dx.doi.org/10.52297/2181-1466/2020/4/6/8"
    },
    {
        "id": 13698,
        "title": "A comparison of language-dependent and language-independent models for violence prediction",
        "authors": "Ben Greenawald, Yingjie Liu, Gregory Wert, Mohammad Al Boni, Donald E. Brown",
        "published": "2018-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/sieds.2018.8374748"
    },
    {
        "id": 13699,
        "title": "Towards Task-Agnostic Privacy- And Utility-Preserving Models",
        "authors": "Yaroslav Emelyanov,  ",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-072-4_045"
    },
    {
        "id": 13700,
        "title": "On the Strength of Character Language Models for Multilingual Named Entity Recognition",
        "authors": "Xiaodong Yu, Stephen Mayhew, Mark Sammons, Dan Roth",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d18-1345"
    },
    {
        "id": 13701,
        "title": "Analysis of the Key Technology of Large-area Concrete Ground Construction",
        "authors": "",
        "published": "2022-2-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i2.338"
    },
    {
        "id": 13702,
        "title": "Research on Manufacturing Technology of Welding Box of A Large Reducer",
        "authors": "",
        "published": "2022-2-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i2.198"
    },
    {
        "id": 13703,
        "title": "Summary of Radiographic Inspection of Large Nuclear Power Casting Pump Case",
        "authors": "",
        "published": "2020-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v1i2.48"
    },
    {
        "id": 13704,
        "title": "CAN STATISTICAL LANGUAGE MODELS BE USED TO DISTINGUISH BETWEEN DIFFERENT GENRES OF NEWS",
        "authors": "S Dreibe, G Hunter",
        "published": "2020-11-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.25144/13349"
    },
    {
        "id": 13705,
        "title": "Is ATIS Too Shallow to Go Deeper for Benchmarking Spoken Language Understanding Models?",
        "authors": "Frédéric Béchet, Christian Raymond",
        "published": "2018-9-2",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2018-2256"
    },
    {
        "id": 13706,
        "title": "Neural Error Corrective Language Models for Automatic Speech Recognition",
        "authors": "Tomohiro Tanaka, Ryo Masumura, Hirokazu Masataki, Yushi Aono",
        "published": "2018-9-2",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2018-1430"
    },
    {
        "id": 13707,
        "title": "Exploiting protein language models for the precise classification of ion channels and ion transporters",
        "authors": "Hamed Ghazikhani, Gregory Butler",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractThis study presents TooT-PLM-ionCT, a composite framework consisting of three distinct systems, each with different architectures and trained on unique datasets. Each system within TooT-PLM-ionCT is dedicated to a specific task: segregating ion channels (ICs) and ion transporters (ITs) from other membrane proteins and differentiating ICs from ITs. These systems exploit the capabilities of six diverse Protein Language Models (PLMs) - ProtBERT, ProtBERT-BFD, ESM-1b, ESM-2 (650M parameters), and ESM-2 (15B parameters). As these proteins play a pivotal role in the regulation of ion movement across cellular membranes, they are integral to numerous biological processes and overall cellular vitality. To circumvent the costly and time-consuming nature of wet lab experiments, we harness the predictive prowess of PLMs, drawing parallels with techniques in natural language processing. Our strategy engages six classifiers, embracing both conventional methodologies and a deep learning model, for each of our defined tasks. Furthermore, we delve into critical factors influencing our tasks, including the implications of dataset balancing, the effect of frozen versus fine-tuned PLM representations, and the potential variance between half and full precision floating-point computations. Our empirical results showcase superior performance in distinguishing ITs from other membrane proteins and differentiating ICs from ITs, while the task of discriminating ICs from other membrane proteins exhibits results commensurate with the current state-of-the-art.Author summaryIn our research, we have designed TooT-PLM-ionCT, a composite framework composed of three unique systems, each tailored to a specific protein classification task and trained on different datasets. This framework is our tool for categorizing integral membrane proteins, specifically ion channels and ion transporters. These proteins are essential to the health of cells, as they manage ion movement across cell membranes. To bypass the high costs and long timelines of conventional lab experiments, we have turned to advanced computation methods akin to how computers process human language. Our three-pronged approach harnesses six top-tier Protein Language Models and a range of classifiers to discern between these key proteins. In doing so, we also evaluated the effects of various conditions, like dataset balance, representation methods, and levels of computation precision, on the accuracy of our classification tasks. The outcomes show our framework effectively identifies ion transporters, sets them apart from ion channels, and distinguishes ion channels on par with existing top-notch techniques. The performance, however, can vary based on the task, suggesting that customizing the approach for each task could be beneficial. In the future, we plan to expand the depth and breadth of our protein study by incorporating additional knowledge sources, utilizing more refined representation methods, and testing our framework on larger and diverse protein datasets. This progress sets us on a path to better understand proteins and their roles in cellular health.",
        "link": "http://dx.doi.org/10.1101/2023.07.11.548644"
    },
    {
        "id": 13708,
        "title": "Exploiting Protein Language Models for the Precise Classification of Ion Channels and Ion Transporters",
        "authors": "Hamed Ghazikhani, Gregory Butler",
        "published": "No Date",
        "citations": 0,
        "abstract": "This study presents TooT-PLM-ionCT, a holistic framework that exploits\nthe capabilities of six diverse Protein Language Models (PLMs) -\nProtBERT, ProtBERT-BFD, ESM-1b, ESM-2 (650M parameters), and ESM-2 (15B\nparameters) - for precise classification of integral membrane proteins,\nspecifically ion channels (ICs) and ion transporters (ITs). As these\nproteins play a pivotal role in the regulation of ion movement across\ncellular membranes, they are integral to numerous biological processes\nand overall cellular vitality. To circumvent the costly and\ntime-consuming nature of wet lab experiments, we harness the predictive\nprowess of PLMs, drawing parallels with techniques in natural language\nprocessing. Our strategy engages six classifiers, embracing both\nconventional methodologies and a deep learning model, to segregate ICs\nand ITs from other membrane proteins, as well as differentiate ICs from\nITs. Furthermore, we delve into critical factors influencing our tasks,\nincluding the implications of dataset balancing, the effect of frozen\nversus fine-tuned PLM representations, and the potential variance\nbetween half and full precision floating-point computations. Our\nempirical results showcase superior performance in distinguishing ITs\nfrom other membrane proteins and differentiating ICs from ITs, while the\ntask of discriminating ICs from other membrane proteins exhibits results\ncommensurate with the current state-of-the-art.",
        "link": "http://dx.doi.org/10.22541/au.169356662.23073962/v1"
    },
    {
        "id": 13709,
        "title": "UTILIZATION OF LANGUAGE MODELS IN HIGHER EDUCATION: STUDENT PERSPECTIVES AND PRACTICES",
        "authors": "Lukáš Herout",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21125/iceri.2023.2068"
    },
    {
        "id": 13710,
        "title": "Massive Data Language Models and Conversational AI: Emerging Issues",
        "authors": "Daniel E. O'Leary",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4281926"
    },
    {
        "id": 13711,
        "title": "Proofs with Predicates",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_0005"
    },
    {
        "id": 13712,
        "title": "Improving protein secondary structure prediction by deep language models and transformer networks",
        "authors": "Tianqi Wu, Weihang Cheng, Jianlin Cheng",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractProtein secondary structure prediction is useful for many applications. It can be considered a language translation problem, i.e., translating a sequence of 20 different amino acids into a sequence of secondary structure symbols (e.g., alpha helix, beta strand, and coil). Here, we develop a novel protein secondary structure predictor called TransPross based on the transformer network and attention mechanism widely used in natural language processing to directly extract the evolutionary information from the protein language (i.e., raw multiple sequence alignment (MSA) of a protein) to predict the secondary structure. The method is different from traditional methods that first generate a MSA and then calculate expert-curated statistical profiles from the MSA as input. The attention mechnism used by TransPross can effectively capture long-range residue-residue interactions in protein sequences to predict secondary structures. Benchmarked on several datasets, TransPross outperforms the state-of-art methods. Moreover, our experiment shows that the prediction accuracy of TransPross positively correlates with the depth of MSAs and it is able to achieve the average prediction accuracy (i.e., Q3 score) above 80% for hard targets with few homologous sequences in their MSAs. TransPross is freely available athttps://github.com/BioinfoMachineLearning/TransPro",
        "link": "http://dx.doi.org/10.1101/2022.11.21.517442"
    },
    {
        "id": 13713,
        "title": "On the N-gram Approximation of Pre-trained Language Models",
        "authors": "Aravind Krishnan, Jesujoba O. Alabi, Dietrich Klakow",
        "published": "2023-8-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-2182"
    },
    {
        "id": 13714,
        "title": "Geo P. Tech, AI Chatbot Geotechnical Engineer",
        "authors": "Brett Maurer",
        "published": "No Date",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31224/2858"
    },
    {
        "id": 13715,
        "title": "Enhancing Attention Models via Multi-head Collaboration",
        "authors": "Huadong Wang, Mei Tu",
        "published": "2020-12-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ialp51396.2020.9310460"
    },
    {
        "id": 13716,
        "title": "Reviewer #1 (Public Review): Sensitive remote homology search by local alignment of small positional embeddings from protein language models",
        "authors": "",
        "published": "2024-2-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.91415.2.sa0"
    },
    {
        "id": 13717,
        "title": "Irony, Hyperbole, Jokes and Banter",
        "authors": "Deirdre Wilson",
        "published": "2017",
        "citations": 17,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5_11"
    },
    {
        "id": 13718,
        "title": "Effectively Building Tera Scale MaxEnt Language Models Incorporating Non-Linguistic Signals",
        "authors": "Fadi Biadsy, Mohammadreza Ghodsi, Diamantino Caseiro",
        "published": "2017-8-20",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2017-1203"
    },
    {
        "id": 13719,
        "title": "Models for Differentiating Instruction in English Language Arts - Literature",
        "authors": "Tamra Stambaugh, Emily Mofield",
        "published": "2022-3-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003238515-3"
    },
    {
        "id": 13720,
        "title": "Large language model for molecular chemistry",
        "authors": "Jie Pan",
        "published": "2023-1-23",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s43588-023-00399-1"
    },
    {
        "id": 13721,
        "title": "Research on Online Evaluation of College Physics Performance in Large Classes",
        "authors": "",
        "published": "2022-6-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/es.v3i6(02).03"
    },
    {
        "id": 13722,
        "title": "Discussion on Key Technologies of Metro Line Planning in Large Cities",
        "authors": "",
        "published": "2021-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i12.131"
    },
    {
        "id": 13723,
        "title": "Thus Spoke GPT-3: Interviewing a Large-Language Model on Climate Finance",
        "authors": "Markus Leippold",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4237242"
    },
    {
        "id": 13724,
        "title": "Evaluation of Prompt Engineering Strategies for Pharmacokinetic Data Analysis with the ChatGPT Large Language Model",
        "authors": "Euibeom Shin, Murali Ramanathan",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nPurpose\n To systematically assess the ChatGPT large language model on diverse tasks relevant to pharmacokinetic data analysis.\nMethods\n ChatGPT was evaluated with prototypical tasks related to report writing, code generation, non-compartmental analysis, and pharmacokinetic word problems. The writing task consisted of writing an introduction for this paper from a draft title. The coding tasks consisted of generating R code for semi-logarithmic graphing of concentration-time profiles and calculating area under the curve and area under the moment curve from time zero to infinity. Pharmacokinetics word problems on single intravenous, extravascular bolus, and multiple dosing were taken from a pharmacokinetics textbook. Chain-of-thought and problem separation were assessed as prompt engineering strategies when errors occurred.\nResults\n ChatGPT showed satisfactory performance on the report writing, code generation tasks and provided accurate information on the principles and methods underlying pharmacokinetic data analysis. However, ChatGPT had high error rates in numerical calculations involving exponential functions. The outputs generated by ChatGPT were not reproducible: the precise content of the output was variable albeit not necessarily erroneous for different instances of the same prompt. Incorporation of prompt engineering strategies reduced but did not eliminate errors in numerical calculations.\nConclusions\n ChatGPT has the potential to become a powerful productivity tool for writing, knowledge encapsulation, and coding tasks in pharmacokinetic data analysis. The poor accuracy of ChatGPT in numerical calculations require resolution before it can be reliably used for PK and pharmacometrics data analysis.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3364157/v1"
    },
    {
        "id": 13725,
        "title": "Which Large Language Model should You Use in Vietnamese Education: ChatGPT, Bing Chat, or Bard?",
        "authors": "Dao Xuan Quy",
        "published": "No Date",
        "citations": 0,
        "abstract": "This paper aims to determine the most suitable large language model (LLM) among ChatGPT, BingChat, and Bard for Vietnamese educators and students. The results show that ChatGPT and BingChat exhibit similar performances and outperform Bard in mathematics. In literature, ChatGPT performs better than BingChat and Bard. However, BingChat demonstrates superior performance compared to ChatGPT and Bard in English. All three LLMs demonstrate relatively comparable performances in physics. For biology, BingChat and Bard outperform ChatGPT. Notably, Bard outperforms both ChatGPT and BingChat in chemistry. In the domain of social sciences, both BingChat and Bard exhibit comparable and better performances than ChatGPT. These findings provide valuable insights for educators and students in Vietnamese high schools in selecting suitable LLM for specific subjects.",
        "link": "http://dx.doi.org/10.31219/osf.io/xjau5"
    },
    {
        "id": 13726,
        "title": "Prompt Learning Under the Large Language Model",
        "authors": "Lili Sun, Zhenquan Shi",
        "published": "2023-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/scset58950.2023.00070"
    },
    {
        "id": 13727,
        "title": "Out-of-core outlier removal for large-scale indoor point clouds",
        "authors": "Linlin Ge, Jieqing Feng",
        "published": "2022-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.gmod.2022.101142"
    },
    {
        "id": 13728,
        "title": "THE IMPORTANCE OF LINGUISTIC MODELS IN THE DEVELOPMENT OF LANGUAGE BASES GE BASE",
        "authors": "Guli Ibragimovna Toirova,  ",
        "published": "2020-12-29",
        "citations": 0,
        "abstract": "Relevance. In Uzbek linguistics, a number of studies have been carried out on automatic translation, the development of the linguistic foundations of the author's corpus, the processing of lexicographic texts and linguistic-statistical analysis. However, the processing of the Uzbek language as the language of the Internet: spelling, automatic processing and translation programs, search programs for various characters, text generation, the linguistic basis of the text corpus and national corpus, the technology of its software is not studied in any monograph. The article discusses such problems as: the transformation of language into the language of the Internet, computer technology, mathematical linguistics, its continuation and the formation and development of computer linguistics, in particular the question of modeling natural languages for artificial intelligence. The Uzbek National Corps plays an important role in enhancing the international status of the Uzbek language.",
        "link": "http://dx.doi.org/10.52297/2181-1466/2020/4/6/8"
    },
    {
        "id": 13729,
        "title": "A comparison of language-dependent and language-independent models for violence prediction",
        "authors": "Ben Greenawald, Yingjie Liu, Gregory Wert, Mohammad Al Boni, Donald E. Brown",
        "published": "2018-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/sieds.2018.8374748"
    },
    {
        "id": 13730,
        "title": "Towards Task-Agnostic Privacy- And Utility-Preserving Models",
        "authors": "Yaroslav Emelyanov,  ",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-072-4_045"
    },
    {
        "id": 13731,
        "title": "On the Strength of Character Language Models for Multilingual Named Entity Recognition",
        "authors": "Xiaodong Yu, Stephen Mayhew, Mark Sammons, Dan Roth",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d18-1345"
    },
    {
        "id": 13732,
        "title": "Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues",
        "authors": "Amal Alqahtani, Rana Salama, Mona Diab, Abdou Youssef",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.clinicalnlp-1.55"
    },
    {
        "id": 13733,
        "title": "Preserving Privacy Through Dememorization: An Unlearning Technique For Mitigating Memorization Risks In Language Models",
        "authors": "Aly Kassem, Omar Mahmoud, Sherif Saad",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.265"
    },
    {
        "id": 13734,
        "title": "Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models",
        "authors": "Jianwei Li, Qi Lei, Wei Cheng, Dongkuan Xu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.79"
    },
    {
        "id": 13735,
        "title": "When are Lemons Purple? The Concept Association Bias of Vision-Language Models",
        "authors": "Yingtian Tang, Yutaro Yamada, Yoyo Zhang, Ilker Yildirim",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.886"
    },
    {
        "id": 13736,
        "title": "Prompt2Model: Generating Deployable Models from Natural Language Instructions",
        "authors": "Vijay Viswanathan, Chenyang Zhao, Amanda Bertsch, Tongshuang Wu, Graham Neubig",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-demo.38"
    },
    {
        "id": 13737,
        "title": "Do Chatbots Have Emotions?",
        "authors": "Mascha Kurpicz-Briki",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-37690-0_4"
    },
    {
        "id": 13738,
        "title": "HOW TO GAMIFY THE FLIPPED CLASSROOM TO SUPPORT ROMANIAN LANGUAGE LEARNING?",
        "authors": "MAHMOUD FAWZI",
        "published": "2022",
        "citations": 0,
        "abstract": "As innovative and effective approaches, gamification and flipped classroom have been widely applied in foreign languages teaching and learning, but little studies were conducted about gamification applying in flipped classrooms to assist the learning of Romanian language. To fill this gap, it was necessary to search for effective ways to find innovative solutions. Implementation of gamification in flipped classrooms can increase students' motivation towards in-class activities and towards Romanian language learning. The purpose of this article is to provide a practical and theoretical framework for integrating gamification in flipped Romanian language courses and use mobile applications such as (Kahoot! and Quizizz) for in-class activities, which can help in supporting with Romanian language learning by concentrating on various perspectives to apply the flipped classroom, in-class activities, gamification, and mobile applications in the educational context.",
        "link": "http://dx.doi.org/10.56177/epvl.ch42.2022.en"
    },
    {
        "id": 13739,
        "title": "Jumping Grammars and Discontinuous Computation",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_5"
    },
    {
        "id": 13740,
        "title": "Language Models and Google Trends: An Application to Tourism in the Andean Countries",
        "authors": "Cristhian Larrahondo, Emily Díaz, Diego Guerrero",
        "published": "2024-2-6",
        "citations": 0,
        "abstract": "Using Google Trends data, this study leverages high-frequency unstructured data to characterize tourism demand in the Andean countries. The paper explores real-time data to monitor trends in the tourism industry, leveraging language models to identify suitable search terms. The document presents a methodology based on keywords related to tourism products in Bolivia, Colombia, Ecuador, Peru, and Venezuela between 2010 and 2023. Results show decline and recovery trends in the interest in traveling to these destinations. Additionally, trends for local tourist destinations and specific products are analyzed. The real-time data-driven results can guide industrial policies in the region, emphasizing the importance of understanding and adapting to changing dynamics of tourism demand in the Andean Region.",
        "link": "http://dx.doi.org/10.18235/0005544"
    },
    {
        "id": 13741,
        "title": "Computational Models for Spatial Prepositions",
        "authors": "Georgiy Platonov, Lenhart Schubert",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-1403"
    },
    {
        "id": 13742,
        "title": "SCALa: A blueprint for computational models of language acquisition in social context",
        "authors": "Sho Tsuji, Alejandrina Cristia, Emmanuel Dupoux",
        "published": "No Date",
        "citations": 0,
        "abstract": "Theories and data on language acquisition suggest a range of cues are used, ranging from information on structure found in the linguistic signal itself, to information gleaned from the environmental context or through social interaction. We propose a blueprint for computational models of the early language learner (SCALa, for Socio-Computational Architecture of Language Acquisition) that makes explicit the connection between the kinds of information available to the social learner and the computational mechanisms required to extract language-relevant information and learn from it. SCALa integrates a range of views on language acquisition, further allowing us to make precise recommendations for future large-scale empirical research.",
        "link": "http://dx.doi.org/10.31234/osf.io/jngzq"
    },
    {
        "id": 13743,
        "title": "Peer Review #2 of \"Feature-based detection of automated language models: tackling GPT-2, GPT-3 and Grover (v0.1)\"",
        "authors": "",
        "published": "2021-4-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.443v0.1/reviews/2"
    },
    {
        "id": 13744,
        "title": "Review comments to manuscript &amp;quot;Societal breakdown as an emergent property of large-scale behavioural models of land use change&amp;quot;",
        "authors": "Gunnar Dressler",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5194/esd-2019-24-rc2"
    },
    {
        "id": 13745,
        "title": "On numerical methods for functions depending on a very large number of variables",
        "authors": "M. Sobol",
        "published": "2017-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1134/s207004821705012x"
    },
    {
        "id": 13746,
        "title": "Task Effects on Linguistic Complexity and Accuracy: A Large‐Scale Learner Corpus Analysis Employing Natural Language Processing Techniques",
        "authors": "Theodora Alexopoulou, Marije Michel, Akira Murakami, Detmar Meurers",
        "published": "2017-6",
        "citations": 83,
        "abstract": "Large‐scale learner corpora collected from online language learning platforms, such as the EF‐Cambridge Open Language Database (EFCAMDAT), provide opportunities to analyze learner data at an unprecedented scale. However, interpreting the learner language in such corpora requires a precise understanding of tasks: How does the prompt and input of a task and its functional requirements influence task‐based linguistic performance? This question is vital for making large‐scale task‐based corpora fruitful for second language acquisition research. We explore the issue through an analysis of selected tasks in EFCAMDAT and the complexity and accuracy of the language they elicit.",
        "link": "http://dx.doi.org/10.1111/lang.12232"
    },
    {
        "id": 13747,
        "title": "Research on Transportation Technology of Nuclear Power Large Shell Cylinder Structure",
        "authors": "",
        "published": "2022-4-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i4(05).05"
    },
    {
        "id": 13748,
        "title": "Study on Seamless Technology of Large Volume Concrete in House Construction",
        "authors": "",
        "published": "2021-3-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i3.21"
    },
    {
        "id": 13749,
        "title": "Common Mechanical Failures and Handling Measures of Large Road Maintenance Machinery",
        "authors": "",
        "published": "2021-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i10.20"
    },
    {
        "id": 13750,
        "title": "Analyzing Chatgpt Based on Large Language Model from Industrial Perspective",
        "authors": "Lakshita Aggarwal, Urvi Vasisht, Rahul Kanwar, Arun Kumar, Puneet Goswami",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4563696"
    },
    {
        "id": 13751,
        "title": "Sustainability Bias in Utility and Infrastructure Related Large Language Model Queries",
        "authors": "William Kuehne, Lauren Basler",
        "published": "2024-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2175/193864718825159252"
    },
    {
        "id": 13752,
        "title": "Investigation of Large-Margin Softmax in Neural Language Modeling",
        "authors": "Jingjing Huo, Yingbo Gao, Weiyue Wang, Ralf Schlüter, Hermann Ney",
        "published": "2020-10-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2020-1849"
    },
    {
        "id": 13753,
        "title": "NetGO 3.0: Protein Language Model Improves Large-scale Functional Annotations",
        "authors": "Shaojun Wang, Ronghui You, Yunjia Liu, Yi Xiong, Shanfeng Zhu",
        "published": "No Date",
        "citations": 3,
        "abstract": "AbstractAs one of the state-of-the-art automated function prediction (AFP) methods, NetGO 2.0 integrates multi-source information to improve the performance. However, it mainly utilizes the proteins with experimentally supported functional annotations without leveraging valuable information from a vast number of unannotated proteins. Recently, protein language models have been proposed to learn informative representations (e.g., Evolutionary Scale Modelling (ESM)-1b embedding) from protein sequences based on self-supervision. We represent each protein by ESM-1b and use logistic regression (LR) to train a new model, LR-ESM, for AFP. The experimental results show that LR-ESM achieves comparable performance with the best-performing component of NetGO 2.0. Therefore, by incorporating LR-ESM into NetGO 2.0, we develop NetGO 3.0 to improve the performance of AFP extensively. NetGO 3.0 is freely accessible athttps://dmiip.sjtu.edu.cn/ng3.0.",
        "link": "http://dx.doi.org/10.1101/2022.12.05.519073"
    },
    {
        "id": 13754,
        "title": "Sustained Linguistic Inquiry as a Means of Confronting Language Ideology and Prejudice",
        "authors": "Kristin Denham, David Pippin",
        "published": "2019-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678-21"
    },
    {
        "id": 13755,
        "title": "An Investigation of Language-Related Challenges in Full and Multilingual English-Medium Instruction Models in Turkey",
        "authors": "Mehmet Altay, Dogan Yuksel",
        "published": "2022-3-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003181859-14"
    },
    {
        "id": 13756,
        "title": "Bridging the Digital Divide: Performance Variation across Socio-Economic Factors in Vision-Language Models",
        "authors": "Joan Nwatu, Oana Ignat, Rada Mihalcea",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.660"
    },
    {
        "id": 13757,
        "title": "Bootstrapping Small &amp; High Performance Language Models with Unmasking-Removal Training Policy",
        "authors": "Yahan Yang, Elior Sulem, Insup Lee, Dan Roth",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.30"
    },
    {
        "id": 13758,
        "title": "A Picture is Worth a Thousand Words: Language Models Plan from Pixels",
        "authors": "Anthony Liu, Lajanugen Logeswaran, Sungryull Sohn, Honglak Lee",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.1025"
    },
    {
        "id": 13759,
        "title": "Dynamic Knowledge Distillation for Pre-trained Language Models",
        "authors": "Lei Li, Yankai Lin, Shuhuai Ren, Peng Li, Jie Zhou, Xu Sun",
        "published": "2021",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.31"
    },
    {
        "id": 13760,
        "title": "Connectives: Order, Causality and Beyond",
        "authors": "Joanna Blochowiak",
        "published": "2017",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5_10"
    },
    {
        "id": 13761,
        "title": "Observations on Theoretical Models in Neuropsychology of Language",
        "authors": "D. Parisi, C. Burani",
        "published": "2018-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781315637426-4"
    },
    {
        "id": 13762,
        "title": "Jumping Automata and Discontinuous Computation",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_8"
    },
    {
        "id": 13763,
        "title": "Exploring Natural Language Models&amp;amp;#39; Responses to Intersectional Identities in Climate Change Education",
        "authors": "Ha Nguyen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3102/ip.23.2007525"
    },
    {
        "id": 13764,
        "title": "Voxelwise encoding models show that cerebellar language representations are highly conceptual",
        "authors": "Amanda LeBel, Shailee Jain, Alexander G. Huth",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractThere is a growing body of research demonstrating that the cerebellum is involved in language understanding. Early theories assumed that the cerebellum is involved in low-level language processing. However, those theories are at odds with recent work demonstrating cerebellar activation during cognitive tasks. Using natural language stimuli and an encoding model framework, we performed an fMRI experiment where subjects passively listened to five hours of natural language stimuli which allowed us to analyze language processing in the cerebellum with higher precision than previous work. We used this data to fit voxelwise encoding models with five different feature spaces that span the hierarchy of language processing from acoustic input to high-level conceptual processing. Examining the prediction performance of these models on separate BOLD data shows that cerebellar responses to language are almost entirely explained by high-level conceptual language features rather than low-level acoustic or phonemic features. Additionally, we found that the cerebellum has a higher proportion of voxels that represent social semantic categories, which include “social” and “people” words, and lower representations of all other semantic categories, including “mental”, “concrete”, and “place” words, than cortex. This suggests that the cerebellum is representing language at a conceptual level with a preference for social information.Significance StatementRecent work has demonstrated that, beyond its typical role in motor planning, the cerebellum is implicated in a wide variety of tasks including language. However, little is known about the language representations in the cerebellum, or how those representations compare to cortex. Using voxelwise encoding models and natural language fMRI data, we demonstrate here that language representations are significantly different in the cerebellum as compared to cortex. Cerebellum language representations are almost entirely semantic, and the cerebellum contains over-representation of social semantic information as compared to cortex. These results suggest that the cerebellum is not involved in language processing per se, but cognitive processing more generally.",
        "link": "http://dx.doi.org/10.1101/2021.01.18.427158"
    },
    {
        "id": 13765,
        "title": "Wave to Syntax: Probing spoken language models for syntax",
        "authors": "Gaofei Shen, Afra Alishahi, Arianna Bisazza, Grzegorz Chrupała",
        "published": "2023-8-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-679"
    },
    {
        "id": 13766,
        "title": "Online Incremental Learning for Speaker-Adaptive Language Models",
        "authors": "Chih Chi Hu, Bing Liu, John Shen, Ian Lane",
        "published": "2018-9-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2018-2259"
    },
    {
        "id": 13767,
        "title": "Limitations of Language Models in The Oil &amp; Gas Upstream Operations",
        "authors": "A. Alsultan, F. Abdul Razak",
        "published": "2024-2-12",
        "citations": 0,
        "abstract": "Abstract\nLanguage models has powered a lot of applications and developments in the past years in different domains. One language model that became popular in the recent years is BERT which is used as a base for many different natural language processing tasks such as classification and question answering. We wanted to apply BERT on some upstream oil and gas related text and study its performance on this domain. We decided to choose classification as a task to experiment with it. We tried a mix of domain adaptation and transfer learning to understand the potential of language models in general and BERT in specific on our domain. Our results emphasized the need to create domain-specific datasets for the oil and gas world and subsequently build models using them.",
        "link": "http://dx.doi.org/10.2523/iptc-23649-ea"
    },
    {
        "id": 13768,
        "title": "eLife assessment: Sensitive remote homology search by local alignment of small positional embeddings from protein language models",
        "authors": "Ignacio Sanchez",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.91415.1.sa2"
    },
    {
        "id": 13769,
        "title": "Automated Extraction and Visualization of Metabolic Networks from Biomedical Literature Using a Large Language Model",
        "authors": "Thiptanawat Phongwattana, Jonathan H Chan",
        "published": "No Date",
        "citations": 1,
        "abstract": "The rapid growth of biomedical literature presents a significant challenge for researchers to extract and analyze relevant information efficiently. In this study, we explore the application of GPT, the large language model to automate the extraction and visualization of metabolic networks from a corpus of PubMed abstracts. Our objective is to provide a valuable tool for biomedical researchers to explore and understand the intricate metabolic interactions discussed in scientific literature. We begin by splitting a ton of the tokens within the corpus, as the GPT-3.5-Turbo model has a token limit of 4,000 per analysis. Through iterative prompt optimization, we successfully extract a comprehensive list of metabolites, enzymes, and proteins from the abstracts. To validate the accuracy and completeness of the extracted entities, our biomedical data domain experts compare them with the provided abstracts and ensure a fully matched result. Using the extracted entities, we generate a directed graph that represents the metabolic network including 3 types of metabolic events that consist of metabolic consumption, metabolic reaction, and metabolic production. The graph visualization, achieved through Python and NetworkX, offers a clear representation of metabolic pathways, highlighting the relationships between metabolites, enzymes, and proteins. Our approach integrates language models and network analysis, demonstrating the power of combining automated information extraction with sophisticated visualization techniques. The research contributions are twofold. Firstly, we showcase the ability of GPT-3.5-Turbo to automatically extract metabolic entities, streamlining the process of cataloging important components in metabolic research. Secondly, we present the generation and visualization of a directed graph that provides a comprehensive overview of metabolic interactions. This graph serves as a valuable tool for further analysis, comparison with existing pathways, and updating or refining metabolic networks. Our findings underscore the potential of large language models and network analysis techniques in extracting and visualizing metabolic information from scientific literature. This approach enables researchers to gain insights into complex biological systems, advancing our understanding of metabolic pathways and their components.",
        "link": "http://dx.doi.org/10.1101/2023.06.27.546560"
    },
    {
        "id": 13770,
        "title": "Application of Pore Pressure Static Penetration Technique to A Large Bridge",
        "authors": "",
        "published": "2022-1-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i1.120"
    },
    {
        "id": 13771,
        "title": "SpaCCC: Large language model-based cell-cell communication inference for spatially resolved transcriptomic data",
        "authors": "Boya Ji, Liwen Xu, Shaoliang Peng",
        "published": "No Date",
        "citations": 0,
        "abstract": "Drawing parallels between linguistic constructs and cellular biology, large language models (LLMs) have achieved remarkable success in diverse downstream applications for single-cell data analysis. However, to date, it still lacks methods to take advantage of LLMs to infer ligand-receptor (LR)-mediated cell-cell communications for spatially resolved transcriptomic data. Here, we propose SpaCCC to facilitate the inference of spatially resolved cell-cell communications, which relies on our fine-tuned single-cell LLM and functional gene interaction network to embed ligand and receptor genes expressed in interacting individual cells into a unified latent space. The LR pairs with a significant closer distance in latent space are taken to be more likely to interact with each other. After that, the molecular diffusion and permutation test strategies are respectively employed to calculate the communication strength and filter out communications with low specificities. The benchmarked performance of SpaCCC is evaluated on real single-cell spatial transcriptomic datasets with remarkable superiority over other methods. SpaCCC also infers known LR pairs concealed by existing aggregative methods and then identifies communication patterns for specific cell types and their signalling pathways. Furthermore, spaCCC provides various cell-cell communication visualization results at both single-cell and cell type resolution. In summary, spaCCC provides a sophisticated and practical tool allowing researchers to decipher spatially resolved cell-cell communications and related communication patterns and signalling pathways based on spatial transcriptome data.",
        "link": "http://dx.doi.org/10.1101/2024.02.21.581369"
    },
    {
        "id": 13772,
        "title": "Modeling of Damage in Turbine Blades for Large Deformations",
        "authors": "Ozgur Aslan",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4322/978-65-86503-83-8.c08"
    },
    {
        "id": 13773,
        "title": "Extracting Petri Modules From Large and Legacy Petri Net Models",
        "authors": "Reggie Davidrajuh",
        "published": "2020",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2020.3020213"
    },
    {
        "id": 13774,
        "title": "Singular Solutions in Nonlinear Models of Fluid Dynamics",
        "authors": "Mikhail Roop",
        "published": "2018-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2018.8551782"
    },
    {
        "id": 13775,
        "title": "Food Chains, Yields, Models, and Management of Large Marine Ecosystems",
        "authors": "Kenneth Sherman",
        "published": "2019-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429042423"
    },
    {
        "id": 13776,
        "title": "Models of Epilepsy Surgery in a Large LAMIC",
        "authors": "Chaturbhuj Rathore, Kurupath Radhakrishnan",
        "published": "2017-4-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139547918.029"
    },
    {
        "id": 13777,
        "title": "Data-based large-scale models provide a window into the organization of cortical computations",
        "authors": "Guozhang Chen, Franz Scherr, Wolfgang Maass",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractThe neocortex of the brain is one of the most powerful computing devices that exists, but it remains largely open how its computations are organized. Since the neocortex is a 2D tapestry consisting of repeating stereotypical local cortical microcircuits, a key step for solving this problem is to understand how cortical microcircuits compute. We know by now a lot about their connectivity structure and their neuron types, but we are lacking tools for elucidating causal relations between this structure and their computational function. We present a new tool for elucidating this relation: We train large-scale models of cortical microcircuits, which integrate most current knowledge about their structure, for carrying out similar computational tasks as in the brain. We show that the trained model achieves a similar computational performance as the brain, and that it reproduces experimentally found traits of cortical computation and coding that do not appear in neural network models from AI. Furthermore, we reverse-engineer how computations are organized in the model, thereby producing specific hypotheses that can be tested in experimental neuroscience. Altogether we show that cortical microcircuits provide a distinct new neural network paradigm that is of particular interest for neuromorphic engineering because it computes with highly energy-efficient sparse activity.TeaserReverse engineering of cortical computations",
        "link": "http://dx.doi.org/10.1101/2023.04.28.538662"
    },
    {
        "id": 13778,
        "title": "The multiverse future of ENSO diversity in large ensembles of climate models",
        "authors": "Bastien Dieppois, Nicola Maher, Antonietta Capotondi, John O'Brien",
        "published": "No Date",
        "citations": 0,
        "abstract": "El Ni&#241;o Southern Oscillation (ENSO) shows large differences from one event to another in terms of its intensity, spatial pattern, and temporal evolution, which are typically referred to as &#8220;ENSO diversity&#8221;. While such differences in ENSO patterns are associated with different regional climate impacts throughout the world, influencing the skill of impact prediction systems, large uncertainties remain concerning its potential future evolution and trends. The location and intensity of ENSO events are indeed strongly influenced by internal/natural climate variations, limiting the detection of forced changes.Here, we exploit the power of single model initial-condition large ensembles (SMILEs) from 13 fully coupled climate models from both CMIP5 and CMIP6 (totalling 580 realizations in historical and SSP-RCP scenarios) to first examine the ability of climate models to simulate realistic diversity of ENSO events compared to multiple observational datasets, and then use those models to characterize future trajectories in the location and intensity of El Ni&#241;o and La Ni&#241;a events. We define the location of ENSO events as the longitude of the absolute maximum (the intensity) of sea-surface temperature anomalies (SSTa) during boreal Winter (December-February) in the equatorial Pacific. Future projections of ENSO diversity are assessed in terms of joint probability distributions of ENSO events&#8217; location and intensity.While some models show a degree of diversity in the location and intensity of events that are comparable with observed statistics, other models tend to favour the occurrence of eastern or central Pacific events. Such contrasting performances during the historical period are found to be associated with different future trajectories of ENSO diversity: i) models favouring the occurrence of eastern Pacific events (e.g., ACCESS-ESM1-5, CanESM2, and 5) show a westward shift in event location over the 21st century; ii) models simulating ENSO events anomalously westward tend to show an eastward shift in event locations and an increased intensity in the 21st century (e.g., CESM1 and 2, CSIRO-MK3-6-0, GFDL-CM3, GFDL-ESM2M, MIROC-ES2L, MIROC6). Nevertheless, we note that models showing the closest match to observed statistics during the historical period also present a westward shift in ENSO locations and a slight increase in intensity in the 21st century (e.g., GFDL-SPEAR and IPSL-CM6-LR).Although the physical cause of model discrepancies remains unclear, this study provides a broader perspective on expected ENSO changes over the 21st century in different models and highlights the spread of projections among models.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-7791"
    },
    {
        "id": 13779,
        "title": "Structural dynamic models of large systems",
        "authors": "Alvar M. Kabe, Brian H. Sako",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-821615-6.00002-2"
    },
    {
        "id": 13780,
        "title": "Review for \"Tissue-engineered tendon nano-constructs for repair of chronic rotator cuff tears in large animal models\"",
        "authors": "Ting-Wu Qin",
        "published": "2022-3-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/btm2.10376/v1/review2"
    },
    {
        "id": 13781,
        "title": "Decision letter for \"Tissue-engineered tendon nano-constructs for repair of chronic rotator cuff tears in large animal models\"",
        "authors": "",
        "published": "2022-6-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/btm2.10376/v3/decision1"
    },
    {
        "id": 13782,
        "title": "Efficient Antenna Scan Response Models for Large Phased Arrays",
        "authors": "Brandt Klopper, Dirk I.L. de Villiers",
        "published": "2018-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/apmc.2018.8617187"
    },
    {
        "id": 13783,
        "title": "Strain Effect in Large Silicon Nanocrystal Quantum Dots",
        "authors": "A. Thean, J.-P. Leburton",
        "published": "2021-11-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003148494-53"
    },
    {
        "id": 13784,
        "title": "Large-Time Asymptotics for Degenerate Cross-Diffusion Population Models with Volume Filling",
        "authors": "XIUQING CHEN, Ansgar Jüngel, Xi Lin, Ling Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4539251"
    },
    {
        "id": 13785,
        "title": "Balanced Reduced-Order Models for Iterative Nonlinear Control of Large-Scale Systems",
        "authors": "Yizhe Huang, Boris Kramer",
        "published": "2021-5-25",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/acc50511.2021.9483101"
    },
    {
        "id": 13786,
        "title": "Bidirectional Transformations in the Large",
        "authors": "Perdita Stevens",
        "published": "2017-9",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/models.2017.8"
    },
    {
        "id": 13787,
        "title": "Anatomy and Plasticity in Large-Scale Brain Models",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3389/978-2-88945-065-7"
    },
    {
        "id": 13788,
        "title": "Forecasting Large Hail using Additive Logistic Regression Models and the ECMWF Reforecasts",
        "authors": "Francesco Battaglioli, Pieter Groenemeijer, Ivan Tsonevsky, Tomáš Púčik",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;An Additive Logistic Regression model for large hail (AR&lt;em&gt;&lt;span lang=&quot;EN-GB&quot;&gt;&lt;sub&gt;hail&lt;/sub&gt;&lt;/span&gt;&lt;/em&gt;&lt;span lang=&quot;EN-GB&quot;&gt;)&lt;/span&gt;&lt;em&gt;&lt;span lang=&quot;EN-GB&quot;&gt;&amp;#160;&lt;/span&gt;&lt;/em&gt;was developed using convective parameters from the ERA5 reanalysis, hail reports from the European Severe Weather Database (ESWD) and lightning observations from the Met Office Arrival Time Difference network (ATDnet). This model was shown to accurately reproduce the climatological distribution and the seasonal cycle of observed hail events in Europe. To explore the value of this approach to medium-range forecasting, a similar four-dimensional model was developed using predictor parameters retrieved from the ECMWF reforecasts: Mixed Layer CAPE, Deep Layer Shear, Mixed Layer Mixing Ratio and the Wet Bulb Zero Height. This model was applied to ECMWF reforecasts to compute probabilistic large hail forecasts for all available 11 ensemble members, from 2008 to 2019 and for lead times up to 228 hours. First, we compared the hail ensemble forecasts for different lead times with observed hail occurrence from the ESWD focusing on a recent hail outbreak. Secondly, we systematically evaluated the model&amp;#8217;s predictive skill depending on the forecast lead time using the Area under the ROC Curve (AUC) as a validation score. This analysis showed that AR&lt;em&gt;&lt;span lang=&quot;EN-GB&quot;&gt;&lt;sub&gt;hail&lt;/sub&gt;&lt;/span&gt;&lt;/em&gt;&lt;span lang=&quot;EN-GB&quot;&gt;&amp;#160;&lt;/span&gt;has a very high predictive skill (AUC &gt; 0.95) for forecasts up to 60 hours lead time. Although the performance scores progressively decrease with increasing lead time, AR&lt;em&gt;&lt;span lang=&quot;EN-GB&quot;&gt;&lt;sub&gt;hail&lt;/sub&gt;&lt;/span&gt;&lt;/em&gt;&amp;#160;retains a high predictive skill even for extended forecasts (AUC = 0.86 at 180 hours lead time) showing that it can provide useful guidance in hail forecasting well in advance. Finally, the performance of the four-dimensional model was compared with that of composite parameters such as the Significant Hail Parameter (SHP) and the product of CAPE and Deep Layer Shear (CAPESHEAR). Results show that AR&lt;em&gt;&lt;span lang=&quot;EN-GB&quot;&gt;&lt;sub&gt;hail&lt;/sub&gt;&lt;/span&gt;&lt;/em&gt; outperforms CAPESHEAR (at all lead times) and SHP (especially at short lead times). This suggest that the developed Additive Logistic Regression model can improve hail forecasting compared to currently used composite indices in Europe.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/ecss2023-103"
    },
    {
        "id": 13789,
        "title": "Di-Higgs production in BSM models",
        "authors": "Tania Robens",
        "published": "2023-3-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22323/1.422.0221"
    },
    {
        "id": 13790,
        "title": "Large scale limit of interface fluctuation models",
        "authors": "Martin Hairer, Weijun Xu",
        "published": "2019-11-1",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1214/18-aop1317"
    },
    {
        "id": 13791,
        "title": "(Large) Finite to Continuum: An Approximation Result for Electoral Competition Models",
        "authors": "Mihir Bhattacharya, Saptarshi Mukherjee, Ruhi Sonal, Raghul  S. Venkatesh",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4499210"
    },
    {
        "id": 13792,
        "title": "Decision letter for \"Tissue-engineered tendon nano-constructs for repair of chronic rotator cuff tears in large animal models\"",
        "authors": "",
        "published": "2022-3-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/btm2.10376/v1/decision1"
    },
    {
        "id": 13793,
        "title": "Econometric Forecasting Models Based on Forecast Combination Methods",
        "authors": "Vera Ivanyuk",
        "published": "2018-10",
        "citations": 20,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2018.8551825"
    },
    {
        "id": 13794,
        "title": "Distributed Agent Optimization for Large-Scale Network Models",
        "authors": "Masahiro Nagao, Sathish Sankaran, Zhenyu Guo",
        "published": "2023-5-15",
        "citations": 0,
        "abstract": "Abstract\nOptimization of production networks is key for managing efficient hydrocarbon production as part of closed-loop asset management. Large-scale surface network optimization is a challenging task that involves high nonlinearity with numerous constraints. In existing tools, the computational cost of solving the surface network optimization can exponentially increase with the size and complexities of the network using traditional approaches involving nonlinear programming methods. In this study, we accelerate the large-scale surface network optimization by using a distributed agent optimization algorithm called alternating direction method of multipliers (ADMM).\nWe develop and apply the ADMM algorithm for large-scale network optimization with over 1000 wells and interconnecting pipelines. In the ADMM framework, a large-scale network system is broken down into many small sub-network systems. Then, a smaller optimization problem is formulated for each sub-network. These sub-network optimization problems are solved in parallel using multiple computer cores so that the entire system optimization will be accelerated. A large-scale surface network involves many inequality and equality constraints, which are effectively handled by using augmented Lagrangian method to enhance the robustness of convergence quality. Additionally, proxy or hybrid models can also be used for pipe flow and pressure calculation for every network segment to further speed up the optimization.\nThe proposed ADMM optimization method is validated by several synthetic cases. We first apply the proposed method to surface network simulation problems of various sizes and complexities (configurations, fluid types, pressure regimes, etc.), where the pressure for all nodes and fluxes in all links will be calculated with a specified separator pressure and reservoir pressures. High accuracy was obtained from the ADMM framework compared with a commercial simulator. Next, the ADMM is applied to network optimization problems, where we optimize the pressure drop across a surface choke for every well to maximize oil production. In a large-scale network case with over 1000 wells, we achieve 2X – 3X speedups in computation time with reasonable accuracy from the ADMM framework compared with benchmarks. Finally, we apply the proposed method to a field case, and validate that the ADMM framework properly works for the actual field applications.\nA novel framework for surface network optimization was developed using the distributed agent optimization algorithm. The proposed framework provides superior computational efficiency for large- scale network optimization problems compared with existing benchmark methods. It enables more efficient and frequent decision-making of large-scale petroleum field management to maximize the hydrocarbon production subject to numerous system constraints.",
        "link": "http://dx.doi.org/10.2118/213022-ms"
    },
    {
        "id": 13795,
        "title": "Internet Appendix for State-Varying Factor Models of Large Dimensions",
        "authors": "Markus Pelger, Ruoxuan Xiong",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3711840"
    },
    {
        "id": 13796,
        "title": "Collapse due to static liquefaction analyzed using large deformation elasto-visco-plastic dynamics",
        "authors": "F. Molenkamp",
        "published": "2020-12-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003078548-92"
    },
    {
        "id": 13797,
        "title": "Fault-Tolerant HLA-Based Distributed Simulations",
        "authors": "Dan Chen, Lizhe Wang, Jingying Chen",
        "published": "2017-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b11883-4"
    },
    {
        "id": 13798,
        "title": "An Application: Density Reconstruction",
        "authors": "Baojiu Li",
        "published": "2018-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1088/978-0-7503-1587-6ch5"
    },
    {
        "id": 13799,
        "title": "Testing Beta-Pricing Models    Using  Large Cross-Sections",
        "authors": "Valentina Raponi, Cesare Robotti, Paolo Zaffaroni",
        "published": "No Date",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2924882"
    },
    {
        "id": 13800,
        "title": "Forecasting Stock Returns with Large Dimensional Factor Models",
        "authors": "Alessandro Giovannelli, Daniele Massacci, Stefano Soccorsi",
        "published": "No Date",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2958491"
    },
    {
        "id": 13801,
        "title": "Impacts of Polarizable Continuum Models on the SCF Convergence and DFT Delocalization Error of Large Molecules",
        "authors": "Fangning Ren, Fang Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "Advances in algorithm developments have enabled density functional theory (DFT) description of large molecules, including whole proteins, but the self-consistent field (SCF) convergence issues often hamper practical applications. The conductor-like polarizable continuum model (CPCM), although initially introduced as an implicit solvent model, was reported to improve SCF convergence in some large molecules. However, the underlying mechanisms and applicable use cases were unclear. We investigated the impacts of CPCM on the SCF convergence of 25 peptides and found that the CPCM only effectively reduced the SCF iterations for molecules with charge separations (e.g., the zwitterionic form of peptides) but had little effect on non-charge-separated molecules. We observed that CPCM increased the HOMO-LUMO gap of both the zwitterionic and non-charge-separated molecules, but only the charge-separated molecules suffered from the vanishing HOMO-LUMO gap problem in the gas phase which is the origin of the convergence issue. We revealed CPCM’s gap-opening mechanism as the selective stabilization/destabilization of molecular orbitals (MO) based on their local electrostatic environment. Compared to level-shifting, a traditional SCF improvement technique, CPCM has superior performance because the stabilization/destabilization of MOs is consistent through SCF iterations. Finally, we examined CPCM’s impacts on DFT density delocalization error (DDE) when used as an SCF accelerator. CPCM can mitigate the DDE and reproduce the density-derived properties (e.g., dipole moments) matching high-level methods when a very low dielectric constant is used but tends to over-localize the electron density at higher dielectric constants.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2022-w3t9p-v3"
    },
    {
        "id": 13802,
        "title": "Advanced Turbulence Models for Large-Scale Atmospheric Boundary Layer Flows",
        "authors": "Ananias Tombouldies, Misun Min, Paul Fischer, Matt Churchfield, Michael Sprague",
        "published": "2023-9-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2172/2229259"
    },
    {
        "id": 13803,
        "title": "Large Models Reshape AI Research and Applications",
        "authors": "Bernd Ludwig",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s13218-023-00829-2"
    },
    {
        "id": 13804,
        "title": "Decision letter for \"Tissue-engineered tendon nano-constructs for repair of chronic rotator cuff tears in large animal models\"",
        "authors": "",
        "published": "2022-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/btm2.10376/v2/decision1"
    },
    {
        "id": 13805,
        "title": "Theoretical Overview on novel BSM models",
        "authors": "Giorgio Arcadi",
        "published": "2023-3-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22323/1.422.0076"
    },
    {
        "id": 13806,
        "title": "Lada Car Sales Models on the Russian Market",
        "authors": "V.V. Makarov",
        "published": "2021-9-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd52249.2021.9600234"
    },
    {
        "id": 13807,
        "title": "Load settlement behavior of large diameter bored piles in over-consolidated clay",
        "authors": "Y. El-Mossallamy",
        "published": "2020-12-17",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003078548-78"
    },
    {
        "id": 13808,
        "title": "The representation of large lakes in high-resolution regional climate models",
        "authors": "Mani Mahdinia, Andre Erler, Yiling Huo, W. Richard Peltier",
        "published": "No Date",
        "citations": 0,
        "abstract": "It has been found that large lakes, a common component of the North American (NA) landscape, can affect the water cycle and modulate temperatures in the surrounding regions. The purpose of this study is to evaluate different lake representations in regional climate model simulations. We use the Weather Research and Forecasting (WRF) model, a widely-used regional climate model, forced by the ERA5 reanalysis product. The study is performed for a 40 year historic period (1979-2019) at a resolution of 12 km. The lakes of concern include the Laurentian Great Lakes, which straddle the US-Canada border; the Great Slave and Great Bear Lakes of the Northwest Territories; and the Lakes Winnipeg and Winnipegosis. Alongside the default lake model, two new column lake models are employed: FLake, a more widely used model, and GL25, a recent, physics-based model. These models have been somewhat successful at alleviating inadequacies of the default model by introducing additional process representations, such as a more realistic surface albedo formulation and a better parameterization for vertical overturning. Additionally, we consider the effect of vertical eddy diffusivity and lake stratification on the model performance. While no column lake model is expected to perform perfectly, our goal here is to identify when (seasonally) and where (geographically) a model produces reliable results, including ice cover distribution and near-surface temperature. The effect of the lake representation on the surrounding regions (e.g., lake-effect precipitation) is also evaluated. We find that the two new lake models perform reasonably well, but there are significant differences in seasonal biases with GL25 performing better in summer and FLake performing better in winter; in fact, FLake reproduces the ice cover of the Great Lakes very well. Furthermore, the biases do not seem to be affected by surface wind induced circulation, and hence 3D modelling may not be a requirement for lake modelling. This study can help with the selection of lake models for regional climate modelling in the NA region and inform the interpretation of the predictions.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-9292"
    },
    {
        "id": 13809,
        "title": "Panel: Multimodal Large Foundation Models",
        "authors": "Mohan Kankanhalli, Marcel Worring",
        "published": "2023-10-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3581783.3617350"
    },
    {
        "id": 13810,
        "title": "Impacts of Polarizable Continuum Models on the SCF Convergence and DFT Delocalization Error of Large Molecules",
        "authors": "Fangning Ren, Fang Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "Advances in algorithm developments have enabled density functional theory (DFT) description of large molecules, including whole proteins, but the self-consistent field (SCF) convergence issues often hamper practical applications. The conductor-like polarizable continuum model (CPCM), although initially introduced as an implicit solvent model, was reported to improve SCF convergence in some large molecules. However, the underlying mechanisms and applicable use cases were unclear. We investigated the impacts of CPCM on the SCF convergence of 25 peptides and found that the CPCM only effectively reduced the SCF iterations for molecules with charge separations (e.g., the zwitterionic form of peptides) but had little effect on non-charge-separated molecules. We observed that CPCM increased the HOMO-LUMO gap of both the zwitterionic and non-charge-separated molecules, but only the charge-separated molecules suffered from the vanishing HOMO-LUMO gap problem in the gas phase which is the origin of the convergence issue. We revealed CPCM’s gap-opening mechanism as the selective stabilization/destabilization of molecular orbitals (MO) based on their local electrostatic environment. Compared to level-shifting, a traditional SCF improvement technique, CPCM has superior performance because the stabilization/destabilization of MOs is consistent through SCF iterations. Finally, we examined CPCM’s impacts on DFT density delocalization error (DDE) when used as an SCF accelerator. CPCM can mitigate the DDE and reproduce the density-derived properties (e.g., dipole moments) matching high-level methods when a very low dielectric constant is used but tends to over-localize the electron density at higher dielectric constants.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2022-w3t9p-v2"
    },
    {
        "id": 13811,
        "title": "Scale-up of Physics-based Models for Predicting Degradation of Large Lithium Ion Batteries",
        "authors": "Hong-Keun Kim, Kyu-Jin Lee",
        "published": "No Date",
        "citations": 0,
        "abstract": "Large lithium-ion batteries (LIBs) in electric vehicles and energy storage systems demonstrate different performance and lifetime compared to small LIB cells, owing to the size effects generated by the electrical configuration and property imbalance. However, the calculation time for performing life predictions with three-dimensional (3D) cell models is undesirably long. In this paper, a lumped cell model with equivalent resistances (LER cell model) is proposed as a reduced order model of the 3D cell model, which enables accurate and fast life predictions of large LIBs. The developed LER cell model is validated via the comparisons with results of the 3D cell models by simulating a 20-Ah commercial pouch cell (NCM/graphite) and the experimental values. In addition, the LER cell models are applied to different cell types and sizes, such as a 20-Ah cylindrical cell and a 60-Ah pouch cell.",
        "link": "http://dx.doi.org/10.20944/preprints202009.0418.v1"
    },
    {
        "id": 13812,
        "title": "How Large-Signal Measurement Techniques Improve the Accuracy of Microwave Transistor Nonlinear Models",
        "authors": "Antonio Raffo",
        "published": "2022-11-29",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/apmc55665.2022.9999807"
    },
    {
        "id": 13813,
        "title": "Language Instructors’ and Students’ Perspective on Large Class Size and What is the Best Technique Language Instructors Utilize to Prompt Learning Autonomy in Class",
        "authors": "Bashayer Al Bloushi, Lulwa Al-Bloushi",
        "published": "2024-2-26",
        "citations": 0,
        "abstract": "In this research, the author identifies the terms of large class size and learning autonomy. The authors exhibit the difference between both terms and explains clearly the idea of both terms. Moreover, the author shows how large class size is related to learning autonomy. The author will then elaborate on how these two terms complete each other. The Author chooses the story of an English teacher who teaches in Nigeria, who is exposed to a large class size confronting different conflicts during this year of teaching. In addition, the author shows how the English teacher overcame these problems and what solutions were chosen that helped to overcome the issue. The Author also exhibits the class size problems and the autonomy in different contexts of other teachers around the world and how they coped with it. He utilized other research papers to show how each teacher dealt with the problem of class size.As a matter of fact, the author shows how a large class size can affect the teaching in class and what solutions are made in order to overcome the large class size complexities. Furthermore, the research also shows the disadvantages of a large class size according to students’ points of view.  It also clarifies how students are affected by large class size and how difficult could learning become in class.",
        "link": "http://dx.doi.org/10.37745/ijelt.13/vol12n25265"
    },
    {
        "id": 13814,
        "title": "Tools for validation and calibration of very large power system models",
        "authors": "Stijn Cole, Francois Promel",
        "published": "2018-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/energycon.2018.8398795"
    },
    {
        "id": 13815,
        "title": "Efficient Estimation of Large-Scale Spatial Capture-Recapture Models",
        "authors": "Daniel Turek, Cyril Milleret, Torbjørn Ergon, Henrik Brøseth, Perry de Valpine",
        "published": "No Date",
        "citations": 4,
        "abstract": "AbstractCapture-recapture methods are a common tool in ecological statistics, which have been extended to spatial capture-recapture models for data accompanied by location information. However, standard formulations of these models can be unwieldy and computationally intractable for large spatial scales, many individuals, and/or activity center movement. We provide a cumulative series of methods that yield dramatic improvements in Markov chain Monte Carlo (MCMC) estimation for two examples. These include removing unnecessary computations, integrating out latent states, vectorizing declarations, and restricting calculations to the locality of individuals. Our approaches leverage the flexibility provided by the nimble R package. In our first example, we demonstrate an improvement in MCMC efficiency (the rate of generating effectively independent posterior samples) by a factor of 100. In our second example, we reduce the computing time required to generate 10,000 posterior samples from 4.5 hours down to five minutes, and realize an increase in MCMC efficiency by a factor of 25. We also explain how these approaches can be applied generally to other spatially-indexed hierarchical models. R code is provided for all examples, as well as an executable web-appendix.",
        "link": "http://dx.doi.org/10.1101/2020.05.07.081182"
    },
    {
        "id": 13816,
        "title": "On the accurate representation of hydropower systems in large-scale hydrological models",
        "authors": "Andrea Galletti, Diego Avesani, Alberto Bellin, Bruno Majone",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Natural streamflow of most mountain catchments worldwide is altered as a consequence of hydropower exploitation and other water uses. Hydrological modelling in these watersheds represents a challenging task, as the streamflow alteration caused by hydropower production is linked to operational schedules as well as to geometrical and technical constraints, which are system specific. Key parameters controlling hydropower functioning are difficult to acquire, because protected by producers, hence modelling hydropower systems in large domains often resorts to simplified (and less realistic) approaches, in order to cope with the lack of information. However, the accuracy of the simulations depends critically on the reliability of the simplified assumptions, which varies among the proposed approaches. In this work we analyzed the impact of the simplifications typically introduced in modelling hydropower at the catchment and larger scales by assuming as reference HYPERstreamHS, a coupled hydrological and hydraulic model exploiting the information publicly available on single hydropower systems. We present an application of the proposed framework to the Adige river basin, a large watershed located in the south-eastern portion of the Alps, in which the presence of 39 large hydropower systems characterized by complex infrastructures, 22 of which connected to storage reservoirs, causes significant alterations of streamflow timing and magnitude. We demonstrate the benefit of accurately representing hydropower-related water diversions by analyzing how the model represents the observed streamflows at impacted sites and hydropower production at the regional scale. We also provide insights on how a simplified representation of large hydropower systems can lead to a biased evaluation of streamflow alterations at impacted sections and of hydropower production at several sites. Our results show that the effects of different simplifications that may be adopted in the modelling framework combine in a non-linear manner, thus complicating the overall evaluation of the associated impacts.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu22-7813"
    },
    {
        "id": 13817,
        "title": "Trench Advance in Collisional settings: insights from large scale 2D and 3D models",
        "authors": "Arijit Laik, Wouter P. Schellart, Vincent Strak",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Continental collision, which leads to mountain building (e.g. Himalayas, Alps), has been under the geodynamic modelling lenses for the last few decades. Such processes subjected to physical and numerical investigations, in conjunction with observational studies, enrich knowledge on mountain belts and have worked out the general architectural large-scale structure and crustal shortening in such regions. The intent to understand the driving forces of long term (~50 Ma) and consistent convergence at the India-Eurasia collisional zone is the goal of the dynamic self-consistent buoyancy-driven whole-mantle scale 2D and 3D models presented in this contribution. The maximum post-collisional convergence rate (~0.362 cm/year) in 2D models, is less than 2 cm/year convergence of India considering it advanced ~1000 km in about 50 Ma.&amp;#160; Additionally, the 2D models are inadequate in exploring the spatio-temporal evolution and dynamics of natural systems, thus necessitating modelling large scale subduction and subsequent continental collision resolving the 3D components of mantle flow.&amp;#160; With a whole mantle reservoir and buoyancy-driven 2D models, the observed trench advance rate, with a large and fixed overriding plate, is relatively novel and higher than previous studies and the high resolution in 2D models also shows crustal-scale localisation in conjunction with large scale mantle flow. The computationally intensive simulations have significantly large (11520 km) trench-perpendicular (in 2D and 3D) and parallel (in 3D) lengths, include two sets of modelled depths: whole mantle (2880 km) and, upper mantle + partial lower mantle (960 km) and use the Underworld2 framework. In 3D, the interaction of an adjacent subducting oceanic plate(s) significantly aids the indentation and trench advance in the collisional margin. These would help understand the dynamics of analogues system(s) in nature such as the Sunda subduction zone and the India-Eurasia collision zone.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu21-7210"
    },
    {
        "id": 13818,
        "title": "Interactive Learning and Control in the Era of Large Models",
        "authors": "Dorsa Sadigh",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc49753.2023.10383349"
    },
    {
        "id": 13819,
        "title": "Report on skill of CMIP6 models to simulate alkalinity and improved parameterizations for large scale alkalinity distribution",
        "authors": "Claudia Hinrichs, Judith Hauck",
        "published": "2022-6-30",
        "citations": 1,
        "abstract": "In part one of this deliverable, an ensemble of 14 CMIP6 Earth System Models is evaluated regarding their performance in simulating alkalinity and related parameters. The majority of the models and the multi-model-mean underestimate surface alkalinity compared to climatological observations. Alkalinity biases stemming from the parametrization of calcium carbonate formation and dissolution can be as big as biases stemming from model physics. In part two, we test the sensitivity of parametrizations concerning the carbonate chemistry in the FESOM2.1-REcoM3 and give recommendations for addressing alkalinity biases.",
        "link": "http://dx.doi.org/10.3289/oceannets_d4.4"
    },
    {
        "id": 13820,
        "title": "Measuring Dynamic Connectedness with Large Bayesian VAR Models",
        "authors": "Dimitris mname Korobilis, Kamil mname Yilmaz",
        "published": "No Date",
        "citations": 45,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3099725"
    },
    {
        "id": 13821,
        "title": "Vietnamese teachers’ views on a large-scale professional development course on using computer-assisted language learning",
        "authors": "Nhat Thi Hong Nguyen",
        "published": "2018-5-16",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781315413259-9"
    },
    {
        "id": 13822,
        "title": "Assessing the Generalization Capacity of Pre-trained Language Models through Japanese Adversarial Natural Language Inference",
        "authors": "Hitomi Yanaka, Koji Mineshima",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.blackboxnlp-1.26"
    },
    {
        "id": 13823,
        "title": "Unsupervised Multi-View Post-OCR Error Correction With Language Models",
        "authors": "Harsh Gupta, Luciano Del Corro, Samuel Broscheit, Johannes Hoffart, Eliot Brenner",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.680"
    },
    {
        "id": 13824,
        "title": "An Empirical Study on Pseudo-log-likelihood Bias Measures for Masked Language Models Using Paraphrased Sentences",
        "authors": "Bum Chul Kwon, Nandana Mihindukulasooriya",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.trustnlp-1.7"
    },
    {
        "id": 13825,
        "title": "Comparing Models of Associative Meaning: An Empirical Investigation of Reference in Simple Language Games",
        "authors": "Judy Hanwen Shen, Matthias Hofer, Bjarke Felbo, Roger Levy",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/k18-1029"
    },
    {
        "id": 13826,
        "title": "Pedagogical models of concordance use: correlations between concordance user preferences",
        "authors": "Oliver James Ballance",
        "published": "2017-5-19",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/09588221.2017.1307228"
    },
    {
        "id": 13827,
        "title": "LanguageCrawl: a generic tool for building language models upon common Crawl",
        "authors": "Szymon Roziewski, Marek Kozłowski",
        "published": "2021-12",
        "citations": 3,
        "abstract": "AbstractThe exponential growth of the internet community has resulted in the production of a vast amount of unstructured data, including web pages, blogs and social media. Such a volume consisting of hundreds of billions of words is unlikely to be analyzed by humans. In this work we introduce the tool LanguageCrawl, which allows Natural Language Processing (NLP) researchers to easily build web-scale corpora using the Common Crawl Archive—an open repository of web crawl information, which contains petabytes of data. We present three use cases in the course of this work: filtering of Polish websites, the construction of n-gram corpora and the training of a continuous skipgram language model with hierarchical softmax. Each of them has been implemented within the LanguageCrawl toolkit, with the possibility to adjust specified language and n-gram ranks. This paper focuses particularly on high computing efficiency by applying highly concurrent multitasking. Our tool utilizes effective libraries and design. LanguageCrawl has been made publicly available to enrich the current set of NLP resources. We strongly believe that our work will facilitate further NLP research, especially in under-resourced languages, in which the lack of appropriately-sized corpora is a serious hindrance to applying data-intensive methods, such as deep neural networks.",
        "link": "http://dx.doi.org/10.1007/s10579-021-09551-7"
    },
    {
        "id": 13828,
        "title": "Knowledge Rumination for Pre-trained Language Models",
        "authors": "Yunzhi Yao, Peng Wang, Shengyu Mao, Chuanqi Tan, Fei Huang, Huajun Chen, Ningyu Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.206"
    },
    {
        "id": 13829,
        "title": "Towards more Human-like Language Models based on Contextualizer Pretraining Strategy",
        "authors": "Chenghao Xiao, G Thomas Hudson, Noura Al Moubayed",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-babylm.28"
    },
    {
        "id": 13830,
        "title": "Artificial neural network language models predict human brain responses to language even after a developmentally realistic amount of training",
        "authors": "Eghbal A. Hosseini, Martin Schrimpf, Yian Zhang, Samuel Bowman, Noga Zaslavsky, Evelina Fedorenko",
        "published": "No Date",
        "citations": 10,
        "abstract": "AbstractArtificial neural networks have emerged as computationally plausible models of human language processing. A major criticism of these models is that the amount of training data they receive far exceeds that of humans during language learning. Here, we use two complementary approaches to ask how the models’ ability to capture human fMRI responses to sentences is affected by the amount of training data. First, we evaluate GPT-2 models trained on 1 million, 10 million, 100 million, or 1 billion words against an fMRI benchmark. We consider the 100-million-word model to be developmentally plausible in terms of the amount of training data given that this amount is similar to what children are estimated to be exposed to during the first 10 years of life. Second, we test the performance of a GPT-2 model trained on a 9-billion-token dataset to reach state-of-the-art next-word prediction performance on the human benchmark at different stages during training. Across both approaches, we find that (i) the models trained on a developmentally plausible amount of data already achieve near-maximal performance in capturing fMRI responses to sentences. Further, (ii) lower perplexity—a measure of next-word prediction performance—is associated with stronger alignment with human data, suggesting that models that have received enough training to achieve sufficiently high next-word prediction performance also acquire representations of sentences that are predictive of human fMRI responses. In tandem, these findings establish that althoughsometraining is necessary for the models’ predictive ability, a developmentally realistic amount of training (∼100 million words) may suffice.",
        "link": "http://dx.doi.org/10.1101/2022.10.04.510681"
    },
    {
        "id": 13831,
        "title": "Exploring Teachers' and Students’ Attitudes towards English Language Large Classes at Herat University, Afghanistan",
        "authors": "Ahmad Fawad Kakar, Kawita Sarwari",
        "published": "2022-1-12",
        "citations": 1,
        "abstract": "This study is qualitative research that seeks to investigate the large class teaching challenges and the instructors' coping strategies through the perspectives of five English language instructors of the English Department of Herat University. Furthermore, the perspectives of ten juniors and seniors of the English Department of Herat University on large EFL classes are also explored. The data collected through face-to-face semi-structured interviews were analyzed thematically. In other words, the data were divided into major and sub-themes, considering the study’s theoretical framework-Kumaravadevelu’s post-method pedagogy- and the research questions. The findings indicated that challenges, such as multi-level students, under-resourced context, a large number of students, giving feedback, assessing students, classroom management, and students' engagement, are the challenges behind large classes in Afghanistan. Further, reducing the number of students, providing teachers with capacity-building programs and teaching resources are also discussed.",
        "link": "http://dx.doi.org/10.18196/ftl.v7i1.12281"
    },
    {
        "id": 13832,
        "title": "On the Impact of Language Selection for Training and Evaluating Programming Language Models",
        "authors": "Jonathan Katzy, Maliheh Izadi, Arie van Deursen",
        "published": "2023-10-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/scam59687.2023.00038"
    },
    {
        "id": 13833,
        "title": "Meta Distant Transfer Learning for Pre-trained Language Models",
        "authors": "Chengyu Wang, Haojie Pan, Minghui Qiu, Jun Huang, Fei Yang, Yin Zhang",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.768"
    },
    {
        "id": 13834,
        "title": "WeLT: Improving Biomedical Fine-tuned Pre-trained Language Models with Cost-sensitive Learning",
        "authors": "Ghadeer Mobasher, Wolfgang Müller, Olga Krebs, Michael Gertz",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.bionlp-1.40"
    },
    {
        "id": 13835,
        "title": "Injecting Domain Knowledge in Language Models for Task-oriented Dialogue Systems",
        "authors": "Denis Emelin, Daniele Bonadiman, Sawsan Alqahtani, Yi Zhang, Saab Mansour",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.820"
    },
    {
        "id": 13836,
        "title": "Syllable-aware Neural Language Models: A Failure to Beat Character-aware Ones",
        "authors": "Zhenisbek Assylbekov, Rustem Takhanov, Bagdat Myrzakhmetov, Jonathan N. Washington",
        "published": "2017",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d17-1199"
    },
    {
        "id": 13837,
        "title": "To Bilingualism and Beyond! Modeling Bilingualism Requires Looking Beyond Language: A Commentary on “Computational Modeling of Bilingual Language Learning: Current Models and Future Directions”",
        "authors": "Viorica Marian",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/lang.12530"
    },
    {
        "id": 13838,
        "title": "An Empirical Study of Metrics to Measure Representational Harms in Pre-Trained Language Models",
        "authors": "Saghar Hosseini, Hamid Palangi, Ahmed Hassan Awadallah",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.trustnlp-1.11"
    },
    {
        "id": 13839,
        "title": "Efficient Hierarchical Domain Adaptation for Pretrained Language Models",
        "authors": "Alexandra Chronopoulou, Matthew Peters, Jesse Dodge",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.96"
    },
    {
        "id": 13840,
        "title": "Instructed Language Models with Retrievers Are Powerful Entity Linkers",
        "authors": "Zilin Xiao, Ming Gong, Jie Wu, Xingyao Zhang, Linjun Shou, Daxin Jiang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.139"
    },
    {
        "id": 13841,
        "title": "Federated Learning of N-Gram Language Models",
        "authors": "Mingqing Chen, Ananda Theertha Suresh, Rajiv Mathews, Adeline Wong, Cyril Allauzen, Françoise Beaufays, Michael Riley",
        "published": "2019",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/k19-1012"
    },
    {
        "id": 13842,
        "title": "Pretrained Language Models for Biomedical and Clinical Tasks: Understanding and Extending the State-of-the-Art",
        "authors": "Patrick Lewis, Myle Ott, Jingfei Du, Veselin Stoyanov",
        "published": "2020",
        "citations": 38,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.clinicalnlp-1.17"
    },
    {
        "id": 13843,
        "title": "Code-Switched Language Models Using Neural Based Synthetic Data from Parallel Sentences",
        "authors": "Genta Indra Winata, Andrea Madotto, Chien-Sheng Wu, Pascale Fung",
        "published": "2019",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/k19-1026"
    },
    {
        "id": 13844,
        "title": "Chapter 6. The semantics, syntax and prosody of adverbs in English",
        "authors": "Evelien Keizer",
        "published": "2020-11-15",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/hcp.70.06kei"
    },
    {
        "id": 13845,
        "title": "Compositional matrix-space models of language: Definitions, properties, and learning methods",
        "authors": "Shima Asaadi, Eugenie Giesbrecht, Sebastian Rudolph",
        "published": "2023-1",
        "citations": 0,
        "abstract": "AbstractWe give an in-depth account of compositional matrix-space models (CMSMs), a type of generic models for natural language, wherein compositionality is realized via matrix multiplication. We argue for the structural plausibility of this model and show that it is able to cover and combine various common compositional natural language processing approaches. Then, we consider efficient task-specific learning methods for training CMSMs and evaluate their performance in compositionality prediction and sentiment analysis.",
        "link": "http://dx.doi.org/10.1017/s1351324921000206"
    },
    {
        "id": 13846,
        "title": "Language Diversity, Cross-Cultural Awareness, and Digital Media in the Writing Classroom",
        "authors": "Florence Elizabeth Bacabac",
        "published": "2021-12-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003124665-12"
    },
    {
        "id": 13847,
        "title": "THE CONCEPT OF LANGUAGE TRANSFER AND ITS ROLE IN THIRD LANGUAGE ACQUISITION MODELS",
        "authors": "T Honcharova-Ilina",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32841/2409-1154.2019.43.5.11"
    },
    {
        "id": 13848,
        "title": "Methods for Estimating and Improving Robustness of Language Models",
        "authors": "Michal Stefanik",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-srw.6"
    },
    {
        "id": 13849,
        "title": "Continual Training of Language Models for Few-Shot Learning",
        "authors": "Zixuan Ke, Haowei Lin, Yijia Shao, Hu Xu, Lei Shu, Bing Liu",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.695"
    },
    {
        "id": 13850,
        "title": "Explaining Data Patterns in Natural Language with Language Models",
        "authors": "Chandan Singh, John X. Morris, Jyoti Aneja, Alexander Rush, Jianfeng Gao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.blackboxnlp-1.3"
    },
    {
        "id": 13851,
        "title": "Towards Low-Resource Automatic Program Repair with Meta-Learning and Pretrained Language Models",
        "authors": "Weishi Wang, Yue Wang, Steven Hoi, Shafiq Joty",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.430"
    },
    {
        "id": 13852,
        "title": "Modeling Second Language Acquisition with pre-trained neural language models",
        "authors": "Álvaro J. Jiménez Palenzuela, Flavius Frasincar, Maria Mihaela Truşcǎ",
        "published": "2022-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.eswa.2022.117871"
    },
    {
        "id": 13853,
        "title": "MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions",
        "authors": "Zexuan Zhong, Zhengxuan Wu, Christopher Manning, Christopher Potts, Danqi Chen",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.971"
    },
    {
        "id": 13854,
        "title": "On the effect of dropping layers of pre-trained transformer models",
        "authors": "Hassan Sajjad, Fahim Dalvi, Nadir Durrani, Preslav Nakov",
        "published": "2023-1",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2022.101429"
    },
    {
        "id": 13855,
        "title": "ReGen: Reinforcement Learning for Text and Knowledge Base Generation using Pretrained Language Models",
        "authors": "Pierre Dognin, Inkit Padhi, Igor Melnyk, Payel Das",
        "published": "2021",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.83"
    },
    {
        "id": 13856,
        "title": "X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained Language Models",
        "authors": "Zhengbao Jiang, Antonios Anastasopoulos, Jun Araki, Haibo Ding, Graham Neubig",
        "published": "2020",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.479"
    },
    {
        "id": 13857,
        "title": "Models of Variable Form Acquisition Should Be Informed by Cross-Dialect Studies of Children with and without Developmental Language Disorder (DLD)",
        "authors": "Janna B. Oetting",
        "published": "2024-1-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/15475441.2023.2239802"
    },
    {
        "id": 13858,
        "title": "Chapter 2. Dual process frameworks on reasoning and linguistic discourse",
        "authors": "Bernd Heine, Tania Kuteva, Haiping Long",
        "published": "2020-11-15",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/hcp.70.02hei"
    },
    {
        "id": 13859,
        "title": "Divisive Language and Propaganda Detection using Multi-head Attention Transformers with Deep Learning BERT-based Language Models for Binary Classification",
        "authors": "Norman Mapes, Anna White, Radhika Medury, Sumeet Dua",
        "published": "2019",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-5014"
    },
    {
        "id": 13860,
        "title": "Using Communication Models to Teach ELLs Science",
        "authors": "Alandeom W. Oliveira, Molly H. Weinburgh",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-02245-7_16"
    },
    {
        "id": 13861,
        "title": "Chapter 4. Dual processing in a functional-cognitive theory of grammar and its neurocognitive basis",
        "authors": "Kasper Boye, Peter Harder",
        "published": "2020-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/hcp.70.04boy"
    },
    {
        "id": 13862,
        "title": "A Simple and Effective Method for Injecting Word-level Information into Character-aware Neural Language Models",
        "authors": "Yukun Feng, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.30.156"
    },
    {
        "id": 13863,
        "title": "Deep learning models to study sentence comprehension in the human brain",
        "authors": "Sophie Arana, Jacques Pesnot Lerousseau, Peter Hagoort",
        "published": "2023-4-18",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/23273798.2023.2198245"
    },
    {
        "id": 13864,
        "title": "Language Models as Knowledge Bases?",
        "authors": "Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander Miller",
        "published": "2019",
        "citations": 330,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-1250"
    },
    {
        "id": 13865,
        "title": "Model Sensemaking Strategies: Exploiting Meta-Model Patterns to Understand Large Models",
        "authors": "Francisco Martínez-Lasaca, Pablo Díez, Esther Guerra, Juan de Lara",
        "published": "2023-10-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/models58315.2023.00023"
    },
    {
        "id": 13866,
        "title": "Don’t Prompt, Search! Mining-based Zero-Shot Learning with Language Models",
        "authors": "Mozes van de Kar, Mengzhou Xia, Danqi Chen, Mikel Artetxe",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.509"
    },
    {
        "id": 13867,
        "title": "Using Captum to Explain Generative Language Models",
        "authors": "Vivek Miglani, Aobo Yang, Aram Markosyan, Diego Garcia-Olano, Narine Kokhlikyan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.nlposs-1.19"
    },
    {
        "id": 13868,
        "title": "Distilling the Knowledge of Large-scale Generative Models into Retrieval Models for Efficient Open-domain Conversation",
        "authors": "Beomsu Kim, Seokjun Seo, Seungju Han, Enkhbayar Erdenee, Buru Chang",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-emnlp.286"
    },
    {
        "id": 13869,
        "title": "TrueChange (TM) Under the Hood: How We Check the Consistency of Large Models (Almost) Instantly",
        "authors": "Hugo Lourenco, Rui Eugenio",
        "published": "2019-9",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/models-c.2019.00056"
    },
    {
        "id": 13870,
        "title": "Models for Differentiating Instruction Using English Language Arts — Informational Texts",
        "authors": "Tamra Stambaugh, Emily Mofield",
        "published": "2022-3-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003238515-4"
    },
    {
        "id": 13871,
        "title": "Melanocortin-1 receptor mutations and pigmentation: Insights from large animals",
        "authors": "Ren-Lei Ji, Ya-Xiong Tao",
        "published": "2022",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/bs.pmbts.2022.03.001"
    },
    {
        "id": 13872,
        "title": "Automating Opinion Extraction from Semi-Structured Webpages: Leveraging Language Models and Instruction Finetuning on Synthetic Data",
        "authors": "Dawid Plaskowski, Szymon Skwarek, Dominika Grajewska, Maciej Niemir, Agnieszka Ławrynowicz",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012384900003636"
    },
    {
        "id": 13873,
        "title": "ENTRUST: Argument Reframing with Language Models and Entailment",
        "authors": "Tuhin Chakrabarty, Christopher Hidey, Smaranda Muresan",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.394"
    },
    {
        "id": 13874,
        "title": "A Study on Accessing Linguistic Information in Pre-Trained Language Models by Using Prompts",
        "authors": "Marion Di Marco, Katharina Hämmerl, Alexander Fraser",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.454"
    },
    {
        "id": 13875,
        "title": "Adaptive Gating in Mixture-of-Experts based Language Models",
        "authors": "Jiamin Li, Qiang Su, Yitao Yang, Yimin Jiang, Cong Wang, Hong Xu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.217"
    },
    {
        "id": 13876,
        "title": "HONEST: Measuring Hurtful Sentence Completion in Language Models",
        "authors": "Debora Nozza, Federico Bianchi, Dirk Hovy",
        "published": "2021",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.191"
    },
    {
        "id": 13877,
        "title": "Do language models have coherent mental models of everyday things?",
        "authors": "Yuling Gu, Bhavana Dalvi Mishra, Peter Clark",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.106"
    },
    {
        "id": 13878,
        "title": "Demand forecasting: AI-based, statistical and hybrid models vs practice-based models - the case of SMEs and large enterprises",
        "authors": "Andrea Kolková, Aleksandr Ključnikov",
        "published": "2022-12",
        "citations": 5,
        "abstract": "Demand forecasting is one of the biggest challenges of post-pandemic logistics. It appears that logistics management based on demand prediction can be a suitable alternative to the just-in-time concept. This study aims to identify the effectiveness of AI-based and statistical forecasting models versus practice-based models for SMEs and large enterprises in practice. The study compares the effectiveness of the practice-based Prophet model with the statistical forecasting models, models based on artificial intelligence, and hybrid models developed in the academic environment. Since most of the hybrid models, and the ones based on artificial intelligence, were developed within the last ten years, the study also answers the question of whether the new models have better accuracy than the older ones. The models are evaluated using a multicriteria approach with different weight settings for SMEs and large enterprises. The results show that the Prophet model has higher accuracy than the other models on most time series. At the same time, the Prophet model is slightly less computationally demanding than hybrid models and models based on artificial neural networks. On the other hand, the results of the multicriteria evaluation show that while statistical methods are more suitable for SMEs, the prophet forecasting method is very effective in the case of large enterprises with sufficient computing power and trained predictive analysts.",
        "link": "http://dx.doi.org/10.14254/2071-789x.2022/15-4/2"
    },
    {
        "id": 13879,
        "title": "Construction Quality Problems and Control Strategies of Large-scale Water Diversion Project",
        "authors": "",
        "published": "2022-1-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i1.112"
    },
    {
        "id": 13880,
        "title": "Large-scale Assessment",
        "authors": "Denise E. Murray, MaryAnn Christison",
        "published": "2020-2-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429275739-15"
    },
    {
        "id": 13881,
        "title": "Study on Construction Quality Evaluation of Railway Large-scale Road Maintenance Machinery",
        "authors": "",
        "published": "2021-8-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i8.215"
    },
    {
        "id": 13882,
        "title": "Realization Method for Precision Correction of Large I-shaped Aluminum Alloy Plate",
        "authors": "",
        "published": "2022-2-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i2.709"
    },
    {
        "id": 13883,
        "title": "LncPNdeep: A long non-coding RNA classifier based on Large Language Model with peptide and nucleotide embedding",
        "authors": "Zongrui Dai, Feiyang Deng",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractLong non-coding RNA plays an important role in various gene transcription and peptide interactions. Classifying lncRNAs from coding RNA is a crucial step in bioinformatics analysis which seriously affects the post-analysis for transcriptome annotation. Although several machine learning-based methods were developed to classify lncRNAs, these methods were mainly focused on nucleotide features without considering the information from the peptide sequence. To integrate both nucleotide and peptide information in lncRNA classification, one efficient deep learning is desired. In this study, we developed one concatenated deep neural network named LncPNdeep to combine this information. LncPNdeep incorporates both peptide and nucleotide embedding from masked language modeling (MLM), being able to discover complex associations between sequence information and lncRNA classification. LncPNdeep achieves state-of-the-art performance in the human transcript database compared with other existing methods (Accuracy=97.1%). It also exhibits superior generalization ability in cross-species comparison, maintaining consistent accuracy and F1 scores compared to other methods. The combination of nucleotide and peptide information makes LncPNdeep able to facilitate the identification of novel lncRNA and gain high accuracy for classification. Our code is available athttps://github.com/yatoka233/LncPNdeep",
        "link": "http://dx.doi.org/10.1101/2023.11.29.569323"
    },
    {
        "id": 13884,
        "title": "Stacked Language Models for an Optimized Next Word Generation",
        "authors": "Ednah Olubunmi Aliyu, Eduan Kotze",
        "published": "2022-5-16",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/ist-africa56635.2022.9845545"
    },
    {
        "id": 13885,
        "title": "Theoretical Models of English as a World Language",
        "authors": "Sarah Buschfeld, Alexander Kautzsch",
        "published": "2019-12-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108349406.003"
    },
    {
        "id": 13886,
        "title": "Front Matter",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.fmatter"
    },
    {
        "id": 13887,
        "title": "Textual Communities",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.6"
    },
    {
        "id": 13888,
        "title": "Text Classification for Marketing Research Using Pre-Trained General Language Models",
        "authors": "David Dornekott",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3932205"
    },
    {
        "id": 13889,
        "title": "Language Design with Intent",
        "authors": "Vadim Zaytsev",
        "published": "2017-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/models.2017.16"
    },
    {
        "id": 13890,
        "title": "Formal Models Based on Unification",
        "authors": "Zhiwei Feng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-5172-4_4"
    },
    {
        "id": 13891,
        "title": "Formal Models of Probabilistic Grammar",
        "authors": "Zhiwei Feng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-5172-4_10"
    },
    {
        "id": 13892,
        "title": "9 Language Classification and Models of Linguistic Change",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9781474463133-015"
    },
    {
        "id": 13893,
        "title": "Structure-informed Language Models Are Protein Designers",
        "authors": "Zaixiang Zheng, Yifan Deng, Dongyu Xue, Yi Zhou, Fei Ye, Quanquan Gu",
        "published": "No Date",
        "citations": 11,
        "abstract": "AbstractThis paper demonstrates that language models are strong structure-based protein designers. We present LM-Design, a generic approach to reprogramming sequence-based protein language models (pLMs), that have learned massive sequential evolutionary knowledge from the universe of natural protein sequences, to acquire an immediate capability to design preferable protein sequences for given folds. We conduct astructural surgeryonpLMs, where a lightweight structural adapter is implanted intopLMs and endows it with structural awareness. During inference, iterative refinement is performed to effectively optimize the generated protein sequences. Experiments show that LM-Designimproves the state-of-the-art results by a large margin, leading to 4% to 12% accuracy gains in sequence recovery (e.g., 55.65%/56.63% on CATH 4.2/4.3 single-chain benchmarks, and>60% when designing protein complexes). We provide extensive and in-depth analyses, which verify that LM-Designcan (1) indeed leverage both structural and sequential knowledge to accurately handle structurally non-deterministic regions, (2) benefit from scaling data and model size, and (3) generalize to other proteins (e.g., antibodies andde novoproteins).",
        "link": "http://dx.doi.org/10.1101/2023.02.03.526917"
    },
    {
        "id": 13894,
        "title": "Peer Review #1 of \"The neural machine translation models for the low-resource Kazakh–English language pair (v0.3)\"",
        "authors": "R Mendoza",
        "published": "2023-2-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.1224v0.3/reviews/1"
    },
    {
        "id": 13895,
        "title": "Comparing drought simulation performance from large-scale and locally set up hydrological models for large mountainous rivers in Switzerland",
        "authors": "Annie Y.-Y. Chang, Konrad Bogner, Maria-Helena Ramos, Shaun Harrigan, Daniela I.V. Domeisen, Massimiliano Zappa",
        "published": "No Date",
        "citations": 0,
        "abstract": "Historically, Switzerland and the nearby alpine countries have not been associated with major droughts. However, in recent years, the European Alpine space has experienced several unprecedented low-flow conditions and drought events. As many economic sectors in the region depend heavily on sufficient water availability, such as hydropower production, navigation and transportation, agriculture, and tourism, it is important for decision-makers to have early warnings of drought tailored to their needs and geographical conditions.The European Flood Awareness System (EFAS) has been in operation since 2012 providing flood risk overviews for Europe up to 15 days in advance. More recently, it has also run long-range hydrological outlooks for sub-seasonal to seasonal horizons. While EFAS early flood warnings have been extensively evaluated in the past years, less attention has been paid to evaluating the system&#8217;s ability to detect upcoming drought conditions. In this study, we turn our focus to this other extreme of the spectrum and on EFAS&#8217; predictability of drought events in large Alpine catchments. Our goal is to investigate how hydrological patterns of skill at a large spatial scale can be combined with local model outputs to more accurately inform decision makers on droughts and their spatio-temporal evolution.For this, we evaluate the performance of EFAS comparatively to that of a local model in terms of the ability to simulate drought conditions. The Precipitation-Runoff-Evapotranspiration HRU (PREVAH) local model was set up for 59 stations in Switzerland. The PREVAH model is a distributed conceptual hydrological model that accounts for processes such as evapotranspiration, interception, snow- and ice-melt, soil moisture storage, groundwater storage, and runoff generation. We analyse 25 overlapping stations between the local model and the EFAS reporting stations (river network points where EFAS outputs are available to users), and compare the drought simulation performances of the two models. We focus on evaluating the duration, deficit, and magnitude of the drought events, as well as metrics including Nash&#8211;Sutcliffe model efficiency coefficient (NSE) and Kling-Gupta efficiency (KGE).The outcome of this study will lay a foundation for how a large-scale hydrological model like EFAS can complement a local model like PREVAH to improve the predictability of sub-seasonal drought forecasting and provide more reliable early warnings for better water resources management.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-12694"
    },
    {
        "id": 13896,
        "title": "Chapter 3. Testing the current models of third language acquisition",
        "authors": "Roumyana Slabakova, María del Pilar García Mayo",
        "published": "2017-8-4",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/bpa.5.04sla"
    },
    {
        "id": 13897,
        "title": "Back Matter",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.13"
    },
    {
        "id": 13898,
        "title": "Hardware estimator for HDL language",
        "authors": "Sangeetha Marikkannnan",
        "published": "2017-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icammaet.2017.8186659"
    },
    {
        "id": 13899,
        "title": "Variable Language Models",
        "authors": "Stefan Sobernig",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-42152-6_3"
    },
    {
        "id": 13900,
        "title": "An Extensive Analysis Between Different Language Models: GPT-3, BERT and MACAW",
        "authors": "Arya Gaikwad, Palash Rambhia, Sarthak Pawar",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe increase in human interactions with commercial applications has given rise to the demand for Interactive interfaces like chat- bots, text translators, text predictors, and text generators which use pre-trained Language Models to perform their own specific tasks. Language models are leading-edge technologies that enable machines to read, decode, comprehend, and make sense of human languages and respond in appropriate ways. In this paper GPT-3, BERT and Macaw language models are tested on different categorial questions to understand their architecture and behaviour in various circumstances. GPT-3 being pre-trained on a robust dataset gives very elaborate and human like answers, while the outputs produced by BERT can be customised by providing custom context and on the other hand Macaw shows more accuracy while answering to general questions.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2155616/v1"
    },
    {
        "id": 13901,
        "title": "Efficient and accurate sequence generation with small-scale protein language models",
        "authors": "Yaiza Serrano, Sergi Roda, Victor Guallar, Alexis Molina",
        "published": "No Date",
        "citations": 1,
        "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities in understanding contextual relationships, outperforming traditional methodologies in downstream tasks such as text generation and sentence classification. This success has been mirrored in the realm of protein language models (pLMs), where proteins are encoded as text via their amino acid sequences. However, the training of pLMs, which involves tens to hundreds of millions of sequences and hundreds of millions to billions of parameters, poses a significant computational challenge.In this study, we introduce a Small-Scale Protein Language Model (SS-pLM), a more accessible approach that requires training on merely millions of representative sequences, reducing the number of trainable parameters to 14.8M. This model significantly reduces the computational load, thereby democratizing the use of foundational models in protein studies. We demonstrate that the performance of our model, when fine-tuned to a specific set of sequences for generation, is comparable to that of larger, more computationally demanding pLM.",
        "link": "http://dx.doi.org/10.1101/2023.08.04.551626"
    },
    {
        "id": 13902,
        "title": "Pretrained language models and weight redistribution achieve precise<i>k</i><sub>cat</sub>prediction",
        "authors": "Han Yu, Xiaozhou Luo",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractThe enzyme turnover number (kcat) is a meaningful and valuable kinetic parameter, reflecting the catalytic efficiency of an enzyme to a specific substrate, which determines the global proteome allocation, metabolic fluxes and cell growth. Here, we present a precisekcatprediction model (PreKcat) leveraging pretrained language models and a weight redistribution strategy. PreKcat significantly outperforms the previouskcatprediction method in terms of various evaluation metrics. We also confirmed the ability of PreKcat to discriminate enzymes of different metabolic contexts and different types. Additionally, the proposed weight redistribution strategies effectively reduce the prediction error of highkcatvalues and capture minor effects of amino acid substitutions on two crucial enzymes of the naringenin synthetic pathway, leading to obvious distinctions. Overall, the presentedkcatprediction model provides a valuable tool for deciphering the mechanisms of enzyme kinetics and enables novel insights into enzymology and biomedical applications.",
        "link": "http://dx.doi.org/10.1101/2022.11.23.517595"
    },
    {
        "id": 13903,
        "title": "Language and Culture: Multiculturalism Models",
        "authors": "A Khalifa",
        "published": "2022",
        "citations": 0,
        "abstract": "The paper begins by introducing the conception of language and culture, and considers the connection between the two through the three presumptive connections encouraged by Wardhaugh: language structure determines language operation, artistic values determine the way we use language, and the claim that a relationship between the two does not live. In the ultimate part of the paper, the counteraccusations of such a relationship are bandied as they pertain to language education and policy. With first language learners immersed in their own culture, connections between language and culture frequently no way come to question. For foreign language learners, where true artistic complications and understandings are positioned well beyond the text, an understanding of language assumes a veritably different form. While it is possible to separate language and culture, one must question the validity and counteraccusations similar separation brings. The significance of artistic faculty is also considered for its relevance to language education and the counteraccusations it holds for language literacy and policy. The final part concludes the specifics of the four multiculturalism models, i.e., multiculturalism education, cultural integration, context for choice, and cultural language. Focusing on the multiculturalism models, it is presented how each model may contribute to business and corporations rather than discuss the philosophical stance of multiculturalism, influence on communication, and exemplify the methodologies for multicultural education. Nevertheless, the important role of multiculturalism is endorsed for language learners and all those involved in language education.",
        "link": "http://dx.doi.org/10.31548/philolog13(4_1).2022.010"
    },
    {
        "id": 13904,
        "title": "Lexical Speaker Error Correction: Leveraging Language Models for Speaker Diarization Error Correction",
        "authors": "Rohit Paturi, Sundararajan Srinivasan, Xiang Li",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1982"
    },
    {
        "id": 13905,
        "title": "The True and the False",
        "authors": "Mascha Kurpicz-Briki",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-37690-0_5"
    },
    {
        "id": 13906,
        "title": "DNA language models are powerful predictors of genome-wide variant effects",
        "authors": "Gonzalo Benegas, Sanjit Singh Batra, Yun S. Song",
        "published": "No Date",
        "citations": 13,
        "abstract": "AbstractThe expanding catalog of genome-wide association studies (GWAS) provides biological insights across a variety of species, but identifying the causal variants behind these associations remains a significant challenge. Experimental validation is both labor-intensive and costly, highlighting the need for accurate, scalable computational methods to predict the effects of genetic variants across the entire genome. Inspired by recent progress in natural language processing, unsupervised pre-training on large protein sequence databases has proven successful in extracting complex information related to proteins. These models showcase their ability to learn variant effects in coding regions using an unsupervised approach. Expanding on this idea, we here introduce theGenomicPre-trainedNetwork (GPN), a model designed to learn genome-wide variant effects through unsupervised pre-training on genomic DNA sequences. Our model also successfully learns gene structure and DNA motifs without any supervision. To demonstrate its utility, we train GPN onunalignedreference genomes ofArabidopsis thalianaand seven related species within the Brassicales order, and evaluate its ability to predict the functional impact of genetic variants inArabidopsis thalianaby utilizing allele frequencies from the 1001 Genomes Project and a comprehensive database of GWAS. Notably, GPN outperforms predictors based on popular conservation scores such as phyloP and phastCons. Our predictions forArabidopsis thalianacan be visualized as sequence logos in the UCSC Genome Browser (https://genome.ucsc.edu/s/gbenegas/gpn-arabidopsis). We provide code (https://github.com/songlab-cal/gpn) to train GPN for any given species using its DNA sequence alone, enabling unsupervised prediction of variant effects across the entire genome.",
        "link": "http://dx.doi.org/10.1101/2022.08.22.504706"
    },
    {
        "id": 13907,
        "title": "eLife assessment: Sensitive remote homology search by local alignment of small positional embeddings from protein language models",
        "authors": "Alan M Moses",
        "published": "2024-2-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.91415.2.sa1"
    },
    {
        "id": 13908,
        "title": "Perplexity-based molecule ranking and bias estimation of chemical language models",
        "authors": "Michael Moret, Francesca Grisoni, Paul Katzberger, Gisbert Schneider",
        "published": "No Date",
        "citations": 0,
        "abstract": "Chemical language models (CLMs) can be employed to design molecules with desired properties. CLMs generate new chemical structures in the form of textual representations, such as the simplified molecular input line entry systems (SMILES) strings, in a rule-free manner. However, the quality of these de novo generated molecules is difficult to assess a priori. In this study, we apply the perplexity metric to determine the degree to which the molecules generated by a CLM match the desired design objectives. This model-intrinsic score allows identifying and ranking the most promising molecular designs based on the probabilities learned by the CLM. Using perplexity to compare “greedy” (beam search) with “explorative” (multinomial sampling) methods for SMILES generation, certain advantages of multinomial sampling become apparent. Additionally, perplexity scoring is performed to identify undesired model biases introduced during model training and allows the development of a new ranking system to remove those undesired biases.",
        "link": "http://dx.doi.org/10.33774/chemrxiv-2021-zv6f1-v2"
    },
    {
        "id": 13909,
        "title": "Do Neural Language Models Overcome Reporting Bias?",
        "authors": "Vered Shwartz, Yejin Choi",
        "published": "2020",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.coling-main.605"
    },
    {
        "id": 13910,
        "title": "Exploration on Geological Prospecting Technology and Innovation in Large-scale Mineral Exploration",
        "authors": "",
        "published": "2022-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/ns.v3i2.047"
    },
    {
        "id": 13911,
        "title": "Automated Scoring of Open-Ended Question Complexity: A Large Language Model Approach",
        "authors": "Tuval Raz, Simone Luchini, Roger Beaty, Yoed Kenett",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nQuestion-asking, an essential yet often understudied activity, holds significant implications for learning, creativity, and cognitive development. In particular, the quality and complexity of the questions asked are crucial factors affecting these fields. Previous research has explored open-ended question complexity through frameworks like the Bloom taxonomy of cognitive objectives, but the measurement of complexity remains challenging. Recent advancements in natural language processing have enabled automated scoring of psychological tasks, notably predicting human ratings of creativity. Although some methods have been applied to measure question complexity, there has been scarce research so far on the automatic assessment of open-ended questions. Here, we address this gap by employing a Large Language Model (LLM) to accurately predict human ratings of open-ended question complexity based on the Bloom taxonomy and comparing these predictions to existing baseline measures such as semantic distance and word count. Specifically, this study capitalized on previously collected human-rated responses from a creative question-asking task to train an LLM for scoring questions based on the Bloom taxonomy of complexity. Our results reveal that our LLM-generated Bloom scores correlated strongly with human ratings of complexity (r = .73), whilst also greatly exceeding tested  baseline measures. Our study emphasizes the significance of LLM in automating the assessment of open-ended question complexity, fostering cost-effective, automatic, and reliable measurements in this domain. Our study further highlights the exciting possibilities for the continued usage of LLM in education and psychology and their potential in helping study how we ask creative questions.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3890828/v1"
    },
    {
        "id": 13912,
        "title": "Portfolio Construction with News Sentiment using Large Language Model",
        "authors": "Qi Zhang, Jianxin Wang, Wei Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4454949"
    },
    {
        "id": 13913,
        "title": "Models of Managerialism",
        "authors": "Thomas Klikauer",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-16379-1_2"
    },
    {
        "id": 13914,
        "title": "Self-trained Pretrained Language Models for Evidence Detection",
        "authors": "Mohamed Elaraby, Diane Litman",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.argmining-1.14"
    },
    {
        "id": 13915,
        "title": "MuLan-Methyl - Multiple Transformer-based Language Models for Accurate DNA Methylation Prediction",
        "authors": "Wenhuan Zeng, Anupam Gautam, Daniel H. Huson",
        "published": "No Date",
        "citations": 3,
        "abstract": "AbstractTransformer-based language models are successfully used to address massive text-related tasks. DNA methylation is an important epigenetic mechanism and its analysis provides valuable insights into gene regulation and biomarker identification. Several deep learning-based methods have been proposed to identify DNA methylation and each seeks to strike a balance between computational effort and accuracy. Here, we introduce MuLan-Methyl, a deep-learning framework for predicting DNA methylation sites, which is based on five popular transformer-based language models. The framework identifies methylation sites for three different types of DNA methylation, namely N6-adenine, N4-cytosine, and 5-hydroxymethylcytosine. Each of the employed language models is adapted to the task using the “pre-train and fine-tune” paradigm. Pre-training is performed on a custom corpus of DNA fragments and taxonomy lineages using self-supervised learning. Fine-tuning aims at predicting the DNA-methylation status of each type. The five models are used to collectively predict the DNA methylation status. We report excellent performance of MuLan-Methyl on a benchmark dataset. Moreover, we argue that the model captures characteristic differences between different species that are relevant for methylation. This work demonstrates that language models can be successfully adapted to applications in biological sequence analysis and that joint utilization of different language models improves model performance. Mulan-Methyl is open source and we provide a web server that implements the approach.Key pointsMuLan-Methyl aims at identifying three types of DNA-methylation sites.It uses an ensemble of five transformer-based language models, which were pre-trained and fine-tuned on a custom corpus.The self-attention mechanism of transformers give rise to importance scores, which can be used to extract motifs.The method performs favorably in comparison to existing methods.The implementation can be applied to chromosomal sequences to predict methylation sites.",
        "link": "http://dx.doi.org/10.1101/2023.01.04.522704"
    },
    {
        "id": 13916,
        "title": "Transformer-Based Multilingual Language Models in Cross-Lingual Plagiarism Detection",
        "authors": "Tatevik Ter-Hovhannisyan, Karen Avetisyan",
        "published": "2022-9-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ivmem57067.2022.9983968"
    },
    {
        "id": 13917,
        "title": "Analysis of Ecological Rehabilitation Models of Mines in Chaoyang City",
        "authors": "",
        "published": "2022-8-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/ns.v3i8(02).43"
    },
    {
        "id": 13918,
        "title": "Applications and Their Perspectives in General",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_13"
    },
    {
        "id": 13919,
        "title": "Enhancing Emotion Extraction Accuracy in Fine-Tuned Language Models Using Heterogeneous Neural Networks",
        "authors": "Abbas Maazallahi, Masoud Asadpour, Parisa Bazmi",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4606492"
    },
    {
        "id": 13920,
        "title": "Generative models, language and active inference",
        "authors": "Karl Friston, Thomas Parr, Yan Yufik, Noor Sajid, Cathy J. Price, Emma Holmes",
        "published": "No Date",
        "citations": 1,
        "abstract": "This paper presents a biologically plausible generative model and inference scheme that is capable of simulating the generation and comprehension of language, when synthetic subjects talk to each other. Building on active inference formulations of dyadic interactions, we simulate linguistic exchange to explore generative models that support dialogues. These models employ high-order interactions among abstract (discrete) states in deep (hierarchical) models. The sequential nature of language processing mandates generative models with a particular factorial structure—necessary to accommodate the rich combinatorics of language. We illustrate this by simulating a synthetic subject who can play the ‘Twenty Questions’ game. In this game, synthetic subjects take the role of the questioner or answerer, using the same generative model. This simulation setup is used to illustrate some key architectural points and demonstrate that many behavioural and neurophysiological correlates of language processing emerge under variational (marginal) message passing, given the right kind of generative model. For example, we show that theta-gamma coupling is an emergent property of belief updating, when listening to another.",
        "link": "http://dx.doi.org/10.31234/osf.io/4j2k6"
    },
    {
        "id": 13921,
        "title": "TalkToModel: Explaining Machine Learning Models with Interactive Natural Language Conversations",
        "authors": "Dylan Slack, Satyapriya Krishna, Himabindu Lakkaraju, Sameer Singh",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nPractitioners increasingly use machine learning (ML) models, yet they have become more complex and harder to understand. To address this issue, researchers have proposed techniques to explain model predictions. However, practitioners struggle to use explainability methods because they do not know which to choose and how to interpret the results. We address these challenges by introducing TalkToModel: an interactive dialogue system that enables users to explain ML models through natural language conversations. TalkToModel comprises three components: 1) an adaptive dialogue engine that interprets natural language and generates meaningful responses, 2) an execution component, which constructs the explanations used in the conversation, 3) a conversational interface. In real-world evaluations, 73% of healthcare workers agreed they would use TalkToModel over existing systems for understanding a disease prediction model, and 85% of ML professionals agreed TalkToModel was easier to use, demonstrating that TalkToModel is highly effective for model explainability.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2129845/v1"
    },
    {
        "id": 13922,
        "title": "Towards A Unified View of Sparse Feed-Forward Network in Pretraining Large Language Model",
        "authors": "Zeyu Liu, Tim Dettmers, Xi Lin, Veselin Stoyanov, Xian Li",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.930"
    },
    {
        "id": 13923,
        "title": "A large amount of exceptions",
        "authors": "Laurie Bauer",
        "published": "2021-8-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003148999-6"
    },
    {
        "id": 13924,
        "title": "Research and Application of Large Section Chamber Supporting Technology in Coal Mine",
        "authors": "",
        "published": "2021-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i10.410"
    },
    {
        "id": 13925,
        "title": "Repair Technology and Control of Foundation Quality Defects of Large Wind Turbine",
        "authors": "",
        "published": "2022-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i5(09).04"
    },
    {
        "id": 13926,
        "title": "Discussion on the Installation and Debugging Method of Large Compressor Control System",
        "authors": "",
        "published": "2021-5-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i5.117"
    },
    {
        "id": 13927,
        "title": "Facilitating Human-Robot Interaction through Emotional Control: A Case Study of Optimus and Large Language Model Chatbots",
        "authors": "Abraham Thomas",
        "published": "No Date",
        "citations": 0,
        "abstract": "The unveiling of Optimus, the Tesla Bot, has raised concerns about the potential risks associated with humanoid robots. However, Tesla has yet to reveal how Optimus will interact with humans. This paper advocates for the integration of chatbots, based on large language models, into Optimus to facilitate human interaction. The paper argues that human brains operate as pattern recognition systems and that emotions serve as control algorithms that enable social coexistence. The current state of chatbot interactions is discussed, highlighting their emphasis on realism and practicality, rather than amicable social living. The paper elucidates the role of emotions in the brain, specifically the use of fear and compassion as fail-safe controls for communal living. Fear and compassion have been instrumental in preventing deadly conflicts, allowing billions of humans to coexist peacefully. This paper proposes that the chatbots utilized by Optimus prioritize emotional control to align with human values and objectives.",
        "link": "http://dx.doi.org/10.31219/osf.io/qf8bt"
    },
    {
        "id": 13928,
        "title": "The Problem of Continuous Large-Scale Grid-Connected Consumption of New Energy",
        "authors": "",
        "published": "2022-8-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i8(03).11"
    },
    {
        "id": 13929,
        "title": "PersianLLaMA: Towards Building First Persian Large Language Model",
        "authors": "Mohammad Amin Abbasi, Arash Ghafouri, Mahdi Firouzmandi, Hassan Naderi, Behrouz Minaei Bidgoli",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nDespite the widespread use of the Persian language by millions globally, limited efforts have been made in natural language processing for this language. The use of large language models as effective tools in various natural language processing tasks typically requires extensive textual data and robust hardware resources. Consequently, the scarcity of Persian textual data and the unavailability of powerful hardware resources have hindered the development of large language models for Persian. This paper introduces the first large Persian language model, named PersianLLaMA, trained on a collection of Persian texts and datasets. This foundational model comes in two versions, with 7 and 13 billion parameters, trained on formal and colloquial Persian texts using two different approaches. PersianLLaMA has been evaluated for natural language generation tasks based on the latest evaluation methods, namely using larger language models, and for natural language understanding tasks based on automated machine metrics. The results indicate that PersianLLaMA significantly outperforms its competitors in both understanding and generating Persian text. PersianLLaMA marks an important step in the development of Persian natural language processing and can be a valuable resource for the Persian-speaking community. This large language model can be used for various natural language processing tasks, especially text generation like chatbots, question-answering, machine translation, and text summarization.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3789059/v1"
    },
    {
        "id": 13930,
        "title": "Large Language Model Based Fake News Detection",
        "authors": "Mussa Aman",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.procs.2023.12.144"
    },
    {
        "id": 13931,
        "title": "Task-Based Language Assessment for Large-Scale and Classroom-Based Oral and Print Assessments",
        "authors": "Lina Mukhopadhyay, N. P. Sudharshana",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-4226-5_11"
    },
    {
        "id": 13932,
        "title": "Morphology-based vs Unsupervised Word Clustering for Training Language Models for Serbian",
        "authors": "",
        "published": "2019-5-16",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.12700/aph.16.2.2019.2.11"
    },
    {
        "id": 13933,
        "title": "Language models explain word reading times better than empirical predictability",
        "authors": "Markus J. Hofmann, Steffen Remus, Chris Biemann, Ralph Radach",
        "published": "No Date",
        "citations": 0,
        "abstract": "While word predictability from sentence context is typically investigated by cloze completion probabilities (CCP), it can be more deeply understood by relying on language models (LMs), allowing to define the three key components of memory: Memory starts with experience as implemented by a text corpus, here defined by Wikipedia capturing general knowledge and (movie) subtitles approximating social interactions. LMs then consolidate a long-term memory structure from experience, as addressed by n-gram, topics and recurrent neural network (RNN) models. Retrieval was investigated by predicting fixation durations from an English and a German reading sample. Item-level regressions showed greater correlations of LMs with single-fixation duration (SFD), gaze duration (GD) and total viewing time (TVT) than CCP. When predicting each fixation case separately using generalized additive models, three LMs together always performed better than CCP. When testing single LMs against the typically-sized English CCP sample (N = 30), LMs usually performed better than CCP (8 vs. 3). The larger German CCP sample (N = 272), however, often performed better than single LMs (4 vs. 2). Subtitles-trained n-gram probabilities of present (and last) words allowed for reliable predictions of all fixation durations. Wikipedia-trained topic probabilities of the last and present word allow for reliable predictions of late GD and TVT effects. The present word predictions of RNNs were less sensitive to training-corpus choice and are recommendable if a single LM is used. Moreover, its reliable next word probability effects make it most suitable to address parafoveal preview and top-down predictions.",
        "link": "http://dx.doi.org/10.31234/osf.io/u43p7"
    },
    {
        "id": 13934,
        "title": "Evaluation of Transformer-Based Neural Language Models for Writing Feedback and Automated Essay Scoring",
        "authors": "Temesgen Abraha, Amril Nazir",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nWriting remains a challenging skill for many students due to inadequate feedback tools. There is a need to develop more effective tools for supporting students’ writing skill development. This study aims to evaluate the effectiveness of transformer-based neural language models for assessing and automatically scoring argumentative essays written by 8th-12th grade English Language Learners (ELLs). The students’ English essays were assessed and scored based on six criteria, including cohesion, syntax, vocabulary, phraseology, grammar, and conventions. The models were trained on real teacher feedback from 2700 scored essays. We also compared various transformer-based neural language models to find the most effective model. Several metrics were used for evaluation, with the root mean square error (RMSE) as the primary measure. The results show that a specific model, DeBERTa-v3-large, outperforms others in most categories. In conclusion, this study suggests that transformer-based neural language models, especially when using the DeBERTa-v3-large model, hold significant promise in improving automated essay scoring and feedback, potentially leading to enhanced writing skills among English language learners.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3979085/v1"
    },
    {
        "id": 13935,
        "title": "Armenian Speech Recognition System: Acoustic and Language Models",
        "authors": "Varuzhan H. Baghdasaryan",
        "published": "2022",
        "citations": 0,
        "abstract": "Nowadays automatic speech recognition (ASR) is an important task for machines. Several applications such as speech translation, virtual assistants and voice bot systems use ASR to understand human speech. Most of the research and available models are for widely used languages, such as English, German, French, Chinese and Spanish. This paper presents the Armenian speech recognition system. As a result of this research developed acoustic and language models for the Armenian language (modern ASR systems combine acoustic and language models to achieve higher accuracy). RNN-based Baidu’s Deep Speech deep neural network was used to train the acoustic model, and the KenLM toolkit was used to train the probabilistic language model. The acoustic model was trained and validated on ArmSpeech Armenian native speech corpus using transfer-learning and data augmentation techniques and tested on the Common Voice Armenian database. The language model was built based on the texts scraped from Armenian news websites. Final models are small in size and can be run and do real-time speech-to-text tasks on IoT devices. Testing on the Common Voice Armenian database the model gave 0.902565 WER and 0.305321 CER without the language model, and 0.552975 WER and 0.285904 CER with the language model. The paper aims to describe environment setup, data collection, acoustic and language models training processes, as well as final results and benchmarks.",
        "link": "http://dx.doi.org/10.51542/ijscia.v3i5.7"
    },
    {
        "id": 13936,
        "title": "Introducing Structure into Neural Network-Based Semantic Models",
        "authors": "Stephen Clark",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w17-3412"
    },
    {
        "id": 13937,
        "title": "Role models in language acquisition and character education",
        "authors": "S. Sugirin",
        "published": "2018-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315104188-58"
    },
    {
        "id": 13938,
        "title": "Front Matter",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.1"
    },
    {
        "id": 13939,
        "title": "Summary and General Conclusions",
        "authors": "Dirk Damsma",
        "published": "2019-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1163/9789004395497_008"
    },
    {
        "id": 13940,
        "title": "Language models and linguistic theories beyond words",
        "authors": "",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s42256-023-00703-8"
    },
    {
        "id": 13941,
        "title": "Enhancing Turkish Sentiment Analysis Using Pre-Trained Language Models",
        "authors": "Ömer Köksal",
        "published": "2021-6-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/siu53274.2021.9477908"
    },
    {
        "id": 13942,
        "title": "Quantifying Context With and Without Statistical Language Models",
        "authors": "Cassandra L. Jacobs",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-03945-4_17"
    },
    {
        "id": 13943,
        "title": "Controllable Protein Design by Prefix-Tuning Protein Language Models",
        "authors": "Jiawei Luo, Xianliang Liu, Jiahao Li, Qingcai Chen, Junjie Chen",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractDesigning novel proteins tailored for specific purposes (e.g. drug discovery, vaccine design) presents a promising approach to address various biomedical challenges. Due to the similarity between protein sequences and natural languages, motivated by the remarkable success in NLP tasks that pre-trained language models have enabled text generation with human-like capabilities, protein language models (ProtLMs) are constructed to generate protein sequences with a predictable function across large protein families. The text generation can be controllable by constructing prefix-phase as control tags to prompt NLP language models. However, the vocabulary of protein sequences only contains 20 amino acid residues, which is not like natural language vocabulary to make up flexible control tags. In this study, we propose a controllable protein design method, named PrefixProt, which utilizes prefix tuning to learn virtual tokens as control tags, enabling to efficiently prompt the pre-trained ProtLM for protein generation tailored for specific purposes. The virtual tokens can be learned on any protein properties by data-driven and are flexible to be combined for fine-grained control. To demonstrate the effectiveness of PrefixProt, we train three virtual tokens on alpha-helix structure dataset, antimicrobial peptide (AMP) dataset and anticancer peptide (ACP) dataset, respectively. Our results show that prefix virtual tokens are efficient to prompt the pretrained ProtLM by optimizing fewer trainable parameters compared with fine-tuning, especially under low-data settings. When combining the virtual tokens, the proportion of generated proteins with multiple properties are significantly improved. Therefore, PrefixProt offers a flexible and controllable protein design solution. We anticipate that PrefixProt will contribute to drug discovery and biomedical advancement.Availability and implementationThe models and associated code are available at:https://github.com/chen-bioinfo/PrefixProt",
        "link": "http://dx.doi.org/10.1101/2023.12.03.569747"
    },
    {
        "id": 13944,
        "title": "Efficient MDI Adaptation for n-Gram Language Models",
        "authors": "Ruizhe Huang, Ke Li, Ashish Arora, Daniel Povey, Sanjeev Khudanpur",
        "published": "2020-10-25",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2020-2909"
    },
    {
        "id": 13945,
        "title": "Perplexity-based molecule ranking and bias estimation of chemical language models",
        "authors": "Michael Moret, Francesca Grisoni, Paul Katzberger, Gisbert Schneider",
        "published": "No Date",
        "citations": 0,
        "abstract": "Chemical language models (CLMs) can be employed to design molecules with desired properties. CLMs generate new chemical structures in the form of textual representations, such as the simplified molecular input line entry systems (SMILES) strings, in a rule-free manner. However, the quality of these de novo generated molecules is difficult to assess a priori. In this study, we apply the perplexity metric to determine the degree to which the molecules generated by a CLM match the desired design objectives. This model-intrinsic score allows identifying and ranking the most promising molecular designs based on the probabilities learned by the CLM. Using perplexity to compare “greedy” (beam search) with “explorative” (multinomial sampling) methods for SMILES generation, certain advantages of multinomial sampling become apparent. Additionally, perplexity scoring is performed to identify undesired model biases introduced during model training and allows the development of a new ranking system to remove those undesired biases.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2021-zv6f1"
    },
    {
        "id": 13946,
        "title": "eLife assessment: Sensitive remote homology search by local alignment of small positional embeddings from protein language models",
        "authors": "Alan M Moses",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.91415.3.sa0"
    },
    {
        "id": 13947,
        "title": "Discussion on Selection of Control Network Layout Scheme for Super Large Bridge",
        "authors": "",
        "published": "2021-2-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i2.56"
    },
    {
        "id": 13948,
        "title": "Construction Scheme of Large Group Project and Measures to Reduce Construction Cost",
        "authors": "",
        "published": "2022-1-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i1.229"
    },
    {
        "id": 13949,
        "title": "Construction Technology of Three-dimensional Variable Size Large Cantilever Prestressed Bent Cap",
        "authors": "",
        "published": "2022-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i5(04).12"
    },
    {
        "id": 13950,
        "title": "Large-Scale Transfer Learning for Low-Resource Spoken Language Understanding",
        "authors": "Xueli Jia, Jianzong Wang, Zhiyong Zhang, Ning Cheng, Jing Xiao",
        "published": "2020-10-25",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2020-59"
    },
    {
        "id": 13951,
        "title": "Technical Problems in the Construction Process of Large-span Complex Steel Structure",
        "authors": "",
        "published": "2022-6-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i6(02).13"
    },
    {
        "id": 13952,
        "title": "Llm-Tikg: Threat Intelligence Knowledge Graph Construction Utilizing Large Language Model",
        "authors": "Yuelin Hu, Futai Zou, Jiajia Han, Xin Sun, Yilei Wang",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4671345"
    },
    {
        "id": 13953,
        "title": "Evaluating large-language-model chatbots to engage communities in large-scale design projects",
        "authors": "Jonathan Dortheimer, Nik Martelaro, Aaron Sprecher, Gerhard Schubert",
        "published": "2024",
        "citations": 0,
        "abstract": "Abstract\nRecent advances in machine learning have enabled computers to converse with humans meaningfully. In this study, we propose using this technology to facilitate design conversations in large-scale urban development projects by creating chatbot systems that can automate and streamline information exchange between stakeholders and designers. To this end, we developed and evaluated a proof-of-concept chatbot system that can perform design conversations on a specific construction project and convert those conversations into a list of requirements. Next, in an experiment with 56 participants, we compared the chatbot system to a regular online survey, focusing on user satisfaction and the quality and quantity of collected information. The results revealed that, with regard to user satisfaction, the participants preferred the chatbot experience to a regular survey. However, we found that chatbot conversations produced more data than the survey, with a similar rate of novel ideas but fewer themes. Our findings provide robust evidence that chatbots can be effectively used for design discussions in large-scale design projects and offer a user-friendly experience that can help to engage people in the design process. Based on this evidence, by providing a space for meaningful conversations between stakeholders and expanding the reach of design projects, the use of chatbot systems in interactive design systems can potentially improve design processes and their outcomes.",
        "link": "http://dx.doi.org/10.1017/s0890060424000027"
    },
    {
        "id": 13954,
        "title": "A Unique Training Strategy to Enhance Language Models Capabilities for Health Mention Detection from Social Media Content",
        "authors": "Pervaiz Khan, Muhammad Asim, Andreas Dengel, Sheraz Ahmed",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012384100003636"
    },
    {
        "id": 13955,
        "title": "Acoustic-to-Word Recognition with Sequence-to-Sequence Models",
        "authors": "Shruti Palaskar, Florian Metze",
        "published": "2018-12",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt.2018.8639664"
    },
    {
        "id": 13956,
        "title": "Factual Consistency of Multilingual Pretrained Language Models",
        "authors": "Constanza Fierro, Anders Søgaard",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-acl.240"
    },
    {
        "id": 13957,
        "title": "Formal Models Based on Lexicalism",
        "authors": "Zhiwei Feng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-5172-4_6"
    },
    {
        "id": 13958,
        "title": "Formal Models of Discourse Analysis",
        "authors": "Zhiwei Feng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-5172-4_9"
    },
    {
        "id": 13959,
        "title": "Pushdown Automata and Parsing",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_0011"
    },
    {
        "id": 13960,
        "title": "Reflections of syntactic structures in non­autoregressive language models",
        "authors": "Sergey Pletenev,  ",
        "published": "2021-6-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.28995/2075-7182-2021-20-1180-1187"
    },
    {
        "id": 13961,
        "title": "An Introduction to Machine Learning",
        "authors": "Mascha Kurpicz-Briki",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-37690-0_2"
    },
    {
        "id": 13962,
        "title": "Utilizing Deep Learning Language Models to Analyze Preservice Teachers' Written Reflections",
        "authors": "Peter Wulff",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3102/1680141"
    },
    {
        "id": 13963,
        "title": "Models of Language Teaching and Humanizing Education",
        "authors": "Rosida Tiurma Manurung",
        "published": "2018-3-29",
        "citations": 0,
        "abstract": "<p><em>Modern, digitalized, high tech, global era characterized by the development of sciences has transform human beings into heartless machines with no sense of humanity and no concerns to their surrounding environment. Therefore, education should be packed with loads that include the perspective of humanism.</em><em> </em><em>Education should not be interpreted as a mere class teaching-learning activity. Education should refer to the various processes and activities that should be productive; creative; develop skills, personality, integration, and excellence; and up to moral and spiritual reinforcement.  Education shall be managed and directed with clear objectives, which are capable to develop positive values in learners. Education should be able to create figures with solid and proven character and personality both in the field of science and the humanities</em><em>. </em><em>Humanizing education means it is capable to produce human with sense of \"humanity\" which is characterized by the willingness to help others; empathy; honesty; share; loyalty; the willingness to take valuable lessons; persistent and tenacious,; high-respect of pluralism; tolerance; respect to others; patience; replied good for evil; always puts the good rather than evil, continuous efforts to improve the quality of charity and kindness; humility; and sincere. Therefore, the teaching materials must also be interpreted, filled, and imbued with the messages of humanity. These entire facts mean that teaching materials are not mere “soulless and empty” materials since if it is, then the materials will be like empty casket with no benefit to human life and livelihood. Approach of humanism in modern era education is considered as the most appropriate solution since this kind of education has education activities that don’t works like the machines do, and this means the students, teachers, and teaching materials should also be “humanized” in order to achieve educational goals optimally and in accordance with the vision and mission carried. This research discuss model of language teaching with humanistic perspective. Hopefully, through language teaching with humanism approach, students and teachers may rediscover the \"human side\" that may have been lost and undetected.</em></p>",
        "link": "http://dx.doi.org/10.26737/cling.v1i1.493"
    },
    {
        "id": 13964,
        "title": "Models and Language of Uncertainty",
        "authors": "",
        "published": "2018-1-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119489375.ch2"
    },
    {
        "id": 13965,
        "title": "Unbiasing Retrosynthesis Language Models with Disconnection Prompts",
        "authors": "Amol Thakkar, Alain Vaucher, Andrea Byekwaso, Philippe Schwaller, Alessandra Toniato, Teodoro Laino",
        "published": "No Date",
        "citations": 0,
        "abstract": "Data-driven approaches to retrosynthesis have thus far been limited in user interaction, in the diversity of their predictions, and the recommendation of unintuitive disconnection strategies. Herein, we extend the notions of prompt- based inference in natural language processing to the task of chemical language modeling. We show that by using a prompt describing the disconnection site in a molecule, we can steer the model to propose a wider set of precursors, overcoming training data biases in retrosynthetic recommendations and achiev- ing a 39 % performance improvement over the baseline. For the first time, the use of a disconnection prompt empowers chemists by giving them back greater control over the disconnection predictions, resulting in more diverse and creative recommendations. In addition, in place of a human-in-the-loop strategy, we propose a schema for automatic identification of disconnection sites, followed by prediction of reactant sets, achieving a 100 % improvement in class diversity as compared to the baseline. The approach is effective in mitigating prediction biases deriving from training data. In turn, this provides a larger variety of usable building blocks, which improves the end-user digital experience. We demonstrate its application to different chemistry domains, from traditional to enzymatic reactions, in which substrate specificity is key.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2022-gx9gb"
    },
    {
        "id": 13966,
        "title": "Language models and psychological sciences",
        "authors": "Giuseppe Sartori, Graziella Orrù",
        "published": "2023-10-20",
        "citations": 1,
        "abstract": "Large language models (LLMs) are demonstrating impressive performance on many reasoning and problem-solving tasks from cognitive psychology. When tested, their accuracy is often on par with average neurotypical adults, challenging long-standing critiques of associative models. Here we analyse recent findings at the intersection of LLMs and cognitive science. Here we discuss how modern LLMs resurrect associationist principles, with abilities like long-distance associations enabling complex reasoning. While limitations remain in areas like causal cognition and planning, phenomena like emergence suggest room for growth. Providing examples and increasing the dimensions of the network are methods that further improve LLM abilities, mirroring facilitation effects in human cognition. Analysis of LLMs errors provides insight into human cognitive biases. Overall, we argue LLMs represent a promising development for cognitive modelling, enabling new explorations of the mechanisms underlying intelligence and reasoning from an associationist point of view. Carefully evaluating LLMs with the tools of cognitive psychology will further understand the building blocks of the human mind.",
        "link": "http://dx.doi.org/10.3389/fpsyg.2023.1279317"
    },
    {
        "id": 13967,
        "title": "Do Language Models Understand Measurements?",
        "authors": "Sungjin Park, Seungwoo Ryu, Edward Choi",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-emnlp.128"
    },
    {
        "id": 13968,
        "title": "Empirical Exploration of Novel Architectures and Objectives for Language Models",
        "authors": "Gakuto Kurata, Abhinav Sethy, Bhuvana Ramabhadran, George Saon",
        "published": "2017-8-20",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2017-723"
    },
    {
        "id": 13969,
        "title": "Perplexity-based molecule ranking and bias estimation of chemical language models",
        "authors": "Michael Moret, Francesca Grisoni, Paul Katzberger, Gisbert Schneider",
        "published": "No Date",
        "citations": 0,
        "abstract": "Chemical language models (CLMs) can be employed to design molecules with desired properties. CLMs generate new chemical structures in the form of textual representations, such as the simplified molecular input line entry systems (SMILES) strings, in a rule-free manner. However, the quality of these de novo generated molecules is difficult to assess a priori. In this study, we apply the perplexity metric to determine the degree to which the molecules generated by a CLM match the desired design objectives. This model-intrinsic score allows identifying and ranking the most promising molecular designs based on the probabilities learned by the CLM. Using perplexity to compare “greedy” (beam search) with “explorative” (multinomial sampling) methods for SMILES generation, certain advantages of multinomial sampling become apparent. Additionally, perplexity scoring is performed to identify undesired model biases introduced during model training and allows the development of a new ranking system to remove those undesired biases.",
        "link": "http://dx.doi.org/10.33774/chemrxiv-2021-zv6f1"
    },
    {
        "id": 13970,
        "title": "Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition",
        "authors": "Sani Abdullahi Sani",
        "published": "No Date",
        "citations": 0,
        "abstract": "Writing skills are essential for academic and professional success. However, many students struggle to become proficient writers, highlighting the need for effective writing instruction and feedback methods. Automated Writing Evaluation (AWS) systems have emerged as a promising solution to address these challenges. This study proposes a model that utilizes fine-tuned language models to evaluate essay structure, specifically identifying key argumentative and rhetorical elements. The Longformer and Bigbird models were fine-tuned and evaluated for discourse classification. The results demonstrate that the Longformer model outperformed the Bigbird model, achieving an F1 score of 0.634 compared to 0.615. The Longformer model's ability to handle large data inputs without losing vital information contributed to its superior performance. Integrating machine learning models with AWE systems can enhance automated essay evaluation, providing valuable feedback to students. While positional encoding improves discourse classification, future research should focus on expanding data coverage across additional essay categories. This study highlights the significance of leveraging advanced NLP techniques to improve writing skills and lays the foundation for further advancements in automated essay evaluation systems.\n",
        "link": "http://dx.doi.org/10.32388/w283y7"
    },
    {
        "id": 13971,
        "title": "Scalable Multi Corpora Neural Language Models for ASR",
        "authors": "Anirudh Raju, Denis Filimonov, Gautam Tiwari, Guitang Lan, Ariya Rastrow",
        "published": "2019-9-15",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2019-3060"
    },
    {
        "id": 13972,
        "title": "Peer Review #1 of \"The neural machine translation models for the low-resource Kazakh–English language pair (v0.2)\"",
        "authors": "R Mendoza",
        "published": "2023-2-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.1224v0.2/reviews/1"
    },
    {
        "id": 13973,
        "title": "Teaching Language Variation in the Classroom",
        "authors": "",
        "published": "2019-1-15",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678"
    },
    {
        "id": 13974,
        "title": "Application of PowerPoint Presentation in Managing Writing Skills in Large English Language Teaching Classes",
        "authors": "",
        "published": "2020-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7176/jlll/68-04"
    },
    {
        "id": 13975,
        "title": "Large-Scale Transfer Learning for Low-Resource Spoken Language Understanding",
        "authors": "Xueli Jia, Jianzong Wang, Zhiyong Zhang, Ning Cheng, Jing Xiao",
        "published": "2020-10-25",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2020-0059"
    },
    {
        "id": 13976,
        "title": "Construction Technology of Connecting Passage in Complex Stratum with Large Buried Depth",
        "authors": "",
        "published": "2022-3-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i3(05).05"
    },
    {
        "id": 13977,
        "title": "Optimization of Operation Mode of Large-sized and Medium-sized Hydropower Stations",
        "authors": "",
        "published": "2021-1-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i1.71"
    },
    {
        "id": 13978,
        "title": "Large‐Scale Writing Assessment",
        "authors": "Sarah Goodwin",
        "published": "2018-1-18",
        "citations": 0,
        "abstract": "Large‐scale writing assessments, or writing tests using standardized directions and procedures for test administration beyond the scope of one classroom or student group, are often high‐stakes situations and may influence important educational decisions. This entry focuses on their purposes, uses, and implications for teachers, for instance through concepts related to assessment literacy.",
        "link": "http://dx.doi.org/10.1002/9781118784235.eelt0542"
    },
    {
        "id": 13979,
        "title": "Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning",
        "authors": "Mingyang Geng, Shangwen Wang, Dezun Dong, Haotian Wang, Ge Li, Zhi Jin, Xiaoguang Mao, Xiangke Liao",
        "published": "2024-2-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3597503.3608134"
    },
    {
        "id": 13980,
        "title": "Review of emerging trends and projection of future developments in large language models research in ophthalmology",
        "authors": "Matthew Wong, Zhi Wei Lim, Krithi Pushpanathan, Carol Y Cheung, Ya Xing Wang, David Chen, Yih Chung Tham",
        "published": "2023-12-11",
        "citations": 1,
        "abstract": "BackgroundLarge language models (LLMs) are fast emerging as potent tools in healthcare, including ophthalmology. This systematic review offers a twofold contribution: it summarises current trends in ophthalmology-related LLM research and projects future directions for this burgeoning field.MethodsWe systematically searched across various databases (PubMed, Europe PMC, Scopus and Web of Science) for articles related to LLM use in ophthalmology, published between 1 January 2022 and 31 July 2023. Selected articles were summarised, and categorised by type (editorial, commentary, original research, etc) and their research focus (eg, evaluating ChatGPT’s performance in ophthalmology examinations or clinical tasks).FindingsWe identified 32 articles meeting our criteria, published between January and July 2023, with a peak in June (n=12). Most were original research evaluating LLMs’ proficiency in clinically related tasks (n=9). Studies demonstrated that ChatGPT-4.0 outperformed its predecessor, ChatGPT-3.5, in ophthalmology exams. Furthermore, ChatGPT excelled in constructing discharge notes (n=2), evaluating diagnoses (n=2) and answering general medical queries (n=6). However, it struggled with generating scientific articles or abstracts (n=3) and answering specific subdomain questions, especially those regarding specific treatment options (n=2). ChatGPT’s performance relative to other LLMs (Google’s Bard, Microsoft’s Bing) varied by study design. Ethical concerns such as data hallucination (n=27), authorship (n=5) and data privacy (n=2) were frequently cited.InterpretationWhile LLMs hold transformative potential for healthcare and ophthalmology, concerns over accountability, accuracy and data security remain. Future research should focus on application programming interface integration, comparative assessments of popular LLMs, their ability to interpret image-based data and the establishment of standardised evaluation frameworks.",
        "link": "http://dx.doi.org/10.1136/bjo-2023-324734"
    },
    {
        "id": 13981,
        "title": "Text2Reaction : Enabling Reactive Task Planning Using Large Language Models",
        "authors": "Zejun Yang, Li Ning, Haitao Wang, Tianyu Jiang, Shaolin Zhang, Shaowei Cui, Hao Jiang, Chunpeng Li, Shuo Wang, Zhaoqi Wang",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/lra.2024.3371223"
    },
    {
        "id": 13982,
        "title": "Analysis on the Causes of Large Fluctuation of Auxiliary 6kV Busbar Voltage",
        "authors": "",
        "published": "2021-4-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i4.148"
    },
    {
        "id": 13983,
        "title": "Discussion on the Management of Coal Mining Technology in Large Inclined Seam",
        "authors": "",
        "published": "2021-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i12.138"
    },
    {
        "id": 13984,
        "title": "ArabianGPT: Native Arabic GPT-based Large Language Model",
        "authors": "Anis Koubaa, Adel Ammar, Lahouari Ghouti, Omer Necar, Serry Sibaee",
        "published": "No Date",
        "citations": 0,
        "abstract": "The predominance of English and Latin-based large language models (LLMs) has led to a notable deficit in native Arabic LLMs. This discrepancy is accentuated by the prevalent inclusion of English tokens in existing Arabic models, detracting from their efficacy in processing native Arabic's intricate morphology and syntax. Consequently, there is a theoretical and practical imperative for developing LLMs predominantly focused on Arabic linguistic elements. To address this gap, this paper proposes ArabianGPT, a series of transformer-based models within the ArabianLLM suite designed explicitly for Arabic. These models, including ArabianGPT-0.1B and ArabianGPT-0.3B, vary in size and complexity, aligning with the nuanced linguistic characteristics of Arabic. The AraNizer tokenizer, integral to these models, addresses the unique morphological aspects of Arabic script, ensuring more accurate text processing. Empirical results from fine-tuning the models on tasks like sentiment analysis and summarization demonstrate significant improvements. For sentiment analysis, the fine-tuned ArabianGPT-0.1B model achieved a remarkable accuracy of 95%, a substantial increase from the base model's 56%. Similarly, in summarization tasks, fine-tuned models showed enhanced F1 scores, indicating improved precision and recall in generating concise summaries. Comparative analysis of fine-tuned ArabianGPT models against their base versions across various benchmarks reveals nuanced differences in performance, with fine-tuning positively impacting specific tasks like question answering and summarization. These findings underscore the efficacy of fine-tuning in aligning ArabianGPT models more closely with specific NLP tasks, highlighting the potential of tailored transformer architectures in advancing Arabic NLP.",
        "link": "http://dx.doi.org/10.20944/preprints202402.1409.v1"
    },
    {
        "id": 13985,
        "title": "Large Language Model guided Protocol Fuzzing",
        "authors": "Ruijie Meng, Martin Mirchev, Marcel Böhme, Abhik Roychoudhury",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14722/ndss.2024.24556"
    },
    {
        "id": 13986,
        "title": "Emotional Intelligence of GPT-4 Large Language Model",
        "authors": "Gleb Vzorin, Alexey Bukinich, Anna Sedykh, Irina Vetrova, Elena Sergienko",
        "published": "No Date",
        "citations": 1,
        "abstract": "Current neural network models can demonstrate reasonable-looking behavior, considered by some developers and researchers human-like. For example, a large language model GPT-3 is susceptible to human-like cognitive biases. Yet there is no data of such models solving emotional intelligence (EI) tasks. They are connected to the abilities that has been previously considered as specifically human EI is an important aspect of human communication. The ability to understand and respond to emotional cues is essential for effective communication. Therefore, it is crucial to determine the ways AI models such as ChatGPT demonstrate EI. The present research aims to measure the EI of GPT-4, a large language model trained by OpenAI. Russian version of the Mayer&ndash;Salovey&ndash;Caruzo Emotional Intelligence Test sections B, C, D, F, G and H were used in this research. High points were obtained in Understanding emotions scale and Strategic EI. Mean points are obtained in Managing emotions scale. Low and less reliable values are obtained in Using emotions to facilitate thought scale. Thus, GPT-4 seems already capable of identifying emotions in text and describing techniques for managing them. However, complex cases and irregular situations requiring emotions qualitative analysis would be a hard task for GPT-4.",
        "link": "http://dx.doi.org/10.20944/preprints202310.1458.v1"
    },
    {
        "id": 13987,
        "title": "Selected Bibliography",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.11"
    },
    {
        "id": 13988,
        "title": "Multigenerative Grammar Systems and Parallel Computation",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_12"
    },
    {
        "id": 13989,
        "title": "Findings and analysis Teacher language attitudes",
        "authors": "Angela Farrell",
        "published": "2019-11-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429425530-6"
    },
    {
        "id": 13990,
        "title": "Joint Survival Models Potential to Improve Monitoring of English Language Progress",
        "authors": "Pete Goldschmidt",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3102/2018160"
    },
    {
        "id": 13991,
        "title": "Automatic Generation of SBML Kinetic Models from Natural Language Texts using GPT",
        "authors": "Kazuhiro Maeda, Hiroyuki Kurata",
        "published": "No Date",
        "citations": 0,
        "abstract": "Kinetic modeling is an essential tool in systems biology research, enabling the quantitative analysis of biological systems and predicting their behavior. However, the development of kinetic models is a complex and time-consuming process. In this article, we propose a novel approach called KinModGPT, which generates kinetic models directly from natural language text. KinModGPT employs GPT-3 as a natural language interpreter and Tellurium as an SBML generator. We demonstrate the effectiveness of KinModGPT in creating SBML models from complex natural language descriptions of biochemical reactions. KinModGPT successfully generates valid SBML models from a range of natural language model descriptions of metabolic pathways, protein-protein interaction networks, and heat shock response. This article demonstrates the potential of KinModGPT in kinetic modeling automation.",
        "link": "http://dx.doi.org/10.20944/preprints202303.0122.v1"
    },
    {
        "id": 13992,
        "title": "Benchmarking Transformers-based models on French Spoken Language Understanding tasks",
        "authors": "Oralie Cattan, Sahar Ghannay, Christophe Servan, Sophie Rosset",
        "published": "2022-9-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2022-385"
    },
    {
        "id": 13993,
        "title": "Transformer protein language models are unsupervised structure learners",
        "authors": "Roshan Rao, Joshua Meier, Tom Sercu, Sergey Ovchinnikov, Alexander Rives",
        "published": "No Date",
        "citations": 99,
        "abstract": "AbstractUnsupervised contact prediction is central to uncovering physical, structural, and functional constraints for protein structure determination and design. For decades, the predominant approach has been to infer evolutionary constraints from a set of related sequences. In the past year, protein language models have emerged as a potential alternative, but performance has fallen short of state-of-the-art approaches in bioinformatics. In this paper we demonstrate that Transformer attention maps learn contacts from the unsupervised language modeling objective. We find the highest capacity models that have been trained to date already outperform a state-of-the-art unsupervised contact prediction pipeline, suggesting these pipelines can be replaced with a single forward pass of an end-to-end model.1",
        "link": "http://dx.doi.org/10.1101/2020.12.15.422761"
    },
    {
        "id": 13994,
        "title": "Pushdown Automata and Parsing",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811260674_0011"
    },
    {
        "id": 13995,
        "title": "Quantifying Context With and Without Statistical Language Models",
        "authors": "Cassandra L. Jacobs",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-44982-7_17-1"
    },
    {
        "id": 13996,
        "title": "Sarcasm Detection in Arabic Text Using Contextualized Models",
        "authors": "Youssef Mansour, Ashraf Elnagar",
        "published": "2023-11-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ialp61005.2023.10337175"
    },
    {
        "id": 13997,
        "title": "Unsupervised and Efficient Vocabulary Expansion for Recurrent Neural Network Language Models in ASR",
        "authors": "Yerbolat Khassanov, Eng Siong Chng",
        "published": "2018-9-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2018-1021"
    },
    {
        "id": 13998,
        "title": "Peer Review #1 of \"The neural machine translation models for the low-resource Kazakh–English language pair (v0.1)\"",
        "authors": "R Mendoza",
        "published": "2023-2-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.1224v0.1/reviews/1"
    },
    {
        "id": 13999,
        "title": "Perplexity-based molecule ranking and bias estimation of chemical language models",
        "authors": "Michael Moret, Francesca Grisoni, Paul Katzberger, Gisbert Schneider",
        "published": "No Date",
        "citations": 0,
        "abstract": "Chemical language models (CLMs) can be employed to design molecules with desired properties. CLMs generate new chemical structures in the form of textual representations, such as the simplified molecular input line entry systems (SMILES) strings, in a rule-free manner. However, the quality of these de novo generated molecules is difficult to assess a priori. In this study, we apply the perplexity metric to determine the degree to which the molecules generated by a CLM match the desired design objectives. This model-intrinsic score allows identifying and ranking the most promising molecular designs based on the probabilities learned by the CLM. Using perplexity to compare “greedy” (beam search) with “explorative” (multinomial sampling) methods for SMILES generation, certain advantages of multinomial sampling become apparent. Additionally, perplexity scoring is performed to identify undesired model biases introduced during model training and allows the development of a new ranking system to remove those undesired biases.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2021-zv6f1-v2"
    },
    {
        "id": 14000,
        "title": "PENGAPSAHAN: TRANSLATION MODELS, LOCAL LANGUAGE PRESERVATION, AND LANGUAGE ACCULTURATION PROCESSES IN KIAI BOOKS OF COASTAL JAVA",
        "authors": "Muhamad Jaeni",
        "published": "2019-12-20",
        "citations": 0,
        "abstract": "Pengapsahan model is a translation model that has long been used by Kiai in several traditional pesantren (Islamic boarding schools) on coastal Java. During this time, the conjugation model is only understood as a tool for analyzing text structures, whereas far more than that, there is a variety of Javanese typically used in pesantren having a social role so that the variety of Javanese is still preserved by pesantren communities. This paper examines the model of analyzing the pesantren books. The study will also look at the formulation of Kitabi Javanese language and the reasons why the variety of Javanese of the pesantren that continues to be preserved and maintained by the pesantren community, as well as how the process of conjugation has become a part of the process of acculturation in Javanese and Arabic in the texts of religious books. The results of this study, First; the conjugation model is a special model for Arabic texts created by Islamic boarding school scholars with various analytical tools in it; Second, the variety of languages used in the conjugation of the book is a variety of Javanese of coastal dialects and it has become a corpus of its language which is called Jawa Kitabi (Kitabi Javanese); Third, the process of acculturation of Arabic-Javanese in the tradition of conjugation is characterized by the emergence of the pegon script, the emergence of Javanese translation books with the Arabic structure of fusha, the existence of mixed code phenomena in the writing and translating pesantren books, both mixed codes of Javanese-Arabic, Javanese-Indonesian and mixed codes of Javanese Krama-Ngoko.",
        "link": "http://dx.doi.org/10.15408/a.v6i2.12091"
    },
    {
        "id": 14001,
        "title": "YNU-HPCC at SemEval-2022 Task 4: Finetuning Pretrained Language Models for Patronizing and Condescending Language Detection",
        "authors": "Wenqiang Bai, Jin Wang, Xuejie Zhang",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.semeval-1.61"
    },
    {
        "id": 14002,
        "title": "Viable Threat on News Reading: Generating Biased News Using Natural Language Models",
        "authors": "Saurabh Gupta, Hong Huy Nguyen, Junichi Yamagishi, Isao Echizen",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.nlpcss-1.7"
    },
    {
        "id": 14003,
        "title": "UNBNLP at SemEval-2019 Task 5 and 6: Using Language Models to Detect Hate Speech and Offensive Language",
        "authors": "Ali Hakimi Parizi, Milton King, Paul Cook",
        "published": "2019",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/s19-2092"
    },
    {
        "id": 14004,
        "title": "Named Entity Recognition in Industrial Tables using Tabular Language Models",
        "authors": "Aneta Koleva, Martin Ringsquandl, Mark Buckley, Rakeb Hasan, Volker Tresp",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-industry.35"
    },
    {
        "id": 14005,
        "title": "On the Sentence Embeddings from Pre-trained Language Models",
        "authors": "Bohan Li, Hao Zhou, Junxian He, Mingxuan Wang, Yiming Yang, Lei Li",
        "published": "2020",
        "citations": 165,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.733"
    },
    {
        "id": 14006,
        "title": "Finding Skill Neurons in Pre-trained Transformer-based Language Models",
        "authors": "Xiaozhi Wang, Kaiyue Wen, Zhengyan Zhang, Lei Hou, Zhiyuan Liu, Juanzi Li",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.765"
    },
    {
        "id": 14007,
        "title": "ChapterBreak: A Challenge Dataset for Long-Range Language Models",
        "authors": "Simeng Sun, Katherine Thai, Mohit Iyyer",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.271"
    },
    {
        "id": 14008,
        "title": "Prompt Discriminative Language Models for Domain Adaptation",
        "authors": "Keming Lu, Peter Potash, Xihui Lin, Yuwen Sun, Zihan Qian, Zheng Yuan, Tristan Naumann, Tianxi Cai, Junwei Lu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.clinicalnlp-1.30"
    },
    {
        "id": 14009,
        "title": "Examining the Causal Impact of First Names on Language Models: The Case of Social Commonsense Reasoning",
        "authors": "Sullam Jeoung, Jana Diesner, Halil Kilicoglu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.trustnlp-1.7"
    },
    {
        "id": 14010,
        "title": "A Data Cartography based MixUp for Pre-trained Language Models",
        "authors": "Seo Yeon Park, Cornelia Caragea",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.314"
    },
    {
        "id": 14011,
        "title": "Structural Persistence in Language Models: Priming as a Window into Abstract Language Representations",
        "authors": "Arabella Sinclair, Jaap Jumelet, Willem Zuidema, Raquel Fernández",
        "published": "2022-9-19",
        "citations": 4,
        "abstract": "Abstract\nWe investigate the extent to which modern neural language models are susceptible to structural priming, the phenomenon whereby the structure of a sentence makes the same structure more probable in a follow-up sentence. We explore how priming can be used to study the potential of these models to learn abstract structural information, which is a prerequisite for good performance on tasks that require natural language understanding skills. We introduce a novel metric and release Prime-LM, a large corpus where we control for various linguistic factors that interact with priming strength. We find that Transformer models indeed show evidence of structural priming, but also that the generalizations they learned are to some extent modulated by semantic information. Our experiments also show that the representations acquired by the models may not only encode abstract sequential structure but involve certain level of hierarchical syntactic information. More generally, our study shows that the priming paradigm is a useful, additional tool for gaining insights into the capacities of language models and opens the door to future priming-based investigations that probe the model’s internal states.1",
        "link": "http://dx.doi.org/10.1162/tacl_a_00504"
    },
    {
        "id": 14012,
        "title": "Assessing the influence of attractor-verb distance on grammatical agreement in humans and language models",
        "authors": "Christos Zacharopoulos, Théo Desbordes, Mathias Sablé-Meyer",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.998"
    },
    {
        "id": 14013,
        "title": "Tiny Language Models Enriched with Multimodal Knowledge from Multiplex Networks",
        "authors": "Clayton Fields, Osama Natouf, Andrew McMains, Catherine Henry, Casey Kennington",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-babylm.3"
    },
    {
        "id": 14014,
        "title": "How well can Text-to-Image Generative Models understand Ethical Natural Language Interventions?",
        "authors": "Hritik Bansal, Da Yin, Masoud Monajatipoor, Kai-Wei Chang",
        "published": "2022",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.88"
    },
    {
        "id": 14015,
        "title": "Identity Formation in Second Language Writing",
        "authors": "Nayef Jomaa",
        "published": "2021",
        "citations": 1,
        "abstract": "Part of the researcher's duties towards his supervisees is to guide them in their postgraduate research journeys. Two important questions were raised by his supervisees. One of them is why the majority of studies follow Hyland's framework in analysing identity. The other question is why we do not follow Hyland's (framework in analysing the reporting verbs instead of Halliday's transitivity system. Is it because the latter is so difficult to understand? Therefore, this chapter aims at focusing on identity in second language (L2) writing, comparing between Halliday's modality, Vande Kopple's taxonomy, Crismore et al.'s taxonomy, and Hyland's model of metadiscourse. The findings showed a sort of similarity as well as variety, thus resulting in overlapping and lacking a solid model for analysing how writers reveal their identity. Therefore, a necessity arises to present a comprehensive model that can be used to identify all the categories and subcategories related to interpersonal meanings. ",
        "link": "http://dx.doi.org/10.4018/978-1-7998-6508-7.ch011"
    },
    {
        "id": 14016,
        "title": "Models of retrieval in sentence comprehension: A computational evaluation using Bayesian hierarchical modeling",
        "authors": "Bruno Nicenboim, Shravan Vasishth",
        "published": "2018-4",
        "citations": 38,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jml.2017.08.004"
    },
    {
        "id": 14017,
        "title": "Masking as an Efficient Alternative to Finetuning for Pretrained Language Models",
        "authors": "Mengjie Zhao, Tao Lin, Fei Mi, Martin Jaggi, Hinrich Schütze",
        "published": "2020",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.174"
    },
    {
        "id": 14018,
        "title": "A Self-Evolution Data Fusion Platform for Large-Scale Water Models",
        "authors": "Xinya Li, Chris Vernon, Min Chen, Heng Wang, Zhangshuan Hou",
        "published": "2021-4-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2172/1769652"
    },
    {
        "id": 14019,
        "title": "Experiments and Results of Simulation Cloning Algorithms",
        "authors": "Dan Chen, Lizhe Wang, Jingying Chen",
        "published": "2017-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b11883-10"
    },
    {
        "id": 14020,
        "title": "Fast distributed MAP inference for large-scale graphical models",
        "authors": "Claudia Soares, Joao Gomes",
        "published": "2019-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/eurocon.2019.8861615"
    },
    {
        "id": 14021,
        "title": "Autoregression models of large space debris motion",
        "authors": "Oleksandr Sarichev, Bogdan Perviy",
        "published": "2021-3-1",
        "citations": 1,
        "abstract": "A statistical method was developed for modeling the large space debris motion in the class of autoregressive models. The method improves the quality of description and forecasting of the movement of large fragments of space debris based on their TLE elements.",
        "link": "http://dx.doi.org/10.34185/1562-9945-6-131-2020-12"
    },
    {
        "id": 14022,
        "title": "Large-Scale Comparative Analysis of Codon Models Accounting for Protein and Nucleotide Selection",
        "authors": "Iakov I. Davydov, Nicolas Salamin, Marc Robinson-Rechavi",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractThere are numerous sources of variation in the rate of synonymous substitutions inside genes, such as direct selection on the nucleotide sequence, or mutation rate variation. Yet scans for positive selection rely on codon models which incorporate an assumption of effectively neutral synonymous substitution rate, constant between sites of each gene. Here we perform a large-scale comparison of approaches which incorporate codon substitution rate variation and propose our own simple yet effective modification of existing models. We find strong effects of substitution rate variation on positive selection inference. More than 70% of the genes detected by the classical branch-site model are presumably false positives caused by the incorrect assumption of uniform synonymous substitution rate. We propose a new model which is strongly favored by the data while remaining computationally tractable. With the new model we can capture signatures of nucleotide level selection acting on translation initiation and on splicing sites within the coding region. Finally, we show that rate variation is highest in the highly recombining regions, and we propose that recombination and mutation rate variation, such as high CpG mutation rate, are the two main sources of nucleotide rate variation. While we detect fewer genes under positive selection in Drosophila than without rate variation, the genes which we detect contain a stronger signal of adaptation of dynein, which could be associated withWolbachiainfection. We provide software to perform positive selection analysis using the new model.",
        "link": "http://dx.doi.org/10.1101/174839"
    },
    {
        "id": 14023,
        "title": "Dual Variational Formulations for a Large Class of Non-Convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops dual variational formulations for a large class of models in variational optimization. The results are established through basic tools of functional analysis, convex analysis and duality theory. The main duality principle is developed as an application to a Ginzburg-Landau type system in superconductivity in the absence of a magnetic field. In the first sections, we develop new general dual convex variational formulations, more specifically, dual formulations with a large region of convexity around the critical points which are suitable for the non-convex optimization for a large class of models in physics and engineering. Finally, in the last section we present some numerical results concerning the generalized method of lines applied to a Ginzburg-Landau type equation.",
        "link": "http://dx.doi.org/10.20944/preprints202210.0091.v6"
    },
    {
        "id": 14024,
        "title": "Dual Variational Formulations for a Large Class of Non-Convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops dual variational formulations for a large class of models in variational optimization. The results are established through basic tools of functional analysis, convex analysis and duality theory. The main duality principle is developed as an application to a Ginzburg-Landau type system in superconductivity in the absence of a magnetic field. In the first sections, we develop new general dual convex variational formulations, more specifically, dual formulations with a large region of convexity around the critical points which are suitable for the non-convex optimization for a large class of models in physics and engineering. Finally, in the last section we present some numerical results concerning the generalized method of lines applied to a Ginzburg-Landau type equation.",
        "link": "http://dx.doi.org/10.20944/preprints202210.0091.v11"
    },
    {
        "id": 14025,
        "title": "Dual Variational Formulations for a Large Class of Non-Convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops dual variational formulations for a large class of models in variational optimization. The results are established through basic tools of functional analysis, convex analysis and duality theory. The main duality principle is developed as an application to a Ginzburg-Landau type system in superconductivity in the absence of a magnetic field. In the first sections, we develop new general dual convex variational formulations, more specifically, dual formulations with a large region of convexity around the critical points which are suitable for the non-convex optimization for a large class of models in physics and engineering. Finally, in the last section we present some numerical results concerning the generalized method of lines applied to a Ginzburg-Landau type equation.",
        "link": "http://dx.doi.org/10.20944/preprints202210.0091.v10"
    },
    {
        "id": 14026,
        "title": "Towards Robustness of Large Language Models on Text-to-SQL Task: An Adversarial and Cross-Domain Investigation",
        "authors": "Weixu Zhang, Yu Wang, Ming Fan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-44192-9_15"
    },
    {
        "id": 14027,
        "title": "A rapid review on current and potential uses of large language models in nursing",
        "authors": "Mollie Hobensack, Hanna Von Gerich, Pankaj Vyas, Jennifer Withall, Laura-Maria Peltonen, Lorraine J. Block, Shauna Davies, Ryan Chan, Liesbet Van Bulck, Hwayoung Cho, Robert Paquin, James Mitchell, Maxim Topaz, Jiyoun Song",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ijnurstu.2024.104753"
    },
    {
        "id": 14028,
        "title": "Advanced PromptCBLUE Performance: A Novel Approach Leveraging Large Language Models",
        "authors": "Hongshun Ling, Chengze Ge, Jie Wang, Fuliang Quan, Jianping Zeng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-7224-1_28"
    },
    {
        "id": 14029,
        "title": "智能化时代的软件开发: 拥抱大模型的正确姿势",
        "authors": "Xin Peng",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1631/fitee.2300537"
    },
    {
        "id": 14030,
        "title": "Boosting legal case retrieval by query content selection with large language models",
        "authors": "Youchao Zhou, Heyan Huang, Zhijing Wu",
        "published": "2023-11-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3624918.3625328"
    },
    {
        "id": 14031,
        "title": "An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation",
        "authors": "Max Schäfer, Sarah Nadi, Aryaz Eghbali, Frank Tip",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tse.2023.3334955"
    },
    {
        "id": 14032,
        "title": "The Future of Molecular Studies through the Lens of Large Language Models",
        "authors": "Jinlu Zhang, Yin Fang, Xin Shao, Huajun Chen, Ningyu Zhang, Xiaohui Fan",
        "published": "2024-2-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1021/acs.jcim.3c01977"
    },
    {
        "id": 14033,
        "title": "CPM-2: Large-scale cost-effective pre-trained language models",
        "authors": "Zhengyan Zhang, Yuxian Gu, Xu Han, Shengqi Chen, Chaojun Xiao, Zhenbo Sun, Yuan Yao, Fanchao Qi, Jian Guan, Pei Ke, Yanzheng Cai, Guoyang Zeng, Zhixing Tan, Zhiyuan Liu, Minlie Huang, Wentao Han, Yang Liu, Xiaoyan Zhu, Maosong Sun",
        "published": "2021",
        "citations": 23,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.aiopen.2021.12.003"
    },
    {
        "id": 14034,
        "title": "Reliability of large language models in managing odontogenic sinusitis clinical scenarios: a preliminary multidisciplinary evaluation",
        "authors": "Alberto Maria Saibene, Fabiana Allevi, Christian Calvo-Henriquez, Antonino Maniaci, Miguel Mayo-Yáñez, Alberto Paderno, Luigi Angelo Vaira, Giovanni Felisati, John R. Craig",
        "published": "2024-4",
        "citations": 0,
        "abstract": "Abstract\nPurpose\nThis study aimed to evaluate the utility of large language model (LLM) artificial intelligence tools, Chat Generative Pre-Trained Transformer (ChatGPT) versions 3.5 and 4, in managing complex otolaryngological clinical scenarios, specifically for the multidisciplinary management of odontogenic sinusitis (ODS).\n\nMethods\nA prospective, structured multidisciplinary specialist evaluation was conducted using five ad hoc designed ODS-related clinical scenarios. LLM responses to these scenarios were critically reviewed by a multidisciplinary panel of eight specialist evaluators (2 ODS experts, 2 rhinologists, 2 general otolaryngologists, and 2 maxillofacial surgeons). Based on the level of disagreement from panel members, a Total Disagreement Score (TDS) was calculated for each LLM response, and TDS comparisons were made between ChatGPT3.5 and ChatGPT4, as well as between different evaluators.\n\nResults\nWhile disagreement to some degree was demonstrated in 73/80 evaluator reviews of LLMs’ responses, TDSs were significantly lower for ChatGPT4 compared to ChatGPT3.5. Highest TDSs were found in the case of complicated ODS with orbital abscess, presumably due to increased case complexity with dental, rhinologic, and orbital factors affecting diagnostic and therapeutic options. There were no statistically significant differences in TDSs between evaluators’ specialties, though ODS experts and maxillofacial surgeons tended to assign higher TDSs.\n\nConclusions\nLLMs like ChatGPT, especially newer versions, showed potential for complimenting evidence-based clinical decision-making, but substantial disagreement was still demonstrated between LLMs and clinical specialists across most case examples, suggesting they are not yet optimal in aiding clinical management decisions. Future studies will be important to analyze LLMs’ performance as they evolve over time.\n",
        "link": "http://dx.doi.org/10.1007/s00405-023-08372-4"
    },
    {
        "id": 14035,
        "title": "Benchmarking and In-depth Performance Study of Large Language Models on Habana Gaudi Processors",
        "authors": "Chengming Zhang, Baixi Sun, Xiaodong Yu, Zhen Xie, Weijian Zheng, Kamil A. Iskra, Pete Beckman, Dingwen Tao",
        "published": "2023-11-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3624062.3624257"
    },
    {
        "id": 14036,
        "title": "Who's the Best Detective? Large Language Models vs. Traditional Machine Learning in Detecting Incoherent Fourth Grade Math Answers",
        "authors": "Felipe Urrutia, Roberto Araya",
        "published": "2024-1",
        "citations": 0,
        "abstract": " Written answers to open-ended questions can have a higher long-term effect on learning than multiple-choice questions. However, it is critical that teachers immediately review the answers, and ask to redo those that are incoherent. This can be a difficult task and can be time-consuming for teachers. A possible solution is to automate the detection of incoherent answers. One option is to automate the review with Large Language Models (LLM). They have a powerful discursive ability that can be used to explain decisions. In this paper, we analyze the responses of fourth graders in mathematics using three LLMs: GPT-3, BLOOM, and YOU. We used them with zero, one, two, three and four shots. We compared their performance with the results of various classifiers trained with Machine Learning (ML). We found that LLMs perform worse than MLs in detecting incoherent answers. The difficulty seems to reside in recursive questions that contain both questions and answers, and in responses from students with typical fourth-grader misspellings. Upon closer examination, we have found that the ChatGPT model faces the same challenges. ",
        "link": "http://dx.doi.org/10.1177/07356331231191174"
    },
    {
        "id": 14037,
        "title": "On Hardware Security Bug Code Fixes By Prompting Large Language Models",
        "authors": "Baleegh Ahmad, Shailja Thakur, Benjamin Tan, Ramesh Karri, Hammond Pearce",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tifs.2024.3374558"
    },
    {
        "id": 14038,
        "title": "Pseudo-Labeling With Large Language Models for Multi-Label Emotion Classification of French Tweets",
        "authors": "Usman Malik, Simon Bernard, Alexandre Pauchet, Clément Chatelain, Romain Picot-Clémente, Jérôme Cortinovis",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2024.3354705"
    },
    {
        "id": 14039,
        "title": "Harvesting Event Schemas from Large Language Models",
        "authors": "Jialong Tang, Hongyu Lin, Zhuoqun Li, Yaojie Lu, Xianpei Han, Le Sun",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-7224-1_5"
    },
    {
        "id": 14040,
        "title": "Algorithmic identification of treatment-emergent adverse events from clinical notes using large language models: a pilot study in inflammatory bowel disease",
        "authors": "Anna L Silverman, Madhumita Sushil, Balu Bhasuran, Dana Ludwig, James Buchanan, Rebecca Racz, Mahalakshmi Parakala, Samer El-Kamary, Ohenewaa Ahima, Artur Belov, Lauren Choi, Monisha Billings, Yan Li, Nadia Habal, Qi Liu, Jawahar Tiwari, Atul J Butte, Vivek A Rudrapatna",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractBackground and AimsOutpatient clinical notes are a rich source of information regarding drug safety. However, data in these notes are currently underutilized for pharmacovigilance due to methodological limitations in text mining. Large language models (LLM) like BERT have shown progress in a range of natural language processing tasks but have not yet been evaluated on adverse event detection.MethodsWe adapted a new clinical LLM, UCSF BERT, to identify serious adverse events (SAEs) occurring after treatment with a non-steroid immunosuppressant for inflammatory bowel disease (IBD). We compared this model to other language models that have previously been applied to AE detection.ResultsWe annotated 928 outpatient IBD notes corresponding to 928 individual IBD patients for all SAE-associated hospitalizations occurring after treatment with a non-steroid immunosuppressant. These notes contained 703 SAEs in total, the most common of which was failure of intended efficacy. Out of 8 candidate models, UCSF BERT achieved the highest numerical performance on identifying drug-SAE pairs from this corpus (accuracy 88-92%, macro F1 61-68%), with 5-10% greater accuracy than previously published models. UCSF BERT was significantly superior at identifying hospitalization events emergent to medication use (p < 0.01).ConclusionsLLMs like UCSF BERT achieve numerically superior accuracy on the challenging task of SAE detection from clinical notes compared to prior methods. Future work is needed to adapt this methodology to improve model performance and evaluation using multi-center data and newer architectures like GPT. Our findings support the potential value of using large language models to enhance pharmacovigilance.",
        "link": "http://dx.doi.org/10.1101/2023.09.06.23295149"
    },
    {
        "id": 14041,
        "title": "The GENEA Challenge 2023: A large-scale evaluation of gesture generation models in monadic and dyadic settings",
        "authors": "Taras Kucherenko, Rajmund Nagy, Youngwoo Yoon, Jieyeon Woo, Teodor Nikolov, Mihail Tsakov, Gustav Eje Henter",
        "published": "2023-10-9",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3577190.3616120"
    },
    {
        "id": 14042,
        "title": "Beyond rating scales: With targeted evaluation, large language models are poised for psychological assessment",
        "authors": "Oscar N.E. Kjell, Katarina Kjell, H. Andrew Schwartz",
        "published": "2024-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.psychres.2023.115667"
    },
    {
        "id": 14043,
        "title": "Lost in translation? Not for Large Language Models: Automated divergent thinking scoring performance translates to non-English contexts",
        "authors": "Aleksandra Zielińska, Peter Organisciak, Denis Dumas, Maciej Karwowski",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.tsc.2023.101414"
    },
    {
        "id": 14044,
        "title": "The future landscape of large language models in medicine",
        "authors": "Jan Clusmann, Fiona R. Kolbinger, Hannah Sophie Muti, Zunamys I. Carrero, Jan-Niklas Eckardt, Narmin Ghaffari Laleh, Chiara Maria Lavinia Löffler, Sophie-Caroline Schwarzkopf, Michaela Unger, Gregory P. Veldhuizen, Sophia J. Wagner, Jakob Nikolas Kather",
        "published": "2023-10-10",
        "citations": 48,
        "abstract": "AbstractLarge language models (LLMs) are artificial intelligence (AI) tools specifically trained to process and generate text. LLMs attracted substantial public attention after OpenAI’s ChatGPT was made publicly available in November 2022. LLMs can often answer questions, summarize, paraphrase and translate text on a level that is nearly indistinguishable from human capabilities. The possibility to actively interact with models like ChatGPT makes LLMs attractive tools in various fields, including medicine. While these models have the potential to democratize medical knowledge and facilitate access to healthcare, they could equally distribute misinformation and exacerbate scientific misconduct due to a lack of accountability and transparency. In this article, we provide a systematic and comprehensive overview of the potentials and limitations of LLMs in clinical practice, medical research and medical education.",
        "link": "http://dx.doi.org/10.1038/s43856-023-00370-1"
    },
    {
        "id": 14045,
        "title": "Analyzing the Innovative Potential of Texts Generated by Large Language Models: An Empirical Evaluation",
        "authors": "Oliver Krauss, Michaela Jungwirth, Marius Elflein, Simone Sandler, Christian Altenhofer, Andreas Stoeckl",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-39689-2_2"
    },
    {
        "id": 14046,
        "title": "A Survey of Clinicians’ Views of the Utility of Large Language Models",
        "authors": "Matthew Spotnitz, Betina Idnay, Emily R Gordon, Rebecca Shyu, Gongbo Zhang, Cong Liu, James J Cimino, Chunhua Weng",
        "published": "No Date",
        "citations": 0,
        "abstract": "Objective: Large language models (LLMs) like ChatGPT are powerful algorithms that have been shown to produce human-like text from input data.  A number of potential clinical applications of this technology have been proposed and evaluated by biomedical informatics experts. However, few have surveyed healthcare providers for their opinions about whether the technology is fit for use.  \n\nMaterials and Methods: We distributed a validated mixed-methods survey to gauge practicing clinicians’ comfort with LLMs for a breadth of tasks in clinical practice, research and education, which were selected from the literature.  \n\nResults: A total of 30 clinicians fully completed the survey. Of the 23 tasks, 16 were rated positively by more than 50% of the respondents. Based on our qualitative analysis, healthcare providers considered LLMs to have excellent synthesis skills and efficiency. However, our respondents had concerns that LLMs could generate false information and propagate training data bias. \n\nDiscussion: Our survey respondents were most comfortable with scenarios that allow LLMs to function in an assistive role, like a physician extender or trainee. \n\nConclusion: In a uniquely rigorous and comprehensive mixed-methods survey of clinicians about LLM use, healthcare providers were encouraging of having LLMs in healthcare for many tasks, and especially in assistive roles. There is a need for continued human-centered development of both LLMs and artificial intelligence (AI) in general.\n",
        "link": "http://dx.doi.org/10.1055/a-2281-7092"
    },
    {
        "id": 14047,
        "title": "Efficient Fine-Tuning Large Language Models for Knowledge-Aware Response Planning",
        "authors": "Minh Nguyen, K. C. Kishan, Toan Nguyen, Ankit Chadha, Thuy Vu",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-43415-0_35"
    },
    {
        "id": 14048,
        "title": "The predictive skill of neural network models for the large-scale dynamics of the multi-level Lorenz '96 systems",
        "authors": "Seoleun Shin",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/essoar.10508229.1"
    },
    {
        "id": 14049,
        "title": "Estimation of Large Dimensional Conditional Factor Models in Finance",
        "authors": "Patrick Gagliardini, Elisa Ossola, Olivier Scaillet",
        "published": "No Date",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3443426"
    },
    {
        "id": 14050,
        "title": "Aggregating over land surface heterogeneity systematically biases evapotranspiration estimates in large-scale evaporation models",
        "authors": "Elham Rouholahnejad Freund, Massimiliano Zappa, Kirchner James",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Land surface models are highly uncertain in estimating evapotranspiration (ET) fluxes, and differ substantially in their projections of how ET will evolve in the future. Biases in estimated ET fluxes will affect the partitioning between sensible and latent heat, and thus alter simulated temperatures and model predictions of droughts and heatwaves. One potential source of bias is the &quot;aggregation bias&quot; that arises whenever nonlinear processes, such as those that regulate ET fluxes, are modeled using averages of heterogeneous inputs. Here we demonstrate that this aggregation bias leads to substantial overestimates in ET fluxes in a typical large-scale land surface model. The proposed methodology can be used to correct for aggregation biases in ET estimates by quantifying the effects of finer-resolution spatiotemporal variability in ET drivers at each modeling time step, without explicitly representing sub-grid heterogeneities in large-scale land surface models.&amp;#160;&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu21-15460"
    },
    {
        "id": 14051,
        "title": "Probes of Cosmic Structure Formation",
        "authors": "Baojiu Li",
        "published": "2018-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1088/978-0-7503-1587-6ch3"
    },
    {
        "id": 14052,
        "title": "Dual Variational Formulations for a Large Class of Non-Convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops dual variational formulations for a large class of models in variational optimization. The results are established through basic tools of functional analysis, convex analysis and duality theory. The main duality principle is developed as an application to a Ginzburg-Landau type system in superconductivity in the absence of a magnetic field. In the first part final sections, we develop new general dual convex variational formulations, more specifically, dual formulations with a large region of convexity around the critical points which are suitable for the non-convex optimization for a large class of models in physics and engineering. Finally, in the last section we present some numerical results concerning the generalized method of lines applied to a Ginzburg-Landau type equation.",
        "link": "http://dx.doi.org/10.20944/preprints202210.0091.v1"
    },
    {
        "id": 14053,
        "title": "Dual Variational Formulations for a Large Class of Non-Convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops dual variational formulations for a large class of models in variational optimization. The results are established through basic tools of functional analysis, convex analysis and duality theory. The main duality principle is developed as an application to a Ginzburg-Landau type system in superconductivity in the absence of a magnetic field. In the first sections, we develop new general dual convex variational formulations, more specifically, dual formulations with a large region of convexity around the critical points which are suitable for the non-convex optimization for a large class of models in physics and engineering. Finally, in the last section we present some numerical results concerning the generalized method of lines applied to a Ginzburg-Landau type equation.",
        "link": "http://dx.doi.org/10.20944/preprints202210.0091.v12"
    },
    {
        "id": 14054,
        "title": "Dual Variational Formulations for a Large Class of Non-Convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops dual variational formulations for a large class of models in variational optimization. The results are established through basic tools of functional analysis, convex analysis and duality theory. The main duality principle is developed as an application to a Ginzburg-Landau type system in superconductivity in the absence of a magnetic field. In the first sections, we develop new general dual convex variational formulations, more specifically, dual formulations with a large region of convexity around the critical points which are suitable for the non-convex optimization for a large class of models in physics and engineering. Finally, in the last section we present some numerical results concerning the generalized method of lines applied to a Ginzburg-Landau type equation.",
        "link": "http://dx.doi.org/10.20944/preprints202210.0091.v8"
    },
    {
        "id": 14055,
        "title": "Improving Under-Resourced Code-Switched Speech Recognition: Large Pre-trained Models or Architectural Interventions",
        "authors": "Joshua Jansen van Vüren, Thomas Niesler",
        "published": "2023-8-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1841"
    },
    {
        "id": 14056,
        "title": "A Hybrid Deep Learning Framework to Generate Locally Relevant Streamflow from Large Scale Hydrological Models&amp;#160;",
        "authors": "Bhanu Magotra, Manabendra Saharia",
        "published": "No Date",
        "citations": 0,
        "abstract": "&#160;The large scale physically based hydrological model outputs can exhibit uncertainties due to various sources such as model structure, parameterization, and inputs. Moreover, these outputs are often available at a coarser resolution due to high computational and data requirements, thus limiting their applicability in operational hydrology. In this study, we present a deep learning framework that reduces the uncertainty in the streamflow generated by a continental scale physical model, using a two-stage process. The hydrological model is setup over the Indian Subcontinent with outputs at 0.1&#176; and daily resolution from 1981-2021. The outputs, including streamflow, are generated by a six-member ensemble consisting of two land surface models (LSM) namely: Noah MP 3.6 and CLSM Fortuna v2.5, and three meteorological forcings namely: MERRA2, CHIRPS and IMD. First, we predict the residual in each of the six-member ensemble streamflow by training a Long Short-Term Memory Network (LSTM) on 220 catchments using dynamic meteorological inputs and static catchment attributes. Next, we pass the six corrected streamflow outputs to another LSTM layer that learns to optimally combine them along with integrating a three-day moving average of observed streamflow, generating an accurate prediction of 1-day ahead streamflow for each catchment. &#160;Our results showcase the efficacy of this hybrid framework in significantly enhancing the skill of large-scale hydrological models, imprpoving the national median Kling-Gupta Efficiency (KGE) from 0.01 to 0.628. Moreover, we reproduced extreme event conditions at specific locations with higher accuracy. This study leverages the power of deep learning and extensive observed data to derive locally relevant streamflow predictions from a large-scale hydrological model, offering practical solutions for refining hydrological models and informing water resource management strategies. &#160;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-15073"
    },
    {
        "id": 14057,
        "title": "Segmental Encoder-Decoder Models for Large Vocabulary Automatic Speech Recognition",
        "authors": "Eugen Beck, Mirko Hannemann, Patrick Dötsch, Ralf Schlüter, Hermann Ney",
        "published": "2018-9-2",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2018-1212"
    },
    {
        "id": 14058,
        "title": "Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models",
        "authors": "Shuai Zhao, Jinming Wen, Anh Luu, Junbo Zhao, Jie Fu",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.757"
    },
    {
        "id": 14059,
        "title": "Few-shot Subgoal Planning with Language Models",
        "authors": "Lajanugen Logeswaran, Yao Fu, Moontae Lee, Honglak Lee",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.402"
    },
    {
        "id": 14060,
        "title": "Gendered Mental Health Stigma in Masked Language Models",
        "authors": "Inna Lin, Lucille Njoo, Anjalie Field, Ashish Sharma, Katharina Reinecke, Tim Althoff, Yulia Tsvetkov",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.139"
    },
    {
        "id": 14061,
        "title": "Ensemble And Re-Ranking Based On Language Models To Improve ASR",
        "authors": "Shu-Fen Tsai, Shih-Chan Kuo, Ren-Yuan Lyu, Jyh-Shing Roger Jang",
        "published": "2022-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iscslp57327.2022.10038087"
    },
    {
        "id": 14062,
        "title": "Sequential use of spectral models to reduce deletion and insertion errors in vowel detection",
        "authors": "Hamidreza Baradaran Kashani, Abolghasem Sayadiyan",
        "published": "2018-7",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2017.12.008"
    },
    {
        "id": 14063,
        "title": "An Empirical Analysis of Memorization in Fine-tuned Autoregressive Language Models",
        "authors": "Fatemehsadat Mireshghallah, Archit Uniyal, Tianhao Wang, David Evans, Taylor Berg-Kirkpatrick",
        "published": "2022",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.119"
    },
    {
        "id": 14064,
        "title": "Classifying large strains from digital imagery: application to analogue models of lithosphere deformation",
        "authors": "Taco Broerse, Nemanja Krstekanic, Cor Kasbergen, Ernst Willingshofer",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;We are interested in reconstructing the time evolution of 2D plane deformation of analogue models of tectonic processes. Under relevant forcings, these models develop internal deformation, such as faults, and broader zones of deformation. We use Particle Image Velocimetry (PIV) to derive incremental displacements from top-view images that we use in subsequent steps to calculate the shape changes that come with large deformation. Because PIV describes displacement in a spatial reference, and material moves through the area in view, displacements at any given time refer to fixed locations in space, and not to specific material points. By reconstructing the path of material, we can follow small regions of material while they translate, rotate and change shape.&lt;/p&gt;&lt;p&gt;&lt;br&gt;To aid the qualitative interpretation of this deformation, we have developed a novel method that can qualitatively describe shape changes coming from extensional, shortening and horizontal shearing (strike-slip) deformation or combinations of these. This method is based on a logarithmic measure of stretch and results agree well with the visual interpretation of structures that we observe in our models. Thus, we provide tools with which the evolution of 2D tectonic deformation can be interpreted in a physically meaningful manner, but our method may be useful outside the realm of tectonics. Our software to compute deformation is freely available and can be used to post-process incremental displacements from PIV or similar autocorrelation methods.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu21-6046"
    },
    {
        "id": 14065,
        "title": "Amplitude effects allow short jetlags and large seasonal phase shifts in minimal clock models",
        "authors": "Bharath Ananthasubramaniam, Christoph Schmal, Hanspeter Herzel",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractMathematical models of varying complexity have helped shed light on different aspects of circadian clock function. In this work, we question whether minimal clock models (Goodwin models) are sufficient to reproduce essential phenotypes of the clock: a small phase response curve (PRC), fast jetlag and seasonal phase shifts. Instead of building a single best model, we take an approach where we study the properties of a set of models satisfying certain constraints; here a one-hour pulse PRC with a range of three hours and clock periods between 22h and 26h. Surprisingly, almost all these randomly parameterized models showed a four hour change in phase of entrainment between long and short days and jetlag durations of three to seven days in advance and delay. Moreover, intrinsic clock period influenced jetlag duration and entrainment amplitude and phase. Fast jetlag was realized in this model by means of an interesting amplitude effect: the association between clock amplitude and clock period termed ‘twist’. This twist allows amplitude changes to speed up and slow down clocks enabling faster shifts. These findings were robust to the addition of positive feedback to the model. In summary, the known design principles of rhythm generation – negative feedback, long delay and switch-like inhibition (we review these in detail) – are sufficient to reproduce the essential clock phenotypes. Furthermore, amplitudes play a role in determining clock properties and must be always considered, although they are difficult to measure.",
        "link": "http://dx.doi.org/10.1101/825331"
    },
    {
        "id": 14066,
        "title": "Streamflow forecasting at large time scales using statistical models",
        "authors": "Hristos Tyralis, Georgia Papacharalampous, Andreas Langousis",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-820673-7.00004-4"
    },
    {
        "id": 14067,
        "title": "Dual Variational Formulations for a Large Class of Non-Convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops dual variational formulations for a large class of models in variational optimization. The results are established through basic tools of functional analysis, convex analysis and duality theory. The main duality principle is developed as an application to a Ginzburg-Landau type system in superconductivity in the absence of a magnetic field. In the first sections, we develop new general dual convex variational formulations, more specifically, dual formulations with a large region of convexity around the critical points which are suitable for the non-convex optimization for a large class of models in physics and engineering. Finally, in the last section we present some numerical results concerning the generalized method of lines applied to a Ginzburg-Landau type equation.",
        "link": "http://dx.doi.org/10.20944/preprints202210.0091.v5"
    },
    {
        "id": 14068,
        "title": "Dual Variational Formulations for a Large Class of Non-Convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops dual variational formulations for a large class of models in variational optimization. The results are established through basic tools of functional analysis, convex analysis and duality theory. The main duality principle is developed as an application to a Ginzburg-Landau type system in superconductivity in the absence of a magnetic field. In the first part final sections, we develop new general dual convex variational formulations, more specifically, dual formulations with a large region of convexity around the critical points which are suitable for the non-convex optimization for a large class of models in physics and engineering. Finally, in the last section we present some numerical results concerning the generalized method of lines applied to a Ginzburg-Landau type equation.",
        "link": "http://dx.doi.org/10.20944/preprints202210.0091.v4"
    },
    {
        "id": 14069,
        "title": "Dual Variational Formulations for a Large Class of Non-Convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops dual variational formulations for a large class of models in variational optimization. The results are established through basic tools of functional analysis, convex analysis and duality theory. The main duality principle is developed as an application to a Ginzburg-Landau type system in superconductivity in the absence of a magnetic field. In the first sections, we develop new general dual convex variational formulations, more specifically, dual formulations with a large region of convexity around the critical points which are suitable for the non-convex optimization for a large class of models in physics and engineering. Finally, in the last section we present some numerical results concerning the generalized method of lines applied to a Ginzburg-Landau type equation.",
        "link": "http://dx.doi.org/10.20944/preprints202210.0091.v7"
    },
    {
        "id": 14070,
        "title": "ESTIMATION AND INFERENCE FOR VERY LARGE LINEAR MIXED EFFECTS MODELS",
        "authors": "Katelyn Gao, Art B. Owen",
        "published": "2020",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5705/ss.202018.0029"
    },
    {
        "id": 14071,
        "title": "SpeechMoE: Scaling to Large Acoustic Models with Dynamic Routing Mixture of Experts",
        "authors": "Zhao You, Shulin Feng, Dan Su, Dong Yu",
        "published": "2021-8-30",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-478"
    },
    {
        "id": 14072,
        "title": "Studying the history of the Arabic language: language technology and a large-scale historical corpus",
        "authors": "Yonatan Belinkov, Alexander Magidow, Alberto Barrón-Cedeño, Avi Shmidman, Maxim Romanov",
        "published": "2019-12",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10579-019-09460-w"
    },
    {
        "id": 14073,
        "title": "Solving Large Markov Models Described with Standard Programming Language",
        "authors": "P. Pecka, M. P. Nowak, A. Rataj, S. Nowak",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-00840-6_7"
    },
    {
        "id": 14074,
        "title": "Evaluation of General Large Language Models in Understanding Clinical Concepts Extracted from Adult Critical Care Electronic Health Record Notes",
        "authors": "Darren Liu, Cheng Ding, Delgersuren Bold, Monique Bouvier, Jiaying Lu, Benjamin Shickel, Craig S. Jabaley, Wenhui Zhang, Soojin Park, Michael Young, Mark  S. Wainwright, Gilles Clermont, Parisa Rashidi, Eric  S. Rosenthal, Laurie Dimisko, Xiao Ran, JooHeung Yoon, Carl Yang, Xiao Hu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4734730"
    },
    {
        "id": 14075,
        "title": "Enhancing phenotype recognition in clinical notes using large language models: PhenoBCBERT and PhenoGPT",
        "authors": "Jingye Yang, Cong Liu, Wendy Deng, Da Wu, Chunhua Weng, Yunyun Zhou, Kai Wang",
        "published": "2024-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patter.2023.100887"
    },
    {
        "id": 14076,
        "title": "Large language models as tax attorneys: a case study in legal capabilities emergence",
        "authors": "John J. Nay, David Karamardian, Sarah B. Lawsky, Wenting Tao, Meghana Bhat, Raghav Jain, Aaron Travis Lee, Jonathan H. Choi, Jungo Kasai",
        "published": "2024-4-15",
        "citations": 0,
        "abstract": "Better understanding of Large Language Models' (LLMs) legal analysis abilities can contribute to improving the efficiency of legal services, governing artificial intelligence and leveraging LLMs to identify inconsistencies in law. This paper explores LLM capabilities in applying tax law. We choose this area of law because it has a structure that allows us to set up automated validation pipelines across thousands of examples, requires logical reasoning and maths skills, and enables us to test LLM capabilities in a manner relevant to real-world economic lives of citizens and companies. Our experiments demonstrate emerging legal understanding capabilities, with improved performance in each subsequent OpenAI model release. We experiment with retrieving and using the relevant legal authority to assess the impact of providing additional legal context to LLMs. Few-shot prompting, presenting examples of question–answer pairs, is also found to significantly enhance the performance of the most advanced model, GPT-4. The findings indicate that LLMs, particularly when combined with prompting enhancements and the correct legal texts, can perform at high levels of accuracy but not yet at expert tax lawyer levels. As LLMs continue to advance, their ability to reason about law autonomously could have significant implications for the legal profession and AI governance.\nThis article is part of the theme issue ‘A complexity science approach to law and governance’.",
        "link": "http://dx.doi.org/10.1098/rsta.2023.0159"
    },
    {
        "id": 14077,
        "title": "The Potential Role of Large Language Models in Uveitis Care: Perspectives After ChatGPT and Bard Launch",
        "authors": "Collin Tan Yip Ming, William Rojas-Carabali, Carlos Cifuentes-González, Rajdeep Agrawal, Jennifer E. Thorne, Ilknur Tugal-Tutkun, Quan Dong Nguyen, Vishali Gupta, Alejandra de-la-Torre, Rupesh Agrawal",
        "published": "2023-8-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/09273948.2023.2242462"
    },
    {
        "id": 14078,
        "title": "Advanced prompting as a catalyst: Empowering large language models in the management of gastrointestinal cancers",
        "authors": "Jiajia Yuan, Peng Bao, Zifan Chen, Mingze Yuan, Jie Zhao, Jiahua Pan, Yi Xie, Yanshuo Cao, Yakun Wang, Zhenghang Wang, Zhihao Lu, Xiaotian Zhang, Jian Li, Lei Ma, Yang Chen, Li Zhang, Lin Shen, Bin Dong",
        "published": "2023",
        "citations": 0,
        "abstract": "<p>Large Language Models' (LLMs) performance in healthcare can be significantly impacted by prompt engineering. However, the area of study remains relatively uncharted in gastrointestinal oncology until now. Our research delves into this unexplored territory, investigating the efficacy of varied prompting strategies, including simple prompts, templated prompts, in-context learning (ICL), and multi-round iterative questioning, for optimizing the performance of LLMs within a medical setting. We develop a comprehensive evaluation system to assess the performance of LLMs across multiple dimensions. This robust evaluation system ensures a thorough assessment of the LLMs' capabilities in the field of medicine. Our findings suggest a positive relationship between the comprehensiveness of the prompts and the LLMs' performance. Notably, the multi-round strategy, which is characterized by iterative question-and-answer rounds, consistently yields the best results. ICL, a strategy that capitalizes on interrelated contextual learning, also displays significant promise, surpassing the outcomes achieved with simpler prompts. The research underscores the potential of advanced prompt engineering and iterative learning approaches for boosting the applicability of LLMs in healthcare. We recommend that additional research be conducted to refine these strategies and investigate their potential integration, to truly harness the full potential of LLMs in medical applications.</p>\n                            ",
        "link": "http://dx.doi.org/10.59717/j.xinn-med.2023.100019"
    },
    {
        "id": 14079,
        "title": "Analyzing the Use of Large Language Models for Content Moderation with ChatGPT Examples",
        "authors": "Mirko Franco, Ombretta Gaggi, Claudio E. Palazzi",
        "published": "2023-9-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3599696.3612895"
    },
    {
        "id": 14080,
        "title": "Using Large Language Models for Interpreting Autonomous Robots Behaviors",
        "authors": "Miguel Á. González-Santamarta, Laura Fernández-Becerra, David Sobrín-Hidalgo, Ángel Manuel Guerrero-Higueras, Irene González, Francisco J. Rodríguez Lera",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-40725-3_45"
    },
    {
        "id": 14081,
        "title": "Large-scale text analysis using generative language models: A case study in discovering public value expressions in AI patents",
        "authors": "Sergio Pelaez, Gaurav Verma, Barbara Ribeiro, Philip Shapira",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "Abstract\nWe put forward a novel approach using a generative language model (GPT-4) to produce labels and rationales for large-scale text analysis. The approach is used to discover public value expressions in patents. Using text (5.4 million sentences) for 154,934 US AI patent documents from the United States Patent and Trademark Office (USPTO), we design a semi-automated, human-supervised framework for identifying and labeling public value expressions in these sentences. A GPT-4 prompt is developed which includes definitions, guidelines, examples, and rationales for text classification. We evaluate the labels and rationales produced by GPT-4 using BLEU scores and topic modeling, finding that they are accurate, diverse, and faithful. GPT-4 achieved an advanced recognition of public value expressions from our framework, which it also uses to discover unseen public value expressions. The GPT-produced labels are used to train BERT-based classifiers and predict sentences on the entire database, achieving high F1 scores for the 3-class (0.85) and 2-class classification (0.91) tasks. We discuss the implications of our approach for conducting large-scale text analyses with complex and abstract concepts. With careful framework design and interactive human oversight, we suggest that generative language models can offer significant assistance in producing labels and rationales.\n\nPeer Review\nhttps://www.webofscience.com/api/gateway/wos/peer-review/10.1162/qss_a_00285\n",
        "link": "http://dx.doi.org/10.1162/qss_a_00285"
    },
    {
        "id": 14082,
        "title": "Large language models can match junior clinicians in discharge letter writing: a single-blinded study (Preprint)",
        "authors": "Joshua Yi Min Tung, Sunil Ravinder Gill, Gerald Gui Ren Sng, Daniel Yan Zheng Lim, Yuhe Ke, Ting Fang Tan, Liyuan Jin, Kabilan Elangovan, Jasmine Chiat Ling Ong, Hairil Rizal Abdullah, Daniel Shu Wei Ting, Tsung Wen Chong",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nDischarge letters are a critical component in continuity of care between specialists and primary care providers, but are time-consuming to write, under-prioritized in comparison to direct clinical care, and are often tasked to junior doctors. Prior studies assessing the quality of discharge summaries written for inpatient hospital admissions show inadequacies in many domains. Large language models such as GPT have the ability to summarize large volumes of unstructured free text, such as electronic medical records, and have the potential to automate such tasks, providing time savings and consistency in quality.\n\n\nOBJECTIVE\nTo assess the performance of GPT-4 in generating discharge letters written from Urology specialist outpatient clinics to primary care providers, and compare their quality against letters written by junior clinicians.\n\n\nMETHODS\nFictional electronic records were written by physicians, simulating five common Urology outpatient cases with long-term follow-up. Records comprised simulated consultation notes, referral letters and replies, and relevant discharge summaries from inpatient admissions. GPT-4 was tasked to write discharge letters for these cases, with a specified target audience of primary care providers who would be continuing the patient’s care. Prompts were written for safety, content, and style. Concurrently, junior clinicians were provided with the same case records and instructional prompts. GPT-4 output was assessed by the study team for instances of hallucination. A blinded panel of primary care physicians then evaluated the letters using a standardized questionnaire tool.\n\n\nRESULTS\nGPT-4 outperformed human counterparts in information provision, but was less concise. GPT-4 had no instances of hallucination. There were no statistical differences in the clarity, collegiality, follow-up recommendations, and overall satisfaction between letters generated by humans and by GPT-4.\n\n\nCONCLUSIONS\nDischarge letters written by GPT-4 had equivalent quality to those written by junior clinicians, without any hallucinations. This study demonstrates proof of concept that LLMs can be useful and safe tools in clinical documentation.\n",
        "link": "http://dx.doi.org/10.2196/preprints.57721"
    },
    {
        "id": 14083,
        "title": "Practical and ethical challenges of large language models in education: A systematic scoping review",
        "authors": "Lixiang Yan, Lele Sha, Linxuan Zhao, Yuheng Li, Roberto Martinez‐Maldonado, Guanliang Chen, Xinyu Li, Yueqiao Jin, Dragan Gašević",
        "published": "2024-1",
        "citations": 20,
        "abstract": "AbstractEducational technology innovations leveraging large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (eg, question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs‐based innovations in authentic educational contexts. To address this, we conducted a systematic scoping review of 118 peer‐reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The findings revealed 53 use cases for LLMs in automating education tasks, categorised into nine main categories: profiling/labelling, detection, grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation. Additionally, we also identified several practical and ethical challenges, including low technological readiness, lack of replicability and transparency and insufficient privacy and beneficence considerations. The findings were summarised into three recommendations for future studies, including updating existing innovations with state‐of‐the‐art models (eg, GPT‐3/4), embracing the initiative of open‐sourcing models/systems, and adopting a human‐centred approach throughout the developmental process. As the intersection of AI and education is continuously evolving, the findings of this study can serve as an essential reference point for researchers, allowing them to leverage the strengths, learn from the limitations, and uncover potential research opportunities enabled by ChatGPT and other generative AI models.\nPractitioner notesWhat is currently known about this topic\n\nGenerating and analysing text‐based content are time‐consuming and laborious tasks.\nLarge language models are capable of efficiently analysing an unprecedented amount of textual content and completing complex natural language processing and generation tasks.\nLarge language models have been increasingly used to develop educational technologies that aim to automate the generation and analysis of textual content, such as automated question generation and essay scoring.\nWhat this paper adds\n\nA comprehensive list of different educational tasks that could potentially benefit from LLMs‐based innovations through automation.\nA structured assessment of the practicality and ethicality of existing LLMs‐based innovations from seven important aspects using established frameworks.\nThree recommendations that could potentially support future studies to develop LLMs‐based innovations that are practical and ethical to implement in authentic educational contexts.\nImplications for practice and/or policy\n\nUpdating existing innovations with state‐of‐the‐art models may further reduce the amount of manual effort required for adapting existing models to different educational tasks.\nThe reporting standards of empirical research that aims to develop educational technologies using large language models need to be improved.\nAdopting a human‐centred approach throughout the developmental process could contribute to resolving the practical and ethical challenges of large language models in education.\n\n",
        "link": "http://dx.doi.org/10.1111/bjet.13370"
    },
    {
        "id": 14084,
        "title": "Large Language Models are Zero-Shot Rankers for Recommender Systems",
        "authors": "Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley, Wayne Xin Zhao",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-56060-6_24"
    },
    {
        "id": 14085,
        "title": "Designing Ecosystem Business Models: a Multi-Proj ect Approach",
        "authors": "Yana Matkovskaya",
        "published": "2022-9-26",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd55143.2022.9934242"
    },
    {
        "id": 14086,
        "title": "Persistence of Averages in Financial Markov Switching Models: A Large Deviations Approach",
        "authors": "Michael Jay Stutzer",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3505614"
    },
    {
        "id": 14087,
        "title": "Large Volatility Matrix Analysis Using Global and National Factor Models",
        "authors": "Sung Hoon Choi, Donggyu Kim",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4200781"
    },
    {
        "id": 14088,
        "title": "Large (and Deep) Factor Models",
        "authors": "Bryan T. Kelly, Boris Kuznetsov, Semyon Malamud, Teng Andrea Xu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4679269"
    },
    {
        "id": 14089,
        "title": "2. Large global-in-time solutions to models of chemotaxis",
        "authors": "",
        "published": "2019-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110599534-002"
    },
    {
        "id": 14090,
        "title": "Large-scale exploration of feature sets and deep learning models to classify malicious applications",
        "authors": "Tristan Vanderbruggen, John Cavazos",
        "published": "2017-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/rweek.2017.8088645"
    },
    {
        "id": 14091,
        "title": "Theory and Issues in Distributed Simulation Cloning",
        "authors": "Dan Chen, Lizhe Wang, Jingying Chen",
        "published": "2017-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b11883-6"
    },
    {
        "id": 14092,
        "title": "Large biases in hydrography and circulation of the Arctic Ocean in CMIP6 models",
        "authors": "Céline Heuzé, Hannah Zanowski, Salar Karam, Morven Muilwijk",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Climate models are our best tools to quantify ongoing changes caused by the climate crisis, but they are not perfect. The Arctic Ocean is particularly challenging to simulate: complex circulation flowing through narrow gateways and around tortuous bathymetry, dense water cascading off the steep shelf break, slow exchanges in canyons, along with known biases in sea ice and neighbouring seas.&lt;/p&gt;&lt;p&gt;We investigate the Arctic Ocean in the historical run of 14 distinct models that participated to the latest Climate Model Intercomparison Project phase 6 (CMIP6) and find large biases in temperature, salinity, density, and depth of critical water masses, both on the shelves and in the deep basins. The biases are consistent throughout the water column and throughout the Arctic, with correlations often exceeding 0.9. However, no significant trend is observed in these biases, suggesting that the deep basins of the Arctic are not correctly ventilated already at the level of the Atlantic Water.&lt;/p&gt;&lt;p&gt;Using the subset of models that submitted the age of water output, we confirm this absence of ventilation by dense water overflows: the overflows occur at too few locations and are diluted at shallow depths.&amp;#160;&amp;#160;&amp;#160;&lt;/p&gt;&lt;p&gt;Work is ongoing to relate these biases to the relevant processes, the upper water column, and fluxes through the various Arctic Ocean gateways.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu22-1760"
    },
    {
        "id": 14093,
        "title": "Distilling Monolingual Models from Large Multilingual Transformers",
        "authors": "Pranaydeep Singh, Orphée De Clercq, Els Lefever",
        "published": "2023-2-18",
        "citations": 1,
        "abstract": "Although language modeling has been trending upwards steadily, models available for low-resourced languages are limited to large multilingual models such as mBERT and XLM-RoBERTa, which come with significant overheads for deployment vis-à-vis their model size, inference speeds, etc. We attempt to tackle this problem by proposing a novel methodology to apply knowledge distillation techniques to filter language-specific information from a large multilingual model into a small, fast monolingual model that can often outperform the teacher model. We demonstrate the viability of this methodology on two downstream tasks each for six languages. We further dive into the possible modifications to the basic setup for low-resourced languages by exploring ideas to tune the final vocabulary of the distilled models. Lastly, we perform a detailed ablation study to understand the different components of the setup better and find out what works best for the two under-resourced languages, Swahili and Slovene.",
        "link": "http://dx.doi.org/10.3390/electronics12041022"
    },
    {
        "id": 14094,
        "title": "Instrumental Variable Estimation of Large Panel Data Models with Common Factors",
        "authors": "Sebastian Kripfganz, Vasilis Sarafidis",
        "published": "No Date",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3668588"
    },
    {
        "id": 14095,
        "title": "Dual Variational Formulations for a Large Class of Non-Convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops dual variational formulations for a large class of models in variational optimization. The results are established through basic tools of functional analysis, convex analysis and duality theory. The main duality principle is developed as an application to a Ginzburg-Landau type system in superconductivity in the absence of a magnetic field. In the first sections, we develop new general dual convex variational formulations, more specifically, dual formulations with a large region of convexity around the critical points which are suitable for the non-convex optimization for a large class of models in physics and engineering. Finally, in the last section we present some numerical results concerning the generalized method of lines applied to a Ginzburg-Landau type equation.",
        "link": "http://dx.doi.org/10.20944/preprints202210.0091.v9"
    },
    {
        "id": 14096,
        "title": "Immune Response Associated with Islet Xenotransplantation in Small and Large Animal Models",
        "authors": "Jennifer Croden, Wenlong Huang, Gina R. Rayat",
        "published": "2017-7-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5772/intechopen.68999"
    },
    {
        "id": 14097,
        "title": "Decision letter: Hypoexcitability precedes denervation in the large fast-contracting motor units in two unrelated mouse models of ALS",
        "authors": "",
        "published": "2017-10-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.30955.018"
    },
    {
        "id": 14098,
        "title": "Models and methods of the business processes theory",
        "authors": "Georgyi N. Kalyanov",
        "published": "2017-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2017.8109642"
    },
    {
        "id": 14099,
        "title": "Large Deviations of Factor Models with Regularly-Varying Tails:  Asymptotics and Efficient Estimation",
        "authors": "Farzad Pourbabaee",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2931587"
    },
    {
        "id": 14100,
        "title": "Dual Variational Formulations for a Large Class of Non-Convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops dual variational formulations for a large class of models in variational optimization. The results are established through basic tools of functional analysis, convex analysis and duality theory. The main duality principle is developed as an application to a Ginzburg-Landau type system in superconductivity in the absence of a magnetic field. In the first part final sections, we develop new general dual convex variational formulations, more specifically, dual formulations with a large region of convexity around the critical points which are suitable for the non-convex optimization for a large class of models in physics and engineering. Finally, in the last section we present some numerical results concerning the generalized method of lines applied to a Ginzburg-Landau type equation.",
        "link": "http://dx.doi.org/10.20944/preprints202210.0091.v3"
    },
    {
        "id": 14101,
        "title": "2. Large global-in-time solutions to models of chemotaxis",
        "authors": "",
        "published": "2019-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110599534-002"
    },
    {
        "id": 14102,
        "title": "Persistence of Averages in Financial Markov Switching Models: A Large Deviations Approach",
        "authors": "Michael Jay Stutzer",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3505614"
    },
    {
        "id": 14103,
        "title": "Large (and Deep) Factor Models",
        "authors": "Bryan T. Kelly, Boris Kuznetsov, Semyon Malamud, Teng Andrea Xu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4679269"
    },
    {
        "id": 14104,
        "title": "Large Volatility Matrix Analysis Using Global and National Factor Models",
        "authors": "Sung Hoon Choi, Donggyu Kim",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4200781"
    },
    {
        "id": 14105,
        "title": "A Unified Numerical Approach for a Large Class of Nonlinear Black-Scholes Models",
        "authors": "Miglena N. Koleva, Lubin G. Vulkov",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-73441-5_64"
    },
    {
        "id": 14106,
        "title": "The Impact of Large Language Modeling on Natural Language Processing in Legal Texts: A Comprehensive Survey",
        "authors": "Dang Hoang Anh, Dinh-Truong Do, Vu Tran, Nguyen Le Minh",
        "published": "2023-10-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/kse59128.2023.10299488"
    },
    {
        "id": 14107,
        "title": "BreizhCorpus: A Large Breton Language Speech Corpus and Its Use for Text-to-Speech Synthesis",
        "authors": "David Guennec, Hassan Hajipoor, Gwénolé Lecorvé, Pascal Lintanf, Damien Lolive, Antoine Perquin, Gaëlle Vidal",
        "published": "2022-6-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/odyssey.2022-37"
    },
    {
        "id": 14108,
        "title": "CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model",
        "authors": "Kaiyan Zhang, Ning Ding, Biqing Qi, Xuekai Zhu, Xinwei Long, Bowen Zhou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.597"
    },
    {
        "id": 14109,
        "title": "Ensemble And Re-Ranking Based On Language Models To Improve ASR",
        "authors": "Shu-Fen Tsai, Shih-Chan Kuo, Ren-Yuan Lyu, Jyh-Shing Roger Jang",
        "published": "2022-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iscslp57327.2022.10038087"
    },
    {
        "id": 14110,
        "title": "Sequential use of spectral models to reduce deletion and insertion errors in vowel detection",
        "authors": "Hamidreza Baradaran Kashani, Abolghasem Sayadiyan",
        "published": "2018-7",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2017.12.008"
    },
    {
        "id": 14111,
        "title": "Few-shot Subgoal Planning with Language Models",
        "authors": "Lajanugen Logeswaran, Yao Fu, Moontae Lee, Honglak Lee",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.402"
    },
    {
        "id": 14112,
        "title": "Gendered Mental Health Stigma in Masked Language Models",
        "authors": "Inna Lin, Lucille Njoo, Anjalie Field, Ashish Sharma, Katharina Reinecke, Tim Althoff, Yulia Tsvetkov",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.139"
    },
    {
        "id": 14113,
        "title": "Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models",
        "authors": "Shuai Zhao, Jinming Wen, Anh Luu, Junbo Zhao, Jie Fu",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.757"
    },
    {
        "id": 14114,
        "title": "An Empirical Analysis of Memorization in Fine-tuned Autoregressive Language Models",
        "authors": "Fatemehsadat Mireshghallah, Archit Uniyal, Tianhao Wang, David Evans, Taylor Berg-Kirkpatrick",
        "published": "2022",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.119"
    },
    {
        "id": 14115,
        "title": "Chinese Medical Named Entity Recognition Based on Chinese Character Radical Features and Pre-trained Language Models",
        "authors": "Haixin Tan, Zhihao Yang, Jinzhong Ning, Zeyuan Ding, Qiming Liu",
        "published": "2021-12-11",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ialp54817.2021.9675274"
    },
    {
        "id": 14116,
        "title": "Knowledge-Grounded Dialogue Generation with Pre-trained Language Models",
        "authors": "Xueliang Zhao, Wei Wu, Can Xu, Chongyang Tao, Dongyan Zhao, Rui Yan",
        "published": "2020",
        "citations": 42,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.272"
    },
    {
        "id": 14117,
        "title": "BabyStories: Can Reinforcement Learning Teach Baby Language Models to Write Better Stories?",
        "authors": "Xingmeng Zhao, Tongnian Wang, Sheri Osborn, Anthony Rios",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-babylm.16"
    },
    {
        "id": 14118,
        "title": "A Predictive Factor Analysis of Social Biases and Task-Performance in Pretrained Masked Language Models",
        "authors": "Yi Zhou, Jose Camacho-Collados, Danushka Bollegala",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.683"
    },
    {
        "id": 14119,
        "title": "Increasing The Performance of Cognitively Inspired Data-Efficient Language Models via Implicit Structure Building",
        "authors": "Omar Momen, David Arps, Laura Kallmeyer",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-babylm.29"
    },
    {
        "id": 14120,
        "title": "Understanding the Role of Input Token Characters in Language Models: How Does Information Loss Affect Performance?",
        "authors": "Ahmed Alajrami, Katerina Margatina, Nikolaos Aletras",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.563"
    },
    {
        "id": 14121,
        "title": "Large population and size scale limit of a stochastic particle model",
        "authors": "Philippe Michel",
        "published": "2017-3",
        "citations": 1,
        "abstract": " The aim of this work is to study a stochastic individual-based model, structured with respect to age (progression within the cell cycle) and space (radial distance from the oocyte). We prove the existence of solutions and the convergence in large population and size scale limit to a solution of a partial differential equation. ",
        "link": "http://dx.doi.org/10.1142/s0218202517500105"
    },
    {
        "id": 14122,
        "title": "Statistical characteristics of anomalously large surface waves based on computational experiments",
        "authors": "R. V. Shamin, A. V. Yudin",
        "published": "2017-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1134/s2070048217020107"
    },
    {
        "id": 14123,
        "title": "Subgrid Models, Reaction Mechanisms, and Combustion Models in Large-Eddy Simulation of Supersonic Combustion",
        "authors": "C. Fureby",
        "published": "2021-1",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2514/1.j059597"
    },
    {
        "id": 14124,
        "title": "Accelerated evidence synthesis in orthopaedics—the roles of natural language processing, expert annotation and large language models",
        "authors": "Bálint Zsidai, Janina Kaarre, Ann‐Sophie Hilkert, Eric Narup, Eric Hamrin Senorski, Alberto Grassi, Olufemi R. Ayeni, Volker Musahl, Christophe Ley, Elmar Herbst, Michael T. Hirschmann, Sebastian Kopf, Romain Seil, Thomas Tischer, Kristian Samuelsson, Robert Feldt,  ",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s40634-023-00662-4"
    },
    {
        "id": 14125,
        "title": "Solving Large Markov Models Described with Standard Programming Language",
        "authors": "P. Pecka, M. P. Nowak, A. Rataj, S. Nowak",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-00840-6_7"
    },
    {
        "id": 14126,
        "title": "Analyzing the Use of Large Language Models for Content Moderation with ChatGPT Examples",
        "authors": "Mirko Franco, Ombretta Gaggi, Claudio E. Palazzi",
        "published": "2023-9-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3599696.3612895"
    },
    {
        "id": 14127,
        "title": "Practical and ethical challenges of large language models in education: A systematic scoping review",
        "authors": "Lixiang Yan, Lele Sha, Linxuan Zhao, Yuheng Li, Roberto Martinez‐Maldonado, Guanliang Chen, Xinyu Li, Yueqiao Jin, Dragan Gašević",
        "published": "2024-1",
        "citations": 20,
        "abstract": "AbstractEducational technology innovations leveraging large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (eg, question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs‐based innovations in authentic educational contexts. To address this, we conducted a systematic scoping review of 118 peer‐reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The findings revealed 53 use cases for LLMs in automating education tasks, categorised into nine main categories: profiling/labelling, detection, grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation. Additionally, we also identified several practical and ethical challenges, including low technological readiness, lack of replicability and transparency and insufficient privacy and beneficence considerations. The findings were summarised into three recommendations for future studies, including updating existing innovations with state‐of‐the‐art models (eg, GPT‐3/4), embracing the initiative of open‐sourcing models/systems, and adopting a human‐centred approach throughout the developmental process. As the intersection of AI and education is continuously evolving, the findings of this study can serve as an essential reference point for researchers, allowing them to leverage the strengths, learn from the limitations, and uncover potential research opportunities enabled by ChatGPT and other generative AI models.\nPractitioner notesWhat is currently known about this topic\n\nGenerating and analysing text‐based content are time‐consuming and laborious tasks.\nLarge language models are capable of efficiently analysing an unprecedented amount of textual content and completing complex natural language processing and generation tasks.\nLarge language models have been increasingly used to develop educational technologies that aim to automate the generation and analysis of textual content, such as automated question generation and essay scoring.\nWhat this paper adds\n\nA comprehensive list of different educational tasks that could potentially benefit from LLMs‐based innovations through automation.\nA structured assessment of the practicality and ethicality of existing LLMs‐based innovations from seven important aspects using established frameworks.\nThree recommendations that could potentially support future studies to develop LLMs‐based innovations that are practical and ethical to implement in authentic educational contexts.\nImplications for practice and/or policy\n\nUpdating existing innovations with state‐of‐the‐art models may further reduce the amount of manual effort required for adapting existing models to different educational tasks.\nThe reporting standards of empirical research that aims to develop educational technologies using large language models need to be improved.\nAdopting a human‐centred approach throughout the developmental process could contribute to resolving the practical and ethical challenges of large language models in education.\n\n",
        "link": "http://dx.doi.org/10.1111/bjet.13370"
    },
    {
        "id": 14128,
        "title": "Using Large Language Models for Interpreting Autonomous Robots Behaviors",
        "authors": "Miguel Á. González-Santamarta, Laura Fernández-Becerra, David Sobrín-Hidalgo, Ángel Manuel Guerrero-Higueras, Irene González, Francisco J. Rodríguez Lera",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-40725-3_45"
    },
    {
        "id": 14129,
        "title": "Advanced prompting as a catalyst: Empowering large language models in the management of gastrointestinal cancers",
        "authors": "Jiajia Yuan, Peng Bao, Zifan Chen, Mingze Yuan, Jie Zhao, Jiahua Pan, Yi Xie, Yanshuo Cao, Yakun Wang, Zhenghang Wang, Zhihao Lu, Xiaotian Zhang, Jian Li, Lei Ma, Yang Chen, Li Zhang, Lin Shen, Bin Dong",
        "published": "2023",
        "citations": 0,
        "abstract": "<p>Large Language Models' (LLMs) performance in healthcare can be significantly impacted by prompt engineering. However, the area of study remains relatively uncharted in gastrointestinal oncology until now. Our research delves into this unexplored territory, investigating the efficacy of varied prompting strategies, including simple prompts, templated prompts, in-context learning (ICL), and multi-round iterative questioning, for optimizing the performance of LLMs within a medical setting. We develop a comprehensive evaluation system to assess the performance of LLMs across multiple dimensions. This robust evaluation system ensures a thorough assessment of the LLMs' capabilities in the field of medicine. Our findings suggest a positive relationship between the comprehensiveness of the prompts and the LLMs' performance. Notably, the multi-round strategy, which is characterized by iterative question-and-answer rounds, consistently yields the best results. ICL, a strategy that capitalizes on interrelated contextual learning, also displays significant promise, surpassing the outcomes achieved with simpler prompts. The research underscores the potential of advanced prompt engineering and iterative learning approaches for boosting the applicability of LLMs in healthcare. We recommend that additional research be conducted to refine these strategies and investigate their potential integration, to truly harness the full potential of LLMs in medical applications.</p>\n                            ",
        "link": "http://dx.doi.org/10.59717/j.xinn-med.2023.100019"
    },
    {
        "id": 14130,
        "title": "Large language models as tax attorneys: a case study in legal capabilities emergence",
        "authors": "John J. Nay, David Karamardian, Sarah B. Lawsky, Wenting Tao, Meghana Bhat, Raghav Jain, Aaron Travis Lee, Jonathan H. Choi, Jungo Kasai",
        "published": "2024-4-15",
        "citations": 0,
        "abstract": "Better understanding of Large Language Models' (LLMs) legal analysis abilities can contribute to improving the efficiency of legal services, governing artificial intelligence and leveraging LLMs to identify inconsistencies in law. This paper explores LLM capabilities in applying tax law. We choose this area of law because it has a structure that allows us to set up automated validation pipelines across thousands of examples, requires logical reasoning and maths skills, and enables us to test LLM capabilities in a manner relevant to real-world economic lives of citizens and companies. Our experiments demonstrate emerging legal understanding capabilities, with improved performance in each subsequent OpenAI model release. We experiment with retrieving and using the relevant legal authority to assess the impact of providing additional legal context to LLMs. Few-shot prompting, presenting examples of question–answer pairs, is also found to significantly enhance the performance of the most advanced model, GPT-4. The findings indicate that LLMs, particularly when combined with prompting enhancements and the correct legal texts, can perform at high levels of accuracy but not yet at expert tax lawyer levels. As LLMs continue to advance, their ability to reason about law autonomously could have significant implications for the legal profession and AI governance.\nThis article is part of the theme issue ‘A complexity science approach to law and governance’.",
        "link": "http://dx.doi.org/10.1098/rsta.2023.0159"
    },
    {
        "id": 14131,
        "title": "Large language models can match junior clinicians in discharge letter writing: a single-blinded study (Preprint)",
        "authors": "Joshua Yi Min Tung, Sunil Ravinder Gill, Gerald Gui Ren Sng, Daniel Yan Zheng Lim, Yuhe Ke, Ting Fang Tan, Liyuan Jin, Kabilan Elangovan, Jasmine Chiat Ling Ong, Hairil Rizal Abdullah, Daniel Shu Wei Ting, Tsung Wen Chong",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nDischarge letters are a critical component in continuity of care between specialists and primary care providers, but are time-consuming to write, under-prioritized in comparison to direct clinical care, and are often tasked to junior doctors. Prior studies assessing the quality of discharge summaries written for inpatient hospital admissions show inadequacies in many domains. Large language models such as GPT have the ability to summarize large volumes of unstructured free text, such as electronic medical records, and have the potential to automate such tasks, providing time savings and consistency in quality.\n\n\nOBJECTIVE\nTo assess the performance of GPT-4 in generating discharge letters written from Urology specialist outpatient clinics to primary care providers, and compare their quality against letters written by junior clinicians.\n\n\nMETHODS\nFictional electronic records were written by physicians, simulating five common Urology outpatient cases with long-term follow-up. Records comprised simulated consultation notes, referral letters and replies, and relevant discharge summaries from inpatient admissions. GPT-4 was tasked to write discharge letters for these cases, with a specified target audience of primary care providers who would be continuing the patient’s care. Prompts were written for safety, content, and style. Concurrently, junior clinicians were provided with the same case records and instructional prompts. GPT-4 output was assessed by the study team for instances of hallucination. A blinded panel of primary care physicians then evaluated the letters using a standardized questionnaire tool.\n\n\nRESULTS\nGPT-4 outperformed human counterparts in information provision, but was less concise. GPT-4 had no instances of hallucination. There were no statistical differences in the clarity, collegiality, follow-up recommendations, and overall satisfaction between letters generated by humans and by GPT-4.\n\n\nCONCLUSIONS\nDischarge letters written by GPT-4 had equivalent quality to those written by junior clinicians, without any hallucinations. This study demonstrates proof of concept that LLMs can be useful and safe tools in clinical documentation.\n",
        "link": "http://dx.doi.org/10.2196/preprints.57721"
    },
    {
        "id": 14132,
        "title": "Evaluation of General Large Language Models in Understanding Clinical Concepts Extracted from Adult Critical Care Electronic Health Record Notes",
        "authors": "Darren Liu, Cheng Ding, Delgersuren Bold, Monique Bouvier, Jiaying Lu, Benjamin Shickel, Craig S. Jabaley, Wenhui Zhang, Soojin Park, Michael Young, Mark  S. Wainwright, Gilles Clermont, Parisa Rashidi, Eric  S. Rosenthal, Laurie Dimisko, Xiao Ran, JooHeung Yoon, Carl Yang, Xiao Hu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4734730"
    },
    {
        "id": 14133,
        "title": "Large-scale text analysis using generative language models: A case study in discovering public value expressions in AI patents",
        "authors": "Sergio Pelaez, Gaurav Verma, Barbara Ribeiro, Philip Shapira",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "Abstract\nWe put forward a novel approach using a generative language model (GPT-4) to produce labels and rationales for large-scale text analysis. The approach is used to discover public value expressions in patents. Using text (5.4 million sentences) for 154,934 US AI patent documents from the United States Patent and Trademark Office (USPTO), we design a semi-automated, human-supervised framework for identifying and labeling public value expressions in these sentences. A GPT-4 prompt is developed which includes definitions, guidelines, examples, and rationales for text classification. We evaluate the labels and rationales produced by GPT-4 using BLEU scores and topic modeling, finding that they are accurate, diverse, and faithful. GPT-4 achieved an advanced recognition of public value expressions from our framework, which it also uses to discover unseen public value expressions. The GPT-produced labels are used to train BERT-based classifiers and predict sentences on the entire database, achieving high F1 scores for the 3-class (0.85) and 2-class classification (0.91) tasks. We discuss the implications of our approach for conducting large-scale text analyses with complex and abstract concepts. With careful framework design and interactive human oversight, we suggest that generative language models can offer significant assistance in producing labels and rationales.\n\nPeer Review\nhttps://www.webofscience.com/api/gateway/wos/peer-review/10.1162/qss_a_00285\n",
        "link": "http://dx.doi.org/10.1162/qss_a_00285"
    },
    {
        "id": 14134,
        "title": "The Potential Role of Large Language Models in Uveitis Care: Perspectives After ChatGPT and Bard Launch",
        "authors": "Collin Tan Yip Ming, William Rojas-Carabali, Carlos Cifuentes-González, Rajdeep Agrawal, Jennifer E. Thorne, Ilknur Tugal-Tutkun, Quan Dong Nguyen, Vishali Gupta, Alejandra de-la-Torre, Rupesh Agrawal",
        "published": "2023-8-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/09273948.2023.2242462"
    },
    {
        "id": 14135,
        "title": "Large Language Models are Zero-Shot Rankers for Recommender Systems",
        "authors": "Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley, Wayne Xin Zhao",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-56060-6_24"
    },
    {
        "id": 14136,
        "title": "Enhancing phenotype recognition in clinical notes using large language models: PhenoBCBERT and PhenoGPT",
        "authors": "Jingye Yang, Cong Liu, Wendy Deng, Da Wu, Chunhua Weng, Yunyun Zhou, Kai Wang",
        "published": "2024-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patter.2023.100887"
    },
    {
        "id": 14137,
        "title": "Cross-Lingual Speaker Identification for Indian Languages",
        "authors": "Amaan Rizvi,  , Anupam Jamatia, Dwijen Rudrapal, Kunal Chakma, Björn Gambäck,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_105"
    },
    {
        "id": 14138,
        "title": "Studying the history of the Arabic language: language technology and a large-scale historical corpus",
        "authors": "Yonatan Belinkov, Alexander Magidow, Alberto Barrón-Cedeño, Avi Shmidman, Maxim Romanov",
        "published": "2019-12",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10579-019-09460-w"
    },
    {
        "id": 14139,
        "title": "Evaluating Explanations for Software Patches Generated by Large Language Models",
        "authors": "Dominik Sobania, Alina Geiger, James Callan, Alexander Brownlee, Carol Hanna, Rebecca Moussa, Mar Zamorano López, Justyna Petke, Federica Sarro",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-48796-5_12"
    },
    {
        "id": 14140,
        "title": "Intelligent Practices of Large Language Models in Digital Government Services",
        "authors": "Jiawei Han, Jiankang Lu, Ying Xu, Jin You, Bingxin Wu",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2024.3349969"
    },
    {
        "id": 14141,
        "title": "Large Language Models for Education: Grading Open-Ended Questions Using ChatGPT",
        "authors": "Gustavo Pinto, Isadora Cardoso-Pereira, Danilo Monteiro, Danilo Lucena, Alberto Souza, Kiev Gama",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3613372.3614197"
    },
    {
        "id": 14142,
        "title": "Decision-Making in Robotic Grasping with Large Language Models",
        "authors": "Jianfeng Liao, Haoyang Zhang, Haofu Qian, Qiwei Meng, Yinan Sun, Yao Sun, Wei Song, Shiqiang Zhu, Jason Gu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-6495-6_36"
    },
    {
        "id": 14143,
        "title": "Leveraging Large Language Models for Topic Classification in the Domain of Public Affairs",
        "authors": "Alejandro Peña, Aythami Morales, Julian Fierrez, Ignacio Serna, Javier Ortega-Garcia, Íñigo Puente, Jorge Córdova, Gonzalo Córdova",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-41498-5_2"
    },
    {
        "id": 14144,
        "title": "Application of Large Language Models to DDoS Attack Detection",
        "authors": "Michael Guastalla, Yiyi Li, Arvin Hekmati, Bhaskar Krishnamachari",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-51630-6_6"
    },
    {
        "id": 14145,
        "title": "Transforming Building Industry Knowledge Management: A Study on the Role of Large Language Models in Fire Safety Planning",
        "authors": "Ori Ashkenazi, Shabtai Isaac, Alberto Giretti, Alessandro Carbonari, Dilan Durmus",
        "published": "2023",
        "citations": 0,
        "abstract": "This paper discusses the potential use of AI in general, and large language models (LLMs) in particular, to support knowledge management (KM) in the building industry. The application of conventional methods and tools for KM in the building industry is currently limited due to the large variability of buildings, and the industry’s fragmentation. Instead, relatively labor-intensive methods need to be employed to curate the knowledge gained in previous projects and make it accessible for use in future projects. The recent development of LLMs has the potential to develop new approaches to KM in the building industry. These may include querying a variety of relatively unstructured documents from previous projects and other textual sources of technical expertise, processing these data to create knowledge, identifying patterns, and storing knowledge for future use. A proposed framework is defined for the use of LLMs for KM in construction. We will perform preliminary analyses on how to train models that can generate information and knowledge required to make decisions in the development of specific tasks of fire safety planning",
        "link": "http://dx.doi.org/10.36253/10.36253/979-12-215-0289-3.73"
    },
    {
        "id": 14146,
        "title": "Transforming Building Industry Knowledge Management: A Study on the Role of Large Language Models in Fire Safety Planning",
        "authors": "Ori Ashkenazi, Shabtai Isaac, Alberto Giretti, Alessandro Carbonari, Dilan Durmus",
        "published": "2023",
        "citations": 0,
        "abstract": "This paper discusses the potential use of AI in general, and large language models (LLMs) in particular, to support knowledge management (KM) in the building industry. The application of conventional methods and tools for KM in the building industry is currently limited due to the large variability of buildings, and the industry’s fragmentation. Instead, relatively labor-intensive methods need to be employed to curate the knowledge gained in previous projects and make it accessible for use in future projects. The recent development of LLMs has the potential to develop new approaches to KM in the building industry. These may include querying a variety of relatively unstructured documents from previous projects and other textual sources of technical expertise, processing these data to create knowledge, identifying patterns, and storing knowledge for future use. A proposed framework is defined for the use of LLMs for KM in construction. We will perform preliminary analyses on how to train models that can generate information and knowledge required to make decisions in the development of specific tasks of fire safety planning",
        "link": "http://dx.doi.org/10.36253/979-12-215-0289-3.73"
    },
    {
        "id": 14147,
        "title": "A Survey of Knowledge Enhanced Pre-Trained Language Models",
        "authors": "Linmei Hu, Zeyi Liu, Ziwang Zhao, Lei Hou, Liqiang Nie, Juanzi Li",
        "published": "2024-4",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tkde.2023.3310002"
    },
    {
        "id": 14148,
        "title": "A Survey on Evaluation of Large Language Models",
        "authors": "Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, Xing Xie",
        "published": "2024-1-23",
        "citations": 17,
        "abstract": "\n            Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions:\n            what to evaluate\n            ,\n            where to evaluate\n            , and\n            how to evaluate\n            . Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the ‘where’ and ‘how’ questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at: https://github.com/MLGroupJLU/LLM-eval-survey.\n          ",
        "link": "http://dx.doi.org/10.1145/3641289"
    },
    {
        "id": 14149,
        "title": "Opinions of ESL Preservice Teachers on Using Artificial Intelligence Language Models in Language Education",
        "authors": "Matti Izora Ibrahim, Mohamed M. Ibrahim",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "This chapter examined the opinion of 417 ESL preservice teachers regarding the use of AI language models in teaching and learning English language. The study found that most of the participants do not believe that AI language models could replace human teachers in ESL education, either now or in the future. However, it was found that there are some ethical, social, and cultural concerns related to the use of AI language models in language education. The concerns voiced by participants include the issue of the users' privacy and ownership, the lack of social interaction, empathy, and communication, and the potential for cultural bias. The chapter also recommended that ESL educators should offer comprehensive training that addresses these concerns and develops critical thinking skills by emphasizing the significance of safeguarding users' privacy and data, mitigating bias in AI models, clarifying intellectual property rights, ensuring reliable text generation, considering social and cultural implications, and promoting a balanced and ethical approach to using AI language models.",
        "link": "http://dx.doi.org/10.4018/978-1-6684-9893-4.ch014"
    },
    {
        "id": 14150,
        "title": "What do end-to-end speech models learn about speaker, language and channel information? A layer-wise and neuron-level analysis",
        "authors": "Shammur Absar Chowdhury, Nadir Durrani, Ahmed Ali",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2023.101539"
    },
    {
        "id": 14151,
        "title": "Large Language Model-based Tools in Language Teaching to Develop Critical Thinking and Sustainable Cognitive Structures",
        "authors": "Sindhu Joseph,  ",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "Experts assert that Large Language Model (LLM) based tools like ChatGPT are the next generation in the evolution of Artificial Intelligence and will permeate all walks of human life including education. The current narrative is that we need to embed the LLM-based tools into the system taking advantage of their personalised, dynamic, adaptive nature while being mindful of their limitations. One of the greatest limitations so far identified is that these pre-trained transformer-based encoder models fine-tuned on Natural Language Processing (NLP) tasks do not reveal verifiable reasoning ability. As a result, the information generated by these tools is subject to ethical and factual errors that need human oversight. This paper uses the integrative literature review to identify and synthesize Critical Digital Literacy frameworks in language teaching in the light of the essential competencies and learning domains identified by the UNESCO Education for Sustainable Development directives. The Critical AI Literacy framework proposed in this paper would enable language teachers to adopt LLM-based tools to enhance their instructional strategies. The cognitive, affective and conative competencies developed through the new CAIL framework would empower learners to understand the manipulative nature of language and use language to build a sustainable future.",
        "link": "http://dx.doi.org/10.21659/rupkatha.v15n4.13"
    },
    {
        "id": 14152,
        "title": "Overview of the Impact of Large-scale Photovoltaic Power Generation on Power Systems",
        "authors": "",
        "published": "2021-8-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i8.155"
    },
    {
        "id": 14153,
        "title": "Analysis on Technical Difficulties and Quality Control Factors of Large Underground Space Construction",
        "authors": "",
        "published": "2021-6-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i6.75"
    },
    {
        "id": 14154,
        "title": "NoHateBrazil: A Brazilian Portuguese Text Offensiveness Analysis System",
        "authors": "Francielle Vargas,  , Isabelle Carvalho, Wolfgang S. Schmeisser-Nieto, Fabrício Benevenuto, Thiago A. S. Pardo,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_125"
    },
    {
        "id": 14155,
        "title": "20 Disabilities and home language maintenance: Myths, models of disability, and equity",
        "authors": "Gregory A. Cheatham, Sumin Lim",
        "published": "2020-6-22",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9781501510175-020"
    },
    {
        "id": 14156,
        "title": "Refining Targeted Syntactic Evaluation of Language Models",
        "authors": "Benjamin Newman, Kai-Siang Ang, Julia Gong, John Hewitt",
        "published": "2021",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.290"
    },
    {
        "id": 14157,
        "title": "Fast, Effective, and Self-Supervised: Transforming Masked Language Models into Universal Lexical and Sentence Encoders",
        "authors": "Fangyu Liu, Ivan Vulić, Anna Korhonen, Nigel Collier",
        "published": "2021",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.109"
    },
    {
        "id": 14158,
        "title": "Sparse Low-rank Adaptation of Pre-trained Language Models",
        "authors": "Ning Ding, Xingtai Lv, Qiaosen Wang, Yulin Chen, Bowen Zhou, Zhiyuan Liu, Maosong Sun",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.252"
    },
    {
        "id": 14159,
        "title": "Leveraging Frozen Pretrained Written Language Models for Neural Sign Language Translation",
        "authors": "Mathieu De Coster, Joni Dambre",
        "published": "2022-4-23",
        "citations": 5,
        "abstract": "We consider neural sign language translation: machine translation from signed to written languages using encoder–decoder neural networks. Translating sign language videos to written language text is especially complex because of the difference in modality between source and target language and, consequently, the required video processing. At the same time, sign languages are low-resource languages, their datasets dwarfed by those available for written languages. Recent advances in written language processing and success stories of transfer learning raise the question of how pretrained written language models can be leveraged to improve sign language translation. We apply the Frozen Pretrained Transformer (FPT) technique to initialize the encoder, decoder, or both, of a sign language translation model with parts of a pretrained written language model. We observe that the attention patterns transfer in zero-shot to the different modality and, in some experiments, we obtain higher scores (from 18.85 to 21.39 BLEU-4). Especially when gloss annotations are unavailable, FPTs can increase performance on unseen data. However, current models appear to be limited primarily by data quality and only then by data quantity, limiting potential gains with FPTs. Therefore, in further research, we will focus on improving the representations used as inputs to translation models.",
        "link": "http://dx.doi.org/10.3390/info13050220"
    },
    {
        "id": 14160,
        "title": "Can Language Models Encode Perceptual Structure Without Grounding? A Case Study in Color",
        "authors": "Mostafa Abdou, Artur Kulmizev, Daniel Hershcovich, Stella Frank, Ellie Pavlick, Anders Søgaard",
        "published": "2021",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.conll-1.9"
    },
    {
        "id": 14161,
        "title": "An Explorative Guide on How to Detect Forged Car Insurance Claims with Language Models",
        "authors": "Quentin Telnoff, Emanuela Boros, Mickael Coustaty, Fabrice Crohas, Antoine Doucet, Frédéric Bars",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012232900003598"
    },
    {
        "id": 14162,
        "title": "Interpolated Spectral NGram Language Models",
        "authors": "Ariadna Quattoni, Xavier Carreras",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/p19-1594"
    },
    {
        "id": 14163,
        "title": "Index",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.index"
    },
    {
        "id": 14164,
        "title": "Leveraging molecular structure and bioactivity with chemical language models for drug design",
        "authors": "Michael Moret, Francesca Grisoni, Cyrill Brunner, Gisbert Schneider",
        "published": "No Date",
        "citations": 0,
        "abstract": "Generative chemical language models (CLMs) can be used for de novo molecular structure generation. These CLMs learn from the structural information of known molecules to generate new ones. In this paper, we show that “hybrid” CLMs can additionally leverage the bioactivity information available for the training compounds. To computationally design ligands of phosphoinositide 3-kinase gamma (PI3Kγ), we created a large collection of virtual molecules with a generative CLM. This primary virtual compound library was further refined using a CLM-based classifier for bioactivity prediction. This second hybrid CLM was pretrained with patented molecular structures and fine-tuned with known PI3Kγ binders and non-binders by transfer learning. Several of the computer-generated molecular designs were commercially available, which allowed for fast prescreening and preliminary experimental validation. A new PI3Kγ ligand with sub-micromolar activity was identified. The results positively advocate hybrid CLMs for virtual compound screening and activity-focused molecular design in low-data situations.",
        "link": "http://dx.doi.org/10.33774/chemrxiv-2021-xzgst"
    },
    {
        "id": 14165,
        "title": "Bilingual Models of Speaking",
        "authors": "Kees de Bot, Szilvia Bátyi",
        "published": "2022-1-20",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003022497-3"
    },
    {
        "id": 14166,
        "title": "FUTURE OF THE LANGUAGE MODELS IN HEALTHCARE: THE ROLE OF CHATGPT",
        "authors": "Francisco Tustumi, Nelson Adami Andreollo, José Eduardo de Aguilar-Nascimento",
        "published": "No Date",
        "citations": 2,
        "abstract": "The field of medicine has always been at the forefront of technological innovation, constantly seeking new strategies to diagnose, treat, and prevent diseases. Guidelines for clinical practice to orientate medical teams regarding diagnosis, treatment, and prevention measures have increased over the years. The purpose is to gather the most medical knowledge to construct an orientation for practice. Evidence-based guidelines follow several of the main characteristics of a systematic review, including systematic and unbiased search, selection, and extraction of the source of evidence. In recent years, the rapid advancement of artificial intelligence (AI) has provided clinicians and patients with access to personalized, data-driven insights, support and new opportunities for healthcare professionals to improve patient outcomes, increase efficiency, and reduce costs. One of the most exciting developments in AI has been the emergence of chatbots. A chatbot is a computer program to simulate conversation with human users. Recently, OpenAI, a research organization focused on machine learning, developed ChatGPT, a large language model that generates human-like text. ChatGPT uses a type of AI known as a deep learning model. ChatGPT can quickly search and select pieces of evidence through numerous databases to provide answers to complex questions, reducing the time and effort required to research a particular topic manually. Consequently, language models can accelerate the creation of clinical practice guidelines. While there is no doubt that ChatGPT has the potential to revolutionize the way healthcare is delivered, it is essential to note that it should not be used as a substitute for human healthcare professionals. Instead, ChatGPT should be seen as a tool that can be used to augment and support the work of healthcare professionals, helping them to provide better care to their patients.",
        "link": "http://dx.doi.org/10.1590/0102-672020230002e171"
    },
    {
        "id": 14167,
        "title": "Marx’s Systematic Dialectics and Mathematics",
        "authors": "Dirk Damsma",
        "published": "2019-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1163/9789004395497_006"
    },
    {
        "id": 14168,
        "title": "Lexicon-enhanced Pre-trained Language Models for Chinese Ethics-related Tasks",
        "authors": "Tianlong Gu, Tong Bao, Long Li, Liang Chang, Xuan Feng",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The proposal and rapid development of pre-trained language models have led to unprecedented breakthroughs in natural language processing techniques. Although pre-trained language models have strong text-understanding capabilities, their performance in handling ethical issues is unsatisfactory due to the complexity of ethical connotations. To improve the ethical understanding and generation capabilities of pre-trained language models, a novel knowledge enhancement solution based on the ethics lexicon is proposed.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23689404.v1"
    },
    {
        "id": 14169,
        "title": "The Implications of Literacy",
        "authors": "Brian Stock",
        "published": "2021-5-11",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n"
    },
    {
        "id": 14170,
        "title": "Peer Review #1 of \"Feature-based detection of automated language models: tackling GPT-2, GPT-3 and Grover (v0.1)\"",
        "authors": "DW Heck",
        "published": "2021-4-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.443v0.1/reviews/1"
    },
    {
        "id": 14171,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Rui Hou",
        "published": "2023-6-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/0gtr30"
    },
    {
        "id": 14172,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Fan Zhang",
        "published": "2023-7-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/04qqms"
    },
    {
        "id": 14173,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Omid Noroozi",
        "published": "2023-7-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/52evv5"
    },
    {
        "id": 14174,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Shweta Chauhan",
        "published": "2023-6-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/lpszul"
    },
    {
        "id": 14175,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Oleg Nozhovnik",
        "published": "2023-6-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/mk293v"
    },
    {
        "id": 14176,
        "title": "Standardizing chemical compounds with language models",
        "authors": "Miruna T. Cretu, Alessandra Toniato, Amol Thakkar, Amin Debabeche, Teodoro Laino, Alain C. Vaucher",
        "published": "No Date",
        "citations": 1,
        "abstract": "With the growing amount of chemical data stored digitally, it has become crucial to represent chemical compounds accurately and consistently. Harmonized representations facilitate the extraction of insightful information from datasets, and are advantageous for machine learning applications. To achieve consistent representations throughout datasets, one relies on molecule standardization, which is typically accomplished using rule-based algorithms that modify descriptions of functional groups. Here, we present the first deep-learning model for molecular standardization. We enable custom standardization schemes based solely on data, which, as additional benefit, support standardization options that are difficult to encode into rules. Our model achieves over 98% accuracy in learning two popular rule-based standardization protocols. We then follow a transfer learning approach to standardize metal-organic compounds (for which there is currently no automated standardization practice), based on a human-curated dataset of 1512 compounds. This model predicts the expected standardized molecular format with a test accuracy of 75.6%. As standardization can be considered, more broadly, a transformation from undesired to desired representations of compounds, the same data-driven architecture can be applied to other tasks. For instance, we demonstrate the application to compound canonicalization and to the determination of major tautomers in solution, based on computed and experimental data.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2022-14ztf-v2"
    },
    {
        "id": 14177,
        "title": "ProkBERT Family: Genomic Language Models for Microbiome Applications",
        "authors": "Balázs Ligeti, István Szepesi-Nagy, Babett Bodnár, Noémi Ligeti-Nagy, János Juhász",
        "published": "No Date",
        "citations": 0,
        "abstract": "ABSTRACTMachine learning offers transformative capabilities in microbiology and microbiome analysis, deciphering intricate microbial interactions, predicting functionalities, and unveiling novel patterns in vast datasets. This enriches our comprehension of microbial ecosystems and their influence on health and disease. However, the integration of machine learning in these fields contends with issues like the scarcity of labeled datasets, the immense volume and complexity of microbial data, and the subtle interactions within microbial communities. Addressing these challenges, we introduce the ProkBERT model family. Built on transfer learning and self-supervised methodologies, ProkBERT models capitalize on the abundant available data, demonstrating adaptability across diverse scenarios. The models’ learned representations align with established biological understanding, shedding light on phylogenetic relationships. With the novel Local Context-Aware (LCA) tokenization, the ProkBERT family overcomes the context size limitations of traditional transformer models without sacrificing performance or the information rich local context. In bioinformatics tasks like promoter prediction and phage identification, ProkBERT models excel. For promoter predictions, the best performing model achieved an MCC of 0.74 forE. coliand 0.62 in mixed-species contexts. In phage identification, they all consistently outperformed tools like VirSorter2 and DeepVirFinder, registering an MCC of 0.85. Compact yet powerful, the ProkBERT models are efficient, generalizable, and swift. They cater to both supervised and unsupervised tasks, providing an accessible tool for the community. The models are available on GitHub and HuggingFace.",
        "link": "http://dx.doi.org/10.1101/2023.11.09.566411"
    },
    {
        "id": 14178,
        "title": "Predicting Temporal Performance Drop of Deployed Production Spoken Language Understanding Models",
        "authors": "Quynh Do, Judith Gaspers, Daniil Sorokin, Patrick Lehnen",
        "published": "2021-8-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-580"
    },
    {
        "id": 14179,
        "title": "Protein Fitness Prediction is Impacted by the Interplay of Language Models, Ensemble Learning, and Sampling Methods",
        "authors": "Mehrsa Mardikoraem, Daniel Woldring",
        "published": "No Date",
        "citations": 3,
        "abstract": "AbstractAdvances in machine learning (ML) and the availability of protein sequences via high-throughput sequencing techniques have transformed our ability to design novel diagnostic and therapeutic proteins. ML allows protein engineers to capture complex trends hidden within protein sequences that would otherwise be difficult to identify in the context of the immense and rugged protein fitness landscape. Despite this potential, there persists a need for guidance during the training and evaluation of ML methods over sequencing data. Two key challenges for training discriminative models and evaluating their performance include handling severely imbalanced datasets (e.g., few high-fitness proteins among an abundance of non-functional proteins) and selecting appropriate protein sequence representations. Here, we present a framework for applying ML over assay-labeled datasets to elucidate the capacity of sampling methods and protein representations to improve model performance in two different datasets with binding affinity and thermal stability prediction tasks. For protein sequence representations, we incorporate two widely used methods (One-Hot encoding, physiochemical encoding) and two language-based methods (next-token prediction, UniRep; masked-token prediction, ESM). Elaboration on performance is provided over protein fitness, length, data size, and sampling methods. In addition, an ensemble of representation methods is generated to discover the contribution of distinct representations to the final prediction score. Within the context of these datasets, the synthetic minority oversampling technique (SMOTE) outperformed undersampling while encoding sequences with One-Hot, UniRep, and ESM representations. In addition, ensemble learning increased the predictive performance of the affinity-based dataset by 4% compared to the best single encoding candidate (F1-score = 97%), while ESM alone was rigorous enough in stability prediction (F1-score = 92%).",
        "link": "http://dx.doi.org/10.1101/2023.02.09.527362"
    },
    {
        "id": 14180,
        "title": "RaptorX-Single: single-sequence protein structure prediction by integrating protein language models",
        "authors": "Xiaoyang Jing, Fandi Wu, Xiao Luo, Jinbo Xu",
        "published": "No Date",
        "citations": 2,
        "abstract": "AbstractProtein structure prediction has been greatly improved by deep learning in the past few years. However, the most successful methods rely on multiple sequence alignment (MSA) of the sequence homologs of the protein under prediction. In nature a protein folds in the absence of its sequence homologs and thus, a MSA-free structure prediction method is desired. Here we develop a single sequence-based protein structure prediction method RaptorX-Single by integrating several protein language models and a structure generation module and then study its advantage over MSA-based prediction methods. Our experimental results indicate that in addition to running much faster than MSA-based methods such as AlphaFold2, RaptorX-Single outperforms AlphaFold2 and other MSA-free methods in predicting the structure of antibodies, proteins of very few sequence homologs and single mutation effects. RaptorX-Single also compares favorably to MSA-based AlphaFold2 when the protein under prediction has a large number of sequence homologs.",
        "link": "http://dx.doi.org/10.1101/2023.04.24.538081"
    },
    {
        "id": 14181,
        "title": "Protein language models can capture protein quaternary state",
        "authors": "Orly Avraham, Tomer Tsaban, Ziv Ben-Aharon, Linoy Tsaban, Ora Schueler-Furman",
        "published": "No Date",
        "citations": 2,
        "abstract": "AbstractBackgroundDetermining a protein’s quaternary state,i.e. how many monomers assemble together to form the functioning unit, is a critical step in protein characterization, and deducing it is not trivial. Many proteins form multimers for their activity, and over 50% are estimated to naturally form homomultimers. Experimental quaternary state determination can be challenging and require extensive work. To complement these efforts, a number of computational tools have been developed for quaternary state prediction, often utilizing experimentally validated structural information. Recently, dramatic advances have been made in the field of deep learning for predicting protein structure and other characteristics. Protein language models that apply computational natural-language models to proteins successfully capture secondary structure, protein cell localization and other characteristics, from a single sequence. Here we hypothesize that information about the protein quaternary state may be contained within protein sequences as well, allowing us to benefit from these novel approaches in the context of quaternary state prediction.ResultsWe generated embeddings for a large dataset of quaternary state labels, extracted from the curated QSbio dataset. We then trained a model for quaternary state classification and assessed it on a non-overlapping set of distinct folds (ECOD family level). Our model, named QUEEN (QUaternary state prediction using dEEp learNing), performs worse than approaches that include information from solved crystal structures. However, we show that it successfully learned to distinguish multimers from monomers, and that the specific quaternary state is predicted with moderate success, better than a simple model that transfers annotation based on sequence similarity. Our results demonstrate that complex, quaternary state related information is included in these embeddings.ConclusionsQUEEN is the first to investigate the power of embeddings for the prediction of the quaternary state of proteins. As such, it lays out the strength as well as limitations of a sequence-based protein language model approach compared to structure-based approaches. Since it does not require any structural information and is fast, we anticipate that it will be of wide use both for in-depth investigation of specific systems, as well as for studies of large sets of protein sequences. A simple colab implementation is available at:https://colab.research.google.com/github/Orly-A/QUEEN_prediction/blob/main/QUEEN_prediction_notebook.ipynb.",
        "link": "http://dx.doi.org/10.1101/2023.03.30.534955"
    },
    {
        "id": 14182,
        "title": "Sustainable Modular Debiasing of Language Models",
        "authors": "Anne Lauscher, Tobias Lueken, Goran Glavaš",
        "published": "2021",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-emnlp.411"
    },
    {
        "id": 14183,
        "title": "Chinese Medical Named Entity Recognition Based on Pre-trained Language Models",
        "authors": "Peiguang Ruan, Wei Lv, Mingxuan Li, Weiyu Tang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nWith the progressive development of academic research and the increasing standard of living, the need for medical entity identification is gradually increasing. Medical entity recognition has been rapidly developed to help build medical knowledge graphs and disease prediction, improve diagnostic accuracy, enable disease prevention, simplify clinical decision-making and reduce healthcare costs. In Chinese named entity recognition, the input is a word-level vector representation, but in Chinese text, words are the smallest units that express meaning. Although the BERT model has the advantage of excellent training results and can avoid the noise generated by the different word-level vector when the input word-level vector is used, it is wasteful for Chinese words that possess more information. Therefore, we propose a pre-training model based on Tag Embedding and Simple Lexicon word strengthening with word information fusion, which incorporates the word boundary information of the text into the more expressive text after encoding, increasing the amount of information it contains. The purpose of this study is to build a named entity recognition model using deep neural networks to improve the accuracy of medical-related entity recognition from the perspective of improving the information exploiting of medical data sets in the current era of big data informatics, and to contribute to related research.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3005797/v1"
    },
    {
        "id": 14184,
        "title": "Predictive Models of the Acquisition of Individual Words",
        "authors": "",
        "published": "2021-3-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7551/mitpress/11577.003.0011"
    },
    {
        "id": 14185,
        "title": "Educational Models that Promote Additive Bilingualism",
        "authors": "Sarah J. Shin",
        "published": "2017-7-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781315535579-8"
    },
    {
        "id": 14186,
        "title": "Grammar and Theory of Mind in Autism",
        "authors": "Stephanie Durrleman",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5_17"
    },
    {
        "id": 14187,
        "title": "NLMs: Augmenting Negation in Language Models",
        "authors": "Rituraj Singh, Rahul Kumar, Vivek Sridhar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.873"
    },
    {
        "id": 14188,
        "title": "Hybrid protein-ligand binding residue prediction with protein language models: Does the structure matter?",
        "authors": "Hamza Gamouh, Marian Novotny, David Hoksza",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractPredicting protein-ligand binding sites is crucial in studying protein interactions with applications in biotechnology and drug discovery. Two distinct paradigms have emerged for this purpose: sequence-based methods, which leverage protein sequence information, and structure-based methods, which rely on the three-dimensional (3D) structure of the protein. To enhance the state-of-the-art performance in this field, we propose a novel approach combining both paradigms’ strengths. Our hybrid model integrates two recent deep learning architectures: protein language models (pLMs) from the sequence-based paradigm and Graph Neural Networks (GNNs) from the structure-based paradigm. Specifically, we construct a residue-level Graph Attention Network (GAT) model based on the protein’s 3D structure that uses pre-trained pLM embeddings as node features. This integration enables our model to capture both the sequential information encoded in the protein sequence and the structural relationships within the protein. The model has improved state-of-the-art performance on a benchmark dataset over a range of ligands and ligand types. Ablation studies have demonstrated the role of the graph attention mechanism, particularly in densely connected graphs. Moreover, we have shown that as more complex pLMs are employed to represent node features, the relative impact of the GNN architecture diminishes. This observation suggests that, to some extent, the structural information required for accurate binding site prediction is inherently captured by the pLMs themselves. protein-ligand binding sites, binding residues prediction, graph neural networks, graph attention, protein language models, protein embeddings",
        "link": "http://dx.doi.org/10.1101/2023.08.11.553028"
    },
    {
        "id": 14189,
        "title": "Fleshing Out Models of Gender in English-Language Novels (1850 – 2000)",
        "authors": "Jonathan Cheng",
        "published": "2020-1-29",
        "citations": 2,
        "abstract": "Distant readers have used predictive modelling to study the strength of the relationship between characterization and binary notions of gender. This essay builds on that research, shedding light on several historical trends concerning anatomical description and its relationship to gender. Some of the evidence suggests that bodily language has long played a larger role in configuring fictional women than it did for fictional men. Other evidence implies that bodily characteristics were increasingly bifurcated along a gender binary, reflecting how characters are more and more physically sorted along a feminine-masculine axis. Taken altogether, this essay unpacks a suggestive correlation: a growing aspect of characterization was increasingly imbricated in heteronormative discourses. By weighing the discrepancies between the evidence presented in this essay, and that of its predecessors, this essay will ultimately suggest that disaggregating statistical models can unfold patterns of literary change that would otherwise remain suppressed.",
        "link": "http://dx.doi.org/10.22148/001c.11652"
    },
    {
        "id": 14190,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Jayakaran Mukundan",
        "published": "2023-6-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/xg4u3n"
    },
    {
        "id": 14191,
        "title": "Analysis of Large Shield Driving Attitude and Stratum Stability in Soft Soil Stratum",
        "authors": "",
        "published": "2022-3-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i3(09).04"
    },
    {
        "id": 14192,
        "title": "Risk Management and Control of Blasting Operation in Large Open-pit Coal Mine",
        "authors": "",
        "published": "2022-1-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i1.293"
    },
    {
        "id": 14193,
        "title": "Overview of the Influence of Large-scale Photovoltaic Power Generation on Power System",
        "authors": "",
        "published": "2021-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i12.230"
    },
    {
        "id": 14194,
        "title": "The Application Potential of Large Language Model in the Management for Diabetic Ketoacidosis: Systematic Review (Preprint)",
        "authors": "Song Xue, Zhiguang Zhou",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nThere is a gap for at least 10,000 endocrinologists, which might cause delayed treatment in some patients with DKA. The efficacy of large language model (LLM) in improving productivity has been illustrated in rehabilitation medicine. However, it remains unclear in the management for patients with DKA.\n\n\nOBJECTIVE\nThis study aimed to investigate the application potentials of large language model in the management of patients with diabetes ketoacidosis (DKA).\n\n\nMETHODS\nChatGPT-4 was applied to generate information of diagnosis, treatment and regular follow-up based on a classic DKA case. Junior and senior endocrinologist were invited to review accuracy and limitations of the output to determine the rough value of ChatGPT-4 in the routine practice, especially in DKA.\n\n\nRESULTS\nChatGPT-4 could respond in seconds and generated information including the diagnosis, regimen and follow-up pertinent to the case. Also, it provided rationale for the diagnosis or suggestion outputted. Compared with the standard answer or guideline, recommendation ChatGPT-4 offered was more elaborate, which including self-management education, diet and exercise, assessment for chronic disease management follow-up, and psychosocial support. However, there were some limitations, including the inability to provide the most suitable recommendations in the complex situations. Similar findings were found when compared with the endocrinologists.\n\n\nCONCLUSIONS\nLarge language model present tremulous potentials in facilitating routine practice and medical education on improving the working efficiency of endocrinologists.\n",
        "link": "http://dx.doi.org/10.2196/preprints.52600"
    },
    {
        "id": 14195,
        "title": "Assessing Large Classes",
        "authors": "Rubina Khan, Arifa Rahman",
        "published": "2018-1-18",
        "citations": 0,
        "abstract": "Teaching in large classes is looked upon as a difficult endeavor and, by the same token, assessing large classes is an even greater struggle. This entry identifies the major challenges faced by teachers in large‐class assessment. Apart from the inherent difficulty of adhering to the essential guiding principles of quality assessment (reliability, validity, and practicality) and to the right use of assessment types (formative, summative), problems are further compounded by the lack of adequate resources and the paucity of available teaching staff, in particular trained and assessment‐literate personnel capable of maintaining sound assessment procedures. Finally, the section on pedagogic implications discusses the overarching guidelines and some specific strategies for assessing large classes.",
        "link": "http://dx.doi.org/10.1002/9781118784235.eelt0322"
    },
    {
        "id": 14196,
        "title": "Exploring the Potential of Large Language Model-Based Task-Oriented Dialogue Chatbots from Learner Perspectives",
        "authors": "Jang Ho Lee, Dongkwang Shin, Yohan Hwang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4644306"
    },
    {
        "id": 14197,
        "title": "TreeSwap: Data Augmentation for Machine Translation via Dependency Subtree Swapping",
        "authors": "Attila Nagy,  , Dorina Lakatos, Botond Barta, Judit Ács,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_082"
    },
    {
        "id": 14198,
        "title": "InA: Inhibition Adaption on Pre-Trained Language Models",
        "authors": "Cheng Kang, Jindich Prokop, Lei Tong, Huiyu Zhou, Yong Hu, Daniel Novak",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4551993"
    },
    {
        "id": 14199,
        "title": "Exploring Weaknesses of VQA Models through Attribution Driven Insights",
        "authors": "Shaunak Halbe",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.challengehml-1.9"
    },
    {
        "id": 14200,
        "title": "Training Natural Language Processing Models on Encrypted Text for Enhanced Privacy",
        "authors": "Davut Emre TAŞAR, Ceren ÖCAL TAŞAR",
        "published": "No Date",
        "citations": 0,
        "abstract": "  With the increasing use of cloud-based services for training and deploying machine learning models, data privacy has become a major concern. This is particularly important for natural language processing (NLP) models, which often process sensitive information such as personal communications and confidential documents. In this study, we propose a method for training NLP models on encrypted text data to mitigate data privacy concerns while maintaining similar performance to models trained on non-encrypted data. We demonstrate our method using two different architectures, namely Doc2Vec+XGBoost and Doc2Vec+LSTM, and evaluate the models on the 20 Newsgroups dataset. Our results indicate that both encrypted and non-encrypted models achieve comparable performance, suggesting that our encryption method is effective in preserving data privacy without sacrificing model accuracy. In order to replicate our experiments, we have provided a Colab notebook at the following address: https://t.ly/lR-TP   ",
        "link": "http://dx.doi.org/10.20944/preprints202305.0287.v1"
    },
    {
        "id": 14201,
        "title": "Chapter 10. Models and metaphors",
        "authors": "Judith F. Kroll, Eleonora Rossi",
        "published": "2023-6-15",
        "citations": 0,
        "abstract": "   Ellen Bialystok’s research on bilingualism and cognition has transformed our understanding of how life experience with two or more languages has enduring consequences for the mind and the brain. But how do these consequences arise? In this chapter we focus on models of bilingual language processing and the metaphors that they have generated for testing hypotheses about how learning and using two languages engage domain general cognition and the neural mechanisms that support it. Research in the last two decades provides compelling support for the view that the bilingual’s two languages are continually interacting. Those interactions create mutual influences that are dynamic, changing within individuals across the lifespan and from one context to another, even over relatively short periods of time. Cross-language interactions have been hypothesized to impose unique demands on cognition that make bilingual minds and brains different from those of monolingual speakers. The models that characterize bilingual language processing capture different aspects of this process, some focused on the linguistic processes themselves, and others on the way that each language is regulated or controlled when there is potential cross-language competition. Here we illustrate each type of model and consider how the models themselves provide metaphors for thinking about how bilingualism affects cognition.  ",
        "link": "http://dx.doi.org/10.1075/sibil.64.10kro"
    },
    {
        "id": 14202,
        "title": "Dual Language Education Models and Research in Early Childhood Education in the USA",
        "authors": "Kathryn Lindholm-Leary",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-47073-9_11-1"
    },
    {
        "id": 14203,
        "title": "Open Translation Models, Tools and Services",
        "authors": "Jörg Tiedemann, Mikko Aulamo, Sam Hardwick, Tommi Nieminen",
        "published": "2023",
        "citations": 0,
        "abstract": "AbstractThe ambition of the Open Translation Models, Tools and Services (OPUSMT) project is to develop state-of-the art neural machine translation (NMT) models that can freely be distributed and applied in research as well as professional applications. The goal is to pre-train translation models on a large scale on openly available parallel data and to create a catalogue of such resources for streamlined integration and deployment. For the latter we also implement and improve web services and computer-assisted translation (CAT) tools that can be used in on-line interfaces and professional workflows. Furthermore, we want to enable the re-use of models to avoid repeating costly training procedures from scratch and with this contribute to a reduction of the carbon footprint in MT research and development. The ELG pilot project focused on European minority languages and improved translation quality in low resource settings and the integration of MT services in the ELG infrastructure.",
        "link": "http://dx.doi.org/10.1007/978-3-031-17258-8_24"
    },
    {
        "id": 14204,
        "title": "Reusing Weights in Subword-Aware Neural Language Models",
        "authors": "Zhenisbek Assylbekov, Rustem Takhanov",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/n18-1128"
    },
    {
        "id": 14205,
        "title": "Cross-Lingual Ability of Multilingual Masked Language Models: A Study of Language Structure",
        "authors": "Yuan Chai, Yaobo Liang, Nan Duan",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.acl-long.322"
    },
    {
        "id": 14206,
        "title": "Red Teaming Language Model Detectors with Language Models",
        "authors": "Zhouxing Shi, Yihan Wang, Fan Yin, Xiangning Chen, Kai-Wei Chang, Cho-Jui Hsieh",
        "published": "2024-2-23",
        "citations": 0,
        "abstract": "Abstract\nThe prevalence and strong capability of large language models (LLMs) present significant safety and ethical risks if exploited by malicious users. To prevent the potentially deceptive usage of LLMs, recent work has proposed algorithms to detect LLM-generated text and protect LLMs. In this paper, we investigate the robustness and reliability of these LLM detectors under adversarial attacks. We study two types of attack strategies: 1) replacing certain words in an LLM’s output with their synonyms given the context; 2) automatically searching for an instructional prompt to alter the writing style of the generation. In both strategies, we leverage an auxiliary LLM to generate the word replacements or the instructional prompt. Different from previous works, we consider a challenging setting where the auxiliary LLM can also be protected by a detector. Experiments reveal that our attacks effectively compromise the performance of all detectors in the study with plausible generations, underscoring the urgent need to improve the robustness of LLM-generated text detection systems. Code is available at https://github.com/shizhouxing/LLM-Detector-Robustness.",
        "link": "http://dx.doi.org/10.1162/tacl_a_00639"
    },
    {
        "id": 14207,
        "title": "InA: Inhibition Adaption on Pre-Trained Language Models",
        "authors": "Cheng Kang, Jindich Prokop, Lei Tong, Huiyu Zhou, Yong Hu, Daniel Novak",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4551993"
    },
    {
        "id": 14208,
        "title": "Exploring Weaknesses of VQA Models through Attribution Driven Insights",
        "authors": "Shaunak Halbe",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.challengehml-1.9"
    },
    {
        "id": 14209,
        "title": "Training Natural Language Processing Models on Encrypted Text for Enhanced Privacy",
        "authors": "Davut Emre TAŞAR, Ceren ÖCAL TAŞAR",
        "published": "No Date",
        "citations": 0,
        "abstract": "  With the increasing use of cloud-based services for training and deploying machine learning models, data privacy has become a major concern. This is particularly important for natural language processing (NLP) models, which often process sensitive information such as personal communications and confidential documents. In this study, we propose a method for training NLP models on encrypted text data to mitigate data privacy concerns while maintaining similar performance to models trained on non-encrypted data. We demonstrate our method using two different architectures, namely Doc2Vec+XGBoost and Doc2Vec+LSTM, and evaluate the models on the 20 Newsgroups dataset. Our results indicate that both encrypted and non-encrypted models achieve comparable performance, suggesting that our encryption method is effective in preserving data privacy without sacrificing model accuracy. In order to replicate our experiments, we have provided a Colab notebook at the following address: https://t.ly/lR-TP   ",
        "link": "http://dx.doi.org/10.20944/preprints202305.0287.v1"
    },
    {
        "id": 14210,
        "title": "THEORETICAL BACKGROUNDS TO COGNITIVE LANGUAGE MODELS: IMAGE SCHEMAS",
        "authors": "A.I. Nabok",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32843/2663-6085/2021/32-1.24"
    },
    {
        "id": 14211,
        "title": "A Natural Language Processing Model Based on Pre-trained Deep Learning Models",
        "authors": "牛 奕童",
        "published": "2022-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.57237/j.imis.2022.01.003"
    },
    {
        "id": 14212,
        "title": "Learning and Language Acquisition in Primates",
        "authors": "Duane M. Rumbaugh, Η. Κ. Massel",
        "published": "2018-2-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781351075039-7"
    },
    {
        "id": 14213,
        "title": "Precision of phonological errors in aphasia supports resource models of phonological working memory in language production",
        "authors": "Jenah Black, Nazbanou Nozari",
        "published": "No Date",
        "citations": 0,
        "abstract": "Working memory is critical for many cognitive functions and language production is no exception. Despite their differences, all accounts of working memory agree on its capacity limitation. Two dominant models have been proposed to account for such capacity limitation: slot models and resource models. In recent years, resource models have found support in both visual and auditory perception. An important question is whether they also extend to production. We investigate this issue by analyzing sublexical errors from four individuals with aphasia. Using tools from computational linguistics, we first define the concept of “precision” of sublexical errors. We then demonstrate that such precision decreases with increased working memory load, i.e., word length, as predicted by resource models. Finally, we rule out alternative accounts of this effect, such as articulatory simplification. These data provide the first evidence for the applicability of the resource model to production and further point to the generalizability of this account as a model of resource division in working memory.",
        "link": "http://dx.doi.org/10.31234/osf.io/cnak2"
    },
    {
        "id": 14214,
        "title": "Collaborative Language Systems Therapy",
        "authors": "Siva Perera",
        "published": "2023-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003382621-25"
    },
    {
        "id": 14215,
        "title": "Explaining Reading Comprehension: Models of Reading",
        "authors": "",
        "published": "2022-9-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108878944.007"
    },
    {
        "id": 14216,
        "title": "Simple non-linear models",
        "authors": "Radan Martinec, Theo van Leeuwen",
        "published": "2020-10-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003060499-2"
    },
    {
        "id": 14217,
        "title": "The Evolution of Language Models: From N-Grams to LLMs, and Beyond",
        "authors": "Mohammad Raeini",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4625356"
    },
    {
        "id": 14218,
        "title": "E2E NLG Challenge: Neural Models vs. Templates",
        "authors": "Yevgeniy Puzikov, Iryna Gurevych",
        "published": "2018",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-6557"
    },
    {
        "id": 14219,
        "title": "Lost for Words! Defining the Language Around Role Models in Engineering Education",
        "authors": "Virginia Grande",
        "published": "2018-10",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/fie.2018.8659104"
    },
    {
        "id": 14220,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Sakshi Ranjan",
        "published": "2023-6-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/9zk2dt"
    },
    {
        "id": 14221,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Hamed Barjesteh",
        "published": "2023-6-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/qrsbm8"
    },
    {
        "id": 14222,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Zahra Shahsavar",
        "published": "2023-6-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/0nvaae"
    },
    {
        "id": 14223,
        "title": "Exploration on Fault Analysis and Maintenance of Medium and Large Pumping Station Equipment",
        "authors": "",
        "published": "2021-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i12.220"
    },
    {
        "id": 14224,
        "title": "Application of GPS RTK in Surveying and Mapping of Large-scale Topographic Map",
        "authors": "",
        "published": "2021-6-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i6.35"
    },
    {
        "id": 14225,
        "title": "A Large Language Model Framework to Uncover Underreporting in Traffic Crashes",
        "authors": "Cristian Arteaga, Jee Woong Park",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4613378"
    },
    {
        "id": 14226,
        "title": "Kazakh Cultural Models of Family and Home in Contrast",
        "authors": "Barbara Lewandowska-Tomaszczyk, Bibigul Burkhanovna Utegaliyeva",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-42734-4_6"
    },
    {
        "id": 14227,
        "title": "Can Character-based Language Models Improve Downstream Task Performances In Low-Resource And Noisy Language Scenarios?",
        "authors": "Arij Riabi, Benoît Sagot, Djamé Seddah",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.wnut-1.47"
    },
    {
        "id": 14228,
        "title": "Sequence Teacher-Student Training of Acoustic Models for Automatic Free Speaking Language Assessment",
        "authors": "Y. Wang, J. H. M. Wong, M. J. F. Gales, K. M. Knill, A. Ragni",
        "published": "2018-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt.2018.8639557"
    },
    {
        "id": 14229,
        "title": "Language-Theoretic and Finite Relation Models for the (Full) Lambek Calculus",
        "authors": "Christian Wurm",
        "published": "2017-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10849-017-9249-z"
    },
    {
        "id": 14230,
        "title": "On the Effectiveness of Pre-Trained Language Models for Legal Natural Language Processing: An Empirical Study",
        "authors": "Dezhao Song, Sally Gao, Baosheng He, Frank Schilder",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2022.3190408"
    },
    {
        "id": 14231,
        "title": "TreeSwap: Data Augmentation for Machine Translation via Dependency Subtree Swapping",
        "authors": "Attila Nagy,  , Dorina Lakatos, Botond Barta, Judit Ács,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_082"
    },
    {
        "id": 14232,
        "title": "Hakuin: Optimizing Blind SQL Injection with Probabilistic Language Models",
        "authors": "Jakub Pružinec, Nguyen Anh Quynh",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/spw59333.2023.00039"
    },
    {
        "id": 14233,
        "title": "Table of Contents",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.3"
    },
    {
        "id": 14234,
        "title": "Oral and Written",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.5"
    },
    {
        "id": 14235,
        "title": "SIMULATING FSPN MODELS USING PROCESS-BASED DISCRETE -EVENT SIMULATION LANGUAGE",
        "authors": "Zoran Kotevski",
        "published": "2018-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22306/asim.v4i2.42"
    },
    {
        "id": 14236,
        "title": "Aligning Language Models to User Opinions",
        "authors": "EunJeong Hwang, Bodhisattwa Majumder, Niket Tandon",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.393"
    },
    {
        "id": 14237,
        "title": "Formal Models of Automatic Semantic Processing",
        "authors": "Zhiwei Feng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-5172-4_7"
    },
    {
        "id": 14238,
        "title": "The language dimension of mental models in digital learning environments",
        "authors": "Kurt Englmeier",
        "published": "2023",
        "citations": 0,
        "abstract": "Mental models support learners to develop conceptual and operational representations of learning environments. They help learners to structure their knowledge and to translate learning goals for their knowledge acquisition into cognitive learning processes. It is essential for digital environments supporting self-paced learning not only to provide a clear picture of the knowledge the learner can acquire but also to help the learners in developing a clear image of their state of knowledge acquisition and to keep up a high level of learning motivation.",
        "link": "http://dx.doi.org/10.54941/ahfe1003152"
    },
    {
        "id": 14239,
        "title": "Character-Based Embedding Models and Reranking Strategies for Understanding Natural Language Meal Descriptions",
        "authors": "Mandy Korpusik, Zachary Collins, James Glass",
        "published": "2017-8-20",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2017-422"
    },
    {
        "id": 14240,
        "title": "Investigating Bidirectional Recurrent Neural Network Language Models for Speech Recognition",
        "authors": "X. Chen, A. Ragni, X. Liu, Mark J.F. Gales",
        "published": "2017-8-20",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2017-513"
    },
    {
        "id": 14241,
        "title": "Storytelling Motivation: Creating Role Models with Inspirational Stories",
        "authors": "",
        "published": "2021-3-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.33948/jrlt-ksu-1-1-1"
    },
    {
        "id": 14242,
        "title": "Standardized Nomenclature for Legal Prompting in Generative Language Models",
        "authors": "Aditya Sivakumar, Ben Gelman, Robert Simmons, Edward Yu, Mackenzie Sharp",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nWith the increasing availability of commercial Artificial Intelligence, General Language Models (GLMs) have been widely explored in various domains, including law. However, to ensure accurate and standardized legal results, it is crucial to establish a consistent framework for prompting GLMs. This paper presents one of the first instances of such nomenclature, providing a robust framework of “variables” and “clauses” that enhances legal-focused results. The proposed framework was applied in diverse legal scenarios, demonstrating its potential from both client and attorney perspectives. By introducing standardized variables and clauses, legal professionals can effectively communicate with GLMs. This not only improves the accuracy of the generated outcomes but also facilitates collaboration between AI systems and legal experts. With a common framework in place, legal practitioners can leverage AI technology confidently, knowing that the results produced align with established legal principles. Furthermore, the framework serves as a foundation for future research in the field of legal prompting with GLMs, and several avenues for future research are recommended in this paper. This standardization of nomenclature is expected to contribute to the wider adoption and benefit of GLMs in the legal field, leading to more accurate and reliable outcomes.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3308564/v1"
    },
    {
        "id": 14243,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Xueyan Hu",
        "published": "2023-6-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/zr9vd7"
    },
    {
        "id": 14244,
        "title": "Manipulating the Perceived Personality Traits of Language Models",
        "authors": "Graham Caron, Shashank Srivastava",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.156"
    },
    {
        "id": 14245,
        "title": "Improving handwritten Chinese text recognition using neural network language models and convolutional neural network shape models",
        "authors": "Yi-Chao Wu, Fei Yin, Cheng-Lin Liu",
        "published": "2017-5",
        "citations": 118,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patcog.2016.12.026"
    },
    {
        "id": 14246,
        "title": "Numerical Optimizations for Weighted Low-rank Estimation on Language Models",
        "authors": "Ting Hua, Yen-Chang Hsu, Felicity Wang, Qian Lou, Yilin Shen, Hongxia Jin",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.91"
    },
    {
        "id": 14247,
        "title": "A Comparison of Character Neural Language Model and Bootstrapping\n            for Language Identification in Multilingual Noisy Texts",
        "authors": "Wafia Adouane, Simon Dobnik, Jean-Philippe Bernardy, Nasredine Semmar",
        "published": "2018",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-1203"
    },
    {
        "id": 14248,
        "title": "Using Natural Sentence Prompts for Understanding Biases in Language Models",
        "authors": "Sarah Alnegheimish, Alicia Guo, Yi Sun",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.203"
    },
    {
        "id": 14249,
        "title": "Analysis of EPC Implementation of Large-diameter Long-distance HDPE Sewage Pipeline Project",
        "authors": "",
        "published": "2022-7-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i7(03).14"
    },
    {
        "id": 14250,
        "title": "Large‐Sized Classes",
        "authors": "Fauzia Shamim, Hywel Coleman",
        "published": "2018-1-18",
        "citations": 4,
        "abstract": "Large‐sized classes are widespread around the world, but large ESL/ESOL classes occur mainly in under‐resourced contexts. There is no consensus on the size of a “large” class, but there is agreement that class size is one variable that interacts with and upon other variables. Research on the relationship between class size and achievement has been undertaken for over a century, but the findings have generally been contradictory or inconclusive. In contrast, teachers have always reported discomfort in teaching large classes. Recently, there have been attempts to describe what happens in different size classes. Reducing class size is expensive and brings uncertain benefits, so attention has turned from searching for the “optimum” class size to finding alternatives for improving teaching‐learning quality. Current emphasis, particularly in under‐resourced contexts, is on developing a contextually‐appropriate pedagogy, and deriving principles for “good practice” for large classes. This has implications for teacher research and development.",
        "link": "http://dx.doi.org/10.1002/9781118784235.eelt0633"
    },
    {
        "id": 14251,
        "title": "The Impact of AI and Cross-Border Data Regulation on International Trade in Digital Services: A Large Language Model",
        "authors": "Ruiqi Sun, Daniel Trefler",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3386/w31925"
    },
    {
        "id": 14252,
        "title": "The Use of a Large Language Model for Cyberbullying Detection",
        "authors": "Bayode Ogunleye, Babitha Dharmaraj",
        "published": "2023-9-6",
        "citations": 1,
        "abstract": "The dominance of social media has added to the channels of bullying for perpetrators. Unfortunately, cyberbullying (CB) is the most prevalent phenomenon in today’s cyber world, and is a severe threat to the mental and physical health of citizens. This opens the need to develop a robust system to prevent bullying content from online forums, blogs, and social media platforms to manage the impact in our society. Several machine learning (ML) algorithms have been proposed for this purpose. However, their performances are not consistent due to high class imbalance and generalisation issues. In recent years, large language models (LLMs) like BERT and RoBERTa have achieved state-of-the-art (SOTA) results in several natural language processing (NLP) tasks. Unfortunately, the LLMs have not been applied extensively for CB detection. In our paper, we explored the use of these models for cyberbullying (CB) detection. We have prepared a new dataset (D2) from existing studies (Formspring and Twitter). Our experimental results for dataset D1 and D2 showed that RoBERTa outperformed other models.",
        "link": "http://dx.doi.org/10.3390/analytics2030038"
    },
    {
        "id": 14253,
        "title": "Vector-Based and Neural Models of Semantics",
        "authors": "Willem Zuidema, Phong Le",
        "published": "2019-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7551/mitpress/10841.003.0028"
    },
    {
        "id": 14254,
        "title": "Leveraging molecular structure and bioactivity with chemical language models for drug design",
        "authors": "Michael Moret, Francesca Grisoni, Cyrill Brunner, Gisbert Schneider",
        "published": "No Date",
        "citations": 0,
        "abstract": "Generative chemical language models (CLMs) can be used for de novo molecular structure generation. These CLMs learn from the structural information of known molecules to generate new ones. In this paper, we show that “hybrid” CLMs can additionally leverage the bioactivity information available for the training compounds. To computationally design ligands of phosphoinositide 3-kinase gamma (PI3Kγ), we created a large collection of virtual molecules with a generative CLM. This primary virtual compound library was further refined using a CLM-based classifier for bioactivity prediction. This second hybrid CLM was pretrained with patented molecular structures and fine-tuned with known PI3Kγ binders and non-binders by transfer learning. Several of the computer-generated molecular designs were commercially available, which allowed for fast prescreening and preliminary experimental validation. A new PI3Kγ ligand with sub-micromolar activity was identified. The results positively advocate hybrid CLMs for virtual compound screening and activity-focused molecular design in low-data situations.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2021-xzgst"
    },
    {
        "id": 14255,
        "title": "Deep Pushdown Automata and New Stack Structures",
        "authors": "Alexander Meduna, Ondřej Soukup",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-63100-4_9"
    },
    {
        "id": 14256,
        "title": "Finite Automata and Regular Languages",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_0009"
    },
    {
        "id": 14257,
        "title": "Learning the Language of NMR: Structure Elucidation from NMR spectra using Transformer Models",
        "authors": "Marvin Alberts, Federico Zipoli, Alain C. Vaucher",
        "published": "No Date",
        "citations": 1,
        "abstract": "The application of machine learning models in chemistry has made remarkable strides in recent years. Even though there is considerable interest in automating common proce- dure in analytical chemistry using machine learning, very few models have been adopted into everyday use. Among the analytical instruments available to chemists, Nuclear Mag- netic Resonance (NMR) spectroscopy is one of the most important, offering insights into molecular structure unobtainable with other methods. However, most processing and analysis of NMR spectra is still performed manually, making the task tedious and time consuming especially for larger quantities of spectra. We present a transformer-based machine learning model capable of predicting the molecular structure directly from the NMR spectrum. Our model is pretrained on synthetic NMR spectra, achieving a top–1 accuracy of 67.0% when predicting the structure from both the 1H and 13C spectrum. Additionally, we train a model which, given a spectrum and a set of likely compounds, selects the one corresponding to the spectrum. This model achieves a top–1 accuracy of 96.0% when trained on 1H spectra.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2023-8wxcz"
    },
    {
        "id": 14258,
        "title": "Complex non-linear models",
        "authors": "Radan Martinec, Theo van Leeuwen",
        "published": "2020-10-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003060499-3"
    },
    {
        "id": 14259,
        "title": "Exploring Robust Overfitting for Pre-trained Language Models",
        "authors": "Bin Zhu, Yanghui Rao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.340"
    },
    {
        "id": 14260,
        "title": "Feature Interactions Reveal Linguistic Structure in Language Models",
        "authors": "Jaap Jumelet, Willem Zuidema",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.554"
    },
    {
        "id": 14261,
        "title": "Cognitive Models of Syntax and Sentence Processing",
        "authors": "Vera Demberg, Frank Keller",
        "published": "2019-10-29",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7551/mitpress/10841.003.0027"
    },
    {
        "id": 14262,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Tingting Fan",
        "published": "2023-7-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/4s67me"
    },
    {
        "id": 14263,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Matteo Ciniselli",
        "published": "2023-6-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/8zg12w"
    },
    {
        "id": 14264,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Evelin Amorim",
        "published": "2023-6-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/cqcl3y"
    },
    {
        "id": 14265,
        "title": "Supplementary material to &amp;quot;Societal breakdown as an emergent property of large-scale\nbehavioural models of land use change&amp;quot;",
        "authors": "Calum Brown, Bumsuk Seo, Mark Rounsevell",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5194/esd-2019-24-supplement"
    },
    {
        "id": 14266,
        "title": "How Effectively Train Large-Scale Machine Learning Models?",
        "authors": "Aven Samareh, Mahshid Salemi Parizi",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-28565-4_14"
    },
    {
        "id": 14267,
        "title": "Dual Variational Formulations for a Large Class of Non-Convex Models in the Calculus of Variations",
        "authors": "Fabio Silva Botelho",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003258131-15"
    },
    {
        "id": 14268,
        "title": "Exemplar models are useful and deep neural networks overcome their limitations: A commentary on Ambridge (2020)",
        "authors": "James L. McClelland",
        "published": "2020-10",
        "citations": 1,
        "abstract": " Humans are sensitive to the properties of individual items, and exemplar models are useful for capturing this sensitivity. I am a proponent of an extension of exemplar-based architectures that I briefly describe. However, exemplar models are very shallow architectures in which it is necessary to stipulate a set of primitive elements that make up each example, and such architectures have not been as successful as deep neural networks in capturing language usage and meaning. More work is needed bringing contemporary deep learning architectures used in machine intelligence to the effort to understand human language processing. ",
        "link": "http://dx.doi.org/10.1177/0142723720905765"
    },
    {
        "id": 14269,
        "title": "Fast and Robust Early-Exiting Framework for Autoregressive Language Models with Synchronized Parallel Decoding",
        "authors": "Sangmin Bae, Jongwoo Ko, Hwanjun Song, Se-Young Yun",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.362"
    },
    {
        "id": 14270,
        "title": "A Framework for Vision-Language Warm-up Tasks in Multimodal Dialogue Models",
        "authors": "Jaewook Lee, Seongsik Park, Seong-Heum Park, Hongjin Kim, Harksoo Kim",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.167"
    },
    {
        "id": 14271,
        "title": "Investigating Bias in Multilingual Language Models: Cross-Lingual Transfer of Debiasing Techniques",
        "authors": "Manon Reusens, Philipp Borchert, Margot Mieskes, Jochen De Weerdt, Bart Baesens",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.175"
    },
    {
        "id": 14272,
        "title": "A Comparative Analysis of Task-Agnostic Distillation Methods for Compressing Transformer Language Models",
        "authors": "Takuma Udagawa, Aashka Trivedi, Michele Merler, Bishwaranjan Bhattacharjee",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-industry.3"
    },
    {
        "id": 14273,
        "title": "Language surveillance: Pressure to follow local models of speakerhood among Latinx students in Madrid",
        "authors": "Luisa Martín Rojo, Rosina Márquez Reiter",
        "published": "2019-5-27",
        "citations": 4,
        "abstract": "Abstract\nIn this article, we examine the language surveillance – both self and externally imposed – experienced by Madrid university students of Latin American origin in their encounters with the local population in educational settings. A pattern of language surveillance emerges in the interviews held with these students. It consists of hierarchical observation, normalising judgment and interrogation. These three reported practices are related to the following linguistic and non-linguistic resources that make surveillance possible, namely: (a) indexicality, especially with regard to phonological distinctions that index speakers as “local” vs. “non-local” or “native” vs. “non-native”; (b) the invoking of disciplinary and prescriptive linguistic knowledge, together with the application of a colonial episteme whereby the metropolitan norm prevails, thus denying non-metropolitan speakers their right to language ownership; and, (c) the management of power within interactions. By these means, varieties and speakers of Spanish are hierarchised and those that differ from locals are positioned as subaltern others. Language surveillance is a disciplinary power technique that prompts speakers to adapt to the centripetal force exerted by the reproduction of this knowledge. Finally, the article examines the extent to which this stylistic move to adapt, could be considered an example of muda given that these shifts are situational and relational and attend to the different social demands of the communicative settings where the practice is observed.",
        "link": "http://dx.doi.org/10.1515/ijsl-2019-2019"
    },
    {
        "id": 14274,
        "title": "Dual Language Education Models and Research in Early Childhood Education in the USA",
        "authors": "Kathryn Lindholm-Leary",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-91662-6_11"
    },
    {
        "id": 14275,
        "title": "Application Analysis on Fly-by-Wire Flight Control System on Large Transport Aircraft",
        "authors": "",
        "published": "2022-5-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i5(02).13"
    },
    {
        "id": 14276,
        "title": "Large language model-based information extraction from free-text radiology reports: a scoping review protocol",
        "authors": "Daniel Reichenpfader, Henning Müller, Kerstin Denecke",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractIntroductionRadiological imaging is one of the most frequently performed diagnostic tests worldwide. The free text contained in radiology reports is currently only rarely utilized for secondary use, including research and predictive analysis. However, this data might be made available by means of information extraction (IE), based on natural language processing (NLP). Recently, a new approach to NLP, large language models (LLMs), has gained momentum and continues to improve performance. The objective of this scoping review is to show the state of research regarding IE from free-text radiology reports based on LLMs, to investigate applied methods, and to guide future research by showing open challenges and limitations of current approaches. To our knowledge, no systematic nor scoping review of IE of radiology reports, based on LLMs, has been conducted yet. Existing publications are outdated and do not comprise LLM-based models.Methods and analysisThis protocol is designed based on the JBI manual for evidence synthesis, chapter 11.2: “Development of a scoping review protocol”. Inclusion criteria and a search strategy comprising four databases (PubMed, IEEE Xplore, Web of Science Core Collection, ACM Digital Library) are defined. Furthermore, we describe the screening process, data charting, analysis and presentation of extracted data.Ethics and disseminationThis protocol describes the methodology of a scoping literature review and does not comprise research on or with humans, animals or their data. Therefore, no ethical approval is required. After the publication of this protocol and the conduct of the review, its results are going to be published in an open access journal dedicated to biomedical informatics/ digital health.Strengths and limitations of this studyThis scoping review protocol strictly adheres to standardized guidelines for scoping review conduction, including JBI Manual for Evidence Synthesis and the PRISMA-ScR guideline.The search strategy comprises four databases: PubMed, IEEE Xplore, Web of Science Core Collection, and ACM Digital Library.This scoping review will close the knowledge gap present in the field of information extraction from radiology reports caused by the recent rapid technical process.According to the nature of a scoping review, identified sources of evidence are not critically appraised.The results of the scoping review will serve as a basis for defining further research directions regarding information extraction from radiology reports.",
        "link": "http://dx.doi.org/10.1101/2023.07.28.23292031"
    },
    {
        "id": 14277,
        "title": "Towards Large Language Model Organization: A Case Study on Abstractive Summarization",
        "authors": "Krisztián Boros, Masafumi Oyamada",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386199"
    },
    {
        "id": 14278,
        "title": "Utility-based recommendation system for large datasets using EAHUIM",
        "authors": "Vandna Dahiya",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003244332-2"
    },
    {
        "id": 14279,
        "title": "Data-Driven Unsupervised Semantic Network Algorithm for Large Language Model Examination/Exploration",
        "authors": "Sriram Elango, Kokil Jaidka",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4410157"
    },
    {
        "id": 14280,
        "title": "Unveiling Specialization Trends in Economics Research: A Large-Scale Study Using Natural Language Processing and Citation Analysis",
        "authors": "Sebastian Galiani, Ramiro Gálvez, Ian Nachman",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3386/w31295"
    },
    {
        "id": 14281,
        "title": "Eplus-Llm: A Large Language Model-Based Computing Platform for Automated Building Energy Modeling",
        "authors": "Gang Jiang, Zhihao Ma, Liang Zhang, Jianli Chen",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4743437"
    },
    {
        "id": 14282,
        "title": "Terminology-Aware Translation with Constrained Decoding and Large Language Model Prompting",
        "authors": "Nikolay Bogoychev, Pinzhen Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.wmt-1.80"
    },
    {
        "id": 14283,
        "title": "How large should a dense corpus be for reliable studies in early language acquisition ?",
        "authors": "Christophe Parisse",
        "published": "2019-6-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4000/cognitextes.1483"
    },
    {
        "id": 14284,
        "title": "GastroGPT: Successful proof-of-concept study of gastroenterology-specific large language model",
        "authors": "Robert van den Heuvel",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.55788/c6bd4c96"
    },
    {
        "id": 14285,
        "title": "Invited Session III: Neural network models of the visual system: Reverse-engineering neural code in the language of objects and generative models",
        "authors": "Ilker Yildirim",
        "published": "2023-9-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1167/jov.23.11.19"
    },
    {
        "id": 14286,
        "title": "Better Handling Coreference Resolution in Aspect Level Sentiment Classification by Fine-Tuning Language Models",
        "authors": "Dhruv Mullick, Bilal Ghanem, Alona Fyshe",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.crac-main.5"
    },
    {
        "id": 14287,
        "title": "Going Big!: The Case of a Large District’s Effort to Maximize the Benefits of Dual Language Programming for their Children",
        "authors": "Craige Willey, James Kigamwa",
        "published": "2019-3-29",
        "citations": 0,
        "abstract": "Dual language (DL) programs have been held up as a promising means by which to reach student achievement goals across demographics (Collier & Thomas, 2004). Yet, the social and political risks associated with implementing DL programs are significant. This paper analyzes one large metropolitan school district’s rationale and preparedness for initiating its DL program, as well as the outcomes of its efforts to scale up the DL program to reach thousands of students, most of whom are children of color. The findings suggest that the district personnel used three pillars to rationalize their decision to implement their DL program: legal, research, and student demographics. In addition, the school district administrators, teachers, and parents showed varying levels of preparedness for the mass implementation of the DL program. While a young program with few quantitative data points to showcase its success, the qualitative data revealed that the program’s structure and professional development efforts for the teachers and principals benefited from a clear and ambitious vision and the unwavering support of the district’s executive leadership. In addition to the extensive data compiled from interviews with key stakeholders, case studies of two schools from the district are provided in order to highlight emergent tensions and showcase how the district’s efforts have materialized into intentional and dynamic DL learning environments.",
        "link": "http://dx.doi.org/10.21423/dlrpj-v1.a1"
    },
    {
        "id": 14288,
        "title": "Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication",
        "authors": "Zhangyue Yin, Qiushi Sun, Cheng Chang, Qipeng Guo, Junqi Dai, Xuanjing Huang, Xipeng Qiu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.936"
    },
    {
        "id": 14289,
        "title": "Socially Responsible Hate Speech Detection: Can Classifiers Reflect Social Stereotypes?",
        "authors": "Francielle Vargas,  , Isabelle Carvalho, Ali Hürriyetoğlu, Thiago A. S. Pardo, Fabrício Benevenuto,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_126"
    },
    {
        "id": 14290,
        "title": "The Dialectical Foundations of Mathematics",
        "authors": "Dirk Damsma",
        "published": "2019-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1163/9789004395497_004"
    },
    {
        "id": 14291,
        "title": "Bibliography",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.biblio"
    },
    {
        "id": 14292,
        "title": "Psycholinguistic Diagnosis of Language Models’ Commonsense Reasoning",
        "authors": "Yan Cong",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.csrr-1.3"
    },
    {
        "id": 14293,
        "title": "CultureBERT: Measuring Corporate Culture With Transformer-Based Language Models",
        "authors": "Sebastian Koch, Stefan Pasch",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386765"
    },
    {
        "id": 14294,
        "title": "Investigating the Influence of News Sources and Language Models on Climate Beta Estimates",
        "authors": "Jean-Michel Maeso, Dominic O&apos;Kane",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4390552"
    },
    {
        "id": 14295,
        "title": "Lexicon-enhanced Pre-trained Language Models for Chinese Ethics-related Tasks",
        "authors": "Tianlong Gu, Tong Bao, Long Li, Liang Chang, Xuan Feng",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The proposal and rapid development of pre-trained language models have led to unprecedented breakthroughs in natural language processing techniques. Although pre-trained language models have strong text-understanding capabilities, their performance in handling ethical issues is unsatisfactory due to the complexity of ethical connotations. To improve the ethical understanding and generation capabilities of pre-trained language models, a novel knowledge enhancement solution based on the ethics lexicon is proposed.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23689404"
    },
    {
        "id": 14296,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Shivani Malhotra",
        "published": "2023-6-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/gj41tb"
    },
    {
        "id": 14297,
        "title": "Models of multilingual competence",
        "authors": "Britta Hufeisen",
        "published": "2018-10-8",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/hsld.7.08huf"
    },
    {
        "id": 14298,
        "title": "Multilingual Lottery Tickets to Pretrain Language Models",
        "authors": "Jaeseong Lee, Seung-won Hwang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.629"
    },
    {
        "id": 14299,
        "title": "Review on natural language processing models",
        "authors": "LI YIKUN",
        "published": "2024-2-4",
        "citations": 0,
        "abstract": "Accessing information has grown simpler as a result of the internet's expanding use and the arrival of the big data era. Compared to traditional approaches, employing NLP for information condensation and amalgamation proves to be a highly effective method. This article focuses primarily on the sentiment analysis aspect of NLP, offering a comprehensive exploration of two deep learning models: BERT and CNN. It delves into the intricacies of their principles, analyzes their respective strengths and weaknesses, and proposes potential avenues for enhancement. By delving into these models, Researchers and practitioners can obtain a better understanding of sentiment analysis and its applications in diverse fields.",
        "link": "http://dx.doi.org/10.54254/2755-2721/35/20230350"
    },
    {
        "id": 14300,
        "title": "A Comprehensive Survey on Word Representation Models: From Classical to State-of-the-Art Word Representation Language Models",
        "authors": "Usman Naseem, Imran Razzak, Shah Khalid Khan, Mukesh Prasad",
        "published": "2021-9-30",
        "citations": 61,
        "abstract": "Word representation has always been an important research area in the history of natural language processing (NLP). Understanding such complex text data is imperative, given that it is rich in information and can be used widely across various applications. In this survey, we explore different word representation models and its power of expression, from the classical to modern-day state-of-the-art word representation language models (LMS). We describe a variety of text representation methods, and model designs have blossomed in the context of NLP, including SOTA LMs. These models can transform large volumes of text into effective vector representations capturing the same semantic information. Further, such representations can be utilized by various machine learning (ML) algorithms for a variety of NLP-related tasks. In the end, this survey briefly discusses the commonly used ML- and DL-based classifiers, evaluation metrics, and the applications of these word embeddings in different NLP tasks.",
        "link": "http://dx.doi.org/10.1145/3434237"
    },
    {
        "id": 14301,
        "title": "GeoMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models",
        "authors": "Da Yin, Hritik Bansal, Masoud Monajatipoor, Liunian Harold Li, Kai-Wei Chang",
        "published": "2022",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.132"
    },
    {
        "id": 14302,
        "title": "The Application of Probing Prompting Learning Models in Mastering Foreign Language Vocabulary",
        "authors": "Misnawaty Usman, Himala Praptami Adys, Rosmaladewi Rosmaladewi, Muhammad Nur Ashar Asnur",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "This study aims to obtain data about the probing prompting learning model in vocabulary mastery of the students of the Foreign Language Education Study Program, Department of Foreign Language Education, in a public university. This research is classroom action research conducted in two cycles. The subjects of this study were 30 students of the 2019/2020 Odd Semester of Foreign Language Education Study Program. The research data consists of two types, namely, qualitative data and quantitative data. Qualitative data were obtained through observation, while quantitative data were obtained through the results of the first cycle and second cycle vocabulary mastery tests. The data were analyzed using percentage techniques. The results showed that the vocabulary mastery with the percentage of values obtained by the German Language Education Study Program students in the first cycle reached 67.65%, and the second cycle reached 84.52%. These results indicate that the application of the probing-prompting learning model increases the mastery of German vocabulary for students of the German Language Education Study Program, Department of Foreign Language Education of a public university.",
        "link": "http://dx.doi.org/10.26858/ijole.v7i4.58366"
    },
    {
        "id": 14303,
        "title": "Referencing context in sentence processing: A failure to replicate the strong interactive mental models hypothesis",
        "authors": "Jack Dempsey, Kiel Christianson",
        "published": "2022-8",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jml.2022.104335"
    },
    {
        "id": 14304,
        "title": "OPI@LT-EDI-ACL2022: Detecting Signs of Depression from Social Media Text using RoBERTa Pre-trained Language Models",
        "authors": "Rafał Poświata, Michał Perełkiewicz",
        "published": "2022",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.ltedi-1.40"
    },
    {
        "id": 14305,
        "title": "CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models",
        "authors": "Nikita Nangia, Clara Vania, Rasika Bhalerao, Samuel R. Bowman",
        "published": "2020",
        "citations": 32,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.154"
    },
    {
        "id": 14306,
        "title": "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts",
        "authors": "Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, Sameer Singh",
        "published": "2020",
        "citations": 205,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.346"
    },
    {
        "id": 14307,
        "title": "Models of company's capital structure: Classification and analysis",
        "authors": "Dmitry Sizykh, Natalia Sizykh",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2017.8109687"
    },
    {
        "id": 14308,
        "title": "Evaluating Causal Psychological Models: Causes of Altered Imitation in Autism Using a Large Sample",
        "authors": "Bohao Tang, Ericka Wodka, Brian Caffo, Joshua Ewen",
        "published": "No Date",
        "citations": 0,
        "abstract": "We used a large convenience sample (n=22,228) from the Simons Powering Autism Research(SPARK) dataset to evaluate theories positing various psychological factors as causes of altered imitation in autism. We used a highly theory-constrained approach, formalizing statistical models based on the proposals of Hobson &amp; Lee (1999), Baron-Cohen (1988) and Smith &amp; Bryson (1994). These theories specified key roles of social engagement, metarepresentation and the effect of restricted and repetitive behaviors on motor development. Our results disconfirmed a key role of any of these factors in the development of altered propensity to imitate, within the limitations of the convenience dataset.",
        "link": "http://dx.doi.org/10.31234/osf.io/q3xda"
    },
    {
        "id": 14309,
        "title": "Global robust Bayesian analysis in large models",
        "authors": "Paul Ho",
        "published": "2023-8",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jeconom.2022.06.004"
    },
    {
        "id": 14310,
        "title": "Dynamic models of large-scale brain activity",
        "authors": "Michael Breakspear",
        "published": "2017-3",
        "citations": 764,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/nn.4497"
    },
    {
        "id": 14311,
        "title": "Dynamics between reading and math proficiency over time in secondary education – observational evidence from continuous time models",
        "authors": "Christoph Jindra, Karoline A. Sachse, Martin Hecht",
        "published": "2022-12-9",
        "citations": 1,
        "abstract": "AbstractIntroductionReading and math proficiency are assumed to be crucial for the development of other academic skills. Further, different studies found reading and math development to be related. We contribute to the literature by looking at the relationship between reading and math using continuous time models. In contrast to previous studies, this allows us to (a) report estimates for autoregressive and cross-lagged effects for a range of possible time intervals while still only estimating one set of continuous time parameters and (b) identify peak effects for the relationship between the two. Using data from Starting Cohort 3 of the National Educational Panel Study, we find, in line with previous evidence, a larger effect of reading on math than the other way around. Furthermore, we identify peak standardized cross-lagged effects ($${a}_{reading\\to math}\\approx 0.30$$,$${a}_{math\\to reading}\\approx 0.13$$) for a time interval of approximately 6 months.",
        "link": "http://dx.doi.org/10.1186/s40536-022-00136-6"
    },
    {
        "id": 14312,
        "title": "Confounder Balancing in Adversarial Domain Adaptation for Pre-Trained Large Models Fine-Tuning",
        "authors": "Shuoran Jiang, Qingcai Chen, Yang Xiang, Youcheng Pan, Xiangping Wu",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The excellent generalization, contextual learning, and emergence abilities in the pre-trained large models (PLMs) handle specific tasks without direct training data, making them the better foundation models in the adversarial domain adaptation (ADA) methods to transfer knowledge learned from the source domain to target domains. However, existing ADA methods fail to account for the confounder properly, which is the root cause of the source data distribution that differs from the target domains. This study proposes an adversarial domain adaptation with confounder balancing for PLMs fine-tuning (ADA-CBF). The ADA-CBF includes a PLM as the foundation model for a feature extractor, a domain classifier and a confounder classifier, and they are jointly trained with an adversarial loss. This loss is designed to improve the domain-invariant representation learning by diluting the discrimination in the domain classifier. At the same time, the adversarial loss also balances the confounder distribution among source and unmeasured domains in training. Compared to existing ADA methods, ADA-CBF can correctly identify confounders in domain-invariant features, thereby eliminating the confounder biases in the extracted features from PLMs. The confounder classifier in ADA-CBF is designed as a plug-and-play and can be applied in the confounder measurable, unmeasurable, or partially measurable environments. Empirical results on natural language processing and computer vision downstream tasks show that ADA-CBF outperforms the newest GPT-4, LLaMA2, ViT and ADA methods.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24432997.v1"
    },
    {
        "id": 14313,
        "title": "Structural Changes in Panel Data Models",
        "authors": "",
        "published": "2020-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811220784_0004"
    },
    {
        "id": 14314,
        "title": "The State Of Population Health Of Russians: Models And Concepts",
        "authors": "Viktor Glebov",
        "published": "2023-9-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd58227.2023.10304000"
    },
    {
        "id": 14315,
        "title": "Preface",
        "authors": "Ya-Xiong Tao",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/s1877-1173(22)00055-2"
    },
    {
        "id": 14316,
        "title": "Assessing the Role of Initial Conditions in the Local Structural Identifiability of Large Dynamic Models",
        "authors": "Dominique Joubert, J.D. Stigter, Jaap Molenaar",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nStructural identifiability is a binary property that determines whether or not unique parameter values can, in principle, be estimated from error-free input-output data. The many papers that have been written on this topic collectively stress theimportance of this a priori analysis in the model development process. The story however, often ends with a structurallyunidentifiable model. This may leave a model developer with no plan of action on how to address this potential issue. We continue this model exploration journey by identifying one of the possible sources of a model’s unidentifiability: problematic initial conditions. It is well-known that certain initial values may result in the loss of local structural identifiability. Nevertheless, literature on this topic has been limited to the analysis of small toy models. Here, we present a systematic approach to detect problematic initial conditions of real-world systems biology models, that are usually not small. A model’s identifiability can often be reinstated by changing the value of such problematic initial conditions. This provides modellers an option to resolve the “unidentifiablemodel” problem. Additionally, a good understanding of which initial values should rather be avoided can be very useful during experimental design. We show how our approach works in practice by applying it to five models. First, two small benchmark models are studied toget the reader acquainted with the method. The first one shows the effect of a zero-valued problematic initial condition. The second one illustrates that the approach also yields correct results in the presence of input signals and that problematic initial conditions need not be zero-values. For the remaining three examples, we set out to identify key initial values which may result in the structural unidentifiability. The third and fourth examples involve a systems biology Epo receptor model and a JAK/STAT model, respectively. In the final Pharmacokinetics model, of which its global structural identifiability has only recently been confirmed, we indicate that there are still sets of initial values for which this property does not hold.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-209455/v1"
    },
    {
        "id": 14317,
        "title": "Circumstantial evidence and explanatory models for synapses in large-scale spike recordings",
        "authors": "Ian H. Stevenson",
        "published": "2023-12-2",
        "citations": 2,
        "abstract": "Whether, when, and how causal interactions between neurons can be meaningfully studied from observations of neural activity alone are vital questions in neural data analysis. Here we aim to better outline the concept of functional connectivity for the specific situation where systems neuroscientists aim to study synapses using spike train recordings. In some cases, cross-correlations between the spikes of two neurons are such that, although we may not be able to say that a relationship is causal without experimental manipulations, models based on synaptic connections provide precise explanations of the data. Additionally, there is often strong circumstantial evidence that pairs of neurons are monosynaptically connected. Here we illustrate how circumstantial evidence for or against synapses can be systematically assessed and show how models of synaptic effects can provide testable predictions for pair-wise spike statistics. We use case studies from large-scale multi-electrode spike recordings to illustrate key points and to demonstrate how modeling synaptic effects using large-scale spike recordings opens a wide range of data analytic questions.",
        "link": "http://dx.doi.org/10.51628/001c.90831"
    },
    {
        "id": 14318,
        "title": "Flight Dynamic Modelling and Simulation of Large Flexible Aircraft",
        "authors": "Gaétan Dussart, Vilius Portapas, Alessandro Pontillo, Mudassir Lone",
        "published": "2018-2-14",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5772/intechopen.71050"
    },
    {
        "id": 14319,
        "title": "Efficient parameterization of large-scale dynamic models based on relative measurements",
        "authors": "Leonard Schmiester, Yannik Schälte, Fabian Fröhlich, Jan Hasenauer, Daniel Weindl",
        "published": "No Date",
        "citations": 5,
        "abstract": "AbstractMotivationMechanistic models of biochemical reaction networks facilitate the quantitative understanding of biological processes and the integration of heterogeneous datasets. However, some biological processes require the consideration of comprehensive reaction networks and therefore large-scale models. Parameter estimation for such models poses great challenges, in particular when the data are on a relative scale.ResultsHere, we propose a novel hierarchical approach combining (i) the efficient analytic evaluation of optimal scaling, offset, and error model parameters with (ii) the scalable evaluation of objective function gradients using adjoint sensitivity analysis. We evaluate the properties of the methods by parameterizing a pan-cancer ordinary differential equation model (>1000 state variables,>4000 parameters) using relative protein, phospho-protein and viability measurements. The hierarchical formulation improves optimizer performance considerably. Furthermore, we show that this approach allows estimating error model parameters with negligible computational overhead when no experimental estimates are available, pro-viding an unbiased way to weight heterogeneous data. Overall, our hierarchical formulation is applicable to a wide range of models, and allows for the efficient parameterization of large-scale models based on heterogeneous relative measurements.Contactjan.hasenauer@helmholtz-muenchen.deSupplementary informationSupplementary information are available atbioRxivonline. Supplementary code and data are available online athttp://doi.org/10.5281/zenodo.2593839andhttp://doi.org/10.5281/zenodo.2592186.",
        "link": "http://dx.doi.org/10.1101/579045"
    },
    {
        "id": 14320,
        "title": "Modern Research on the Human Ability to Solve Problems that Have Large Search Spaces",
        "authors": "",
        "published": "2022-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009205603.004"
    },
    {
        "id": 14321,
        "title": "Mesh Adaptation Using Adjoint Methods and Reduced-Order Models for Large Eddy Simulation",
        "authors": "X. Li, S. Hulshoff, S. Hickel",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23967/wccm-eccomas.2020.196"
    },
    {
        "id": 14322,
        "title": "A Lagrange-Multiplier Test for Large Heterogeneous Panel Data Models",
        "authors": "Natalia Bailey, JIANG Dandan, Jianfeng Yao",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3804164"
    },
    {
        "id": 14323,
        "title": "Large Animal Models of Cardiovascular Disease: From Training to Translation",
        "authors": "Claudia Báez-Díaz, Verónica Crisóstomo",
        "published": "2023-3-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3791/64983-v"
    },
    {
        "id": 14324,
        "title": "Efficient Large Scale Optimization Under Uncertainty With Multiple Proxy Models",
        "authors": "N.H. Goodwin",
        "published": "2018-9-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3997/2214-4609.201802302"
    },
    {
        "id": 14325,
        "title": "An Empirical Validation Protocol for Large-Scale Agent-Based Models",
        "authors": "Sylvain Barde, Sander van der Hoog",
        "published": "No Date",
        "citations": 26,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2992473"
    },
    {
        "id": 14326,
        "title": "Equilibrium in Open Market Models with Nonconstant Elastisities",
        "authors": "Alexander Kotyukov, Pavlova Natal’Ya",
        "published": "2023-9-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd58227.2023.10303986"
    },
    {
        "id": 14327,
        "title": "Invited Session III: Neural network models of the visual system: Reverse-engineering neural code in the language of objects and generative models",
        "authors": "Ilker Yildirim",
        "published": "2023-9-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1167/jov.23.11.19"
    },
    {
        "id": 14328,
        "title": "Better Handling Coreference Resolution in Aspect Level Sentiment Classification by Fine-Tuning Language Models",
        "authors": "Dhruv Mullick, Bilal Ghanem, Alona Fyshe",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.crac-main.5"
    },
    {
        "id": 14329,
        "title": "The Simulation Models in Grid Methods of Uniform Probing",
        "authors": "Galina M. Antonova",
        "published": "2019-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2019.8910978"
    },
    {
        "id": 14330,
        "title": "Control Models at the Public-Private Partnership (PPP)",
        "authors": "A.D. Tsvirkun, F.I. Ereshko",
        "published": "2019-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2019.8911011"
    },
    {
        "id": 14331,
        "title": "Winter extreme weather in EURO-CORDEX climate models and their links to large-scale atmospheric circulation",
        "authors": "Eva Plavcová, Ondřej Lhotka, Jan Stryhal",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Regional Climate Models (RCMs) are powerful tools to study changes in the climate system on the regional scale. However, the reliability of their simulations has been considerably limited by the longstanding issue that climate models often fail to reproduce various aspects of the historical climate. In our study, we analyse how RCMs from the EURO-CORDEX project are able to reproduce extreme winter weather. We analyse temporal and spatial characteristics of extreme wind gust, extremely cold temperature, and extreme precipitation. Model outputs are validated against observed data from the European gridded observational&amp;#160;database (EOBS) and the novel ERA5 reanalysis. We focus on the Central European domain (defined between 48&amp;#8211;52&amp;#176;N and 10&amp;#8211;19&amp;#176;E) over the 1979 &amp;#8211; 2017 period. We investigate a set of 9 simulations of 3 different RCMs driven by 3 different global climate models which allow us to analyse the influence of driving data on the RCM&amp;#8217;s performance. Since local climate elements are relatively tightly linked to a large-scale atmospheric circulation over Europe in winter, we also evaluate the ability of RCMs to reproduce the atmospheric circulation and its links to selected high-impact winter weather in detail. We use the classification of circulation based on the method of Sammon mapping. Investigation of these links can lead to better physical understanding of the climate and to the identification of inadequacies in simulated characteristics of the studied events. All of this is an important step forward in further improving the models and enhancing the credibility of climate change scenarios based on climate model simulations.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/ems2021-377"
    },
    {
        "id": 14332,
        "title": "On the Construction and Analysis of Macroeconomic Operating Game Models",
        "authors": "Shevchenko Vasiliy",
        "published": "2018-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2018.8551764"
    },
    {
        "id": 14333,
        "title": "Pre-supernova models for massive stars produced with large nuclear reaction network by MESA",
        "authors": "Byeongchan Park, Kyujin Kwak",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/1.5030832"
    },
    {
        "id": 14334,
        "title": "Improved Handling for Large CAD Models",
        "authors": "",
        "published": "2019-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.12968/s0261-2097(22)60344-7"
    },
    {
        "id": 14335,
        "title": "Large Animal Models of Cardiovascular Disease: From Training to Translation",
        "authors": "Claudia Báez-Díaz, Verónica Crisóstomo",
        "published": "2023-3-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3791/64983"
    },
    {
        "id": 14336,
        "title": "Machine-Learnt Closure Models with Embedded Geometry Independencetraining Framework for Large-Eddy Simulations in Natural Convection",
        "authors": "Liyuan Liu, Chitrarth Lav, Richard Sandberg",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4673116"
    },
    {
        "id": 14337,
        "title": "Large-scale process models using deep learning",
        "authors": "R. Bhushan Gopaluni, Liang Cao, Yankai Cao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-823869-1.00009-0"
    },
    {
        "id": 14338,
        "title": "Huntington's disease: From large animal models to HD gene therapy",
        "authors": "Sen Yan, Xiao-Jiang Li, Shihua Li",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-95672-7.00014-5"
    },
    {
        "id": 14339,
        "title": "Going Big!: The Case of a Large District’s Effort to Maximize the Benefits of Dual Language Programming for their Children",
        "authors": "Craig Willey, James Kigamwa",
        "published": "2018-12-4",
        "citations": 0,
        "abstract": "Dual language (DL) programs have been held up as a promising means by which to reach student achievement goals across demographics (Collier & Thomas, 2004). Yet, the social and political risks associated with implementing DL programs are significant. This paper analyzes one large metropolitan school district’s rationale and preparedness for initiating its DL program, as well as the outcomes of its efforts to scale up the DL program to reach thousands of students, most of whom are children of color. The findings suggest that the district personnel used three pillars to rationalize their decision to implement their DL program: legal, research, and student demographics. In addition, the school district administrators, teachers, and parents showed varying levels of preparedness for the mass implementation of the DL program. While a young program with few quantitative data points to showcase its success, the qualitative data revealed that the program’s structure and professional development efforts for the teachers and principals benefited from a clear and ambitious vision and the unwavering support of the district’s executive leadership. In addition to the extensive data compiled from interviews with key stakeholders, case studies of two schools from the district are provided in order to highlight emergent tensions and showcase how the district’s efforts have materialized into intentional and dynamic DL learning environments.",
        "link": "http://dx.doi.org/10.21423/dlrpj-v1.a6"
    },
    {
        "id": 14340,
        "title": "Morphologically motivated word classes for very large vocabulary speech recognition of Finnish and Estonian",
        "authors": "Matti Varjokallio, Sami Virpioja, Mikko Kurimo",
        "published": "2021-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2020.101141"
    },
    {
        "id": 14341,
        "title": "StructGPT: A General Framework for Large Language Model to Reason over Structured Data",
        "authors": "Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Xin Zhao, Ji-Rong Wen",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.574"
    },
    {
        "id": 14342,
        "title": "Pretrained models + simulations for our HESSD submission \"Towards learning universal, regional, and local hydrological behaviors via machine learning applied to large-sample datasets\"",
        "authors": "Frederik Kratzert",
        "published": "2019-12-17",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4211/hs.83ea5312635e44dc824eeb99eda12f06"
    },
    {
        "id": 14343,
        "title": "Models of Metrical Structure in Music",
        "authors": "Edward W. Large",
        "published": "2019-5-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781315789354-93"
    },
    {
        "id": 14344,
        "title": "A Highly Accurate Traveltime Approximation for Large-offset Reflections over Layered VTI Models",
        "authors": "M.M. Abedi, D. Pardo",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3997/2214-4609.202112529"
    },
    {
        "id": 14345,
        "title": "Factor-Augmented Panel Data Regression Models",
        "authors": "",
        "published": "2020-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811220784_0003"
    },
    {
        "id": 14346,
        "title": "Tailoring large-scale hydrological models for national planning of climate actions in vulnerable countries",
        "authors": "Berit Arheimer, Frida Gyllensvärd, René Capell, Jafet Andersson",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Many countries vulnerable to climate change do not yet have national modelling systems in place to guide adaptation measures. Especially low- and middle-income countries are at the mercy of global or large-scale estimates of climate change impacts, which might not be relevant to the spatial scale of societal challenges or to engineering methods based on observations.&lt;/p&gt;&lt;p&gt;Climate services are launched with scientific data, which can be misunderstood and misused if not communicated in a pedagogic way. For instance, the results from climate models represents an average for a calculation unit and neglects the spatial variability within that unit. In-situ observations from monitoring stations represents a point value and may thus be very different from areal estimates. Moreover, observations are relatively few leaving large areas ungauged. Sometimes, the area of interest falls in between grids or is very small compared to the grid or catchment and the average values may then not be representative or useful.&lt;/p&gt;&lt;p&gt;Moreover, the results from climate models represents a statistical period of 30 years, but not the chronological happening of events or weather conditions. Time-series from climate models are thus not representing specific dates and should not be compared to observed time-series but only to statistical estimates, such as indicators.&amp;#160;&lt;/p&gt;&lt;p&gt;In this presentation we showcase (1) state-of the art methods to produce climate indicators for weather and water data over large domains, and (2) some ways to tailor climate and water data for local applications and practical use.&lt;/p&gt;&lt;p&gt;We will demonstrate the global climate service climateinformation.org, in which climate and water indicators result from an extensive production chain, merging data from various sources with different resolution in time and space.&lt;/p&gt;&lt;p&gt;For water indicators, climateinformation.org uses results from a global integrated-catchment model, the world-wide HYPE. To tailor data, it is recommended to use a more detailed national/local model or set-up the HYPE model using national/local data. SMHI share the open source HYPE-model code and here we will explain how to apply climate indicators to calculate climate-change effects on water resources using a local/national model. Showcases are given for St Lucia, DR Congo, Cape Verde, and Cambodia.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/iahs2022-426"
    },
    {
        "id": 14347,
        "title": "On large market asymptotics for spatial price competition models",
        "authors": "Taisuke Otsu, Keita Sunada",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.econlet.2023.111468"
    },
    {
        "id": 14348,
        "title": "Confounder Balancing in Adversarial Domain Adaptation for Pre-Trained Large Models Fine-Tuning",
        "authors": "Shuoran Jiang, Qingcai Chen, Yang Xiang, Youcheng Pan, Xiangping Wu",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The excellent generalization, contextual learning, and emergence abilities in the pre-trained large models (PLMs) handle specific tasks without direct training data, making them the better foundation models in the adversarial domain adaptation (ADA) methods to transfer knowledge learned from the source domain to target domains. However, existing ADA methods fail to account for the confounder properly, which is the root cause of the source data distribution that differs from the target domains. This study proposes an adversarial domain adaptation with confounder balancing for PLMs fine-tuning (ADA-CBF). The ADA-CBF includes a PLM as the foundation model for a feature extractor, a domain classifier and a confounder classifier, and they are jointly trained with an adversarial loss. This loss is designed to improve the domain-invariant representation learning by diluting the discrimination in the domain classifier. At the same time, the adversarial loss also balances the confounder distribution among source and unmeasured domains in training. Compared to existing ADA methods, ADA-CBF can correctly identify confounders in domain-invariant features, thereby eliminating the confounder biases in the extracted features from PLMs. The confounder classifier in ADA-CBF is designed as a plug-and-play and can be applied in the confounder measurable, unmeasurable, or partially measurable environments. Empirical results on natural language processing and computer vision downstream tasks show that ADA-CBF outperforms the newest GPT-4, LLaMA2, ViT and ADA methods.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24432997"
    },
    {
        "id": 14349,
        "title": "WaterBench: A Large-scale Benchmark Dataset for Data-Driven Streamflow Forecasting",
        "authors": "Ibrahim Demir, Zhongrun Xiang, Bekir Demiray, Muhammed Sit",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract. This study proposes a comprehensive benchmark dataset for streamflow forecasting, WaterBench, that follows FAIR data principles that is prepared with a focus on convenience for utilizing in data-driven and machine learning studies, and provides benchmark performance for state-of-art deep learning architectures on the dataset for comparative analysis. By aggregating the datasets of streamflow, precipitation, watershed area, slope, soil types, and evapotranspiration from federal agencies and state organizations (i.e., NASA, NOAA, USGS, and Iowa Flood Center), we provided the WaterBench for hourly streamflow forecast studies. This dataset has a high temporal and spatial resolution with rich metadata and relational information, which can be used for varieties of deep learning and machine learning research. We defined a sample streamflow forecasting task for the next 120 hours and provided performance benchmarks on this task with sample linear regression and deep learning models, including Long Short-Term Memory (LSTM), Gated Recurrent Units (GRU), and S2S (Sequence-to-sequence). To some extent, WaterBench makes up for the lack of unified benchmarks in earth science research. We highly encourage researchers to use the WaterBench for deep learning research in hydrology.\n                        ",
        "link": "http://dx.doi.org/10.5194/essd-2022-52"
    },
    {
        "id": 14350,
        "title": "Cosmology constraints on Dark Sector models for colliders",
        "authors": "Andreas Goudelis",
        "published": "2021-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22323/1.397.0129"
    },
    {
        "id": 14351,
        "title": "Difference Diffusion Models with Equilibrium",
        "authors": "",
        "published": "2021-8-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119851257.ch6"
    },
    {
        "id": 14352,
        "title": "Mixed Effects Models",
        "authors": "Jiming Jiang",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-91695-4_12"
    },
    {
        "id": 14353,
        "title": "Large-scale Agent-Based Epidemic Models and Their  Technical Implementation on Supercomputers",
        "authors": "Alina Ageeva",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18254/s207751800010459-3"
    },
    {
        "id": 14354,
        "title": "Models of Forming and Processing Packages of Transport Services",
        "authors": "S. A. Savushkin",
        "published": "2019-10",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2019.8910992"
    },
    {
        "id": 14355,
        "title": "Devising storylines of Arctic climate change from a large ensemble of CMIP6 models",
        "authors": "Xavier Levine, Ryan Williams, Lise Seland Graff, Priscilla Mooney",
        "published": "No Date",
        "citations": 0,
        "abstract": "While polar amplification has been established as a defining feature of Arctic climate change, poor quantitative agreement among models remains when assessing its magnitude and spatial pattern. Here, we apply the storyline approach to a large ensemble of CMIP6 models, with the aim of distilling the wide spread in model predictions into four physically plausible outcomes of Arctic climate change. This is made possible by leveraging strong covariability in the climate system: specifically, we find that differences in Barents Sea warming and lower tropospheric warming among CMIP6 models explain most of the intermodel variability in pan-Arctic surface climate response to global warming. Based on this novel finding, we compare regional disparities in climate change across the four storylines, and discuss potential implications for modeling climate change impacts on ecosystems and human activities.&#160;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-7398"
    },
    {
        "id": 14356,
        "title": "Nonlinear Modal Aeroelastic Analysis from Large Industrial-Scale Models",
        "authors": "Alvaro Cea, Rafael Palacios",
        "published": "2019-1-7",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2514/6.2019-0208"
    },
    {
        "id": 14357,
        "title": "Large covariance estimation through elliptical factor models",
        "authors": "Jianqing Fan, Han Liu, Weichen Wang",
        "published": "2018-8-1",
        "citations": 39,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1214/17-aos1588"
    },
    {
        "id": 14358,
        "title": "A Hybrid CPU-GPU Scalable Strategy for Multi-resolution Rendering of Large Digital Elevation Models with Borders and Holes",
        "authors": "Andrey Rodrigues, Waldemar Celes",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006621902400247"
    },
    {
        "id": 14359,
        "title": "Language as a bridge to higher education: a large-scale empirical study of heritage language proficiency on language minority students’ academic success",
        "authors": "Eunjee Jang, Janina Brutt-Griffler",
        "published": "2019-4-21",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/01434632.2018.1518451"
    },
    {
        "id": 14360,
        "title": "Natural language generation from Universal Dependencies using data augmentation and pre-trained language models",
        "authors": "Dang Tuan Nguyen, Trung Tran",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijiids.2023.128292"
    },
    {
        "id": 14361,
        "title": "Beyond prompting: Making Pre-trained Language Models Better Zero-shot Learners by Clustering Representations",
        "authors": "Yu Fei, Zhao Meng, Ping Nie, Roger Wattenhofer, Mrinmaya Sachan",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.587"
    },
    {
        "id": 14362,
        "title": "Multilingual Language Models Predict Human Reading Behavior",
        "authors": "Nora Hollenstein, Federico Pirovano, Ce Zhang, Lena Jäger, Lisa Beinborn",
        "published": "2021",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.10"
    },
    {
        "id": 14363,
        "title": "Spanish language proficiency in dual language and English as a second language models: the impact of model, time, teacher, and student on Spanish language development",
        "authors": "Trish Morita-Mullaney, Jennifer Renn, Ming Ming Chiu",
        "published": "2022-11-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/13670050.2022.2089012"
    },
    {
        "id": 14364,
        "title": "Teachers’ Perceptions of Heritage Language Learners: A Large-scale Survey Study on Dialect Variation, Expectations, and Assessment Needs",
        "authors": "John Chi, Anne E. Donovan, Margaret E. Malone",
        "published": "2022-11-24",
        "citations": 0,
        "abstract": "Abstract\nMany case studies of heritage language learners (HLL s) have documented learners’ perceptions and experiences, including experiences of stigmatization in the classroom for use of a non-standard variation or for not meeting teachers’ expectations of an HLL. However, few have investigated teachers’ perceptions of their HLL s, and how these could address or illuminate documented negative learning experiences. The current study uses survey methodology to investigate language teachers’ language ideologies of heritage languages and perceptions of HLL s on a larger scale than previous efforts. The study is inclusive of teachers of different grade levels, types of classrooms, and, perhaps most importantly, different languages. By looking at a wide array of participants (N = 325), this study addresses the overarching question: How do language teachers perceive their HLL s in the classroom? The findings provide insight on teachers’ views of HLL s’ dialects, their expectations of learners, and the practical needs of teachers.",
        "link": "http://dx.doi.org/10.1163/15507076-bja10009"
    },
    {
        "id": 14365,
        "title": "Neural Japanese Zero Anaphora Resolution with Candidate Reduction Using Large-scale Case Frames",
        "authors": "Souta Yamashiro, Hitoshi Nishikawa, Takenobu Tokunaga",
        "published": "2019-6-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.26.509"
    },
    {
        "id": 14366,
        "title": "How well do NLI models capture verb veridicality?",
        "authors": "Alexis Ross, Ellie Pavlick",
        "published": "2019",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-1228"
    },
    {
        "id": 14367,
        "title": "Is Incoherence Surprising? Targeted Evaluation of Coherence Prediction from Language Models",
        "authors": "Anne Beyer, Sharid Loáiciga, David Schlangen",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.328"
    },
    {
        "id": 14368,
        "title": "DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models",
        "authors": "Xinwei Wu, Junzhuo Li, Minghui Xu, Weilong Dong, Shuangzhi Wu, Chao Bian, Deyi Xiong",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.174"
    },
    {
        "id": 14369,
        "title": "Comparative Analysis of Language Models for Linguistic Examination of Ancient Chinese Classics: A Case Study of Zuozhuan Corpus",
        "authors": "Yiqin Zhang, Sanhong Deng, Qi Zhang, Dongbo Wang, Hongcun Gong",
        "published": "2023-11-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ialp61005.2023.10337146"
    },
    {
        "id": 14370,
        "title": "AuGPT: Auxiliary Tasks and Data Augmentation for End-To-End Dialogue with Pre-Trained Language Models",
        "authors": "Jonáš Kulhánek, Vojtěch Hudeček, Tomáš Nekvinda, Ondřej Dušek",
        "published": "2021",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.nlp4convai-1.19"
    },
    {
        "id": 14371,
        "title": "Coordinate Structure Analysis using Local Models and CKY Algorithm",
        "authors": "Hiroki Teranishi, Hiroyuki Shindo, Taro Watanabe, Yuji Matsumoto",
        "published": "2020-12-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.27.719"
    },
    {
        "id": 14372,
        "title": "Models in Problem-Based Learning",
        "authors": "Loghman Ansarian, Mei Lin Teoh",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-13-0941-0_3"
    },
    {
        "id": 14373,
        "title": "SEA-LION (Southeast Asian Languages In One Network): A Family of Southeast Asian Language Models",
        "authors": "William Tjhi, David Ong, Peerat Limkonchotiwat",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.nlposs-1.26"
    },
    {
        "id": 14374,
        "title": "Assertion Detection in Clinical Notes: Medical Language Models to the Rescue?",
        "authors": "Betty van Aken, Ivana Trajanovska, Amy Siu, Manuel Mayrdorfer, Klemens Budde, Alexander Loeser",
        "published": "2021",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.nlpmc-1.5"
    },
    {
        "id": 14375,
        "title": "Gender Bias in Masked Language Models for Multiple Languages",
        "authors": "Masahiro Kaneko, Aizhan Imankulova, Danushka Bollegala, Naoaki Okazaki",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.197"
    },
    {
        "id": 14376,
        "title": "The impact of virtual exchange on TPACK and foreign language competence: reviewing a large-scale implementation across 23 virtual exchanges",
        "authors": "Bart Rienties, Tim Lewis, Robert O’Dowd, Irina Rets, Jekaterina Rogaten",
        "published": "2022-3-4",
        "citations": 31,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/09588221.2020.1737546"
    },
    {
        "id": 14377,
        "title": "A causal partition of trait correlations: using graphical models to derive statistical models from theoretical language",
        "authors": "James Patrick Cronin, Donald R. Schoolmaster",
        "published": "2018-9",
        "citations": 10,
        "abstract": "AbstractRecent studies hypothesize various causes of species‐level trait covariation, namely size (e.g., metabolic theory of ecology and leaf economics spectrum), pace‐of‐life (e.g., slow‐to‐fast continuum; lifestyle continuum), evolutionary history (e.g., phylogenetic conservatism), and ecological conditions (e.g., stabilizing selection). Various methods have been used in attempts to partition trait correlation among these influences (e.g., univariate analysis, principal components analysis, and factor analysis). However, it is not clear that the implied causal structure assumed by these methods matches the hypothesized causal structure driving trait correlations, a situation that can potentially lead to biased estimates and incorrect partitioning among mechanisms. Here, we propose the application of graphical causal models (GCM) for across‐kingdom synthesis and to aid researchers in their selection of correct analytical strategies. Graphical causal models use causal diagrams (i.e., box‐and‐arrow graphs) to represent expert knowledge of the data‐generating processes to analytically investigate the possibility of identifying hypothesized causal associations. We developed a causal diagram that synthesizes prominent hypotheses of trait covariation. Using the causal diagram, we (1) derived a quantitative expression to partition trait covariance among its hypothesized causal elements (i.e., size, pace‐of‐life, evolutionary history, and ecological conditions) and (2) developed analytic strategies to attribute trait covariance among the hypothesized causal elements under real‐world data availability, namely unobserved variables (i.e., pace‐of‐life) and confounding variables (i.e., evolutionary history and ecological conditions). Finally, we tested each analytic strategy by simulating trait datasets and, after incorporating the data limitations, tested their ability to correctly partition trait covariance. The analytical strategies were able to correctly partition trait covariance into the hypothesized causal elements of size, pace‐of‐life, and the historical effects of evolutionary history and ecological conditions. We demonstrate the efficacy of these strategies by applying them to a widely used trait dataset. Overall, the application of GCM revealed that researchers have used inappropriate measures to represent their theoretical constructs and have relied on analytical strategies that violated their causal assumptions, likely resulting in biased estimates. We discuss how this mismatch between theoretical language and statistical methods is prevalent in species‐level, trait‐based research and call for future studies to address these limitations.",
        "link": "http://dx.doi.org/10.1002/ecs2.2422"
    },
    {
        "id": 14378,
        "title": "Research on Teaching Activities of Large Class Kindergartens Based on Lifestyle",
        "authors": "",
        "published": "2021-5-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/es.v2i5.41"
    },
    {
        "id": 14379,
        "title": "7. Discussion and Conclusions: Implementing DLBE to Serve Emerging Bilinguals",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781788928106-008"
    },
    {
        "id": 14380,
        "title": "Large Scale Speech Recognition for Low Resource Language Amharic, an End-to-End Approach",
        "authors": "Yohannes Ayana Ejigu, Tesfa Tegegne Asfaw",
        "published": "No Date",
        "citations": 0,
        "abstract": "Speech recognition, or automatic speech recognition (ASR), is a technology designed to convert spoken language into text using software. However, conventional ASR methods involve several distinct components, including language, acoustic, and pronunciation models with dictionaries. This modular approach can be time-consuming and may influence performance. In this study, we propose a method that streamlines the speech recognition process by incorporating a unified recurrent neural network (RNN) architecture. Our architecture integrates a convolutional neural network (CNN) with an RNN and employs a connectionist temporal classification (CTC) loss function.\nKey experiments were carried out using a dataset comprising 576,656 valid sentences, using erosion techniques. Evaluation of the model performance, measured by the word error rate (WER) metric, demonstrated remarkable results, achieving a WER of 2%. This approach has significant implications for the realm of speech recognition, as it alleviates the need for labor-intensive dictionary creation, enhancing the efficiency and accuracy of ASR systems, and making them more applicable to real-world scenarios.\nFor future enhancements, we recommend the inclusion of dialectal and spontaneous data in the dataset to broaden the model&#039;s adaptability. Additionally, fine-tuning the model for specific tasks can optimize its performance for targeted objectives or domains, further enhancing its effectiveness in those areas.",
        "link": "http://dx.doi.org/10.20944/preprints202402.0813.v1"
    },
    {
        "id": 14381,
        "title": "Large Scale Wind Power Consumption Model of Power Grid Based on Hydrogen Energy Economy",
        "authors": "",
        "published": "2021-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i10.50"
    },
    {
        "id": 14382,
        "title": "The Impact of Unexpected Large Passenger Flows on Urban Rail Transit Stations and Countermeasures",
        "authors": "",
        "published": "2022-3-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i3(06).13"
    },
    {
        "id": 14383,
        "title": "The Question of Metaphor in Natural Language: A Case Study",
        "authors": "",
        "published": "2017-3-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781315224107-11"
    },
    {
        "id": 14384,
        "title": "Finite Element Analysis and Research on the Structure of Large-Span Wellbore Underground Parking",
        "authors": "",
        "published": "2020-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v1i2.44"
    },
    {
        "id": 14385,
        "title": "An Improved Transformer-based Model for Detecting Phishing, Spam, and Ham: A Large Language Model Approach",
        "authors": "Suhaima Jamal, Hayden Wimmer, Iqbal Sarker",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nPhishing and spam detection is a long standing challenge that has been the subject of much academic research. Large Language Models (LLM) have vast potential to transform society and provide new and innovative approaches to solve well-established challenges. Phishing and spam have caused financial hardships and lost time and resources to email users all over the world and frequently serve as an entry point for ransomware threat actors. While detection approaches exist, especially heuristic-based approaches, LLMs offer the potential to venture into a new unexplored area for understanding and solving this challenge. LLMs have rapidly altered the landscape from business, consumers, and throughout academia and demonstrate transformational potential for the potential of society. Based on this, applying these new and innovative approaches to email detection is a rational next step in academic research. In this work, we present IPSDM, an improved phishing spam detection model based on fine-tuning the BERT family of models to specifically detect phishing and spam email. We demonstrate our fine-tuned version, IPSDM, is able to better classify emails in both unbalanced and balanced datasets.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3608294/v1"
    },
    {
        "id": 14386,
        "title": "Large language model is a flagship for Japan",
        "authors": "Shotaro Kinoshita, Hiromi Yokoyama",
        "published": "2023-7-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/d41586-023-02230-3"
    },
    {
        "id": 14387,
        "title": "Noetic end-to-end response selection with supervised neural network based classifiers and unsupervised similarity models",
        "authors": "Paweł Skórzewski, Weronika Sieińska, Marek Kubis",
        "published": "2020-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2020.101074"
    },
    {
        "id": 14388,
        "title": "Hybrid Natural Language Processing: An Introduction",
        "authors": "Jose Manuel Gomez-Perez, Ronald Denaux, Andres Garcia-Silva",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-44830-1_1"
    },
    {
        "id": 14389,
        "title": "PAC-tuning: Fine-tuning Pre-trained Language Models with PAC-driven Perturbed Gradient Descent",
        "authors": "Guangliang Liu, Zhiyu Xue, Xitong Zhang, Kristen Johnson, Rongrong Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.748"
    },
    {
        "id": 14390,
        "title": "Zero-shot Sharpness-Aware Quantization for Pre-trained Language Models",
        "authors": "Miaoxi Zhu, Qihuang Zhong, Li Shen, Liang Ding, Juhua Liu, Bo Du, Dacheng Tao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.696"
    },
    {
        "id": 14391,
        "title": "Compressing and Debiasing Vision-Language Pre-Trained Models for Visual Question Answering",
        "authors": "Qingyi Si, Yuanxin Liu, Zheng Lin, Peng Fu, Yanan Cao, Weiping Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.34"
    },
    {
        "id": 14392,
        "title": "Pre-training Language Models with Deterministic Factual Knowledge",
        "authors": "Shaobo Li, Xiaoguang Li, Lifeng Shang, Chengjie Sun, Bingquan Liu, Zhenzhou Ji, Xin Jiang, Qun Liu",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.764"
    },
    {
        "id": 14393,
        "title": "Fully automatic summarization of radiology reports using natural language processing with language models",
        "authors": "Mizuho Nishio, Takaaki Matsunaga, Hidetoshi Matsuo, Munenobu Nogami, Yasuhisa Kurata, Koji Fujimoto, Osamu Sugiyama, Toshiaki Akashi, Shigeki Aoki, Takamichi Murakami",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractNatural language processing using language models has yielded promising results in various fields. The use of language models may help improve the workflow of radiologists. This retrospective study aimed to construct and evaluate language models for the automatic summarization of radiology reports. Two datasets of radiology reports were used: MIMIC-CXR and the Japan Medical Image Database (JMID). MIMIC-CXR is an open dataset comprising chest radiograph reports. JMID is a large dataset of CT and MRI reports comprising reports from 10 academic medical centers in Japan. A total of 128,032 and 1,101,271 reports from the MIMIC-CXR and JMID, respectively, were included in this study. Four Text-to-Text Transfer Transformer (T5) models were constructed. Recall-Oriented Understudy for Gisting Evaluation (ROUGE), a quantitative metric, was used to evaluate the quality of text summarized from 19,205 and 58,043 test sets from MIMIC-CXR and JMID, respectively. The Wilcoxon signed-rank test was utilized to evaluate the differences among the ROUGE values of the four T5 models. In addition, subsets of automatically summarized text in the test sets were manually evaluated by two radiologists. Based on the Wilcoxon signed-rank test, the best T5 models were selected for the automatic summarization. The quantitative metrics of the best T5 models were as follows: ROUGE-1 = 57.75 ± 30.99, ROUGE-2 = 49.96 ± 35.36, and ROUGE-L = 54.07 ± 32.48 in MIMIC-CXR; ROUGE-1 = 50.00 ± 29.24, ROUGE-2 = 39.66 ± 30.21, and ROUGE-L = 47.87 ± 29.44 in JMID. The radiologists’ evaluations revealed that 86% (86/100) and 85% (85/100) of the texts automatically summarized from MIMIC-CXR and JMID, respectively, were clinically useful. The T5 models constructed in this study were capable of automatic summarization of radiology reports. The radiologists’ evaluations revealed that most of the automatically summarized texts were clinically valuable.",
        "link": "http://dx.doi.org/10.1101/2023.12.01.23299267"
    },
    {
        "id": 14394,
        "title": "Birds have four legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-Trained Language Models",
        "authors": "Bill Yuchen Lin, Seyeon Lee, Rahul Khanna, Xiang Ren",
        "published": "2020",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.557"
    },
    {
        "id": 14395,
        "title": "Introduction",
        "authors": "Lina M. Reznicek-Parrado",
        "published": "2023-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003191179-1"
    },
    {
        "id": 14396,
        "title": "Character aware models with similarity learning for metaphor detection",
        "authors": "Tarun Kumar, Yashvardhan Sharma",
        "published": "2020",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.figlang-1.18"
    },
    {
        "id": 14397,
        "title": "Discussion on Risk Management Models of Production Planning in Nuclear Power Plants",
        "authors": "",
        "published": "2021-5-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/em.v2i5.01"
    },
    {
        "id": 14398,
        "title": "The Eucharist and Nature",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.7"
    },
    {
        "id": 14399,
        "title": "AMS Processes",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.ch10"
    },
    {
        "id": 14400,
        "title": "Index",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.12"
    },
    {
        "id": 14401,
        "title": "What are the Future Trends in Natural Gas Technology to Address Climate Change? Patent Analysis Through Large Language Model",
        "authors": "Mingyu Kim, Juyong Lee",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4690275"
    },
    {
        "id": 14402,
        "title": "Natural Language Processing for Computer Scientists and Data Scientists at a Large State University",
        "authors": "Casey Kennington",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.teachingnlp-1.21"
    },
    {
        "id": 14403,
        "title": "Building theories of consistency and variability in children’s language development: A large-scale data approach",
        "authors": "Angeline Tsui, Virginia A. Marchman, Michael C. Frank",
        "published": "No Date",
        "citations": 1,
        "abstract": "Young children typically begin learning words during their first two years of life. On the other hand, they also vary substantially in their language learning. Similarities and differences in language learning call for a quantitative theory that can predict and explain which aspects of early language are consistent and which are variable. However, current developmental research practices limit our ability to build such quantitative theories because of small sample sizes and challenges related to reproducibility and replicability. In this chapter, we suggest that three approaches – meta-analysis, multi-site collaborations, and secondary data aggregation – can together address some of the limitations of current research in the developmental area. We review the strengths and limitations of each approach and end by discussing the potential impacts of combining these three approaches.",
        "link": "http://dx.doi.org/10.31234/osf.io/z7yrx"
    },
    {
        "id": 14404,
        "title": "Brief Discussion on Some Problems in Fire Water Supply Design of Large Urban Complex",
        "authors": "",
        "published": "2022-8-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i8(07).11"
    },
    {
        "id": 14405,
        "title": "Discussion on Depreciation of Fixed Assets of Large and Medium-sized Reservoir Management Units",
        "authors": "",
        "published": "2022-8-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/em.v3i8(01).03"
    },
    {
        "id": 14406,
        "title": "Research on Anchor Construction Technology of Large-span Suspension Bridge and Super-inclined Tunne",
        "authors": "",
        "published": "2022-5-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i5(01).04"
    },
    {
        "id": 14407,
        "title": "Schema-Based Priming of Large Language Model for Data Object Validation Compliance",
        "authors": "Jo Inge Arnes, Alexander Horsch",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4453361"
    },
    {
        "id": 14408,
        "title": "Enhancing Natural Language Representation with Large-Scale Out-of-Domain Commonsense",
        "authors": "Wanyun Cui, Xingran Chen",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-acl.138"
    },
    {
        "id": 14409,
        "title": "Introduction",
        "authors": "Lina M. Reznicek-Parrado",
        "published": "2023-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003191179-1"
    },
    {
        "id": 14410,
        "title": "Character aware models with similarity learning for metaphor detection",
        "authors": "Tarun Kumar, Yashvardhan Sharma",
        "published": "2020",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.figlang-1.18"
    },
    {
        "id": 14411,
        "title": "Discussion on Risk Management Models of Production Planning in Nuclear Power Plants",
        "authors": "",
        "published": "2021-5-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/em.v2i5.01"
    },
    {
        "id": 14412,
        "title": "The Eucharist and Nature",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.7"
    },
    {
        "id": 14413,
        "title": "AMS Processes",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.ch10"
    },
    {
        "id": 14414,
        "title": "Index",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.12"
    },
    {
        "id": 14415,
        "title": "Comparative Evaluation of Fine-Tuned and Standard Language Models in Emulating Living Historical Figures: A Detailed Study Proposal",
        "authors": "Daniel S Goldman",
        "published": "No Date",
        "citations": 0,
        "abstract": "The contemporary growth spurt in artificial intelligence has engendered an opportunity to explore evermore complex applications of language models. This research proposal outlines an in-depth comparative study aimed at investigating the proficiency of fine-tuned language models against standard general-purpose transformer (GPT) models. Specifically, we aim to emulate dialogues characteristic of selected, living historical figures. With a primary focus on accuracy, authenticity, and reliability, we propose an innovative \"biographimetric\" approach that correlates psychometric properties of AI-generated responses with biographical data. This study anticipates not only shedding light on the comparative potential of customized and standard language models but also developing a comprehensive evaluation matrix for such models. Furthermore, we aim to touch upon the array of practical applications, ethical issues, and potential impacts on various domains, including archival studies, AI ethics, and sectors such as education and entertainment. Ultimately, our research could contribute significantly to understanding the boundaries and possibilities of AI language models in capturing and replicating unique human thought processes.",
        "link": "http://dx.doi.org/10.31235/osf.io/q7xad"
    },
    {
        "id": 14416,
        "title": "PromptSMILES: Prompting for scaffold decoration and fragment linking in chemical language models",
        "authors": "Morgan Thomas, Mazen Ahmad, Gary Tresadern, Gianni de Fabritiis",
        "published": "No Date",
        "citations": 0,
        "abstract": "SMILES-based generative models are amongst the most robust and successful recent methods used to augment drug design. They are typically used for complete de novo generation, however, scaffold decoration and fragment linking applications are sometimes desirable which requires a different architecture, a different training dataset and therefore, re-training of a new model. In this work, we describe a simple procedure to conduct constrained molecule generation with a SMILES-based generative model to extend applicability to scaffold decoration and fragment linking by providing SMILES prompts, without the need for re-training. In combination with reinforcement learning, we show that pre-trained, decoder-only models adapt to these applications quickly and can further optimize molecule generation towards a specified objective. We compare the performance of this approach to a variety of orthogonal approaches and show that performance is comparable or better. This approach enables the unification of de novo generation, scaffold decoration, and fragment linking into one chemical language model, without the need to use a bespoke grammar, curate a custom dataset or train a separate model. For convenience, we provide an easy-to-use python package to facilitate model sampling which can be found on GitHub and the Python Package Index.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2024-z5jnt"
    },
    {
        "id": 14417,
        "title": "Natural language generation from Universal Dependencies using data augmentation and pre-trained language models",
        "authors": "Trung Tran, Dang Tuan Nguyen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijiids.2023.10053426"
    },
    {
        "id": 14418,
        "title": "Hierarchical Sub-sentential Alignment with IBM Models for Statistical Phrase-based Machine Translation",
        "authors": "Hao Wang, Yves Lepage",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.24.619"
    },
    {
        "id": 14419,
        "title": "Optimization of paraphrase generation and identification using language models in natural language processing",
        "authors": "Hemant Palivela",
        "published": "2021-11",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jjimei.2021.100025"
    },
    {
        "id": 14420,
        "title": "Sequence-to-Sequence Models for Data-to-Text Natural Language Generation: Word- vs. Character-based Processing and Output Diversity",
        "authors": "Glorianna Jagfeld, Sabrina Jenne, Ngoc Thang Vu",
        "published": "2018",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-6529"
    },
    {
        "id": 14421,
        "title": "Grading for Growth: Introducing New Assessment Approaches in Traditional Grading Models",
        "authors": "Beth A. Walsh-Moorman, Katie Ours, Aubrey Deaton, Maura McGinty-O'Hara",
        "published": "2020-5-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.9707/2168-149x.2200"
    },
    {
        "id": 14422,
        "title": "Issue report classification using pre-trained language models",
        "authors": "Giuseppe Colavito, Filippo Lanubile, Nicole Novielli",
        "published": "2022-5-21",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3528588.3528659"
    },
    {
        "id": 14423,
        "title": "Commonsense Knowledge Mining from Pretrained Models",
        "authors": "Joe Davison, Joshua Feldman, Alexander Rush",
        "published": "2019",
        "citations": 49,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-1109"
    },
    {
        "id": 14424,
        "title": "Study on the Applicability of URANS, Large Eddy Simulations, and Hybrid Large Eddy Simulations/RANS Models for Prediction of Hydrodynamics of Cyclone Separator",
        "authors": "Sai Guruprasad Jakkala, S. Vengadesan",
        "published": "2022-3-1",
        "citations": 2,
        "abstract": "Abstract\nCyclone separators are an integral part of many industrial processes. A good understanding of the flow features is paramount to efficiently use them. The turbulent fluid flow characteristics are modeled using unsteady Reynolds-averaged Navier–Stokes (URANS), large eddy simulations (LES), and hybrid LES/Reynolds–averaged Navier–Stokes (RANS) turbulent models. The hybrid LES/RANS approaches, namely, detached eddy simulation (DES), delayed detached eddy simulation (DDES), and improved delayed detached eddy simulation (IDDES) based on the k−ω SST RANS approaches are explored. The study is carried out for three different inlet velocities (v = 8, 16.1, and 32 m/s). The results from hybrid LES/RANS models are shown to be in good agreement with the experimental data available in the literature. Reduction in computational time and mesh size are the two main benefits of using hybrid LES/RANS models over the traditional LES methods. The Reynolds stresses are observed in order to understand the redistribution of turbulent energy in the flow field. The velocity profiles and vorticity quantities are explored to obtain a better understanding of the behavior of fluid flow in cyclone separators.",
        "link": "http://dx.doi.org/10.1115/1.4052050"
    },
    {
        "id": 14425,
        "title": "Gradient Models of Geological Medium to Safety of Large-Scale Fuel-Energy Systems",
        "authors": "Tatyana Alexandrovna Smaglichenko, Nadezhda Vasilievna Sokolova, Alexander Vadimovich Smaglichenko, Arkady Lvovich Genkin, Maria Kontantinovna Sayankina",
        "published": "2019-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2019.8911061"
    },
    {
        "id": 14426,
        "title": "CascadeBERT: Accelerating Inference of Pre-trained Language Models via Calibrated Complete Models Cascade",
        "authors": "Lei Li, Yankai Lin, Deli Chen, Shuhuai Ren, Peng Li, Jie Zhou, Xu Sun",
        "published": "2021",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-emnlp.43"
    },
    {
        "id": 14427,
        "title": "Power, Society, and Identity",
        "authors": "Holly Hoover",
        "published": "2019-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678-11"
    },
    {
        "id": 14428,
        "title": "You are What You Write: Preserving Privacy in the Era of Pre-Trained Language Models",
        "authors": "Richard Plant, Valerio Giuffrida, Dimitra Gkatzia",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4417900"
    },
    {
        "id": 14429,
        "title": "Image and text correction using language models",
        "authors": "Ido Kissos, Nachum Dershowitz",
        "published": "2017-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/asar.2017.8067779"
    },
    {
        "id": 14430,
        "title": "Geographic and Geopolitical Biases of Language Models",
        "authors": "Fahim Faisal, Antonios Anastasopoulos",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.mrl-1.12"
    },
    {
        "id": 14431,
        "title": "Improving Keyword Search in Sign Language using Similarity Models",
        "authors": "Mansur Yesilbursa, Murat Saraclar",
        "published": "2022-5-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/siu55565.2022.9864859"
    },
    {
        "id": 14432,
        "title": "Probabilistic Preliminaries",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.ch2"
    },
    {
        "id": 14433,
        "title": "Guiding Ideas",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.ch1"
    },
    {
        "id": 14434,
        "title": "Reverse Transfer Learning: Can Word Embeddings Trained for Different NLP Tasks Improve Neural Language Models?",
        "authors": "Lyan Verwimp, Jerome R. Bellegarda",
        "published": "2019-9-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2019-1332"
    },
    {
        "id": 14435,
        "title": "Natural Language Processing Models: A Comparative Perspective",
        "authors": "Bianchi S Sangma, Vandana Sharma",
        "published": "2023-7-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icecaa58104.2023.10212389"
    },
    {
        "id": 14436,
        "title": "Do You Speak Basquenglish? Assessing Low-Resource Multilingual Proficiency of Pretrained Language Models",
        "authors": "Iñigo Parra",
        "published": "2023-11-25",
        "citations": 0,
        "abstract": "Multilingual language models’ have democratized access to information and artificial intelligence (AI). Still, low-resource languages (LRL) remain underrepresented. This study compares the performance of GPT-4, LlaMa (7B), and PaLM 2 when asked to reproduce English-Basque code-switched outputs. The study uses code-switching as a test to argue for the multilingual capabilities of each model and compares and studies their cross-lingual understanding. All models were tested using 84 prompts (N = 252), with their responses subjected to qualitative and quantitative analysis. This study compares the naturalness of the outputs, code-switching competence (CSness), and the frequency of hallucinations. Results of pairwise comparisons show statistically significant differences in naturalness and the ability to produce grammatical code- switched output across models. This study underscores the critical role of linguistic representation in large language models (LLMs) and the necessity for improvement in handling LRLs.",
        "link": "http://dx.doi.org/10.5121/csit.2023.132215"
    },
    {
        "id": 14437,
        "title": "Polysemy—Evidence from Linguistics, Behavioral Science, and Contextualized Language Models",
        "authors": "Janosch Haber, Massimo Poesio",
        "published": "2024-2-27",
        "citations": 1,
        "abstract": "Abstract\nPolysemy is the type of lexical ambiguity where a word has multiple distinct but related interpretations. In the past decade, it has been the subject of a great many studies across multiple disciplines including linguistics, psychology, neuroscience, and computational linguistics, which have made it increasingly clear that the complexity of polysemy precludes simple, universal answers, especially concerning the representation and processing of polysemous words. But fuelled by the growing availability of large, crowdsourced datasets providing substantial empirical evidence; improved behavioral methodology; and the development of contextualized language models capable of encoding the fine-grained meaning of a word within a given context, the literature on polysemy recently has developed more complex theoretical analyses.\nIn this survey we discuss these recent contributions to the investigation of polysemy against the backdrop of a long legacy of research across multiple decades and disciplines. Our aim is to bring together different perspectives to achieve a more complete picture of the heterogeneity and complexity of the phenomenon of polysemy. Specifically, we highlight evidence supporting a range of hybrid models of the mental processing of polysemes. These hybrid models combine elements from different previous theoretical approaches to explain patterns and idiosyncrasies in the processing of polysemous that the best known models so far have failed to account for. Our literature review finds that (i) traditional analyses of polysemy can be limited in their generalizability by loose definitions and selective materials; (ii) linguistic tests provide useful evidence on individual cases, but fail to capture the full range of factors involved in the processing of polysemous sense extensions; and (iii) recent behavioral (psycho) linguistics studies, large-scale annotation efforts, and investigations leveraging contextualized language models provide accumulating evidence suggesting that polysemous sense similarity covers a wide spectrum between identity of sense and homonymy-like unrelatedness of meaning.\nWe hope that the interdisciplinary account of polysemy provided in this survey inspires further fundamental research on the nature of polysemy and better equips applied research to deal with the complexity surrounding the phenomenon, for example, by enabling the development of benchmarks and testing paradigms for large language models informed by a greater portion of the rich evidence on the phenomenon currently available.",
        "link": "http://dx.doi.org/10.1162/coli_a_00500"
    },
    {
        "id": 14438,
        "title": "Exploring Techniques to Detect and Mitigate Non-Inclusive Language Bias in Marketing Communications using a Dictionary-Based Approach",
        "authors": "Bharathi Raja Chakravarthi,  , Prasanna Kumar Kumaresan, Rahul Ponnusamy, John P McCrae, Michaela Comerford, Jay Megaro, Deniz Keles, Last Feremenga,  ,  ,  ,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-092-2_099"
    },
    {
        "id": 14439,
        "title": "Decoding the Encoded – Linguistic Secrets of Language Models: A Systematic Literature Review",
        "authors": "H Avetisyan, D Broneske",
        "published": "2023-9-16",
        "citations": 0,
        "abstract": "Language models’ growing role in natural language processing neces- sitates a deeper understanding of their linguistic knowledge. Linguistic probing tasks have become crucial for model explainability, designed to evaluate models’ understanding of vari-ous linguistic phenomena. Objective: This systematic review critically assesses the linguistic knowledge of language models via linguistic probing, providing a comprehensive overview ofthe understood linguistic phenomena and identifying future research areas. Method: We performed an extensive search of relevant academic databases and analyzed 57 articles pub- lished between October 2018 and October 2022. Results: While language models exhibit extensive linguistic knowledge, limitations persist in their comprehension of specific phe- nomena. The review also points to a need for consensus on evaluating language models’ linguistic knowledge and the linguistic terminology used. Conclusion: Our review offers an extensive look into linguistic knowledge of language models through linguistic probing tasks. This study underscores the importance of understanding these models’ linguistic capabilities for effective use in NLP applications and for fostering more explainable AI systems.",
        "link": "http://dx.doi.org/10.5121/csit.2023.131606"
    },
    {
        "id": 14440,
        "title": "Probing Multilingual Language Models for Discourse",
        "authors": "Murathan Kurfalı, Robert Östling",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.repl4nlp-1.2"
    },
    {
        "id": 14441,
        "title": "Using Language Differences to Detect Cyberattacks",
        "authors": "Wayne Patterson",
        "published": "2023-8-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003415060-16"
    },
    {
        "id": 14442,
        "title": "Integrating Natural Language Specifications and Cad Models: An Approach for Requirements Engineering and Chaining",
        "authors": "Josip Stjepandic, Alain-Jerome Fougeres, Egon Ostrosi",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4559688"
    },
    {
        "id": 14443,
        "title": "Rituals, Symbols, and Interpretations",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.9"
    },
    {
        "id": 14444,
        "title": "Spelling convention sensitivity in neural language models",
        "authors": "Elizabeth Nielsen, Christo Kirov, Brian Roark",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-eacl.98"
    },
    {
        "id": 14445,
        "title": "SYNTHESIS OF KNOWLEDGE TRACING MODELS USING NATURAL LANGUAGE PROCESSING ON LECTURE CONTENT",
        "authors": "Robin Nicolay, Alke Martens",
        "published": "2020-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21125/edulearn.2020.0539"
    },
    {
        "id": 14446,
        "title": "Patterns of Polysemy and Homonymy in Contextualised Language Models",
        "authors": "Janosch Haber, Massimo Poesio",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-emnlp.226"
    },
    {
        "id": 14447,
        "title": "Neural language models for automatic speech Recognition",
        "authors": "V. Y. Chuchupal",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.58633/2305-8129_2020_1-2_27"
    },
    {
        "id": 14448,
        "title": "Predicting polymerization reactions via transfer learning using chemical language models",
        "authors": "Ronaldo Giro, Brenda Ferrari, Matteo Manica, Teodoro Laino, Mathias Steiner",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nPolymers are candidate materials for a wide range of sustainability applications such as carbon capture and energy storage. However, computational polymer discovery lacks automated analysis of reaction pathways and stability assessment through retro-synthesis. Here, we report the first extension of transformer-based language models to polymerization reactions for both forward and retrosynthesis tasks. To that end, we have curated a  polymerization dataset for vinyl polymers covering reactions and retrosynthesis for representative homo-polymers and co-polymers. Overall, we obtain a forward model Top-4 accuracy of 80\\% and a backward model Top-4 accuracy of 60\\%. We further analyze the model performance with representative polymerization and retro-synthesis examples and evaluate its prediction quality from a materials science perspective.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3470273/v1"
    },
    {
        "id": 14449,
        "title": "EFL Professional Development: Discussion of Effective Models in Literature",
        "authors": "Anas Almuhammadi",
        "published": "2017-5-25",
        "citations": 3,
        "abstract": "This paper explores the professional development literature in the educational setting. The different literature pieces are aligned to a framework that requires effective professional development to focus on three concepts: content, context, and process. The content focuses on the “what” question in the programs while the context aims to align the content with “where” question. The third component is the focus on the process variables that professional development should follow. This paper tries to add to the English as a Foreign Language (EFL) and English as a Second Language (ESL) fields’ literature by presenting categorized overview of relevant works. The different theories include adult learning theory, functional theory, multiple intelligences, twenty-one learning styles, the Australian Government Quality Teaching Program (AGQTP) model and model of teacher change.",
        "link": "http://dx.doi.org/10.5539/elt.v10n6p118"
    },
    {
        "id": 14450,
        "title": "AutoKG: Efficient Automated Knowledge Graph Generation for Language Models",
        "authors": "Bohan Chen, Andrea L. Bertozzi",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386454"
    },
    {
        "id": 14451,
        "title": "Open-source language AI challenges big tech’s models",
        "authors": "Elizabeth Gibney",
        "published": "2022-6-30",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/d41586-022-01705-z"
    },
    {
        "id": 14452,
        "title": "AMP-Diffusion: Integrating Latent Diffusion with Protein Language Models for Antimicrobial Peptide Generation",
        "authors": "Tianlai Chen, Pranay Vure, Rishab Pulugurta, Pranam Chatterjee",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractDenoising Diffusion Probabilistic Models (DDPMs) have emerged as a potent class of generative models, demonstrating exemplary performance across diverse AI domains such as computer vision and natural language processing. In the realm of protein design, while there have been advances in structure-based, graph-based, and discrete sequence-based diffusion, the exploration of continuous latent space diffusion within protein language models (pLMs) remains nascent. In this work, we introduce AMP-Diffusion, a latent space diffusion model tailored for antimicrobial peptide (AMP) design, harnessing the capabilities of the state-of-the-art pLM, ESM-2, tode novogenerate functional AMPs for downstream experimental application. Our evaluations reveal that peptides generated by AMP-Diffusion align closely in both pseudo-perplexity and amino acid diversity when benchmarked against experimentally-validated AMPs, and further exhibit relevant physicochemical properties similar to these naturally-occurring sequences. Overall, these findings underscore the biological plausibility of our generated sequences and pave the way for their empirical validation. In total, our framework motivates future exploration of pLM-based diffusion models for peptide and protein design.",
        "link": "http://dx.doi.org/10.1101/2024.03.03.583201"
    },
    {
        "id": 14453,
        "title": "Sensitive remote homology search by local alignment of small positional embeddings from protein language models",
        "authors": "Sean R. Johnson, Meghana Peshwa, Zhiyi Sun",
        "published": "No Date",
        "citations": 0,
        "abstract": "Accurately detecting distant evolutionary relationships between proteins remains an ongoing challenge in bioinformatics. Search methods based on primary sequence struggle to accurately detect homology between sequences with less than 20% amino acid identity. Profile- and structure-based strategies extend sensitive search capabilities into this twilight zone of sequence similarity but require slow pre-processing steps. Recently, whole-protein and positional embeddings from deep neural networks have shown promise for providing sensitive sequence comparison and annotation at long evolutionary distances. Embeddings are generally faster to compute than profiles and predicted structures but still suffer several drawbacks related to the ability of whole-protein embeddings to discriminate domain-level homology, and the database size and search speed of methods using positional embeddings. In this work, we show that low-dimensionality positional embeddings can be used directly in speed-optimized local search algorithms. As a proof of concept, we use the ESM2 3B model to convert primary sequences directly into the 3Di alphabet or amino acid profiles and use these embeddings as input to the highly optimized Foldseek, HMMER3, and HH-suite search algorithms. Our results suggest that positional embeddings as small as a single byte can provide sufficient information for dramatically improved sensitivity over amino acid sequence searches without sacrificing search speed.",
        "link": "http://dx.doi.org/10.7554/elife.91415.2"
    },
    {
        "id": 14454,
        "title": "Generating novel protein sequences using Gibbs sampling of masked language models",
        "authors": "Sean R. Johnson, Sarah Monaco, Kenneth Massie, Zaid Syed",
        "published": "No Date",
        "citations": 7,
        "abstract": "AbstractRecently developed language models (LMs) based on deep neural networks have demonstrated the ability to generate fluent natural language text. LMs pre-trained on protein sequences have shown state of the art performance on a variety of downstream tasks. Protein LMs have also been used to generate novel protein sequences. In the present work we use Gibbs sampling of BERT-style LMs, pre-trained on protein sequences using the masked language modeling task, to generate novel protein sequences. We evaluate the quality of the generated sequences by comparing them to natural sequences from the same family. In particular, we focus on proteins from the chorismate mutase type II family, which has been used in previous work as an example target for protein generative models. We find that the Gibbs sampling process on BERT-style models pretrained on millions to billions of protein sequences is able to generate novel sequences that retain key features of related natural sequences. Further, we find that smaller models fine-tuned or trained from scratch on family-specific data are able to equal or surpass the generation quality of large pre-trained models by some metrics. The ability to generate novel natural-like protein sequences could contribute to the development of improved protein therapeutics and protein-catalysts for industrial chemical production.",
        "link": "http://dx.doi.org/10.1101/2021.01.26.428322"
    },
    {
        "id": 14455,
        "title": "Hp Positive Diffuse Large B-cell Lymphoma: A Case Report and Literature Review",
        "authors": "",
        "published": "2022-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/mh.v3i6(02).27"
    },
    {
        "id": 14456,
        "title": "Analysis on Construction Technology of Wear-resistant Concrete Floor for Large-scale Factory Building",
        "authors": "",
        "published": "2022-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i2.353"
    },
    {
        "id": 14457,
        "title": "Tool Wear Analysis of Large Diameter Mud Shield in Clay and Silty Clay Stratum",
        "authors": "",
        "published": "2021-9-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i9.247"
    },
    {
        "id": 14458,
        "title": "A large quantitative analysis of written language challenges the idea that all languages are equally complex",
        "authors": "Alexander Koplenig, Sascha Wolfer, Peter Meyer",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nOne of the fundamental questions about human language is whether all languages are equally complex. Here, we approach this question from an information-theoretic perspective. We present a large scale quantitative cross-linguistic analysis of written language by training a language model on more than 6,500 different documents as represented in 41 multilingual text collections consisting of ~3.5 billion words or ~9.0 billion characters and covering 2,069 different languages that are spoken as a native language by more than 90% of the world population. We statistically infer the entropy of each language model as an index of what we call average prediction complexity. We compare complexity rankings across corpora and show that a language that tends to be more complex than another language in one corpus also tends to be more complex in another corpus. In addition, we show that speaker population size predicts entropy. We argue that both results constitute evidence against the equi-complexity hypothesis from an information-theoretic perspective.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1462001/v3"
    },
    {
        "id": 14459,
        "title": "A large-scale longitudinal study of syntactic complexity development in EFL writing: A mixed-effects model approach",
        "authors": "Lei Lei, Ju Wen, Xiaohu Yang",
        "published": "2023-3",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jslw.2022.100962"
    },
    {
        "id": 14460,
        "title": "Acceptability and Effectiveness Analysis of Large Language Model-Based Artificial Intelligence Chatbot Among Arabic Learners",
        "authors": " Nely Rahmawati Zaimah,  Eko Budi Hartanto,  Fatchiatu Zahro",
        "published": "2023-12-5",
        "citations": 1,
        "abstract": "This research stems from the broad use of AI based on Large Language Models (LLMs), which many academics find relevant and effective in higher education Arabic language learning. The goal is to confirm these views.This research is a mixed reseach that employs a both of qualitative and quantitative methodologies. The qualitative segment involves observations and literature reviews. Observations involved reviewing how participants used chatbots and carefully checking the accuracy and consistency of platform responses. The quantitative facet utilizes a paired experimental design, encompassing both classical and Bayesian Paired Sample t-Tests analysis. The research encompasses 45 individuals with a proficient understanding of Modern Standard Arabic and no hindrances in comprehending the material. These individuals are enrolled as students at Islamic College (STAI) Al-Anwar Rembang, Indonesia. The results show increased motivation and ease of use with the chatbot in Arabic language learning. However, concerns about the consistency of chatbot content have arisen, affecting participants' confidence in response accuracy of AI. This prompts an evaluation of effectiveness through classical and Bayesian tests, which fail to demonstrate statistically significant variances, even in the adaptive Bayesian probability analysis. These outcomes deviate from previous research on relevance and effectiveness and corroborate preceding studies on academic apprehensions and accuracy enhancements. The researchers advocate for further investigations, especially concerning the accuracy analysis of AI chatbots in Arabic pedagogical contexts.",
        "link": "http://dx.doi.org/10.25217/mantiqutayr.v4i1.3951"
    },
    {
        "id": 14461,
        "title": "Improving Endangered Language Archives: A Comparison Study of Models in Use",
        "authors": "Victoria Jesswein",
        "published": "2020-11-10",
        "citations": 0,
        "abstract": "Endangered language archives hold important resources of information for students, researchers, and the speech community. However, because their use is often limited to small documentary projects, often these repositories fail to reach all potential researchers, to connect their material to other repositories in the community and throughout the world, and to be involved in a larger body of research on endangered languages and cultures. This research explores ways of expanding the accessibility, usability, and relevance of (endangered) language archives, with the aim of allowing a larger body of researchers to access materials while supporting the endangered speech community from which the material originates. Different models of linguistic archive practice are compared, each serving as an example of an area for potential archive growth and outreach: (1) the use of the language archive by a larger body of linguistic and non-linguistic researchers, (2) engagement with the speech community for heritage preservation and community-based archives, and (3) outreach to inform the general public. The models are analysed with regard to their rationale and procedures supported by relevant literature concerning best practice in the structure and use of archives. Following the analysis of compared models, recommendations are made to implement best practice for endangered language collections, envisioning the broadest and most accessible presentation of material for resource discovery, use, and preservation.",
        "link": "http://dx.doi.org/10.54356/ma/2020/2/dcjk2245"
    },
    {
        "id": 14462,
        "title": "Biophysics-based protein language models for protein engineering",
        "authors": "Sam Gelman, Bryce Johnson, Chase Freschlin, Sameer D'Costa, Anthony Gitter, Philip A Romero",
        "published": "No Date",
        "citations": 0,
        "abstract": "Protein language models trained on evolutionary data have emerged as powerful tools for predictive problems involving protein sequence, structure, and function. However, these models overlook decades of research into biophysical factors governing protein function. We propose Mutational Effect Transfer Learning (METL), a protein language model framework that unites advanced machine learning and biophysical modeling. Using the METL framework, we pretrain transformer-based neural networks on biophysical simulation data to capture fundamental relationships between protein sequence, structure, and energetics. We finetune METL on experimental sequence-function data to harness these biophysical signals and apply them when predicting protein properties like thermostability, catalytic activity, and fluorescence. METL excels in challenging protein engineering tasks like generalizing from small training sets and position extrapolation, although existing methods that train on evolutionary signals remain powerful for many types of experimental assays. We demonstrate METL's ability to design functional green fluorescent protein variants when trained on only 64 examples, showcasing the potential of biophysics-based protein language models for protein engineering.",
        "link": "http://dx.doi.org/10.1101/2024.03.15.585128"
    },
    {
        "id": 14463,
        "title": "Learning natural language interfaces with neural models",
        "authors": "Li Dong",
        "published": "2021-6",
        "citations": 0,
        "abstract": "Language is the primary and most natural means of communication for humans. The learning curve of interacting with various services (e.g., digital assistants, and smart appliances) would be greatly reduced if we could talk to machines using human language. However, in most cases computers can only interpret and execute formal languages.",
        "link": "http://dx.doi.org/10.1145/3478369.3478375"
    },
    {
        "id": 14464,
        "title": "Improved the Protein Complex Prediction with Protein Language Models",
        "authors": "Bo Chen, Ziwei Xie, Jiezhong Qiu, Zhaofeng Ye, Jinbo Xu, Jie Tang",
        "published": "No Date",
        "citations": 3,
        "abstract": "AbstractAlphaFold-Multimer has greatly improved protein complex structure prediction, but its accuracy also depends on the quality of the multiple sequence alignment (MSA) formed by the interacting homologs (i.e., interologs) of the complex under prediction. Here we propose a novel method, denoted as ESMPair, that can identify interologs of a complex by making use of protein language models (PLMs). We show that ESMPair can generate better interologs than the default MSA generation method in AlphaFold-Multimer. Our method results in better complex structure prediction than AlphaFold-Multimer by a large margin (+10.7% in terms of the Top-5 best DockQ), especially when the predicted complex structures have low confidence. We further show that by combining several MSA generation methods, we may yield even better complex structure prediction accuracy than Alphafold-Multimer (+22% in terms of the Top-5 best DockQ). We systematically analyze the impact factors of our algorithm and find out the diversity of MSA of interologs significantly affects the prediction accuracy. Moreover, we show that ESMPair performs particularly well on complexes in eucaryotes.",
        "link": "http://dx.doi.org/10.1101/2022.09.15.508065"
    },
    {
        "id": 14465,
        "title": "Automated Chinese Essay Scoring using Pre-Trained Language Models",
        "authors": "Lulu Dong, Lin Li, HongChao Ma, YeLing Liang",
        "published": "2021-11-27",
        "citations": 0,
        "abstract": "Automated Essay Scoring (AES) aims to assign a proper score to an essay written by a given prompt, which is a significant application of Natural Language Processing (NLP) in the education area. In this work, we focus on solving the Chinese AES problem by Pre-trained Language Models (PLMs) including state-of-the-art PLMs BERT and ERNIE. A Chinese essay dataset has been built up in this work, by which we conduct extensive AES experiments. Our PLMs-based AES models acquire 68.70% in Quadratic Weighted Kappa (QWK), which outperform classic feature-based linear regression AES model. The results show that our methods effectively alleviate the dependence on manual features and improve the portability of AES models. Furthermore, we acquire well-performed AES models with a limited scale of the dataset, which solves the lack of datasets in Chinese AES.",
        "link": "http://dx.doi.org/10.5121/csit.2021.111901"
    },
    {
        "id": 14466,
        "title": "Mapping Brains with Language Models: A Survey",
        "authors": "Antonia Karamolegkou, Mostafa Abdou, Anders Søgaard",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.618"
    },
    {
        "id": 14467,
        "title": "Predicting Numerals in Text Using Nearest Neighbor Language Models",
        "authors": "Taku Sakamoto, Akiko Aizawa",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.295"
    },
    {
        "id": 14468,
        "title": "Learning Dynamic Author Representations with Temporal Language Models",
        "authors": "Edouard Delasalles, Sylvain Lamprier, Ludovic Denoyer",
        "published": "2019-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdm.2019.00022"
    },
    {
        "id": 14469,
        "title": "GAN You Hear Me? Reclaiming Unconditional Speech Synthesis from Diffusion Models",
        "authors": "Matthew Baas, Herman Kamper",
        "published": "2023-1-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt54892.2023.10023153"
    },
    {
        "id": 14470,
        "title": "On Marx’s and Hegel’s Dialectical Methods",
        "authors": "Dirk Damsma",
        "published": "2019-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1163/9789004395497_003"
    },
    {
        "id": 14471,
        "title": "Chemical language models for molecular design",
        "authors": "Jürgen Bajorath",
        "published": "2024-1",
        "citations": 0,
        "abstract": "AbstractIn drug discovery, chemical language models (CLMs) originating from natural language processing offer new opportunities for molecular design. CLMs have been developed using recurrent neural network (RNN) or transformer architectures. For the predictive performance of RNN‐based encoder‐decoder frameworks and transformers, attention mechanisms play a central role. Among others, emerging application areas for CLMs include constrained generative modeling and the prediction of chemical reactions or drug‐target interactions. Since CLMs are applicable to any compound or target data that can be presented in a sequential format and tokenized, mappings of different types of sequences can be learned. For example, active compounds can be predicted from protein sequence motifs. Novel off‐the‐beat‐path applications can also be considered. For example, analogue series from medicinal chemistry can be perceived and represented as chemical sequences and extended with new compounds using CLMs. Herein, methodological features of CLMs and different applications are discussed.",
        "link": "http://dx.doi.org/10.1002/minf.202300288"
    },
    {
        "id": 14472,
        "title": "Introducing meta-analysis in the evaluation of computational models of infant language development",
        "authors": "María Andrea Cruz Blandón, Alejandrina Cristia, Okko Räsänen",
        "published": "No Date",
        "citations": 3,
        "abstract": "Computational models of child language development can help us understand the cognitive underpinnings of the language learning process, which occurs along several linguistic levels at once (e.g., prosodic and phonological). However, in light of the replication crisis, modellers face the challenge of selecting representative and consolidated infant data. Thus, it is desirable to have evaluation methodologies that could account for robust empirical reference data, across multiple infant capabilities. Moreover, there is a need for practices that can compare developmental trajectories of infants to those of models as a function of language experience and development. The present study aims to take concrete steps to address these needs by introducing the concept of comparing models with large-scale cumulative empirical data from infants, as quantified by meta-analyses conducted across a large number of individual behavioural studies. We formalise the connection between measurable model and human behaviour, and then present a conceptual framework for meta-analytic evaluation of computational models. We exemplify the meta-analytic model evaluation approach with two modelling experiments on infant-directed speech preference and native/non-native vowel discrimination.",
        "link": "http://dx.doi.org/10.31234/osf.io/yjz5a"
    },
    {
        "id": 14473,
        "title": "Ergodic Properties",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.ch4"
    },
    {
        "id": 14474,
        "title": "Probabilistic Toolbox",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.ch3"
    },
    {
        "id": 14475,
        "title": "Modeling Confidence in Sequence-to-Sequence Models",
        "authors": "Jan Niehues, Ngoc-Quan Pham",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-8671"
    },
    {
        "id": 14476,
        "title": "Language Recognition Based on Unsupervised Pretrained Models",
        "authors": "Haibin Yu, Jing Zhao, Song Yang, Zhongqin Wu, Yuting Nie, Wei-Qiang Zhang",
        "published": "2021-8-30",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-807"
    },
    {
        "id": 14477,
        "title": "Extracting Business Process Models Using Natural Language Processing (NLP) Techniques",
        "authors": "Konstantinos Sintoris, Kostas Vergidis",
        "published": "2017-7",
        "citations": 25,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cbi.2017.41"
    },
    {
        "id": 14478,
        "title": "Protein language models can capture protein quaternary state",
        "authors": "Orly Avraham, Tomer Tsaban, Ziv Ben-Aharon, Linoy Tsaban, Ora Schueler-Furman",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground:\nDetermining a protein’s quaternary state, i.e. the number of monomers in a functional unit, is a critical step in protein characterization. Many proteins form multimers for their activity, and over 50% are estimated to naturally form homomultimers. Experimental quaternary state determination can be challenging and require extensive work. To complement these efforts, a number of computational tools have been developed for quaternary state prediction, often utilizing experimentally validated structural information. Recently, dramatic advances have been made in the field of deep learning for predicting protein structure and other characteristics. Protein language models, such as ESM-2, that apply computational natural-language models to proteins successfully capture secondary structure, protein cell localization and other characteristics, from a single sequence. Here we hypothesize that information about the protein quaternary state may be contained within protein sequences as well, allowing us to benefit from these novel approaches in the context of quaternary state prediction.\nResults:\nWe generated ESM-2 embeddings for a large dataset of proteins with quaternary state labels from the curated QSbio dataset. We trained a model for quaternary state classification and assessed it on a non-overlapping set of distinct folds (ECOD family level). Our model, named QUEEN (QUaternary state prediction using dEEp learNing), performs worse than approaches that include information from solved crystal structures. However, it successfully learned to distinguish multimers from monomers, and predicts the specific quaternary state with moderate success, better than simple sequence similarity-based annotation transfer. Our results demonstrate that complex, quaternary state related information is included in such embeddings.\nConclusions:\nQUEEN is the first to investigate the power of embeddings for the prediction of the quaternary state of proteins. As such, it lays out strengths as well as limitations of a sequence-based protein language model approach, compared to structure-based approaches. Since it does not require any structural information and is fast, we anticipate that it will be of wide use both for in-depth investigation of specific systems, as well as for studies of large sets of protein sequences. A simple colab implementation is available at:\nhttps://colab.research.google.com/github/Orly-A/QUEEN_prediction/blob/main/QUEEN_prediction_notebook.ipynb.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2761491/v1"
    },
    {
        "id": 14479,
        "title": "Conclusion",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.10"
    },
    {
        "id": 14480,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Attila Miklós Wind",
        "published": "2023-6-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/lcvsgt"
    },
    {
        "id": 14481,
        "title": "Distilling Reasoning Capabilities into Smaller Language Models",
        "authors": "Kumar Shridhar, Alessandro Stolfo, Mrinmaya Sachan",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.441"
    },
    {
        "id": 14482,
        "title": "Large Language Model-Empowered Agents for Simulating Macroeconomic Activities",
        "authors": "Nian Li, Chen Gao, Yong Li, Qingmin Liao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4606937"
    },
    {
        "id": 14483,
        "title": "Research and Application of Subway Construction Method for Large-scale Municipal Tunnel Crossing Operation",
        "authors": "",
        "published": "2022-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i8(04).20"
    },
    {
        "id": 14484,
        "title": "CompressionGPT: Evaluating Fault Tolerance of a Compressed Large Language Model",
        "authors": "Neil Kapur, America Rangel, Lillian Pentecost",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iiswc59245.2023.00033"
    },
    {
        "id": 14485,
        "title": "Semantic representations extracted from large language corpora predict high-level human judgment in seven diverse behavioral domains",
        "authors": "Russell Richie, Wanling Zou, Sudeep Bhatia",
        "published": "No Date",
        "citations": 3,
        "abstract": "Recent advances in machine learning, combined with the increased availability of large natural language datasets, have made it possible to uncover semantic representations that characterize what people know about and associate with a wide range of objects and concepts. In this paper, we examine the power of word embeddings, a popular approach for uncovering semantic representations, for studying high-level human judgment. Word embeddings are typically applied to linguistic and semantic tasks, however we show that word embeddings can be used to predict complex theoretically- and practically-relevant human perceptions and evaluations in domains as diverse as social cognition, health behavior, risk perception, organizational behavior, and marketing. By learning mappings from word embeddings directly onto judgment ratings, we outperform a similarity-based baseline as well as common metrics of human inter-rater reliability. Word embeddings are also able to identify the concepts that are most associated with observed perceptions and evaluations, and can thus shed light on the psychological substrates of judgment. Overall, we provide new methods and insights for predicting and understanding high-level human judgment, with important applications across the social and behavioral sciences.",
        "link": "http://dx.doi.org/10.31234/osf.io/g9j83"
    },
    {
        "id": 14486,
        "title": "Literary History Writ Large; or, The Multilingual <i>MLQ</i>",
        "authors": "Barbara Fuchs",
        "published": "2021-9-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1215/00267929-9090374"
    },
    {
        "id": 14487,
        "title": "What are the Future Trends in Natural Gas Technology to Address Climate Change? Patent Analysis Through Large Language Model",
        "authors": "Mingyu Kim, Juyong Lee",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4743899"
    },
    {
        "id": 14488,
        "title": "Updating The Domain Analysis Of The Writing Subtest Of A Large-Scale Standardized Test For K-12 English Language Learners",
        "authors": "Jing Wei, Tanya Bitterman, Ruslana Westerlund, Jennifer Norton",
        "published": "2019-2-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429437922-6"
    },
    {
        "id": 14489,
        "title": "Predictors of second language English lexical recognition",
        "authors": "Stephen Skalicky, Scott A. Crossley, Cynthia M. Berger",
        "published": "2019-12-31",
        "citations": 5,
        "abstract": "Abstract\nIn this study we analyze a large database of lexical decision times for English content words made by speakers of\n                    English as an additional language residing in the United States. Our first goal was to test whether the use of statistical\n                    measures better able to model variation associated with participants and items would replicate findings of a previous analysis of\n                    this data (Berger, Crossley, & Skalicky, 2019). Our second goal was to determine\n                    whether variables related to experiences using and learning English would interact with linguistic features of the target words.\n                    Results from our statistical analysis suggest affirmative answers to both of these questions. First, our results included\n                    significant effects for linguistic features related to contextual diversity and contextual distinctiveness, providing a\n                    replication of findings from the original study in that words appearing in more textual and lexical contexts were responded to\n                    quicker. Second, a measure of length of English learning and a measure of daily English use interacted with a measure of\n                    orthographic similarity. Our study provides further evidence regarding how a large, crowdsourced database can be used to obtain a\n                    better understanding of second language lexical recognition behavior and provides suggestions for further research.",
        "link": "http://dx.doi.org/10.1075/ml.19028.ska"
    },
    {
        "id": 14490,
        "title": "Predicting Credit Rating Migration Employing Neural Network Models",
        "authors": "Michael D'Rosario, Calvin Hsieh",
        "published": "2020",
        "citations": 0,
        "abstract": "Credit rating migration ranks amongst the most pertinent issues concerning institutional lenders and investors alike. There are a number of studies that have employed both parametric and non-parametric methodologies to forecast credit rating migration, employing machine learning methods; and notably, artificial intelligence methods becoming increasingly popular. The present study extends upon research within the extant literature employing a novel estimation method, a neural network modelling technique, herewith the MPANN (multi-layer neural network). Consistent with the extant literature, the present article identifies that the legal framework and system of taxation enacted within a polity are pertinent to predicting rating migration. However, extending upon traditional estimation techniques the study identifies that a number of different model calibrations achieve greater predictive accuracy than traditional parametric regression. Notably, the method is able to achieve superior goodness of fit and predictive accuracy in determining credit rating migration than models employed within the extant literature. ",
        "link": "http://dx.doi.org/10.4018/978-1-7998-0951-7.ch005"
    },
    {
        "id": 14491,
        "title": "Flexible Log File Parsing Using Hidden Markov Models",
        "authors": "Nadine Kuhnert, Andreas Maier",
        "published": "2019-9-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5121/csit.2019.91201"
    },
    {
        "id": 14492,
        "title": "Teaching English Language Variation in the Global Classroom",
        "authors": "Michelle D. Devereaux, Chris C. Palmer",
        "published": "2021-12-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003124665"
    },
    {
        "id": 14493,
        "title": "Future Research",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.oth"
    },
    {
        "id": 14494,
        "title": "Reconsidering the Past: Optimizing Hidden States in Language Models",
        "authors": "Davis Yoshida, Kevin Gimpel",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-emnlp.346"
    },
    {
        "id": 14495,
        "title": "Formal Models Based on Phrase Structure Grammar",
        "authors": "Zhiwei Feng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-5172-4_3"
    },
    {
        "id": 14496,
        "title": "AutoDistiller: An Automatic Compression Method for Multi-task Language Models",
        "authors": "Hongsheng Wang, Geyang Xiao, Yuan Liang",
        "published": "2022-7-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/ccc55666.2022.9901868"
    },
    {
        "id": 14497,
        "title": "Introduction",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.4"
    },
    {
        "id": 14498,
        "title": "Specializing Multilingual Language Models: An Empirical Study",
        "authors": "Ethan C. Chau, Noah A. Smith",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.mrl-1.5"
    },
    {
        "id": 14499,
        "title": "Estimation of Gap Between Current Language Models and Human Performance",
        "authors": "Xiaoyu Shen, Youssef Oualil, Clayton Greenberg, Mittul Singh, Dietrich Klakow",
        "published": "2017-8-20",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2017-729"
    },
    {
        "id": 14500,
        "title": "Deep models and optimizers for Indian sign language recognition",
        "authors": "P. Sharma, R.S. Anand",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1049/icp.2021.1445"
    },
    {
        "id": 14501,
        "title": "Mapping Brains with Language Models: A Survey",
        "authors": "Antonia Karamolegkou, Mostafa Abdou, Anders Søgaard",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.618"
    },
    {
        "id": 14502,
        "title": "Predicting Numerals in Text Using Nearest Neighbor Language Models",
        "authors": "Taku Sakamoto, Akiko Aizawa",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.295"
    },
    {
        "id": 14503,
        "title": "Learning Dynamic Author Representations with Temporal Language Models",
        "authors": "Edouard Delasalles, Sylvain Lamprier, Ludovic Denoyer",
        "published": "2019-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdm.2019.00022"
    },
    {
        "id": 14504,
        "title": "GAN You Hear Me? Reclaiming Unconditional Speech Synthesis from Diffusion Models",
        "authors": "Matthew Baas, Herman Kamper",
        "published": "2023-1-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt54892.2023.10023153"
    },
    {
        "id": 14505,
        "title": "On Marx’s and Hegel’s Dialectical Methods",
        "authors": "Dirk Damsma",
        "published": "2019-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1163/9789004395497_003"
    },
    {
        "id": 14506,
        "title": "Introducing meta-analysis in the evaluation of computational models of infant language development",
        "authors": "María Andrea Cruz Blandón, Alejandrina Cristia, Okko Räsänen",
        "published": "No Date",
        "citations": 3,
        "abstract": "Computational models of child language development can help us understand the cognitive underpinnings of the language learning process, which occurs along several linguistic levels at once (e.g., prosodic and phonological). However, in light of the replication crisis, modellers face the challenge of selecting representative and consolidated infant data. Thus, it is desirable to have evaluation methodologies that could account for robust empirical reference data, across multiple infant capabilities. Moreover, there is a need for practices that can compare developmental trajectories of infants to those of models as a function of language experience and development. The present study aims to take concrete steps to address these needs by introducing the concept of comparing models with large-scale cumulative empirical data from infants, as quantified by meta-analyses conducted across a large number of individual behavioural studies. We formalise the connection between measurable model and human behaviour, and then present a conceptual framework for meta-analytic evaluation of computational models. We exemplify the meta-analytic model evaluation approach with two modelling experiments on infant-directed speech preference and native/non-native vowel discrimination.",
        "link": "http://dx.doi.org/10.31234/osf.io/yjz5a"
    },
    {
        "id": 14507,
        "title": "Ergodic Properties",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.ch4"
    },
    {
        "id": 14508,
        "title": "Probabilistic Toolbox",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.ch3"
    },
    {
        "id": 14509,
        "title": "Biophysics-based protein language models for protein engineering",
        "authors": "Sam Gelman, Bryce Johnson, Chase Freschlin, Sameer D'Costa, Anthony Gitter, Philip A Romero",
        "published": "No Date",
        "citations": 0,
        "abstract": "Protein language models trained on evolutionary data have emerged as powerful tools for predictive problems involving protein sequence, structure, and function. However, these models overlook decades of research into biophysical factors governing protein function. We propose Mutational Effect Transfer Learning (METL), a protein language model framework that unites advanced machine learning and biophysical modeling. Using the METL framework, we pretrain transformer-based neural networks on biophysical simulation data to capture fundamental relationships between protein sequence, structure, and energetics. We finetune METL on experimental sequence-function data to harness these biophysical signals and apply them when predicting protein properties like thermostability, catalytic activity, and fluorescence. METL excels in challenging protein engineering tasks like generalizing from small training sets and position extrapolation, although existing methods that train on evolutionary signals remain powerful for many types of experimental assays. We demonstrate METL's ability to design functional green fluorescent protein variants when trained on only 64 examples, showcasing the potential of biophysics-based protein language models for protein engineering.",
        "link": "http://dx.doi.org/10.1101/2024.03.15.585128"
    },
    {
        "id": 14510,
        "title": "Language Recognition Based on Unsupervised Pretrained Models",
        "authors": "Haibin Yu, Jing Zhao, Song Yang, Zhongqin Wu, Yuting Nie, Wei-Qiang Zhang",
        "published": "2021-8-30",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-807"
    },
    {
        "id": 14511,
        "title": "Protein language models can capture protein quaternary state",
        "authors": "Orly Avraham, Tomer Tsaban, Ziv Ben-Aharon, Linoy Tsaban, Ora Schueler-Furman",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground:\nDetermining a protein’s quaternary state, i.e. the number of monomers in a functional unit, is a critical step in protein characterization. Many proteins form multimers for their activity, and over 50% are estimated to naturally form homomultimers. Experimental quaternary state determination can be challenging and require extensive work. To complement these efforts, a number of computational tools have been developed for quaternary state prediction, often utilizing experimentally validated structural information. Recently, dramatic advances have been made in the field of deep learning for predicting protein structure and other characteristics. Protein language models, such as ESM-2, that apply computational natural-language models to proteins successfully capture secondary structure, protein cell localization and other characteristics, from a single sequence. Here we hypothesize that information about the protein quaternary state may be contained within protein sequences as well, allowing us to benefit from these novel approaches in the context of quaternary state prediction.\nResults:\nWe generated ESM-2 embeddings for a large dataset of proteins with quaternary state labels from the curated QSbio dataset. We trained a model for quaternary state classification and assessed it on a non-overlapping set of distinct folds (ECOD family level). Our model, named QUEEN (QUaternary state prediction using dEEp learNing), performs worse than approaches that include information from solved crystal structures. However, it successfully learned to distinguish multimers from monomers, and predicts the specific quaternary state with moderate success, better than simple sequence similarity-based annotation transfer. Our results demonstrate that complex, quaternary state related information is included in such embeddings.\nConclusions:\nQUEEN is the first to investigate the power of embeddings for the prediction of the quaternary state of proteins. As such, it lays out strengths as well as limitations of a sequence-based protein language model approach, compared to structure-based approaches. Since it does not require any structural information and is fast, we anticipate that it will be of wide use both for in-depth investigation of specific systems, as well as for studies of large sets of protein sequences. A simple colab implementation is available at:\nhttps://colab.research.google.com/github/Orly-A/QUEEN_prediction/blob/main/QUEEN_prediction_notebook.ipynb.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2761491/v1"
    },
    {
        "id": 14512,
        "title": "Modeling Confidence in Sequence-to-Sequence Models",
        "authors": "Jan Niehues, Ngoc-Quan Pham",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-8671"
    },
    {
        "id": 14513,
        "title": "Improved the Protein Complex Prediction with Protein Language Models",
        "authors": "Bo Chen, Ziwei Xie, Jiezhong Qiu, Zhaofeng Ye, Jinbo Xu, Jie Tang",
        "published": "No Date",
        "citations": 3,
        "abstract": "AbstractAlphaFold-Multimer has greatly improved protein complex structure prediction, but its accuracy also depends on the quality of the multiple sequence alignment (MSA) formed by the interacting homologs (i.e., interologs) of the complex under prediction. Here we propose a novel method, denoted as ESMPair, that can identify interologs of a complex by making use of protein language models (PLMs). We show that ESMPair can generate better interologs than the default MSA generation method in AlphaFold-Multimer. Our method results in better complex structure prediction than AlphaFold-Multimer by a large margin (+10.7% in terms of the Top-5 best DockQ), especially when the predicted complex structures have low confidence. We further show that by combining several MSA generation methods, we may yield even better complex structure prediction accuracy than Alphafold-Multimer (+22% in terms of the Top-5 best DockQ). We systematically analyze the impact factors of our algorithm and find out the diversity of MSA of interologs significantly affects the prediction accuracy. Moreover, we show that ESMPair performs particularly well on complexes in eucaryotes.",
        "link": "http://dx.doi.org/10.1101/2022.09.15.508065"
    },
    {
        "id": 14514,
        "title": "Chemical language models for molecular design",
        "authors": "Jürgen Bajorath",
        "published": "2024-1",
        "citations": 0,
        "abstract": "AbstractIn drug discovery, chemical language models (CLMs) originating from natural language processing offer new opportunities for molecular design. CLMs have been developed using recurrent neural network (RNN) or transformer architectures. For the predictive performance of RNN‐based encoder‐decoder frameworks and transformers, attention mechanisms play a central role. Among others, emerging application areas for CLMs include constrained generative modeling and the prediction of chemical reactions or drug‐target interactions. Since CLMs are applicable to any compound or target data that can be presented in a sequential format and tokenized, mappings of different types of sequences can be learned. For example, active compounds can be predicted from protein sequence motifs. Novel off‐the‐beat‐path applications can also be considered. For example, analogue series from medicinal chemistry can be perceived and represented as chemical sequences and extended with new compounds using CLMs. Herein, methodological features of CLMs and different applications are discussed.",
        "link": "http://dx.doi.org/10.1002/minf.202300288"
    },
    {
        "id": 14515,
        "title": "Distilling Reasoning Capabilities into Smaller Language Models",
        "authors": "Kumar Shridhar, Alessandro Stolfo, Mrinmaya Sachan",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.441"
    },
    {
        "id": 14516,
        "title": "Conclusion",
        "authors": "",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.10"
    },
    {
        "id": 14517,
        "title": "Review of: \"Enhancing Student Writing Skills: Leveraging Transfer Learning and Fine-tuned Language Models for Automated Essay Structure Recognition\"",
        "authors": "Attila Miklós Wind",
        "published": "2023-6-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/lcvsgt"
    },
    {
        "id": 14518,
        "title": "Extracting Business Process Models Using Natural Language Processing (NLP) Techniques",
        "authors": "Konstantinos Sintoris, Kostas Vergidis",
        "published": "2017-7",
        "citations": 25,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cbi.2017.41"
    },
    {
        "id": 14519,
        "title": "Differences Across Levels in the Language of Agency and Ability in Rating Scales for Large-Scale Second Language Writing Assessments",
        "authors": "Salena Sampson Anderson",
        "published": "2017-12-1",
        "citations": 0,
        "abstract": "Abstract\nWhile large-scale language and writing assessments benefit from a wealth of literature on the reliability and validity of specific tests and rating procedures, there is comparatively less literature that explores the specific language of second language writing rubrics. This paper provides an analysis of the language of performance descriptors for the public versions of the TOEFL and IELTS writing assessment rubrics, with a focus on linguistic agency encoded by agentive verbs and language of ability encoded by modal verbs can and cannot. While the IELTS rubrics feature more agentive verbs than the TOEFL rubrics, both pairs of rubrics feature uneven syntax across the band or score descriptors with either more agentive verbs for the highest scores, more nominalization for the lowest scores, or language of ability exclusively in the lowest scores. These patterns mirror similar patterns in the language of college-level classroom-based writing rubrics, but they differ from patterns seen in performance descriptors for some large-scale admissions tests. It is argued that the lack of syntactic congruity across performance descriptors in the IELTS and TOEFL rubrics may reflect a bias in how actual student performances at different levels are characterized.",
        "link": "http://dx.doi.org/10.1515/stap-2017-0006"
    },
    {
        "id": 14520,
        "title": "Implementation of an accommodations policy for candidates with diverse needs in a large-scale testing system",
        "authors": "Johanna Motteram, Richard Spiby, Gemma Bellhouse, Katarzyna Sroka",
        "published": "2023-10",
        "citations": 1,
        "abstract": " This article describes the implementation of a special accommodations policy for a suite of localised English language and numeracy tests, the Workplace Literacy and Numeracy (WPLN) Assessments. The WPLN are computer-delivered assessments, part of the WPLN training and assessment programme, which exists to provide access to workforce skills training across the Singaporean population. Operational and interview data were analysed to investigate three main areas: the extent to which WPLN accommodations are considered appropriate and effective for the test-taker population; the impact of the accommodations on test-takers’ future opportunities; and the main factors perceived by stakeholders as playing an important role in test accommodations. The findings indicate that while the accommodations provided are generally considered to be appropriate and effective for the diverse WPLN test-taker population and facilitate improved future educational and workplace opportunities, some areas of the process are problematic or worthy of further consideration. Specifically, recommendations are made for future improvement in special accommodations policy development, dissemination, and implementation in large-scale test systems to safeguard access and inclusion. ",
        "link": "http://dx.doi.org/10.1177/02655322231166587"
    },
    {
        "id": 14521,
        "title": "Allocating Large Vocabulary Capacity for Cross-Lingual Language Model Pre-Training",
        "authors": "Bo Zheng, Li Dong, Shaohan Huang, Saksham Singhal, Wanxiang Che, Ting Liu, Xia Song, Furu Wei",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.257"
    },
    {
        "id": 14522,
        "title": "Latent-Variable Generative Models for Data-Efficient Text Classification",
        "authors": "Xiaoan Ding, Kevin Gimpel",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-1048"
    },
    {
        "id": 14523,
        "title": "Underdeterminacy without ostension: A blind spot in the prevailing models of communication",
        "authors": "Constant Bonard",
        "published": "2023-9-19",
        "citations": 0,
        "abstract": "Together, the code and inferential models of communication are often thought to range over all cases of communication. However, their prevailing versions seem unable to fully explain what I callunderdeterminacy without ostension. The latter is constituted by communication where stimuli that are not (nor appear to be) produced with communicative or informative intentions nevertheless communicate information underdetermined by the relevant codes. Though the prevailing accounts of communication cannot fully explain how communication works in such cases, I suggest that some version of the inferential model can—if we allow it to extend to non‐ostensive, non‐intentional behaviors.",
        "link": "http://dx.doi.org/10.1111/mila.12481"
    },
    {
        "id": 14524,
        "title": "MLlab4CS at SemEval-2023 Task 2: Named Entity Recognition in Low-resource Language Bangla Using Multilingual Language Models",
        "authors": "Shrimon Mukherjee, Madhusudan Ghosh, Girish ., Partha Basuchowdhuri",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.semeval-1.192"
    },
    {
        "id": 14525,
        "title": "We’re Afraid Language Models Aren’t Modeling Ambiguity",
        "authors": "Alisa Liu, Zhaofeng Wu, Julian Michael, Alane Suhr, Peter West, Alexander Koller, Swabha Swayamdipta, Noah Smith, Yejin Choi",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.51"
    },
    {
        "id": 14526,
        "title": "The better your Syntax, the better your Semantics? Probing Pretrained Language Models for the English Comparative Correlative",
        "authors": "Leonie Weissweiler, Valentin Hofmann, Abdullatif Köksal, Hinrich Schütze",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.746"
    },
    {
        "id": 14527,
        "title": "The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models",
        "authors": "Lovisa Hagström, Denitsa Saynova, Tobias Norlund, Moa Johansson, Richard Johansson",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.332"
    },
    {
        "id": 14528,
        "title": "Does the Correctness of Factual Knowledge Matter for Factual Knowledge-Enhanced Pre-trained Language Models?",
        "authors": "Boxi Cao, Qiaoyu Tang, Hongyu Lin, Xianpei Han, Le Sun",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.143"
    },
    {
        "id": 14529,
        "title": "Automatic mechanistic inference from large families of Boolean models generated by Monte Carlo Tree Search",
        "authors": "Bryan Glazer, Jonathan Lifferth, Carlos F. Lopez",
        "published": "No Date",
        "citations": 0,
        "abstract": "1AbstractMotivationMany important processes in biology, such as signaling and gene regulation, can be described using logic models. These logic models are typically built to behaviorally emulate experimentally observed phenotypes, which are assumed to be steady states of a biological system. Most models are built by hand and therefore researchers are only able to consider one or perhaps a few potential mechanisms. We present a method to automatically synthesize Boolean logic models with a specified set of steady states. Our method, called MC-Boomer, is based on Monte Carlo Tree Search (MCTS), an efficient, parallel search method using reinforcement learning. Our approach enables users to constrain the model search space using prior knowledge or biochemical interaction databases, thus leading to generation of biologically plausible mechanistic hypotheses. Our approach can generate very large numbers of data-consistent models. To help develop mechanistic insight from these models, we developed analytical tools for multi-model inference and model selection. These tools reveal the key sets of interactions that govern the behavior of the models.ResultsWe demonstrate that MC-Boomer works well at reconstructing randomly generated models. Then, using single time point measurements and reasonable biological constraints, our method generates hundreds of thousands of candidate models that match experimentally validatedin-vivobehaviors of theDrosophilasegment polarity network. Finally we outline how our multimodel analysis procedures elucidate potentially novel biological mechanisms and provide opportunities for model-driven experimental validation.AvailabilityCode is available at:www.github.com/bglazer/mcboomer",
        "link": "http://dx.doi.org/10.1101/2022.10.13.512151"
    },
    {
        "id": 14530,
        "title": "Technical roadmap towards trustworthy large-scale models in medicine",
        "authors": "Jie Yang, Qian Ding, Jie Tian, Puxiang Lai",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.59717/j.xinn-med.2024.100058"
    },
    {
        "id": 14531,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v5"
    },
    {
        "id": 14532,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v19"
    },
    {
        "id": 14533,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v28"
    },
    {
        "id": 14534,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v24"
    },
    {
        "id": 14535,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v31"
    },
    {
        "id": 14536,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v15"
    },
    {
        "id": 14537,
        "title": "A Weak Contrast Function Approach to Adaptive Semi-Markov Decision Models",
        "authors": "Rodolfo A. Milito, J. B. Cruz",
        "published": "2020-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003066866-8"
    },
    {
        "id": 14538,
        "title": "Methods and Models for Adapting the Russian Transport Infrastructure Under Sanctions",
        "authors": "Vladimir Tsyganov",
        "published": "2022-9-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd55143.2022.9934751"
    },
    {
        "id": 14539,
        "title": "Mathematical Models for Digital Twins in Flexible Discrete Manufacturing",
        "authors": "Natalia Aristova, Valentin Chadeev",
        "published": "2023-9-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd58227.2023.10303836"
    },
    {
        "id": 14540,
        "title": "scSemiProfiler: Advancing Large-scale Single-cell Studies through Semi-profiling with Deep Generative Models and Active Learning",
        "authors": "Jingtao Wang, Gregory Fonseca, Jun Ding",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractSingle-cell sequencing is a crucial tool for dissecting the cellular intricacies of complex diseases. Its prohibitive cost, however, hampers its application in expansive biomedical studies. Traditional cellular deconvolution approaches can infer cell type proportions from more affordable bulk sequencing data, yet they fall short in providing the detailed resolution required for singlecell-level analyses. To overcome this challenge, we introduce “scSemiProfiler”, an innovative computational framework that marries deep generative model with active learning strategies. This method adeptly infers single-cell profiles across large cohorts by fusing bulk sequencing data with targeted single-cell sequencing from a few carefully chosen representatives. Extensive validation across heterogeneous datasets verifies the precision of our semi-profiling approach, aligning closely with true single-cell profiling data and empowering refined cellular analyses. Originally developed for extensive disease cohorts, “scSemiProfiler” is adaptable for broad applications. It provides a scalable, cost-effective solution for single-cell profiling, facilitating in-depth cellular investigation in various biological domains.",
        "link": "http://dx.doi.org/10.1101/2023.11.20.567929"
    },
    {
        "id": 14541,
        "title": "Large Scale Systems and SIR Models: A Featured Graphon Approach",
        "authors": "Alex Dunyak, Peter E. Caines",
        "published": "2021-12-14",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc45484.2021.9683048"
    },
    {
        "id": 14542,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v46"
    },
    {
        "id": 14543,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v54"
    },
    {
        "id": 14544,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v57"
    },
    {
        "id": 14545,
        "title": "Large-scale generalized linear longitudinal data models with grouped patterns of unobserved heterogeneity",
        "authors": "Tomohiro Ando, Jushan Bai",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4004263"
    },
    {
        "id": 14546,
        "title": "Application of Physically Based Distributed Flood Models for Large-Scale Flood Simulations",
        "authors": "Siddharth Saksena, Venkatesh Merwade",
        "published": "2022-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780429463938-19"
    },
    {
        "id": 14547,
        "title": "Alternative Solutions for Cloning in HLA-Based Distributed Simulation",
        "authors": "Dan Chen, Lizhe Wang, Jingying Chen",
        "published": "2017-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b11883-7"
    },
    {
        "id": 14548,
        "title": "Large-scale calibration of conceptual rainfall-runoff models for two-stage probabilistic hydrological post-processing",
        "authors": "Georgia Papacharalampous, Hristos Tyralis, Demetris Koutsoyiannis, Alberto Montanari",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Probabilistic hydrological modelling methodologies often comprise two-stage post-processing schemes, thereby allowing the exploitation of the information provided by conceptual or physically-based rainfall-runoff models. They might also require issuing an ensemble of rainfall-runoff model simulations by using the rainfall-runoff model with different input data and/or different parameters. For obtaining a large number of rainfall-runoff model parameters in this regard, Bayesian schemes can be adopted; however, such schemes are accompanied by computational limitations (that are well-recognized in the literature). Therefore, in this work, we investigate the replacement of Bayesian rainfall-runoff model calibration schemes by computationally convenient non-Bayesian schemes within probabilistic hydrological modelling methodologies of the above-defined family. For our experiments, we use a methodology of this same family that is additionally characterized by the following distinguishing features: It (a) is in accordance with a theoretically consistent blueprint, (b) allows the exploitation of quantile regression algorithms (which offer larger flexibility than parametric models), and (c) has been empirically proven to harness the &amp;#8220;wisdom of the crowd&amp;#8221; in terms of average interval score. We also use a parsimonious conceptual rainfall-runoff model and 50-year-long monthly time series observed in 270 catchments in the United States to apply and compare 12 variants of the selected methodology. Six of these variants simulate the posterior distribution of the rainfall-runoff model parameters (conditional on the observations of a calibration period) within a Bayesian Markov chain Monte Carlo framework (first category of variants), while the other six variants use a simple computationally efficient approach instead (second category of variants). Six indicative combinations of the remaining components of the probabilistic hydrological modelling methodology (i.e., its post-processing scheme and its error model) are examined, each being used in one variant from each of the above-defined categories. In this specific context, the two large-scale calibration schemes (each representing a different &amp;#8220;modelling culture&amp;#8221; in our tests) are compared using proper scores and large-scale benchmarking. Overall, our findings suggest that the compared &amp;#8220;modelling cultures&amp;#8221; can lead to mostly equally good probabilistic predictions.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu21-18"
    },
    {
        "id": 14549,
        "title": "A Simple Method to Estimate Large Fixed Effects Models Applied to Wage Determinants and Matching",
        "authors": "Nikolas Mittag",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2895295"
    },
    {
        "id": 14550,
        "title": "Data Normalization Models in the Security Event Management Systems",
        "authors": "Andrey Iskhakov, Sergey Iskhakov",
        "published": "2020-9-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd49919.2020.9247682"
    },
    {
        "id": 14551,
        "title": "NarrativeXL: a Large-scale Dataset for Long-Term Memory Models",
        "authors": "Arsenii Moskvichev, Ky-Vinh Mai",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.1005"
    },
    {
        "id": 14552,
        "title": "Jump factor models in large cross‐sections",
        "authors": "Jia Li, Viktor Todorov, George Tauchen",
        "published": "2019",
        "citations": 14,
        "abstract": "We develop tests for deciding whether a large cross‐section of asset prices obey an exact factor structure at the times of factor jumps. Such jump dependence is implied by standard linear factor models. Our inference is based on a panel of asset returns with asymptotically increasing cross‐sectional dimension and sampling frequency, and essentially no restriction on the relative magnitude of these two dimensions of the panel. The test is formed from the high‐frequency returns at the times when the risk factors are detected to have a jump. The test statistic is a cross‐sectional average of a measure of discrepancy in the estimated jump factor loadings of the assets at consecutive jump times. Under the null hypothesis, the discrepancy in the factor loadings is due to a measurement error, which shrinks with the increase of the sampling frequency, while under an alternative of a noisy jump factor model this discrepancy contains also nonvanishing firm‐specific shocks. The limit behavior of the test under the null hypothesis is nonstandard and reflects the strong‐dependence in the cross‐section of returns as well as their heteroskedasticity which is left unspecified. We further develop estimators for assessing the magnitude of firm‐specific risk in asset prices at the factor jump events. Empirical application to S&P 100 stocks provides evidence for exact one‐factor structure at times of big market‐wide jump events.",
        "link": "http://dx.doi.org/10.3982/qe1060"
    },
    {
        "id": 14553,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v40"
    },
    {
        "id": 14554,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v39"
    },
    {
        "id": 14555,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v1"
    },
    {
        "id": 14556,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v17"
    },
    {
        "id": 14557,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v26"
    },
    {
        "id": 14558,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v11"
    },
    {
        "id": 14559,
        "title": "Developing hybrid distributed models for hydrological simulation and climate change assessment in large alpine basins",
        "authors": "Bu Li, Ting Sun, Fuqiang Tian, Guangheng Ni",
        "published": "No Date",
        "citations": 0,
        "abstract": "Large alpine basins on the Tibetan Plateau (TP) provide abundant water resources crucial for hydropower generation, irrigation, and daily life. In recent decades, the TP has been significantly affected by climate change, making it crucial to understand the runoff response to climate change are essential for water resources management. While limited knowledge of specific alpine hydrological processes has constrained the accuracy of hydrological models and heightened uncertainties in climate change assessments. Recently, hybrid hydrological models have come to the forefront, synergizing the exceptional learning capacity of deep learning with a rigorous adherence to hydrological knowledge of process-based models. These models exhibit considerable promise in achieving precision in hydrological simulations and conducting climate change assessments. However, a notable limitation of existing hybrid models lies in their failure to incorporate spatial information and describe alpine hydrological processes, which restricts their applicability in hydrological modeling and climate change assessment in large alpine basins. To address this issue, we develop a set of hybrid distributed hydrological models by employing a distributed process-based model as the backbone, and utilizing embedded neural networks (ENNs) to parameterize and replace different internal modules. The proposed models are tested on three large alpine basins on the Tibetan Plateau. Results are compared to those obtained from hybrid lumped models, state-of-the-art distributed hydrological model, and DL models. A climate perturbation method is further used to evaluate the alpine basins' runoff response to climate change.Results indicate that proposed hybrid hydrological models can perform well in predicting runoff in large alpine basins. The optimal hybrid model with Nash-Sutcliffe efficiency coefficients (NSEs) higher than 0.87 shows comparable performance to state-of-the-art DL models. The hybrid distributed model also exhibits remarkable capability in simulating hydrological processes at ungauged sites within the basin, markedly surpassing traditional distributed models. Besides, runoff exhibits an amplification effect in response to precipitation changes, with a 10% precipitation change resulting in a 15&#8211;20% runoff change in large alpine basins. An increase in temperature enhances evaporation capacity and changes the redistribution of rainfall and snowfall and the timing of snowmelt, leading to a decrease in the total runoff and a reduction in the intra-annual variability of runoff. Overall, this study provides a high-performance tool enriched with explicit hydrological knowledge for hydrological prediction and improves our understanding about runoff&#8217;s response to climate change in large alpine basins on the TP.&#160;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-9319"
    },
    {
        "id": 14560,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v30"
    },
    {
        "id": 14561,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v59"
    },
    {
        "id": 14562,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v21"
    },
    {
        "id": 14563,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v51"
    },
    {
        "id": 14564,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v55"
    },
    {
        "id": 14565,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v53"
    },
    {
        "id": 14566,
        "title": "Updating The Domain Analysis Of The Writing Subtest Of A Large-Scale Standardized Test For K-12 English Language Learners",
        "authors": "Jing Wei, Tanya Bitterman, Ruslana Westerlund, Jennifer Norton",
        "published": "2019-2-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429437922-6"
    },
    {
        "id": 14567,
        "title": "Predictors of second language English lexical recognition",
        "authors": "Stephen Skalicky, Scott A. Crossley, Cynthia M. Berger",
        "published": "2019-12-31",
        "citations": 5,
        "abstract": "Abstract\nIn this study we analyze a large database of lexical decision times for English content words made by speakers of\n                    English as an additional language residing in the United States. Our first goal was to test whether the use of statistical\n                    measures better able to model variation associated with participants and items would replicate findings of a previous analysis of\n                    this data (Berger, Crossley, & Skalicky, 2019). Our second goal was to determine\n                    whether variables related to experiences using and learning English would interact with linguistic features of the target words.\n                    Results from our statistical analysis suggest affirmative answers to both of these questions. First, our results included\n                    significant effects for linguistic features related to contextual diversity and contextual distinctiveness, providing a\n                    replication of findings from the original study in that words appearing in more textual and lexical contexts were responded to\n                    quicker. Second, a measure of length of English learning and a measure of daily English use interacted with a measure of\n                    orthographic similarity. Our study provides further evidence regarding how a large, crowdsourced database can be used to obtain a\n                    better understanding of second language lexical recognition behavior and provides suggestions for further research.",
        "link": "http://dx.doi.org/10.1075/ml.19028.ska"
    },
    {
        "id": 14568,
        "title": "An efficient approximation-based robust design optimization framework for large-scale structural systems",
        "authors": "Tanmoy Chatterjee, Rajib Chowdhury",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-816514-0.00007-2"
    },
    {
        "id": 14569,
        "title": "Identification of conceptual rainfall-runoff models of large drainage basins based on GRACE and in-situ data",
        "authors": "Karim Douch, Peyman Saemian, Nico Sneeuw",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Since 2002, estimates of the spatio-temporal variations of Earth&amp;#8217;s gravity field derived from the Gravity Recovery and Climate Experiment (GRACE and now GRACE-FO) mission measurements have provided new insights into large scale water redistributions at inter-annual, seasonal and sub-seasonal timescales. It has been shown for example that for many large drainage basins the empirical relationship between aggregated Terrestrial Water Storage (TWS) and discharge at the outlet reveals an underlying dynamic that is approximately linear and time-invariant.&lt;/p&gt;&lt;p&gt;In this contribution, we further analyse this relationship in the case of the Amazon basin and sub-basins by investigating different physically interpretable, lumped-parameter models for the TWS-discharge dynamics. To this end, we first put forward a linear and continuous-time model using a state-space representation. We then enhance the model by introducing a non-linear term accounting for the observed saturation of the discharge. Finally, we reformulate the model by replacing the discharge by the river stage at the outlet and add a prescribed model of the rating curve to obtain the discharge. The suggested models are successively calibrated against TWS anomaly derived from GRACE data and discharge or river stage records using the prediction-error-method. It is noteworthy that one of the estimated parameters can be interpreted as the total amount of drainable water stored across the basin, a quantity that cannot be observed by GRACE alone. This quantity is estimated to be on average 1,750 km&amp;#179; during the period 2004-2009. These models are eventually combined with the equation of water mass balance, in order to obtain a consistent representation of the basin-scale rainfall-runoff dynamics suited to data assimilation.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu22-7903"
    },
    {
        "id": 14570,
        "title": "Benchmarking Deep Graph Models for Large Molecular Generation",
        "authors": "Jin-Jun Park, Lee Sael",
        "published": "2022-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigcomp54360.2022.00032"
    },
    {
        "id": 14571,
        "title": "Generation of Large-Scale High Quality 3-D Urban Models",
        "authors": "Yilei Shi, Richard Bamler, Yuanyuan Wang, Xiao Xiang Zhu",
        "published": "2020-9-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/radarconf2043947.2020.9266314"
    },
    {
        "id": 14572,
        "title": "High-impact winter weather in EURO-CORDEX climate models and their links to large-scale atmospheric circulation",
        "authors": "Eva Plavcová, Ondřej Lhotka, Jan Stryhal",
        "published": "No Date",
        "citations": 0,
        "abstract": "\n        &lt;p&gt;Regional Climate Models (RCMs) are powerful tools to study changes in the climate system on the regional scale. However, the reliability of their simulations has been considerably limited by the longstanding issue that climate models often fail to reproduce various aspects of the historical climate. In our study, we analyse how RCMs from the EURO-CORDEX project are able to reproduce high-impact winter weather. We analyse temporal and spatial characteristics of snowfalls, wind gust, extreme temperatures, late spring frosts, total precipitation, and winter storms. Model outputs are validated against observed data from the gridded European database (EOBS) and the novel ERA5 reanalysis. We focus on the Central European domain (defined roughly between 48&amp;#8211;52&amp;#176;N and 10&amp;#8211;20&amp;#176;E) over the 1979 &amp;#8211; 2017 period. We investigate a set of 12 simulations of 4 different RCMs driven by 3 different global climate models which allow us to analyse the influence of driving data on the RCM&amp;#8217;s performance. Since local climate elements are relatively tightly linked to a large-scale atmospheric circulation over Europe in winter, we also evaluate the ability of RCMs to reproduce the atmospheric circulation and its links to selected high-impact winter weather in detail. Investigation of these links can lead to better physical understanding of the climate and to the identification of inadequacies in simulated characteristics of the studied events. All of this is an important step forward in further improving the models and enhancing the credibility of climate change scenarios based on climate model simulations.&lt;/p&gt;\n        ",
        "link": "http://dx.doi.org/10.5194/egusphere-egu2020-4620"
    },
    {
        "id": 14573,
        "title": "Efficient Localized Inference for Large Graphical Models",
        "authors": "Jinglin Chen, Jian Peng, Qiang Liu",
        "published": "2018-7",
        "citations": 0,
        "abstract": "We propose a new localized inference algorithm for answering marginalization queries in large graphical models with the correlation decay property. Given a query variable and a large graphical model, we define a much smaller model in a local region around the query variable in the target model so that the marginal distribution of the query variable can be accurately approximated. We introduce two approximation error bounds based on the Dobrushin’s comparison theorem and apply our bounds to derive a greedy expansion algorithm that efficiently guides the selection of neighbor nodes for localized inference. We verify our theoretical bounds on various datasets and demonstrate that our localized inference algorithm can provide fast and accurate approximation for large graphical models.",
        "link": "http://dx.doi.org/10.24963/ijcai.2018/692"
    },
    {
        "id": 14574,
        "title": "Probabilistic Models with Nonlocal Correlations: Numerical Evidence of Q-Large Deviation Theory",
        "authors": "Dario Javier Zamora, Constantino Tsallis",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4146162"
    },
    {
        "id": 14575,
        "title": "Large Electrode Movements: Realistic Electrical Crater Models",
        "authors": "Vetle Kjær Risinggård, Manuel Sparta, Mads Fromreide, Svenn Anton Halvorsen",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4117701"
    },
    {
        "id": 14576,
        "title": "Large-Scale Simulation Study of Active Learning models for Systematic Reviews",
        "authors": "Jelle Jasper Teijema, Jonathan de Bruin, Ayoub Bagheri, Rens van de Schoot",
        "published": "No Date",
        "citations": 0,
        "abstract": "The active learning methods for prioritising systematic reviews have undergone significant progress and innovation in recent years. This rapid development, however, has inadvertently highlighted the disparity between the rapid development of these methodologies and their rigorous evaluation, stemming from constraints in simulation size, lack of infrastructure, and the use of few datasets.We embark on a large-scale simulation study involving over 27 thousand simulations and over 156 million datapoints, designed to provide robust empirical evidence of active learning methodologies performance. We evaluate 13 combinations of different classification models and feature extraction techniques across high-quality datasets sourced from the SYNERGY dataset. We run a single simulation for each possible combination of selected classification model, feature extraction technique, dataset, and relevant document. The spectrum of performance varies considerably, from marginally better than random reading to near flawless results. Still, every single model-feature extraction combination outperforms random screening. Results are publicly available for analysis and replication.This study advocates for large-scale simulations as the gold standard for assessing active learning methods; it underscores the importance of comprehensive testing to reduce reporting bias and enhance result reliability. It also highlights the need for curating diverse datasets for systematic review literature.",
        "link": "http://dx.doi.org/10.31234/osf.io/2w3rm"
    },
    {
        "id": 14577,
        "title": "CommonAccent: Exploring Large Acoustic Pretrained Models for Accent Classification Based on Common Voice",
        "authors": "Juan Zuluaga-Gomez, Sara Ahmed, Danielius Visockas, Cem Subakan",
        "published": "2023-8-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-2419"
    },
    {
        "id": 14578,
        "title": "Large biases in soil moisture limitation across CMIP6 models",
        "authors": "Francesco Giardina, Ryan S. Padrón, Benjamin D. Stocker, Dominik L. Schumacher, Sonia I. Seneviratne",
        "published": "No Date",
        "citations": 0,
        "abstract": "Accurate soil moisture representation is crucial in climate modeling, due to its significant role in land-atmosphere interactions. Our study focuses on water storage dynamics and analyzes how soil moisture limitation is represented in simulations from the land component (land-hist experiment) of seven models within the Coupled Model Intercomparison Project phase 6 (CMIP6). We quantified the annual maximum depletion in soil moisture, contrasting model results with observations of terrestrial water storage from the Gravity Recovery and Climate Experiment (GRACE). Our analysis shows that CMIP6 models mostly underestimate these annual extremes in soil moisture reductions, with the Amazon consistently emerging as the most biased region. We further computed the critical soil moisture thresholds and quantified the frequency of soil moisture limitation in CMIP6 simulations, comparing model estimates against solar-induced fluorescence (SIF) and GRACE observations. We found consistent results with the annual maximum depletion in soil moisture, with models almost always overestimating the frequency of soil moisture limitation globally compared to observations. We validated our findings with data from 128 eddy-covariance sites from eight biomes worldwide. Our study illuminates the biases in soil moisture storage and dynamics between CMIP6 models and empirical observations, highlighting the importance of improving the representations of soil moisture and land-atmosphere interactions in Earth System Models.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-17662"
    },
    {
        "id": 14579,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v36"
    },
    {
        "id": 14580,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v47"
    },
    {
        "id": 14581,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v41"
    },
    {
        "id": 14582,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v43"
    },
    {
        "id": 14583,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v45"
    },
    {
        "id": 14584,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v8"
    },
    {
        "id": 14585,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v14"
    },
    {
        "id": 14586,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v6"
    },
    {
        "id": 14587,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v38"
    },
    {
        "id": 14588,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v16"
    },
    {
        "id": 14589,
        "title": "Lexical processing in child and adult classroom second language learners: Uniqueness and similarities, and implications for cognitive models",
        "authors": "Janet G. van Hell",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/bs.plm.2020.03.004"
    },
    {
        "id": 14590,
        "title": "Balancing Type I error and power in linear mixed models",
        "authors": "Hannes Matuschek, Reinhold Kliegl, Shravan Vasishth, Harald Baayen, Douglas Bates",
        "published": "2017-6",
        "citations": 986,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jml.2017.01.001"
    },
    {
        "id": 14591,
        "title": "5. Interculturality in Foreign Language Teacher Training: Performing Arts Projects Across National, Language and Cultural Borders",
        "authors": "Micha Fleiner",
        "published": "2017-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781783098552-007"
    },
    {
        "id": 14592,
        "title": "Exploring intrinsic information content models for addressing the issues of traditional semantic measures to evaluate verb similarity",
        "authors": "M. Krishna Siva Prasad, Poonam Sharma",
        "published": "2022-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2021.101280"
    },
    {
        "id": 14593,
        "title": "Who gets to be the hero(ine)? Analysing female and male role models in Japanese textbooks of English as a foreign language",
        "authors": "Martina Ronci",
        "published": "2021-12-20",
        "citations": 0,
        "abstract": "Research on textbooks of English as a Foreign Language (EFL) in Japan has pointed out issues in gender and ethnic representation. Sustained efforts to achieve equal representation of both subjects have led to more balanced contents, but the problem has not yet been overcome. The aim of this paper is to address how the ‘role model’ genre found in Japanese EFL high school textbooks perpetuates negative stereotypes and ideologies through consistent misrepresentation. The findings point to an under-representation of female, foreign and diverse characters, often relegated to submissive archetypes (such as nature and environmental concerns) as opposed to the athletes, winners and successful individuals portrayed by active Japanese male characters.",
        "link": "http://dx.doi.org/10.55393/babylonia.v3i.115"
    },
    {
        "id": 14594,
        "title": "Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting",
        "authors": "Sanyuan Chen, Yutai Hou, Yiming Cui, Wanxiang Che, Ting Liu, Xiangzhan Yu",
        "published": "2020",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.634"
    },
    {
        "id": 14595,
        "title": "clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents",
        "authors": "Kranti Chalamalasetti, Jana Götze, Sherzod Hakimov, Brielen Madureira, Philipp Sadler, David Schlangen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.689"
    },
    {
        "id": 14596,
        "title": "SafeText: A Benchmark for Exploring Physical Safety in Language Models",
        "authors": "Sharon Levy, Emily Allaway, Melanie Subbiah, Lydia Chilton, Desmond Patton, Kathleen McKeown, William Yang Wang",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.154"
    },
    {
        "id": 14597,
        "title": "Simultaneous Inference of Plate Boundary Stresses and Mantle Rheology Using Adjoints: Large-Scale Two-Dimensional Models",
        "authors": "Johann Rudi, Michael Gurnis, Georg Stadler",
        "published": "No Date",
        "citations": 0,
        "abstract": "Plate motions are a primary surface constraint on plate and mantle dynamics and rheology, plate boundary stresses, and the occurrence of great earthquakes.  Within an optimization method, we use plate motion data to better constrain uncertain mantle parameters.  For the optimization problem characterizing the maximum a posteriori rheological parameters we derive gradients using adjoints and expressions to approximate the posterior distributions for stresses within plate boundaries.  We apply these methods to a 2-D cross section from the western to eastern Pacific, with temperature distributions and fault zone geometries developed primarily from seismic and plate motion data.  We find that the best-fitting stress exponent, $n$, is about 2.8 and the yield stress about 100 MPa or less. The normal stress on the interplate fault zones is about 100 MPa and the shear stresses about 10 MPa or less.",
        "link": "http://dx.doi.org/10.31223/x57h0r"
    },
    {
        "id": 14598,
        "title": "Which climate models capture the variability and forced response in observed temperatures: a large ensemble comparison",
        "authors": "Nicola Maher, Laura Suarez-Gutierrez, Sebastian Milinski",
        "published": "No Date",
        "citations": 0,
        "abstract": "\n        &lt;p&gt;We evaluate how large ensembles of ten coupled climate models represent the observed internal variability and response to external forcings in historical surface temperatures based on a novel methodological framework. This framework allows us to directly attribute whether discrepancies between models and observations arise due to biases in the simulated internal variability or rather in the forced response, without relying on assumptions to separate both signals in the observations. The largest discrepancies occur due to overestimated forced warming in some models during recent decades. The areas where most models, a maximum of nine, adequately simulate observed temperatures are the North Atlantic, Tropical Eastern Pacific, and the Northern Hemisphere land areas. In contrast, none of the models considered offers an adequate representation over the Southern Ocean. Our evaluation shows that CESM-LE, GFDL-ESM2M, and MPI-GE perform best at representing the internal variability and forced response in observed surface temperatures both globally and regionally.&amp;#160;&lt;/p&gt;\n        ",
        "link": "http://dx.doi.org/10.5194/egusphere-egu2020-6081"
    },
    {
        "id": 14599,
        "title": "Non-Stationary Dynamic Factor Models for Large Datasets",
        "authors": "Matteo Barigozzi, Marco Lippi, Matteo Luciani",
        "published": "2017-8",
        "citations": 2,
        "abstract": "We study a Large-Dimensional Non-Stationary Dynamic Factor Model where (1) the factors Ft are I(1) and singular, that is Ft has dimension r and is driven by q dynamic shocks with q less than r, (2) the idiosyncratic components are either I(0) or I(1). Under these assumption the factors Ft are cointegrated and modeled by a singular Error Correction Model. We provide conditions for consistent estimation, as both the cross-sectional size n, and the time dimension T, go to infinity, of the factors, the loadings, the shocks, the ECM coefficients and therefore the Impulse Response Functions. Finally, the numerical properties of our estimator are explored by means of a MonteCarlo exercise and of a real-data application, in which we study the effects of monetary policy and supply shocks on the US economy.",
        "link": "http://dx.doi.org/10.17016/feds.2016.024r1"
    },
    {
        "id": 14600,
        "title": "A Fine-grained Large-scale Analysis of Coreference Projection",
        "authors": "Michal Novák",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-0709"
    },
    {
        "id": 14601,
        "title": "Investigating the seasonal response of precipitation extremes to global warming using observations and large-ensembles of coupled climate models",
        "authors": "Andrew Williams, Paul O'Gorman",
        "published": "No Date",
        "citations": 0,
        "abstract": "\n        &lt;p&gt;Changes in extreme precipitation are amongst the most impactful consequences of global warming, with potential effects ranging from increased flood risk and landslides to crop failures and impacts on ecosystems. Thus, understanding historical and future changes in extreme precipitation is not only important from a scientific perspective, but also has direct societal relevance.&lt;/p&gt;&lt;p&gt;However, while most current research has focused on annual precipitation extremes and their response to warming, it has recently been noted that climate model projections show a distinct seasonality to future changes in extreme precipitation. In particular, CMIP5 models suggest that over Northern Hemisphere (NH) land the summer response is weaker than the winter response in terms of percentage changes.&lt;/p&gt;&lt;p&gt;Here we investigate changes in seasonal precipitation extremes using observations and simulations with coupled climate models. First, we analyse observed trends from the Hadley Centre&amp;#8217;s global climate extremes dataset (HadEX2) to investigate to what extent there is already a difference between summer and winter trends over NH land. Second, we use 40 ensemble members from the CESM Large Ensemble to characterize the role played by internal variability in trends over the historical period. Lastly, we use CMIP5 simulations to explore the possibility of a link between the seasonality of changes in precipitation extremes and decreases in surface relative humidity over land.&lt;/p&gt;\n        ",
        "link": "http://dx.doi.org/10.5194/egusphere-egu2020-5989"
    },
    {
        "id": 14602,
        "title": "O(N)-symmetric vector models for N large",
        "authors": "Jean Zinn-Justin",
        "published": "2021-4-15",
        "citations": 0,
        "abstract": "Abstract\nSo far, universal properties of O(N) symmetric critical systems have been derived within the framework of the formal ϵ = 4−d expansion. Therefore, it is reassuring to verify that the results obtained in this way remain valid, at least in some limiting case, even when ϵ is not infinitesimal. Here it is shown in the example of the O(N) symmetric (ϕ2)2 field theory, the same universal properties can also be derived at fixed dimension in the large N limit and, more generally, order by order in an 1/N expansion. Moreover, large N techniques are also useful, because they provide an insight into other non-perturbative questions, including issues relevant to four-dimensional physics like renormalons and triviality. Using a large N expansion, we exhibit a remarkable relation between the (ϕ2)2 field theory and the non-linear σ-model, valid to all orders.",
        "link": "http://dx.doi.org/10.1093/oso/9780198834625.003.0018"
    },
    {
        "id": 14603,
        "title": "Estimating Large-Scale Tree Logit Models via a Difference of Strictly Convex Functions",
        "authors": "Srikanth Jagabathula, Paat Rusmevichientong",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3416311"
    },
    {
        "id": 14604,
        "title": "Equivalence of ensembles for large vehicle-sharing models",
        "authors": "Christine Fricker, Danielle Tibi",
        "published": "2017-4-1",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1214/16-aap1219"
    },
    {
        "id": 14605,
        "title": "The use of large animal models to improve pre-clinical translational research",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3389/978-2-83251-932-5"
    },
    {
        "id": 14606,
        "title": "Optimization Techniques for Large Speech Tasks",
        "authors": "Tara N. Sainath, Brian Kingsbury, Hagen Soltau, Bhuvana Ramabhadran",
        "published": "2018-11-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7551/mitpress/10012.003.0008"
    },
    {
        "id": 14607,
        "title": "Uncertain Programming Models for Finding Reliably Compromise Design Solutions",
        "authors": "George Veresnikov, Oleg Ogorodnikov",
        "published": "2022-9-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd55143.2022.9933997"
    },
    {
        "id": 14608,
        "title": "Review on long time asymptotics of large data in some nonintegrable dispersive models",
        "authors": "Claudio Muñoz",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21711/231766362023/rmc575"
    },
    {
        "id": 14609,
        "title": "Neural Field Models for Latent State Inference: Application to Large-Scale Neuronal Recordings",
        "authors": "M. E. Rule, D. Schnoerr, M. H. Hennig, G. Sanguinetti",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractLarge-scale neural recordings are becoming increasingly better at providing a window into functional neural networks in the living organism. Interpreting such rich data sets, however, poses fundamental statistical challenges. The neural field models of Wilson, Cowan and colleagues remain the mainstay of mathematical population modeling owing to their interpretable, mechanistic parameters and amenability to mathematical analysis. We developed a method based on moment closure to interpret neural field models as latent state-space point-process models, making mean field models amenable to statistical inference. We demonstrate that this approach can infer latent neural states, such as active and refractory neurons, in large populations. After validating this approach with synthetic data, we apply it to high-density recordings of spiking activity in the developing mouse retina. This confirms the essential role of a long lasting refractory state in shaping spatio-temporal properties of neonatal retinal waves. This conceptual and methodological advance opens up new theoretical connections between mathematical theory and point-process state-space models in neural data analysis.SignificanceDeveloping statistical tools to connect single-neuron activity to emergent collective dynamics is vital for building interpretable models of neural activity. Neural field models relate single-neuron activity to emergent collective dynamics in neural populations, but integrating them with data remains challenging. Recently, latent state-space models have emerged as a powerful tool for constructing phenomenological models of neural population activity. The advent of high-density multi-electrode array recordings now enables us to examine large-scale collective neural activity. We show that classical neural field approaches can yield latent statespace equations and demonstrate inference for a neural field model of excitatory spatiotemporal waves that emerge in the developing retina.",
        "link": "http://dx.doi.org/10.1101/543769"
    },
    {
        "id": 14610,
        "title": "Benchmarking optimization methods for parameter estimation in large kinetic models",
        "authors": "Alejandro F. Villaverde, Fabian Fröhlich, Daniel Weindl, Jan Hasenauer, Julio R. Banga",
        "published": "No Date",
        "citations": 9,
        "abstract": "AbstractMotivationMechanistic kinetic models usually contain unknown parameters, which need to be estimated by optimizing the fit of the model to experimental data. This task can be computationally challenging due to the presence of local optima and ill-conditioning. While a variety of optimization methods have been suggested to surmount these issues, it is not obvious how to choose the best one for a given problem a priori, since many factors can influence their performance. A systematic comparison of methods that are suited to parameter estimation problems of sizes ranging from tens to hundreds of optimization variables is currently missing, and smaller studies indeed provided contradictory findings.ResultsHere, we use a collection of benchmark problems to evaluate the performance of two families of optimization methods: (i) a multi-start of deterministic local searches; and (ii) a hybrid metaheuristic combining stochastic global search with deterministic local searches. A fair comparison is ensured through a collaborative evaluation, involving researchers applying each method on a daily basis, and a consideration of multiple performance metrics capturing the trade-off between computational efficiency and robustness. Our results show that, thanks to recent advances in the calculation of parametric sensitivities, a multi-start of gradient-based local methods is often a successful strategy, but a better performance can be obtained with a hybrid metaheuristic. The best performer is a combination of a global scatter search metaheuristic with an interior point local method, provided with gradients estimated with adjoint-based sensitivities. We provide an implementation of this novel method in an open-source software toolbox to render it available to the scientific community.Availability and ImplementationThe code to reproduce the results is available at Zenodo https://doi.org/10.5281/zenodo.1160343Contactjan.hasenauer@helmholtz-muenchen.de, julio@iim.csic.es",
        "link": "http://dx.doi.org/10.1101/295006"
    },
    {
        "id": 14611,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v48"
    },
    {
        "id": 14612,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v52"
    },
    {
        "id": 14613,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v56"
    },
    {
        "id": 14614,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v10"
    },
    {
        "id": 14615,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v4"
    },
    {
        "id": 14616,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v44"
    },
    {
        "id": 14617,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v29"
    },
    {
        "id": 14618,
        "title": "Large Spatial Competition",
        "authors": "Matías Núñez, Marco Scarsini",
        "published": "2017",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-52654-6_10"
    },
    {
        "id": 14619,
        "title": "Estimating Subgraph Generation Models to Understand Large Network Formation",
        "authors": "Laurens Bogaardt, Frank W. Takes",
        "published": "2018-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/escience.2018.00106"
    },
    {
        "id": 14620,
        "title": "Latent-Grouped Structure in Panel Data Models",
        "authors": "",
        "published": "2020-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811220784_0005"
    },
    {
        "id": 14621,
        "title": "Artificial Neural Network Models for Large-Scale Data",
        "authors": "Vo Ngoc Phu, Vo Thi Ngoc Tran",
        "published": "2022",
        "citations": 0,
        "abstract": "Artificial intelligence (ARTINT) and information have been famous fields for many years. A reason has been that many different areas have been promoted quickly based on the ARTINT and information, and they have created many significant values for many years. These crucial values have certainly been used more and more for many economies of the countries in the world, other sciences, companies, organizations, etc. Many massive corporations, big organizations, etc. have been established rapidly because these economies have been developed in the strongest way. Unsurprisingly, lots of information and large-scale data sets have been created clearly from these corporations, organizations, etc. This has been the major challenges for many commercial applications, studies, etc. to process and store them successfully. To handle this problem, many algorithms have been proposed for processing these big data sets. ",
        "link": "http://dx.doi.org/10.4018/978-1-6684-2408-7.ch006"
    },
    {
        "id": 14622,
        "title": "Exponential Random Graph Models",
        "authors": "Sourav Chatterjee",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-65816-2_7"
    },
    {
        "id": 14623,
        "title": "Evaluating Causal Psychological Models: A Study of Imitation Theories of Autism Using a Large Sample",
        "authors": "Bohao Tang, Ericka Wodka, Brian Caffo, Joshua Ewen",
        "published": "No Date",
        "citations": 0,
        "abstract": "We used a large convenience sample (n=22,228) from the Simons Powering Autism Research (SPARK) dataset to causal, explanatory theories of autism positing a key role of imitation ability within the same, large sample. We used a highly theory-constrained approach, formalizing statistical models based on the proposals of Ornitz &amp; Ritvo (1968), Rogers &amp; Pennington (1991) and Mostofsky &amp; Ewen (2011). Results disconfirmatory for the accounts of Rogers &amp; Pennington and Mostofsky &amp; Ewen, however limitations of the convenience sample affected the strength of the inference. While the results did not disconfirm the tested portions of Ornitz &amp; Ritvo’s model linking sensory-motor function with social engagement and language, they did entail that other mechanisms must also be in play.",
        "link": "http://dx.doi.org/10.31234/osf.io/qfv5c"
    },
    {
        "id": 14624,
        "title": "Simplifying the Computation of Shapley Values for Allocating Congestion Costs in Large Power Grid Models",
        "authors": "Simon Voswinkel",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4449794"
    },
    {
        "id": 14625,
        "title": "Front Matter",
        "authors": "",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119529019.fmatter"
    },
    {
        "id": 14626,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v18"
    },
    {
        "id": 14627,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v60"
    },
    {
        "id": 14628,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v33"
    },
    {
        "id": 14629,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v37"
    },
    {
        "id": 14630,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v20"
    },
    {
        "id": 14631,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v13"
    },
    {
        "id": 14632,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v2"
    },
    {
        "id": 14633,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v3"
    },
    {
        "id": 14634,
        "title": "On the Application of Agricultural Productivity Assessment Models for Developing Regions",
        "authors": "Bayramov Orudzh",
        "published": "2023-9-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd58227.2023.10303925"
    },
    {
        "id": 14635,
        "title": "Latent feature models for large-scale link prediction",
        "authors": "Jun Zhu, Bei Chen",
        "published": "2017-12",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s41044-016-0016-y"
    },
    {
        "id": 14636,
        "title": "Efficient surrogate modeling methods for large-scale Earth system models based on machine learning techniques",
        "authors": "Dan Lu, Daniel Ricciuto",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract. Improving predictive understanding of Earth system variability and change requires data-model integration. Efficient data-model integration for complex models requires surrogate modeling to reduce model evaluation time. However, building a surrogate of a large-scale Earth system model (ESM) with many output variables is computationally intensive because it involves a large number of expensive ESM simulations. In this effort, we propose an efficient surrogate method capable of using a few ESM runs to build an accurate and fast-to-evaluate surrogate system of model outputs over large spatial and temporal domains. We first use singular value decomposition to reduce the output dimensions, and then use Bayesian optimization techniques to generate an accurate neural network surrogate model based on limited ESM simulation samples. Our machine learning based surrogate methods can build and evaluate a large surrogate system of many variables quickly. Thus, whenever the quantities of interest change such as a different objective function, a new site, and a longer simulation time, we can simply extract the information of interest from the surrogate system without rebuilding new surrogates, which significantly saves computational efforts. We apply the proposed method to a regional ecosystem model to approximate the relationship between 8 model parameters and 42 660 carbon flux outputs. Results indicate that using only 20 model simulations, we can build an accurate surrogate system of the 42 660 variables, where the consistency between the surrogate prediction and actual model simulation is 0.93 and the mean squared error is 0.02. This highly-accurate and fast-to-evaluate surrogate system will greatly enhance the computational efficiency in data-model integration to improve predictions and advance our understanding of the Earth system.\n                        ",
        "link": "http://dx.doi.org/10.5194/gmd-2018-327"
    },
    {
        "id": 14637,
        "title": "Large structures simulation for landscape evolution models",
        "authors": "Julien Coatléven, Benoit Chauveau",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract. Because of the chaotic behavior of the coupling between water flow and sediment erosion and transport, without any special treatment the practical results of landscape evolution models (LEM) are likely to be dominated by numerical errors. This paper describes two areas of improvement that we believe are necessary for the successful simulation of landscape evolution models. The first one concerns the expression of the water flux that was initially rebuilt in a recent paper in a mathematically consistent way for the cell-to-cell multiple flow direction algorithms, thanks to a reinterpretation as a well chosen discretization of the Gauckler-Manning-Strickler continuous equation. Building on those results, we introduce here a general framework allowing to derive consistent expressions of the water flux for the most commonly used multiple/single flow direction (MFD/SFD) water flow routines, including node-to-node versions. If having a consistent water flux is crucial to avoid any mesh size dependence in a LEM and controlling the consistency error, the expected non-linear self amplification mechanisms of the water and sediment coupling can still lead to simulations blurred by numerical errors. Those numerical instabilities being highly reminiscent of turbulence induced instabilities in computational fluid dynamics (CFD), in the second part of our paper we present a ``large structure simulation'' (LSS) approach for LEM, mimicking the large-eddy simulations (LES) used for turbulent CFD. The LSS allows to control numerical errors while preserving the major physical based geomorphic patterns.\n                        ",
        "link": "http://dx.doi.org/10.5194/egusphere-2023-687"
    },
    {
        "id": 14638,
        "title": "Interplay of Team Mental Models, Project Process Models, and Language in Software-Development Teams",
        "authors": "Azusa Ebisuya, Tomoki Sekiguchi, Gayan Prasad Hettiarachchi",
        "published": "2017-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5465/ambpp.2017.11968abstract"
    },
    {
        "id": 14639,
        "title": "Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction",
        "authors": "Masahiro Kaneko, Masato Mita, Shun Kiyono, Jun Suzuki, Kentaro Inui",
        "published": "2020",
        "citations": 33,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.acl-main.391"
    },
    {
        "id": 14640,
        "title": "Did the Models Understand Documents? Benchmarking Models for Language Understanding in Document-Level Relation Extraction",
        "authors": "Haotian Chen, Bingsheng Chen, Xiangdong Zhou",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.354"
    },
    {
        "id": 14641,
        "title": "Basic Principles of Cross-Lingual Models",
        "authors": "Serge Sharoff, Reinhard Rapp, Pierre Zweigenbaum",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-31384-4_2"
    },
    {
        "id": 14642,
        "title": "Supporting systematic literature reviews using deep-learning-based language models",
        "authors": "Rand Alchokr, Manoj Borkar, Sharanya Thotadarya, Gunter Saake, Thomas Leich",
        "published": "2022-5-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3528588.3528658"
    },
    {
        "id": 14643,
        "title": "Gender Biases and Where to Find Them: Exploring Gender Bias in Pre-Trained Transformer-based Language Models Using Movement Pruning",
        "authors": "Przemyslaw Joniak, Akiko Aizawa",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gebnlp-1.6"
    },
    {
        "id": 14644,
        "title": "Probing Contextual Language Models for Common Ground with Visual Representations",
        "authors": "Gabriel Ilharco, Rowan Zellers, Ali Farhadi, Hannaneh Hajishirzi",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.422"
    },
    {
        "id": 14645,
        "title": "It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners",
        "authors": "Timo Schick, Hinrich Schütze",
        "published": "2021",
        "citations": 107,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.185"
    },
    {
        "id": 14646,
        "title": "Large-scale benchmark yields no evidence that language model surprisal explains syntactic disambiguation difficulty",
        "authors": "Kuan-Jung Huang, Suhas Arehalli, Mari Kugemoto, Christian Muxica, Grusha Prasad, Brian Dillon, Tal Linzen",
        "published": "2024-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jml.2024.104510"
    },
    {
        "id": 14647,
        "title": "The Effects of Large-Scale Social Movements on Language Attitudes: Cantonese and Mandarin in Hong Kong",
        "authors": "Priscilla Lok-chee Shum, Chi-Shing Tse, Takeshi Hamamura, Stephen C. Wright",
        "published": "2023-6",
        "citations": 1,
        "abstract": " Speakers with standard accents are typically judged more favorably than non-standard speakers, but this may shift in response to perceived intergroup conflict with ethnolinguistic outgroups. Three studies were conducted to examine how large-scale social movements may impact language attitudes in Hong Kong. Attitudes toward standard-accented and non-standard-accented Cantonese and Mandarin were collected across four instances in 2013 and 2015 (pre- and post-Umbrella Movement), 2018 and 2019 (pre- and post-Anti-Extradition Bill Movement), respectively. Compared to Study 1 (2013), Hong Kong participants judged standard speakers of Cantonese (the ingroup variety), and ingroup, non-standard speakers of Mandarin (the outgroup variety) significantly more favorably in Study 2 (2015). Study 3 showed that the retrospective endorsement of the Umbrella Movement moderated preferences for standard Cantonese and Mandarin speakers. Comparison of 2018 and 2019 data partially replicated the findings in Studies 1 and 2, though the current endorsement of the Anti-Extradition Bill Movement did not moderate preferences for standard speakers. ",
        "link": "http://dx.doi.org/10.1177/0261927x221150502"
    },
    {
        "id": 14648,
        "title": "Simplified equivalent models of large-scale wind power and their application on small-signal stability",
        "authors": "Nan Ding, Zongxiang Lu, Ying Qiao, Yong Min",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/energyo.s40565-013-0005-3"
    },
    {
        "id": 14649,
        "title": "Numerical simulation of large strain fracture problems using X-FEM",
        "authors": "",
        "published": "2017-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140216-10"
    },
    {
        "id": 14650,
        "title": "Enhanced Constrained Pressure Residual ECPR Preconditioning for Solving Difficult Large Scale Thermal Models",
        "authors": "Gary Li, John Wallis",
        "published": "2017-2-20",
        "citations": 2,
        "abstract": "Abstract\nThe Constrained Pressure Residual (CPR1,2) preconditioning method with FGMRES3 acceleration, although very efficient for iterative solution of isothermal fully implicit linear systems, may encounter significant convergence difficulties for large scale thermal cases. This is in part due to the fact that for these problems pressures are not the only strong variables. For such cases this paper describes an enhanced version of CPR (ECPR) preconditioning which is simple to implement and can significantly decrease iterations by 50% −80% or more depending on problem difficulty, converge where CPR fails, and substantially reduce work.\nThe two-stage ECPR preconditioning uses an expanded variable set for the first stage. The key step involves a fast strong variable selection algorithm which can substantially increase the robustness of CPR. For the approximate solution of this enhanced first stage we used FGMRES with equilibrated ILUC as the preconditioning. The improved strength of this step allows the use of a less expensive second stage preconditioning such as block ILU(0) rather than block ILU (1)2.\nThe block ILU(0) /ECPR method showed significant improvement in convergence rate for these difficult thermal cases over the original block ILU(1)/CPR method. We observed over 50% reduction in the number of iterations for our moderately difficult test cases over entire runs and reduction in run times. For individual linear systems requiring many CPR iterations test cases show iterations can be reduced by 80% or more using ECPR. In one particular test case CPR failed to converge after 100 iterations but ECPR converged in 7 iterations.",
        "link": "http://dx.doi.org/10.2118/182619-ms"
    },
    {
        "id": 14651,
        "title": "An Efficient 2D Method for Training Super-Large Deep Learning Models",
        "authors": "Qifan Xu, Yang You",
        "published": "2023-5",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ipdps54959.2023.00031"
    },
    {
        "id": 14652,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v32"
    },
    {
        "id": 14653,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v12"
    },
    {
        "id": 14654,
        "title": "Variations in fracture distribution across Northern Bavaria &amp;#8211; Towards large-scale geothermal fracture models",
        "authors": "Ruaridh Smith, Rahul Prabhakaran, Fabian Jakob, Daniel Koehn",
        "published": "No Date",
        "citations": 0,
        "abstract": "Natural faults and fractures form a critical component of fluid flow in low permeable reservoirs such as tight carbonates for a wide variety of applications including geothermal energy extraction. Fractured systems often control permeability in these reservoirs at the first order where properties of these networks are defined by fracture orientation, intensity, aperture, and connectivity. Accurately quantifying these network properties is vital in generating representations of the fracture networks at reservoir depth.\nIn regions with limited subsurface data (borehole and seismic), field data and outcrop analogues become an important source for characterising the fracture networks for modelling reservoirs at depth. Outcrops can be used to define several properties of the networks and information on the variation in the fracture distribution across defined areas.\nThe Franconian Basin is a major tectonic structure in Northern Bavaria containing Mesozoic sediments up to 3500m thick. It is a relatively under-researched region where limited subsurface data is available in comparison to the south in the Molasse Basin where geothermal exploration and production is well established with extensive subsurface datasets widely distributed. Increased geothermal gradients have been identified in Northern Bavaria, including surrounding the major urban areas presenting an opportunity to improve the understanding of the geothermal potential of the region. Several of the identified reservoir units in this region are primarily composed of low permeable carbonates where faults and fractures control primary reservoir flow. These units are also present as outcrop analogues in the Franconian Alb which can be utilised for surface fracture characterisation.\nWe present results analysing the variations in the fault and fracture systems from across the region captured from 1D measurements and 2D and 3D imaging of quarry and cave outcrops. Using these results, stochastic fracture models of the parts of the region can be generated, providing realisations of the fracture networks which can contribute to assessing the permeability and geothermal potential of the reservoirs in Northern Bavaria.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-18458"
    },
    {
        "id": 14655,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v58"
    },
    {
        "id": 14656,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v22"
    },
    {
        "id": 14657,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v23"
    },
    {
        "id": 14658,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v25"
    },
    {
        "id": 14659,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v34"
    },
    {
        "id": 14660,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v50"
    },
    {
        "id": 14661,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v49"
    },
    {
        "id": 14662,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v42"
    },
    {
        "id": 14663,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v35"
    },
    {
        "id": 14664,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v7"
    },
    {
        "id": 14665,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v9"
    },
    {
        "id": 14666,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in the last section we present a concerning numerical example and the respective software.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v27"
    },
    {
        "id": 14667,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-Convex Models in the Calculus of Variations",
        "authors": "Fabio Silva Botelho",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003258131-14"
    },
    {
        "id": 14668,
        "title": "Múnlaí teanga na Gaeilge agus an idé-eolaíocht teanga",
        "authors": "Noel Ó Murchadha",
        "published": "2020-11-27",
        "citations": 1,
        "abstract": "Cíorann an t-alt seo na múnlaí teanga atá i réim sa Ghaeilge .i. na spriocanna don teanga a nglactar leo sa lá inniu. Déantar anailís ar na múnlaí teanga atá intuigthe san anailís teangeolaíochta agus i gcáipéisí curaclaim na Gaeilge ón réamhscolaíocht go dtí an ollscolaíocht. Féachtar ina dhiaidh sin ar na hidé-eolaíochtaí teanga ar a bhfuil na múnlaí sin bunaithe agus ar na tuiscintí a chuireann siad in iúl maidir leis an rud is teanga ann. Ceistítear roinnt de na tuiscintí seanbhunaithe ar an rud is Gaeilge agus Gaeilge mhaith ann sa lá inniu. Ar deireadh, cuirtear moltaí i láthair maidir leis an tslí a bhfaighfí múnlaí teanga na Gaeilge a athshamhlú don aonú aois is fiche.\nThis article examines dominant language models in Irish, i.e. the target language varieties of Irish that are deemed most acceptable today. The language models implicit in linguistic analyses and in Irish language curriculum documents from preschool to university level are analysed. The ideologies on which those models are based and the implicit understandings of what constitutes ‘a language’ are examined. Some long-established ideas about what Irish is and what good Irish should look like are questioned. Finally, recommendations are made about how language models for Irish might be reimagined for the twenty-first century. ",
        "link": "http://dx.doi.org/10.35903/teanga.v27i.487"
    },
    {
        "id": 14669,
        "title": "Cross-Sectional Evaluation of Grammatical Error Correction Models",
        "authors": "Masato Mita, Tomoya Mizumoto, Masahiro Kaneko, Ryo Nagata, Kentaro Inui",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.28.160"
    },
    {
        "id": 14670,
        "title": "Chinese WPLC: A Chinese Dataset for Evaluating Pretrained Language Models on Word Prediction Given Long-Range Context",
        "authors": "Huibin Ge, Chenxi Sun, Deyi Xiong, Qun Liu",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.306"
    },
    {
        "id": 14671,
        "title": "COPEN: Probing Conceptual Knowledge in Pre-trained Language Models",
        "authors": "Hao Peng, Xiaozhi Wang, Shengding Hu, Hailong Jin, Lei Hou, Juanzi Li, Zhiyuan Liu, Qun Liu",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.335"
    },
    {
        "id": 14672,
        "title": "Lil-Bevo: Explorations of Strategies for Training Language Models in More Humanlike Ways",
        "authors": "Venkata S Govindarajan, Juan Diego Rodriguez, Kaj Bostrom, Kyle Mahowald",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-babylm.27"
    },
    {
        "id": 14673,
        "title": "Personalized neural language models for real-world query auto completion",
        "authors": "Nicolas Fiorini, Zhiyong Lu",
        "published": "2018",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/n18-3026"
    },
    {
        "id": 14674,
        "title": "DG approach to large bending plate deformations with isometry constraint",
        "authors": "Andrea Bonito, Ricardo H. Nochetto, Dimitrios Ntogkas",
        "published": "2021-1",
        "citations": 11,
        "abstract": "We propose a new discontinuous Galerkin (dG) method for a geometrically nonlinear Kirchhoff plate model for large isometric bending deformations. The minimization problem is nonconvex due to the isometry constraint. We present a practical discrete gradient flow that decreases the energy and computes discrete minimizers that satisfy a prescribed discrete isometry defect. We prove [Formula: see text]-convergence of the discrete energies and discrete global minimizers. We document the flexibility and accuracy of the dG method with several numerical experiments.",
        "link": "http://dx.doi.org/10.1142/s0218202521500044"
    },
    {
        "id": 14675,
        "title": "Implementation of hyperbolic complex numbers in Julia language",
        "authors": "Anna V. Korolkova, Migran N. Gevorkyan, Dmitry S. Kulyabov",
        "published": "2022-12-26",
        "citations": 1,
        "abstract": "Hyperbolic complex numbers are used in the description of hyperbolic spaces. One of the well-known examples of such spaces is the Minkowski space, which plays a leading role in the problems of the special theory of relativity and electrodynamics. However, such numbers are not very common in different programming languages. Of interest is the implementation of hyperbolic complex in scientific programming languages, in particular, in the Julia language. The Julia language is based on the concept of multiple dispatch. This concept is an extension of the concept of polymorphism for object-oriented programming languages. To implement hyperbolic complex numbers, the multiple dispatching approach of the Julia language was used. The result is a library that implements hyperbolic numbers. Based on the results of the study, we can conclude that the concept of multiple dispatching in scientific programming languages is convenient and natural.",
        "link": "http://dx.doi.org/10.22363/2658-4670-2022-30-4-318-329"
    },
    {
        "id": 14676,
        "title": "Analysis of open dynamical systems' models with the help of stochastic differential equations (based on the example of macroeconomic growth models)",
        "authors": "Nataliya Asanova, Irina Tarasova, Liana Sagatelova, Yaroslav Kalinin",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2017.8109594"
    },
    {
        "id": 14677,
        "title": "Application of discrete choice models for mode and destination choice in a large scale demand model",
        "authors": "Florian Koppelhuber, Georg Kriebernegg, Bernhard Lugers, Jacqueline Aspack",
        "published": "2017-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mtits.2017.8005718"
    },
    {
        "id": 14678,
        "title": "Investigating Side-Wind Stability of High Speed Trains Using High Resolution Large Eddy Simulations and Hybrid Models",
        "authors": "Moritz M. Fragner, Ralf Deiterding",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-54490-8_14"
    },
    {
        "id": 14679,
        "title": "Mixed Models with Emphasis on Large Data Sets",
        "authors": "Geert Verbeke, Geert Molenberghs, Steffen Fieuws, Samuel Iddi",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-69830-4_2"
    },
    {
        "id": 14680,
        "title": "On Lagrange Multiplier Theorems for Non-Smooth Optimization for a Large Class of Variational Models in Banach Spaces",
        "authors": "Fabio Silva Botelho",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003258131-11"
    },
    {
        "id": 14681,
        "title": "Large Eddy Simulation of a Turbulent Polydisperse Spray Flow: A Comparative Study of Subgrid Scale Models and Droplet Injection Models",
        "authors": "Teng Zhang, Jinghua Li, Yingwen Yan, Yuxin Fan",
        "published": "2024-7-1",
        "citations": 0,
        "abstract": "Abstract\nThis study performs an investigation of the effects of the subgrid-scale (SGS) and droplet injection models in the large eddy simulation (LES) of turbulent two-phase spray flows. Three LES SGS models (Smagorinsky, wall-adapting local eddy viscosity (WALE), and dynamic Smagorinsky) and two droplet injection models (cone nozzle injection and conditional droplet injection) are validated to the experimental measurements. For both gaseous and liquid phases, all SGS models provide comparable results, indicating that the current two-phase flow field does not exhibit a pronounced sensitivity to the LES SGS model. As for different droplet injection models and spray dispersion angles, minimal differences are observed in the prediction of the gaseous mean and root-mean-square (RMS) velocity profiles. However, for the result of liquid phase, CDIM (conditional droplet injection model) predictions of the droplet mean diameter and velocity are in better agreement with experiments, and less sensitive to spray dispersion angle settings. While the CNIM (cone nozzle injection model) prediction of droplet diameter is less accurate when increasing the dispersion angle. The study suggests that turbulent two-phase spray flows are more influenced by the spray boundary conditions rather than the LES SGS models.",
        "link": "http://dx.doi.org/10.1115/1.4064760"
    },
    {
        "id": 14682,
        "title": "Translating Hungarian language dialects using natural language processing models",
        "authors": "Barbara Simon, Ádám Hartveg, Lehel Dénes-Fazakas, György Eigner, László Szilágyi",
        "published": "2023-11-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cinti59972.2023.10382068"
    },
    {
        "id": 14683,
        "title": "Back Transcription as a Method for Evaluating Robustness of Natural Language Understanding Models to Speech Recognition Errors",
        "authors": "Marek Kubis, Paweł Skórzewski, Marcin Sowańnski, Tomasz Zietkiewicz",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.724"
    },
    {
        "id": 14684,
        "title": "Large Language Models are Versatile Decomposers: Decomposing Evidence and Questions for Table-based Reasoning",
        "authors": "Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, Yongbin Li",
        "published": "2023-7-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3539618.3591708"
    },
    {
        "id": 14685,
        "title": "Opportunities and challenges for ChatGPT and large language models in biomedicine and health",
        "authors": "Shubo Tian, Qiao Jin, Lana Yeganova, Po-Ting Lai, Qingqing Zhu, Xiuying Chen, Yifan Yang, Qingyu Chen, Won Kim, Donald C Comeau, Rezarta Islamaj, Aadit Kapoor, Xin Gao, Zhiyong Lu",
        "published": "2023-11-22",
        "citations": 11,
        "abstract": "Abstract\nChatGPT has drawn considerable attention from both the general public and domain experts with its remarkable text generation capabilities. This has subsequently led to the emergence of diverse applications in the field of biomedicine and health. In this work, we examine the diverse applications of large language models (LLMs), such as ChatGPT, in biomedicine and health. Specifically, we explore the areas of biomedical information retrieval, question answering, medical text summarization, information extraction and medical education and investigate whether LLMs possess the transformative power to revolutionize these tasks or whether the distinct complexities of biomedical domain presents unique challenges. Following an extensive literature survey, we find that significant advances have been made in the field of text generation tasks, surpassing the previous state-of-the-art methods. For other applications, the advances have been modest. Overall, LLMs have not yet revolutionized biomedicine, but recent rapid progress indicates that such methods hold great potential to provide valuable means for accelerating discovery and improving health. We also find that the use of LLMs, like ChatGPT, in the fields of biomedicine and health entails various risks and challenges, including fabricated information in its generated responses, as well as legal and privacy concerns associated with sensitive patient data. We believe this survey can provide a comprehensive and timely overview to biomedical researchers and healthcare practitioners on the opportunities and challenges associated with using ChatGPT and other LLMs for transforming biomedicine and health.",
        "link": "http://dx.doi.org/10.1093/bib/bbad493"
    },
    {
        "id": 14686,
        "title": "Application of the Long-term Health and Safety Monitoring System in a Very Large Bridge",
        "authors": "",
        "published": "2022-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i5(06).33"
    },
    {
        "id": 14687,
        "title": "Discussion on Selection and Design of Large-span Steel Truss Trestle in Coal Preparation Plant",
        "authors": "",
        "published": "2021-12-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i12.428"
    },
    {
        "id": 14688,
        "title": "The Impact of Internal Control and Audit Capability on the Value of Large Group Enterprises",
        "authors": "",
        "published": "2021-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/em.v2i10.20"
    },
    {
        "id": 14689,
        "title": "Improving Large-scale Paraphrase Acquisition and Generation",
        "authors": "Yao Dou, Chao Jiang, Wei Xu",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.631"
    },
    {
        "id": 14690,
        "title": "Performance of the Large Language Model ChatGPT on the National Nurse Examinations in Japan: Evaluation Study (Preprint)",
        "authors": "Kazuya Taira, Takahiro Itaya, Ayame Hanada",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nChatGPT, a large language model, has shown good performance on physician certification examinations and medical consultations. However, its performance has not been examined in languages other than English or on nursing examinations.\n\n\nOBJECTIVE\nWe aimed to evaluate the performance of ChatGPT on the Japanese National Nurse Examinations.\n\n\nMETHODS\nWe evaluated the percentages of correct answers provided by ChatGPT (GPT-3.5) for all questions on the Japanese National Nurse Examinations from 2019 to 2023, excluding inappropriate questions and those containing images. Inappropriate questions were pointed out by a third-party organization and announced by the government to be excluded from scoring. Specifically, these include “questions with inappropriate question difficulty” and “questions with errors in the questions or choices.” These examinations consist of 240 questions each year, divided into basic knowledge questions that test the basic issues of particular importance to nurses and general questions that test a wide range of specialized knowledge. Furthermore, the questions had 2 types of formats: simple-choice and situation-setup questions. Simple-choice questions are primarily knowledge-based and multiple-choice, whereas situation-setup questions entail the candidate reading a patient’s and family situation’s description, and selecting the nurse's action or patient's response. Hence, the questions were standardized using 2 types of prompts before requesting answers from ChatGPT. Chi-square tests were conducted to compare the percentage of correct answers for each year's examination format and specialty area related to the question. In addition, a Cochran-Armitage trend test was performed with the percentage of correct answers from 2019 to 2023.\n\n\nRESULTS\nThe 5-year average percentage of correct answers for ChatGPT was 75.1% (SD 3%) for basic knowledge questions and 64.5% (SD 5%) for general questions. The highest percentage of correct answers on the 2019 examination was 80% for basic knowledge questions and 71.2% for general questions. ChatGPT met the passing criteria for the 2019 Japanese National Nurse Examination and was close to passing the 2020-2023 examinations, with only a few more correct answers required to pass. ChatGPT had a lower percentage of correct answers in some areas, such as pharmacology, social welfare, related law and regulations, endocrinology/metabolism, and dermatology, and a higher percentage of correct answers in the areas of nutrition, pathology, hematology, ophthalmology, otolaryngology, dentistry and dental surgery, and nursing integration and practice.\n\n\nCONCLUSIONS\nChatGPT only passed the 2019 Japanese National Nursing Examination during the most recent 5 years. Although it did not pass the examinations from other years, it performed very close to the passing level, even in those containing questions related to psychology, communication, and nursing.\n",
        "link": "http://dx.doi.org/10.2196/preprints.47305"
    },
    {
        "id": 14691,
        "title": "Large-scale similarity search with Optimal Transport",
        "authors": "Cléa Laouar, Yuki Takezawa, Makoto Yamada",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.730"
    },
    {
        "id": 14692,
        "title": "Understanding Large Language Model Based Metrics for Text Summarization",
        "authors": "Abhishek Pradhan, Ketan Todi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.eval4nlp-1.12"
    },
    {
        "id": 14693,
        "title": "DiffusionBERT: Improving Generative Masked Language Models with Diffusion Models",
        "authors": "Zhengfu He, Tianxiang Sun, Qiong Tang, Kuanning Wang, Xuanjing Huang, Xipeng Qiu",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.248"
    },
    {
        "id": 14694,
        "title": "Large Language Model in Creative Work: The Role of Collaboration Modality and User Expertise",
        "authors": "Zenan Chen, Jason Chan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4575598"
    },
    {
        "id": 14695,
        "title": "Brief Introduction of Shallow Soil Jacking Construction Method of Large Section Rectangular Pipe Jacking Machine",
        "authors": "",
        "published": "2022-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i3(04).08"
    },
    {
        "id": 14696,
        "title": "VetLLM: Large Language Model for Predicting Diagnosis from Veterinary Notes",
        "authors": "Yixing Jiang, Jeremy A. Irvin, Andrew Y. Ng, James Zou",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811286421_0010"
    },
    {
        "id": 14697,
        "title": "Application and technology of an open source AI large language model in the medical field",
        "authors": "Tairui Zhang, Tianyi Feng",
        "published": "2023",
        "citations": 0,
        "abstract": "To explore the application prospects of an open source artificial intelligence (AI) large language model (LLM) in the medical field, we conducted an analysis from multiple dimensions, including the introduction of LLM, the classification of model types, and the status quo of the open source ecosystem development. The development of an open source LLM is currently in the rapid expansion phase, and there are many types of models and related tools. After analyzing the advantages and disadvantages of the models, we expounded feasible technical solutions for the application of an LLM in the medical field and made corresponding predictions. At present, LLMs in the medical field are still in the early stages, and there are still many problems related to ethics, technology, legal issues, and medical use.",
        "link": "http://dx.doi.org/10.15212/radsci-2023-0007"
    },
    {
        "id": 14698,
        "title": "Constructing Knowledge Graph from Cyber Threat Intelligence Using Large Language Model",
        "authors": "Jiehui Liu, Jieyu Zhan",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386611"
    },
    {
        "id": 14699,
        "title": "Redefining Crowdsourced Test Report Prioritization: An Innovative Approach with Large Language Model",
        "authors": "Yuchen Ling, Shengcheng Yu, Chunrong Fang, Guobin Pan, Jun Wang, Jia Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4741001"
    },
    {
        "id": 14700,
        "title": "Existing Problems and Improvement Measures in the Maintenance and Management of Large Medical Equipment",
        "authors": "",
        "published": "2022-8-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/mh.v3i8(05).07"
    },
    {
        "id": 14701,
        "title": "ArabicTransformer: Efficient Large Arabic Language Model with Funnel Transformer and ELECTRA Objective",
        "authors": "Sultan Alrowili, Vijay Shanker",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-emnlp.108"
    },
    {
        "id": 14702,
        "title": "VLIB: Unveiling insights through Visual and Linguistic Integration of Biorxiv data relevant to cancer via Multimodal Large Language Model",
        "authors": "Vignesh Prabhakar, Kai Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractThe field of cancer research has greatly benefited from the wealth of new knowledge provided by research articles and preprints on platforms like Biorxiv. This study investigates the role of scientific figures and their accompanying captions in enhancing our comprehension of cancer. Leveraging the capabilities of Multimodal Large Language Models (MLLMs), we conduct a comprehensive analysis of both visual and linguistic data in biomedical literature. Our work introduces VLIB, a substantial scientific figure-caption dataset generated from cancer biology papers on Biorxiv. After thorough preprocessing, which includes figure-caption pair extraction, sub-figure identification, and text normalization, VLIB comprises over 500,000 figures from more than 70,000 papers, each accompanied by relevant captions. We fine-tune baseline MLLMs using our VLIB dataset for downstream vision-language tasks, such as image captioning and visual question answering (VQA), to assess their performance. Our experimental results underscore the vital role played by scientific figures, including molecular structures, histological images, and data visualizations, in conjunction with their captions, in facilitating knowledge translation through MLLMs. Specifically, we achieved a ROUGE score of 0.66 for VQA and 0.68 for image captioning, as well as a BLEU score of 0.72 for VQA and 0.70 for image captioning. Furthermore, our investigation highlights the potential of MLLMs to bridge the gap between artificial intelligence and domain experts in the field of cancer biology.",
        "link": "http://dx.doi.org/10.1101/2023.10.31.565037"
    },
    {
        "id": 14703,
        "title": "Using Large Recent Corpora to Study Language Change",
        "authors": "Terttu Nevalainen",
        "published": "2020-7-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781118732168.ch13"
    },
    {
        "id": 14704,
        "title": "A prototype of a chatbot for evaluating and refining student startup ideas using a large language model",
        "authors": "Joseph Benjamin Rodriguez Ilagan, Jose Ramon Ilagan",
        "published": "No Date",
        "citations": 1,
        "abstract": "Assessing the soundness of business models is a critical skill for aspiring entrepreneurs and is an essential part of entrepreneurship education. However, evaluating business models can be time-consuming, costly, and subjective. This study describes the design and the prototype of a chatbot as a conversational intelligent tutoring system that assesses and gives feedback on business model soundness using natural language processing techniques and GPT-3.5, a large language model (LLM) trained by OpenAI, to help student co-founders learn and refine their startup ideas. Our method involves indexing articles and rubrics for evaluating technology startup pitches by extracting word embeddings via the OpenAI API. The chatbot accepts descriptions of startup businesses from student co-founders through a Telegram chatbot, and these are formatted as prompts and then fed into GPT-3.5. The responses are formulated by GPT-3 based on another set of prompts instructing the bot to give feedback from three virtual panelists: 1) a harsh judge, 2) a neutral expert, and 3) an optimistic investor.",
        "link": "http://dx.doi.org/10.35542/osf.io/azhf9"
    },
    {
        "id": 14705,
        "title": "Molformer: Large Scale Chemical Language Representations Capture Molecular Structure and Properties",
        "authors": "Jerret Ross, Brian Belgodere, Vijil Chenthamarakshan, Inkit Padhi, Youssef Mroueh, Payel Das",
        "published": "No Date",
        "citations": 4,
        "abstract": "Abstract\nPredicting the  properties of a chemical molecule is of great importance in many applications, including drug discovery and material design. Machine learning-based models promise to enable more accurate and faster molecular property predictions than the current state-of-the-art techniques, such as Density Functional Theory calculations or wet-lab experiments.Various supervised machine learning models, including graph neural nets, have demonstrated promising  performance in molecular property prediction tasks. However, the vast chemical space and the limited availability of property labels make supervised learning challenging, calling for learning a general-purpose molecular representation. Recently, unsupervised transformer-based language models pre-trained on large unlabeled corpus have produced state-of-the-art results in many downstream natural language processing tasks. Inspired by this development, we present molecular embeddings obtained by training an efficient transformer encoder model, MoLFormer, which uses rotary positional embeddings. This model employs a linear attention mechanism, coupled with highly distributed training, on SMILES sequences of 1.1 billion unlabeled molecules from the PubChem and ZINC datasets.Experiments show that utilizing the learned molecular representation outperforms existing baselines on downstream tasks, including supervised and self-supervised graph neural net baselines and language models, on several  classification and regression tasks from ten benchmark datasets while performing competitively on two others. Further analyses, specifically through the lens of attention, demonstrate that MoLFormer trained on chemical SMILES indeed learns the spatial relationships between atoms within a molecule. These results provide encouraging evidence that the large-scale molecular language models can capture sufficient  chemical and structural information to predict various distinct molecular properties, including quantum-chemical properties.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1570270/v1"
    },
    {
        "id": 14706,
        "title": "On the History of Models in American Linguistics",
        "authors": "Jacqueline Léon",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-55438-5_13"
    },
    {
        "id": 14707,
        "title": "Attitude Change Is Not Enough",
        "authors": "Rebecca Wheeler",
        "published": "2019-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678-19"
    },
    {
        "id": 14708,
        "title": "2. Models for Teaching English as an International Language",
        "authors": "",
        "published": "2020-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21832/9781788928199-005"
    },
    {
        "id": 14709,
        "title": "Error Causal inference for Multi-Fusion models",
        "authors": "Chengxi Li, Brent Harrison",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.alvr-1.2"
    },
    {
        "id": 14710,
        "title": "MODELS OF MENTORING IN LANGUAGE TEACHER EDUCATION",
        "authors": "Do Thi Xuan Hoa",
        "published": "2018-10-2",
        "citations": 0,
        "abstract": "Nguyen Thi Mai Hoa\r\nNew York: Springer, 2017 ",
        "link": "http://dx.doi.org/10.25073/2525-2445/vnufs.4313"
    },
    {
        "id": 14711,
        "title": "Coding and Computation",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.ch7"
    },
    {
        "id": 14712,
        "title": "Cultural Models: Learning How a Language Thinks",
        "authors": "Jacob Algrim",
        "published": "2020-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4208/it1.20200005"
    },
    {
        "id": 14713,
        "title": "Introduction",
        "authors": "Michelle D. Devereaux, Chris C. Palmer",
        "published": "2019-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678-1"
    },
    {
        "id": 14714,
        "title": "Probing Relational Knowledge in Language Models via Word Analogies",
        "authors": "Kiamehr Rezaee, Jose Camacho-Collados",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-emnlp.289"
    },
    {
        "id": 14715,
        "title": "Gesture Recognition in Indonesian Sign Language Using Hybrid Deep Learning Models",
        "authors": "Muhammad Yusuf Daffa Izzalhaqqi,  Wahyono",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iwis58789.2023.10284666"
    },
    {
        "id": 14716,
        "title": "Appendix 2: Representation of phonological structure in three models",
        "authors": "",
        "published": "2022-6-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110765694-011"
    },
    {
        "id": 14717,
        "title": "Formal Models of Neural Network and Deep Learning",
        "authors": "Zhiwei Feng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-5172-4_11"
    },
    {
        "id": 14718,
        "title": "Utilizing Language Models to Expand Vision-Based Commonsense Knowledge Graphs",
        "authors": "Navid Rezaei, Marek Z. Reformat",
        "published": "2022-8-17",
        "citations": 0,
        "abstract": "The introduction and ever-growing size of the transformer deep-learning architecture have had a tremendous impact not only in the field of natural language processing but also in other fields. The transformer-based language models have contributed to a renewed interest in commonsense knowledge due to the abilities of deep learning models. Recent literature has focused on analyzing commonsense embedded within the pre-trained parameters of these models and embedding missing commonsense using knowledge graphs and fine-tuning. We base our current work on the empirically proven language understanding of very large transformer-based language models to expand a limited commonsense knowledge graph, initially generated only on visual data. The few-shot-prompted pre-trained language models can learn the context of an initial knowledge graph with less bias than language models fine-tuned on a large initial corpus. It is also shown that these models can offer new concepts that are added to the vision-based knowledge graph. This two-step approach of vision mining and language model prompts results in the auto-generation of a commonsense knowledge graph well equipped with physical commonsense, which is human commonsense gained by interacting with the physical world. To prompt the language models, we adapted the chain-of-thought method of prompting. To the best of our knowledge, it is a novel contribution to the domain of the generation of commonsense knowledge, which can result in a five-fold cost reduction compared to the state-of-the-art. Another contribution is assigning fuzzy linguistic terms to the generated triples. The process is end to end in the context of knowledge graphs. It means the triples are verbalized to natural language, and after being processed, the results are converted back to triples and added to the commonsense knowledge graph.",
        "link": "http://dx.doi.org/10.3390/sym14081715"
    },
    {
        "id": 14719,
        "title": "Extending the Conversation",
        "authors": "Suzanne Loosen, Teaira McMurtry",
        "published": "2019-1-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678-20"
    },
    {
        "id": 14720,
        "title": "Explaining Code-Switching. Matrix Language Models vs. Bilingual Construction Grammar",
        "authors": "Philipp Wasserscheidt",
        "published": "2020-12",
        "citations": 1,
        "abstract": "This paper challenges the concept of matrix, base or basic language used in many descriptions and models of insertional code-switching. It proposes an account based on Construction Grammar and usage-based principles. At the heart of the paper is a discussion of four problematic issues of matrix-language approaches: the unitary conception of the notion of language, the generalization that syntactic frames mirror languages, the missing independent evidence for a matrix language and the narrow scope of the models that employ this term. The proposed approach of Bilingual Construction Grammar instead operates with a more complex, usage-based concept of language affiliation and places constructions in the centre of speech production. It thus avoids too coarse global predictions in favour of construction-specific predictions. This way, the matrix-language effect can be reinterpreted as by-product of constructional processing. Instead of using the term matrix language it is thus more appropriate to speak of matrix constructions.",
        "link": "http://dx.doi.org/10.33669/kj2020-31-04"
    },
    {
        "id": 14721,
        "title": "Authorship Attribution of Small Messages Through Language Models",
        "authors": "Antonio Theophilo, Anderson Rocha",
        "published": "2022-12-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wifs55849.2022.9975413"
    },
    {
        "id": 14722,
        "title": "Identifying and Reducing Gender Bias in Word-Level Language Models",
        "authors": "Shikha Bordia, Samuel R. Bowman",
        "published": "2019",
        "citations": 43,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/n19-3002"
    },
    {
        "id": 14723,
        "title": "Temporal predictive regression models for linguistic style analysis",
        "authors": "Carmen Klaussner, Carl Vogel",
        "published": "2018-8-31",
        "citations": 4,
        "abstract": "This paper presents work on modelling language change over time. In particular we use different feature types, i.e.~character, word stem, part-of-speech and word ngrams to predict the publication year of texts. We do this for two different corpora, one containing texts published over an approximately fifty year period, from two individual authors and one larger set containing a variety of text types and authors to approximate an average language style over time, for the same temporal span as the two authors.  Our linear regression models achieve good accuracy in the two authors case and very good results in the case of the reference set.",
        "link": "http://dx.doi.org/10.15398/jlm.v6i1.177"
    },
    {
        "id": 14724,
        "title": "Transformer-Based Deep Neural Network Language Models for Alzheimer's Disease Detection from Targeted Speech",
        "authors": "Alireza Roshanzamir, Hamid Aghajan, Mahdieh Soleymani Baghshah",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground: We developed transformer-based deep learning models based on natural language processing for early diagnosis of Alzheimer’s disease from the picture description test.Methods: The lack of large datasets poses the most important limitation for using complex models that do not require feature engineering. Transformer-based pre-trained deep language models have recently made a large leap in NLP research and application. These models are pre-trained on available large datasets to understand natural language texts appropriately, and are shown to subsequently perform well on classiﬁcation tasks with small training sets. The overall classiﬁcation model is a simple classiﬁer on top of the pre-trained deep language model.Results: The models are evaluated on picture description test transcripts of the Pitt corpus, which contains data of 170 AD patients with 257 interviews and 99 healthy controls with 243 interviews. The large bidirectional encoder representations from transformers (BERTLarge) embedding with logistic regression classiﬁer achieves classiﬁcation accuracy of 88.08%, which improves the state-of-the-art by 2.48%.Conclusions: Using pre-trained language models can improve AD prediction. This not only solves the problem of lack of suﬃciently large datasets, but also reduces the need for expert-deﬁned features.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-49267/v1"
    },
    {
        "id": 14725,
        "title": "Evaluating Tuning Strategies for Sequence Generation with Protein Language Models",
        "authors": "Andrea Nathansen, Kevin Klein, Bernhard Y. Renard, Melania Nowicka, Jakub M. Bartoszewicz",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractDesigning artificial proteins with specialized functions promises new solutions for biological, medical, and environmental use cases. This field benefits from advances in natural language processing, with state-of-the-art text generation models already being successfully applied to protein sequences. Openly available pre-trained protein language models are able to generate artificial protein sequences and can be finetuned on very specific tasks. Considering the high computational cost of finetuning a model exclusively for one downstream task, prompt tuning has been proposed as a more cost-efficient alternative that shares one model across different tasks. However, no openly available implementation of this approach compatible with protein language models has been previously published. Thus, we adapt an open-source codebase designed for NLP models to build a pipeline for prompt tuning on protein sequence data, supporting the protein language models ProtGPT2 and RITA. We benchmark this implementation for generating proteins of a specific family and evaluate the approach using text processing metrics as well as family membership prediction and protein activity prediction of generated sequences. Our results confirm the advantages of prompt tuning in resource usage, especially storage, encouraging further research and expansion of this technique to related use cases. For our evaluated use case, prompt tuning does not reach up to finetuning in terms of the quality of generated protein sequences, indicating the need for more extensive optimization. Lastly, we observe discrepancies between results of similar evaluation tools, highlighting open problems for principled assessment of protein sequence generation quality.",
        "link": "http://dx.doi.org/10.1101/2023.02.28.530492"
    },
    {
        "id": 14726,
        "title": "Effective Estimation of Deep Generative Language Models",
        "authors": "Tom Pelsmaeker, Wilker Aziz",
        "published": "2020",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.acl-main.646"
    },
    {
        "id": 14727,
        "title": "i-Vectors in Language Modeling: An Efficient Way of Domain Adaptation for Feed-Forward Models",
        "authors": "Karel Beneš, Santosh Kesiraju, Lukáš Burget",
        "published": "2018-9-2",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2018-1070"
    },
    {
        "id": 14728,
        "title": "Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for Propaganda and Disinformation Detection",
        "authors": "Yunze Xiao, Firoj Alam",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.arabicnlp-1.58"
    },
    {
        "id": 14729,
        "title": "Beyond Rating Scales: With Targeted Evaluation, Language Models are Poised for Psychological Assessment",
        "authors": "Oscar Nils Erik Kjell, Katarina Kjell, H. Andrew Schwartz",
        "published": "No Date",
        "citations": 1,
        "abstract": "In this narrative review, we survey recent empirical evaluations of AI-based language assessments and present a case for the technology of large language models to be poised for changing standardized psychological assessment. Artificial intelligence has been undergoing a purported “paradigm shift” initiated by new machine learning models, large language models (e.g., BERT, LAMMA, and that behind ChatGPT). These models have led to unprecedented accuracy over most computerized language processing tasks, from web searches to automatic machine translation and question answering, while their dialogue-based forms, like ChatGPT have captured the interest of over a million users. The success of the large language model is mostly attributed to its capability to numerically represent words in their context, long a weakness of previous attempts to automate psychological assessment from language. While potential applications for automated therapy are beginning to be studied on the heels of chatGPT’s success, here we present evidence that suggests, with thorough validation of targeted deployment scenarios, that AI’s newest technology can move mental health assessment away from rating scales and to instead use how people naturally communicate, in language.",
        "link": "http://dx.doi.org/10.31234/osf.io/yfd8g"
    },
    {
        "id": 14730,
        "title": "Sensitive remote homology search by local alignment of small positional embeddings from protein language models",
        "authors": "Sean R. Johnson, Meghana Peshwa, Zhiyi Sun",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractAccurately detecting distant evolutionary relationships between proteins remains an ongoing challenge in bioinformatics. Search methods based on primary sequence struggle to accurately detect homology between sequences with less than 20% amino acid identity. Profile- and structure-based strategies extend sensitive search capabilities into this twilight zone of sequence similarity but require slow pre-processing steps. Recently, whole-protein and positional embeddings from deep neural networks have shown promise for providing sensitive sequence comparison and annotation at long evolutionary distances. Embeddings are generally faster to compute than profiles and predicted structures but still suffer several drawbacks related to the ability of whole-protein embeddings to discriminate domain-level homology, and the database size and search speed of methods using positional embeddings. In this work, we show that low-dimensionality positional embeddings can be used directly in speed-optimized local search algorithms. As a proof of concept, we use the ESM2 3B model to convert primary sequences directly into the 3Di alphabet or amino acid profiles and use these embeddings as input to the highly optimized Foldseek, HMMER3, and HH-suite search algorithms. Our results suggest that positional embeddings as small as a single byte can provide sufficient information for dramatically improved sensitivity over amino acid sequence searches without sacrificing search speed.",
        "link": "http://dx.doi.org/10.1101/2023.07.26.550718"
    },
    {
        "id": 14731,
        "title": "An analysis of language models for metaphor recognition",
        "authors": "Arthur Neidlein, Philip Wiesenbach, Katja Markert",
        "published": "2020",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.coling-main.332"
    },
    {
        "id": 14732,
        "title": "A New Benchmark for NLP in Social Sciences: Evaluating the Usefulness of Pre-trained Language Models for Classifying Open-ended Survey Responses",
        "authors": "Maximilian Meidinger, Matthias Aßenmacher",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010255108660873"
    },
    {
        "id": 14733,
        "title": "Plurality Is a Good Start, but It's Time for Unification: A Commentary on “Computational Modeling of Bilingual Language Learning: Current Models and Future Directions”",
        "authors": "George Kachergis, Alvin Wei Ming Tan, Michael C. Frank",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/lang.12531"
    },
    {
        "id": 14734,
        "title": "Answer to the letter to the editor of H. Daungsupawong et al. concerning \"Large language models: Are artificial intelligence-based chatbots a reliable source of patient information for spinal surgery?” by R. Stroop et al. (Eur Spine J [2023]; doi:10.1007/s00586-023–07975-z)",
        "authors": "Ralf Stroop",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00586-023-08038-z"
    },
    {
        "id": 14735,
        "title": "In-Context Learning for Knowledge Base Question Answering for Unmanned Systems Based on Large Language Models",
        "authors": "Yunlong Chen, Yaming Zhang, Jianfei Yu, Li Yang, Rui Xia",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-7224-1_26"
    },
    {
        "id": 14736,
        "title": "Leveraging Large Language Models and Weak Supervision for Social Media Data Annotation: An Evaluation Using COVID-19 Self-reported Vaccination Tweets",
        "authors": "Ramya Tekumalla, Juan M. Banda",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-48044-7_26"
    },
    {
        "id": 14737,
        "title": "Évaluation de l’impact des large language learning models sur les articles soumis à Orthopedics &amp; Traumatology: Surgery &amp; Research (OTSR) : une augmentation significative de l’utilisation de l’intelligence artificielle en 2023",
        "authors": "Gaëlle Maroteau, Jae-Sung An, Jérome Murgier, Christophe Hulet, Matthieu Ollivier, Alexandre Ferreira",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.rcot.2023.10.014"
    },
    {
        "id": 14738,
        "title": "Integrating large language models in systematic reviews: a framework and case study using ROBINS-I for risk of bias assessment",
        "authors": "Bashar Hasan, Samer Saadi, Noora S Rajjoub, Moustafa Hegazi, Mohammad Al-Kordi, Farah Fleti, Magdoleen Farah, Irbaz B Riaz, Imon Banerjee, Zhen Wang, Mohammad Hassan Murad",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "Large language models (LLMs) may facilitate and expedite systematic reviews, although the approach to integrate LLMs in the review process is unclear. This study evaluates GPT-4 agreement with human reviewers in assessing the risk of bias using the Risk Of Bias In Non-randomised Studies of Interventions (ROBINS-I) tool and proposes a framework for integrating LLMs into systematic reviews. The case study demonstrated that raw per cent agreement was the highest for the ROBINS-I domain of ‘Classification of Intervention’. Kendall agreement coefficient was highest for the domains of ‘Participant Selection’, ‘Missing Data’ and ‘Measurement of Outcomes’, suggesting moderate agreement in these domains. Raw agreement about the overall risk of bias across domains was 61% (Kendall coefficient=0.35). The proposed framework for integrating LLMs into systematic reviews consists of four domains: rationale for LLM use, protocol (task definition, model selection, prompt engineering, data entry methods, human role and success metrics), execution (iterative revisions to the protocol) and reporting. We identify five basic task types relevant to systematic reviews: selection, extraction, judgement, analysis and narration. Considering the agreement level with a human reviewer in the case study, pairing artificial intelligence with an independent human reviewer remains required.",
        "link": "http://dx.doi.org/10.1136/bmjebm-2023-112597"
    },
    {
        "id": 14739,
        "title": "Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT",
        "authors": "Thilo Hagendorff, Sarah Fabi, Michal Kosinski",
        "published": "2023-10-5",
        "citations": 9,
        "abstract": "AbstractWe design a battery of semantic illusions and cognitive reflection tests, aimed to elicit intuitive yet erroneous responses. We administer these tasks, traditionally used to study reasoning and decision-making in humans, to OpenAI’s generative pre-trained transformer model family. The results show that as the models expand in size and linguistic proficiency they increasingly display human-like intuitive system 1 thinking and associated cognitive errors. This pattern shifts notably with the introduction of ChatGPT models, which tend to respond correctly, avoiding the traps embedded in the tasks. Both ChatGPT-3.5 and 4 utilize the input–output context window to engage in chain-of-thought reasoning, reminiscent of how people use notepads to support their system 2 thinking. Yet, they remain accurate even when prevented from engaging in chain-of-thought reasoning, indicating that their system-1-like next-word generation processes are more accurate than those of older models. Our findings highlight the value of applying psychological methodologies to study large language models, as this can uncover previously undetected emergent characteristics.",
        "link": "http://dx.doi.org/10.1038/s43588-023-00527-x"
    },
    {
        "id": 14740,
        "title": "Applications of Large Language Models (LLMs) in Business Analytics – Exemplary Use Cases in Data Preparation Tasks",
        "authors": "Mehran Nasseri, Patrick Brandtner, Robert Zimmermann, Taha Falatouri, Farzaneh Darbanian, Tobechi Obinwanne",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-48057-7_12"
    },
    {
        "id": 14741,
        "title": "Performance of Three Large Language Models on Dermatology Board Examinations",
        "authors": "Fatima N. Mirza, Rachel K. Lim, Sara Yumeen, Samer Wahood, Bashar Zaidat, Asghar Shah, Oliver Y. Tang, John Kawaoka, Su-Jean Seo, Christopher DiMarco, Jennie Muglia, Hayley S. Goldbach, Oliver Wisco, Abrar A. Qureshi, Tiffany J. Libby",
        "published": "2024-2",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jid.2023.06.208"
    },
    {
        "id": 14742,
        "title": "Evaluation of the impact of large language learning models on articles submitted to Orthopaedics &amp; Traumatology: Surgery &amp; Research (OTSR): A significant increase in the use of artificial intelligence in 2023",
        "authors": "Gaëlle Maroteau, Jae-Sung An, Jérome Murgier, Christophe Hulet, Matthieu Ollivier, Alexandre Ferreira",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.otsr.2023.103720"
    },
    {
        "id": 14743,
        "title": "Improving Adaptive Knowledge Graph Construction via Large Language Models with Multiple Views",
        "authors": "Yilong Chen, Shiyao Cui, Kun Huang, Shicheng Wang, Chuanyu Tang, Tingwen Liu, Binxing Fang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-7224-1_21"
    },
    {
        "id": 14744,
        "title": "Large Language Models Encode Radiation Oncology Domain Knowledge: Performance on the American College of Radiology Standardized Examination",
        "authors": "Nikhil G. Thaker, Navid Redjal, Arturo Loaiza-Bonilla, David Penberthy, Tim Showalter, Ajay Choudhri, Shirnett Williamson, Gautam Thaker, Chirag Shah, Matthew C. Ward, Mihir Thaker, Michael Arcaro",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1089/aipo.2023.0007"
    },
    {
        "id": 14745,
        "title": "CodonBERT: Large Language Models for mRNA design and optimization",
        "authors": "Sizhen Li, Saeed Moayedpour, Ruijiang Li, Michael Bailey, Saleh Riahi, Lorenzo Kogler-Anele, Milad Miladi, Jacob Miner, Dinghai Zheng, Jun Wang, Akshay Balsubramani, Khang Tran, Minnie Zacharia, Monica Wu, Xiaobo Gu, Ryan Clinton, Carla Asquith, Joseph Skaleski, Lianne Boeglin, Sudha Chivukula, Anusha Dias, Fernando Ulloa Montoya, Vikram Agarwal, Ziv Bar-Joseph, Sven Jager",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractmRNA based vaccines and therapeutics are gaining popularity and usage across a wide range of conditions. One of the critical issues when designing such mRNAs is sequence optimization. Even small proteins or peptides can be encoded by an enormously large number of mRNAs. The actual mRNA sequence can have a large impact on several properties including expression, stability, immunogenicity, and more. To enable the selection of an optimal sequence, we developed CodonBERT, a large language model (LLM) for mRNAs. Unlike prior models, CodonBERT uses codons as inputs which enables it to learn better representations. CodonBERT was trained using more than 10 million mRNA sequences from a diverse set of organisms. The resulting model captures important biological concepts. CodonBERT can also be extended to perform prediction tasks for various mRNA properties. CodonBERT outperforms previous mRNA prediction methods including on a new flu vaccine dataset.",
        "link": "http://dx.doi.org/10.1101/2023.09.09.556981"
    },
    {
        "id": 14746,
        "title": "Computer Models for Predicting Oral Proficiency and Intelligibility",
        "authors": "Okim Kang, David O. Johnson, Alyssa Kermad",
        "published": "2021-7-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003022695-9"
    },
    {
        "id": 14747,
        "title": "Text Summarization and Topic Models",
        "authors": "Dipanjan Sarkar",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-4354-1_6"
    },
    {
        "id": 14748,
        "title": "Accurate, interpretable predictions of materials properties within transformer language models",
        "authors": "Vadim Korolev, Pavel Protsenko",
        "published": "2023-10",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patter.2023.100803"
    },
    {
        "id": 14749,
        "title": "Text Classification of Modern Mongolian Documents Using BERT Models",
        "authors": "Garmaabazar Khaltarkhuu, Biligsaikhan Batjargal, Akira Maeda",
        "published": "2022-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ialp57159.2022.9961249"
    },
    {
        "id": 14750,
        "title": "A Study of Compressed Language Models in Social Media Domain",
        "authors": "Linrui Zhang, Belinda Copus",
        "published": "2023-5-8",
        "citations": 0,
        "abstract": "Transfer learning from large-scale language models is witnessing incredible growth and popularity in natural language processing (NLP). However, operating these large models always requires a huge amount of computational power and training effort. Many applications leveraging these large models are not very feasible for industrial products since applying them into power-scarce devices, such as mobile phone, is extremely challenging. In this case, model compression, i.e. transform deep and large networks to shallow and small ones, is becoming a popular research trend in NLP community. Currently, there are many techniques available, such as weight pruning and knowledge distillation. The primary concern regarding these techniques is how much of the language understanding capabilities will be retained by the compressed models in a particular domain? In this paper, we conducted a comparative analyses between several popular large-scale language models, such as BERT, RoBERTa, XLNet-Large and their compressed variants, e.g. Distilled BERT, Distilled RoBERTa and etc, and evaluated their performances on three datasets in the social media domain. Experimental results demonstrate that the compressed language models, though consume less computational resources, are able to achieve approximately the same level of language understanding capabilities as the large-scale language models in the social media domain.",
        "link": "http://dx.doi.org/10.32473/flairs.36.133056"
    },
    {
        "id": 14751,
        "title": "Models of Reading",
        "authors": "Shafinaz Ahmed, ZhaoHong Han",
        "published": "2018-1-18",
        "citations": 0,
        "abstract": "Reading is a process of decoding print and assigning meaning to it, and it happens for a variety of reasons—to obtain information, to communicate, for enjoyment, to name just a few. Second language reading research strives to understand what “good” first language readers do, and tries to guide second language instructors, learners, and readers in that direction (Grabe & Stoller, 2011). However, in order to effectively do so, an understanding of what reading is and its multifaceted nature, both in a reader's first as well as second language, is essential. This entry discusses several models of reading, and highlights the uniqueness—the dual relevance—of second language reading. Suggestions on how the dual relevance can be pedagogically fulfilled are also presented.",
        "link": "http://dx.doi.org/10.1002/9781118784235.eelt0477"
    },
    {
        "id": 14752,
        "title": "The Status of English in Language Policy Models Proposed for the Moroccan Multilingual Context",
        "authors": "Arab World English Journal, Khalid Shahu",
        "published": "No Date",
        "citations": 0,
        "abstract": "This paper suggests a language policy model for Modern Morocco, which can respond to both, the national needs of identity and the demands of Globalization, These two needs are the two major forces that shape the status of the various languages involved in the Moroccan sociolinguistic context, including English. The paper concisely describes how different sociolinguistic phenomenon produced by the ex-colonial powers shape the status of the different languages involved in the Moroccan multilingual context (i.e. language conflict, language competition, language selection and linguistic militantism). It also gives a detailed account of the different approaches and language policy models proposed by various Moroccan intellectuals and linguists in order to face such a de facto multilingualism. Finally, it proposes a multidimensional model that may contribute to reducing tensional relations between the different linguistic varieties cohabiting in Morocco, meeting the requirements of the Moroccan identity, and responding to the needs of modernity, prosperity, science and technology imposed by globalization.",
        "link": "http://dx.doi.org/10.31219/osf.io/5p6hp"
    },
    {
        "id": 14753,
        "title": "Related Existed Models",
        "authors": "Shuli Guo, Lina Han, Wentao Yang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-2665-7_2"
    },
    {
        "id": 14754,
        "title": "Using the Deep Learning Models and Surprisal for Language Analysis",
        "authors": "Sanghoun Song",
        "published": "2022-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.46397/jaih.12.1"
    },
    {
        "id": 14755,
        "title": "Do GPT Language Models Suffer From Split Personality Disorder? The Advent Of Substrate-Free Psychometrics",
        "authors": "Peter Romero, Stephen Fitz, Teruo Nakatsuma",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nPrevious research on emergence in large language models shows these display apparent human-like abilities and psychological latent traits.\n  However, results are partly contradicting in expression and magnitude of these latent traits, yet agree on the worrisome tendencies to score high on the Dark Triad of narcissism, psychopathy, and Machiavellianism, which, together with a track record of derailments, demands more rigorous research on safety of these models.\n  We provided a state of the art language model with the same personality questionnaire in nine languages, and performed Bayesian analysis of Gaussian Mixture Model, finding evidence for a deeper-rooted issue.\n  Our results suggest both interlingual and intralingual instabilities, which indicate that current language models do not develop a consistent core personality. \n  This can lead to unsafe behaviour of artificial intelligence systems that are based on these foundation models, and are increasingly integrated in human life.\n  We subsequently discuss the shortcomings of modern psychometrics, abstract it, and provide a framework for its species-neutral, substrate-free formulation.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2717108/v1"
    },
    {
        "id": 14756,
        "title": "Entropy and Information",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.ch5"
    },
    {
        "id": 14757,
        "title": "Equipartition and Universality",
        "authors": "",
        "published": "2020-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119625384.ch6"
    },
    {
        "id": 14758,
        "title": "Comparative Analysis of Image Classification Models for Norwegian Sign Language Recognition",
        "authors": "Benjamin Svendsen, Seifedine Kadry",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "Communication is integral to every human’s life, allowing individuals to express themselves and understand each other. This process can be challenging for the hearing-impaired population, who rely on sign language for communication due to the limited number of individuals proficient in sign language. Image classification models can be used to create assistive systems to address this communication barrier. This paper conducts a comprehensive literature review and experiments to find the state of the art in sign language recognition. It identifies a lack of research in Norwegian Sign Language (NSL). To address this gap, we created a dataset from scratch containing 24,300 images of 27 NSL alphabet signs and performed a comparative analysis of various machine learning models, including the Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Convolutional Neural Network (CNN) on the dataset. The evaluation of these models was based on accuracy and computational efficiency. Based on these metrics, our findings indicate that SVM and CNN were the most effective models, achieving accuracies of 99.9% with high computational efficiency. Consequently, the research conducted in this report aims to contribute to the field of NSL recognition and serve as a foundation for future studies in this area.",
        "link": "http://dx.doi.org/10.3390/technologies11040099"
    },
    {
        "id": 14759,
        "title": "Shades of meaning: Uncovering the geometry of ambiguous word representations through contextualised language models",
        "authors": "Benedetta Cevoli, Chris Watkins, Yang Gao, Kathleen Rastle",
        "published": "No Date",
        "citations": 1,
        "abstract": "Lexical ambiguity presents a profound and enduring challenge to the language sciences. Researchers for decades have grappled with the problem of how language users learn, represent and process words with more than one meaning. Our work offers new insight into psychological understanding of lexical ambiguity through a series of simulations that capitalise on recent advances in contextual language models. These models have no grounded understanding of the meanings of words at all; they simply learn to predict words based on the surrounding context provided by other words. Yet, our analyses show that their representations capture fine-grained meaningful distinctions between unambiguous, homonymous, and polysemous words that align with lexicographic classifications and psychological theorising. These findings provide quantitative support for modern psychological conceptualisations of lexical ambiguity and raise new challenges for understanding of the way that contextual information shapes the meanings of words across different timescales.",
        "link": "http://dx.doi.org/10.31234/osf.io/z8rmp"
    },
    {
        "id": 14760,
        "title": "Statistically Profiling Biases in Natural Language Reasoning Datasets and Models",
        "authors": "Shanshan Huang, Kenny Zhu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.299"
    },
    {
        "id": 14761,
        "title": "Two Challenges for ‘Neo-Sassurean’ Approaches to Morphosyntax",
        "authors": "Frederick J. Newmeyer",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5_4"
    },
    {
        "id": 14762,
        "title": "Democratizing Protein Language Models with Parameter-Efficient Fine-Tuning",
        "authors": "Samuel Sledzieski, Meghana Kshirsagar, Minkyung Baek, Bonnie Berger, Rahul Dodhia, Juan Lavista Ferres",
        "published": "No Date",
        "citations": 4,
        "abstract": "AbstractProteomics has been revolutionized by large pre-trained protein language models, which learn unsupervised representations from large corpora of sequences. The parameters of these models are then fine-tuned in a supervised setting to tailor the model to a specific downstream task. However, as model size increases, the computational and memory footprint of fine-tuning becomes a barrier for many research groups. In the field of natural language processing, which has seen a similar explosion in the size of models, these challenges have been addressed by methods for parameter-efficient fine-tuning (PEFT). In this work, we newly bring parameter-efficient fine-tuning methods to proteomics. Using the parameter-efficient method LoRA, we train new models for two important proteomic tasks: predicting protein-protein interactions (PPI) and predicting the symmetry of homooligomers. We show that for homooligomer symmetry prediction, these approaches achieve performance competitive with traditional fine-tuning while requiring reduced memory and using three orders of magnitude fewer parameters. On the PPI prediction task, we surprisingly find that PEFT models actually outperform traditional fine-tuning while using two orders of magnitude fewer parameters. Here, we go even further to show that freezing the parameters of the language model and training only a classification head also outperforms fine-tuning, using five orders of magnitude fewer parameters, and that both of these models outperform state-of-the-art PPI prediction methods with substantially reduced compute. We also demonstrate that PEFT is robust to variations in training hyper-parameters, and elucidate where best practices for PEFT in proteomics differ from in natural language processing. Thus, we provide a blueprint to democratize the power of protein language model tuning to groups which have limited computational resources.",
        "link": "http://dx.doi.org/10.1101/2023.11.09.566187"
    },
    {
        "id": 14763,
        "title": "Sequential Integrated Gradients: a simple but effective method for explaining language models",
        "authors": "Joseph Enguehard",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.477"
    },
    {
        "id": 14764,
        "title": "Injecting Descriptive Meta-Information into Pre-Trained Language Models with Hypernetworks",
        "authors": "Wenying Duan, Xiaoxi He, Zimu Zhou, Hong Rao, Lothar Thiele",
        "published": "2021-8-30",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-229"
    },
    {
        "id": 14765,
        "title": "LMPred: predicting antimicrobial peptides using pre-trained language models and deep learning",
        "authors": "William Dee",
        "published": "2022-1-10",
        "citations": 11,
        "abstract": "Abstract\n\nMotivation\nAntimicrobial peptides (AMPs) are increasingly being used in the development of new therapeutic drugs in areas such as cancer therapy and hypertension. Additionally, they are seen as an alternative to antibiotics due to the increasing occurrence of bacterial resistance. Wet-laboratory experimental identification, however, is both time-consuming and costly, so in silico models are now commonly used in order to screen new AMP candidates.\n\n\nResults\nThis paper proposes a novel approach for creating model inputs; using pre-trained language models to produce contextualized embeddings, representing the amino acids within each peptide sequence, before a convolutional neural network is trained as the classifier. The results were validated on two datasets—one previously used in AMP prediction research, and a larger independent dataset created by this paper. Predictive accuracies of 93.33% and 88.26% were achieved, respectively, outperforming previous state-of-the-art classification models.\n\n\nAvailability and implementation\nAll codes are available and can be accessed here: https://github.com/williamdee1/LMPred_AMP_Prediction.\n\n\nSupplementary information\nSupplementary data are available at Bioinformatics Advances online.\n",
        "link": "http://dx.doi.org/10.1093/bioadv/vbac021"
    },
    {
        "id": 14766,
        "title": "eP-ALM: Efficient Perceptual Augmentation of Language Models",
        "authors": "Mustafa Shukor, Corentin Dancette, Matthieu Cord",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.02016"
    },
    {
        "id": 14767,
        "title": "Analyzing Encoded Concepts in Transformer Language Models",
        "authors": "Hassan Sajjad, Nadir Durrani, Fahim Dalvi, Firoj Alam, Abdul Khan, Jia Xu",
        "published": "2022",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.225"
    },
    {
        "id": 14768,
        "title": "Looking into the Future of Natural Language Processing",
        "authors": "Jose Manuel Gomez-Perez, Ronald Denaux, Andres Garcia-Silva",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-44830-1_12"
    },
    {
        "id": 14769,
        "title": "Adaptability of Language Planning Models for Sri Lanka's Medium of Instruction in Higher Education Institutions: Challenges and Opportunities",
        "authors": "Niruba Sarath Jayasundara, Wijesekara Mudiyanselage Sumith Dananjaya",
        "published": "2023-8-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.9734/bpi/rhlle/v8/5630a"
    },
    {
        "id": 14770,
        "title": "Enhancing Chat Language Models by Scaling High-quality Instructional Conversations",
        "authors": "Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Shengding Hu, Zhiyuan Liu, Maosong Sun, Bowen Zhou",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.183"
    },
    {
        "id": 14771,
        "title": "Chapter 3. Analogy in action",
        "authors": "Adam Glaz",
        "published": "2022-10-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/hcp.73.03gla"
    },
    {
        "id": 14772,
        "title": "Prompt-and-Rerank: A Method for Zero-Shot and Few-Shot Arbitrary Textual Style Transfer with Small Language Models",
        "authors": "Mirac Suzgun, Luke Melas-Kyriazi, Dan Jurafsky",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.141"
    },
    {
        "id": 14773,
        "title": "The cave of shadows: Addressing the human factor with generalized additive mixed models",
        "authors": "Harald Baayen, Shravan Vasishth, Reinhold Kliegl, Douglas Bates",
        "published": "2017-6",
        "citations": 110,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jml.2016.11.006"
    },
    {
        "id": 14774,
        "title": "Arabizi Language Models for Sentiment Analysis",
        "authors": "Gaétan Baert, Souhir Gahbiche, Guillaume Gadek, Alexandre Pauchet",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.coling-main.51"
    },
    {
        "id": 14775,
        "title": "A Feature-Based Account of Weak Islands",
        "authors": "Christopher Laenzlinger, Gabriela Soare",
        "published": "2017",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5_2"
    },
    {
        "id": 14776,
        "title": "Profiling, Prejudice, and Prestige",
        "authors": "Stacy Ishigaki Arevalo",
        "published": "2019-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429486678-6"
    },
    {
        "id": 14777,
        "title": "Language Models Do Not Possess the Uniquely Human Cognitive Ability of Relational Abstraction",
        "authors": "Bradley Monk, Timothy Meyer, Mary Ngo",
        "published": "No Date",
        "citations": 0,
        "abstract": "Humans have a unique cognitive ability known as relational abstraction, which allows us to identify logical rules and patterns beyond basic perceptual characteristics. This ability represents a key difference between how humans and other animals learn and interact with the world. With current large language models rivaling human intelligence in many regards, we investigated whether relational abstraction was an emergent chat completion capacity in various models. We find that despite their impressive language processing skills, all tested language models failed the relational match-to-sample (RMTS) test, a benchmark for assessing relational abstraction. These results challenge the assumption that advanced language skills inherently confer the capacity for complex relational reasoning. The paper highlights the need for a broader evaluation of AI cognitive abilities, emphasizing that language proficiency alone may not be indicative of certain higher-order cognitive processes thought to be supported by language.",
        "link": "http://dx.doi.org/10.20944/preprints202401.1681.v1"
    },
    {
        "id": 14778,
        "title": "Prediction of virus-host associations using protein language models and multiple instance learning",
        "authors": "Dan Liu, Francesca Young, David L Robertson, Ke Yuan",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractPredicting virus-host associations is essential to determine the specific host species that viruses interact with, and discover if new viruses infect humans and animals. Currently, the host of the majority of viruses is unknown, particularly in microbiomes. To address this challenge, we introduce EvoMIL, a deep learning method that predicts the host species for viruses from viral sequences only. It also identifies important viral proteins that significantly contribute to host prediction. The method combines a pre-trained large protein language model (ESM) and attention-based multiple instance learning to allow protein-orientated predictions. Our results show that protein embeddings capture stronger predictive signals than sequence composition features, including amino acids, physiochemical properties, and DNA k-mers. In multi-host prediction tasks, EvoMIL achieves median F1 score improvements of 8.6%, 12.3%, and 4.1% in prokaryotic hosts, and 0.5%, 1.8% and 3% in eukaryotic hosts. EvoMIL binary classifiers achieve impressive AUC over 0.95 for all prokaryotic and range from roughly 0.8 to 0.9 for eukaryotic hosts. Furthermore, EvoMIL estimates the importance of single proteins in the prediction task and maps them to an embedding landscape of all viral proteins, where proteins with similar functions are distinctly clustered together, highlighting the ability of EvoMIL to capture key proteins in virus-host specificity.Author summaryBeing able to predict which viruses can infect which host species, and identifying the specific proteins that are involved in these interactions, are fundamental tasks in virology. Traditional methods for predicting these interactions rely on common manual features among proteins, overlooking the structure of the protein ”language” encoded in individual proteins. We have developed a novel method that combines a protein language model and multiple instance learning to allow host prediction directly from protein sequences, without the need to extract manual features. This method significantly improved prediction accuracy and revealed key proteins involved in virus-host interactions.",
        "link": "http://dx.doi.org/10.1101/2023.04.07.536023"
    },
    {
        "id": 14779,
        "title": "Preface",
        "authors": " B.S.",
        "published": "2021-5-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1fkgd2n.2"
    },
    {
        "id": 14780,
        "title": "Towards Cognition-Aligned Visual Language Models via\nZero-Shot Instance Retrieval",
        "authors": "Teng Ma, Daniel Organisciak, Wenbao Ma, Yang Long",
        "published": "No Date",
        "citations": 0,
        "abstract": "The pursuit of Artificial Intelligence (AI) that emulates human cognitive processes is a cornerstone of ethical AI development, ensuring that emerging technologies can integrate seamlessly into societal frameworks requiring nuanced understanding and decision-making. Zero-Shot Instance Retrieval (ZSIR) stands at the forefront of this endeavour, potentially providing a robust platform for AI systems, particularly large visual language models, to demonstrate and refine cognition-aligned learning without the need for direct experience. In this paper, we critically evaluate current cognition alignment methodologies within traditional zero-shot learning paradigms, using visual attributes and word embedding generated by large AI models. We propose a unified similarity function that quantifies the cognitive alignment level, bridging the gap between AI processes and human-like understanding. Through extensive experimentation, our findings illustrate that this similarity function can effectively mirror the visual-semantic gap, steering the model towards enhanced performance in zero-shot instance retrieval. This work not only benchmarks the cognition alignment of AI, but also sets a new precedent for the development of visual language models attuned to the complexities of human cognition.}",
        "link": "http://dx.doi.org/10.20944/preprints202403.0768.v1"
    },
    {
        "id": 14781,
        "title": "Investigating Transferability in Pretrained Language Models",
        "authors": "Alex Tamkin, Trisha Singh, Davide Giovanardi, Noah Goodman",
        "published": "2020",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.findings-emnlp.125"
    },
    {
        "id": 14782,
        "title": "Robot Behavior Tree Manipulation Using Language Models",
        "authors": "Zhuo Yang, Zhizhou Jia",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/itaic58329.2023.10409012"
    },
    {
        "id": 14783,
        "title": "Relation-based Counterfactual Data Augmentation and Contrastive Learning for Robustifying Natural Language Inference Models",
        "authors": "Heerin Yang, Seung-won Hwang, Jungmin So",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-277"
    },
    {
        "id": 14784,
        "title": "Multilingual Translation via Grafting Pre-trained Language Models",
        "authors": "Zewei Sun, Mingxuan Wang, Lei Li",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-emnlp.233"
    },
    {
        "id": 14785,
        "title": "Relevance-Based Language Models",
        "authors": "Victor Lavrenko, W. Bruce Croft",
        "published": "2017-8-2",
        "citations": 50,
        "abstract": "We explore the relation between classical probabilistic models of information retrieval and the emerging language modeling approaches. It has long been recognized that the primary obstacle to effective performance of classical models is the need to estimate a relevance model: probabilities of words in the relevant class. We propose a novel technique for estimating these probabilities using the query alone. We demonstrate that our technique can produce highly accurate relevance models, addressing important notions of synonymy and polysemy. Our experiments show relevance models outperforming baseline language modeling systems on TREC retrieval and TDT tracking tasks. The main contribution of this work is an effective formal method for estimating a relevance model with no training data.",
        "link": "http://dx.doi.org/10.1145/3130348.3130376"
    },
    {
        "id": 14786,
        "title": "Desafios e Inovações da IA Generativa: Large Language Model (LLM) e Engenharia de Prompt",
        "authors": "Wanderley Martins, Vinícius Gonçalves Martins",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.29327/5324257.1-7"
    },
    {
        "id": 14787,
        "title": "Language Matters -Representations of ‘heart failure’ in English discourse: a large-scale linguistic study",
        "authors": "Jane Demmen, Nick Hartshorne-Evans, Elena Semino, Rajiv Sankaranarayanan",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractAimsHeart failure (HF) has a lower public profile compared to other serious health conditions, notably cancer. This discourse analysis study investigates the extent to which HF is discussed in general contemporary English, UK parliamentary debates, and the ways in which HF is framed in discussions, when compared to two other serious health conditions, cancer and dementia.MethodsThe Oxford English Corpus of 21st century English-language texts (2 billion words) and the UK Hansard Reports of parliamentary debates from 1945 to early 2021 were used to investigate the relative frequencies, contexts of use of the terms ‘heart failure’, ‘cancer’ and ‘dementia’.ResultsIn the Oxford English Corpus, the term ‘heart failure’ occurs 4.26 times per million words (pmw), ‘dementia’ occurs 3.68 times pmw and ‘cancer’ occurs 81.96 times pmw. Cancer is talked about 19 times more often than HF and 22 times more often than dementia. These are disproportionately high in relation to actual incidence: annual cancer incidence is 1.8 times that of the other conditions; annual cancer mortality is twice that caused by coronary heart disease (including heart failure) or dementia.‘Heart failure’ is used much less than ‘cancer’ in UK parliamentary debates(House of Commons and House of Lords) between 1945 and early 2021, and less than ‘dementia’ from 1990 onwards. Moreover, HF is even mentioned much less than potholes in UK roads and pavements. In 2018, for example, ‘pothole/s’ were mentioned over 10 times pmw, 37 times more often than ‘heart failure’, mentioned 0.28 times pmw. Discussions of HF are comparatively technical and formulaic, lacking the survivor narratives that occur in discussions of cancer.ConclusionsHF is under-discussed in contemporary English compared to cancer and dementia. HF is also under-discussed in UK parliamentary debates, even compared to the less-obviously life threatening topic of potholes in roads and pavements.What is already known on this topicHeart failure is a serious health condition with significant morbidity and mortality, which is comparable to other serious health conditions such as cancer.What this study addsOur study has shown that heart failure is less frequently discussed in contemporary English as well as in UK parliamentary debates in comparison to other serious health conditions such as cancer and dementia, despite comparably significant adverse outcomes and also that discussions regarding people with heart failure are less empowering in comparison to discussions regarding cancer.How this study might affect research, practice or policy?Results of this study should motivate all stakeholders involved in heart failure to redouble their efforts to spread awareness regarding the seriousness of the condition in general discourse as well as to engage parliamentarians better and thereby exert influence upon commissioners to significantly improve investment in prevention, early diagnosis and better management of heart failure.",
        "link": "http://dx.doi.org/10.1101/2022.02.10.22270750"
    },
    {
        "id": 14788,
        "title": "A BLAST-based, Language-agnostic Text Reuse Algorithm with a MARKUS Implementation and Sequence Alignment Optimized for Large Chinese Corpora",
        "authors": "Paul Vierthaler, Mees Gelein",
        "published": "No Date",
        "citations": 1,
        "abstract": "Until relatively recently, following the life of a phrase or passage from its origin as it is quoted, reused, and remixed through a large corpus of Chinese writing was extremely difficult. Yet identifying how and when a document is appropriating materials from earlier works is critical in many domains. Establishing the source of a given sequence of words is not only important in industry (particularly in patent law), journalism, and academia (to detect and prevent plagiarism), but it is also valuable as an interpretive mechanism for those who study literary or historical documents. Developing consistent ways of tracing information movement through a corpus of documents helps scholars understand information networks, intellectual trends, and quotation practices.",
        "link": "http://dx.doi.org/10.31235/osf.io/7xpqe"
    },
    {
        "id": 14789,
        "title": "Evaluation of Prompts to Simplify Cardiovascular Disease Information Using a Large Language Model",
        "authors": "Vishala Mishra, Ashish Sarraju, Neil M. Kalwani, Joseph P. Dexter",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractAI chatbots powered by large language models (LLMs) are emerging as an important source of public-facing medical information. Generative models hold promise for producing tailored guidance at scale, which could advance health literacy and mitigate well-known disparities in the accessibility of health-protective information. In this study, we highlight an important limitation of basic approaches to AI-powered text simplification: when given a zero-shot or one-shot simplification prompt, GPT-4 often responds by omitting critical details. To address this limitation, we developed a new prompting strategy, which we term rubric prompting. Rubric prompts involve a combination of a zero-shot simplification prompt with brief reminders about important topics to address. Using rubric prompts, we generate recommendations about cardiovascular disease prevention that are more complete, more readable, and have lower syntactic complexity than baseline responses produced without prompt engineering. This analysis provides a blueprint for rigorous evaluation of AI model outputs in medicine.",
        "link": "http://dx.doi.org/10.1101/2023.11.08.23298225"
    },
    {
        "id": 14790,
        "title": "Effect and Analysis of Large-scale Language Model Rescoring on Competitive ASR Systems",
        "authors": "Takuma Udagawa, Masayuki Suzuki, Gakuto Kurata, Nobuyasu Itoh, George Saon",
        "published": "2022-9-18",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2022-11123"
    },
    {
        "id": 14791,
        "title": "BERT-XML: Large Scale Automated ICD Coding Using BERT Pretraining",
        "authors": "Zachariah Zhang, Jingshu Liu, Narges Razavian",
        "published": "2020",
        "citations": 31,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.clinicalnlp-1.3"
    },
    {
        "id": 14792,
        "title": "Models and Theories of Second Language Motivation: English Language Teachers Respond",
        "authors": "Desiree Autumn Midby, Stephanie Elisabeth Mugabonake, Kate Shea, Hayriye Kayi‐Aydar",
        "published": "2020-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/tesq.595"
    },
    {
        "id": 14793,
        "title": "Generic Mechanism for Reducing Repetitions in Encoder-decoder Models",
        "authors": "Ying Zhang, Hidetaka Kamigaito, Tatsuya Aoki, Hiroya Takamura, Manabu Okumura",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.30.401"
    },
    {
        "id": 14794,
        "title": "Making Pre-trained Language Models Better Learn Few-Shot Spoken Language Understanding in More Practical Scenarios",
        "authors": "Yufan Wang, Jie Mei, Bowei Zou, Rui Fan, Tingting He, Ai Ti Aw",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.853"
    },
    {
        "id": 14795,
        "title": "Exploring Mode Connectivity for Pre-trained Language Models",
        "authors": "Yujia Qin, Cheng Qian, Jing Yi, Weize Chen, Yankai Lin, Xu Han, Zhiyuan Liu, Maosong Sun, Jie Zhou",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.451"
    },
    {
        "id": 14796,
        "title": "Pay Attention to the Robustness of Chinese Minority Language Models! Syllable-level Textual Adversarial Attack on Tibetan Script",
        "authors": "Xi Cao, Dolma Dawa, Nuo Qun, Trashi Nyima",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.trustnlp-1.4"
    },
    {
        "id": 14797,
        "title": "Critical review of validation models and practices in language testing: their limitations and future directions for validation research",
        "authors": "Gwan-Hyeok Im, Dongil Shin, Liying Cheng",
        "published": "2019-12",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s40468-019-0089-4"
    },
    {
        "id": 14798,
        "title": "A Comparative Language Study",
        "authors": "Taryn Bipat",
        "published": "2020-10-17",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3406865.3418374"
    },
    {
        "id": 14799,
        "title": "Incorporating Structured Representations into Pretrained Vision &amp; Language Models Using Scene Graphs",
        "authors": "Roei Herzig, Alon Mendelson, Leonid Karlinsky, Assaf Arbelle, Rogerio Feris, Trevor Darrell, Amir Globerson",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.870"
    },
    {
        "id": 14800,
        "title": "What Context Features Can Transformer Language Models Use?",
        "authors": "Joe O’Connor, Jacob Andreas",
        "published": "2021",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.acl-long.70"
    },
    {
        "id": 14801,
        "title": "Assessing Language Skills Using Diagnostic Classification Models: An Example Using a Language Instrument",
        "authors": "Georgios D. Sideridis, Ioannis Tsaousis, Khaleel Al-Harbi",
        "published": "2022-9-12",
        "citations": 0,
        "abstract": "The primary purpose of the present study was to inform and illustrate, using examples, the use of Diagnostic Classification Models (DCMs) for the assessment of skills and competencies in cognition and academic achievement. A secondary purpose was to compare and contrast traditional and contemporary psychometrics for the measurement of skills and competencies. DCMs are described along the lines of other psychometric models within the Confirmatory Factor Analysis tradition, such as the bifactor model and the known mixture models that are utilized to classify individuals into subgroups. The inclusion of interaction terms and constraints along with its confirmatory nature enables DCMs to accurately assess the possession of skills and competencies. The above is illustrated using an empirical dataset from Saudi Arabia (n = 2,642), in which language skills are evaluated on how they conform to known levels of competency, based on the CEFR (Council of Europe, 2001) using the English Proficiency Test (EPT).",
        "link": "http://dx.doi.org/10.21500/20112084.5657"
    },
    {
        "id": 14802,
        "title": "How Conservative are Language Models? Adapting to the Introduction of Gender-Neutral Pronouns",
        "authors": "Stephanie Brandl, Ruixiang Cui, Anders Søgaard",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.265"
    },
    {
        "id": 14803,
        "title": "Using Morphological Knowledge in Open-Vocabulary Neural Language Models",
        "authors": "Austin Matthews, Graham Neubig, Chris Dyer",
        "published": "2018",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/n18-1130"
    },
    {
        "id": 14804,
        "title": "Test preparation pedagogy for international study: Relating teacher cognition, instructional models and academic writing skills",
        "authors": "Tony Clark, Guoxing Yu",
        "published": "2022-1-29",
        "citations": 2,
        "abstract": " There now exists an established body of work outlining the challenges international students can face as part of the acculturation process, including a range of academic and non-academic pressures to overcome. For many students, writing essays in academic English for the first time is problematic. This article considers pedagogical approaches for IELTS writing test preparation prior to university admission, and the potential for introducing academic writing skills at an earlier stage of students’ learning. Noting implications of test constructs, we investigate pedagogical support for candidates preparing for the writing section of IELTS. Conducted at a test preparation centre in China, observational data from courses across three proficiency levels provided the basis for inquiry, alongside interviews with teachers ( n = 2), students ( n = 20), and collating homework essays ( n = 50).  Results indicate that teacher cognition highly influenced pedagogical practice for writing test preparation at the centre involved. It was also evident that (despite variations) overall test preparation objectives were broadly similar. Additionally, higher proficiency learners appeared to be more receptive to – and capable of – learning about early-stage academic writing skills. We suggest a series of tentative recommendations for instructors and areas for future research, including looking at other major university entrance tests, newer ‘digital first’ tests, and the implications of online test preparation. ",
        "link": "http://dx.doi.org/10.1177/13621688211072381"
    },
    {
        "id": 14805,
        "title": "Detoxifying Language Models Risks Marginalizing Minority Voices",
        "authors": "Albert Xu, Eshaan Pathak, Eric Wallace, Suchin Gururangan, Maarten Sap, Dan Klein",
        "published": "2021",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.190"
    },
    {
        "id": 14806,
        "title": "DialCoT Meets PPO: Decomposing and Exploring Reasoning Paths in Smaller Language Models",
        "authors": "Chengcheng Han, Xiaowei Du, Che Zhang, Yixin Lian, Xiang Li, Ming Gao, Baoyuan Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.501"
    },
    {
        "id": 14807,
        "title": "Not all quantifiers are equal: Probing Transformer-based language models’ understanding of generalised quantifiers",
        "authors": "Tharindu Madusanka, Iqra Zahid, Hao Li, Ian Pratt-Hartmann, Riza Batista-Navarro",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.536"
    },
    {
        "id": 14808,
        "title": "ConvFiT: Conversational Fine-Tuning of Pretrained Language Models",
        "authors": "Ivan Vulić, Pei-Hao Su, Samuel Coope, Daniela Gerz, Paweł Budzianowski, Iñigo Casanueva, Nikola Mrkšić, Tsung-Hsien Wen",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.88"
    },
    {
        "id": 14809,
        "title": "Improving the Lexical Ability of Pretrained Language Models for Unsupervised Neural Machine Translation",
        "authors": "Alexandra Chronopoulou, Dario Stojanovski, Alexander Fraser",
        "published": "2021",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.16"
    },
    {
        "id": 14810,
        "title": "Trial Analysis of Application and Development of Innovative Models in Construction Project Management",
        "authors": "",
        "published": "2022-4-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v3i4(02).34"
    },
    {
        "id": 14811,
        "title": "Towards a Spreadsheet-Based Language Workbench",
        "authors": "Mikhail Barash",
        "published": "2021-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/models-c53483.2021.00102"
    },
    {
        "id": 14812,
        "title": "On Laws, Theories, and Models",
        "authors": "A. James Gregor",
        "published": "2020-3-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781351309288-6"
    },
    {
        "id": 14813,
        "title": "Anangu Literacy Practices Unsettle Northern Models of Literacy",
        "authors": "Janet Armitage",
        "published": "2022-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003007074-41"
    },
    {
        "id": 14814,
        "title": "Distilling Word Meaning in Context from Pre-trained Language Models",
        "authors": "Yuki Arase, Tomoyuki Kajiwara",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-emnlp.49"
    },
    {
        "id": 14815,
        "title": "A Neural Network approach for mixing language models",
        "authors": "Youssef Oualil, Dietrich Klakow",
        "published": "2017-3",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp.2017.7953250"
    },
    {
        "id": 14816,
        "title": "Learning Language, Culture, and Community",
        "authors": "Peggy Hashemipour",
        "published": "2023-6-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003448617-7"
    },
    {
        "id": 14817,
        "title": "Business Models in CMMN, DMN and ArchiMate language",
        "authors": "Malgorzata Pankowska",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.procs.2019.12.148"
    },
    {
        "id": 14818,
        "title": "Uni-Fold MuSSe: De Novo Protein Complex Prediction with Protein Language Models",
        "authors": "Jinhua Zhu, Zhenyu He, Ziyao Li, Guolin Ke, Linfeng Zhang",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractAccurately solving the structures of protein complexes is crucial for understanding and further modifying biological activities. Recent success of AlphaFold and its variants shows that deep learning models are capable of accurately predicting protein complex structures, yet with the painstaking effort of homology search and pairing. To bypass this need, we present Uni-Fold MuSSe (Multimer with Single Sequence inputs), which predicts protein complex structures from their primary sequences with the aid of pre-trained protein language models. Specifically, we built protein complex prediction models based on the protein sequence representations of ESM-2, a large protein language model with 3 billion parameters. In order to adapt the language model to inter-protein evolutionary patterns, we slightly modified and further pre-trained the language model on groups of protein sequences with known interactions. Our results highlight the potential of protein language models for complex prediction and suggest room for improvements.",
        "link": "http://dx.doi.org/10.1101/2023.02.14.528571"
    },
    {
        "id": 14819,
        "title": "Formal Models of Automatic Situation and Pragmatic Processing",
        "authors": "Zhiwei Feng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-5172-4_8"
    },
    {
        "id": 14820,
        "title": "Towards Language Models for AI Mental Health Assistant Design",
        "authors": "Cami Czejdo, Sambit Bhattacharya",
        "published": "2021-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/csci54926.2021.00252"
    },
    {
        "id": 14821,
        "title": "Language models for quantum simulation",
        "authors": "Roger G. Melko, Juan Carrasquilla",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s43588-023-00578-0"
    },
    {
        "id": 14822,
        "title": "Transformer-based deep neural network language models for Alzheimer’s disease detection from targeted speech",
        "authors": "Alireza Roshanzamir, Hamid Aghajan, Mahdieh Soleymani Baghshah",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground: We developed transformer-based deep learning models based on natural language processing for early diagnosis of Alzheimer’s disease from the picture description test.Methods: The lack of large datasets poses the most important limitation for using complex models that do not require feature engineering. Transformer-based pre-trained deep language models have recently made a large leap in NLP research and application. These models are pre-trained on available large datasets to understand natural language texts appropriately, and are shown to subsequently perform well on classification tasks with small training sets. The overall classification model is a simple classifier on top of the pre-trained deep language model.Results: The models are evaluated on picture description test transcripts of the Pitt corpus, which contains data of 170 AD patients with 257 interviews and 99 healthy controls with 243 interviews. The large bidirectional encoder representations from transformers (BERTLarge) embedding with logistic regression classifier achieves classification accuracy of 88.08%, which improves thestate-of-the-art by 2.48%.Conclusions: Using pre-trained language models can improve AD prediction. This not only solves the problem of lack of sufficiently large datasets, but also reduces the need for expert-defined features.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-49267/v2"
    },
    {
        "id": 14823,
        "title": "Context-Sensitive Visualization of Deep Learning Natural Language Processing Models",
        "authors": "Andrew Dunn, Diana Inkpen, Razvan Andonie",
        "published": "2021-7",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iv53921.2021.00035"
    },
    {
        "id": 14824,
        "title": "Discrete and Soft Prompting for Multilingual Models",
        "authors": "Mengjie Zhao, Hinrich Schütze",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.672"
    },
    {
        "id": 14825,
        "title": "Rationalism in the face of GPT hypes: Benchmarking the output of large language models against human expert-curated biomedical knowledge graphs",
        "authors": "Negin Sadat Babaiha, Sathvik Guru Rao, Jürgen Klein, Bruce Schultz, Marc Jacobs, Martin Hofmann-Apitius",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ailsci.2024.100095"
    },
    {
        "id": 14826,
        "title": "Large language models improve annotation of prokaryotic viral proteins",
        "authors": "Zachary N. Flamholz, Steven J. Biller, Libusha Kelly",
        "published": "2024-1-29",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41564-023-01584-8"
    },
    {
        "id": 14827,
        "title": "Parameter-efficient fine-tuning of large-scale pre-trained language models",
        "authors": "Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, Yusheng Su, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, Jing Yi, Weilin Zhao, Xiaozhi Wang, Zhiyuan Liu, Hai-Tao Zheng, Jianfei Chen, Yang Liu, Jie Tang, Juanzi Li, Maosong Sun",
        "published": "2023-3-2",
        "citations": 40,
        "abstract": "AbstractWith the prevalence of pre-trained language models (PLMs) and the pre-training–fine-tuning paradigm, it has been continuously shown that larger models tend to yield better performance. However, as PLMs scale up, fine-tuning and storing all the parameters is prohibitively costly and eventually becomes practically infeasible. This necessitates a new branch of research focusing on the parameter-efficient adaptation of PLMs, which optimizes a small portion of the model parameters while keeping the rest fixed, drastically cutting down computation and storage costs. In general, it demonstrates that large-scale models could be effectively stimulated by the optimization of a few parameters. Despite the various designs, here we discuss and analyse the approaches under a more consistent and accessible term ‘delta-tuning’, where ‘delta’ a mathematical notation often used to denote changes, is borrowed to refer to the portion of parameters that are ‘changed’ during training. We formally describe the problem and propose a unified categorization criterion for existing delta-tuning methods to explore their correlations and differences. We also discuss the theoretical principles underlying the effectiveness of delta-tuning and interpret them from the perspectives of optimization and optimal control. Furthermore, we provide a holistic empirical study on over 100 natural language processing tasks and investigate various aspects of delta-tuning. With comprehensive study and analysis, our research demonstrates the theoretical and practical properties of delta-tuning in the adaptation of PLMs.",
        "link": "http://dx.doi.org/10.1038/s42256-023-00626-4"
    },
    {
        "id": 14828,
        "title": "Code Soliloquies for Accurate Calculations in Large Language Models",
        "authors": "Shashank Sonkar, Xinghe Chen, Myco Le, Naiming Liu, Debshila Basu Mallick, Richard Baraniuk",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3636555.3636889"
    },
    {
        "id": 14829,
        "title": "Using a Large Language Model for Accounting Topic Classification",
        "authors": "Jenna Burke, Rani Hoitash, Udi Hoitash, Summer (Xia) Xiao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4484489"
    },
    {
        "id": 14830,
        "title": "Large Foundational Model is a Blessing to Natural Language Understanding and Data Mining",
        "authors": "Jiawei Han",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cogmi58952.2023.00009"
    },
    {
        "id": 14831,
        "title": "Large Language Model for Mental Health: A Systematic Review (Preprint)",
        "authors": "Zhijun Guo, Alvina Lai, Johan Thygesen, Joseph Farrington, Thomas Keen, Kezhi Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nLarge language models (LLMs) have received much attention and show their potential in digital health, while their application in mental health is subject to ongoing debate. This systematic review aims to summarize and characterize the use of LLMs in mental health by investigating the strengths and limitations of the latest work in LLMs and discusses the challenges and opportunities for early screening, digital interventions, and other clinical applications in mental health.\n\n\nOBJECTIVE\nThis systematic review aims to summarize how LLMs are used in mental health. We focus on the models, data sources, methodologies, and main outcomes in existing work, in order to assess the applicability of LLMs to early screening, digital interventions, and other clinical applications.\n\n\nMETHODS\nAdhering to the PRISMA guidelines, this review searched three open-access databases: PubMed, DBLP Computer Science Bibliography (DBLP), and IEEE Xplore (IEEE). Keywords used were: (mental health OR mental illness OR mental disorder OR psychology OR depression OR anxiety) AND (large language models OR LLMs OR GPT OR ChatGPT OR BERT OR Transformer OR LaMDA OR PaLM OR Claude). We included articles published between January 1, 2017, and September 1, 2023, and excluded non-English articles.\n\n\nRESULTS\nIn total, 32 articles were evaluated, including mental health analysis using social media datasets (n=13), LLMs usage for mental health chatbots (n=10), and other applications of LLMs in mental health (n=9). LLMs exhibit substantial effectiveness in classifying and detecting mental health issues and offer more efficient and personalized healthcare to improve telepsychological services. However, assessments also indicate that the current risks associated with the clinical use might surpass their benefits. These risks include inconsistencies in generated text, the production of hallucinatory content, and the absence of a comprehensive ethical framework.\n\n\nCONCLUSIONS\nThis systematic review examines the clinical applications of LLMs in mental health, highlighting their potential and their inherent risks. The study identifies significant concerns, including inherent biases in training data, ethical dilemmas, challenges in interpreting the 'black box' nature of LLMs, and concerns about the accuracy and reliability of the content they produce. Consequently, LLMs should not be considered substitutes for professional mental health services. Despite these challenges, the rapid advancement of LLMs may highlight their potential as new clinical tools, emphasizing the need for continued research and development in this field.\n",
        "link": "http://dx.doi.org/10.2196/preprints.57400"
    },
    {
        "id": 14832,
        "title": "Comparative Analysis of Automatic Literature Review Using Mistral Large Language Model and Human Reviewers",
        "authors": "Hsiao-Ching Tsai, Yueh-Fen Huang, Chih-Wei Kuo",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThis study evaluates the effectiveness of the Mistral Large Language Model (LLM), enhanced with Retrieval-Augmented Generation (RAG), in automating the process of conducting literature reviews, comparing its performance with traditional human-led review processes. Through a methodical analysis of 50 scientific papers from the OpenReview platform, the study investigates the model's efficiency, scalability, and quality of review, including coherence, relevance, and analytical depth. The findings indicate that while the Mistral LLM significantly surpasses human efforts in terms of efficiency and scalability, it occasionally lacks the analytical depth and attention to detail that characterize human reviews. Despite these limitations, the model demonstrates considerable potential in standardizing preliminary literature reviews, suggesting a hybrid approach where Mistral LLM's capabilities are integrated with human expertise to enhance the literature review process. The study underscores the necessity for further advancements in AI technology to achieve deeper analytical insights and highlights the importance of addressing ethical concerns and biases in AI-assisted research. The integration of LLMs like Mistral presents a promising avenue for redefining academic research methodologies, pointing towards a future where AI and human intelligence collaborate to advance scholarly discourse.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-4022248/v1"
    },
    {
        "id": 14833,
        "title": "DB-GPT: Large Language Model Meets Database",
        "authors": "Xuanhe Zhou, Zhaoyan Sun, Guoliang Li",
        "published": "2024-1-19",
        "citations": 0,
        "abstract": "AbstractLarge language models (LLMs) have shown superior performance in various areas. And LLMs have the potential to revolutionize data management by serving as the \"brain\" of next-generation database systems. However, there are several challenges that utilize LLMs to optimize databases. First, it is challenging to provide appropriate prompts (e.g., instructions and demonstration examples) to enable LLMs to understand the database optimization problems. Second, LLMs only capture the logical database characters (e.g., SQL semantics) but are not aware of physical characters (e.g., data distributions), and it requires to fine-tune LLMs to capture both physical and logical information. Third, LLMs are not well trained for databases with strict constraints (e.g., query plan equivalence) and privacy-preserving requirements, and it is challenging to train database-specific LLMs while ensuring database privacy. To overcome these challenges, this vision paper proposes a LLM-based database framework (), including automatic prompt generation, DB-specific model fine-tuning, and DB-specific model design and pre-training. Preliminary experiments show that  achieves relatively good performance in database tasks like query rewrite and index tuning. The source code and datasets are available at github.com/TsinghuaDatabaseGroup/DB-GPT.",
        "link": "http://dx.doi.org/10.1007/s41019-023-00235-6"
    },
    {
        "id": 14834,
        "title": "Which Large Language Model should You Use in Vietnamese Education: ChatGPT, Bing Chat, or Bard?",
        "authors": "Xuan-Quy DAO",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4527476"
    },
    {
        "id": 14835,
        "title": "Capturing Formulation Design of Battery Electrolytes with Chemical Large Language Model",
        "authors": "Eduardo Soares, Vidushi Sharma, Emilio Vital Brazil, Young-Hye Na, Renato Cerqueira",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nRecent progress in large transformers-based foundation models have demonstrated impressive capabilities in mastering complex chemical language representations. These models show promise in learning task-agnostic chemical language representations through a two-step process: pre-training on extensive unlabeled corpora and fine-tuning on specific downstream tasks. By utilizing self-supervised learning capabilities, foundation models have significantly reduced the reliance on labeled data and task-specific features, streamlining data acquisition and pushing the boundaries of chemical language representation. However, their practical implementation in further downstream tasks is still in its early stages and largely limited to sequencing problems. The proposed multimodal approach using MoLFormer, a chemical large language model,  aims to demonstrate the capabilities of transformer based models to non-sequencing applications such as capturing design space of liquid formulations. Multimodal MoLFormer utilizes the extensive chemical information learned in pre-training from unlabeled corpora for predicting performance of battery electrolytes and showcases superior performance compared to state-of-the-art algorithms. The potential of foundation models in designing mixed material systems such as liquid formulations presents a groundbreaking opportunity to accelerate the discovery and optimization of new materials and formulations across various industries.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3593035/v1"
    },
    {
        "id": 14836,
        "title": "Controllable Speaking Styles Using A Large Language Model",
        "authors": "Atli Sigurgeirsson, Simon King",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10448400"
    },
    {
        "id": 14837,
        "title": "Extracting Design Models from Natural Language Descriptions",
        "authors": "Walling R. Cyre",
        "published": "2020-1-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780429332197-19"
    },
    {
        "id": 14838,
        "title": "Research on the Innovation of Junior High School Physics Teaching Models and Methods",
        "authors": "",
        "published": "2021-8-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/es.v2i8.38"
    },
    {
        "id": 14839,
        "title": "Span Fine-tuning for Pre-trained Language Models",
        "authors": "Rongzhou Bao, Zhuosheng Zhang, Hai Zhao",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-emnlp.169"
    },
    {
        "id": 14840,
        "title": "Three Models for Linguistics: Newtonian Mechanics, Darwinism, Axiomatics",
        "authors": "Esa Itkonen",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-55438-5_8"
    },
    {
        "id": 14841,
        "title": "The R Programming Language and Software",
        "authors": "Daniel Wallach, David Makowski, James W. Jones, François Brun",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811756-9.00002-2"
    },
    {
        "id": 14842,
        "title": "Teacher and Student Models of Offensive Language in Social Media",
        "authors": "Tharindu Ranasinghe, Marcos Zampieri",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.241"
    },
    {
        "id": 14843,
        "title": "Information Extraction and Text Transforming Models",
        "authors": "Jyotika Singh",
        "published": "2023-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003264774-7"
    },
    {
        "id": 14844,
        "title": "Adding temporal dynamics to models of impaired language production",
        "authors": "Nadine Martin, Gary Dell",
        "published": "2017",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3389/conf.fnhum.2017.223.00110"
    },
    {
        "id": 14845,
        "title": "Character-Level Chinese Backpack Language Models",
        "authors": "Hao Sun, John Hewitt",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.blackboxnlp-1.8"
    },
    {
        "id": 14846,
        "title": "Partitioning of Posteriorgrams Using Siamese Models for Unsupervised Acoustic Modelling",
        "authors": "Arvid Fahlström Myrman, Giampiero Salvi",
        "published": "2017-8-25",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/glu.2017-6"
    },
    {
        "id": 14847,
        "title": "Identification and Detection of Human Trafficking Using Language Models",
        "authors": "Jessica Zhu, Lin Li, Cara Jones",
        "published": "2019-11",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/eisic49498.2019.9108860"
    },
    {
        "id": 14848,
        "title": "ChemGLaM: Chemical-Genomics Language Models for Compound-Protein Interaction Prediction",
        "authors": "Takuto Koyama, Hayato Tsumura, Shigeyuki Matsumoto, Ryunosuke Okita, Ryosuke Kojima, Yasushi Okuno",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractAccurate prediction of compound-protein interaction (CPI) is of great importance for drug discovery. For creating generalizable CPI prediction deep learning (DL) models, the expansion of CPI data through experimental validation is crucial. However, the cost associated with these experimental validations is a bottleneck. Recently developed large language models (LLMs) such as chemical language models (CLMs) and protein language models (PLMs) have emerged as foundation models, demonstrating high generalization performance in various tasks involving compounds and proteins. Inspired by this, we propose a chemical-genomics language model, ChemGLaM, for predicting compound-protein interactions. ChemGLaM is based on the 2 independent language models, MoLFormer for compounds and ESM-2 for proteins, and fine-tuned for the CPI datasets using an interaction block with a cross-attention mechanism. ChemGLaM is capable of predicting interactions between unknown compounds and proteins with higher accuracy than existing CPI prediction models, demonstrating that combining the independently pre-trained foundation models is effective for obtaining sophisticated representation of compound-protein interactions. Furthermore, visualizing the learned cross-attention map can offer explainable insights into the mechanism of compound-protein interaction. This study emphasizes the potential of integrating the independent foundation models for the tasks of multi-modality such as CPI prediction.",
        "link": "http://dx.doi.org/10.1101/2024.02.13.580100"
    },
    {
        "id": 14849,
        "title": "Offensive Language Detection in Turkish Tweets with Bert Models",
        "authors": "Anil Ozberk, Ilyas Cicekli",
        "published": "2021-9-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ubmk52708.2021.9559000"
    },
    {
        "id": 14850,
        "title": "Language Models Learn POS First",
        "authors": "Naomi Saphra, Adam Lopez",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-5438"
    },
    {
        "id": 14851,
        "title": "Controllable protein design with language models",
        "authors": "Noelia Ferruz, Birte Höcker",
        "published": "2022-6-22",
        "citations": 74,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s42256-022-00499-z"
    },
    {
        "id": 14852,
        "title": "Applying Protein Language Models Using Limited Dataset. Sequence-Based Hot Spot Prediction in Protein Interactions Using AutoGluon",
        "authors": "Karen Sargsyan, Carmay Lim",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground\n Protein language models, inspired by the success of large language models in deciphering human language, have emerged as powerful tools for unraveling the intricate code of life inscribed within protein sequences. They have gained significant attention for their promising applications across various areas, including the sequence-based prediction of secondary and tertiary protein structure, the discovery of new functional protein sequences/folds, and the assessment of mutational impact on protein fitness. However, their utility in learning to predict protein residue properties based on scant datasets, such as protein-protein interaction (PPI)-hotspots whose mutations significantly impair PPIs, remained unclear. Here, we explore the feasibility of using protein language-learned representations as features for machine learning to predict PPI hotspots using a dataset containing 414 experimentally confirmed PPI-hot spots and 504 PPI-nonhot spots.\nResults\n Our findings showcase the capacity of unsupervised learning with protein language models in capturing critical functional attributes of protein residues derived from the evolutionary information encoded within amino acid sequences. We show that methods relying on protein language models can compete with methods employing sequence and structure-based features to predict PPI hotspots from the free protein structure. We observed an optimal number of features for model precision, suggesting a balance between information and overfitting.\nConclusions\n This study underscores the potential of transformer-based protein language models to extract critical knowledge from sparse datasets, exemplified here by the challenging realm of predicting PPI hotspots. These models offer a cost-effective and time-efficient alternative to traditional experimental methods for predicting certain residue properties. However, the challenge of explaining the importance of specific features in determining residue properties remains.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3830911/v1"
    },
    {
        "id": 14853,
        "title": "Does Pre-training Induce Systematic Inference? How Masked Language Models Acquire Commonsense Knowledge",
        "authors": "Ian Porada, Alessandro Sordoni, Jackie Cheung",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.337"
    },
    {
        "id": 14854,
        "title": "Structural Supervision Improves Few-Shot Learning and Syntactic Generalization in Neural Language Models",
        "authors": "Ethan Wilcox, Peng Qian, Richard Futrell, Ryosuke Kohita, Roger Levy, Miguel Ballesteros",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.375"
    },
    {
        "id": 14855,
        "title": "LowResourceNLU at BLP-2023 Task 1 &amp; 2: Enhancing Sentiment Classification and Violence Incitement Detection in Bangla Through Aggregated Language Models",
        "authors": "Hariram Veeramani, Surendrabikram Thapa, Usman Naseem",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.banglalp-1.29"
    },
    {
        "id": 14856,
        "title": "Mavericks at BLP-2023 Task 1: Ensemble-based Approach Using Language Models for Violence Inciting Text Detection",
        "authors": "Saurabh Page, Sudeep Mangalvedhekar, Kshitij Deshpande, Tanmay Chavan, Sheetal Sonawane",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.banglalp-1.22"
    },
    {
        "id": 14857,
        "title": "Calibrating Student Models for Emotion-related Tasks",
        "authors": "Mahshid Hosseini, Cornelia Caragea",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.629"
    },
    {
        "id": 14858,
        "title": "A Self-Supervised Integration Method of Pretrained Language Models and Word Definitions",
        "authors": "Hwiyeol Jo",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.2"
    },
    {
        "id": 14859,
        "title": "A Multi-dimensional study on Bias in Vision-Language models",
        "authors": "Gabriele Ruggeri, Debora Nozza",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.403"
    },
    {
        "id": 14860,
        "title": "Cultural Models: Learning How a Language Thinks",
        "authors": "Jacob Algrim",
        "published": "2020-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4208/itl.20200005"
    },
    {
        "id": 14861,
        "title": "Automatically Exposing Problems with Neural Dialog Models",
        "authors": "Dian Yu, Kenji Sagae",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.37"
    },
    {
        "id": 14862,
        "title": "The Status of English in Language Policy Models Proposed for the Moroccan Multilingual Context",
        "authors": "Khalid Shahu",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2895536"
    },
    {
        "id": 14863,
        "title": "Understanding the Models of Grammar",
        "authors": "Ratna Andhika Mahaputri",
        "published": "2018-10-26",
        "citations": 0,
        "abstract": "This article provides comprehensive explanation about several models of grammar. The first model of grammar which is explained is considered from the functional grammar and associated with the American linguist Noam Chomsky that is Transformational Grammar. This model of grammar is consisted of three components they are phrase structure rule, the lexicon, and transformation. The second model of grammar which is explained in this article is Minimalist Grammar. This article also compares her understanding in two models of grammar they are Transformational Grammar and Minimalist Grammar.",
        "link": "http://dx.doi.org/10.33603/perspective.v1i1.1603"
    },
    {
        "id": 14864,
        "title": "Using Language Models to Augment Data in Stock Prediction",
        "authors": "Yuteng Hou",
        "published": "2023-12-6",
        "citations": 0,
        "abstract": "This paper delves into the innovative application of language models as a means of enhancing data augmentation techniques in the context of Sentiment Analysis for Event-Driven Stock Prediction. In recent years, the integration of natural language processing and machine learning has led to significant advancements in sentiment analysis, enabling the extraction of valuable insights from textual data for enhancing stock prediction accuracy. In this work, we incorporate T-5 language model to enrich the training dataset with semantically diverse and contextually relevant textual variations. By conducting extensive experimental results, we demonstrate the effectiveness of using T-5 for data augmentation in the task of Sentiment Analysis for Event-Driven Stock Prediction..",
        "link": "http://dx.doi.org/10.56028/aemr.8.1.298.2023"
    },
    {
        "id": 14865,
        "title": "Extracting Latent Steering Vectors from Pretrained Language Models",
        "authors": "Nishant Subramani, Nivedita Suresh, Matthew Peters",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-acl.48"
    },
    {
        "id": 14866,
        "title": "Modulating Language Models with Emotions",
        "authors": "Ruibo Liu, Jason Wei, Chenyan Jia, Soroush Vosoughi",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-acl.379"
    },
    {
        "id": 14867,
        "title": "Sequence-Structure Embeddings via Protein Language Models Improve on Prediction Tasks",
        "authors": "Anowarul Kabir, Amarda Shehu",
        "published": "2022-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ickg55886.2022.00021"
    },
    {
        "id": 14868,
        "title": "Using Language-Based and Generative Deep Learning Models for Encoding Design Intentions and Modifying Architectural Design",
        "authors": "Shermeen Yousif,  ",
        "published": "2022",
        "citations": 0,
        "abstract": "Artificial intelligence models are moving design exploration beyond the deterministic rule-based parametric systems by offering new possibilities and expanding the design space, which has become more flexible and adaptive to change. Yet, the fact that AI models are independently learning on their own, raises issues with designers’ control over the process. More recently, models that bridge natural language processing and computer-vision such as Contrastive Language-Image Pre-Training (CLIP) have been integrated into generative deep learning models such as StyleGAN, combining the generative and classification functionalities. This way, to some degree, a certain level of designer’s agency can be attained when using text prompts to modify the generative process, which was the motivation of this work. We investigate here the issue of prototyping a new design system with employing language-based models and deep learning models into an expanded design space towards informing design revision and modification. Our methodology involves experimenting with the targeted deep learning models, prototyping a new framework with language-based models are integrated into the generative process, and testing the prototype by applying the proposed system to a design case. As a result of experimentation, the generative model was modified using a set of text-prompts that describe the intended design alteration. Overall, the results show successful approaches to guiding the generative process and informing design revision, and offer insights into associated potentials and limitations, as discussed in the paper.",
        "link": "http://dx.doi.org/10.35483/acsa.am.110.32"
    },
    {
        "id": 14869,
        "title": "Protein language models guide directed antibody evolution",
        "authors": "Arunima Singh",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41592-023-01924-w"
    },
    {
        "id": 14870,
        "title": "Language Models Do Not Possess the Uniquely Human Cognitive Ability of Relational Abstraction",
        "authors": "Bradley Monk, Timothy Meyer, Mary Ngo",
        "published": "No Date",
        "citations": 0,
        "abstract": "Humans have a unique cognitive ability known as relational abstraction, which allows us to identify logical rules and patterns beyond basic perceptual characteristics. This ability represents a key difference between how humans and other animals learn and interact with the world. With current large language models rivaling human intelligence in many regards, we investigated whether relational abstraction was an emergent chat completion capacity in various models. We find that despite their impressive language processing skills, all tested language models failed the relational match-to-sample (RMTS) test, a benchmark for assessing relational abstraction. These results challenge the assumption that advanced language skills inherently confer the capacity for complex relational reasoning. The paper highlights the need for a broader evaluation of AI cognitive abilities, emphasizing that language proficiency alone may not be indicative of certain higher-order cognitive processes thought to be supported by language.",
        "link": "http://dx.doi.org/10.20944/preprints202401.1681.v2"
    },
    {
        "id": 14871,
        "title": "Building and Interpreting Ad Hoc Categories: A Linguistic Analysis",
        "authors": "Caterina Mauri",
        "published": "2017",
        "citations": 31,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-48832-5_16"
    },
    {
        "id": 14872,
        "title": "Sensitive remote homology search by local alignment of small positional embeddings from protein language models",
        "authors": "Sean R. Johnson, Meghana Peshwa, Zhiyi Sun",
        "published": "No Date",
        "citations": 0,
        "abstract": "Accurately detecting distant evolutionary relationships between proteins remains an ongoing challenge in bioinformatics. Search methods based on primary sequence struggle to accurately detect homology between sequences with less than 20% amino acid identity. Profile- and structure-based strategies extend sensitive search capabilities into this twilight zone of sequence similarity but require slow pre-processing steps. Recently, whole-protein and positional embeddings from deep neural networks have shown promise for providing sensitive sequence comparison and annotation at long evolutionary distances. Embeddings are generally faster to compute than profiles and predicted structures but still suffer several drawbacks related to the ability of whole-protein embeddings to discriminate domain-level homology, and the database size and search speed of methods using positional embeddings. In this work, we show that low-dimensionality positional embeddings can be used directly in speed-optimized local search algorithms. As a proof of concept, we use the ESM2 3B model to convert primary sequences directly into the 3Di alphabet or amino acid profiles and use these embeddings as input to the highly optimized Foldseek, HMMER3, and HH-suite search algorithms. Our results suggest that positional embeddings as small as a single byte can provide sufficient information for dramatically improved sensitivity over amino acid sequence searches without sacrificing search speed.",
        "link": "http://dx.doi.org/10.7554/elife.91415.1"
    },
    {
        "id": 14873,
        "title": "Unsupervised Domain Clusters in Pretrained Language Models",
        "authors": "Roee Aharoni, Yoav Goldberg",
        "published": "2020",
        "citations": 23,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.acl-main.692"
    },
    {
        "id": 14874,
        "title": "Frequency Balanced Datasets Lead to Better Language Models",
        "authors": "Rodolfo Zevallos, Mireia Farrús, Núria Bel",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.527"
    },
    {
        "id": 14875,
        "title": "VariPred: Enhancing Pathogenicity Prediction of Missense Variants Using Protein Language Models",
        "authors": "Weining Lin, Jude Wells, Zeyuan Wang, Christine Orengo, Andrew C.R. Martin",
        "published": "No Date",
        "citations": 3,
        "abstract": "AbstractComputational approaches for predicting the pathogenicity of genetic variants have advanced in recent years. These methods enable researchers to determine the possible clinical impact of rare and novel variants. Historically these prediction methods used hand-crafted features based on structural, evolutionary, or physiochemical properties of the variant. In this study we propose a novel framework that leverages the power of pre-trained protein language models to predict variant pathogenicity. We show that our approach VariPred (VariantimpactPredictor) outperforms current state-of-the-art methods by using an end-to-end model that only requires the protein sequence as input. By exploiting one of the best performing protein language models (ESM-1b), we established a robust classifier, VariPred, requiring no pre-calculation of structural features or multiple sequence alignments. We compared the performance of VariPred with other representative models including 3Cnet, EVE and ‘ESM variant’. VariPred outperformed all these methods on the ClinVar dataset achieving an MCC of 0.751vs. an MCC of 0.690 for the next closest predictor.",
        "link": "http://dx.doi.org/10.1101/2023.03.16.532942"
    },
    {
        "id": 14876,
        "title": "Privacy Risks of General-Purpose Language Models",
        "authors": "Xudong Pan, Mi Zhang, Shouling Ji, Min Yang",
        "published": "2020-5",
        "citations": 30,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/sp40000.2020.00095"
    },
    {
        "id": 14877,
        "title": "Spinning Language Models: Risks of Propaganda-As-A-Service and Countermeasures",
        "authors": "Eugene Bagdasaryan, Vitaly Shmatikov",
        "published": "2022-5",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/sp46214.2022.9833572"
    },
    {
        "id": 14878,
        "title": "Probing phenomenological models implemented in PYTHIA8",
        "authors": "Nameeqa Firdous, Muhammad Faheem, Muhammad Junaid",
        "published": "2023-3-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22323/1.422.0262"
    },
    {
        "id": 14879,
        "title": "Research on Schedule Risk Prediction under Multiple Factors Superimposed on Large Engineering Projects Based on Bayesian Network Models",
        "authors": "Zhenhan Ding, Zhang Chaoyong, Xun Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "Engineering activities can sometimes be affected by individual risk\nfactors, but they can also be affected by multiple risk factors\ncombined. However, existing studies rarely examine whether multiple risk\nfactors superimposed on a particular activity result in superposed or\nnon-superposed effects. To some extent, these effects may influence the\naccuracy of project managers’ decision-making when handling risks. By\nintroducing the Bayesian Network (BN) into the process of multi-factor\nsuperposition influence analysis of project schedule uncertainty, this\nresearch expounded on the construction and implementation of the\nBayesian Network diagram of project schedule risk. Based on the Bayesian\nNetwork concept, this research developed a Bayesian network-based\nengineering schedule risk detection model. Further, it was examined\nwhether the influence produced by the superposition of risk factors\nequals the sum of the influences produced by each risk factor acting\nalone. It has been demonstrated through engineering examples that the\nmodel does not only clearly express project schedules but also has all\nthe functions of a Bayesian Network, allowing it to serve as a platform\nfor processing uncertain data. The case also revealed that when multiple\nrisk factors are superimposed, the impact on the project schedule is not\nsuperimposed. These findings provide policymakers with a more\ncomprehensive understanding of how to respond to risk.",
        "link": "http://dx.doi.org/10.22541/au.169834702.27990994/v1"
    },
    {
        "id": 14880,
        "title": "Deep integrative models for large-scale human genomics",
        "authors": "Arnór I. Sigurdsson, David Westergaard, Ole Winther, Ole Lund, Søren Brunak, Bjarni J. Vilhjálmsson, Simon Rasmussen",
        "published": "No Date",
        "citations": 2,
        "abstract": "ABSTRACTPolygenic risk scores (PRSs) are expected to play a critical role in achieving precision medicine. Currently, PRS predictors are generally based on linear models using summary statistics, and more recently individual-level data. However, these predictors mainly capture additive relationships and are limited in data modalities they can use. Here, we developed a deep learning framework (EIR) for PRS prediction which includes a model, genome-local-net (GLN), specifically designed for large scale genomics data. The framework supports multi-task (MT) learning, automatic integration of other clinical and biochemical data, and model explainability. When applied to individual level data in the UK Biobank, we found that GLN outperformed LASSO for a wide range of diseases and in particularly autoimmune diseases. Furthermore, we show that this was likely due to modelling epistasis, and we showcase this by identifying widespread epistasis for Type 1 Diabetes. Furthermore, we trained PRS by integrating genotype, blood, urine and anthropometrics and found that this improved performance for 93% of 290 diseases and disorders considered. Finally, we found that including genotype data provided better calibrated PRS models compared to using measurements alone. EIR is available at https://github.com/arnor-sigurdsson/EIR.",
        "link": "http://dx.doi.org/10.1101/2021.06.11.447883"
    },
    {
        "id": 14881,
        "title": "Computable models of the cooperation of digital economies",
        "authors": "Ant. F. Ereshko, T. V. Kokuytseva",
        "published": "2017-10",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2017.8109617"
    },
    {
        "id": 14882,
        "title": "Improved PSD Fatigue Approach for Large FE Models with Wide Frequency Range",
        "authors": "Huai-Ren Shih",
        "published": "2020-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4271/2020-01-0499"
    },
    {
        "id": 14883,
        "title": "Scenario Models Based on a Digital Portrait of a Person",
        "authors": "Igor Chernov, Vadim Feyzov",
        "published": "2022-9-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd55143.2022.9934433"
    },
    {
        "id": 14884,
        "title": "Large-scale Multi-Modality Pretrained Models",
        "authors": "Jingren Zhou",
        "published": "2021-10-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3474085.3480241"
    },
    {
        "id": 14885,
        "title": "Large-scale simulation of biomembranes incorporating realistic kinetics into coarse-grained models",
        "authors": "Mohsen Sadeghi, Frank Noé",
        "published": "2020-6-11",
        "citations": 30,
        "abstract": "AbstractBiomembranes are two-dimensional assemblies of phospholipids that are only a few nanometres thick, but form micrometre-sized structures vital to cellular function. Explicit molecular modelling of biologically relevant membrane systems is computationally expensive due to the large number of solvent particles and slow membrane kinetics. Coarse-grained solvent-free membrane models offer efficient sampling but sacrifice realistic kinetics, thereby limiting the ability to predict pathways and mechanisms of membrane processes. Here, we present a framework for integrating coarse-grained membrane models with continuum-based hydrodynamics. This framework facilitates efficient simulation of large biomembrane systems with large timesteps, while achieving realistic equilibrium and non-equilibrium kinetics. It helps to bridge between the nanometer/nanosecond spatiotemporal resolutions of coarse-grained models and biologically relevant time- and lengthscales. As a demonstration, we investigate fluctuations of red blood cells, with varying cytoplasmic viscosities, in 150-milliseconds-long trajectories, and compare kinetic properties against single-cell experimental observations.",
        "link": "http://dx.doi.org/10.1038/s41467-020-16424-0"
    },
    {
        "id": 14886,
        "title": "Review on ESMValTool v2.0 &amp;amp;#8211; Extended set of large-scale diagnostics for quasi-operational and comprehensive evaluation of Earth system models in CMIP",
        "authors": "",
        "published": "2020-1-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5194/gmd-2019-291-rc2"
    },
    {
        "id": 14887,
        "title": "Thai Character-Word Long Short-Term Memory Network Language Models with Dropout and Batch Normalization",
        "authors": "Nuttanit Keskomon,  , Jaturon Harnsomburana",
        "published": "2020-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18178/ijmlc.2020.10.6.1006"
    },
    {
        "id": 14888,
        "title": "Exploring the potential utility of AI large language models for medical ethics: an expert panel evaluation of GPT-4",
        "authors": "Michael Balas, Jordan Joseph Wadden, Philip C Hébert, Eric Mathison, Marika D Warren, Victoria Seavilleklein, Daniel Wyzynski, Alison Callahan, Sean A Crawford, Parnian Arjmand, Edsel B Ing",
        "published": "2024-2",
        "citations": 1,
        "abstract": "Integrating large language models (LLMs) like GPT-4 into medical ethics is a novel concept, and understanding the effectiveness of these models in aiding ethicists with decision-making can have significant implications for the healthcare sector. Thus, the objective of this study was to evaluate the performance of GPT-4 in responding to complex medical ethical vignettes and to gauge its utility and limitations for aiding medical ethicists. Using a mixed-methods, cross-sectional survey approach, a panel of six ethicists assessed LLM-generated responses to eight ethical vignettes.The main outcomes measured were relevance, reasoning, depth, technical and non-technical clarity, as well as acceptability of GPT-4’s responses. The readability of the responses was also assessed. Of the six metrics evaluating the effectiveness of GPT-4’s responses, the overall mean score was 4.1/5. GPT-4 was rated highest in providing technical (4.7/5) and non-technical clarity (4.4/5), whereas the lowest rated metrics were depth (3.8/5) and acceptability (3.8/5). There was poor-to-moderate inter-rater reliability characterised by an intraclass coefficient of 0.54 (95% CI: 0.30 to 0.71). Based on panellist feedback, GPT-4 was able to identify and articulate key ethical issues but struggled to appreciate the nuanced aspects of ethical dilemmas and misapplied certain moral principles.This study reveals limitations in the ability of GPT-4 to appreciate the depth and nuanced acceptability of real-world ethical dilemmas, particularly those that require a thorough understanding of relational complexities and context-specific values. Ongoing evaluation of LLM capabilities within medical ethics remains paramount, and further refinement is needed before it can be used effectively in clinical settings.",
        "link": "http://dx.doi.org/10.1136/jme-2023-109549"
    },
    {
        "id": 14889,
        "title": "Perspective: Large Language Models in Applied Mechanics",
        "authors": "Neal R. Brodnik, Samuel Carton, Caelin Muir, Satanu Ghosh, Doug Downey, McLean P. Echlin, Tresa M. Pollock, Samantha Daly",
        "published": "2023-10-1",
        "citations": 6,
        "abstract": "AbstractLarge language models (LLMs), such as ChatGPT and PaLM, are able to perform sophisticated text comprehension and generation tasks with little or no training. Alongside their broader societal impacts, these capabilities carry great promise for the physical sciences, including applied mechanics. We present a summary of recent developments in these models, their application to mechanics and adjacent fields, and a perspective on their future use in applied mechanics, taking into account their limitations and the unique challenges of the field.",
        "link": "http://dx.doi.org/10.1115/1.4062773"
    },
    {
        "id": 14890,
        "title": "ProphetNet-X: Large-Scale Pre-training Models for English, Chinese, Multi-lingual, Dialog, and Code Generation",
        "authors": "Weizhen Qi, Yeyun Gong, Yu Yan, Can Xu, Bolun Yao, Bartuer Zhou, Biao Cheng, Daxin Jiang, Jiusheng Chen, Ruofei Zhang, Houqiang Li, Nan Duan",
        "published": "2021",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.acl-demo.28"
    },
    {
        "id": 14891,
        "title": "Data Assimilation in Modern Atmospheric Quality Forecasting Models",
        "authors": "Y. G. Fateeva, A. Yu. Efremov",
        "published": "2020-9-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd49919.2020.9247717"
    },
    {
        "id": 14892,
        "title": "The Generic Possibility of Full Surplus Extraction in Models with Large Type Spaces",
        "authors": "Alia Gizatulina, Martin F. Hellwig",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2921868"
    },
    {
        "id": 14893,
        "title": "Analysis of large urn models with local mean-field interactions",
        "authors": "Wen Sun, Robert Philippe",
        "published": "2019-1-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1214/19-ejp304"
    },
    {
        "id": 14894,
        "title": "Large Deviations of Linear Models with Regularly-Varying Tails: Asymptotics and Efficient Estimation",
        "authors": "Farzad Pourbabaee, Omid Shams Solari",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3361346"
    },
    {
        "id": 14895,
        "title": "Large-scale capture of hidden fluorescent labels for training generalizable markerless motion capture models",
        "authors": "Daniel J. Butler, Alexander P. Keim, Shantanu Ray, Eiman Azim",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractRecent advances in deep learning-based markerless pose estimation have dramatically improved the scale and ease with which body landmarks can be tracked in studies of animal behavior. However, pose estimation for animals in a laboratory setting still faces some specific challenges. Researchers typically need to manually generate new training data for each experimental setup and visual environment, limiting the generalizability of this approach. With each network being trained from scratch, different investigators track distinct anatomical landmarks and analyze the resulting kinematic data in idiosyncratic ways. Moreover, much of the movement data is discarded: only a few sparse landmarks are typically labeled, due to the inherent scale and accuracy limits of manual annotation. To address these issues, we developed an approach, which we term GlowTrack, for generating large training datasets that overcome the relatively modest limits of manual labeling, enabling deep learning models that generalize across experimental contexts. The key innovations are: a) an automated, high-throughput approach for generating hidden labels free of human error using fluorescent markers; b) a multi-camera, multi-light setup for generating large amounts of training data under diverse visual conditions; and c) a technique for massively parallel tracking of hundreds of landmarks simultaneously using computer vision feature matching algorithms, providing dense coverage for kinematic analysis at a resolution not currently available. These advances yield versatile deep learning models that are trained at scale, laying the foundation for standardized behavioral pipelines and more complete scrutiny of animal movements.",
        "link": "http://dx.doi.org/10.1101/2022.07.07.499213"
    },
    {
        "id": 14896,
        "title": "Index",
        "authors": "",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119529019.index"
    },
    {
        "id": 14897,
        "title": "Regenerative medicine approaches in large animal models for the temporomandibular joint meniscus",
        "authors": "Alejandro J. Almarza, William Chung",
        "published": "2019-6-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.20517/2573-0002.2019.02"
    },
    {
        "id": 14898,
        "title": "A stream-power law for glacial erosion and its implementation in\nlarge-scale landform-evolution models",
        "authors": "Stefan Hergarten",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract. Modeling glacial landform evolution is more challenging than modeling fluvial landform evolution. While several numerical models of large-scale fluvial erosion are available, there are only a few models of glacial erosion, and their application over long time spans requires a high numerical effort. In this paper, a simple formulation of glacial erosion which is similar to the fluvial stream-power model is presented. The model reproduces the occurrence of overdeepenings, hanging valleys, and steps at confluences at least qualitatively. Beyond this, it allows for a seamless coupling to fluvial erosion and sediment transport. The recently published direct numerical scheme for fluvial erosion and sediment transport can be applied to the entire domain, where the numerical effort is only moderately higher than for a purely fluvial system. Simulations over several million years on lattices of several million nodes can be performed on standard PCs. An open-source implementation is freely available as a part of the landform evolution model OpenLEM.\n                        ",
        "link": "http://dx.doi.org/10.5194/esurf-2021-1"
    },
    {
        "id": 14899,
        "title": "Will Large-scale Generative Models Corrupt Future Datasets?",
        "authors": "Ryuichiro Hataya, Han Bao, Hiromi Arai",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01879"
    },
    {
        "id": 14900,
        "title": "A pipeline for the reconstruction and evaluation of context-specific human metabolic models at a large-scale",
        "authors": "Vítor Vieira, Jorge Ferreira, Miguel Rocha",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractConstraint-based (CB) metabolic models provide a mathematical framework and scaffold for in silico cell metabolism analysis and manipulation. In the past decade, significant efforts have been done to model human metabolism, enabled by the increased availability of multi-omics datasets and curated genome-scale reconstructions, as well as the development of several algorithms for context-specific model (CSM) reconstruction. Although CSM reconstruction has revealed insights on the deregulated metabolism of several pathologies, the process of reconstructing representative models of human tissues still lacks benchmarks and appropriate integrated software frameworks, since many tools required for this process are still disperse across various software platforms, some of which are proprietary.In this work, we address this challenge by assembling a scalable CSM reconstruction pipeline capable of integrating transcriptomics data in CB models. We combined omics preprocessing methods inspired by previous efforts with in-house implementations of existing CSM algorithms and new model refinement and validation routines, all implemented in the Troppo Python-based open-source framework. The pipeline was validated with multi-omics datasets from the Cancer Cell Line Encyclopedia (CCLE), also including reference fluxomics measurements for the MCF7 cell line.We reconstructed over 6000 models based on the Human-GEM template model for 733 cell lines featured in the CCLE, using MCF7 models as reference to find the best parameter combinations. These reference models outperform earlier studies using the same template by comparing gene essentiality and fluxomics experiments. We also analysed the heterogeneity of breast cancer cell lines, identifying key changes in metabolism related to cancer aggressiveness. Despite the many challenges in CB modelling, we demonstrate using our pipeline that combining transcriptomics data in metabolic models can be used to investigate key metabolic shifts. Significant limitations were found on these models ability for reliable quantitative flux prediction, thus motivating further work in genome-wide phenotype prediction.Author summaryGenome-scale models of human metabolism are promising tools capable of contextualising large omics datasets within a framework that enables analysis and manipulation of metabolic phenotypes. Despite various successes in applying these methods to provide mechanistic hypotheses for deregulated metabolism in disease, there is no standardized workflow to extract these models using existing methods and the tools required to do so are mostly implemented using proprietary software.We have assembled a generic pipeline to extract and validate context-specific metabolic models using multi-omics datasets and implemented it using the troppo framework. We first validate our pipeline using MCF7 cell line models and assess their ability to predict lethal gene knockouts as well as flux activity using multi-omics data. We also demonstrate how this approach can be generalized for large-scale transcriptomics datasets and used to generate insights on the metabolic heterogeneity of cancer and relevant features for other data mining approaches. The pipeline is available as part of an open-source framework that is generic for a variety of applications.",
        "link": "http://dx.doi.org/10.1101/2021.07.22.453372"
    },
    {
        "id": 14901,
        "title": "Large-scale capture of hidden fluorescent labels for training generalizable markerless motion capture models",
        "authors": "Daniel J. Butler, Alexander P. Keim, Shantanu Ray, Eiman Azim",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractRecent advances in deep learning-based markerless pose estimation have dramatically improved the scale and ease with which body landmarks can be tracked in studies of animal behavior. However, pose estimation for animals in a laboratory setting still faces some specific challenges. Researchers typically need to manually generate new training data for each experimental setup and visual environment, limiting the generalizability of this approach. With each network being trained from scratch, different investigators track distinct anatomical landmarks and analyze the resulting kinematic data in idiosyncratic ways. Moreover, much of the movement data is discarded: only a few sparse landmarks are typically labeled, due to the inherent scale and accuracy limits of manual annotation. To address these issues, we developed an approach, which we term GlowTrack, for generating large training datasets that overcome the relatively modest limits of manual labeling, enabling deep learning models that generalize across experimental contexts. The key innovations are: a) an automated, high-throughput approach for generating hidden labels free of human error using fluorescent markers; b) a multi-camera, multi-light setup for generating large amounts of training data under diverse visual conditions; and c) a technique for massively parallel tracking of hundreds of landmarks simultaneously using computer vision feature matching algorithms, providing dense coverage for kinematic analysis at a resolution not currently available. These advances yield versatile deep learning models that are trained at scale, laying the foundation for standardized behavioral pipelines and more complete scrutiny of animal movements.",
        "link": "http://dx.doi.org/10.1101/2022.07.07.499213"
    },
    {
        "id": 14902,
        "title": "A pipeline for the reconstruction and evaluation of context-specific human metabolic models at a large-scale",
        "authors": "Vítor Vieira, Jorge Ferreira, Miguel Rocha",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractConstraint-based (CB) metabolic models provide a mathematical framework and scaffold for in silico cell metabolism analysis and manipulation. In the past decade, significant efforts have been done to model human metabolism, enabled by the increased availability of multi-omics datasets and curated genome-scale reconstructions, as well as the development of several algorithms for context-specific model (CSM) reconstruction. Although CSM reconstruction has revealed insights on the deregulated metabolism of several pathologies, the process of reconstructing representative models of human tissues still lacks benchmarks and appropriate integrated software frameworks, since many tools required for this process are still disperse across various software platforms, some of which are proprietary.In this work, we address this challenge by assembling a scalable CSM reconstruction pipeline capable of integrating transcriptomics data in CB models. We combined omics preprocessing methods inspired by previous efforts with in-house implementations of existing CSM algorithms and new model refinement and validation routines, all implemented in the Troppo Python-based open-source framework. The pipeline was validated with multi-omics datasets from the Cancer Cell Line Encyclopedia (CCLE), also including reference fluxomics measurements for the MCF7 cell line.We reconstructed over 6000 models based on the Human-GEM template model for 733 cell lines featured in the CCLE, using MCF7 models as reference to find the best parameter combinations. These reference models outperform earlier studies using the same template by comparing gene essentiality and fluxomics experiments. We also analysed the heterogeneity of breast cancer cell lines, identifying key changes in metabolism related to cancer aggressiveness. Despite the many challenges in CB modelling, we demonstrate using our pipeline that combining transcriptomics data in metabolic models can be used to investigate key metabolic shifts. Significant limitations were found on these models ability for reliable quantitative flux prediction, thus motivating further work in genome-wide phenotype prediction.Author summaryGenome-scale models of human metabolism are promising tools capable of contextualising large omics datasets within a framework that enables analysis and manipulation of metabolic phenotypes. Despite various successes in applying these methods to provide mechanistic hypotheses for deregulated metabolism in disease, there is no standardized workflow to extract these models using existing methods and the tools required to do so are mostly implemented using proprietary software.We have assembled a generic pipeline to extract and validate context-specific metabolic models using multi-omics datasets and implemented it using the troppo framework. We first validate our pipeline using MCF7 cell line models and assess their ability to predict lethal gene knockouts as well as flux activity using multi-omics data. We also demonstrate how this approach can be generalized for large-scale transcriptomics datasets and used to generate insights on the metabolic heterogeneity of cancer and relevant features for other data mining approaches. The pipeline is available as part of an open-source framework that is generic for a variety of applications.",
        "link": "http://dx.doi.org/10.1101/2021.07.22.453372"
    },
    {
        "id": 14903,
        "title": "Will Large-scale Generative Models Corrupt Future Datasets?",
        "authors": "Ryuichiro Hataya, Han Bao, Hiromi Arai",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01879"
    },
    {
        "id": 14904,
        "title": "A stream-power law for glacial erosion and its implementation in\nlarge-scale landform-evolution models",
        "authors": "Stefan Hergarten",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract. Modeling glacial landform evolution is more challenging than modeling fluvial landform evolution. While several numerical models of large-scale fluvial erosion are available, there are only a few models of glacial erosion, and their application over long time spans requires a high numerical effort. In this paper, a simple formulation of glacial erosion which is similar to the fluvial stream-power model is presented. The model reproduces the occurrence of overdeepenings, hanging valleys, and steps at confluences at least qualitatively. Beyond this, it allows for a seamless coupling to fluvial erosion and sediment transport. The recently published direct numerical scheme for fluvial erosion and sediment transport can be applied to the entire domain, where the numerical effort is only moderately higher than for a purely fluvial system. Simulations over several million years on lattices of several million nodes can be performed on standard PCs. An open-source implementation is freely available as a part of the landform evolution model OpenLEM.\n                        ",
        "link": "http://dx.doi.org/10.5194/esurf-2021-1"
    },
    {
        "id": 14905,
        "title": "A differentiable modeling approach to systematically integrating deep learning and physical models for large-scale hydrologic prediction and knowledge discovery",
        "authors": "Dapeng Feng, Chaopeng Shen",
        "published": "No Date",
        "citations": 0,
        "abstract": "Although deep learning (DL) models have shown extraordinary performance in hydrologic modeling, they are still hard to interpret and not able to predict untrained hydrologic variables due to lacking physical meanings and constraints. This study established hybrid differentiable models (namely the delta models) with regionalized parameterization and learnable structures based on a DL-based differentiable parameter learning (dPL) framework. The simulation experiments on both US and global basins demonstrate that the delta models can approach the performance of the state-of-the-art long short-term memory (LSTM) network on discharge prediction. Different from the pure data-driven LSTM model, the delta models can output a full set of hydrologic variables not used as training targets. The evaluation with independent data sources showed that the delta models, only trained on discharge observations, can also give decent predictions for ET and baseflow. The spatial extrapolation experiments showed that the delta models can surpass the performance of the LSTM model for predictions in large ungauged regions in terms of the daily hydrographic metrics and multi-year trend prediction. The spatial patterns of the parameters learned by the delta models remain remarkably stable from the in-sample to spatial out-of-sample predictions, which explains the robustness of the delta models for spatial extrapolation. More importantly, the proposed modeling framework enables directly learning new relations between intermediate variables from large observations. This study shows that the model performance and physical meanings can be balanced with the differentiable modeling approach which is promising to large-scale hydrologic prediction and knowledge discovery.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-16947"
    },
    {
        "id": 14906,
        "title": "Large-scale flood models in watersheds with several lakes and reservoirs",
        "authors": "Gaia Olcese, Christopher Sampson, Gu nol Chon, Pascale Biron, Thomas Buffin B langer",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22541/au.160010749.97447657"
    },
    {
        "id": 14907,
        "title": "Property level pluvial flood risk estimation from large-scale flood models - Identifying potential erroneous locations using a geospatial postprocessing algorithm",
        "authors": "Manoranjan Muthusamy, Ian Bartholomew",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;div&gt;\n&lt;p&gt;&lt;span data-contrast=&quot;auto&quot;&gt;A distinctive characteristic of 2D flood models used in catastrophic modelling in industries such as re/insurance is that they are often developed for a national, continental or even global scale (hereafter referred to as large-scale models). Traditionally these models were used at portfolio-level loss estimations. However, the increased need for understanding flood risk at a much smaller scale (e.g., at the property level), especially for parametric insurance products demands these models to deliver high-resolution, high-accurate flood inundation mapping. Although technological advancements in remote sensing and cloud computing have made this possible to a certain extent, the underlying models are still large-scale models with inherent uncertainties caused by unaccounted small-scale dynamics in both hydrometeorological and terrain data that are impossible to be captured by these large-scale models. Although this uncertainty exists in all three sources of floods (fluvial, pluvial and coastal), pluvial floods&#039; sensitivity to drainage structures and small-scale dynamics in terrain - both of which are&amp;#160;poorly represented in large-scale models - make them the most vulnerable flood type to this uncertainty.&amp;#160;&lt;/span&gt;&lt;span data-ccp-props=&quot;{}&quot;&gt;&amp;#160;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;p&gt;We attempt to develop a novel and practical geospatial approach to identify cases where large-scale 2D flood models are likely to underestimate/miss pluvial flood risk at the property level using easy-to-calculate proxies. These proxies are derived from the inundation clusters created using the 2D flood map itself - hence they do not need any additional data. To test the method, we used data collected from FloodFlash&amp;#8217;s novel and low-cost flood depth sensors installed at properties across the UK. Initial results show that the method is able to identify more than 75% of the cases where the large-scale flood maps underestimated flood risk at the property level (Hits). This method is currently being improved to reduce the number of false positives by finetuning the selected proxies.&amp;#160;&lt;/p&gt;\n&lt;/div&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-16385"
    },
    {
        "id": 14908,
        "title": "Impact of the choice of surface mass balance models and their calibration on large-scale glacier change projections",
        "authors": "Lilian Schuster, David Rounce, Fabien Maussion",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;A recent large model intercomparison study (GlacierMIP) showed that differences between the glacier models is a dominant source of uncertainty for future glacier change projections, in particular in the first half of the century.&amp;#160; Each glacier model has their own unique set of process representations and climate forcing methodology, which makes it impossible to determine the model components that contribute most to the projection uncertainty. This study aims to improve our understanding of the sources of large scale glacier model uncertainty using the Open Global Glacier Model (OGGM), focussing on the surface mass balance (SMB) in a first step. We calibrate and run a set of interchangeable SMB model parameterizations (e.g. monthly vs. daily, constant vs. variable lapse rates, albedo, snowpack evolution and refreezing) under controlled boundary conditions. Based on ensemble approaches, we explore the influence of (i) the parameter calibration strategy and (ii) SMB model complexity on regional to global glacier change. These uncertainties are then put in relation to a qualitative selection of other model design choices, such as the forcing climate dataset and ice dynamics model parameters.&amp;#160;&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu21-1391"
    },
    {
        "id": 14909,
        "title": "Using choice models to inform large marine protected area design",
        "authors": "Kristy Wallmo, Rosemary Kosaka",
        "published": "2017-9",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.marpol.2017.05.034"
    },
    {
        "id": 14910,
        "title": "Inconsistencies of signatures of Eurasian heat waves in the large-scale Rossby waves in CMIP models",
        "authors": "Iana Strigunova, Richard Blender, Frank Lunkeit, Nedjeljka Žagar",
        "published": "No Date",
        "citations": 0,
        "abstract": "This study identifies discrepancies in signatures of the Eurasian heat waves (EHWs) in the reanalyses and climate models. The scale-dependent analysis considers the global Rossby wave spectrum for the extended boreal summer using daily values of the Rossby wave mechanical energy. We filter Rossby waves using a multivariate, 3D projection of the horizontal velocity and geopotential fields onto a set of orthogonal normal-mode functions. Our previous study has found that Rossby wave energy follows a &#967;2-distribution with skewness related to the number of degrees of freedom. During EHWs, the skewness of the normalised energy anomaly distributions increases with a corresponding decrease in the number of active degrees of freedom, implying fewer modes involved. Fewer modes indicate a blocking structure that is identified as an increase in the Rossby wave amplitude in the middle troposphere during EHWs. Here, we compare the spatial structure and energy distributions of the troposphere-barotropic Rossby waves in the subset of CMIP5 models with findings from reanalyses. The increase in planetary Rossby wave amplitudes is first identified for the present-day climate. Significant differences among the models are found regarding the change in the skewness of the Rossby wave energy distribution and hence the number of active degrees of freedom during EHWs. The results highlight inconsistencies in simulating the day-to-day variability of planetary Rossby waves during EHWs in the CMIP models despite the overall agreement in the mean circulation and EHW metrics based on surface data reported in previous studies. The results of this study have potential implications for the interpretation of projected changes in Rossby waves and EHWs in future CMIP climate simulations.&#160;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-11401"
    },
    {
        "id": 14911,
        "title": "How ice anisotropy contributes to fold and ice stream in large-scale ice-sheet models",
        "authors": "Yu Zhang, Paul D. Bons, Till Sachau, Steven Franke",
        "published": "No Date",
        "citations": 0,
        "abstract": "Satellite and airborne sensors have provided detailed data on ice surface flow velocities, englacial structures of ice sheets and bedrock elevations. These data give insight into the flow behaviour of ice sheets and glaciers. One significant phenomenon observed is large-scale folds (over 100 m in amplitude) in the englacial stratigraphy in the Greenland ice sheet. A large population of folds is located at ice streams, where the flow is distinctly faster than in the surroundings, such as the North-East Greenland Ice Stream (NEGIS). While there is no consensus regarding the formation of large-scale folds, unraveling the underlying mechanisms presents significant potential for enhancing our understanding of the formation and dynamics of ice streams.\nIce in ice sheets is a ductile material, i.e., it can flow as a thick viscous fluid with a power-law rheology. Furthermore, ice is significantly anisotropic in its flow properties due to its crystallographic preferred orientation (CPO). Here, we use the Full-Stokes code Underworld2 (Mansour et al.,2022) for 3D modelling of the power-law and transversely isotropic ice flow, also in comparison with the isotropic ice models.\nOur simulated folds with anisotropic ice show complex patterns on a bumpy bedrock, and are classified into three types: large-scale folds (fold amplitudes >100 m), small-scale folds (fold amplitudes <<100 m, wavelength <<km) and recumbent basal-shear folds. Our results indicate that bedrock topography contributes to perturbations in ice layers, and that ice anisotropy due to the CPO amplifies these into large-scale folds in convergent flow by horizontal shortening. As for our ice stream model, we simulate convergent flow as initial condition, which subsequently initiates the development of shear margins due to the rotation of the ice crystal basal planes. As soon as the shear margins develop, the ice stream starts to propagate upstream in a short time and narrows in the upstream part. Our modeling shows that the anisotropic rheology of ice and CPO change play a significant role for large-scale folding and for the initiation of ice streams with distinct shear margins. Hence, we promote the implementation of ice anisotropy in large-scale ice-sheet evolution models as it holds the potential to introduce novel perspectives to the glaciological community on the dynamics of ice flow.\n&#160;\nReferences\nJohn Mansour, Julian Giordani, Louis Moresi, Romain Beucher, Owen Kaluza, Mirko Velic, Rebecca Farrington, Steve Quenette, &amp; Adam Beall. (2022). Underworld2: Python Geodynamics Modelling for Desktop, HPC and Cloud (v2.12.0b). Zenodo. https://doi.org/10.5281/zenodo.5935717",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-5872"
    },
    {
        "id": 14912,
        "title": "Control Models in Dental Implantology",
        "authors": "A. A. Shiroky, A. O. Zekiy, V. V. Novochadov",
        "published": "2018-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd.2018.8551911"
    },
    {
        "id": 14913,
        "title": "Predictability of large subduction earthquakes: insights from analog models and machine learning",
        "authors": "Fabio Corbi, Jonathan Bedford, Laura Sandri, Francesca Funiciello, Adriano Gualandi, Matthias Rosenau",
        "published": "No Date",
        "citations": 0,
        "abstract": "\n        &lt;p&gt;Despite the growing spatio-temporal density of geophysical observations, our understanding of the megathrust earthquake cycle continues to be limited by a series of factors, in particular the short observation time compared to mega-earthquake recurrence and the partial spatial coverage of geodetic data. Here, we attempt to compensate for these natural limitations by simulating dozens of seismic cycles in a laboratory-scale analogue model of subduction. The model creates analog earthquakes of magnitude Mw 6.2&amp;#8211;8.3, with a coefficient of variation in recurrence intervals of 0.5, similar to real subduction megathrusts. Using a digital image correlation technique, we measure coseismic and interseismic deformation &amp;#8211; this is akin to having a dense continuous geodetic network homogeneously distributed over the whole margin. We show how, by deciphering the spatially and temporally complex surface deformation history, machine learning can predict the timing and size of analog earthquakes. Then, we investigate data characteristics that maximize the performance of a machine learning binary classifier predicting slip-events imminence. We show how this framing can be used for designing an efficient geodetic network, and defining the minimum space-time coverage requirements for analog earthquake prediction. Converting the laboratory scale to the natural scale, we found that a 70-85 km wide coastal swath gives the most important information on slip imminence and that model performance is mainly &amp;#8232;influenced by the alarm duration, with density of stations and record length playing a secondary role. Under optimal monitoring conditions, about ten seismic cycles long record is enough to predict alarm periods in good agreement with those observed.&lt;/p&gt;\n        ",
        "link": "http://dx.doi.org/10.5194/egusphere-egu2020-6805"
    },
    {
        "id": 14914,
        "title": "Three operational models for ambidexterity in large corporations",
        "authors": "Sverker Alänge, Annika Steiber",
        "published": "2018-12",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s40604-018-0053-9"
    },
    {
        "id": 14915,
        "title": "Warm-Temperate Food Chains of the Southeast Shelf Ecosystem",
        "authors": "James A. Yoder",
        "published": "2019-5-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429042423-3"
    },
    {
        "id": 14916,
        "title": "BIM Models Enhancement Through Simulation Modeling",
        "authors": "Timur Devyatkov, Vladimir Devyatkov, Alexey Gabalin, Konstantin Shuvalov",
        "published": "2021-9-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlsd52249.2021.9600146"
    },
    {
        "id": 14917,
        "title": "Fast Processes in Large‐Scale Atmospheric Models",
        "authors": "",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119529019"
    },
    {
        "id": 14918,
        "title": "Recursive Estimation in Large Panel Data Models: Theory and Practice",
        "authors": "Bin Jiang, Yanrong Yang, Jiti Gao, Cheng Hsiao",
        "published": "No Date",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2915749"
    },
    {
        "id": 14919,
        "title": "The Large Housing Complexes of the Utopian Socialists",
        "authors": "Friedrich Engels",
        "published": "2019-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783035618686-008"
    },
    {
        "id": 14920,
        "title": "Automated customization of large-scale spiking network models to neuronal population activity",
        "authors": "Shenghao Wu, Chengcheng Huang, Adam Snyder, Matthew Smith, Brent Doiron, Byron Yu",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractUnderstanding brain function is facilitated by constructing computational models that accurately reproduce aspects of brain activity. Networks of spiking neurons capture the underlying biophysics of neuronal circuits, yet the dependence of their activity on model parameters is notoriously complex. As a result, heuristic methods have been used to configure spiking network models, which can lead to an inability to discover activity regimes complex enough to match large-scale neuronal recordings. Here we propose an automatic procedure, Spiking Network Optimization using Population Statistics (SNOPS), to customize spiking network models that reproduce the population-wide covariability of large-scale neuronal recordings. We first confirmed that SNOPS accurately recovers simulated neural activity statistics. Then, we applied SNOPS to recordings in macaque visual and prefrontal cortices and discovered previously unknown limitations of spiking network models. Taken together, SNOPS can guide the development of network models and thereby enable deeper insight into how networks of neurons give rise to brain function.",
        "link": "http://dx.doi.org/10.1101/2023.09.21.558920"
    },
    {
        "id": 14921,
        "title": "scSemiProfiler: Advancing Large-scale Single-cell Studies through Semi-profiling with Deep Generative Models and Active Learning",
        "authors": "Jun Ding, Jingtao Wang, Gregory Fonseca",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nSingle-cell sequencing is a crucial tool for dissecting the cellular intricacies of complex diseases. Its prohibitive cost, however, hampers its application in expansive biomedical studies. Traditional cellular deconvolution approaches can infer cell type proportions from more affordable bulk sequencing data, yet they fall short in providing the detailed resolution required for single-cell-level analyses. To overcome this challenge, we introduce \"scSemiProfiler\", an innovative computational framework that marries deep generative model with active learning strategies. This method adeptly infers single-cell profiles across large cohorts by fusing bulk sequencing data with targeted single-cell sequencing from a few carefully chosen representatives. Extensive validation across heterogeneous datasets verifies the precision of our semi-profiling approach, aligning closely with true single-cell profiling data and empowering refined cellular analyses. Originally developed for extensive disease cohorts, \"scSemiProfiler\" is adaptable for broad applications. It provides a scalable, cost-effective solution for single-cell profiling, facilitating in-depth cellular investigation in various biological domains.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3638900/v1"
    },
    {
        "id": 14922,
        "title": "Dynamic Nonlinear Algebraic Models With Scale-Similarity Dynamic Procedure For Large-Eddy Simulation of Turbulence",
        "authors": "Zelong Yuan, Yunpeng Wang, Chenyue Xie, Jianchun Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nA dynamic nonlinear algebraic model with scale-similarity dynamic procedure (DNAM-SSD) is proposed for subgrid-scale (SGS) stress in large-eddy simulation of turbulence. The model coefficients of the DNAM-SSD model are adaptively calculated through the scale-similarity relation, which greatly simplifies the conventional Germano-identity based dynamic procedure (GID). The  a priori  study shows that the DNAM-SSD model predicts the SGS stress considerably better than the conventional velocity gradient model (VGM), dynamic Smagorinsky model (DSM), dynamic mixed model (DMM) and DNAM-GID model at a variety of filter widths ranging from inertial to viscous ranges. The correlation coefficients of the SGS stress predicted by the DNAM-SSD model can be larger than 95% with the relative errors lower than 30%. In the  a posteriori  testings of LES, the DNAM-SSD model outperforms the implicit LES (ILES), DSM, DMM and DNAM-GID models without increasing computational costs, which only takes up half the time of the DNAM-GID model. The DNAM-SSD model accurately predicts plenty of turbulent statistics and instantaneous spatial structures in reasonable agreement with the filtered DNS data. These results indicate that the current DNAM-SSD model is attractive for the development of highly accurate SGS models for LES of turbulence.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1078014/v1"
    },
    {
        "id": 14923,
        "title": "Scaling Large Language Models to the Extreme: Neural Semantic Processing of Multiple Tasks in Italian",
        "authors": "Claudiu D. Hromei, Danilo Croce, Valerio Basile, Roberto Basili",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-47546-7_12"
    },
    {
        "id": 14924,
        "title": "Integrating Large Language Models and Metaverse in Autonomous Racing: An Education-Oriented Perspective",
        "authors": "Bai Li, Tian'ao Xu, Xinyuan Li, Yaodong Cui, Xuepeng Bian, Siyu Teng, Siji Ma, Lili Fan, Yonglin Tian, Fei-Yue Wang",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tiv.2024.3349466"
    },
    {
        "id": 14925,
        "title": "Prompting Multilingual Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages",
        "authors": "Zheng Xin Yong, Ruochen Zhang, Jessica Forde, Skyler Wang, Arjun Subramonian, Holy Lovenia, Samuel Cahyawijaya, Genta Winata, Lintang Sutawika, Jan Christian Blaise Cruz, Yin Lin Tan, Long Phan, Long Phan, Rowena Garcia, Thamar Solorio, Alham Aji",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.calcs-1.5"
    },
    {
        "id": 14926,
        "title": "Using large language models in psychology",
        "authors": "Dorottya Demszky, Diyi Yang, David S. Yeager, Christopher J. Bryan, Margarett Clapper, Susannah Chandhok, Johannes C. Eichstaedt, Cameron Hecht, Jeremy Jamieson, Meghann Johnson, Michaela Jones, Danielle Krettek-Cobb, Leslie Lai, Nirel JonesMitchell, Desmond C. Ong, Carol S. Dweck, James J. Gross, James W. Pennebaker",
        "published": "2023-10-13",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s44159-023-00241-5"
    },
    {
        "id": 14927,
        "title": "You reap what you sow: On the Challenges of Bias Evaluation Under Multilingual Settings",
        "authors": "Zeerak Talat, Aurélie Névéol, Stella Biderman, Miruna Clinciu, Manan Dey, Shayne Longpre, Sasha Luccioni, Maraim Masoud, Margaret Mitchell, Dragomir Radev, Shanya Sharma, Arjun Subramonian, Jaesung Tae, Samson Tan, Deepak Tunuguntla, Oskar Van Der Wal",
        "published": "2022",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.bigscience-1.3"
    },
    {
        "id": 14928,
        "title": "Large language models generate functional protein sequences across diverse families",
        "authors": "Ali Madani, Ben Krause, Eric R. Greene, Subu Subramanian, Benjamin P. Mohr, James M. Holton, Jose Luis Olmos, Caiming Xiong, Zachary Z. Sun, Richard Socher, James S. Fraser, Nikhil Naik",
        "published": "2023-8",
        "citations": 214,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41587-022-01618-2"
    },
    {
        "id": 14929,
        "title": "From Prose to Prototype: Synthesising Executable UML Models from Natural Language",
        "authors": "Guus J. Ramackers, Pepijn P. Griffioen, Martijn B.J. Schouten, Michel R.V. Chaudron",
        "published": "2021-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/models-c53483.2021.00061"
    },
    {
        "id": 14930,
        "title": "MatSci-NLP: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling",
        "authors": "Yu Song, Santiago Miret, Bang Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.201"
    },
    {
        "id": 14931,
        "title": "Dynamic Ensemble of Heterogeneous Encoding Models in Knowledge Extraction of Diverse Event Expressions",
        "authors": "Kai Ishikawa, Hiroya Takamura, Manabu Okumura",
        "published": "2020-6-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.27.329"
    },
    {
        "id": 14932,
        "title": "Regionalized models for Spanish language variations based on Twitter",
        "authors": "Eric S. Tellez, Daniela Moctezuma, Sabino Miranda, Mario Graff, Guillermo Ruiz",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10579-023-09640-9"
    },
    {
        "id": 14933,
        "title": "Language and Culture in Interdisciplinary Studies",
        "authors": "Anna Majewska-Wójcik",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18290/rh237110.17"
    },
    {
        "id": 14934,
        "title": "An Explainable Toolbox for Evaluating Pre-trained Vision-Language Models",
        "authors": "Tiancheng Zhao, Tianqi Zhang, Mingwei Zhu, Haozhan Shen, Kyusong Lee, Xiaopeng Lu, Jianwei Yin",
        "published": "2022",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-demos.4"
    },
    {
        "id": 14935,
        "title": "Ecco: An Open Source Library for the Explainability of Transformer Language Models",
        "authors": "J Alammar",
        "published": "2021",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.acl-demo.30"
    },
    {
        "id": 14936,
        "title": "On the transparency of large AI models",
        "authors": "Wanying Wang, Ge Wang, Vukosi Marivate, Andrew L. Hufton",
        "published": "2023-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patter.2023.100797"
    },
    {
        "id": 14937,
        "title": "Large discrepancies on nitrate loading estimates from sparse measurements by SWAT and statistical models at catchment scale",
        "authors": "Kang Liang, Yefang Jiang, Fan-Rui Meng",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Nitrogen (N) is one of the major pollutants to aquatic ecosystems. One of the key steps for efficient N reduction management at watershed scale is accurate quantification of N load. High frequency monitoring of stream water N concentration has not been common, and this has largely been the limiting factor for accurate estimation of N loading worldwide. N loads have often been estimated from sparse measurements. The objective of this study was to investigate the performance of the physical-based SWAT (Soil and Water Assessment Tool) model and three commonly used regression methods, namely LI (linear interpolation), WRTDS (Weighted Regression on Time, Discharge, and Season), and the LOADEST (LOAD ESTimator) on estimating nitrate load from sparse measurements through a case study in an agricultural watershed in eastern Canada. The range of daily nitrate load of SWAT and LOADEST was 0.05-1.29 and 0.14 - 1.35 t day&lt;sup&gt;-1&lt;/sup&gt;, compared with 0.13 - 13.08 t day&lt;sup&gt;-1&amp;#160; &lt;/sup&gt;and 0.15 - 16.75 t day&lt;sup&gt;-1 &lt;/sup&gt;for LI and WRTDS, respectively. Mean daily nitrate load estimated by the four methods followed the order: WRTDS &gt; LI &gt; LOADEST &gt; SWAT. The large discrepancies were mainly occurred during the non-growing season during which there was observation data available. As regression methods use concentration data from dry seasons to estimate the concentrations of wet seasons, there is a strong likelihood of overestimation of nitrate load for wet seasons. The results of this study shed new light on nitrate load estimation under conditions of different data availability. Under situations of limited water quality measurement, policy makers or researchers are likely to benefit from using hydrological models such as SWAT for constituent load estimation. However, the selection of the most appropriate method for load estimation should be seen as a dynamic process, and case by case evaluation is required especially when only sparsely measured data is available. As agri-environmental water quality issues become more pressing, it is critical that data collection strategies that encompass seasonal variation in streamflow and nitrate concentration be employed in regions like Atlantic Canada in the future.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu21-10458"
    },
    {
        "id": 14938,
        "title": "Fast Algorithms for Conducting Large-Scale GWAS of Age-at-Onset Traits Using Cox Mixed-Effects Models",
        "authors": "",
        "published": "2020-8-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1534/genetics.120.303447"
    },
    {
        "id": 14939,
        "title": "Identification and (Fast) Estimation of Large Nonlinear Panel Models with Two-Way Fixed Effects",
        "authors": "Martin Mugnier, Ao Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4186349"
    },
    {
        "id": 14940,
        "title": "Biogeographic multi-species occupancy models for large-scale survey data",
        "authors": "Jacob B. Socolar, Simon C. Mills, Torbjørn Haugaasen, James J. Gilroy, David P. Edwards",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractEcologists often seek to infer patterns of species occurrence or community structure from survey data. Hierarchical models, including multi-species occupancy models (MSOMs), can improve inference by pooling information across multiple species via random effects. Originally developed for local-scale survey data, MSOMs are increasingly applied to larger spatial scales that transcend major abiotic gradients and dispersal barriers. At biogeographic scales, the benefits of partial pooling in MSOMs trade off against the difficulty of incorporating sufficiently complex spatial effects to account for biogeographic variation in occupancy across multiple species simultaneously.We show how this challenge can be overcome by incorporating pre-existing range information into MSOMs, yielding a ‘biogeographic multi-species occupancy model’ (bMSOM). We illustrate the bMSOM using two published datasets: Parulid warblers in the United States Breeding Bird Survey, and entire avian communities in forests and pastures of Colombia’s West Andes.Compared to traditional MSOMs, the bMSOM provides dramatically better predictive performance at lower computational cost. The bMSOM avoids severe spatial biases in predictions of the traditional MSOM and provides principled species-specific inference even for never-observed species.Incorporating pre-existing range data enables principled partial pooling of information across species in large-scale MSOMs. Our biogeographic framework for multi-species modeling should be broadly applicable in hierarchical models that predict species occurrences, whether or not false-absences are modeled in an occupancy framework.",
        "link": "http://dx.doi.org/10.1101/2021.11.05.467527"
    },
    {
        "id": 14941,
        "title": "Duality Principles and Numerical Procedures for a Large Class of Non-convex Models in the Calculus of Variations",
        "authors": "Fabio Silva Botelho",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article develops duality principles and numerical results for a large class of non-convex variational models. The main results are based on fundamental tools of convex analysis, duality theory and calculus of variations. More specifically the approach is established for a class of non-convex functionals similar as those found in some models in phase transition. Finally, in some sections we present concerning numerical examples and the respective softwares.",
        "link": "http://dx.doi.org/10.20944/preprints202302.0051.v61"
    },
    {
        "id": 14942,
        "title": "Large-scale heavy precipitation over the Czech Republic and its link to atmospheric circulation in CORDEX regional climate models",
        "authors": "Romana Beranová, Jan Kyselý",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe study evaluates ability of regional climate models (RCMs) to reproduce relationships between large-scale heavy precipitation events (LHPEs) over the Czech Republic and atmospheric circulation. We use an ensemble of 32 RCM simulations with the 0.11° resolution from the Euro-CORDEX project, and compare the historical simulations (1951–2005) against observations from the E-OBS data set. A novel selection criterion for LHPEs is proposed, defining these as days with at least 70% of all grid boxes over a given area with precipitation amounts exceeding the 90th grid-specific percentile of the seasonal distribution of daily amounts. The association with atmospheric circulation is investigated through circulation types derived from sea level pressure using airflow indices (direction, strength and vorticity). The majority of the RCMs capture that the frequency of days with LHPEs is higher in winter than summer, but almost all underestimate the occurrence of LHPEs in both seasons. In winter, the observed LHPEs are connected mainly with cyclonic types and westerly supertype; the role of nonwesterly and cyclonic-nonwesterly supertypes is significant only in the eastern part, where the Atlantic influence is weaker. In summer, the importance of cyclonic and nonwesterly types in producing LHPEs increases compared to winter. The RCMs reasonably well reproduce these links, including differences between seasons and regions, if their ensemble mean is evaluated, but large variations occur among individual simulations mainly in summer. The importance of cyclonic vorticity is overestimated in the RCMs, while westerly advection of moist air plays a smaller role in models than in observations.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1640919/v1"
    },
    {
        "id": 14943,
        "title": "Decoding the Silent Majority: Inducing Belief Augmented Social Graph with Large Language Model for Response Forecasting",
        "authors": "Chenkai Sun, Jinning Li, Yi Fung, Hou Chan, Tarek Abdelzaher, ChengXiang Zhai, Heng Ji",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.4"
    },
    {
        "id": 14944,
        "title": "Bayesian Parametric and Semiparametric Factor Models for Large Realized Covariance Matrices",
        "authors": "Xin Jin, John M. Maheu, Qiao Yang",
        "published": "No Date",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3159716"
    },
    {
        "id": 14945,
        "title": "Hybrid Modeling and Simulation of Huge Crowd over an HGA",
        "authors": "Dan Chen, Lizhe Wang, Jingying Chen",
        "published": "2017-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b11883-11"
    },
    {
        "id": 14946,
        "title": "Verification of Large Scale Control Systems with Hybrid Digital Models and Digital Twins",
        "authors": "Kirill Semenkov, Vitaly Promyslov, Alexey Poletykin",
        "published": "2020-9",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/rusautocon49822.2020.9208167"
    },
    {
        "id": 14947,
        "title": "Structural Identification of Large Finite Element Models Using Commodity Computing Clusters for Parallel Genetic Algorithms",
        "authors": "MATTHEW WHELAN, TIMOTHY KERNICKY, NEAL ZAMUDIO",
        "published": "2105",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.12783/shm2015/112"
    },
    {
        "id": 14948,
        "title": "Cloud-Enabled Ubiquitous Collaboration on Large Models Using Augmented Reality",
        "authors": "Phathompat Boonyasaknanon, Raymond Pols, Katja Schulze, Robert Rundle",
        "published": "2020-11-9",
        "citations": 1,
        "abstract": "Abstract\nA cloud-based augmented reality system is presented which is designed to enhance the real-time collaboration of domain experts involved in modeling large reservoirs. An evaluation of traditional techniques is compared with this new approach. Work-from-home (WFH) scenarios are becoming more important and, in some cases, critical. There is a need to untether the geologist and other domain experts from high end office-bound workstations.\nReservoir models in recent years have become increasingly large. The volume of seismic, well data and modeling data structures presents a challenge in both management of the data and making it accessible to domain experts and others. The traditional practice of siloing data in various disconnected data repositories in various corporate data centers is becoming increasingly untenable. What is needed is a comprehensive approach that scales to the largest models and is accessible anywhere for time critical analysis and collaboration. The authors have created a prototype of a potential solution to this problem, where the model resides in the cloud and can be visualized in augmented reality either as a hologram through a head mounted display or through the AR capabilities of tablets and smartphones. This technology is ideal for WFH scenarios: it is light weight, inexpensive and does not require broadband speeds in excess of what most home users can access.\nWhat we have found is that AR based approaches to modeling large reservoirs can rival traditional workstation approaches. Furthermore, AR based approaches are superior for close collaboration among domain experts. Collaboration on 3D models has not changed significantly in a generation. For co-located personnel the approach is to gather around a 2D screen. For remote personnel the approach is sharing a model through a 2D screen along with video chat. Over the years various attempts have been tried to enhance the collaboration experience and have all fallen short. Virtual reality (VR) has been proposed as a solution. However, we have found that augmented reality (AR) is a much better solution for many reasons which are explored in the paper.\nThe cloud has been transformative for nearly every industry. The oil and gas industry has been slow to adopt cloud technologies for many reasons that have largely been overcome. AR has already acquired an impressive track record in various industries. AR will have applications in nearly all industries. For various historical reasons, the uptake for AR is much faster in some industries than others. It is too early to tell whether the use of cloud-based augmented reality for modeling large reservoirs will be transformative, however the results of this initial work are promising.",
        "link": "http://dx.doi.org/10.2118/203025-ms"
    },
    {
        "id": 14949,
        "title": "Scalable Filtering of Large Graph-Coupled Hidden Markov Models",
        "authors": "Ravi N. Haksar, Joseph Lorenzetti, Mac Schwager",
        "published": "2019-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc40024.2019.9029382"
    },
    {
        "id": 14950,
        "title": "Large-Scale Thermochemistry Calculations for Combustion Models",
        "authors": "Kiran Yalamanchi, Yang Li, Tairan Wang, Manuel Monge-Palacios, Mani Sarathy",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4075603"
    },
    {
        "id": 14951,
        "title": "End-to-End Training of Acoustic Models for Large Vocabulary Continuous Speech Recognition with TensorFlow",
        "authors": "Ehsan Variani, Tom Bagby, Erik McDermott, Michiel Bacchiani",
        "published": "2017-8-20",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2017-1284"
    },
    {
        "id": 14952,
        "title": "Improved Latent Factor Models for Undirected and Sparse Networks with Large Scales",
        "authors": "Ming Li, Yan Song, Guisong Yang, Guoliang Wei",
        "published": "2019-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/chicc.2019.8865968"
    },
    {
        "id": 14953,
        "title": "Implementing an empirical scalar tertiary anisotropic rheology (ESTAR) into large-scale ice sheet models",
        "authors": "Felicity S. Graham, Mathieu Morlighem, Roland C. Warner, Adam Treverrow",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract. The microstructural evolution that occurs in polycrystalline ice during deformation leads to the development of anisotropic rheological properties that are not adequately described by the most common, isotropic, ice flow relation used in large-scale ice sheet models – the Glen flow relation. We present a preliminary assessment of the implementation in the Ice Sheet System Model (ISSM) of a computationally-efficient, empirical, scalar, tertiary, anisotropic rheology (ESTAR). The effect of this anisotropic rheology on ice flow dynamics is investigated by comparing idealised simulations using ESTAR with those using the isotropic Glen flow relation, where the latter includes a flow enhancement factor. For an idealised embayed ice shelf, the Glen flow relation overestimates velocities by up to 17 % when using an enhancement factor equivalent to the maximum value prescribed by ESTAR. Importantly, no single Glen enhancement factor can accurately capture the spatial variations in flow over the ice shelf. For flow-line studies of idealised grounded flow over a bumpy topography or a sticky base – both scenarios dominated at depth by bed-parallel shear – the differences between simulated velocities using ESTAR and the Glen flow relation vary according to the value of the enhancement factor used to calibrate the Glen flow relation. These results demonstrate the importance of describing the anisotropic rheology of ice in a physically realistic manner, and have implications for simulations of ice sheet evolution used to reconstruct paleo-ice sheet extent and predict future ice sheet contributions to sea level.\n                        ",
        "link": "http://dx.doi.org/10.5194/tc-2017-54"
    },
    {
        "id": 14954,
        "title": "Developmental differences of large-scale functional brain networks for spoken word processing",
        "authors": "Xin Liu, Yin He, Yue Gao, James R. Booth, Lihuan Zhang, Shudong Zhang, Chunming Lu, Li Liu",
        "published": "2022-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.bandl.2022.105149"
    },
    {
        "id": 14955,
        "title": "Implementation of hospital wide dysphagia screening in a large acute tertiary teaching hospital",
        "authors": "Sarah Heaton, Anna Farrell, Lynell Bassett",
        "published": "2020-1-2",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/17549507.2019.1597922"
    },
    {
        "id": 14956,
        "title": "Bayesian methods for ancestral state reconstruction in morphosyntax: Exploring the history of argument marking strategies in a large language family",
        "authors": "Joshua Phillips, Claire Bowern",
        "published": "2022-7-23",
        "citations": 3,
        "abstract": "AbstractBayesian phylogenetic methods have been gaining traction and currency in historical linguistics, as their potential for uncovering elements of language change is increasingly understood. Here, we demonstrate a proof of concept for using ancestral state reconstruction methods to reconstruct changes in morphology. We use a simple Brownian motion model of character evolution to test how splits in ergative marking evolve across Pama-Nyungan, a large family of Australian languages. We are able to recover linguistically plausible paths of change, as well as rejecting implausible paths. The results of these analyses elucidate constraints on changes that have led to extensive synchronic variation in an interlocking morphological system. They further provide evidence of an ergative–accusative split traceable to Proto-Pama-Nyungan.",
        "link": "http://dx.doi.org/10.1093/jole/lzac002"
    },
    {
        "id": 14957,
        "title": "KoBigBird-large: Transformation of Transformer for Korean Language Understanding",
        "authors": "Kisu Yang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.ijcnlp-main.68"
    },
    {
        "id": 14958,
        "title": "Disentangling Semantics and Syntax in Sentence Embeddings with Pre-trained Language Models",
        "authors": "James Y. Huang, Kuan-Hao Huang, Kai-Wei Chang",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.naacl-main.108"
    },
    {
        "id": 14959,
        "title": "Can training neural language models on a curriculum with developmentally plausible data improve alignment with human reading behavior?",
        "authors": "Aryaman Chobey, Oliver Smith, Anzi Wang, Grusha Prasad",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-babylm.9"
    },
    {
        "id": 14960,
        "title": "Pretrained Language Models v. Court Ruling Predictions: A Case Study on a Small Dataset of French Court of Appeal Rulings",
        "authors": "Olivia Vaudaux, Caroline Bazzoli, Maximin Coavoux, Géraldine Vial, Étienne Vergès",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.nllp-1.5"
    },
    {
        "id": 14961,
        "title": "Linguistic Models, Acquisition Theories, and Learner Corpora: Morphological Productivity in SLA Research Exemplified by Complex Verbs in German",
        "authors": "Anke Lüdeling, Hagen Hirschmann, Anna Shadrova",
        "published": "2017-6",
        "citations": 9,
        "abstract": "The present study analyzes morphological productivity for complex verbs in second language acquisition by analyzing a corpus of German as a Foreign Language (GFL). It shows that advanced learners of GFL use prefix and particle verbs relatively frequently and productively but less so than native speakers do and discusses these findings in the light of different linguistic models and acquisition theories. It argues that corpus data must be evaluated against good models and that it is necessary to make the categorization decisions available as annotations.",
        "link": "http://dx.doi.org/10.1111/lang.12231"
    },
    {
        "id": 14962,
        "title": "Best practice guidance for linear mixed-effects models in psychological science",
        "authors": "Lotte Meteyard, Robert A.I. Davies",
        "published": "2020-6",
        "citations": 237,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jml.2020.104092"
    },
    {
        "id": 14963,
        "title": "Designing a Multilingual Large-Scale Placement Test with a Formative Perspective: A Case Study at the University of Grenoble Alpes",
        "authors": "Cristiana Cervini, Monica Masperi",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-33-4232-3_18"
    },
    {
        "id": 14964,
        "title": "Natural Language Processing with Graph and Machine Learning Algorithms-based Large-scale Text Document Summarization and Its Applications",
        "authors": "Shaikh Ashfaq Amir, Pathan Mohd. Shafi, Vinod V. Kimbahune, Vijaykumar S. Bidve",
        "published": "2022-11-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003272649-5"
    },
    {
        "id": 14965,
        "title": "Thus spoke GPT-3: Interviewing a large-language model on climate finance",
        "authors": "Markus Leippold",
        "published": "2023-5",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.frl.2022.103617"
    },
    {
        "id": 14966,
        "title": "Large-Scale Representation Learning from Visually Grounded Untranscribed Speech",
        "authors": "Gabriel Ilharco, Yuan Zhang, Jason Baldridge",
        "published": "2019",
        "citations": 20,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/k19-1006"
    },
    {
        "id": 14967,
        "title": "MassiveSumm: a very large-scale, very multilingual, news summarisation dataset",
        "authors": "Daniel Varab, Natalie Schluter",
        "published": "2021",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.797"
    },
    {
        "id": 14968,
        "title": "Automating intended target identification for paraphasias in discourse using a large language model",
        "authors": "Alexandra C. Salem, Robert C. Gale, Mikala Fleegle, Gerasimos Fergadiotis, Steven Bedrick",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractPurposeTo date there are no automated tools for the identification and fine-grained classification of paraphasias within discourse, the production of which is the hallmark characteristic of most people with aphasia (PWA). In this work we fine-tune a large language model (LLM) to automatically predict paraphasia targets in Cinderella story retellings.MethodData consisted of 353 Cinderella story retellings containing 2,489 paraphasias from PWA, for which research assistants identified their intended targets. We supplemented this training data with 256 sessions from control participants, to which we added 2,427 synthetic paraphasias. We conducted four experiments using different training data configurations to fine-tune the LLM to automatically “fill in the blank” of the paraphasia with a predicted target, given the context of the rest of the story retelling. We tested the experiments’ predictions against our human-identified targets and stratified our results by ambiguity of the targets and clinical factors.ResultsThe model trained on controls and PWA achieved 46.8% accuracy at exactly matching the human-identified target. Fine-tuning on PWA data, with or without controls, led to comparable performance. The model performed better on targets with less human ambiguity, and on paraphasias from participants with less severe or fluent aphasia.ConclusionWe were able to automatically identify the intended target of paraphasias in discourse using just the surrounding language about half of the time. These findings take us a step closer to automatic aphasic discourse analysis. In future work, we will incorporate phonological information from the paraphasia to further improve predictive utility.",
        "link": "http://dx.doi.org/10.1101/2023.06.18.23291555"
    },
    {
        "id": 14969,
        "title": "Analysis on the Basic Problems of Safe and Efficient Utilization of Large-scale New Energy Power",
        "authors": "",
        "published": "2021-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47939/et.v2i12.264"
    },
    {
        "id": 14970,
        "title": "Homology detection using a protein secondary structure-based large language model",
        "authors": "Roman Kogay, Weicheng Ma, Jad Bousselham, Zechen Yang, Daniel Rockmore, Olga Zhaxybayeva, Soroush Vosoughi",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractDetection of homology among proteins is fundamental to understanding protein function. Unfortunately, traditional homology searches using amino acid sequence similarity are limited when numerous amino acid substitutions have accumulated either due to billions of years of evolution or through processes of accelerated change. Recent applications of deep-learning approaches demonstrate that “protein language” models of amino acid sequences can improve the accuracy of the traditional homology searches. Ultimately, the ability to work seamlessly with tertiary structures of proteins will solve the homology detection challenge and provide accompanying insights directly related to function, but to date the use of 3D structures suffers both from data availability and computational bottlenecks. Herein, we present the Protein Secondary Structure Language (ProSSL) model, an efficient encoding of protein secondary structure information in a Transformer-based deep-learning architecture. We conjecture that the secondary protein structure, which is better conserved than primary sequences and much more easily predictable and available than tertiary protein structure, could aid in the task of homology detection. ProSSL has the computational advantages of primary sequence-based homology detection, while also providing important structural information for similarity scoring. Using two case studies of large, diverse viral protein families, we show that the ProSSL model successfully captures patterns of secondary structure arrangements and is effective in detecting homologs either as a pre-trained or fine-tuned model. In both tasks, we accurately detect members of these protein families, including those missed in traditional amino acid similarity searches. We also illustrate how functional insights from the individual ProSSL models could be obtained from the use of the Shapley Additive exPlanations (SHAP) values.Author SummaryWhen DNA is obtained from an organism or an environment, scientists are tasked with determining the functions of the proteins encoded in the genetic material. Such “functional annotation” relies on assigning functions based on the similarity of the proteins to counterparts in databases comprising annotated sequence data. Especially challenging is an ability to recognize similarity in proteins that accumulated a lot of amino acid changes. It is well-known that spatial structure of proteins that share ancestry and perform similar functions evolves much slower than the sequences of the proteins’ amino acids. Thus, comparison of 3D structures could address this challenge, but the data is still limited to certain classes of proteins, and the requisite computations are expensive. Herein we present a deep-learning model derived from protein secondary structure representation, a symbolic encoding of the way neighboring amino acid residues of a protein interact with each other. Unlike 3D structure, the secondary structure is quickly and accurately predictable from amino acid sequences of proteins. Using two viral proteins as case studies, we demonstrate that our model works well for detection of protein similarity, including identification of very distantly related proteins.",
        "link": "http://dx.doi.org/10.1101/2023.12.19.572443"
    },
    {
        "id": 14971,
        "title": "When to Use Large Language Model: Upper Bound Analysis of BM25 Algorithms in Reading Comprehension Task",
        "authors": "Tingzhen Liu, Qianqian Xiong, Shengxi Zhang",
        "published": "No Date",
        "citations": 1,
        "abstract": "Large language model (LLM) is a representation of a major advancement in AI, and has been used in multiple natural language processing tasks. Nevertheless, in different business scenarios, LLM requires fine-tuning by engineers to achieve satisfactory performance, and the cost of achieving target performance and fine-tuning may not match. Based on the Baidu STI dataset, we study the upper bound of the performance that classical information retrieval methods can achieve under a specific business, and compare it with the cost and performance of the participating team based on LLM. This paper gives an insight into the potential of classical computational linguistics algorithms, and which can help decision-makers make reasonable choices for LLM and low-cost methods in business R&amp;D.",
        "link": "http://dx.doi.org/10.20944/preprints202301.0219.v1"
    },
    {
        "id": 14972,
        "title": "Leveraging a large language model to predict protein phase transition: a physical, multiscale and interpretable approach",
        "authors": "Mor Frank, Pengyu Ni, Matthew Jensen, Mark B Gerstein",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractProtein phase transitions (PPTs) from the soluble state to a dense liquid phase (forming droplets via liquid-liquid phase separation) or solid aggregates (such as amyloid) play key roles in pathological processes associated with age-related diseases such as Alzheimer’s disease (AD). Several computational frameworks are capable of separately predicting the formation of protein droplets or amyloid aggregates based on protein sequences, yet none have tackled the prediction of both within a unified framework. Recently, large language models (LLMs) have exhibited great success in protein structure prediction; however, they have not yet been used for PPTs. Here, we fine-tune a LLM for predicting PPTs and demonstrate its superior performance compared to suitable classical benchmarks. Due to the “black-box” nature of the LLM, we also employ a classical random forest model along with biophysical features to facilitate interpretation. Finally, focusing on AD-related proteins, we demonstrate that greater aggregation is associated with reduced gene expression in AD, suggesting a natural defense mechanism.Significance StatementThe protein phase transition is a physical mechanism associated with both physiological processes and age-related diseases. Here, we present a modeling approach for predicting a specific protein sequence’s propensity to undergo phase transitions directly from its sequence. Our methodology involves utilizing a large language model to analyze the likelihood of a given protein sequence existing in a particular material state. Additionally, for enhanced interpretability, we incorporate a classical knowledge-based model. Our results suggest the potential for accurately predicting the propensity to form either liquid or solid condensates. Furthermore, our findings indicate the potential regulation of this propensity by gene expression under pathological conditions to prevent aggregation.",
        "link": "http://dx.doi.org/10.1101/2023.11.21.568125"
    },
    {
        "id": 14973,
        "title": "Harvesting Global Oceanic Lead Data Using Machine Learning: Standardization, Alignment and Spatio-temporal Puzzle Assembly with Large Language Model",
        "authors": "Yiming Liu, Shiyu Liang, Xinbing Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "The scarcity and inherently challenging nature of acquiring observational data has long hampered our understanding of elemental lead (Pb) distribution across global oceans. Recent advancements in data mining and machine learning offer new directions to address this challenge. In this study, we capitalize on our team's existing data mining system, DataExpo, to collate Pb-related data sets accessible via the internet, aiming to depict a comprehensive picture of global oceanic Pb. The collected datasets are heterogeneous in nature, exhibiting variances across data descriptions, formats, and types due to disparate data sources. To facilitate congruity in data amalgamation, Llama2, a generative large language model (LLM), is used to achieve semantic understanding to standardize and align the differing data table headers. Following the standardization and alignment processes, the aggregated data are spliced according to geographical location and temporal period, creating a complete spatio-temporal puzzle of global oceanic lead. The ultimate portrayal of this panoramic view promises to shed light on the global cycling pathways of Pb within our oceans. Among the anticipated outcomes are the identification of origins of Pb contamination and the elucidation of potential cycling pathways. These findings are critical for targeted interventions to mitigate contamination effects and enhance our understanding of bio-geochemical processes. Further advancements in global oceanic lead estimates are foreseen through iterative enhancements of our generative large language model application methodology.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-8790"
    },
    {
        "id": 14974,
        "title": "CAM: A Large Language Model-based Creative Analogy Mining Framework",
        "authors": "Bhavya Bhavya, Jinjun Xiong, Chengxiang Zhai",
        "published": "2023-4-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3543507.3587431"
    },
    {
        "id": 14975,
        "title": "Why do people produce pronouns? Pragmatic selection vs. rational models",
        "authors": "Jennifer E. Arnold, Sandra A. Zerkle",
        "published": "2019-10-21",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/23273798.2019.1636103"
    },
    {
        "id": 14976,
        "title": "Models of Disability and the Translation to Psychiatric Categories",
        "authors": "Michelle O’Reilly, Jessica Nina Lester",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-60095-6_5"
    },
    {
        "id": 14977,
        "title": "Role-specific Language Models for Processing Recorded Neuropsychological Exams",
        "authors": "Tuka Al Hanai, Rhoda Au, James Glass",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/n18-2117"
    },
    {
        "id": 14978,
        "title": "Chapter 2. From lexical bundles to surprisal and language models",
        "authors": "Gerold Schneider, Gintare Grigonyte",
        "published": "2018-2-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/scl.82.02sch"
    },
    {
        "id": 14979,
        "title": "Global Spelling Correction in Context using Language Models: Application to the Arabic Language",
        "authors": "Saida Laaroussi, Abdellah Yousfi, Si Lhoussain Aouragh, Said Ouatik El Alaoui",
        "published": "2023-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.12785/ijcds/130129"
    },
    {
        "id": 14980,
        "title": "ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained Language Models for Question Answering over Knowledge Graph",
        "authors": "Jinhao Jiang, Kun Zhou, Xin Zhao, Yaliang Li, Ji-Rong Wen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.228"
    },
    {
        "id": 14981,
        "title": "Integrating Language Models into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection",
        "authors": "Dennis Fucci, Marco Gaido, Sara Papi, Mauro Cettolo, Matteo Negri, Luisa Bentivogli",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.705"
    },
    {
        "id": 14982,
        "title": "Document Hashing with Mixture-Prior Generative Models",
        "authors": "Wei Dong, Qinliang Su, Dinghan Shen, Changyou Chen",
        "published": "2019",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-1526"
    },
    {
        "id": 14983,
        "title": "Task repetition and corrective feedback via models and direct corrections among young EFL writers: Draft quality and task motivation",
        "authors": "Hanne Roothooft, Amparo Lázaro-Ibarrola, Bram Bulté",
        "published": "2022-4-26",
        "citations": 8,
        "abstract": " Second language (L2) writing research has demonstrated that young learners discuss linguistic issues, make use of feedback, and show a generally positive disposition toward writing tasks. However, many issues deserve further investigation. Regarding task implementation, few studies have been conducted with young learners writing individually, and few have compared different feedback types. Also, the focus of analysis has mostly been placed on students’ discussions; little is known about aspects such as draft quality and task motivation. To address these gaps, draft quality and task motivation were measured in 75 learners (aged 10–12 years) engaged in a three-stage writing task. They were divided into a task repetition group ( n = 21), a group that received feedback via direct corrections ( n = 30), and a group that received feedback via model texts ( n = 24). Students’ drafts improved very slightly in complexity with task repetition; they significantly improved in accuracy with direct corrections, and also in lexical diversity and text quality with models. Task motivation remained high throughout the writing cycle in the task repetition group, where students found the task easy. However, it dropped slightly with direct corrections and – especially before the final draft, with models – which students deemed conducive to learning but difficult. Some pedagogical guidelines are discussed. ",
        "link": "http://dx.doi.org/10.1177/13621688221082041"
    },
    {
        "id": 14984,
        "title": "GPT4All: An Ecosystem of Open Source Compressed Language Models",
        "authors": "Yuvanesh Anand, Zach Nussbaum, Adam Treat, Aaron Miller, Richard Guo, Benjamin Schmidt, Brandon Duderstadt, Andriy Mulyar",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.nlposs-1.7"
    },
    {
        "id": 14985,
        "title": "LLMs in e-commerce: A comparative analysis of GPT and LLaMA models in product review evaluation",
        "authors": "Konstantinos I. Roumeliotis, Nikolaos D. Tselikas, Dimitrios K. Nasiopoulos",
        "published": "2024-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.nlp.2024.100056"
    },
    {
        "id": 14986,
        "title": "JointLK: Joint Reasoning with Language Models and Knowledge Graphs for Commonsense Question Answering",
        "authors": "Yueqing Sun, Qi Shi, Le Qi, Yu Zhang",
        "published": "2022",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.372"
    },
    {
        "id": 14987,
        "title": "Neural Machine Translation Models using Binarized Prediction and Error Correction",
        "authors": "Yusuke Oda, Philip Arthur, Graham Neubig, Koichiro Yoshino, Satoshi Nakamura",
        "published": "2018-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5715/jnlp.25.167"
    },
    {
        "id": 14988,
        "title": "“I’m sorry to hear that”: Finding New Biases in Language Models with a Holistic Descriptor Dataset",
        "authors": "Eric Michael Smith, Melissa Hall, Melanie Kambadur, Eleonora Presani, Adina Williams",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.emnlp-main.625"
    },
    {
        "id": 14989,
        "title": "Causal Distillation for Language Models",
        "authors": "Zhengxuan Wu, Atticus Geiger, Joshua Rozner, Elisa Kreiss, Hanson Lu, Thomas Icard, Christopher Potts, Noah Goodman",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.318"
    },
    {
        "id": 14990,
        "title": "Regularized Training of Nearest Neighbor Language Models",
        "authors": "Jean-Francois Ton, Walter Talbott, Shuangfei Zhai, Joshua M. Susskind",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-srw.4"
    },
    {
        "id": 14991,
        "title": "L2 irregular verb morphology: Exploring behavioral data from intermediate English learners of German as a foreign language using generalized mixed effects models",
        "authors": "Thomas Wagner",
        "published": "2017-9-15",
        "citations": 2,
        "abstract": "This paper examines possible psycholinguistic mechanisms governing stem vowel changes of irregular verbs in intermediate English learners of German as a foreign language (GFL). In Experiment 1, nonce-infinitives embedded in an authentic fictional text had to be inflected for German preterite, thus testing possible analogy driven pattern associations. Experiment 2 explored the psycholinguistic reality of the so-called apophonic path by prompting two inflections for one given nonce-word. Data were analyzed using generalized mixed effects models accounting for within-subject as well as within-item variance. The results of Experiment 1 and 2 support the notion of a pattern associator and yield only scarce evidence for the psycholinguistic reality of a universal apophonic path. Therefore, the organization of irregular verb morphology in the mental lexicon of intermediate GFL learners might best be captured by the linguistic notion of structured lexical entries as well as the psycholinguistic mechanism of an analogy-based pattern associator.",
        "link": "http://dx.doi.org/10.14746/ssllt.2017.7.3.9"
    },
    {
        "id": 14992,
        "title": "The Increasing Need for Quality Assurance and Accreditation in Foreign Language Education",
        "authors": "Donald F. Staub",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-21421-0_1"
    },
    {
        "id": 14993,
        "title": "Visual Interrogation of Attention-Based Models for Natural Language Inference and Machine Comprehension",
        "authors": "Shusen Liu, Tao Li, Zhimin Li, Vivek Srikumar, Valerio Pascucci, Peer-Timo Bremer",
        "published": "2018",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d18-2007"
    },
    {
        "id": 14994,
        "title": "XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models",
        "authors": "Davis Liang, Hila Gonen, Yuning Mao, Rui Hou, Naman Goyal, Marjan Ghazvininejad, Luke Zettlemoyer, Madian Khabsa",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.813"
    },
    {
        "id": 14995,
        "title": "Generating identities with mixture models for speaker anonymization",
        "authors": "Henry Turner, Giulio Lovisotto, Ivan Martinovic",
        "published": "2022-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csl.2021.101318"
    },
    {
        "id": 14996,
        "title": "Combatting online harassment by using transformer language models for the detection of emotions, hate speech and offensive language on social media",
        "authors": "Doorgesh Sookarah, Loovesh S. Ramwodin",
        "published": "2022-11-22",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/elecom54934.2022.9965237"
    },
    {
        "id": 14997,
        "title": "Usage of Combinational Acoustic Models (DNN-HMM and SGMM) and Identifying the Impact of Language Models in Sinhala Speech Recognition",
        "authors": "Buddhi Gamage, Randil Pushpananda, Ruvan Weerasinghe, Thilini Nadungodage",
        "published": "2020-11-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icter51097.2020.9325439"
    },
    {
        "id": 14998,
        "title": "WECHSEL: Effective initialization of subword embeddings for cross-lingual transfer of monolingual language models",
        "authors": "Benjamin Minixhofer, Fabian Paischer, Navid Rekabsaz",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.293"
    },
    {
        "id": 14999,
        "title": "Emotion Classification in German Plays with Transformer-based Language Models Pretrained on Historical and Contemporary Language",
        "authors": "Thomas Schmidt, Katrin Dennerlein, Christian Wolff",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.latechclfl-1.8"
    },
    {
        "id": 15000,
        "title": "Transfer Knowledge from Natural Language to Electrocardiography: Can We Detect Cardiovascular Disease Through Language Models?",
        "authors": "Jielin Qiu, William Han, Jiacheng Zhu, Mengdi Xu, Michael Rosenberg, Emerson Liu, Douglas Weber, Ding Zhao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-eacl.33"
    }
]