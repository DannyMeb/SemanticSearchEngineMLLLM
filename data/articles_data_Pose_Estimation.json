[
    {
        "id": 12771,
        "title": "Camera Pose Estimation using Human Head Pose Estimation",
        "authors": "Robert Fischer, Michael Hödlmoser, Margrit Gelautz",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010879400003124"
    },
    {
        "id": 12772,
        "title": "Pose Estimation Problems",
        "authors": "",
        "published": "2017-7-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781316671528.009"
    },
    {
        "id": 12773,
        "title": "3D Human Pose Estimation = 2D Pose Estimation + Matching",
        "authors": "Ching-Hang Chen, Deva Ramanan",
        "published": "2017-7",
        "citations": 316,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr.2017.610"
    },
    {
        "id": 12774,
        "title": "Pose-and-Point Estimation Problems",
        "authors": "",
        "published": "2017-7-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781316671528.010"
    },
    {
        "id": 12775,
        "title": "Simple Pose Based Graph Reasoning for Human Pose Estimation",
        "authors": "Jia Wang, Yanmin Luo, Guihu Bai",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nAiming at the challenge of modeling the relations globally among different body joints. In this paper, we proposed a simple network based on graph reasoning for human pose estimation, which named SP-GRe. We introduce dilated convolution to construct a Dilated Bottleneck Module (DRM), which can enlarge the receptive field and exploit its feature extraction capability. Meanwhile, it can enhance the model’s local representations of each key point. In view of the potential advantages of graph-based propagation, we design a Global Graph Reasoning module (GGR) based on graph convolution. The module stores the explicit joints in the graph structure for global relationship reasoning. By aggregating the features of local joints and global graph nodes, GGR enables the accurate location of key points in the interaction between projection and back-projection. Comprehensive experiments demonstrate that the proposed method achieves superior top-down pose estimation results on two benchmark datasets, MSCOCO and MPII. Moreover, SP-GRe demonstrates superior results on human pose estimation over popular human pose estimation networks.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1737952/v1"
    },
    {
        "id": 12776,
        "title": "Pose Estimation Problems",
        "authors": "",
        "published": "2024-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009299909.010"
    },
    {
        "id": 12777,
        "title": "Ego-Body Pose Estimation via Ego-Head Pose Estimation",
        "authors": "Jiaman Li, C. Karen Liu, Jiajun Wu",
        "published": "2023-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01644"
    },
    {
        "id": 12778,
        "title": "Ego-Body Pose Estimation via Ego-Head Pose Estimation",
        "authors": "Jiaman Li, C. Karen Liu, Jiajun Wu",
        "published": "2023-6",
        "citations": 0,
        "abstract": "\n            Estimating 3D human motion from an ego-centric video, which records the environment viewed from the first-person perspective with a front-facing monocular camera, is critical to applications in VR/AR. However, naively learning a mapping between egocentric videos and full-body human motions is challenging for two reasons. First, modeling this complex relationship is difficult; unlike reconstruction motion from third-person videos, the human body is often out of view of an egocentric video. Second, learning this mapping requires a large-scale, diverse dataset containing paired egocentric videos and the corresponding 3D human poses. Creating such a dataset requires meticulous instrumentation for data acquisition, and unfortunately, such a dataset does not currently exist. As such, existing works have only worked on small-scale datasets with limited motion and scene diversity\n            (yuan20183d; yuan2019ego; luo2021dynamics).\n",
        "link": "http://dx.doi.org/10.1145/3609468.3609473"
    },
    {
        "id": 12779,
        "title": "P2p-Gnet: Proposal-to-Pose Voting Using Multi-Level Graphnet with Pose Refinement for Hand Pose Estimation",
        "authors": "Zhiwei Zheng, Hui Qin, Yuhua Qu, Shuai Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4469567"
    },
    {
        "id": 12780,
        "title": "Pose estimation for robotic percussive riveting.",
        "authors": "Yu Lin",
        "published": "No Date",
        "citations": 0,
        "abstract": "Recently, a robotic percussive riveting system has been developed at Ryerson University for an automation of percussive riveting process of aero-structural fastening assembly. The system consists of a robot holding a percussive riveting gun equipped with a rivet feeder, a gantry holding a working panel of aero-structure, and a position visual sensor. Prior to riveting, the robot is required to first position and then insert a rivet precisely into a hole on the panel without engaging the panel to prevent potential damage. The underlying challenges to precise insertion are various sources of system uncertainties, mainly including alignment errors among coordinate systems of the robot, panel and sensor, and relatively poor absolute positioning accuracy of the robot due to mechanical deflection, assembly clearance, and machining tolerance. For this reason, the research of relative pose estimation between the robot and panel has been carried out pertaining to these challenges.\n\nEssentially, pose estimation is proposed for robotic percussive riveting, which estimates the relative pose between two rigid bodies based on noisy visual measurements of point features on rigid bodies. Three categories can be classified, namely, static, dynamic, and robust pose estimation. Firstly, static pose estimation is the parameter estimation of static relative pose transformations among a number of frames, which solves the issue of alignment errors. Direct solutions of static relative pose estimation are derived based on least-square methods. Secondly, to tackle the issue of poor absolute positioning accuracy of the robot, dynamic relative pose estimation is proposed addressing a state estimation of relative poses during motion. Iterative extended Kalman filter method is adapted for the state estimation. Thirdly, for robustness against outliers of point measurements, robust pose estimation is proposed based on an outlier diagnosis using the technique of relaxation of rigid body constraints. Indeed, outlier diagnosis is a pre-processing of point measurements, in which outliers are detected and removed prior to the relative pose estimation. Further, a decorrelation method is proposed for measurement calibration using multivariate statistical analysis to find an optimal sensor-to-target configuration. As a result, each coordinate measurement is close to uncorrelated and it allows for a simple calibration.",
        "link": "http://dx.doi.org/10.32920/ryerson.14662803"
    },
    {
        "id": 12781,
        "title": "Pose estimation for robotic percussive riveting.",
        "authors": "Yu Lin",
        "published": "No Date",
        "citations": 0,
        "abstract": "Recently, a robotic percussive riveting system has been developed at Ryerson University for an automation of percussive riveting process of aero-structural fastening assembly. The system consists of a robot holding a percussive riveting gun equipped with a rivet feeder, a gantry holding a working panel of aero-structure, and a position visual sensor. Prior to riveting, the robot is required to first position and then insert a rivet precisely into a hole on the panel without engaging the panel to prevent potential damage. The underlying challenges to precise insertion are various sources of system uncertainties, mainly including alignment errors among coordinate systems of the robot, panel and sensor, and relatively poor absolute positioning accuracy of the robot due to mechanical deflection, assembly clearance, and machining tolerance. For this reason, the research of relative pose estimation between the robot and panel has been carried out pertaining to these challenges.\n\nEssentially, pose estimation is proposed for robotic percussive riveting, which estimates the relative pose between two rigid bodies based on noisy visual measurements of point features on rigid bodies. Three categories can be classified, namely, static, dynamic, and robust pose estimation. Firstly, static pose estimation is the parameter estimation of static relative pose transformations among a number of frames, which solves the issue of alignment errors. Direct solutions of static relative pose estimation are derived based on least-square methods. Secondly, to tackle the issue of poor absolute positioning accuracy of the robot, dynamic relative pose estimation is proposed addressing a state estimation of relative poses during motion. Iterative extended Kalman filter method is adapted for the state estimation. Thirdly, for robustness against outliers of point measurements, robust pose estimation is proposed based on an outlier diagnosis using the technique of relaxation of rigid body constraints. Indeed, outlier diagnosis is a pre-processing of point measurements, in which outliers are detected and removed prior to the relative pose estimation. Further, a decorrelation method is proposed for measurement calibration using multivariate statistical analysis to find an optimal sensor-to-target configuration. As a result, each coordinate measurement is close to uncorrelated and it allows for a simple calibration.",
        "link": "http://dx.doi.org/10.32920/ryerson.14662803.v1"
    },
    {
        "id": 12782,
        "title": "Deformable Pose Network: A Multi-Stage Deformable Convolutional Network for 2D Hand Pose Estimation",
        "authors": "Sartaj Salman, Ali Zakir, Hiroki Takahashi",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012569000003660"
    },
    {
        "id": 12783,
        "title": "Pose-and-Point Estimation Problems",
        "authors": "",
        "published": "2024-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009299909.011"
    },
    {
        "id": 12784,
        "title": "An Augmented Reality Mirror Exergame using 2D Pose Estimation",
        "authors": "Fernando Losilla, Francisca Rosique",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007798906430648"
    },
    {
        "id": 12785,
        "title": "Next Viewpoint Recommendation by Pose Ambiguity Minimization for Accurate Object Pose Estimation",
        "authors": "Nik Hashim, Yasutomo Kawanishi, Daisuke Deguchi, Ichiro Ide, Hiroshi Murase, Ayako Amma, Norimasa Kobori",
        "published": "2019",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007366700600067"
    },
    {
        "id": 12786,
        "title": "Next Viewpoint Recommendation by Pose Ambiguity Minimization for Accurate Object Pose Estimation",
        "authors": "Nik Hashim, Yasutomo Kawanishi, Daisuke Deguchi, Ichiro Ide, Hiroshi Murase, Ayako Amma, Norimasa Kobori",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007366700002108"
    },
    {
        "id": 12787,
        "title": "Distributed Human 3D Pose Estimation and Action Recognition",
        "authors": "Guoliang Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "In this paper, we propose a distributed solution for3D human pose estimation using a RGBD camera network. Thekey feature of our method is a dynamic hybrid consensus filter(DHCF) is introduced to fuse the multiple view informationof cameras. In contrast to the centralized fusion solution,the DHCF algorithm can be used in a distributed network,which requires no central information fusion center. Therefore,the DHCF based fusion algorithm can benefit from manyadvantages of distributed network. We also show that theproposed fusion algorithm can handle the occlusion problemseffectively, and achieve higher action recognition rate comparedto the ones using only single view information.<br>",
        "link": "http://dx.doi.org/10.36227/techrxiv.11687196.v1"
    },
    {
        "id": 12788,
        "title": "Integrated Driver Pose Estimation for Autonomous Driving",
        "authors": "Xiao Cao, Wei Hu, Hui Liu",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012639400003657"
    },
    {
        "id": 12789,
        "title": "Hidden Markov Models for Pose Estimation",
        "authors": "László Czúni, Amr Nagy",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009357505980603"
    },
    {
        "id": 12790,
        "title": "Distributed Human 3D Pose Estimation and Action Recognition",
        "authors": "Guoliang Liu",
        "published": "No Date",
        "citations": 1,
        "abstract": "In this paper, we propose a distributed solution for3D human pose estimation using a RGBD camera network. Thekey feature of our method is a dynamic hybrid consensus filter(DHCF) is introduced to fuse the multiple view informationof cameras. In contrast to the centralized fusion solution,the DHCF algorithm can be used in a distributed network,which requires no central information fusion center. Therefore,the DHCF based fusion algorithm can benefit from manyadvantages of distributed network. We also show that theproposed fusion algorithm can handle the occlusion problemseffectively, and achieve higher action recognition rate comparedto the ones using only single view information.<br>",
        "link": "http://dx.doi.org/10.36227/techrxiv.11687196"
    },
    {
        "id": 12791,
        "title": "AiShifu: AI Karate Pose Trainer Using Human Pose Estimation",
        "authors": "Frederick Lu",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "One application of the artificial intelligence (AI) technology is self-guided physical activities where a computing device acts as a trainer. One key challenge for these applications is how to measure the performance of such an AI trainer, especially when the AI trainer is run on a generic PC or a mobile device. In the spirit of the Turing test, an AI trainer should mimic the behavior of a human trainer. A good human trainer generally considers the training history and the level of the trainee when providing feedback, which requires more than body position analysis. In this work, we built a Martial Art trainer application called AIShifu that helps users practice martial art poses using Human Pose Estimation (HPE). We chose an open-source neural network called HRNET trained with MS-COCO dataset as the core of the HPE. The joint coordinates and angles were used to identify the pose being practiced by the trainee, whether the active side is left or right, and how close is the key joint angle to that from a “golden” image. We collected data from both a black belt martial artist and a novice trainee and on three Karate poses. Based on the data, it is clear that the blackbelt performed the poses more consistently. A much larger sample size was required to test how well an AI trainer can discern the difference between trainees with different levels of proficiency. This understanding forms the foundation to customize AI trainer softwares for different users.",
        "link": "http://dx.doi.org/10.47611/jsrhs.v12i3.5063"
    },
    {
        "id": 12792,
        "title": "Human Pose Estimation from Monocular Images",
        "authors": "Bastian Wandt",
        "published": "2020",
        "citations": 0,
        "abstract": "\nAbstract\nThis dissertation deals with the problem of capturing human motions and poses using a single camera. The frst part of the thesis proposes two closely related approaches for the 3D reconstruction of human motions from image sequences. To resolve inherent ambiguities in monocular 3D reconstruction the main idea of this part is to exploit temporal properties of human motions in combination with a human body model learned from training data. The second part of the thesis tackles the problem of reconstructing a human pose from a single image. A human body model is learned by training a deep neural network that covers nonlinearities and anthropometric constraints.\nC O N T E N T S\n1 Introduction ….. 1\n1.1 Applications and Commercial Systems . . . . . . . . . . . 1\n1.2 Image-based Motion Capture . . . . . . . . . . . . . . . . 2\n1.3 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.3.1 Time Consistent Human Motion Reconstruction . 6\n1.3.2 RepNet . . . . . . . ...",
        "link": "http://dx.doi.org/10.51202/9783186869104"
    },
    {
        "id": 12793,
        "title": "3D Human Pose Estimation from Deep Multi-View 2D Pose",
        "authors": "Steven Schwarcz, Thomas Pollard",
        "published": "2018-8",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icpr.2018.8545631"
    },
    {
        "id": 12794,
        "title": "Posegu: 3d Human Pose Estimation with Novel Human Pose Generator and Unbiased Learning",
        "authors": "Shannan GUAN, Haiyan LU, Linchao ZHU, Gengfa FANG",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4327712"
    },
    {
        "id": 12795,
        "title": "Improvement of Pose Transfer by Introducing 3D Pose Estimation",
        "authors": "Mahiro Watanabe, Ikuko Shimizu",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/gcce59613.2023.10315346"
    },
    {
        "id": 12796,
        "title": "On Exploring Pose Estimation as an Auxiliary Learning Task for Visible-Infrared Person Re-Identificationon Exploring Pose Estimation as an Auxiliary Learning Task",
        "authors": "Yunqi Miao, Nianchang Huang, Xiao Ma, Qiang Zhang, Jungong Han",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4445220"
    },
    {
        "id": 12797,
        "title": "Articulated Pose Estimation",
        "authors": "",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-63416-2_300218"
    },
    {
        "id": 12798,
        "title": "Vehicle Pose Estimation: Exploring Angular Representations",
        "authors": "Ivan Orlov, Marco Buzzelli, Raimondo Schettini",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012574300003660"
    },
    {
        "id": 12799,
        "title": "Hybrid 6D Object Pose Estimation from the RGB Image",
        "authors": "Rafal Staszak, Dominik Belter",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007933105410549"
    },
    {
        "id": 12800,
        "title": "Real-time 2D Multi-Person Pose Estimation on CPU: Lightweight OpenPose",
        "authors": "Daniil Osokin",
        "published": "2019",
        "citations": 92,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007555407440748"
    },
    {
        "id": 12801,
        "title": "Pointless Pose: Part Affinity Field-Based 3D Pose Estimation without Detecting Keypoints",
        "authors": "Jue Wang, Zhigang Luo",
        "published": "2021-4-13",
        "citations": 2,
        "abstract": "Human pose estimation finds its application in an extremely wide domain and is therefore never pointless. We propose in this paper a new approach that, unlike any prior one that we are aware of, bypasses the 2D keypoint detection step based on which the 3D pose is estimated, and is thus pointless. Our motivation is rather straightforward: 2D keypoint detection is vulnerable to occlusions and out-of-image absences, in which case the 2D errors propagate to 3D recovery and deteriorate the results. To this end, we resort to explicitly estimating the human body regions of interest (ROI) and their 3D orientations. Even if a portion of the human body, like the lower arm, is partially absent, the predicted orientation vector pointing from the upper arm will take advantage of the local image evidence and recover the 3D pose. This is achieved, specifically, by deforming a skeleton-shaped puppet template to fit the estimated orientation vectors. Despite its simple nature, the proposed approach yields truly robust and state-of-the-art results on several benchmarks and in-the-wild data.",
        "link": "http://dx.doi.org/10.3390/electronics10080929"
    },
    {
        "id": 12802,
        "title": "Adapted human pose: monocular 3D human pose estimation with zero real 3D pose data",
        "authors": "Shuangjun Liu, Naveen Sehgal, Sarah Ostadabbas",
        "published": "2022-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10489-022-03341-6"
    },
    {
        "id": 12803,
        "title": "Application of the extended Kalman filter to LIDAR pose estimation",
        "authors": "Marcin Kuryllo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The goal of this work is to investigate the benefits of using a well-known nonlinear motion estimator, an Extended Kalman Filter (EKF), in conjunction with the Iterative Closest Point algorithm (ICP}, in particular, for the purpose of tracking the pose of a target satellite using a chaser satellite equipped with a LIDAR sensor. To accomplish this goal, two different architectures for tracking the pose of a target satellite were first implemented in MATLAB Simulink, and then implemented and tested on the Canadian Space Agency Automated Robotics Test Bed (CART} at the Canadian Space Agency (CSA} using a Neptec Laser Camera System as a sensor. The two architectures are: a} a pose tracking architecture that accepts the estimated pose supplied by the EKF to provide an initial pose guess to the ICP algorithm; and b) a pose tracking architecture that uses the pose supplied by the pervious pose measurement from the ICP algorithm as the initial pose guess for the ICP algorithm. The pose estimator combine with the EKF was able to track an object with a higher rate of motion then the rate possible without a nonlinear estimator. When the EKF estimate of the target satellite's states converges, a decrease in the number of ICP iterations per sensor measurement was also observed. Furthermore, the EKF increased the robustness of the system allowing the system to continue tracking after blackout periods. The test results showed an increased level of robustness of the tracking architecture that utilizes a nonlinear estimator in conjunction with the ICP algorithm. The advantages of the use of EKF were observed both in a simulated environment and experimentation.</p>",
        "link": "http://dx.doi.org/10.32920/ryerson.14658153"
    },
    {
        "id": 12804,
        "title": "Application of the extended Kalman filter to LIDAR pose estimation",
        "authors": "Marcin Kuryllo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The goal of this work is to investigate the benefits of using a well-known nonlinear motion estimator, an Extended Kalman Filter (EKF), in conjunction with the Iterative Closest Point algorithm (ICP}, in particular, for the purpose of tracking the pose of a target satellite using a chaser satellite equipped with a LIDAR sensor. To accomplish this goal, two different architectures for tracking the pose of a target satellite were first implemented in MATLAB Simulink, and then implemented and tested on the Canadian Space Agency Automated Robotics Test Bed (CART} at the Canadian Space Agency (CSA} using a Neptec Laser Camera System as a sensor. The two architectures are: a} a pose tracking architecture that accepts the estimated pose supplied by the EKF to provide an initial pose guess to the ICP algorithm; and b) a pose tracking architecture that uses the pose supplied by the pervious pose measurement from the ICP algorithm as the initial pose guess for the ICP algorithm. The pose estimator combine with the EKF was able to track an object with a higher rate of motion then the rate possible without a nonlinear estimator. When the EKF estimate of the target satellite's states converges, a decrease in the number of ICP iterations per sensor measurement was also observed. Furthermore, the EKF increased the robustness of the system allowing the system to continue tracking after blackout periods. The test results showed an increased level of robustness of the tracking architecture that utilizes a nonlinear estimator in conjunction with the ICP algorithm. The advantages of the use of EKF were observed both in a simulated environment and experimentation.</p>",
        "link": "http://dx.doi.org/10.32920/ryerson.14658153.v1"
    },
    {
        "id": 12805,
        "title": "ConvPoseCNN: Dense Convolutional 6D Object Pose Estimation",
        "authors": "Catherine Capellen, Max Schwarz, Sven Behnke",
        "published": "2020",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008990901620172"
    },
    {
        "id": 12806,
        "title": "Regression-based 3D Hand Pose Estimation using Heatmaps",
        "authors": "Chaitanya Bandi, Ulrike Thomas",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008973206360643"
    },
    {
        "id": 12807,
        "title": "A Real-time Affordance-based Object Pose Estimation Approach for Robotic Grasp Pose Estimation",
        "authors": "Shang-Wen Wong, Yu-Chen Chiu, Chi-Yi Tsai",
        "published": "2023-7-27",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icsse58758.2023.10227244"
    },
    {
        "id": 12808,
        "title": "B-Pose: Bayesian Deep Network for Accurate Camera 6-DoF Pose Estimation from RGB Images",
        "authors": "Aref Miri Rekavandi, Farid Boussaid, ABD-KRIM SEGHOUANE, Mohammed Bennamoun",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Camera pose estimation has long relied on geometry-based approaches and sparse 2D-3D keypoint correspondences. With the advent of deep learning methods, the estimation of camera pose parameters (i.e., the six parameters that describe position and rotation) has decreased from tens of meters to a few centimeters in median error for indoor applications. For outdoor applications, errors can be quite large and highly dependent on the levels of variations in occlusion, contrast, brightness, repetitive structures, or blur introduced by camera motion. To address these limitations, we introduce, BPose, a Bayesian Convolutional deep network capable of not only automatically estimating the camera’s pose parameters from a single RGB image but also providing a measure of uncertainty in the parameter estimation. Reported experiments on outdoor and indoor datasets demonstrate that B-Pose outperforms SOTA techniques and generalizes better to unseen RGB images. A strong correlation is shown between the prediction error and the model’s uncertainty, indicating that the prediction is almost always incorrect whenever the model’s uncertainty is high.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.21951398.v1"
    },
    {
        "id": 12809,
        "title": "Bibliography",
        "authors": "Bastian Wandt",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.51202/9783186869104-101"
    },
    {
        "id": 12810,
        "title": "Anti-drift pose tracker (ADPT): A transformer-based network for robust animal pose estimation cross-species",
        "authors": "Guoling Tang, Yaning Han, Quanying Liu, Pengfei Wei",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractDeep learning-based methods for animal pose estimation have recently made substantial progress in improving the accuracy and efficiency of quantitative descriptions of animal behavior. However, these methods commonly suffer from tracking drifts, i.e., sudden jumps in the estimated position of a body point due to noise, thus reducing the reliability of behavioral study results. Here, we present a transformer-based animal pose estimation tool, called Anti-Drift Pose Tracker (ADPT), for eliminating tracking drifts in behavior analysis. To verify the anti-drift performance of ADPT, we conduct extensive experiments in multiple cross-species datasets, including long-term recorded mouse and monkey behavioral datasets collected by ourselves, as well as two public Drosophilas and macaques datasets. Our results show that ADPT greatly reduces the rate of tracking drifts, and significantly outperforms the existing deep-learning methods, such as DeepLabCut, SLEAP, and DeepPoseKit. Moreover, ADPT is compatible with multi-animal pose estimation, enabling animal identity recognition and social behavioral study. Specifically, ADPT provided an identification accuracy of 93.16% for 10 unmarked mice, and of 90.36% for free-social unmarked mice which can be further refined to 99.72%. Compared to other multi-stage network-based tools like multi-animal DeepLabCut, SIPEC and Social Behavior Atlas, the end-to-end structure of ADPT supports its lower computational costs and meets the needs of real-time analysis. Together, ADPT is a versatile anti-drift animal behavior analysis tool, which can greatly promote the accuracy, robustness, and reproducibility of animal behavioral studies. The code of ADPT is available athttps://github.com/tangguoling/ADPT.",
        "link": "http://dx.doi.org/10.1101/2024.02.06.579164"
    },
    {
        "id": 12811,
        "title": "Zero-Shot Pose Estimation Using Image Translation Maintaining Object Pose",
        "authors": "Kohei Fujita, Tsuyoshi Tasaki",
        "published": "2024-1-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/sii58957.2024.10417482"
    },
    {
        "id": 12812,
        "title": "B-Pose: Bayesian Deep Network for Accurate Camera 6-DoF Pose Estimation from RGB Images",
        "authors": "Aref Miri Rekavandi, Farid Boussaid, ABD-KRIM SEGHOUANE, Mohammed Bennamoun",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Camera pose estimation has long relied on geometry-based approaches and sparse 2D-3D keypoint correspondences. With the advent of deep learning methods, the estimation of camera pose parameters (i.e., the six parameters that describe position and rotation) has decreased from tens of meters to a few centimeters in median error for indoor applications. For outdoor applications, errors can be quite large and highly dependent on the levels of variations in occlusion, contrast, brightness, repetitive structures, or blur introduced by camera motion. To address these limitations, we introduce, BPose, a Bayesian Convolutional deep network capable of not only automatically estimating the camera’s pose parameters from a single RGB image but also providing a measure of uncertainty in the parameter estimation. Reported experiments on outdoor and indoor datasets demonstrate that B-Pose outperforms SOTA techniques and generalizes better to unseen RGB images. A strong correlation is shown between the prediction error and the model’s uncertainty, indicating that the prediction is almost always incorrect whenever the model’s uncertainty is high.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.21951398"
    },
    {
        "id": 12813,
        "title": "Continuous Sign-Language Recognition using Transformers and Augmented Pose Estimation",
        "authors": "Reemt Hinrichs, Angelo Sitcheu, Jörn Ostermann",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011709100003411"
    },
    {
        "id": 12814,
        "title": "Unsupervised 3D Human Pose Estimation in Multi-view-multi-pose Video",
        "authors": "Cheng Sun, Diego Thomas, Hiroshi Kawasaki",
        "published": "2021-1-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icpr48806.2021.9412270"
    },
    {
        "id": 12815,
        "title": "Oa-Pose: Occlusion-Aware Monocular 6-Dof Object Pose Estimation Under Geometry Alignment for Robot Manipulation",
        "authors": "Jikun Wang, Luqing Luo, Weixiang Liang, Zhi-Xin Yang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4391367"
    },
    {
        "id": 12816,
        "title": "3  Fundamentals",
        "authors": "Bastian Wandt",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.51202/9783186869104-22"
    },
    {
        "id": 12817,
        "title": "Titelei/Inhaltsverzeichnis",
        "authors": "Bastian Wandt",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.51202/9783186869104-i"
    },
    {
        "id": 12818,
        "title": "Human Pose Estimation",
        "authors": "Leonid Sigal",
        "published": "2021",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-63416-2_584"
    },
    {
        "id": 12819,
        "title": "Crane Spreader Pose Estimation from a Single View",
        "authors": "Maria Pateraki, Panagiotis Sapoutzoglou, Manolis Lourakis",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011788800003417"
    },
    {
        "id": 12820,
        "title": "6  Conclusions",
        "authors": "Bastian Wandt",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.51202/9783186869104-97"
    },
    {
        "id": 12821,
        "title": "Automated Pose Estimation in Primates",
        "authors": "Benjamin Hayden, Hyun Soo Park, Jan Zimmermann",
        "published": "No Date",
        "citations": 5,
        "abstract": "Understanding the behavior of primates is important for primatology, for psychology, and for biology more broadly. It is also important for biomedicine, where primates are an important model organism, and whose behavior is often an important variable of interest. Our ability to rigorously quantify behavior has, however, long been limited. On one hand, we can rigorously quantify low-information measures like preference, looking time, and reaction time; on the other, we can use more gestalt measures like behavioral categories tracked via ethogram, but at high cost and with high variability. Recent technological advances have led to a major revolution in behavioral measurement that offers affordable and scalable rigor. Specifically, digital video cameras and automated pose tracking software can provide measures of full body position (i.e., pose) of primates over time (i.e., behavior) with high spatial and temporal resolution. Pose-tracking technology in turn can be used to infer behavioral states, such as eating, sleeping, and mating. We call this technological approach behavioral imaging. In this review, we situate the behavioral imaging revolution in the history of the study of behavior, argue for investment in and development of analytical and research techniques that can profit from the advent of the era of big behavior, and propose that primate centers and zoos will take on a more central role in relevant fields of research than they have in the past.",
        "link": "http://dx.doi.org/10.31234/osf.io/36e7h"
    },
    {
        "id": 12822,
        "title": "Player pose analysis in tennis video based on pose estimation",
        "authors": "Ryunosuke Kurose, Masaki Hayashi, Takeo Ishii, Yoshimitsu Aoki",
        "published": "2018-1",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iwait.2018.8369762"
    },
    {
        "id": 12823,
        "title": "Multi-Instance Pose Networks: Rethinking Top-Down Pose Estimation",
        "authors": "Rawal Khirodkar, Visesh Chari, Amit Agrawal, Ambrish Tyagi",
        "published": "2021-10",
        "citations": 44,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv48922.2021.00311"
    },
    {
        "id": 12824,
        "title": "Inter-Pose: An Interactive 3D Modeling Based on 6D Pose Estimation",
        "authors": "Yuzhi Li, Xingjun Wang",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aiim60438.2023.10441042"
    },
    {
        "id": 12825,
        "title": "Rigid Body Dynamics Estimation by Unscented Filtering Pose Estimation Neural Networks",
        "authors": "Trevor Avant, Kristi A. Morgansen",
        "published": "2020-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/acc45564.2020.9147262"
    },
    {
        "id": 12826,
        "title": "Accurate 6D Object Pose Estimation and Refinement in Cluttered Scenes",
        "authors": "Yixiang Jin, John Rossiter, Sandor Veres",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010654500003061"
    },
    {
        "id": 12827,
        "title": "Evaluation of Camera Pose Estimation Using Human Head Pose Estimation",
        "authors": "Robert Fischer, Michael Hödlmoser, Margrit Gelautz",
        "published": "2023-3-30",
        "citations": 2,
        "abstract": "AbstractWe introduce and evaluate a novel camera pose estimation framework that uses the human head as a calibration object. The proposed method facilitates extrinsic calibration from 2D input images (NIR and/or RGB), while merely relying on the detected human head, without the need for depth information. The approach is applicable to single cameras or multi-camera networks. Our implementation uses a fine-tuned deep learning-based 2D human facial landmark detector to estimate the 3D human head pose by fitting a 3D head model to the detected 2D facial landmarks. Our work focuses on an evaluation of the proposed approach on real multi-camera recordings and synthetic renderings to determine the accuracy of the pose estimation results and their applicability. We assess the robustness of our method against different input parameters, such as varying relative camera positions, variations of head models, face occlusions (by masks, sun glasses, etc.), potential biases and variance among humans. Based on the experimental results, we expect our approach to be effective for numerous use cases including automotive attention monitoring, robotics, VR/AR and other scenarios where ease of handling outweighs accuracy.",
        "link": "http://dx.doi.org/10.1007/s42979-023-01709-0"
    },
    {
        "id": 12828,
        "title": "Video-based 3D pose estimation for residential roofing (dataset).",
        "authors": "",
        "published": "2022-8-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26616/nioshrd-1042-2022-0"
    },
    {
        "id": 12829,
        "title": "Pose Estimation",
        "authors": "",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-23161-2_300931"
    },
    {
        "id": 12830,
        "title": "Principal Component Analysis for ICP Pose Estimation of Space Structures",
        "authors": "Lun H. Mark",
        "published": "No Date",
        "citations": 0,
        "abstract": "This thesis investigates how geometry of complex objects is related to LIDAR scanning with the Iterative Closest Point (ICP) pose estimation and provides statistical means to assess the pose accuracy.  LIDAR scanners have become essential parts of space vision systems for autonomous docking and rendezvous.  Principal Componenet Analysis based geometric constraint indices have been found to be strongly related to the pose error norm and the error of each individual degree of freedom.  This leads to the development of several strategies for identifying the best view of an object and the optimal combination of localized scanned areas of the object's surface to achieve accurate pose estimation.  Also investigated is the possible relation between the ICP pose estimation accuracy and the districution or allocation of the point cloud.  The simulation results were validated using point clouds generated by scanning models of Quicksat and a cuboctahedron using Neptec's TriDAR scanner.",
        "link": "http://dx.doi.org/10.32920/ryerson.14656941"
    },
    {
        "id": 12831,
        "title": "Automatic SAR Target Recognition and Pose Estimation. Part 1. Geometric Methods for Pose Estimation",
        "authors": "Tarik Namas, Migdat Hodžić",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-71321-2_76"
    },
    {
        "id": 12832,
        "title": "Principal Component Analysis for ICP Pose Estimation of Space Structures",
        "authors": "Lun H. Mark",
        "published": "No Date",
        "citations": 0,
        "abstract": "This thesis investigates how geometry of complex objects is related to LIDAR scanning with the Iterative Closest Point (ICP) pose estimation and provides statistical means to assess the pose accuracy.  LIDAR scanners have become essential parts of space vision systems for autonomous docking and rendezvous.  Principal Componenet Analysis based geometric constraint indices have been found to be strongly related to the pose error norm and the error of each individual degree of freedom.  This leads to the development of several strategies for identifying the best view of an object and the optimal combination of localized scanned areas of the object's surface to achieve accurate pose estimation.  Also investigated is the possible relation between the ICP pose estimation accuracy and the districution or allocation of the point cloud.  The simulation results were validated using point clouds generated by scanning models of Quicksat and a cuboctahedron using Neptec's TriDAR scanner.",
        "link": "http://dx.doi.org/10.32920/ryerson.14656941.v1"
    },
    {
        "id": 12833,
        "title": "1  Introduction",
        "authors": "Bastian Wandt",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.51202/9783186869104-1"
    },
    {
        "id": 12834,
        "title": "Head Pose Estimation with Uncertainty",
        "authors": "Federico  Figari Tomenotti, Nicoletta Noceti, Francesca Odone",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4399244"
    },
    {
        "id": 12835,
        "title": "SDFPoseGraphNet: Spatial Deep Feature Pose Graph Network for 2D Hand Pose Estimation",
        "authors": "Sartaj Ahmed Salman, Ali Zakir, Hiroki Takahashi",
        "published": "2023-11-10",
        "citations": 1,
        "abstract": "In the field of computer vision, hand pose estimation (HPE) has attracted significant attention from researchers, especially in the fields of human–computer interaction (HCI) and virtual reality (VR). Despite advancements in 2D HPE, challenges persist due to hand dynamics and occlusions. Accurate extraction of hand features, such as edges, textures, and unique patterns, is crucial for enhancing HPE. To address these challenges, we propose SDFPoseGraphNet, a novel framework that combines the strengths of the VGG-19 architecture with spatial attention (SA), enabling a more refined extraction of deep feature maps from hand images. By incorporating the Pose Graph Model (PGM), the network adaptively processes these feature maps to provide tailored pose estimations. First Inference Module (FIM) potentials, alongside adaptively learned parameters, contribute to the PGM’s final pose estimation. The SDFPoseGraphNet, with its end-to-end trainable design, optimizes across all components, ensuring enhanced precision in hand pose estimation. Our proposed model outperforms existing state-of-the-art methods, achieving an average precision of 7.49% against the Convolution Pose Machine (CPM) and 3.84% in comparison to the Adaptive Graphical Model Network (AGMN).",
        "link": "http://dx.doi.org/10.3390/s23229088"
    },
    {
        "id": 12836,
        "title": "Multi Person Pose Estimation and 3D Pose Detection Animation",
        "authors": "Anand R N, Suja Palaniswamy",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/smartgencon60755.2023.10442905"
    },
    {
        "id": 12837,
        "title": "Fast and Robust Vehicle Pose Estimation by Optimizing Multiple Pose Graphs",
        "authors": "Maxmilian Harr, Johannes Janosovits, Christoph Stiller, Sascha Wirges",
        "published": "2018-7",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/icif.2018.8455309"
    },
    {
        "id": 12838,
        "title": "CullNet: Calibrated and Pose Aware Confidence Scores for Object Pose Estimation",
        "authors": "Kartik Gupta, Lars Petersson, Richard Hartley",
        "published": "2019-10",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccvw.2019.00337"
    },
    {
        "id": 12839,
        "title": "Real-time Human Pose Estimation with Convolutional Neural Networks",
        "authors": "Marko Linna, Juho Kannala, Esa Rahtu",
        "published": "2018",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006624403350342"
    },
    {
        "id": 12840,
        "title": "Reviewer #2 (Public Review): OpenApePose: a database of annotated ape photographs for pose estimation",
        "authors": "",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.86873.2.sa2"
    },
    {
        "id": 12841,
        "title": "eLife assessment: OpenApePose: a database of annotated ape photographs for pose estimation",
        "authors": "Ammie Kalan",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.86873.2.sa0"
    },
    {
        "id": 12842,
        "title": "Target Design for LIDAR-Based ICP Pose Estimation for Space Vision Tasks",
        "authors": "Aradhana Choudhuri",
        "published": "No Date",
        "citations": 0,
        "abstract": "The goal of this thesis is to develop a methodology for designing 3D target shapes for accurate LIDAR pose estimation. Scanned from a range of views, this shape can be attached to the surface of a spacecraft and deliver accurate pose scanned. It would act as an LIDAR- based analogue to fiducial markers placed on the surface and viewed by CCD camera(s). Continuum Shape Constraint Analysis (CSCA) which assesses shapes for pose estimation and measures the performance of the Iterative Closest Point (ICP) Algorithm is used as a shape design tool. CSCA directly assesses the sensitivity of pose error to variation in viewing direction. Three of the CSCA measures, Noise Amplification Index, Minimal Eigen-value and Expectivity Index, were compared, and Expectivity Index was shown to be the best index to use as shape design tool. Using CSCA and numerical simulations, a Cuboctahedron was shown to be an optimal  shape which delivers an accurate pose when viewed from all angles and the nitial pose guess is close to the true poses. Separate from Constraint Analysis, the problem of shape ambiguity was addressed using numerical tools.  The Cuboctahedron was modified in order to resolve shape ambiguity - the tendency of the ICP algorithm to converge with low registration error on a pose configuration geometrically identical, but actually different from a “true pose”. The numerical characteristics of geometrical ambiguity were studied, and a heuristic design methodology to reduce shape ambiguity was developed and is presented in this thesis. A Reduced Ambiguity Cuboctahedron is the resultant shape that delivers an accurate pose from all views and does not suffer from shape ambiguity. The shapes were subjected to simulation and experimental validation. They were manufactured using 3D Rapid Prototyper, and a NEPTEC Design Group TriDAR Scanner was used to obtain experimental data for three shapes: the Tetrahedron, Cuboctahedron, and reduced Ambiguity  Cuboctahedron. The Tetrahedron, which has poorly constrained views, was included in the testing process as a comparison shape. The simulation and experimental results were congruent, and validated the design methodology and the designed shapes.",
        "link": "http://dx.doi.org/10.32920/ryerson.14648208.v1"
    },
    {
        "id": 12843,
        "title": "Smoothness-based Consistency Learning for Macaque Pose Estimation",
        "authors": "Ping Xue, ShiXiong Deng",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nMacaques are a rare substitute and play an important role in study of human psychology and spiritual science. Accurate estimation of macaque pose information is key to these studies,macaque pose estimation remains to be hindered by the scarcity of labeled images. To address this problem, this work introduces a novel semi-supervised approach called smoothness-based spatio-temporal consistency learning (SSTCL) and a dual network structure (DNS) to leverage the amounts of unlabeled real images. Specifically, the SSTCL introduce the smoothness assumption to help the model generalize from the labeled training images to the unlabeled images, and the spatiotemporal consistency is designed to leverage both spatial and temporal consistencies to pick the most reliable pseudo labels. Moreover, a dual network structure (DNS) is proposed to empower the model the ability of self-correction, which can prevent the degeneration caused by the noisy pseudo labels in semi-supervised learning. In ablation experiments, the effectiveness of DNS for pseudolabel quality assurance is demonstrated. We evaluate the proposed method on the public OpenMonkeyPose dataset, the results show that the proposed method can achieve competitive performance while using less labeled images, and the final accuracy surpasses the strong baseline HRNet-w48 of 2.1 AP.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2185088/v1"
    },
    {
        "id": 12844,
        "title": "Human Pose Estimation through a Novel Multi-view Scheme",
        "authors": "Jorge Charco, Angel Sappa, Boris Vintimilla",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010899900003124"
    },
    {
        "id": 12845,
        "title": "PoseAug: A Differentiable Pose Augmentation Framework for 3D Human Pose Estimation",
        "authors": "Kehong Gong, Jianfeng Zhang, Jiashi Feng",
        "published": "2021-6",
        "citations": 78,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr46437.2021.00847"
    },
    {
        "id": 12846,
        "title": "Point-To-Pose Voting Based Hand Pose Estimation Using Residual Permutation Equivariant Layer",
        "authors": "Shile Li, Dongheui Lee",
        "published": "2019-6",
        "citations": 45,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr.2019.01220"
    },
    {
        "id": 12847,
        "title": "Posegu: 3d Human Pose Estimation with Novel Human Pose Generator and Unbiased Learning",
        "authors": "Shannan GUAN, Haiyan LU, Linchao ZHU, Gengfa FANG",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4248596"
    },
    {
        "id": 12848,
        "title": "2  Related Work",
        "authors": "Bastian Wandt",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.51202/9783186869104-17"
    },
    {
        "id": 12849,
        "title": "Rotation and Pose Extras",
        "authors": "",
        "published": "2024-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009299909.014"
    },
    {
        "id": 12850,
        "title": "eLife assessment: OpenApePose: a database of annotated ape photographs for pose estimation",
        "authors": "Ammie Kalan",
        "published": "2023-7-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.86873.1.sa0"
    },
    {
        "id": 12851,
        "title": "Reviewer #2 (Public Review):: OpenApePose, a database of annotated ape photographs for pose estimation",
        "authors": "",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.86873.3.sa2"
    },
    {
        "id": 12852,
        "title": "Fully Convolutional Neural Network for Event Camera Pose Estimation",
        "authors": "Ahmed Tabia, Fabien Bonardi, Samia Bouchafa-Bruneau",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011641500003417"
    },
    {
        "id": 12853,
        "title": "An Effective Deep Network for Head Pose Estimation without Keypoints",
        "authors": "Chien Thai, Viet Tran, Minh Bui, Huong Ninh, Hai Tran",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010870900003122"
    },
    {
        "id": 12854,
        "title": "Reviewer #1 (Public Review): OpenApePose: a database of annotated ape photographs for pose estimation",
        "authors": "",
        "published": "2023-7-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.86873.1.sa1"
    },
    {
        "id": 12855,
        "title": "Reviewer #2 (Public Review): OpenApePose: a database of annotated ape photographs for pose estimation",
        "authors": "",
        "published": "2023-7-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.86873.1.sa2"
    },
    {
        "id": 12856,
        "title": "Pose guided structured region ensemble network for cascaded hand pose estimation",
        "authors": "Xinghao Chen, Guijin Wang, Hengkai Guo, Cairong Zhang",
        "published": "2020-6",
        "citations": 98,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neucom.2018.06.097"
    },
    {
        "id": 12857,
        "title": "Reviewer #1 (Public Review): OpenApePose: a database of annotated ape photographs for pose estimation",
        "authors": "",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.86873.2.sa1"
    },
    {
        "id": 12858,
        "title": "Reviewer #1 (Public Review):: OpenApePose, a database of annotated ape photographs for pose estimation",
        "authors": "",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.86873.3.sa1"
    },
    {
        "id": 12859,
        "title": "Target Design for LIDAR-Based ICP Pose Estimation for Space Vision Tasks",
        "authors": "Aradhana Choudhuri",
        "published": "No Date",
        "citations": 0,
        "abstract": "The goal of this thesis is to develop a methodology for designing 3D target shapes for accurate LIDAR pose estimation. Scanned from a range of views, this shape can be attached to the surface of a spacecraft and deliver accurate pose scanned. It would act as an LIDAR- based analogue to fiducial markers placed on the surface and viewed by CCD camera(s). Continuum Shape Constraint Analysis (CSCA) which assesses shapes for pose estimation and measures the performance of the Iterative Closest Point (ICP) Algorithm is used as a shape design tool. CSCA directly assesses the sensitivity of pose error to variation in viewing direction. Three of the CSCA measures, Noise Amplification Index, Minimal Eigen-value and Expectivity Index, were compared, and Expectivity Index was shown to be the best index to use as shape design tool. Using CSCA and numerical simulations, a Cuboctahedron was shown to be an optimal  shape which delivers an accurate pose when viewed from all angles and the nitial pose guess is close to the true poses. Separate from Constraint Analysis, the problem of shape ambiguity was addressed using numerical tools.  The Cuboctahedron was modified in order to resolve shape ambiguity - the tendency of the ICP algorithm to converge with low registration error on a pose configuration geometrically identical, but actually different from a “true pose”. The numerical characteristics of geometrical ambiguity were studied, and a heuristic design methodology to reduce shape ambiguity was developed and is presented in this thesis. A Reduced Ambiguity Cuboctahedron is the resultant shape that delivers an accurate pose from all views and does not suffer from shape ambiguity. The shapes were subjected to simulation and experimental validation. They were manufactured using 3D Rapid Prototyper, and a NEPTEC Design Group TriDAR Scanner was used to obtain experimental data for three shapes: the Tetrahedron, Cuboctahedron, and reduced Ambiguity  Cuboctahedron. The Tetrahedron, which has poorly constrained views, was included in the testing process as a comparison shape. The simulation and experimental results were congruent, and validated the design methodology and the designed shapes.",
        "link": "http://dx.doi.org/10.32920/ryerson.14648208"
    },
    {
        "id": 12860,
        "title": "Mask6D: Masked Pose Priors for 6D Object Pose Estimation",
        "authors": "Yuechen Xie, Haobo Jiang, Jin Xie",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447716"
    },
    {
        "id": 12861,
        "title": "Fast and Accurate Pose Estimation in Videos based on Knowledge Distillation and Pose Propagation",
        "authors": "Xiaomao Zhou, Xiaolong Yu, Cheng Xu",
        "published": "2022-7-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn55064.2022.9892706"
    },
    {
        "id": 12862,
        "title": "Domain adaptation of articulated pose estimation via synthetic pose prior",
        "authors": "Kazuhiko Murasaki, Haruka Yonemoto, Kyoko Sudo, Tetsuya Kinebuchi",
        "published": "2017-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/mva.2017.7986820"
    },
    {
        "id": 12863,
        "title": "Pose estimation for six-axis industrial robots based on pose distillation",
        "authors": "Xin Gao, Deng Chen",
        "published": "2022-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aemcse55572.2022.00028"
    },
    {
        "id": 12864,
        "title": "Relative Pose Consistency for Semi-Supervised Head Pose Estimation",
        "authors": "Felix Kuhnke, Sontje Ihler, Jorn Ostermann",
        "published": "2021-12-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/fg52635.2021.9666992"
    },
    {
        "id": 12865,
        "title": "Pose Estimation with Action Classification Using Global-and-Pose Features and Fine-Grained Action-Specific Pose Models",
        "authors": "Norimichi UKITA",
        "published": "2018",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1587/transinf.2017edp7204"
    },
    {
        "id": 12866,
        "title": "Gated Region-Refine pose transformer for human pose estimation",
        "authors": "Tianfeng Wang, Xiaoxu Zhang",
        "published": "2023-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neucom.2023.01.090"
    },
    {
        "id": 12867,
        "title": "Deep Body-pose Estimation via Synthetic Depth Data: A Case Study",
        "authors": "Christopher Pramerdorfer, Martin Kampel",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008941303180325"
    },
    {
        "id": 12868,
        "title": "Human Pose Estimation",
        "authors": "Leonid Sigal",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-03243-2_584-1"
    },
    {
        "id": 12869,
        "title": "Learning toward practical head pose estimation",
        "authors": "",
        "published": "2017-8-19",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/1.oe.56.8.083104"
    },
    {
        "id": 12870,
        "title": "Hand Pose Estimation",
        "authors": "Liuhao Ge, Junsong Yuan",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-63416-2_875"
    }
]