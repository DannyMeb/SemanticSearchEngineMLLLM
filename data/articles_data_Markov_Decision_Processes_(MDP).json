[
    {
        "id": 2901,
        "title": "S-MDP: Streaming With Markov Decision Processes",
        "authors": "Koffka Khan, Wayne Goodridge",
        "published": "2019-8",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tmm.2019.2892304"
    },
    {
        "id": 2902,
        "title": "MDP for Query-Based Wireless Sensor Networks",
        "authors": "Mihaela Mitici",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-47766-4_20"
    },
    {
        "id": 2903,
        "title": "Markov decision processes",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-3"
    },
    {
        "id": 2904,
        "title": "Find Optimal Values and Optimal Policies for Finite MDP",
        "authors": "Zhiqing Xiao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-3740-0_14"
    },
    {
        "id": 2905,
        "title": "Markov Decision Processes",
        "authors": "",
        "published": "2020-7-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108571401.047"
    },
    {
        "id": 2906,
        "title": "Constrained Markov Decision Processes",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 86,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223"
    },
    {
        "id": 2907,
        "title": "Accelerating Interval Iteration for Expected Rewards in Markov Decision Processes",
        "authors": "Mohammadsadegh Mohagheghi, Khayyam Salehi",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009833700390050"
    },
    {
        "id": 2908,
        "title": "Markov Decision Processes",
        "authors": "",
        "published": "2022-5-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009051873.016"
    },
    {
        "id": 2909,
        "title": "Expert-guided Symmetry Detection in Markov Decision Processes",
        "authors": "Giorgio Angelotti, Nicolas Drougard, Caroline Chanel",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010783400003116"
    },
    {
        "id": 2910,
        "title": "Decision letter for \"A primer on Partially Observable Markov Decision Processes (POMDPs)\"",
        "authors": "",
        "published": "2021-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/2041-210x.13692/v3/decision1"
    },
    {
        "id": 2911,
        "title": "Decision letter for \"A primer on Partially Observable Markov Decision Processes (POMDPs)\"",
        "authors": "",
        "published": "2020-12-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/2041-210x.13692/v1/decision1"
    },
    {
        "id": 2912,
        "title": "Decision letter for \"A primer on Partially Observable Markov Decision Processes (POMDPs)\"",
        "authors": "",
        "published": "2021-5-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/2041-210x.13692/v2/decision1"
    },
    {
        "id": 2913,
        "title": "Finding the Optimal Shortest Path in Stochastic Networks Using the Markov Decision Process (MDP)",
        "authors": "",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18576/isl/120830"
    },
    {
        "id": 2914,
        "title": "Dynamic Pricing Strategy for Electromobility using Markov Decision Processes",
        "authors": "Jan Mrkos, Antonín Komenda, Michal Jakob",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006601505070514"
    },
    {
        "id": 2915,
        "title": "Introduction",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-1"
    },
    {
        "id": 2916,
        "title": "Review for \"A primer on Partially Observable Markov Decision Processes (POMDPs)\"",
        "authors": "",
        "published": "2020-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/2041-210x.13692/v1/review2"
    },
    {
        "id": 2917,
        "title": "A Quick Employment of Markov Decision Process (MDP) in Partially Unknown Three-dimensional Discrete Space",
        "authors": "Enxu Liu, Hongyi Zhu",
        "published": "2023-2-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ic-c57619.2023.00016"
    },
    {
        "id": 2918,
        "title": "Stratified Breast Cancer Follow-Up Using a Partially Observable MDP",
        "authors": "J. W. M. Otten, A. Witteveen, I. M. H. Vliegen, S. Siesling, J. B. Timmer, M. J. IJzerman",
        "published": "2017",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-47766-4_7"
    },
    {
        "id": 2919,
        "title": "Review for \"A primer on Partially Observable Markov Decision Processes (POMDPs)\"",
        "authors": "",
        "published": "2021-4-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/2041-210x.13692/v2/review1"
    },
    {
        "id": 2920,
        "title": "Some Applications of the Partially Observable Markov Decision Processes",
        "authors": "Doncho S. Donchev",
        "published": "2023-3-17",
        "citations": 0,
        "abstract": "We give two examples of reduction of a POMDPs model to a MDP model with a complete information. In both MDP models, corresponding Bellman’s equations allow to construct optimal policies. The first example is the classical discrete time disorder problem. We include it into the framework of POMDPs in contrast to the standard approach based on optimal stopping rules. In the second model, we consider the steps of a transaction under threat as a trajectory of POMDP. We show how to define the elements of the model in order to achieve an optimal balance between the successful end of the transaction and minimum applications of mitigating actions.",
        "link": "http://dx.doi.org/10.5772/intechopen.1001135"
    },
    {
        "id": 2921,
        "title": "A context-aware warehouse robots collision detection and avoidance using Markov Decision Process (MDP)",
        "authors": "Yang Liu, Yu Sun",
        "published": "2022-6-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2639526"
    },
    {
        "id": 2922,
        "title": "Sensitivity analysis",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-16"
    },
    {
        "id": 2923,
        "title": "Safe Policy Improvement Approaches on Discrete Markov Decision Processes",
        "authors": "Philipp Scholl, Felix Dietrich, Clemens Otte, Steffen Udluft",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010786600003116"
    },
    {
        "id": 2924,
        "title": "Markov Decision Processes for Screening and Treatment of Chronic Diseases",
        "authors": "Lauren N. Steimle, Brian T. Denton",
        "published": "2017",
        "citations": 36,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-47766-4_6"
    },
    {
        "id": 2925,
        "title": "Self-Triggered Markov Decision Processes",
        "authors": "Yunhan Huang, Quanyan Zhu",
        "published": "2021-12-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc45484.2021.9682918"
    },
    {
        "id": 2926,
        "title": "The discounted cost",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-12"
    },
    {
        "id": 2927,
        "title": "Markov Decision Processes",
        "authors": "Kwang-Cheng Chen",
        "published": "2022-9-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003337256-4"
    },
    {
        "id": 2928,
        "title": "Markov Decision Processes",
        "authors": "",
        "published": "2022-12-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009218245.019"
    },
    {
        "id": 2929,
        "title": "The discounted cost",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-4"
    },
    {
        "id": 2930,
        "title": "Self-Healing Misconfiguration of Cloud-Based IoT Systems Using Markov Decision Processes",
        "authors": "Areeg Samir, Håvard Dagenborg",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011966700003488"
    },
    {
        "id": 2931,
        "title": "The expected average cost",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-13"
    },
    {
        "id": 2932,
        "title": "The expected average cost",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-5"
    },
    {
        "id": 2933,
        "title": "Review for \"A primer on Partially Observable Markov Decision Processes (POMDPs)\"",
        "authors": " Paul L. Fackler",
        "published": "2020-11-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/2041-210x.13692/v1/review1"
    },
    {
        "id": 2934,
        "title": "Markov Decision Processes",
        "authors": "",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811268397_0004"
    },
    {
        "id": 2935,
        "title": "State truncation and approximation",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-19"
    },
    {
        "id": 2936,
        "title": "Solving constrained K-Markov decision processes",
        "authors": "",
        "published": "2021-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36334/modsim.2021.i2.ferrermestres"
    },
    {
        "id": 2937,
        "title": "Markov Decision Processes",
        "authors": "William Uther",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_512"
    },
    {
        "id": 2938,
        "title": "Markov Decision Processes and Stochastic Control Problems on Networks",
        "authors": "Dmitrii Lozovanu, Stefan Wolfgang Pickl",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-40180-0_2"
    },
    {
        "id": 2939,
        "title": "Convergence of discounted constrained MDPs",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-17"
    },
    {
        "id": 2940,
        "title": "Bayes Adaptive Markov Decision Processes",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_100034"
    },
    {
        "id": 2941,
        "title": "Markov Decision Processes with Exogenous Variables",
        "authors": "Robert Bray",
        "published": "No Date",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2919946"
    },
    {
        "id": 2942,
        "title": "Markov Decision Processes: A Gentle Tutorial",
        "authors": "Oualid Missaoui",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4535241"
    },
    {
        "id": 2943,
        "title": "Belief State Markov Decision Processes",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_100039"
    },
    {
        "id": 2944,
        "title": "Risk-aware semi-Markov decision processes",
        "authors": "Jukka Isohataia, William B. Haskell",
        "published": "2017-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc.2017.8264293"
    },
    {
        "id": 2945,
        "title": "The total cost: classification of MDPs",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-9"
    },
    {
        "id": 2946,
        "title": "Discounted Markov Decision Processes with Fuzzy Rewards Induced by Non-fuzzy Systems",
        "authors": "Karla Carrero-Vera, Hugo Cruz-Suárez, Raúl Montes-de-Oca",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010231400490059"
    },
    {
        "id": 2947,
        "title": "Discounted Markov Decision Processes with Fuzzy Rewards Induced by Non-fuzzy Systems",
        "authors": "Karla Carrero-Vera, Hugo Cruz-Suárez, Raúl Montes-de-Oca",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010231400002859"
    },
    {
        "id": 2948,
        "title": "Risk-sensitive Markov Decision Processes with Risk Constraints of Coherent Risk Measures in Fuzzy and Stochastic Environment",
        "authors": "Yuji Yoshida",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007957502690277"
    },
    {
        "id": 2949,
        "title": "Discrete Markov Processes and Numerical Algorithms for Markov Chains",
        "authors": "Dmitrii Lozovanu, Stefan Wolfgang Pickl",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-40180-0_1"
    },
    {
        "id": 2950,
        "title": "Conformal Off-Policy Evaluation in Markov Decision Processes",
        "authors": "Daniele Foffano, Alessio Russo, Alexandre Proutiere",
        "published": "2023-12-13",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc49753.2023.10383469"
    },
    {
        "id": 2951,
        "title": "Risk-aware Q-learning for Markov decision processes",
        "authors": "Wenjie Huang, William B. Haskell",
        "published": "2017-12",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc.2017.8264388"
    },
    {
        "id": 2952,
        "title": "Privacy-Preserving Policy Synthesis in Markov Decision Processes",
        "authors": "Parham Gohari, Matthew Hale, Ufuk Topcu",
        "published": "2020-12-14",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc42340.2020.9304015"
    },
    {
        "id": 2953,
        "title": "Optimal Decision Tree Policies for Markov Decision Processes",
        "authors": "Daniël Vos, Sicco Verwer",
        "published": "2023-8",
        "citations": 0,
        "abstract": "Interpretability of reinforcement learning policies is essential for many real-world tasks but learning such interpretable policies is a hard problem. Particularly, rule-based policies such as decision trees and rules lists are difficult to optimize due to their non-differentiability. While existing techniques can learn verifiable decision tree policies, there is no guarantee that the learners generate a policy that performs optimally. In this work, we study the optimization of size-limited decision trees for Markov Decision Processes (MPDs) and propose OMDTs: Optimal MDP Decision Trees. Given a user-defined size limit and MDP formulation, OMDT directly maximizes the expected discounted return for the decision tree using Mixed-Integer Linear Programming. By training optimal tree policies for different MDPs we empirically study the optimality gap for existing imitation learning techniques and find that they perform sub-optimally. We show that this is due to an inherent shortcoming of imitation learning, namely that complex policies cannot be represented using size-limited trees. In such cases, it is better to directly optimize the tree for expected return. While there is generally a trade-off between the performance and interpretability of machine learning models, we find that on small MDPs, depth 3 OMDTs often perform close to optimally.",
        "link": "http://dx.doi.org/10.24963/ijcai.2023/606"
    },
    {
        "id": 2954,
        "title": "The total cost: Dynamic and Linear Programming",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-11"
    },
    {
        "id": 2955,
        "title": "Convergence as the horizon tends to infinity",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-18"
    },
    {
        "id": 2956,
        "title": "Expected average cost: Dynamic Programming and LP",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-14"
    },
    {
        "id": 2957,
        "title": "MDPs with infinite state and action spaces",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-8"
    },
    {
        "id": 2958,
        "title": "Partially Observable Markov Decision Processes",
        "authors": "Pascal Poupart",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_629"
    },
    {
        "id": 2959,
        "title": "Markov Decision Processes For Multi-Objective Satellite Task Planning",
        "authors": "Duncan Eddy, Mykel Kochenderfer",
        "published": "2020-3",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aero47225.2020.9172258"
    },
    {
        "id": 2960,
        "title": "Developing Decision-Making Algorithm for Unmanned Vessel Navigation Using Markov Processes",
        "authors": "",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23977/mastic.023"
    },
    {
        "id": 2961,
        "title": "Robust Partially Observable Markov Decision Processes",
        "authors": "Mohammad Rasouli, Soroush Saghafian",
        "published": "No Date",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3195310"
    },
    {
        "id": 2962,
        "title": "Markov Decision Processes",
        "authors": "Ashwin Rao, Tikhon Jelvis",
        "published": "2022-10-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003229193-4"
    },
    {
        "id": 2963,
        "title": "Easy Decomposable Markov Decision Processes and Stochastic Games",
        "authors": "Jie Ning",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3225298"
    },
    {
        "id": 2964,
        "title": "Risk-Sensitive Markov Decision Processes",
        "authors": "Christiane Barz, Nicole Bäuerle",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-54621-2_819-1"
    },
    {
        "id": 2965,
        "title": "A Policy Gradient Approach for Finite Horizon Constrained Markov Decision Processes",
        "authors": "Soumyajit Guin, Shalabh Bhatnagar",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc49753.2023.10383413"
    },
    {
        "id": 2966,
        "title": "Asymptotic Security by Model-based Incident Handlers for Markov Decision Processes",
        "authors": "Hampei Sasahara, Henrik Sandberg",
        "published": "2021-12-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc45484.2021.9682989"
    },
    {
        "id": 2967,
        "title": "Simulator-Defined Markov Decision Processes: A Case Study in Managing Bio-invasions",
        "authors": "",
        "published": "2019-2-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108587792.012"
    },
    {
        "id": 2968,
        "title": "Dynamic Programming and Markov Decision Processes",
        "authors": "Steven A. Lippman",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1057/978-1-349-95189-5_80"
    },
    {
        "id": 2969,
        "title": "Constrained total undiscounted continuous-time Markov decision processes",
        "authors": "Xianping Guo, Yi Zhang",
        "published": "2017-8-1",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3150/15-bej793"
    },
    {
        "id": 2970,
        "title": "Weakly Coupled Constrained Markov Decision Processes in Borel Spaces",
        "authors": "Mukul Gagrani, Ashutosh Nayyar",
        "published": "2020-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/acc45564.2020.9147627"
    },
    {
        "id": 2971,
        "title": "Applying Markov Decision Processes to Evaluate Ransomware Data Theft Risks",
        "authors": "Tingting Zhu, Xiang Li, Wenbo Zhang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nRansomware has rapidly evolved into sophisticated, stealthy threats built to extort payments through data encryption and extraction. This paper presents an innovative methodology for ransomware risk evaluation using the mathematical frameworks of Markov Decision Processes (MDP). By modeling ransomware scenarios as MDPs, overlaying risk equations, and applying our analysis, a quantitative assessment of dynamic risk levels and effectiveness of defensive strategies is enabled. The technique is demonstrated through comparative assessment of prominent ransomware groups, industry-specific impact analysis, and time projections of data theft risk trajectories. Despite limitations in model complexity and real-world validation, the methodology elucidates an interdisciplinary approach blending decision theory, control systems and applied mathematics to enrich cyber risk research.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3736872/v1"
    },
    {
        "id": 2972,
        "title": "Weakly Coupled Markov Decision Processes with Imperfect Information",
        "authors": "Mahshid Salemi Parizi, Archis Ghate",
        "published": "2019-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wsc40007.2019.9004927"
    },
    {
        "id": 2973,
        "title": "Risk-sensitive average optimality in Markov decision processes",
        "authors": "Karel Sladký",
        "published": "2018-12-28",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14736/kyb-2018-6-1218"
    },
    {
        "id": 2974,
        "title": "Easy Affine Markov Decision Processes: Theory",
        "authors": "Jie Ning, Matthew J. Sobel",
        "published": "No Date",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2959096"
    },
    {
        "id": 2975,
        "title": "Robust Action Selection in Partially Observable Markov Decision Processes with Model Uncertainty",
        "authors": "Mahmoud El Chamie, Hala Mostafa",
        "published": "2018-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc.2018.8619468"
    },
    {
        "id": 2976,
        "title": "Online Active Perception for Partially Observable Markov Decision Processes with Limited Budget",
        "authors": "Mahsa Ghasemi, Ufuk Topcu",
        "published": "2019-12",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc40024.2019.9029762"
    },
    {
        "id": 2977,
        "title": "Verification of Markov Decision Processes with Risk-Sensitive Measures",
        "authors": "Murat Cubuktepe, Ufuk Topcu",
        "published": "2018-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/acc.2018.8430905"
    },
    {
        "id": 2978,
        "title": "Flow and service control in a single-server queue",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-6"
    },
    {
        "id": 2979,
        "title": "Markov Decision Processes: Application to Treatment Planning",
        "authors": "Matt Baucum, Anahita Khojandi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-54621-2_844-1"
    },
    {
        "id": 2980,
        "title": "The Problems of Risk Probability  for Infinite Discounted Semi-Markov Decision Processes",
        "authors": "Haifeng Huo, Hongxiang Pan, Xian Wen",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4403793"
    },
    {
        "id": 2981,
        "title": "Switched Linear Systems Meet Markov Decision Processes: Stability Guaranteed Policy Synthesis",
        "authors": "Bo Wu, Murat Cubuktepe, Ufuk Topcu",
        "published": "2019-12",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc40024.2019.9029513"
    },
    {
        "id": 2982,
        "title": "Markov Decision Processes",
        "authors": "",
        "published": "2021-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811239359_0010"
    },
    {
        "id": 2983,
        "title": "Learning Policies for Markov Decision Processes in Continuous Spaces",
        "authors": "Santiago Paternain, Juan Andres Bazerque, Austin Small, Alejandro Ribeiro",
        "published": "2018-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc.2018.8619719"
    },
    {
        "id": 2984,
        "title": "Efficient Off-Policy Algorithms for Structured Markov Decision Processes",
        "authors": "Sourav Ganguly, Raghuram Bharadwaj Diddigi, Prabuchandran K J",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc49753.2023.10383276"
    },
    {
        "id": 2985,
        "title": "Least Inferable Policies for Markov Decision Processes",
        "authors": "Mustafa O. Karabag, Melkior Ornik, Ufuk Topcu",
        "published": "2019-7",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/acc.2019.8815129"
    },
    {
        "id": 2986,
        "title": "The total cost: occupation measures and the primal LP",
        "authors": "Eitan Altman",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140223-10"
    },
    {
        "id": 2987,
        "title": "Markov Abstractions for PAC Reinforcement Learning in Non-Markov Decision Processes",
        "authors": "Alessandro Ronca, Gabriel Paludo Licks, Giuseppe De Giacomo",
        "published": "2022-7",
        "citations": 1,
        "abstract": "Our work aims at developing reinforcement learning algorithms that do not rely on the Markov assumption. We consider the class of Non-Markov Decision Processes where histories can be abstracted into a finite set of states while preserving the dynamics. We call it a Markov abstraction since it induces a Markov Decision Process over a set of states that encode the non-Markov dynamics. This phenomenon underlies the recently introduced Regular Decision Processes (as well as POMDPs where only a finite number of belief states is reachable). In all such kinds of decision process, an agent that uses a Markov abstraction can rely on the Markov property to achieve optimal behaviour. We show that Markov abstractions can be learned during reinforcement learning. Our approach combines automata learning and classic reinforcement learning. For these two tasks, standard algorithms can be employed. We show that our approach has PAC guarantees when the employed algorithms have PAC guarantees, and we also provide an experimental evaluation.",
        "link": "http://dx.doi.org/10.24963/ijcai.2022/473"
    },
    {
        "id": 2988,
        "title": "A Contracting Dynamical System Perspective toward Interval Markov Decision Processes",
        "authors": "Saber Jafarpour, Samuel Coogan",
        "published": "2023-12-13",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc49753.2023.10383575"
    },
    {
        "id": 2989,
        "title": "Satisfiability Bounds for ω-Regular Properties in Bounded-Parameter Markov Decision Processes",
        "authors": "Maximilian Weininger, Tobias Meggendorfer, Jan Kretinsky",
        "published": "2019-12",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc40024.2019.9029460"
    },
    {
        "id": 2990,
        "title": "Learning Markov Decision Processes Based on Genetic Programming",
        "authors": "Rong Wu, Jin Xu",
        "published": "2022-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/acie55485.2022.00023"
    },
    {
        "id": 2991,
        "title": "Easy Affine Markov Decision Processes: Algorithms and Applications",
        "authors": "Jie Ning, Matthew J. Sobel",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2998786"
    },
    {
        "id": 2992,
        "title": "On Anderson Acceleration for Partially Observable Markov Decision Processes",
        "authors": "Melike Ermis, Mingyu Park, Insoon Yang",
        "published": "2021-12-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc45484.2021.9683383"
    },
    {
        "id": 2993,
        "title": "Distance-Penalized Active Learning via Markov Decision Processes",
        "authors": "Dingyu Wang, John Lipor, Gautam Dasarathy",
        "published": "2019-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dsw.2019.8755602"
    },
    {
        "id": 2994,
        "title": "Analysis of Risks and Costs in Intruder Detection With Markov Decision Processes",
        "authors": "Jorma Jormakka, Sourangshu Ghosh",
        "published": "No Date",
        "citations": 0,
        "abstract": "Let us assume that defence mechanisms are so strong that the average outcome of a hacking attack is unsuccessful. How to calculate the costs arising from false positives and false negatives in intruder detection? Is it better for the hacker to make fewer but more effective attacks rather than several but less effective attacks? How to calculate the difference between these alternative strategies?",
        "link": "http://dx.doi.org/10.20944/preprints202104.0713.v1"
    },
    {
        "id": 2995,
        "title": "Markov Decision Processes",
        "authors": "J. Frédéric Bonnans",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-14977-2_7"
    },
    {
        "id": 2996,
        "title": "(Not) Throwing the Game - An Application of Markov Decision Processes and Reinforcement Learning to Optimising Darts Strategy",
        "authors": "Graham Baird",
        "published": "No Date",
        "citations": 0,
        "abstract": "This article determines an aimpoint selection strategy for players in order to improve their chances of winning at the classic darts game of 501. Although many studies have considered the problem of aimpoint selection in order to maximise the expected score a player can achieve, few have considered the more general strategical question of minimising the expected number of turns required for a player to finish. By casting the problem as a Markov decision process and utilising the reinforcement learning method of value iteration, a framework is derived for the identification  of the optimal aimpoint for a player in an arbitrary game scenario. This study represents the first analytical investigation of the full game under the normal game rules, and is, to our knowledge, the first application of reinforcement learning methods to the optimisation of darts strategy. The article concludes with an empirical study investigating the optimal aimpoints for a number of player skill levels under a range of game scenarios.",
        "link": "http://dx.doi.org/10.31224/osf.io/p43zn"
    },
    {
        "id": 2997,
        "title": "Application of Markov Decision Processes to High School Mathematics Course-Taking",
        "authors": "Yueban Gongchang",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3102/1566910"
    },
    {
        "id": 2998,
        "title": "Constrained Markov Decision Processes for Intelligent Traffic",
        "authors": "Tripty Singh",
        "published": "2019-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icccnt45670.2019.8944574"
    },
    {
        "id": 2999,
        "title": "Online learning for Markov decision processes applied to multi-agent systems",
        "authors": "Mahmoud El Chamie, Behcet Acikmese, Mehran Mesbahi",
        "published": "2017-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc.2017.8263879"
    },
    {
        "id": 3000,
        "title": "Continuous simulation abstraction refinement for Markov decision processes",
        "authors": "Xu Guo, Zongyuan Yang",
        "published": "2017-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icsai.2017.8248391"
    }
]