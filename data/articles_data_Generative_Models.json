[
    {
        "id": 12971,
        "title": "Generative models",
        "authors": "Thomas P. Trappenberg",
        "published": "2019-11-28",
        "citations": 0,
        "abstract": "This chapter presents an introduction to the important topic of building generative models. These are models that are aimed to understand the variety of a class such as cars or trees. A generative mode should be able to generate feature vectors for instances of the class they represent, and such models should therefore be able to characterize the class with all its variations. The subject is discussed both in a Bayesian and in a deep learning context, and also within a supervised and unsupervised context. This area is related to important algorithms such as k-means clustering, expectation maximization (EM), naïve Bayes, generative adversarial networks (GANs), and variational autoencoders (VAE).",
        "link": "http://dx.doi.org/10.1093/oso/9780198828044.003.0008"
    },
    {
        "id": 12972,
        "title": "Large Generative Models Meet Multimodal Video Intelligence",
        "authors": "Mike Zheng Shou",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3607827.3616847"
    },
    {
        "id": 12973,
        "title": "Multiscale Generative Models: Improving Performance of a Generative Model Using Feedback from Other Dependent Generative Models",
        "authors": "Changyu Chen, Avinandan Bose, Shih-Fen Cheng, Arunesh Sinha",
        "published": "2022-6-28",
        "citations": 0,
        "abstract": "Realistic fine-grained multi-agent simulation of real-world complex systems is crucial for many downstream tasks such as reinforcement learning. Recent work has used generative models (GANs in particular) for providing high-fidelity simulation of real-world systems. However, such generative models are often monolithic and miss out on modeling the interaction in multi-agent systems. In this work, we take a first step towards building multiple interacting generative models (GANs) that reflects the interaction in real world. We build and analyze a hierarchical set-up where a higher-level GAN is conditioned on the output of multiple lower-level GANs. We present a technique of using feedback from the higher-level GAN to improve performance of lower-level GANs. We mathematically characterize the conditions under which our technique is impactful, including understanding the transfer learning nature of our set-up. We present three distinct experiments on synthetic data, time series data, and image domain, revealing the wide applicability of our technique.",
        "link": "http://dx.doi.org/10.1609/aaai.v36i6.20568"
    },
    {
        "id": 12974,
        "title": "Generative Models for Missing Data",
        "authors": "Huiming Xie, Fei Xue, Xiao Wang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-46238-2_27"
    },
    {
        "id": 12975,
        "title": "Why good generative models categorize?",
        "authors": "Serge Dolgikh",
        "published": "No Date",
        "citations": 0,
        "abstract": "In this work connections between training processes of unsupervised generative learning with self-encoding and regeneration and information structure in the latent representations created by such models were investigated. Theoretical arguments were proposed leading to the conclusion, confirmed by previously published experimental results, that in generative self-learning under certain constraints latent representations with spontaneous categorization are statistically preferred. The results can provide insights into common principles underlying learning and emergence of intelligence in machine and biologic systems.",
        "link": "http://dx.doi.org/10.33774/coe-2021-dzh8r"
    },
    {
        "id": 12976,
        "title": "Generative Models",
        "authors": "",
        "published": "2022-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108891530.012"
    },
    {
        "id": 12977,
        "title": "Generating 3D Reconstructions Using Generative Models",
        "authors": "Mehdi Malah, Ramzi Agaba, Fayçal Abbas",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-46238-2_20"
    },
    {
        "id": 12978,
        "title": "AI Deep Learning Generative Models for Drug Discovery",
        "authors": "Qifeng Bai, Jian Ma, Tingyang Xu",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-46238-2_23"
    },
    {
        "id": 12979,
        "title": "Generative Models For Synthetic Populations",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22360/summersim.2017.scsc.007"
    },
    {
        "id": 12980,
        "title": "Analog Ensemble Probabilistic Forecasting using Deep Generative Models",
        "authors": "Alessandro Fanfarillo",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/essoar.10501903.1"
    },
    {
        "id": 12981,
        "title": "Generative Adversarial Networks and Other Generative Models",
        "authors": "Markus Wenzel",
        "published": "2023",
        "citations": 1,
        "abstract": "AbstractGenerative networks are fundamentally different in their aim and methods compared to CNNs for classification, segmentation, or object detection. They have initially been meant not to be an image analysis tool but to produce naturally looking images. The adversarial training paradigm has been proposed to stabilize generative methods and has proven to be highly successful—though by no means from the first attempt.This chapter gives a basic introduction into the motivation for generative adversarial networks (GANs) and traces the path of their success by abstracting the basic task and working mechanism and deriving the difficulty of early practical approaches. Methods for a more stable training will be shown, as well as typical signs for poor convergence and their reasons.Though this chapter focuses on GANs that are meant for image generation and image analysis, the adversarial training paradigm itself is not specific to images and also generalizes to tasks in image analysis. Examples of architectures for image semantic segmentation and abnormality detection will be acclaimed, before contrasting GANs with further generative modeling approaches lately entering the scene. This will allow a contextualized view on the limits but also benefits of GANs.",
        "link": "http://dx.doi.org/10.1007/978-1-0716-3195-9_5"
    },
    {
        "id": 12982,
        "title": "Overview of Generative Models",
        "authors": "",
        "published": "2021-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108938051.014"
    },
    {
        "id": 12983,
        "title": "Deep Generative Models",
        "authors": "Momiao Xiong",
        "published": "2022-2-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003028543-3"
    },
    {
        "id": 12984,
        "title": "Generative models in computer vision and biometrics",
        "authors": "Vitomir Štruc",
        "published": "No Date",
        "citations": 0,
        "abstract": "With the developments in the field of generative modeling and with the appearance of powerful model architectures, such as Generative Adversarial Networks (GAN), a wide range of new techniques and inventive algorithms has emerged recently to solve diverse computer vision problems, including many problems in the area of biometrics. In this talk, I will first provide a short overview of recent advances in generative modeling and describe some of our research efforts that focus explicitly on generative models. Next, I will present examples of our recent work utilizing generative models and talk about: (i) face image editing with our GAN inversion based MaskFaceGAN technique that allows for photo realistic image manipulation and explicitly addresses the problem of attribute entanglement seen with many latent-space based editing solutions, (ii) computer vision for fashion and virtual try-on with our context-driven C-VTON model  and (ii) bimodal ocular image generation (and annotation) with our Dual-Branch StlyGAN2 (DB-StyleGAN) model. Finally, I will elaborate on some of the existing challenges with generative models and highlight future research directions.",
        "link": "http://dx.doi.org/10.52843/cassyni.fztqj2"
    },
    {
        "id": 12985,
        "title": "Privacy in Generative Models: Attacks and Defense Mechanisms",
        "authors": "Maryam Azadmanesh, Behrouz Shahgholi Ghahfarokhi, Maede Ashouri Talouki",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-46238-2_4"
    },
    {
        "id": 12986,
        "title": "Score-Based Generative Models for PET Image Reconstruction",
        "authors": "Imraj RD Singh, Alexander Denker, Riccardo Barbano, Željko Kereta, Bangti Jin, Kris Thielemans, Peter Maass, Simon Arridge",
        "published": "2024-1-23",
        "citations": 0,
        "abstract": "Score-based generative models have demonstrated highly promising results for medical image reconstruction tasks in magnetic resonance imaging or computed tomography. However, their application to Positron Emission Tomography (PET) is still largely unexplored. PET image reconstruction involves a variety of challenges, including Poisson noise with high variance and a wide dynamic range. To address these challenges, we propose several PET-specific adaptations of score-based generative models. The proposed framework is developed for both 2D and 3D PET. In addition, we provide an extension to guided reconstruction using magnetic resonance images. We validate the approach through extensive 2D and 3D <emph>in-silico</emph> experiments with a model trained on patient-realistic data without lesions, and evaluate on data without lesions as well as out-of-distribution data with lesions. This demonstrates the proposed method’s robustness and significant potential for improved PET reconstruction.",
        "link": "http://dx.doi.org/10.59275/j.melba.2024-5d51"
    },
    {
        "id": 12987,
        "title": "Deep Generative Models to Extend Active Directory Graphs with Honeypot Users",
        "authors": "Ondřej Lukáš, Sebastian Garcia",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010556600002996"
    },
    {
        "id": 12988,
        "title": "Deep Generative Models to Extend Active Directory Graphs with Honeypot Users",
        "authors": "Ondřej Lukáš, Sebastian Garcia",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010556601400147"
    },
    {
        "id": 12989,
        "title": "Large Language Models",
        "authors": "Tom Taulli",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-9367-6_5"
    },
    {
        "id": 12990,
        "title": "Deep Generative Models",
        "authors": "Gang Hua",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-63416-2_865"
    },
    {
        "id": 12991,
        "title": "Textual Alchemy",
        "authors": "Gagan Deep, Jyoti Verma",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "This chapter explores the transformative potential of generative models for advanced text generation, focusing on leveraging structural equation modeling techniques. With the rapid advancements in deep learning and natural language processing, generative models have emerged as powerful tools for creative writing, semantic coherence, and contextual understanding. This chapter provides a comprehensive overview of the foundations, methodologies, and applications of generative models in text generation. The chapter begins with an introduction to the evolution of generative models and highlights their significance in various domains. It lays the groundwork by explaining language modeling techniques and the architectures employed in text generation using deep learning algorithms. The subsequent sections delve into the core aspects of generative models for text generation.",
        "link": "http://dx.doi.org/10.4018/979-8-3693-0502-7.ch007"
    },
    {
        "id": 12992,
        "title": "Generative models",
        "authors": "Harry Crane",
        "published": "2018-4-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315209661-4"
    },
    {
        "id": 12993,
        "title": "Listening with generative models",
        "authors": "Maddie Cusimano, Luke B. Hewitt, Josh H. McDermott",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractPerception has long been envisioned to use an internal model of the world to explain the causes of sensory signals. However, such accounts have historically not been testable, typically requiring intractable search through the space of possible explanations. Using auditory scenes as a case study, we leveraged contemporary computational tools to infer explanations of sounds in a candidate internal model of the auditory world (ecologically inspired audio synthesizers). Model inferences accounted for many classic illusions. Unlike traditional accounts of auditory illusions, the model is applicable to any sound, and exhibited human-like perceptual organization for real world sound mixtures. The combination of stimulus-computability and interpretable model structure enabled ‘rich falsification’, revealing additional assumptions about sound generation needed to account for perception. The results show how generative models can account for the perception of both classic illusions and everyday sensory signals, and provide the basis on which to build theories of perception.",
        "link": "http://dx.doi.org/10.1101/2023.04.27.538626"
    },
    {
        "id": 12994,
        "title": "Emulating Land-Processes in Climate Models Using Generative Machine Learning",
        "authors": "Graham Clyne",
        "published": "No Date",
        "citations": 0,
        "abstract": "Recent advances in climate model emulation have been shown to accurately represent atmospheric variables from large general circulation models, but little investigation has been done into emulating land-related variables. The land-carbon sink absorbs around a third of the fossil fuel anthropogenic emissions every year, yet there is significant uncertainty around this prediction. We aim to reduce this uncertainty by first investigating the predictability of several land-related variables that drive land-atmospheric carbon exchange. We use data from the IPSL-CM6A-LR submission to the Decadal Climate Prediction Project (DCPP). The DCPP is initialized from observed data and explores decadal trends in relationships between various climatic variables. The land-component of the IPSL-CM6A-LR, ORCHIDEE, represents various land-carbon interactions and we target these processes for emulation. As a first step, we attempt to predict the target land variables from ORCHIDEE using a vision transformer. We then investigate the impacts of different feature selection on the target variables - by including atmospheric and oceanic variables, how does this improve the short and medium term predictions of land-related processes? In a second step, we apply generative modeling (with diffusion models) to emulate land processes. The diffusion model can be used to generate several unseen scenarios based on the DCPP and provides a tool to investigate a wider range of climatic scenarios that would be otherwise computationally expensive.&#160;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-10328"
    },
    {
        "id": 12995,
        "title": "Autoregressive Models",
        "authors": "Jakub M. Tomczak",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-93158-2_2"
    },
    {
        "id": 12996,
        "title": "Interpretable deep generative models for genomics",
        "authors": "Yongin Choi, Ruoxin Li, Gerald Quon",
        "published": "No Date",
        "citations": 3,
        "abstract": "ABSTRACTDeep neural networks implementing generative models for dimensionality reduction have been extensively used for the visualization and analysis of genomic data. One of their key limitations is lack of interpretability: it is challenging to quantitatively identify which input features are used to construct the embedding dimensions, thus preventing insight into why cells are organized in a particular data visualization, for example. Here we present a scalable, interpretable variational autoencoder (siVAE) that is interpretable by design: it learns feature embeddings that guide the interpretation of the cell embeddings in a manner analogous to factor loadings of factor analysis. siVAE is as powerful and nearly as fast to train as the standard VAE but achieves full interpretability of the embedding dimensions. Using siVAE, we exploit a number of connections between dimensionality reduction and gene network inference to identify gene neighborhoods and gene hubs, without the explicit need for gene network inference. We observe a systematic difference in the gene neighborhoods identified by dimensionality reduction methods and gene network inference algorithms in general, suggesting they provide complementary information about the underlying structure of the gene co-expression network. Finally, we apply siVAE to implicitly learn gene networks for individual iPSC lines and uncover a correlation between neuronal differentiation efficiency and loss of co-expression of several mitochondrial complexes, including NADH dehydrogenase, cytochrome C oxidase, and cytochrome b.",
        "link": "http://dx.doi.org/10.1101/2021.09.15.460498"
    },
    {
        "id": 12997,
        "title": "Mean Dimension of Generative Models for Protein Sequences",
        "authors": "Christoph Feinauer, Emanuele Borgonovo",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractGenerative models for protein sequences are important for protein design, mutational effect prediction and structure prediction. In all of these tasks, the introduction of models which include interactions between pairs of positions has had a major impact over the last decade. More recently, many methods going beyond pairwise models have been developed, for example by using neural networks that are in principle able to capture interactions between more than two positions from multiple sequence alignments. However, not much is known about the inter-dependency patterns between positions in these models, and how important higher-order interactions involving more than two positions are for their performance. In this work, we introduce the notion of mean dimension for generative models for protein sequences, which measures the average number of positions involved in interactions when weighted by their contribution to the total variance in log probability of the model. We estimate the mean dimension for different model classes trained on different protein families, relate it to the performance of the models on mutational effect prediction tasks and also trace its evolution during training. The mean dimension is related to the performance of models in biological prediction tasks and can highlight differences between model classes even if their performance in the prediction task is similar. The overall low mean dimension indicates that well-performing models are not necessarily of high complexity and encourages further work in interpreting their performance in biological terms.",
        "link": "http://dx.doi.org/10.1101/2022.12.12.520028"
    },
    {
        "id": 12998,
        "title": "Generative Models of Regular Languages",
        "authors": "",
        "published": "2017-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813229211_0008"
    },
    {
        "id": 12999,
        "title": "Good Models Borrow, Great Models Steal: Intellectual Property Rights and Generative AI",
        "authors": "Simon Chesterman",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4590006"
    },
    {
        "id": 13000,
        "title": "Evaluation of pseudo-healthy image reconstruction for anomaly detection with deep generative models: Application to brain FDG PET",
        "authors": "Ravi Hassanaly, Camille Brianceau, Maëlys Solal, Olivier Colliot, Ninon Burgos",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "Over the past years, pseudo-healthy reconstruction for unsupervised anomaly detection has gained in popularity. This approach has the great advantage of not requiring tedious pixel-wise data annotation and offers possibility to generalize to any kind of anomalies, including that corresponding to rare diseases. By training a deep generative model with only images from healthy subjects, the model will learn to reconstruct pseudo-healthy images. This pseudo-healthy reconstruction is then compared to the input to detect and localize anomalies. The evaluation of such methods often relies on a ground truth lesion mask that is available for test data, which may not exist depending on the application.<br>We propose an evaluation procedure based on the simulation of realistic abnormal images to validate pseudo-healthy reconstruction methods when no ground truth is available. This allows us to extensively test generative models on different kinds of anomalies and measuring their performance using the pair of normal and abnormal images corresponding to the same subject. It can be used as a preliminary automatic step to validate the capacity of a generative model to reconstruct pseudo-healthy images, before a more advanced validation step that would require clinician’s expertise. We apply this framework to the reconstruction of 3D brain FDG PET using a convolutional variational autoencoder with the aim to detect as early as possible the neurodegeneration markers that are specific to dementia such as Alzheimer’s disease.",
        "link": "http://dx.doi.org/10.59275/j.melba.2024-b87a"
    },
    {
        "id": 13001,
        "title": "Vectorization of Dynamic Subgraphs via Generative Models (Final Report)",
        "authors": "Geoffrey Sanders, Mark Heimann",
        "published": "2023-10-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2172/2203636"
    },
    {
        "id": 13002,
        "title": "Stellenwert von Natural Language Processing und chatbasierten Generative Language Models",
        "authors": "Markus Haar, Michael Sonntagbauer, Stefan Kluge",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00063-023-01098-5"
    },
    {
        "id": 13003,
        "title": "Energy-Based Models",
        "authors": "Jakub M. Tomczak",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-93158-2_6"
    },
    {
        "id": 13004,
        "title": "A Generative Bayesian Approach for Incorporating Biosurveillance Sources into Epidemiological Models",
        "authors": "David Manheim",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractBiosurveillance “systematically collects and analyzes data for the purpose of detecting cases of disease, [and] outbreaks of disease.” (Wagner, Moore and Aryel, 2006) This typically involves using a set of known sources of epidemiological data, instead of opportunistically using the data sources which become available over time. This work attempts to partially remedy that limitation by using an easily adapted generative Bayesian econometric model to allow incorporation of novel data sources. This is done by building a generative model of the information sources, then using Bayesian Markov-chain Monte-Carlo to find the relationships between data and actual caseloads to use in an epidemiological model1.While the application presented is limited to three data sources for a single disease (influenza), the methodology is potentially widely applicable, and enables rapid incorporation of a variety of sources and source types.",
        "link": "http://dx.doi.org/10.1101/328518"
    },
    {
        "id": 13005,
        "title": "Annotated Hands for Generative Models",
        "authors": "Yue Yang, Atith N Gandhi, Greg Turk",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nGenerative models such as GANs and diffusion models have demonstrated impressive image generation capabilities. Despite these successes, these systems are surprisingly poor at creating images with hands. We propose a novel training framework for generative models that substantially improves the ability of such systems to create hand images. Our approach is to augment the training images with three additional channels that provide annotations to any hands in the image. These annotations provide additional structure that coax the generative model to produce higher quality hand images. We demonstrate this approach on two different generative models: a generative adversarial network and a diffusion model. We demonstrate our method both on a new synthetic dataset of hand images and also on real photographs that contain hands. We measure the improved quality of the generated hands through higher confidence in finger joint identification using an off-the-shelf hand detector.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3895352/v1"
    },
    {
        "id": 13006,
        "title": "A Systematic Survey on Deep Generative Models for Graph Generation",
        "authors": "Xiaojie Guo, Liang Zhao",
        "published": "No Date",
        "citations": 6,
        "abstract": "Graphs are important data representations for describing objects and their relationships, which appear in a wide diversity of real-world scenarios. As one of a critical problem in this area, graph generation considers learning the distributions of given graphs and generating more novel graphs. Owing to its wide range of applications, generative models for graphs have a rich history, which, however, are traditionally hand-crafted and only capable of modeling a few statistical properties of graphs. Recent advances in deep generative models for graph generation is an important step towards improving the fidelity of generated graphs and paves the way for new kinds of applications. This article provides an extensive overview of the literature in the field of deep generative models for graph generation. Firstly, the formal definition of deep generative models for the graph generation as well as preliminary knowledge is provided. Secondly, two taxonomies of deep generative models for unconditional, and conditional graph generation respectively are proposed; the existing works of each are compared and analyzed. After that, an overview of the evaluation metrics in this specific domain is provided. Finally, the applications that deep graph generation enables are summarized and five promising future research directions are highlighted.",
        "link": "http://dx.doi.org/10.36227/techrxiv.12733037.v1"
    },
    {
        "id": 13007,
        "title": "Latent Variable Models",
        "authors": "Jakub M. Tomczak",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-93158-2_4"
    },
    {
        "id": 13008,
        "title": "Flow-Based Models",
        "authors": "Jakub M. Tomczak",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-93158-2_3"
    },
    {
        "id": 13009,
        "title": "A Systematic Study of Deep Generative Models for Rapid Topology Optimization",
        "authors": "Manoj Malviya",
        "published": "No Date",
        "citations": 7,
        "abstract": "With the advent in Additive Manufacturing (AM) technologies and Computational Sciences, design algorithms such as Topology Optimization (TO) have garnered the interest of academia and industry. TO aims to generate optimum structures by maximizing the stiffness of the structure, given a set of geometric, loading and boundary conditions. However, these approaches are computationally expensive as it requires many iterations to converge to an optimum solution. The purpose of this work is to explore the effectiveness of deep generative models on a diverse range of topology optimization problems with varying design constraints, loading and boundary conditions. Specifically, four distinctive models were successfully developed, trained, and evaluated to generate rapid designs with comparable results to that of conventional algorithms. Our findings highlight the effectiveness of the novel design problem representation and proposed generative models in rapid topology optimization.",
        "link": "http://dx.doi.org/10.31224/osf.io/9gvqs"
    },
    {
        "id": 13010,
        "title": "Forward-Generative Models of Functional Neuroimaging Data",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-0716-1006-0_300240"
    },
    {
        "id": 13011,
        "title": "A Systematic Survey on Deep Generative Models for Graph Generation",
        "authors": "Xiaojie Guo, Liang Zhao",
        "published": "No Date",
        "citations": 2,
        "abstract": "Graphs are important data representations for describing objects and their relationships, which appear in a wide diversity of real-world scenarios. As one of a critical problem in this area, graph generation considers learning the distributions of given graphs and generating more novel graphs. Owing to its wide range of applications, generative models for graphs have a rich history, which, however, are traditionally hand-crafted and only capable of modeling a few statistical properties of graphs. Recent advances in deep generative models for graph generation is an important step towards improving the fidelity of generated graphs and paves the way for new kinds of applications. This article provides an extensive overview of the literature in the field of deep generative models for graph generation. Firstly, the formal definition of deep generative models for the graph generation as well as preliminary knowledge is provided. Secondly, two taxonomies of deep generative models for unconditional, and conditional graph generation respectively are proposed; the existing works of each are compared and analyzed. After that, an overview of the evaluation metrics in this specific domain is provided. Finally, the applications that deep graph generation enables are summarized and five promising future research directions are highlighted.",
        "link": "http://dx.doi.org/10.36227/techrxiv.12733037"
    },
    {
        "id": 13012,
        "title": "Probabilistic streamflow forecasting using generative deep learning models",
        "authors": "Mohammad Sina Jahangir, John Quilty",
        "published": "No Date",
        "citations": 0,
        "abstract": "The significance of probabilistic hydrological forecasting has grown in recent years, offering crucial insights for risk-based decision-making and effective flood management. This study explores generative deep learning models, specifically the conditional variational autoencoder (CVAE), for probabilistic streamflow forecasting. This innovative approach is applied for forecasting streamflow one to seven days (s) ahead in 75 Canadian basins included in the open-source Canadian model parameter experiment (CANOPEX) database. CVAE is compared against two benchmark quantile-based deep learning models: the quantile-based encoder-decoder (ED) and the quantile-based CVAE (QCVAE).\nOver 9000 deep learning models are developed based on different input variables, basin characteristics, and model structures and evaluated regarding point forecast accuracy and forecast reliability. Results highlight CVAE&#8216;s superior reliability, showing a median reliability of 92.49% compared to 87.35% for ED and 84.59% for QCVAE (considering a desired 90% confidence level). However, quantile-based forecast models exhibit marginally better point forecasts, as evidenced by Kling-Gupta efficiency (KGE), with a median KGE of 0.90 for ED and QCVAE (compared to 0.88 for CVAE). Notably, the CVAE model provides reliable probabilistic forecasts in basins with low point forecast accuracy.\nThe developed generative deep learning models can be used as a benchmark for probabilistic streamflow forecasting due to the use of the open-source CANOPEX dataset. Overall, the results of this study contribute to the expanding field of generative deep learning models in hydrological forecasting, offering a general framework that applies to forecasting other hydrological variables as well (precipitation and soil moisture).",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-2939"
    },
    {
        "id": 13013,
        "title": "Generative Adversarial Examples for Sequential Text Recognition Models with Artistic Text Style",
        "authors": "Yanhong Liu, Fengming Cao, Yuqi Zhang",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010866800003122"
    },
    {
        "id": 13014,
        "title": "Generative Models for Biomedical Imaging",
        "authors": "",
        "published": "2023-9-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009042529.015"
    },
    {
        "id": 13015,
        "title": "Generative Models for Financial Data",
        "authors": "Pierre Henry-Labordere",
        "published": "No Date",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3408007"
    },
    {
        "id": 13016,
        "title": "Assessment Models and Meta‐models",
        "authors": "",
        "published": "2018-1-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119422044.ch4"
    },
    {
        "id": 13017,
        "title": "AI as Agency Without Intelligence: On ChatGPT, Large Language Models, and Other Generative Models",
        "authors": "Luciano Floridi",
        "published": "2023",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4358789"
    },
    {
        "id": 13018,
        "title": "A Roadmap towards Tuneable Random Ontology Generation Via Probabilistic Generative Models",
        "authors": "Pietro Galliani, Oliver Kutz, Roberto Confalonieri",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006961103510357"
    },
    {
        "id": 13019,
        "title": "Multimodal Generative Models for Responsible Deployment in Healthcare and Biology",
        "authors": "Mashrin Srivastava",
        "published": "No Date",
        "citations": 0,
        "abstract": "Generative modeling has recently gained significant attention due to its high-profile successes in natural language processing and computer vision. However, there remain major challenges in deploying generative models for real-world impact in domains like healthcare and biology. This paper discusses the importance of multimodal capabilities, deployment-critical features, and human-facing evaluation in generative models for responsible deployment in healthcare and biology. We review recent advances in these areas, provide a detailed analysis of various techniques, and highlight the challenges and opportunities for future research.",
        "link": "http://dx.doi.org/10.31219/osf.io/q7v3b"
    },
    {
        "id": 13020,
        "title": "Deep Generative Models",
        "authors": "Gang Hua",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-03243-2_865-1"
    },
    {
        "id": 13021,
        "title": "Generalizing predictions to unseen sequencing profiles via deep generative models",
        "authors": "Min Oh, Liqing Zhang",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractPredictive models trained on sequencing profiles often fail to achieve expected performance when externally validated on unseen profiles. While many factors such as batch effects, small data sets, and technical errors contribute to the gap between source and unseen data distributions, it is a challenging problem to generalize the predictive models across studies without any prior knowledge of the unseen data distribution. Here, this study proposes DeepBioGen, a sequencing profile augmentation procedure that characterizes visual patterns of sequencing profiles, generates realistic profiles based on a deep generative model capturing the patterns, and generalizes the subsequent classifiers. DeepBioGen outperforms other methods in terms of enhancing the generalizability of the prediction models on unseen data. The generalized classifiers surpass the state-of-the-art method, evaluated on RNA sequencing tumor expression profiles for anti-PD1 therapy response prediction and WGS human gut microbiome profiles for type 2 diabetes diagnosis.",
        "link": "http://dx.doi.org/10.1101/2021.05.06.443027"
    },
    {
        "id": 13022,
        "title": "Comparing Prominent Generative Language Models for Classifying Political Alignment Of Limited Context Bigrams",
        "authors": "Sankalp Singh",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.58445/rars.510"
    },
    {
        "id": 13023,
        "title": "Competition in Generative AI Foundation Models",
        "authors": "Christophe Carugati",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4553787"
    },
    {
        "id": 13024,
        "title": "Theoretical Research on Generative Diffusion Models: An Overview",
        "authors": "Melike Nur Yegin, Mehmet Fatih Amasyalı",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4627329"
    },
    {
        "id": 13025,
        "title": "Introduction to Generative AI",
        "authors": "Akshay Kulkarni, Adarsha Shivananda, Anoosh Kulkarni, Dilip Gudivada",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-9994-4_1"
    },
    {
        "id": 13026,
        "title": "Connectomes, Generative Models, and Their Implications for Cognition",
        "authors": "Petra E. Vértes",
        "published": "2020-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7551/mitpress/11442.003.0078"
    },
    {
        "id": 13027,
        "title": "Predicting absolute protein folding stability using generative models",
        "authors": "Matteo Cagiada, Sergey Ovchinnikov, Kresten Lindorff-Larsen",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractWhile there has been substantial progress in our ability to predict changes in protein stability due to amino acid substitutions, progress has been slow in methods to predict the absolute stability of a protein. Here we show how a generative model for protein sequence can be leveraged to predict absolute protein stability. We benchmark our predictions across a broad set of proteins and find a mean error of 1.5 kcal/mol and a correlation coefficient of 0.7 for the absolute stability across a range of small–medium sized proteins up to ca. 150 amino acid residues. We analyse current limitations and future directions including how such model may be useful for predicting conformational free energies. Our approach is simple to use and freely available via an online implementation.",
        "link": "http://dx.doi.org/10.1101/2024.03.14.584940"
    },
    {
        "id": 13028,
        "title": "Variational Inference and Deep Generative Models",
        "authors": "Wilker Aziz, Philip Schulz",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/p18-5003"
    },
    {
        "id": 13029,
        "title": "Review for \"Data augmentation for enhancing EEG-based emotion recognition with deep generative models\"",
        "authors": "Dania Gutiérrez",
        "published": "2020-6-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1088/1741-2552/abb580/v1/review1"
    },
    {
        "id": 13030,
        "title": "Review for \"Data augmentation for enhancing EEG-based emotion recognition with deep generative models\"",
        "authors": " Chengcheng Hua",
        "published": "2020-6-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1088/1741-2552/abb580/v1/review2"
    },
    {
        "id": 13031,
        "title": "Interpretable Pairwise Distillations for Generative Protein Sequence Models",
        "authors": "Christoph Feinauer, Barthelemy Meynard-Piganeau, Carlo Lucibello",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractMany different types of generative models for protein sequences have been proposed in literature. Their uses include the prediction of mutational effects, protein design and the prediction of structural properties. Neural network (NN) architectures have shown great performances, commonly attributed to the capacity to extract non-trivial higher-order interactions from the data. In this work, we analyze three different NN models and assess how close they are to simple pairwise distributions, which have been used in the past for similar problems. We present an approach for extracting pairwise models from more complex ones using an energy-based modeling framework. We show that for the tested models the extracted pairwise models can replicate the energies of the original models and are also close in performance in tasks like mutational effect prediction.",
        "link": "http://dx.doi.org/10.1101/2021.10.14.464358"
    },
    {
        "id": 13032,
        "title": "Examining Generative Image Models Amidst Privacy Regulations",
        "authors": "Hannah Ismael",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4560416"
    },
    {
        "id": 13033,
        "title": "Autoencoders and deep generative models in bioinformatics",
        "authors": "Habib Izadkhah",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-823822-6.00018-4"
    },
    {
        "id": 13034,
        "title": "Proceedings of the 1st Workshop on Large Generative Models Meet Multimodal Applications",
        "authors": "",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3607827"
    },
    {
        "id": 13035,
        "title": "ReAGent: A Model-agnostic Feature Attribution Method for Generative Language Models",
        "authors": "Zhixue Zhao, Boxuan Shan",
        "published": "No Date",
        "citations": 0,
        "abstract": "Feature attribution methods (FAs), such as gradients and attention, are\nwidely employed approaches to derive the importance of all input\nfeatures to the model predictions. Existing work in natural language\nprocessing has mostly focused on developing and testing FAs for\nencoder-only language models (LMs) in classification tasks. However, it\nis unknown if it is faithful to use these FAs for decoder-only models on\ntext generation, due to the inherent differences between model\narchitectures and task settings respectively. Moreover, previous work\nhas demonstrated that there is no ‘one-wins-all’ FA across models and\ntasks. This makes the selection of a FA computationally expensive for\nlarge LMs since input importance derivation often requires multiple\nforward and backward passes including gradient computations that might\nbe prohibitive even with access to large compute. To address these\nissues, we present a model-agnostic FA for generative LMs called\nRecursive Attribution Generator (ReAGent). Our method updates the token\nimportance distribution in a recursive manner. For each update, we\ncompute the difference in the probability distribution over the\nvocabulary for predicting the next token between using the original\ninput and using a modified version where a part of the input is replaced\nwith RoBERTa predictions. Our intuition is that replacing an important\ntoken in the context should have resulted in a larger change in the\nmodel’s confidence in predicting the token than replacing an unimportant\ntoken. Our method can be universally applied to any generative LM\nwithout accessing internal model weights or additional training and\nfine-tuning, as most other FAs require. We extensively compare the\nfaithfulness of ReAGent with seven popular FAs across six decoder-only\nLMs of various sizes. The results show that our method consistently\nprovides more faithful token importance distributions. Our\ncode: https://github.com/casszhao/ReAGent",
        "link": "http://dx.doi.org/10.22541/au.170709121.16176681/v1"
    },
    {
        "id": 13036,
        "title": "Large Generative AI Models vs Smaller Parameter Models with More Data: A Comprehensive Literature Review",
        "authors": "Archer Woodford",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4453658"
    },
    {
        "id": 13037,
        "title": "Modern Applications With a Focus on Training ChatGPT and GPT Models",
        "authors": "Isha Kondurkar, Akanksha Raj, D. Lakshmi",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "Generative AI (GAI) and natural language processing (NLP) have emerged as the most exciting and rapidly growing fields in artificial intelligence (AI). This book chapter provides a comprehensive exploration of the advanced applications of GAI and NLP models, with a specific focus on the renowned ChatGPT model. The chapter commences by offering a concise historical overview of the development of GAI and NLP, highlighting crucial milestones and advancements in the field over the period. In order to understand the workings of the current technology sensation, we will take a brief look at the basic building blocks of GPT models, such as transformers. Subsequently, the chapter delves into the introduction of ChatGPT, presenting an extensive overview of the model, elucidating its underlying architecture, and emphasizing its unique capabilities. Furthermore, it will illustrate the training process of the GPT model followed by a fine-tuning process to deal with the current model's shortcomings.",
        "link": "http://dx.doi.org/10.4018/979-8-3693-0502-7.ch010"
    },
    {
        "id": 13038,
        "title": "Constrained sampling from deep generative image models reveals mechanisms of human target detection",
        "authors": "Ingo Fruend",
        "published": "No Date",
        "citations": 0,
        "abstract": "The first steps of visual processing are often described as a bank of oriented filters followed by divisive normalization. This approach has been tremendously successful at predicting contrast thresholds in simple visual displays. However, it is unclear to what extent this kind of architecture also supports processing in more complex visual tasks performed in naturally looking images.We used a deep generative image model to embed arc segments with different curvatures in naturalistic images. These images contain the target as part of the image scene, resulting in considerable appearance variation of target as well as background. Three observers localized arc targets in these images, achieving an accuracy of 74.7% correct responses on average. Data were fit by several biologically inspired models, 4 standard deep convolutional neural networks (CNN) from the computer vision literature, and by a 5-layer CNN specifically trained for this task. Four models were particularly good at predicting observer responses, (i) a bank of oriented filters, similar to complex cells in primate area V1, (ii) a bank of oriented filters followed by tuned gain control, incorporating knowledge about cortical surround interactions, (iii) a bank of oriented filters followed by local normalization, (iv) the 5-layer specifically trained CNN. A control experiment with optimized stimuli based on these four models showed that the observers’ data were best explained by model (ii) with tuned gain control.These data suggest that standard models of early vision provide good descriptions of performance in much more complex tasks than what they were designed for, while general purpose non-linear models such as convolutional neural networks do not.",
        "link": "http://dx.doi.org/10.1101/578633"
    },
    {
        "id": 13039,
        "title": "Designing ultrastable carbonic anhydrase with deep generative models and high-throughput assays",
        "authors": "Pascal Notin Pascal Notin",
        "published": "2023-10-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18258/57574"
    },
    {
        "id": 13040,
        "title": "Conditional Generative Models for OceanBench Sea Surface Height Interpolation",
        "authors": "Nils Lehmann, Jonathan Bamber, Xiaoxiang Zhu",
        "published": "No Date",
        "citations": 0,
        "abstract": "Rising sea levels are one of many consequences of anthropogenic climatechange. Over the past few decades, several global observational records havebecome available that give a more detailed picture of the increasingimpacts. Nevertheless, there continue to be data challenges, such assparsity or signal to noise ratio, that need to be dealt with. Machine Learning (ML)and specifically, Deep Learning (DL) approaches have presented themselves as valuabletools for such large-scale and complex data sources. To this end, the OceanBenchBenchmark suite was recently developed to provide astandardized pre-processing and evaluation framework for Sea Surface Height(SSH) interpolation tasks involving nadir and Surface Water and Ocean Topography(SWAT) Altimetry Tracks. From the methodological perspective, a reoccurringissue is the lack of uncertainty quantification for DL applications in EarthObservation. Therefore, we extend the suite of metrics provided by OceanBenchto probabilistic evaluation metrics and test state-of-the-art uncertaintyquantification models from the DL community. Specifically, we focus onConditional Convolutional Neural Processes (ConvCNP) andInpainting Diffusion models as methodologies to quantifyuncertainty for the interpolation task and demonstrate their viability andadvantages over other ML methods for both accuracy and probabilistic metrics.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-15594"
    },
    {
        "id": 13041,
        "title": "No Title",
        "authors": "",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.59275/j.melba.2023-4f1d"
    },
    {
        "id": 13042,
        "title": "Generative Models",
        "authors": "Isaiah Hull",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6373-0_9"
    },
    {
        "id": 13043,
        "title": "Unlocking Multimedia Capabilities of Gigantic Pretrained Language Models",
        "authors": "Boyang Li",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3607827.3616846"
    },
    {
        "id": 13044,
        "title": "Generative Models",
        "authors": "Shriram K. Vasudevan, Sini Raj Pulari, Subashri Vasudevan",
        "published": "2021-12-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003185635-9"
    },
    {
        "id": 13045,
        "title": "Peer Review #3 of \"Discovering generative models from event logs: data-driven simulation vs deep learning (v0.2)\"",
        "authors": "",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.577v0.2/reviews/3"
    },
    {
        "id": 13046,
        "title": "Deep Generative Models: A Review",
        "authors": "Rayeesa Mehmood,  , Rumaan Bashir, Kaiser J Giri",
        "published": "2023-2-21",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.17485/ijst/v16i7.2296"
    },
    {
        "id": 13047,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "Shariq Aziz",
        "published": "2023-9-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/p1urtl"
    },
    {
        "id": 13048,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "Muhammad Ali",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/p6vv1c"
    },
    {
        "id": 13049,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "Sunil Mohapatra",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/avwsmy"
    },
    {
        "id": 13050,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "Hormoz Shahrzad",
        "published": "2023-9-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/jueefv"
    },
    {
        "id": 13051,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "Debraj Sen",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/c67ewj"
    },
    {
        "id": 13052,
        "title": "Peer Review #2 of \"Discovering generative models from event logs: data-driven simulation vs deep learning (v0.2)\"",
        "authors": "",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.577v0.2/reviews/2"
    },
    {
        "id": 13053,
        "title": "Peer Review #1 of \"Discovering generative models from event logs: data-driven simulation vs deep learning (v0.2)\"",
        "authors": "",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.577v0.2/reviews/1"
    },
    {
        "id": 13054,
        "title": "Peer Review #3 of \"Discovering generative models from event logs: data-driven simulation vs deep learning (v0.1)\"",
        "authors": "",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.577v0.1/reviews/3"
    },
    {
        "id": 13055,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "Mohammed Attya",
        "published": "2023-9-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/aduw4x"
    },
    {
        "id": 13056,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "Javier Bueno",
        "published": "2023-10-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/e991bt"
    },
    {
        "id": 13057,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "Liang Zhang",
        "published": "2023-10-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/9y5tht"
    },
    {
        "id": 13058,
        "title": "Generative AI Applications in the Health and Well-Being Domain: Virtual and Robotic Assistance and the Need for Niche Language Models (NLMs)",
        "authors": "Graeme Revell",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-46238-2_9"
    },
    {
        "id": 13059,
        "title": "Generative Models",
        "authors": "Sim-Hui Tee",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10670-020-00338-w"
    },
    {
        "id": 13060,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "Thomas Hanne",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/o2jnmk"
    },
    {
        "id": 13061,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "Mehmet Fırat",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/jyljh7"
    },
    {
        "id": 13062,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "Bechoo Lal",
        "published": "2023-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/qetyfi"
    },
    {
        "id": 13063,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "越 杨",
        "published": "2023-9-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/8vzbd0"
    },
    {
        "id": 13064,
        "title": "Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations",
        "authors": "Swapnil Morandé, Kanwal Gul",
        "published": "No Date",
        "citations": 0,
        "abstract": "The integration of generative AI into academic research holds immense promise but necessitates judicious oversight to address risks. This pioneering study provides crucial insights to guide responsible adoption through a rigorous comparative benchmarking of four cutting-edge models – Claude, LaMDA, Sydney and Galactica. Carefully designed prompts assess competencies across core scholarly tasks, with quantitative scoring and qualitative analysis elucidating specialized capabilities, gaps, risks and validation needs. Key findings reveal strengths in focused assistive roles but limitations in generalizing reasoning across disciplines compared to human scholars. The AI systems emphasize extensive validation to mitigate risks, underscoring the need for transparency, peer review, reproducibility checks and continuous benchmarking as adoption accelerates. To steer progress responsibly, tailored recommendations for pragmatic system-task alignment, calibrating expectations, enhancing reasoning skills, holistic risk mitigation and participatory oversight are provided to researchers, developers, institutions and publishers. This timely applied framework grounded in real-world evidence provides a roadmap to harness AI’s immense opportunities to benefit scholarship through prudent integration focused on human-AI collaboration under an ethical oversight framework.\n",
        "link": "http://dx.doi.org/10.32388/7ovvw2"
    },
    {
        "id": 13065,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "Sohail Sarwar",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/09dv4l"
    },
    {
        "id": 13066,
        "title": "A Basic Introduction to Messy Structures and Generative Models",
        "authors": "Karl F. Vachuska, Stephen C Rodriguez-Elliott",
        "published": "No Date",
        "citations": 0,
        "abstract": "While networks have been the standard mathematical representation for detailedarrangements of relations in society, the simplicity of the representation limits whatinformation can be preserved in the abstraction, and subsequently, what can bemathematically analyzed. In this paper, we introduce a more rigorous and flexibleabstraction for representing arrangements of relations in society, the Messy Structure.After introducing the representational form and theoretically justifying it, we introducesome basic generative procedures for creating Messy Structures with “hierarchical”properties.",
        "link": "http://dx.doi.org/10.31235/osf.io/kpeuq"
    },
    {
        "id": 13067,
        "title": "For antibody sequence generative modeling, mixture models may be all you need",
        "authors": "Jonathan Parkinson, Wei Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "ABSTRACTAntibody therapeutic candidates must exhibit not only tight binding to their target but also good developability properties, especially low risk of immunogenicity. In this work, we fit a simple generative model, SAM, to sixty million human heavy and seventy million human light chains. We show that the probability of a sequence calculated by the model distinguishes human sequences from other species with the same or better accuracy on a variety of benchmark datasets containing >400 million sequences than any other model in the literature, outperforming large language models (LLMs) by large margins. SAM can humanize sequences, generate new sequences, and score sequences for humanness. It is both fast and fully interpretable. Our results highlight the importance of using simple models as baselines for protein engineering tasks. We additionally introduce a new tool for numbering antibody sequences which is orders of magnitude faster than existing tools in the literature. Both these tools are available athttps://github.com/Wang-lab-UCSD/AntPack.",
        "link": "http://dx.doi.org/10.1101/2024.01.27.577555"
    },
    {
        "id": 13068,
        "title": "Peer Review #2 of \"Discovering generative models from event logs: data-driven simulation vs deep learning (v0.1)\"",
        "authors": "",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.577v0.1/reviews/2"
    },
    {
        "id": 13069,
        "title": "Generative Models",
        "authors": "Cao Xiao, Jimeng Sun",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-82184-5_12"
    },
    {
        "id": 13070,
        "title": "Review of: \"Towards Responsible AI-Assisted Scholarship: Comparative Assessment of Generative Models and Adoption Recommendations\"",
        "authors": "Fredys Simanca",
        "published": "2023-9-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/9wss7f"
    }
]