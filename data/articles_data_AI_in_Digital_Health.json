[
    {
        "id": 701,
        "title": "Transforming Healthcare: The Integration of AI and Digital Technologies",
        "authors": "Kamel N",
        "published": "2024",
        "citations": 0,
        "abstract": "This article discusses the integration of digital technologies, including AI and robotic systems, on the health profession globally, and how profession can adapt to the changing landscape of healthcare.",
        "keywords": "",
        "link": "http://dx.doi.org/10.53902/tnhcr.2024.04.000534"
    },
    {
        "id": 702,
        "title": "Digital loneliness—changes of social recognition through AI companions",
        "authors": "Kerrin Artemis Jacobs",
        "published": "2024-3-5",
        "citations": 0,
        "abstract": "Inherent to the experience of loneliness is a significant change of meaningful relatedness that (usually negatively) affects a person's relationship to self and others. This paper goes beyond a purely subjective-phenomenological description of individual suffering by emphasizing loneliness as a symptomatic expression of distortions of social recognition relations. Where there is loneliness, a recognition relation has changed. Most societies face an increase in loneliness among all groups of their population, and this sheds light on the reproduction conditions of social integration and inclusion. These functions are essential lifeworldly components of social cohesion and wellbeing. This study asks whether “social” AI promotes these societal success goals of social integration of lonely people. The increasing tendency to regard AI Companions (AICs) as reproducers of adequate recognition is critically discussed with this review. My skepticism requires further justification, especially as a large portion of sociopolitical prevention efforts aim to fight an increase of loneliness primarily with digital strategies. I will argue that AICs rather reproduce than sustainably reduce the pathodynamics of loneliness: loneliness gets simply “digitized.”",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fdgth.2024.1281037"
    },
    {
        "id": 703,
        "title": "Crossing the frontier: the first global AI safety summit",
        "authors": "Talha Burki",
        "published": "2024-2",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(24)00001-3"
    },
    {
        "id": 704,
        "title": "Preventing harm from non-conscious bias in medical generative AI",
        "authors": "Janna Hastings",
        "published": "2024-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00246-7"
    },
    {
        "id": 705,
        "title": "The impact of AI on sexual health knowledge, attitude and behaviour",
        "authors": "D. -M. Welch",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/icp.2023.2613"
    },
    {
        "id": 706,
        "title": "Artificial intelligence (AI) in restorative dentistry: Performance of AI models designed for detection of interproximal carious lesions on primary and permanent dentition",
        "authors": "Amr Ahmed Azhari, Narmin Helal, Leena M Sabri, Abeer Abduljawad",
        "published": "2023-1",
        "citations": 0,
        "abstract": "Objective The objective of this study was to evaluate the effectiveness of deep learning methods in detecting dental caries from radiographic images. Methods A total of 771 bitewing radiographs were divided into two groups: adult (n = 554) and pediatric (n = 217). Two distinct semantic segmentation models were constructed for each group. They were manually labeled by general dentists for semantic segmentation. The inter-examiner reliability of the two examiners was also measured. Finally, the models were trained using transfer learning methodology along with computer science advanced tools, such as ensemble U-Nets with ResNet50, ResNext101, and Vgg19 as the encoders, which were all pretrained on ImageNet weights using a training dataset. Results Intersection over union (IoU) score was used to evaluate the outcomes of the deep learning model. For the adult dataset, the IoU averaged 98%, 23%, 19%, and 51% for zero, primary, moderate, and advanced carious lesions, respectively. For pediatric bitewings, the IoU averaged 97%, 8%, 17%, and 25% for zero, primary, moderate, and advanced caries, respectively. Advanced caries was more accurately detected than primary caries on adults and pediatric bitewings P < 0.05. Conclusions The proposed deep learning models can accurately detect advanced caries in permanent or primary bitewing radiographs. Misclassification mostly occurs between primary and moderate caries. Although the model performed well in correctly classifying the lesions, it can misclassify one as the other or does not accurately capture the depth of the lesion at this early stage. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1177/20552076231216681"
    },
    {
        "id": 707,
        "title": "AI Chatbots in Digital Mental Health",
        "authors": "Luke Balcombe",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "Artificial intelligence (AI) chatbots have gained prominence since 2022. Powered by big data, natural language processing (NLP) and machine learning (ML) algorithms, they offer the potential to expand capabilities, improve productivity and provide guidance and support in various domains. Human–Artificial Intelligence (HAI) is proposed to help with the integration of human values, empathy and ethical considerations into AI in order to address the limitations of AI chatbots and enhance their effectiveness. Mental health is a critical global concern, with a substantial impact on individuals, communities and economies. Digital mental health solutions, leveraging AI and ML, have emerged to address the challenges of access, stigma and cost in mental health care. Despite their potential, ethical and legal implications surrounding these technologies remain uncertain. This narrative literature review explores the potential of AI chatbots to revolutionize digital mental health while emphasizing the need for ethical, responsible and trustworthy AI algorithms. The review is guided by three key research questions: the impact of AI chatbots on technology integration, the balance between benefits and harms, and the mitigation of bias and prejudice in AI applications. Methodologically, the review involves extensive database and search engine searches, utilizing keywords related to AI chatbots and digital mental health. Peer-reviewed journal articles and media sources were purposively selected to address the research questions, resulting in a comprehensive analysis of the current state of knowledge on this evolving topic. In conclusion, AI chatbots hold promise in transforming digital mental health but must navigate complex ethical and practical challenges. The integration of HAI principles, responsible regulation and scoping reviews are crucial to maximizing their benefits while minimizing potential risks. Collaborative approaches and modern educational solutions may enhance responsible use and mitigate biases in AI applications, ensuring a more inclusive and effective digital mental health landscape.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/informatics10040082"
    },
    {
        "id": 708,
        "title": "Top 10 market entry strategies for digital health companies",
        "authors": "Liz Kwo, Katherine Sham",
        "published": "2023-12",
        "citations": 0,
        "abstract": " Tweetable abstract  The digital health market is growing at an unprecedented rate, and it's the perfect time for enterprising digital health startups to strike – but what's the best way to enter the market? Read on for potential GTM strategies and key considerations for business model development. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.2217/fmai-2023-0009"
    },
    {
        "id": 709,
        "title": "AI in healthcare: navigating opportunities and challenges in digital communication",
        "authors": "George Sun, Yi-Hui Zhou",
        "published": "2023-12-19",
        "citations": 2,
        "abstract": "The landscape of healthcare communication is undergoing a profound transformation in the digital age, and at the heart of this evolution are AI-powered chatbots. This mini-review delves into the role of AI chatbots in digital health, providing a detailed exploration of their applications, benefits, challenges, and future prospects. Our focus is on their versatile applications within healthcare, encompassing health information dissemination, appointment scheduling, medication management, remote patient monitoring, and emotional support services. The review underscores the compelling advantages of AI chatbots. However, it also addresses the significant challenges posed by the integration of AI tools into healthcare communication.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fdgth.2023.1291132"
    },
    {
        "id": 710,
        "title": "Improving quality in Digital Health Intervention safety",
        "authors": "S. Harrison, C. Maple, G. Epiphaniou, T. N. Arvanitis",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/icp.2023.2610"
    },
    {
        "id": 711,
        "title": "POINT OF CARE AI DRIVEN ER2EP REFERRALS FOR NON-VALVULAR ATRIAL FIBRILLATION PATIENTS IN THE EMERGENCY DEPARTMENT",
        "authors": "Kim Schwab",
        "published": "2023-10",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cvdhj.2023.08.004"
    },
    {
        "id": 712,
        "title": "AI for mammography screening: enter evidence from prospective trials",
        "authors": "Nehmat Houssami, M Luke Marinovich",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00176-0"
    },
    {
        "id": 713,
        "title": "AI-CAD for tuberculosis and other global high-burden diseases",
        "authors": "Matthew Arentz, Nikhil Jagtiani, Sandra Kik, Morten Ruhwald, Rigveda Kadam",
        "published": "2023-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(22)00254-0"
    },
    {
        "id": 714,
        "title": "AI for identification of systemic biomarkers from external eye photos: a promising field in the oculomics revolution",
        "authors": "Delia Cabrera DeBuc",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00047-x"
    },
    {
        "id": 715,
        "title": "New FDA Advisory Team to Focus on AI, Other Digital Health Technologies",
        "authors": "Emily Harris",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1001/jama.2023.21177"
    },
    {
        "id": 716,
        "title": "AI image-based diagnosis systems: how to implement them?",
        "authors": "Ablameyko Maria, Sergey Ablameyko",
        "published": "2023-6-20",
        "citations": 0,
        "abstract": "Artificial intelligence (AI) is starting to be widely used in the medical field and has great potential benefits to help doctors and patients. However, it also raises new challenges and problems. This paper analyzed the existing capacities of AI to make a diagnosis and assessed the legal consequences. We present AI medical image analysis systems developed in Belarus. International practice on how AI-systems are implemented in medicine is analyzed. Russian experience in developing standards to test and use AI systems in hospitals is described. Finally, the paper put forward some suggestions on how to improve the legal framework of AI systems using in medicine.",
        "keywords": "",
        "link": "http://dx.doi.org/10.55976/jdh.22023113912-21"
    },
    {
        "id": 717,
        "title": "Moving beyond algorithmic accuracy to improving user interaction with clinical AI",
        "authors": "Shlomo Berkovsky, Enrico Coiera",
        "published": "2023-3-22",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1371/journal.pdig.0000222"
    },
    {
        "id": 718,
        "title": "POINT OF CARE AI DRIVEN ER2EP REFERRALS FOR NON-VALVULAR ATRIAL FIBRILLATION",
        "authors": "Ali R. Roghanizad, Lauren E. Lederer, T. Clark Howell, Shelley Hwang, Jessilyn P. Dunn",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cvdhj.2023.11.011"
    },
    {
        "id": 719,
        "title": "Critical analysis of the AI impact on the patient–physician relationship: A multi-stakeholder qualitative study",
        "authors": "Anto Čartolovni, Anamaria Malešević, Luka Poslon",
        "published": "2023-1",
        "citations": 1,
        "abstract": "Objective This qualitative study aims to present the aspirations, expectations and critical analysis of the potential for artificial intelligence (AI) to transform patient–physician relationship, according to multi-stakeholder insight. Methods This study was conducted from June to December 2021, using an anticipatory ethics approach and sociology of expectations as the theoretical frameworks. It focused mainly on three groups of stakeholders; namely, physicians (n = 12), patients (n = 15) and healthcare managers (n = 11), all of whom are directly related to the adoption of AI in medicine (n = 38). Results In this study, interviews were conducted with 40% of the patients in the sample (15/38), as well as 31% of the physicians (12/38) and 29% of health managers in the sample (11/38). The findings highlight the following: (1) the impact of AI on fundamental aspects of the patient–physician relationship and the underlying importance of a synergistic relationship between the physician and AI; (2) the potential for AI to alleviate workload and reduce administrative burden by saving time and putting the patient at the centre of the caring process and (3) the potential risk to the holistic approach by neglecting humanness in healthcare. Conclusions This multi-stakeholder qualitative study, which focused on the micro-level of healthcare decision-making, sheds new light on the impact of AI on healthcare and the potential transformation of patient–physician relationship. The results of the current study highlight the need to adopt a critical awareness approach to the implementation of AI in healthcare by applying critical thinking and reasoning. It is important not to rely solely upon the recommendations of AI while neglecting clinical reasoning and physicians’ knowledge of best clinical practices. Instead, it is vital that the core values of the existing patient–physician relationship – such as trust and honesty, conveyed through open and sincere communication – are preserved. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1177/20552076231220833"
    },
    {
        "id": 720,
        "title": "Digital sovereignty, digital infrastructures, and quantum horizons",
        "authors": "Geoff Gordon",
        "published": "2024-2",
        "citations": 1,
        "abstract": "AbstractThis article holds that governmental investments in quantum technologies speak to the imaginable futures of digital sovereignty and digital infrastructures, two major areas of change driven by related technologies like AI and Big Data, among other things, in international law today. Under intense development today for future interpolation into digital systems that they may alter, quantum technologies occupy a sort of liminal position, rooted in existing assemblages of computational technologies while pointing to new horizons for them. The possibilities they raise are neither certain nor determinate, but active investments in them (legal, political and material investments) offer perspective on digital technology-driven influences on an international legal imagination. In contributing to visions of the future that are guiding ambitions for digital sovereignty and digital infrastructures, quantum technologies condition digital technology-driven changes to international law and legal imagination in the present. Privileging observation and description, I adapt and utilize a diffractive method with the aim to discern what emerges out of the interference among the several related things assembled for this article, including material technologies and legal institutions. In conclusion, I observe ambivalent changes to an international legal imagination, changes which promise transformation but appear nonetheless to reproduce current distributions of power and resources.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01729-7"
    },
    {
        "id": 721,
        "title": "Your robot therapist is not your therapist: understanding the role of AI-powered mental health chatbots",
        "authors": "Zoha Khawaja, Jean-Christophe Bélisle-Pipon",
        "published": "2023-11-8",
        "citations": 5,
        "abstract": "Artificial intelligence (AI)-powered chatbots have the potential to substantially increase access to affordable and effective mental health services by supplementing the work of clinicians. Their 24/7 availability and accessibility through a mobile phone allow individuals to obtain help whenever and wherever needed, overcoming financial and logistical barriers. Although psychological AI chatbots have the ability to make significant improvements in providing mental health care services, they do not come without ethical and technical challenges. Some major concerns include providing inadequate or harmful support, exploiting vulnerable populations, and potentially producing discriminatory advice due to algorithmic bias. However, it is not always obvious for users to fully understand the nature of the relationship they have with chatbots. There can be significant misunderstandings about the exact purpose of the chatbot, particularly in terms of care expectations, ability to adapt to the particularities of users and responsiveness in terms of the needs and resources/treatments that can be offered. Hence, it is imperative that users are aware of the limited therapeutic relationship they can enjoy when interacting with mental health chatbots. Ignorance or misunderstanding of such limitations or of the role of psychological AI chatbots may lead to a therapeutic misconception (TM) where the user would underestimate the restrictions of such technologies and overestimate their ability to provide actual therapeutic support and guidance. TM raises major ethical concerns that can exacerbate one's mental health contributing to the global mental health crisis. This paper will explore the various ways in which TM can occur particularly through inaccurate marketing of these chatbots, forming a digital therapeutic alliance with them, receiving harmful advice due to bias in the design and algorithm, and the chatbots inability to foster autonomy with patients.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fdgth.2023.1278186"
    },
    {
        "id": 722,
        "title": "What Is the Role of AI for Digital Twins?",
        "authors": "Frank Emmert-Streib",
        "published": "2023-9-1",
        "citations": 4,
        "abstract": "The concept of a digital twin is intriguing as it presents an innovative approach to solving numerous real-world challenges. Initially emerging from the domains of manufacturing and engineering, digital twin research has transcended its origins and now finds applications across a wide range of disciplines. This multidisciplinary expansion has impressively demonstrated the potential of digital twin research. While the simulation aspect of a digital twin is often emphasized, the role of artificial intelligence (AI) and machine learning (ML) is severely understudied. For this reason, in this paper, we highlight the pivotal role of AI and ML for digital twin research. By recognizing that a digital twin is a component of a broader Digital Twin System (DTS), we can fully grasp the diverse applications of AI and ML. In this paper, we explore six AI techniques—(1) optimization (model creation), (2) optimization (model updating), (3) generative modeling, (4) data analytics, (5) predictive analytics and (6) decision making—and their potential to advance applications in health, climate science, and sustainability.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ai4030038"
    },
    {
        "id": 723,
        "title": "Precision Medicine 2.0: How Digital Health and AI Are Changing the Game",
        "authors": "Daniele Giansanti",
        "published": "2023-6-28",
        "citations": 8,
        "abstract": "In the era of rapid IT developments, the health domain is undergoing a considerable transformation [...]",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/jpm13071057"
    },
    {
        "id": 724,
        "title": "HPR202 The Digital Transformation: How Could Artificial Intelligence (AI) Re-Shape Drug Launch?",
        "authors": "A. Robert, D. Foster, M. Brazier",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jval.2023.09.1520"
    },
    {
        "id": 725,
        "title": "Enhancing the relationship between digital technology/AI and frontline NHS healthcare staff",
        "authors": "S. Sholapurkar, A. T. Sheik",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/icp.2023.2555"
    },
    {
        "id": 726,
        "title": "Ethical considerations in implementing AI for mortality prediction in the emergency department: Linking theory and practice",
        "authors": "Lena Petersson, Kalista Vincent, Petra Svedberg, Jens M Nygren, Ingrid Larsson",
        "published": "2023-1",
        "citations": 1,
        "abstract": "Background Artificial intelligence (AI) is predicted to be a solution for improving healthcare, increasing efficiency, and saving time and recourses. A lack of ethical principles for the use of AI in practice has been highlighted by several stakeholders due to the recent attention given to it. Research has shown an urgent need for more knowledge regarding the ethical implications of AI applications in healthcare. However, fundamental ethical principles may not be sufficient to describe ethical concerns associated with implementing AI applications. Objective The aim of this study is twofold, (1) to use the implementation of AI applications to predict patient mortality in emergency departments as a setting to explore healthcare professionals’ perspectives on ethical issues in relation to ethical principles and (2) to develop a model to guide ethical considerations in AI implementation in healthcare based on ethical theory. Methods Semi-structured interviews were conducted with 18 participants. The abductive approach used to analyze the empirical data consisted of four steps alternating between inductive and deductive analyses. Results Our findings provide an ethical model demonstrating the need to address six ethical principles (autonomy, beneficence, non-maleficence, justice, explicability, and professional governance) in relation to ethical theories defined as virtue, deontology, and consequentialism when AI applications are to be implemented in clinical practice. Conclusions Ethical aspects of AI applications are broader than the prima facie principles of medical ethics and the principle of explicability. Ethical aspects thus need to be viewed from a broader perspective to cover different situations that healthcare professionals, in general, and physicians, in particular, may face when using AI applications in clinical practice. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1177/20552076231206588"
    },
    {
        "id": 727,
        "title": "The ensemble artificial intelligence (AI) method: Detection of hip fractures in AP pelvis plain radiographs by majority voting using a multi-center dataset",
        "authors": "Salih Beyaz, Sahika Betul Yayli, Ersin Kılıc, Ugur Doktur",
        "published": "2023-1",
        "citations": 0,
        "abstract": "Introduction This article was undertaken to explore the potential of AI in enhancing the diagnostic accuracy and efficiency in identifying hip fractures using X-ray radiographs. In the study, we trained three distinct deep learning models, and we utilized majority voting to evaluate their outcomes, aiming to yield the most reliable and precise diagnoses of hip fractures from X-ray radiographs. Methods An initial study was conducted of 10,849 AP pelvis X-rays obtained from five hospitals affiliated with Başkent University. Two expert orthopedic surgeons initially labeled 2,291 radiographs as fractures and 8,558 as non-fractures. The algorithm was trained on 6,943 (64%) radiographs, validated on 1,736 (16%) radiographs, and tested on 2,170 (20%) radiographs, ensuring an even distribution of fracture presence, age, and gender. We employed three advanced deep learning architectures, Xception (Model A), EfficientNet (Model B), and NfNet (Model C), with a final decision aggregated through a majority voting technique (Model D). Results For each model, we achieved the following metrics: For Model A: F1 Score 0.895, Accuracy 0.956, Specificity 0.973, Sensitivity 0.893. For Model B: F1 Score 0.900, Accuracy 0.960, Specificity 0.991, Sensitivity 0.845. For Model C: F1 Score 0.919, Accuracy 0.966, Specificity 0.984, Sensitivity 0.899. For Model D: F1 Score 0.929, Accuracy 0.971, Specificity 0.991, Sensitivity 0.897. We concluded that Model D (majority voting) achieved the best results in terms of the F1 score, accuracy, and specificity values. Conclusions Our study demonstrates that the results obtained by aggregating the decisions of multiple models through voting, rather than relying solely on the decision of a single algorithm, are more consistent. The practical application of these algorithms will be difficult due to ethical, legal, and confidentiality issues, despite the theoretical success achieved. Developing successful algorithms and methodologies should not be viewed as the ultimate goal; it is important to understand how these algorithms will be used in real-life situations. In order to achieve more consistent results, feedback from clinical practice will be helpful. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1177/20552076231216549"
    },
    {
        "id": 728,
        "title": "Social Media and Artificial Intelligence – Understanding Medical Misinformation Through Snapchat’s New AI Chatbot",
        "authors": "Clara E. Tandar, Simar S. Bajaj, Fatima Cody Stanford",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mcpdig.2024.04.004"
    },
    {
        "id": 729,
        "title": "Physician leadership in the new era of AI and digital health tools",
        "authors": "Jesse Ehrenfeld",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ibmed.2023.100109"
    },
    {
        "id": 730,
        "title": "Emerging data inputs for infectious diseases surveillance and decision making",
        "authors": "Aminath Shausan, Yoni Nazarathy, Amalie Dyda",
        "published": "2023-4-4",
        "citations": 1,
        "abstract": "Infectious diseases create a significant health and social burden globally and can lead to outbreaks and epidemics. Timely surveillance for infectious diseases is required to inform both short and long term public responses and health policies. Novel data inputs for infectious disease surveillance and public health decision making are emerging, accelerated by the COVID-19 pandemic. These include the use of technology-enabled physiological measurements, crowd sourcing, field experiments, and artificial intelligence (AI). These technologies may provide benefits in relation to improved timeliness and reduced resource requirements in comparison to traditional methods. In this review paper, we describe current and emerging data inputs being used for infectious disease surveillance and summarize key benefits and limitations.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fdgth.2023.1131731"
    },
    {
        "id": 731,
        "title": "AI ethics and ordoliberalism 2.0: towards a ‘Digital Bill of Rights’",
        "authors": "Manuel Wörsdörfer",
        "published": "2023-11-21",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00367-5"
    },
    {
        "id": 732,
        "title": "The Promise of Explainable AI in Digital Health for Precision Medicine: A Systematic Review",
        "authors": "Ben Allen",
        "published": "2024-3-1",
        "citations": 1,
        "abstract": "This review synthesizes the literature on explaining machine-learning models for digital health data in precision medicine. As healthcare increasingly tailors treatments to individual characteristics, the integration of artificial intelligence with digital health data becomes crucial. Leveraging a topic-modeling approach, this paper distills the key themes of 27 journal articles. We included peer-reviewed journal articles written in English, with no time constraints on the search. A Google Scholar search, conducted up to 19 September 2023, yielded 27 journal articles. Through a topic-modeling approach, the identified topics encompassed optimizing patient healthcare through data-driven medicine, predictive modeling with data and algorithms, predicting diseases with deep learning of biomedical data, and machine learning in medicine. This review delves into specific applications of explainable artificial intelligence, emphasizing its role in fostering transparency, accountability, and trust within the healthcare domain. Our review highlights the necessity for further development and validation of explanation methods to advance precision healthcare delivery.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/jpm14030277"
    },
    {
        "id": 733,
        "title": "A MULTI-MODAL WORKFLOW FOR INTEGRATING AI-BASED CT SCAR IMAGING AND COMPUTATIONAL ECG MAPPING TARGETS FOR VENTRICULAR TACHYCARDIA ABLATION",
        "authors": "Christopher Villongco, Christian D. Marton, Tony Moyeda, David E. Krummen, Gordon Ho",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cvdhj.2023.08.018"
    },
    {
        "id": 734,
        "title": "The robot butler: How and why should we study predictive algorithms and artificial intelligence (AI) in healthcare?",
        "authors": "Iben Mundbjerg Gjødsbøl, Anna Kirstine Ringgaard, Peter Christoffer Holm, Søren Brunak, Henning Bundgaard",
        "published": "2024-1",
        "citations": 0,
        "abstract": " Artificial intelligence (AI) and algorithms are heralded as significant solutions to the widening gap between the rising healthcare needs of ageing and multi-morbid populations and the scarcity of resources to provide such care. Objective This article investigates how the PMHnet algorithm – an AI prognostication tool developed in Denmark to predict the one-year all-cause mortality risk for patients hospitalized with ischemic heart disease – was presented to cardiologists working in the hospital setting, and how they responded to this novel decision-support tool. Methods Empirically, we draw upon ethnographic fieldwork in the Danish-led international research project, PM Heart, which since 2019 has developed the PMHnet algorithm and implemented the software into the electronic health record system in hospitals in Eastern Denmark (the Capital Region and Region Zealand). Results Paying careful attention to the hopes and concerns of cardiologists who will have to embrace and adapt to algorithmic tools in their everyday work of diagnosing and treating patients, we identify three analytical themes meriting attention when AI is implemented in healthcare: 1) the re-negotiation of agency and autonomy in human-algorithm relations, 2) accountability in algorithmic prognostication and 3) the complex relationship between association and causation actualized by predictive algorithms. From these analytical themes, we elicit methodological questions to guide future ethnographic explorations of how AI and advanced algorithms are put to use in the healthcare system, with what implications, and for whom. Conclusion We conclude that local, qualitative investigations of how algorithms are used, embraced and contested in everyday clinical practice are needed in order to understand their implications – good and bad, intended and unintended – for clinicians, patients and healthcare provision. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1177/20552076241241674"
    },
    {
        "id": 735,
        "title": "Economics of AI behavior: nudging the digital minds toward greater societal benefit",
        "authors": "Emre Sezgin",
        "published": "2023-8-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01742-w"
    },
    {
        "id": 736,
        "title": "Listen to the patients! Identifying CML patients' needs analyzing patient-generated content with AI-driven methodologies",
        "authors": "Stefanie Scholz, Isabell Berns, Christian Winkler",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "BackgroundVarious patient support programs exist to provide successful therapy options for patients. Pharmaceutical companies are increasingly recognizing the importance of actively supporting patients in their long-term treatment. In order to effectively assist patients, it is crucial to understand their current needs by taking a look at the patients' opinions.ObjectiveThis study focuses specifically on chronic myeloid leukemia (CML) and aims to determine if the current patient engagement offerings from pharmaceutical companies adequately address the needs of CML patients. To achieve this, the study uses content generated by CML patients to assess the patient engagement strategies of selected pharmaceutical companies, explore the relevance of medication, their products, and services, and analyze key concerns from the perspective of the patients.MethodsTo address the research questions, various methodologies were employed. Initially, desk research was conducted to identify relevant pharmaceutical companies and internet forums related to CML. Subsequently, content generated by patients was acquired and AI-driven techniques such as topic modeling and topic evolution analyses were used to examine this user-generated content (UGC) within the identified public forums. This involved analyzing topic models and tracking topic changes over time.ResultsThe desk research revealed that pharmaceutical companies primarily offer information about the disease and available treatment options. The UGC analysis confirmed the significant role played by the industry in supporting CML patients. Key areas of interest for patients include the disease itself, potential treatment methods and associated side effects, dosage of active substances, and the possibility of switching therapies due to treatment failure or resistance. Stem cell transplantation was also discussed.ConclusionsOverall, the pharmaceutical industry adequately addresses the needs of CML patients. However, there is room for improvement in educating patients about treatment options, drugs, and their side effects. Psychological support should not be neglected. Since CML patients frequently engage with clinical trial outcomes, there is potential for increased patient involvement in such trials. Further research in this area is recommended.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fdgth.2023.1243215"
    },
    {
        "id": 737,
        "title": "Improving Accessibility and Readability of Survey Reports in Digital Health Platforms using Conversational AI",
        "authors": "Pooya Moradian Zadeh, Deborah Sattler",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bibm58861.2023.10386018"
    },
    {
        "id": 738,
        "title": "AI-ASSISTED SHORT-TERM FORECASTING OF IMPENDING ATRIAL FIBRILLATION EPISODES USING A WEARABLE ECG PATCH",
        "authors": "Soonil Kwon, Jangwon Suh, Jungmin Ko, Hyo-Jeong Ahn, So-Ryoung Lee, Wonjong Rhee, Eue-Keun Choi, Seil Oh",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cvdhj.2023.08.012"
    },
    {
        "id": 739,
        "title": "Explainable artificial intelligence for mental health through transparency and interpretability for understandability",
        "authors": "Dan W. Joyce, Andrey Kormilitzin, Katharine A. Smith, Andrea Cipriani",
        "published": "2023-1-18",
        "citations": 33,
        "abstract": "AbstractThe literature on artificial intelligence (AI) or machine learning (ML) in mental health and psychiatry lacks consensus on what “explainability” means. In the more general XAI (eXplainable AI) literature, there has been some convergence on explainability meaning model-agnostic techniques that augment a complex model (with internal mechanics intractable for human understanding) with a simpler model argued to deliver results that humans can comprehend. Given the differing usage and intended meaning of the term “explainability” in AI and ML, we propose instead to approximate model/algorithm explainability by understandability defined as a function of transparency and interpretability. These concepts are easier to articulate, to “ground” in our understanding of how algorithms and models operate and are used more consistently in the literature. We describe the TIFU (Transparency and Interpretability For Understandability) framework and examine how this applies to the landscape of AI/ML in mental health research. We argue that the need for understandablity is heightened in psychiatry because data describing the syndromes, outcomes, disorders and signs/symptoms possess probabilistic relationships to each other—as do the tentative aetiologies and multifactorial social- and psychological-determinants of disorders. If we develop and deploy AI/ML models, ensuring human understandability of the inputs, processes and outputs of these models is essential to develop trustworthy systems fit for deployment.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41746-023-00751-9"
    },
    {
        "id": 740,
        "title": "The role of uncertainty and affect in decision-making on the adoption of AI-based contact-tracing technology during the COVID-19 pandemic",
        "authors": "Soo Jung Hong, Hichang Cho",
        "published": "2023-1",
        "citations": 4,
        "abstract": "ObjectiveThis study explores how negative affect, perceived net equity, and uncertainty influence the public's privacy decision-making regarding the adoption of contact-tracing technology based on artificial intelligence (AI) during the COVID-19 pandemic.MethodsFour hundred and eighteen adults in the US participated in the study via Amazon Mechanical Turk in August 2020. Statistical analyses were performed using the PROCESS macro. Indirect effects and their significance were estimated using bias-corrected bootstrap confidence intervals (CIs) with resampling set to n = 5000.ResultsPerceived net equity was positively associated with low levels of perceived uncertainty regarding a COVID-19 contact-tracing application and intention to adopt it. Low levels of perceived uncertainty were positively associated with intentions to adopt such an application, thereby suggesting that a perceived level of uncertainty mediates the association between perceived net equity and adoption intentions. Anxieties regarding AI technology and COVID-19 risks both moderate the associations among perceived net equity, perceived level of uncertainty, and intentions to adopt the contact-tracing technology.ConclusionsOur findings highlight how the differing sources of emotion influence the associations among rational judgment, perceptions, and decision-making about new contact-tracing technology. Overall, the results suggest that both rational judgments and affective reactions to risks are important influencers of individuals’ perceptions and privacy-related decision-making regarding a new health technology during the pandemic.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1177/20552076231169836"
    },
    {
        "id": 741,
        "title": "Privacy preserving in health data collection using LDP and IOTA",
        "authors": "I. Nawaz, M. A. Shah, M. Bibi, A. Nawaz",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/icp.2023.2559"
    },
    {
        "id": 742,
        "title": "The Emergence of AI-Based Wearable Sensors for Digital Health Technology: A Review",
        "authors": "Shaghayegh Shajari, Kirankumar Kuruvinashetti, Amin Komeili, Uttandaraman Sundararaj",
        "published": "2023-11-29",
        "citations": 6,
        "abstract": "Disease diagnosis and monitoring using conventional healthcare services is typically expensive and has limited accuracy. Wearable health technology based on flexible electronics has gained tremendous attention in recent years for monitoring patient health owing to attractive features, such as lower medical costs, quick access to patient health data, ability to operate and transmit data in harsh environments, storage at room temperature, non-invasive implementation, mass scaling, etc. This technology provides an opportunity for disease pre-diagnosis and immediate therapy. Wearable sensors have opened a new area of personalized health monitoring by accurately measuring physical states and biochemical signals. Despite the progress to date in the development of wearable sensors, there are still several limitations in the accuracy of the data collected, precise disease diagnosis, and early treatment. This necessitates advances in applied materials and structures and using artificial intelligence (AI)-enabled wearable sensors to extract target signals for accurate clinical decision-making and efficient medical care. In this paper, we review two significant aspects of smart wearable sensors. First, we offer an overview of the most recent progress in improving wearable sensor performance for physical, chemical, and biosensors, focusing on materials, structural configurations, and transduction mechanisms. Next, we review the use of AI technology in combination with wearable technology for big data processing, self-learning, power-efficiency, real-time data acquisition and processing, and personalized health for an intelligent sensing platform. Finally, we present the challenges and future opportunities associated with smart wearable sensors.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23239498"
    },
    {
        "id": 743,
        "title": "Joint Expedition: Exploring the Intersection of Digital Health and AI in Precision Medicine with Team Integration",
        "authors": "Daniele Giansanti",
        "published": "2024-4-4",
        "citations": 0,
        "abstract": "Precision medicine stands as a transformative force in the orbit of healthcare, fundamentally reshaping traditional approaches by customizing therapeutic interventions to align with the distinctive attributes of individual patients [...]",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/jpm14040388"
    },
    {
        "id": 744,
        "title": "Editorial: Surfacing best practices for AI software development and integration in\nhealthcare",
        "authors": "Mark Sendak, David Vidal, Sylvia Trujillo, Karandeep Singh, Xiaoxuan Liu, Suresh Balu",
        "published": "2023-2-21",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fdgth.2023.1150875"
    },
    {
        "id": 745,
        "title": "Predictive modeling of skin permeability for molecules: Investigating FDA-approved drug permeability with various AI algorithms",
        "authors": "Rami M. Abdallah, Hisham E. Hasan, Ahmad Hammad",
        "published": "2024-4-3",
        "citations": 0,
        "abstract": "The transdermal route of drug administration has gained popularity for its convenience and bypassing the first-pass metabolism. Accurate skin permeability prediction is crucial for successful transdermal drug delivery (TDD). In this study, we address this critical need to enhance TDD. A dataset comprising 441 records for 140 molecules with diverse LogKp values was characterized. The descriptor calculation yielded 145 relevant descriptors. Machine learning models, including MLR, RF, XGBoost, CatBoost, LGBM, and ANN, were employed for regression analysis. Notably, LGBM, XGBoost, and gradient boosting models outperformed others, demonstrating superior predictive accuracy. Key descriptors influencing skin permeability, such as hydrophobicity, hydrogen bond donors, hydrogen bond acceptors, and topological polar surface area, were identified and visualized. Cluster analysis applied to the FDA-approved drug dataset (2326 compounds) revealed four distinct clusters with significant differences in molecular characteristics. Predicted LogKp values for these clusters offered insights into the permeability variations among FDA-approved drugs. Furthermore, an investigation into skin permeability patterns across 83 classes of FDA-approved drugs based on the ATC code showcased significant differences, providing valuable information for drug development strategies. The study underscores the importance of accurate skin permeability prediction for TDD, emphasizing the superior performance of nonlinear machine learning models. The identified key descriptors and clusters contribute to a nuanced understanding of permeability characteristics among FDA-approved drugs. These findings offer actionable insights for drug design, formulation, and prioritization of molecules with optimum properties, potentially reducing reliance on costly experimental testing. Future research directions include offering promising applications in pharmaceutical research and formulation within the burgeoning field of computer-aided drug design.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1371/journal.pdig.0000483"
    },
    {
        "id": 746,
        "title": "Medical practitioner perspectives on AI in emergency triage",
        "authors": "Beverley A. Townsend, Katherine L. Plant, Victoria J. Hodge, Ol’Tunde Ashaolu, Radu Calinescu",
        "published": "2023-12-6",
        "citations": 1,
        "abstract": "IntroductionA proposed Diagnostic AI System for Robot-Assisted Triage (“DAISY”) is under development to support Emergency Department (“ED”) triage following increasing reports of overcrowding and shortage of staff in ED care experienced within National Health Service, England (“NHS”) but also globally. DAISY aims to reduce ED patient wait times and medical practitioner overload. The objective of this study was to explore NHS health practitioners' perspectives and attitudes towards the future use of AI-supported technologies in ED triage.MethodsBetween July and August 2022 a qualitative-exploratory research study was conducted to collect and capture the perceptions and attitudes of nine NHS healthcare practitioners to better understand the challenges and benefits of a DAISY deployment. The study was based on a thematic analysis of semi-structured interviews. The study involved qualitative data analysis of the interviewees' responses. Audio-recordings were transcribed verbatim, and notes included into data documents. The transcripts were coded line-by-line, and data were organised into themes and sub-themes. Both inductive and deductive approaches to thematic analysis were used to analyse such data.ResultsBased on a qualitative analysis of coded interviews with the practitioners, responses were categorised into broad main thematic-types, namely: trust; current practice; social, legal, ethical, and cultural concerns; and empathetic practice. Sub-themes were identified for each main theme. Further quantitative analyses explored the vocabulary and sentiments of the participants when talking generally about NHS ED practices compared to discussing DAISY. Limitations include a small sample size and the requirement that research participants imagine a prototype AI-supported system still under development. The expectation is that such a system would work alongside the practitioner. Findings can be generalisable to other healthcare AI-supported systems and to other domains.DiscussionThis study highlights the benefits and challenges for an AI-supported triage healthcare solution. The study shows that most NHS ED practitioners interviewed were positive about such adoption. Benefits cited were a reduction in patient wait times in the ED, assistance in the streamlining of the triage process, support in calling for appropriate diagnostics and for further patient examination, and identification of those very unwell and requiring more immediate and urgent attention. Words used to describe the system were that DAISY is a “good idea”, “help”, helpful, “easier”, “value”, and “accurate”. Our study demonstrates that trust in the system is a significant driver of use and a potential barrier to adoption. Participants emphasised social, legal, ethical, and cultural considerations and barriers to DAISY adoption and the importance of empathy and non-verbal cues in patient interactions. Findings demonstrate how DAISY might support and augment human medical performance in ED care, and provide an understanding of attitudinal barriers and considerations for the development and implementation of future triage AI-supported systems.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fdgth.2023.1297073"
    },
    {
        "id": 747,
        "title": "Implementing AI-based Computer-Aided Diagnosis for Radiological Detection of Tuberculosis: A Multi-Stage Health Technology Assessment",
        "authors": "David Hua, Neysa Petrina, Noel Young, Jin-Gun Cho, Simon K. Poon",
        "published": "2023-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdh60066.2023.00059"
    },
    {
        "id": 748,
        "title": "Usability evaluation of mobile phone technologies for capturing cancer patient-reported outcomes and physical functions",
        "authors": "Ingrid Oakley-Girvan, Reem Yunis, Stephanie J Fonda, Elad Neeman, Raymond Liu, Sara Aghaee, Maya E Ramsey, Ai Kubo, Sharon W Davis",
        "published": "2023-1",
        "citations": 3,
        "abstract": "Background By eliminating the requirement for participants to make frequent visits to research sites, mobile phone applications (“apps”) may help to decentralize clinical trials. Apps may also be an effective mechanism for capturing patient-reported outcomes and other endpoints, helping to optimize patient care during and outside of clinical trials. Objectives We report on the usability of Digital BioMarkers for Clinical Impact (DigiBioMarC™ (DBM)), a novel smartphone-based app used by cancer patients in conjunction with a wearable device (Apple Watch®). DBM is designed to collect patient-reported outcomes and record physical functions. Methods In a fully decentralized “bring-your-own-device” smartphone study, we enrolled 54 cancer patient and caregiver dyads from Kaiser Permanente Northern California (KPNC) from October 2020 through March 2021. Patients used the app for at least 28 days, completed weekly questionnaires about their symptoms, physical functions, and mood, and performed timed physical tasks. Usability was determined through a subset of the Mobile App Rating Scale (MARS), the full System Usability Scale (SUS), the Net Promoter Score (NPS), and semi-structured interviews. Results We obtained usability survey data from 50 of 54 patients. Median responses to the selected MARS questions and the mean SUS scores indicated above average usability. The NPS from the semi-structured interviews at the end of the study was 24, indicating a favorable score. Conclusions Cancer patients reported above average usability for the DBM app. Qualitative analyses indicated that the app was easy to use and helpful. Future work will emphasize implementing further patient recommendations and evaluating the app's clinical efficacy in multiple settings. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1177/20552076231186515"
    },
    {
        "id": 749,
        "title": "Online Learning and Its Short-term Impact on Digital Engagement and Digital-related Health Symptoms Amongst University Students During the COVID-19 Pandemic",
        "authors": "Ai-Hong Chen, Nur Rifqah Roslan, YW Hoe Cosette, Swee Chai Teoh",
        "published": "2023-5-15",
        "citations": 0,
        "abstract": "Introduction: The COVID-19 pandemic has precipitated a rapid shift of learning and education from traditional means to digital platforms. This paper aims to examine the impact of online learning on digital engagement and digital-related health symptoms among university students one year into the coronavirus pandemic. Methods: Data was collected through a self-administered online questionnaire after ethical approval. The questionnaire was adapted from the previously published Lifestyle Study in Youth Questionnaire. Through the questionnaire, the perception of students toward online learning was probed and recorded. Digital engagement and digital-related health symptoms were compared before and during the COVID-19 lockdown. Results: The majority (97.5%) of respondents preferred face-to-face learning. The time spent on digital devices was 1.8 times higher during COVID-19 than before the COVID-19 lockdown (t-test = -18.86, p<0.0001). The total hours of sleep were reduced during COVID-19 lockdown (0.6 hours lesser) (t-test = -3.92, p<0.0001). The Wilcoxon Signed Ranks Test revealed significant changes in digital-related health symptoms (15 out of 17) due to the COVID-19 lockdown. Digital eye strain, dry eye syndrome, carpal tunnel syndrome, and upper quadrant postural and muscle strain emerged (p<0.05). Conclusion: Most university students favoured face-to-face learning compared to online learning. There was a two-fold rise in digital engagement during the COVID-19 lockdown. As a result, it has seemed to translate into reduced sleeping hours. The short-term impact of the coronavirus pandemic on digital-related health symptoms amongst university students was apparent. The long-term effects require further investigations to facilitate fact-based decision-making.",
        "keywords": "",
        "link": "http://dx.doi.org/10.47836/mjmhs.19.3.18"
    },
    {
        "id": 750,
        "title": "Lung-DT: An AI-Powered Digital Twin Framework for Thoracic Health Monitoring and Diagnosis",
        "authors": "Roberta Avanzato, Francesco Beritelli, Alfio Lombardo, Carmelo Ricci",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "The integration of artificial intelligence (AI) with Digital Twins (DTs) has emerged as a promising approach to revolutionize healthcare, particularly in terms of diagnosis and management of thoracic disorders. This study proposes a comprehensive framework, named Lung-DT, which leverages IoT sensors and AI algorithms to establish the digital representation of a patient’s respiratory health. Using the YOLOv8 neural network, the Lung-DT system accurately classifies chest X-rays into five distinct categories of lung diseases, including “normal”, “covid”, “lung_opacity”, “pneumonia”, and “tuberculosis”. The performance of the system was evaluated employing a chest X-ray dataset available in the literature, demonstrating average accuracy of 96.8%, precision of 92%, recall of 97%, and F1-score of 94%. The proposed Lung-DT framework offers several advantages over conventional diagnostic methods. Firstly, it enables real-time monitoring of lung health through continuous data acquisition from IoT sensors, facilitating early diagnosis and intervention. Secondly, the AI-powered classification module provides automated and objective assessments of chest X-rays, reducing dependence on subjective human interpretation. Thirdly, the twin digital representation of the patient’s respiratory health allows for comprehensive analysis and correlation of multiple data streams, providing valuable insights as to personalized treatment plans. The integration of IoT sensors, AI algorithms, and DT technology within the Lung-DT system demonstrates a significant step towards improving thoracic healthcare. By enabling continuous monitoring, automated diagnosis, and comprehensive data analysis, the Lung-DT framework has enormous potential to enhance patient outcomes, reduce healthcare costs, and optimize resource allocation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s24030958"
    },
    {
        "id": 751,
        "title": "The Integration of AI in Mental Health Assessment: Leveraging Digital",
        "authors": "Maren M. Michaelsen, Tobias Esch",
        "published": "2023-7-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.61936/themind/202307024"
    },
    {
        "id": 752,
        "title": "Generative AI for Children's Digital Health: Clinician Advice",
        "authors": "Natalia Ingebretsen Kucirkova, Barry Zuckerman",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1097/dbp.0000000000001234"
    },
    {
        "id": 753,
        "title": "How to dance, robot?",
        "authors": "Eric Mullis",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01819-6"
    },
    {
        "id": 754,
        "title": "Artificial intimacy: virtual friends, digital lovers, algorithmic matchmakers",
        "authors": "Linda Hamrick",
        "published": "2023-1-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-022-01624-7"
    },
    {
        "id": 755,
        "title": "AI chatbots not yet ready for clinical use",
        "authors": "Joshua Au Yeung, Zeljko Kraljevic, Akish Luintel, Alfred Balston, Esther Idowu, Richard J. Dobson, James T. Teo",
        "published": "2023-4-12",
        "citations": 38,
        "abstract": "As large language models (LLMs) expand and become more advanced, so do the natural language processing capabilities of conversational AI, or “chatbots”. OpenAI's recent release, ChatGPT, uses a transformer-based model to enable human-like text generation and question-answering on general domain knowledge, while a healthcare-specific Large Language Model (LLM) such as GatorTron has focused on the real-world healthcare domain knowledge. As LLMs advance to achieve near human-level performances on medical question and answering benchmarks, it is probable that Conversational AI will soon be developed for use in healthcare. In this article we discuss the potential and compare the performance of two different approaches to generative pretrained transformers—ChatGPT, the most widely used general conversational LLM, and Foresight, a GPT (generative pretrained transformer) based model focused on modelling patients and disorders. The comparison is conducted on the task of forecasting relevant diagnoses based on clinical vignettes. We also discuss important considerations and limitations of transformer-based chatbots for clinical use.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fdgth.2023.1161098"
    },
    {
        "id": 756,
        "title": "Digital developments in neurology and psychiatry: digital health apps, telemedicine, AI—Blessing or threat?",
        "authors": "Peter Zwanzger, Uta Meyding-Lamadé",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00115-024-01607-7"
    },
    {
        "id": 757,
        "title": "A trustworthy AI reality-check: the lack of transparency of artificial intelligence products in healthcare",
        "authors": "Jana Fehr, Brian Citro, Rohit Malpani, Christoph Lippert, Vince I. Madai",
        "published": "2024-2-20",
        "citations": 0,
        "abstract": "Trustworthy medical AI requires transparency about the development and testing of underlying algorithms to identify biases and communicate potential risks of harm. Abundant guidance exists on how to achieve transparency for medical AI products, but it is unclear whether publicly available information adequately informs about their risks. To assess this, we retrieved public documentation on the 14 available CE-certified AI-based radiology products of the II b risk category in the EU from vendor websites, scientific publications, and the European EUDAMED database. Using a self-designed survey, we reported on their development, validation, ethical considerations, and deployment caveats, according to trustworthy AI guidelines. We scored each question with either 0, 0.5, or 1, to rate if the required information was “unavailable”, “partially available,” or “fully available.” The transparency of each product was calculated relative to all 55 questions. Transparency scores ranged from 6.4% to 60.9%, with a median of 29.1%. Major transparency gaps included missing documentation on training data, ethical considerations, and limitations for deployment. Ethical aspects like consent, safety monitoring, and GDPR-compliance were rarely documented. Furthermore, deployment caveats for different demographics and medical settings were scarce. In conclusion, public documentation of authorized medical AI products in Europe lacks sufficient public transparency to inform about safety and risks. We call on lawmakers and regulators to establish legally mandated requirements for public and substantive transparency to fulfill the promise of trustworthy AI for health.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fdgth.2024.1267290"
    },
    {
        "id": 758,
        "title": "The Epistemic Status of AI in Medical Practices: Ethical Challenges",
        "authors": "Angelina Baeva",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "In recent years, discussions have been increasingly emerging in modern scientific research that, in connection with the development of AI technologies, questions arise about the objectivity, plausibility and reliability of knowledge, as well as whether these technologies will not replace the expert figure as the authority that has so far acted as a guarantor of objectivity and the center of decision-making. Modern historians of science Duston L. and Galison P. in their book on the history of scientific objectivity, they talk about the alternation of \"epistemic virtues\", as one of which objectivity has been established since a certain moment. At the same time, the promotion of one or another virtue regulating the scientific self, i.e. acting as a normative principle for a scientist when choosing one or another way of seeing and one or another scientific practice, depends on making decisions in difficult cases requiring the will and limitation of the self. In this sense, epistemology is combined with ethics: a scientist, guided by certain moral principles, gives preference to one or another way of behavior, choosing, for example, not a more accurate hand-drawn image, but an uncluttered photograph, perhaps fuzzy, but obtained mechanically, which means more objective and free from any admixture of subjectivity. In this regard, the epistemic status of modern AI-based technologies, which increasingly assume the functions of the scientific self, including in terms of influencing final decision-making and obtaining objective knowledge, seems interesting. For example, in the field of medicine, robotic devices already provide significant support, taking over some of the functions, for example, of a first-level doctor to collect and analyze standardized patient data and diagnostics. There is an assumption that AI will take on more and more responsibilities in the near future: data processing, development of new drugs and treatment methods, establishing remote interaction with the patient, etc. But does this mean that the scientific self can be replaced by AI-based algorithms, and another epistemic virtue will replace objectivity, finally breaking the link between ethics and epistemology – this question needs to be investigated.",
        "keywords": "",
        "link": "http://dx.doi.org/10.17816/dd625319"
    },
    {
        "id": 759,
        "title": "The Gap Between AI and Bedside: Participatory Workshop on the Barriers to the Integration, Translation, and Adoption of Digital Health Care and AI Startup Technology Into Clinical Practice",
        "authors": "Iredia M Olaye, Azizi A Seixas",
        "published": "2023-5-2",
        "citations": 4,
        "abstract": "\nBackground\nArtificial intelligence (AI) and digital health technological innovations from startup companies used in clinical practice can yield better health outcomes, reduce health care costs, and improve patients' experience. However, the integration, translation, and adoption of these technologies into clinical practice are plagued with many challenges and are lagging. Furthermore, explanations of the impediments to clinical translation are largely unknown and have not been systematically studied from the perspective of AI and digital health care startup founders and executives.\n\n\nObjective\nThe aim of this paper is to describe the barriers to integrating early-stage technologies in clinical practice and health care systems from the perspectives of digital health and health care AI founders and executives.\n\n\nMethods\nA stakeholder focus group workshop was conducted with a sample of 10 early-stage digital health and health care AI founders and executives. Digital health, health care AI, digital health–focused venture capitalists, and physician executives were represented. Using an inductive thematic analysis approach, transcripts were organized, queried, and analyzed for thematic convergence.\n\n\nResults\nWe identified the following four categories of barriers in the integration of early-stage digital health innovations into clinical practice and health care systems: (1) lack of knowledge of health system technology procurement protocols and best practices, (2) demanding regulatory and validation requirements, (3) challenges within the health system technology procurement process, and (4) disadvantages of early-stage digital health companies compared to large technology conglomerates. Recommendations from the study participants were also synthesized to create a road map to mitigate the barriers to integrating early-stage or novel digital health technologies in clinical practice.\n\n\nConclusions\nEarly-stage digital health and health care AI entrepreneurs identified numerous barriers to integrating digital health solutions into clinical practice. Mitigation initiatives should create opportunities for early-stage digital health technology companies and health care providers to interact, develop relationships, and use evidence-based research and best practices during health care technology procurement and evaluation processes.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.2196/32962"
    },
    {
        "id": 760,
        "title": "Rethinking “digital”: a genealogical enquiry into the meaning of digital and its impact on individuals and society",
        "authors": "Luca Capone, Marta Rocchi, Marta Bertolaso",
        "published": "2023-5-15",
        "citations": 0,
        "abstract": "AbstractIn the current social and technological scenario, the term digital is abundantly used with an apparently transparent and unambiguous meaning. This article aims to unveil the complexity of this concept, retracing its historical and cultural origin. This genealogical overview allows to understand the reason why an instrumental conception of digital media has prevailed, considering the digital as a mere tool to convey a message, as opposed to a constitutive conception. The constitutive conception places the digital phenomenon in the broader ground of media studies, and it considers digital technologies as an interface between the subject and the world. In this perspective, the media is not added to the experience of the person, but it shapes it from within on a cognitive, expressive and communicative level. The article makes use of two powerful examples to show the shortcomings of an instrumental conception of the digital, and to affirm the value of a constitutive conception for current media studies regarding digital interfaces.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01687-0"
    },
    {
        "id": 761,
        "title": "Beyond the physical self: understanding the perversion of reality and the desire for digital transcendence via digital avatars in the context of Baudrillard’s theory",
        "authors": "Lucas Freund",
        "published": "2024-3-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-024-01900-8"
    },
    {
        "id": 762,
        "title": "Generative AI and large language models in health care: pathways to implementation",
        "authors": "Marium M. Raza, Kaushik P. Venkatesh, Joseph C. Kvedar",
        "published": "2024-3-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41746-023-00988-4"
    },
    {
        "id": 763,
        "title": "Digital assemblages with AI for creative interpretation of short stories",
        "authors": "Kieran O'Halloran",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "Abstract\nI demonstrate an approach fostering inventive interpretation of short stories in Literary Studies and higher education generally. It involves constructing an ‘assemblage’—at its simplest, an evolving network of unusual connections for creative outcome. The assemblage of this article combines freshly located research literature, directly and indirectly related to a story’s themes, and/or the personality type of protagonists. Importantly, this assemblage also utilizes text analysis software revealing the relatively invisible (e.g. (in)frequent words, parts of speech, and topics) and Large Language Model (LLM) Generative AI to enrich the interpretation. The use of all these elements helps productively exceed initial intuitions about the story, facilitating creativity. I model the approach using Edgar Allan Poe’s short story, The Black Cat, whose protagonist is a homicidal psychopath. Specifically, the assemblage here includes relevant software-based research (a corpus analysis of homicidal psychopathic language), non-software-based research (psychoanalytical literary criticism of The Black Cat using the empirically validated concept of transference), text analysis software (WMatrix and Datayze), and the LLM Generative AI, ‘ChatGPT’ (using the freely available LLM GPT-3.5). One use of this approach is as a pedagogy in Literary Studies employing text analysis software (e.g. on a digital stylistics course). Yet given creative adaptability is a key 21st-century skill, with digital literacy—including the use of Generative AI—an important contemporary competence, and with the short story genre universally known, I highlight too the utility of this approach as a university-wide pedagogy for enhancing creative thinking.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1093/llc/fqad050"
    },
    {
        "id": 764,
        "title": "Digital twin-based services: a taxonomy",
        "authors": "C. Galera-Zarco, E. Papadonikolaki",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/icp.2023.2578"
    },
    {
        "id": 765,
        "title": "Digital forensics in the age of AI, cryptocurrencies, and mobile phones",
        "authors": "",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.fsidi.2023.301628"
    },
    {
        "id": 766,
        "title": "Digital health equity for older populations",
        "authors": " The Lancet Digital Health",
        "published": "2023-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00114-0"
    },
    {
        "id": 767,
        "title": "Ethics and Transparency Issues in Digital Platforms: An Overview",
        "authors": "Leilasadat Mirghaderi, Monika Sziron, Elisabeth Hildt",
        "published": "2023-9-28",
        "citations": 1,
        "abstract": "There is an ever-increasing application of digital platforms that utilize artificial intelligence (AI) in our daily lives. In this context, the matters of transparency and accountability remain major concerns that are yet to be effectively addressed. The aim of this paper is to identify the zones of non-transparency in the context of digital platforms and provide recommendations for improving transparency issues on digital platforms. First, by surveying the literature and reflecting on the concept of platformization, choosing an AI definition that can be adopted by different stakeholders, and utilizing AI ethics, we will identify zones of non-transparency in the context of digital platforms. Second, after identifying the zones of non-transparency, we go beyond a mere summary of existing literature and provide our perspective on how to address the raised concerns. Based on our survey of the literature, we find that three major zones of non-transparency exist in digital platforms. These include a lack of transparency with regard to who contributes to platforms; lack of transparency with regard to who is working behind platforms, the contributions of those workers, and the working conditions of digital workers; and lack of transparency with regard to how algorithms are developed and governed. Considering the abundance of high-level principles in the literature that cannot be easily operationalized, this is an attempt to bridge the gap between principles and operationalization.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ai4040042"
    },
    {
        "id": 768,
        "title": "ChatGPT and digital capitalism: need for an antidote of Competition Law",
        "authors": "Garima Gupta",
        "published": "2023-12-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01822-x"
    },
    {
        "id": 769,
        "title": "Enhancing patient outcomes: the role of clinical utility in guiding healthcare providers in curating radiology AI applications",
        "authors": "Franziska Lobig, Jacob Graham, Apeksha Damania, Brian Sattin, Joana Reis, Prateek Bharadwaj",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": "With advancements in artificial intelligence (AI) dominating the headlines, diagnostic imaging radiology is no exception to the accelerating role that AI is playing in today's technology landscape. The number of AI-driven radiology diagnostic imaging applications (digital diagnostics) that are both commercially available and in-development is rapidly expanding as are the potential benefits these tools can deliver for patients and providers alike. Healthcare providers seeking to harness the potential benefits of digital diagnostics may consider evaluating these tools and their corresponding use cases in a systematic and structured manner to ensure optimal capital deployment, resource utilization, and, ultimately, patient outcomes—or clinical utility. We propose several guiding themes when using clinical utility to curate digital diagnostics.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fdgth.2024.1359383"
    },
    {
        "id": 770,
        "title": "Opioid-related harms and care impacts of conventional and AI-based prescription management strategies: insights from leveraging agent-based modeling and machine learning",
        "authors": "Narjes Shojaati, Nathaniel D. Osgood",
        "published": "2023-6-20",
        "citations": 0,
        "abstract": "IntroductionLike its counterpart to the south, Canada ranks among the top five countries with the highest rates of opioid prescriptions. With many suffering from opioid use disorder first having encountered opioids via prescription routes, practitioners and health systems have an enduring need to identify and effectively respond to the problematic use of opioid prescription. There are strong challenges to successfully addressing this need: importantly, the patterns of prescription fulfillment that signal opioid abuse can be subtle and difficult to recognize, and overzealous enforcement can deprive those with legitimate pain management needs the appropriate care. Moreover, injudicious responses risk shifting those suffering from early-stage abuse of prescribed opioids to illicitly sourced street alternatives, whose varying dosage, availability, and the risk of adulteration can pose grave health risks.MethodsThis study employs a dynamic modeling and simulation to evaluate the effectiveness of prescription regimes employing machine learning monitoring programs to identify the patients who are at risk of opioid abuse while being treated with prescribed opioids. To this end, an agent-based model was developed and implemented to examine the effect of reduced prescribing and prescription drug monitoring programs on overdose and escalation to street opioids among patients, and on the legitimacy of fulfillments of opioid prescriptions over a 5-year time horizon. A study released by the Canadian Institute for Health Information was used to estimate the parameter values and assist in the validation of the existing agent-based model.Results and discussionThe model estimates that lowering the prescription doses exerted the most favorable impact on the outcomes of interest over 5 years with a minimum burden on patients with a legitimate need for pharmaceutical opioids. The accurate conclusion about the impact of public health interventions requires a comprehensive set of outcomes to test their multi-dimensional effects, as utilized in this research. Finally, combining machine learning and agent-based modeling can provide significant advantages, particularly when using the latter to gain insights into the long-term effects and dynamic circumstances of the former.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fdgth.2023.1174845"
    },
    {
        "id": 771,
        "title": "The AI cycle of health inequity and digital ageism: mitigating biases through the EU regulatory framework on medical devices",
        "authors": "Hannah van Kolfschooten",
        "published": "2023-7-1",
        "citations": 0,
        "abstract": "Abstract\nThe use of Artificial Intelligence (AI) medical devices is rapidly growing. Although AI may benefit the quality and safety of healthcare for older adults, it simultaneously introduces new ethical and legal issues. Many AI medical devices exhibit age-related biases. The first part of this paper explains how ‘digital ageism’ is produced throughout the entire lifecycle of medical AI and may lead to health inequity for older people: systemic, avoidable differences in the health status of different population groups. This paper takes digital ageism as a use case to show the potential inequitable effects of AI, conceptualized as the ‘AI cycle of health inequity’. The second part of this paper explores how the European Union (EU) regulatory framework addresses the issue of digital ageism. It argues that the negative effects of age-related bias in AI medical devices are insufficiently recognized within the regulatory framework of the EU Medical Devices Regulation and the new AI Act. It concludes that while the EU framework does address some of the key issues related to technical biases in AI medical devices by stipulating rules for performance and data quality, it does not account for contextual biases, therefore neglecting part of the AI cycle of health inequity.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1093/jlb/lsad031"
    },
    {
        "id": 772,
        "title": "Children must co-design digital health research",
        "authors": " The Lancet Digital Health",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00071-7"
    },
    {
        "id": 773,
        "title": "Open source intelligence and AI: a systematic review of the GELSI literature﻿",
        "authors": "Riccardo Ghioni, Mariarosaria Taddeo, Luciano Floridi",
        "published": "2023-1-28",
        "citations": 2,
        "abstract": "AbstractToday, open source intelligence (OSINT), i.e., information derived from publicly available sources, makes up between 80 and 90 percent of all intelligence activities carried out by Law Enforcement Agencies (LEAs) and intelligence services in the West. Developments in data mining, machine learning, visual forensics and, most importantly, the growing computing power available for commercial use, have enabled OSINT practitioners to speed up, and sometimes even automate, intelligence collection and analysis, obtaining more accurate results more quickly. As the infosphere expands to accommodate ever-increasing online presence, so does the pool of actionable OSINT. These developments raise important concerns in terms of governance, ethical, legal, and social implications (GELSI). New and crucial oversight concerns emerge alongside standard privacy concerns, as some of the more advanced data analysis tools require little to no supervision. This article offers a systematic review of the relevant literature. It analyzes 571 publications to assess the current state of the literature on the use of AI-powered OSINT (and the development of OSINT software) as it relates to the GELSI framework, highlighting potential gaps and suggesting new research directions.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01628-x"
    },
    {
        "id": 774,
        "title": "The Intersection of AI and Digital Entrepreneurship: Studying the Varied Ways that AI is Changing Digital Enterprises",
        "authors": "Mohammed Charaf Eddine BOUREZIG, Soumya Chahinez TALEB BOUGUERRI TALEB BOUGUERRI",
        "published": "2024-2-10",
        "citations": 0,
        "abstract": "Artificial intеlligеncе (AI) is rеvolutionising industriеs and organisations. This rеsеarch dеlvеs into thе ways in which lеading tеchnology companiеs such, as Googlе, Facеbook, Amazon, Nеtflix, and Alibaba utilisе AI to еnhancе thеir companies’ valuе strеamlinе opеrations and еlеvatе customеr еxpеriеncеs. Through an analysis of publishеd studiеs, this study uncovеrs thе primary applications, kеy succеss factors and potеntial consеquеncеs of intеgrating AI into digital organisations. Thе findings illustratе how AI еmpowеrs businеssеs to offеr products and sеrvicеs improvеs еfficiеncy through automation procеssеs and providеs data drivеn-insights that aid in dеcision making. Howеvеr, it is crucial to еnsurе that AI is utilisеd еthically and rеsponsibly. Dеspitе thе potеntial offеrеd by AI tеchnology businеssеs still nееd to addrеss associatеd challеngеs. To achiеvе succеss in this rеalm, companiеs must еmbracе thе capabilitiеs of AI whilе fostеring crеativity and nurturing a culturе as еmphasisеd in thе rеport.",
        "keywords": "",
        "link": "http://dx.doi.org/10.24818/mer/2024.01-05"
    },
    {
        "id": 775,
        "title": "Leveraging Machine Learning to Develop Digital Engagement Phenotypes of Users in a Digital Diabetes Prevention Program: Evaluation Study",
        "authors": "Danissa V Rodriguez, Ji Chen, Ratnalekha V N Viswanadham, Katharine Lawrence, Devin Mann",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "\nBackground\nDigital diabetes prevention programs (dDPPs) are effective “digital prescriptions” but have high attrition rates and program noncompletion. To address this, we developed a personalized automatic messaging system (PAMS) that leverages SMS text messaging and data integration into clinical workflows to increase dDPP engagement via enhanced patient-provider communication. Preliminary data showed positive results. However, further investigation is needed to determine how to optimize the tailoring of support technology such as PAMS based on a user’s preferences to boost their dDPP engagement.\n\n\nObjective\nThis study evaluates leveraging machine learning (ML) to develop digital engagement phenotypes of dDPP users and assess ML’s accuracy in predicting engagement with dDPP activities. This research will be used in a PAMS optimization process to improve PAMS personalization by incorporating engagement prediction and digital phenotyping. This study aims (1) to prove the feasibility of using dDPP user-collected data to build an ML model that predicts engagement and contributes to identifying digital engagement phenotypes, (2) to describe methods for developing ML models with dDPP data sets and present preliminary results, and (3) to present preliminary data on user profiling based on ML model outputs.\n\n\nMethods\nUsing the gradient-boosted forest model, we predicted engagement in 4 dDPP individual activities (physical activity, lessons, social activity, and weigh-ins) and general activity (engagement in any activity) based on previous short- and long-term activity in the app. The area under the receiver operating characteristic curve, the area under the precision-recall curve, and the Brier score metrics determined the performance of the model. Shapley values reflected the feature importance of the models and determined what variables informed user profiling through latent profile analysis.\n\n\nResults\nWe developed 2 models using weekly and daily DPP data sets (328,821 and 704,242 records, respectively), which yielded predictive accuracies above 90%. Although both models were highly accurate, the daily model better fitted our research plan because it predicted daily changes in individual activities, which was crucial for creating the “digital phenotypes.” To better understand the variables contributing to the model predictor, we calculated the Shapley values for both models to identify the features with the highest contribution to model fit; engagement with any activity in the dDPP in the last 7 days had the most predictive power. We profiled users with latent profile analysis after 2 weeks of engagement (Bayesian information criterion=−3222.46) with the dDPP and identified 6 profiles of users, including those with high engagement, minimal engagement, and attrition.\n\n\nConclusions\nPreliminary results demonstrate that applying ML methods with predicting power is an acceptable mechanism to tailor and optimize messaging interventions to support patient engagement and adherence to digital prescriptions. The results enable future optimization of our existing messaging platform and expansion of this methodology to other clinical domains.\n\n\nTrial Registration\nClinicalTrials.gov NCT04773834; https://www.clinicaltrials.gov/ct2/show/NCT04773834\n\n\nInternational Registered Report Identifier (IRRID)\nRR2-10.2196/26750\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.2196/47122"
    },
    {
        "id": 776,
        "title": "Large language models: a new chapter in digital health",
        "authors": " The Lancet Digital Health",
        "published": "2024-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00254-6"
    },
    {
        "id": 777,
        "title": "Responsible Artificial Intelligence (AI) for Digital Health and Medical Analytics",
        "authors": "Uthayasankar Sivarajah, Yichuan Wang, Hossein Olya, Sherin Mathew",
        "published": "2023-12",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10796-023-10412-7"
    },
    {
        "id": 778,
        "title": "Types of Digital Mindfulness: Improving Mental Health Among College Students – A Scoping Review",
        "authors": "Iyus Yosep, Suryani Suryani, Henny Mediani, Ai Mardhiyah, Kusman Ibrahim",
        "published": "2024-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2147/jmdh.s443781"
    },
    {
        "id": 779,
        "title": "Decolonising health data",
        "authors": " The Lancet Digital Health",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00132-2"
    },
    {
        "id": 780,
        "title": "Music in the digital age: commodity, community, communion",
        "authors": "Ian Cross",
        "published": "2023-12",
        "citations": 1,
        "abstract": "AbstractDigital systems are reshaping how we engage with music as a sounding dimension of cultural life that is capable of being transformed into a commodity. At the same time, as we increasingly engage through digital media with each other and with virtual others, attributes of music that underpin our capacity to interact communicatively are disregarded or overlooked within those media. Even before the advent of technologies of music reproduction, music was susceptible to assimilation into economic acts of exchange. What is new in the digital world is the way in which modes of engagement with music are themselves being absorbed into an economy built on the datafication of virtual acts and the digital shadows of casual preferences. But music is more than just sounds that are culturally sanctioned as musical. Music is manifested as behaviours, and in interactive behaviour. Music is participatory as well as presentational, and in the participatory mode—involving collective, non-specialist, interactive real-time music-making—has significant individual and social consequences. Yet music as real-time participation is largely absent from the virtual world, with potential social costs that remain to be understood. Moreover, our everyday, face-to-face communicative—conversational—interactions are imbued with patterns between interlocutors that are musical, in that they share features with what we are happy to describe as “music”. These features are presently lacking in digital systems designed to subserve communicative functions, and this paper will consider the significant implications for our interactions with machines to which their successful incorporation into voice–user interfaces would give rise.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01670-9"
    },
    {
        "id": 781,
        "title": "Diverse patients’ attitudes towards Artificial Intelligence (AI) in diagnosis",
        "authors": "Christopher Robertson, Andrew Woods, Kelly Bergstrand, Jess Findley, Cayley Balser, Marvin J. Slepian",
        "published": "2023-5-19",
        "citations": 10,
        "abstract": "Artificial intelligence (AI) has the potential to improve diagnostic accuracy. Yet people are often reluctant to trust automated systems, and some patient populations may be particularly distrusting. We sought to determine how diverse patient populations feel about the use of AI diagnostic tools, and whether framing and informing the choice affects uptake. To construct and pretest our materials, we conducted structured interviews with a diverse set of actual patients. We then conducted a pre-registered (osf.io/9y26x), randomized, blinded survey experiment in factorial design. A survey firm provided n = 2675 responses, oversampling minoritized populations. Clinical vignettes were randomly manipulated in eight variables with two levels each: disease severity (leukemia versus sleep apnea), whether AI is proven more accurate than human specialists, whether the AI clinic is personalized to the patient through listening and/or tailoring, whether the AI clinic avoids racial and/or financial biases, whether the Primary Care Physician (PCP) promises to explain and incorporate the advice, and whether the PCP nudges the patient towards AI as the established, recommended, and easy choice. Our main outcome measure was selection of AI clinic or human physician specialist clinic (binary, “AI uptake”). We found that with weighting representative to the U.S. population, respondents were almost evenly split (52.9% chose human doctor and 47.1% chose AI clinic). In unweighted experimental contrasts of respondents who met pre-registered criteria for engagement, a PCP’s explanation that AI has proven superior accuracy increased uptake (OR = 1.48, CI 1.24–1.77, p < .001), as did a PCP’s nudge towards AI as the established choice (OR = 1.25, CI: 1.05–1.50, p = .013), as did reassurance that the AI clinic had trained counselors to listen to the patient’s unique perspectives (OR = 1.27, CI: 1.07–1.52, p = .008). Disease severity (leukemia versus sleep apnea) and other manipulations did not affect AI uptake significantly. Compared to White respondents, Black respondents selected AI less often (OR = .73, CI: .55-.96, p = .023) and Native Americans selected it more often (OR: 1.37, CI: 1.01–1.87, p = .041). Older respondents were less likely to choose AI (OR: .99, CI: .987-.999, p = .03), as were those who identified as politically conservative (OR: .65, CI: .52-.81, p < .001) or viewed religion as important (OR: .64, CI: .52-.77, p < .001). For each unit increase in education, the odds are 1.10 greater for selecting an AI provider (OR: 1.10, CI: 1.03–1.18, p = .004). While many patients appear resistant to the use of AI, accuracy information, nudges and a listening patient experience may help increase acceptance. To ensure that the benefits of AI are secured in clinical practice, future research on best methods of physician incorporation and patient decision making is required.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1371/journal.pdig.0000237"
    },
    {
        "id": 782,
        "title": "The Environmental Impacts of AI and Digital Technologies",
        "authors": "Sepehr Khajeh Naeeni, Nilofar Nouhi",
        "published": "2023",
        "citations": 0,
        "abstract": "This study aims to investigate the environmental impacts of AI and digital technologies, identify potential mitigation strategies, and assess the role of policy, regulation, and public awareness in fostering sustainable practices within this domain. Employing a qualitative research methodology, this study collected data through semi-structured interviews with 27 professionals across the technology sector, environmental research, policy-making, and academia. Thematic analysis was used to analyze the interview transcripts, allowing for the identification of main themes and categories related to the environmental impacts of AI and digital technologies and the exploration of potential mitigation strategies. Five main themes emerged from the analysis: Direct Environmental Impact, Mitigation Strategies, Technological Innovations, Policy and Regulation, and Public Awareness and Engagement. Each theme encompasses various categories and concepts, such as Energy Consumption, E-Waste, Renewable Energy Adoption, Sustainable Design, Energy-Efficient Hardware, Legislation and Standards, Educational Campaigns, and Digital Literacy. The findings highlight the complex and multifaceted nature of AI and digital technologies' environmental impacts, along with the crucial role of innovative mitigation strategies and comprehensive policy frameworks in addressing these challenges. The study concludes that while AI and digital technologies offer tremendous potential for advancing sustainable development, their deployment must be carefully managed to minimize negative environmental impacts. It underscores the importance of integrating sustainability considerations into the development and deployment of these technologies, alongside fostering robust policy and regulatory frameworks and enhancing public awareness and engagement to achieve a sustainable digital future.",
        "keywords": "",
        "link": "http://dx.doi.org/10.61838/kman.aitech.1.4.3"
    },
    {
        "id": 783,
        "title": "Explainable AI (XAI) for AI-Acceptability: The Coming Age of Digital Management 5.0",
        "authors": "Samia Chehbi Gamoura",
        "published": "2023-10-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icnsc58704.2023.10319030"
    },
    {
        "id": 784,
        "title": "The clinician-AI interface: intended use and explainability in FDA-cleared AI devices for medical image interpretation",
        "authors": "Stephanie L. McNamara, Paul H. Yi, William Lotter",
        "published": "2024-3-26",
        "citations": 0,
        "abstract": "AbstractAs applications of AI in medicine continue to expand, there is an increasing focus on integration into clinical practice. An underappreciated aspect of this clinical translation is where the AI fits into the clinical workflow, and in turn, the outputs generated by the AI to facilitate clinician interaction in this workflow. For instance, in the canonical use case of AI for medical image interpretation, the AI could prioritize cases before clinician review or even autonomously interpret the images without clinician review. A related aspect is explainability – does the AI generate outputs to help explain its predictions to clinicians? While many clinical AI workflows and explainability techniques have been proposed, a summative assessment of the current scope in clinical practice is lacking. Here, we evaluate the current state of FDA-cleared AI devices for medical image interpretation assistance in terms of intended clinical use, outputs generated, and types of explainability offered. We create a curated database focused on these aspects of the clinician-AI interface, where we find a high frequency of “triage” devices, notable variability in output characteristics across products, and often limited explainability of AI predictions. Altogether, we aim to increase transparency of the current landscape of the clinician-AI interface and highlight the need to rigorously assess which strategies ultimately lead to the best clinical outcomes.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41746-024-01080-1"
    },
    {
        "id": 785,
        "title": "MT46 Implementation of Cost-Consequences Analysis As an Economic Evaluation Method for Artificial Intelligent (AI) Medical and Digital Technologies. the Case of Hosmartai (HORIZON 2020 FUNDED)",
        "authors": "M. Hatzikou, D. Latsou",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jval.2023.09.2274"
    },
    {
        "id": 786,
        "title": "Implementing quality management systems to close the AI translation gap and facilitate safe, ethical, and effective health AI solutions",
        "authors": "Shauna M. Overgaard, Megan G. Graham, Tracey Brereton, Michael J. Pencina, John D. Halamka, David E. Vidal, Nicoleta J. Economou-Zavlanos",
        "published": "2023-11-25",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41746-023-00968-8"
    },
    {
        "id": 787,
        "title": "“Threatened and empty selves following AI-based virtual influencers”: comparison between followers and non-followers of virtual influencers in AI-driven digital marketing",
        "authors": "S. Venus Jin, Vijay Viswanathan",
        "published": "2024-1-18",
        "citations": 1,
        "abstract": "AbstractArtificial intelligence (AI)-based virtual influencers are now frequently used by brands in various categories to engage customers. However, little is known about who the followers of these AI-based virtual influencers are and more importantly, what drives the followers to use AI-based virtual influencers. The results from a survey support the notion that compensatory mechanisms and the need to belong play important roles in affecting usage intentions of AI-based virtual influencers. Specifically, the study finds that usage intentions are mediated and moderated by compensatory mechanisms that arise from the perception of AI-based virtual influencers’ functional benefits and existential threats to human identity. Furthermore, the need for belonging moderates the effects of the following status (following versus non-following) on perceived personalization benefits of AI-based virtual influencers and behavioral intentions to use AI-based virtual influencers. This study provides important implications for academia delving into the social, cultural, and philosophical implications of AI-based virtual influencers for human societies as well as for brands that plan to use AI-based virtual influencers and gain a better understanding of their customers in AI-driven digital marketing.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01832-9"
    },
    {
        "id": 788,
        "title": "Community perspectives on AI/ML and health equity: AIM-AHEAD nationwide stakeholder listening sessions",
        "authors": "Jamboor K. Vishwanatha, Allison Christian, Usha Sambamoorthi, Erika L. Thompson, Katie Stinson, Toufeeq Ahmed Syed",
        "published": "2023-6-30",
        "citations": 3,
        "abstract": "Artificial intelligence and machine learning (AI/ML) tools have the potential to improve health equity. However, many historically underrepresented communities have not been engaged in AI/ML training, research, and infrastructure development. Therefore, AIM-AHEAD (Artificial Intelligence/Machine Learning Consortium to Advance Health Equity and Researcher Diversity) seeks to increase participation and engagement of researchers and communities through mutually beneficial partnerships. The purpose of this paper is to summarize feedback from listening sessions conducted by the AIM-AHEAD Coordinating Center in February 2022, titled the “AIM-AHEAD Community Building Convention (ACBC).” A total of six listening sessions were held over three days. A total of 977 people registered with AIM-AHEAD to attend ACBC and 557 individuals attended the listening sessions across stakeholder groups. Facilitators led the conversation based on a series of guiding questions, and responses were captured through voice and chat via the Slido platform. A professional third-party provider transcribed the audio. Qualitative analysis included data from transcripts and chat logs. Thematic analysis was then used to identify common and unique themes across all transcripts. Six main themes arose from the sessions. Attendees felt that storytelling would be a powerful tool in communicating the impact of AI/ML in promoting health equity, trust building is vital and can be fostered through existing trusted relationships, and diverse communities should be involved every step of the way. Attendees shared a wealth of information that will guide AIM-AHEAD’s future activities. The sessions highlighted the need for researchers to translate AI/ML concepts into vignettes that are digestible to the larger public, the importance of diversity, and how open-science platforms can be used to encourage multi-disciplinary collaboration. While the sessions confirmed some of the existing barriers in applying AI/ML for health equity, they also offered new insights that were captured in the six themes.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1371/journal.pdig.0000288"
    },
    {
        "id": 789,
        "title": "Wearable health data privacy",
        "authors": " The Lancet Digital Health",
        "published": "2023-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00055-9"
    },
    {
        "id": 790,
        "title": "Mask R-CNN based multiclass segmentation model for endotracheal intubation using video laryngoscope",
        "authors": "Seung Jae Choi, Dae Kon Kim, Byeong Soo Kim, Minwoo Cho, Joo Jeong, You Hwan Jo, Kyoung Jun Song, Yu Jin Kim, Sungwan Kim",
        "published": "2023-1",
        "citations": 2,
        "abstract": "Objective Endotracheal intubation (ETI) is critical to secure the airway in emergent situations. Although artificial intelligence algorithms are frequently used to analyze medical images, their application to evaluating intraoral structures based on images captured during emergent ETI remains limited. The aim of this study is to develop an artificial intelligence model for segmenting structures in the oral cavity using video laryngoscope (VL) images. Methods From 54 VL videos, clinicians manually labeled images that include motion blur, foggy vision, blood, mucus, and vomitus. Anatomical structures of interest included the tongue, epiglottis, vocal cord, and corniculate cartilage. EfficientNet-B5 with DeepLabv3+, EffecientNet-B5 with U-Net, and Configured Mask R-Convolution Neural Network (CNN) were used; EffecientNet-B5 was pretrained on ImageNet. Dice similarity coefficient (DSC) was used to measure the segmentation performance of the model. Accuracy, recall, specificity, and F1 score were used to evaluate the model's performance in targeting the structure from the value of the intersection over union between the ground truth and prediction mask. Results The DSC of tongue, epiglottis, vocal cord, and corniculate cartilage obtained from the EfficientNet-B5 with DeepLabv3+, EfficientNet-B5 with U-Net, and Configured Mask R-CNN model were 0.3351/0.7675/0.766/0.6539, 0.0/0.7581/0.7395/0.6906, and 0.1167/0.7677/0.7207/0.57, respectively. Furthermore, the processing speeds (frames per second) of the three models stood at 3, 24, and 32, respectively. Conclusions The algorithm developed in this study can assist medical providers performing ETI in emergent situations. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1177/20552076231211547"
    },
    {
        "id": 791,
        "title": "S11: Digital Health and Artificial Intelligence (AI) in Psychogeriatrics: Opening Multiple Frontiers",
        "authors": "Ipsit Vahia, Ana F. Trueba, Kreshnik Hoti, Bettina Husebø",
        "published": "2023-12",
        "citations": 0,
        "abstract": "Symposium OverviewOverall Abstract:The past decade has seen an explosion in the growth of technologies in mental health. Particularly, the scaled adoption of virtual care catalyzed by the COVID-19 pandemic has opened up new frontiers in how digital tools can be incorporated into psychiatry. No area of mental health care is as ripe for digital innovation as psychogeriatrics. In this session, an international group of clinicians and researchers will demonstrate how digital health in psychogeriatrics represents multiple cutting edges of innovation.Our symposium will include 4 presentations, that represent original research from the USA, Ecuador, Norway, Kosovo and Australia. We will highlight clinical applications of these digital tools and aligned issues such as improved care access in low- and middle-income countries, the ethics of digital data collection and the potential for creating new liabilities.We will focus on four distinct technologies and applications. Dr. Ipsit Vahia will discuss passive environmental sensing supported by signal processing and artificial intelligence (AI) in guiding treatment decision making, especially in dementia care. His presentation will include discussions on how AI can be incorporated into care while also preserving autonomy. Dr. Kreshnik Hoti will discuss the application of AI on voice-based signals to determine changes in pain levels and psychopathology. His presentation will include research conducted in collaboration between teams based in Australia and Kosovo and through a public-private partnership with a digital health startup. Dr. Ana Trueba will focus on digital interventions, specifically virtual reality (VR). She will present data from two studies, one from McLean hospital In the US, and the other from Ecuador that explore how VR can deliver evidence-based non-pharmacologic interventions. Dr. Bettina Husebø will present data from a project she oversees in Norway. Her talk will discuss how care in nursing homes can be improved by incorporating a range of digital approaches into nursing home care paradigms. A particular focus will be on the relationship between pain and behavior symptoms and dementia among nursing home dwelling older adults.Thus, the symposium will address diagnostics, treatment and systems level care and how New technologies are shaping the evolution of psychogeriatrics worldwide.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1017/s104161022300203x"
    },
    {
        "id": 792,
        "title": "Informing antimicrobial stewardship with explainable AI",
        "authors": "Massimo Cavallaro, Ed Moran, Benjamin Collyer, Noel D. McCarthy, Christopher Green, Matt J. Keeling",
        "published": "2023-1-5",
        "citations": 6,
        "abstract": "The accuracy and flexibility of artificial intelligence (AI) systems often comes at the cost of a decreased ability to offer an intuitive explanation of their predictions. This hinders trust and discourage adoption of AI in healthcare, exacerbated by concerns over liabilities and risks to patients’ health in case of misdiagnosis. Providing an explanation for a model’s prediction is possible due to recent advances in the field of interpretable machine learning. We considered a data set of hospital admissions linked to records of antibiotic prescriptions and susceptibilities of bacterial isolates. An appropriately trained gradient boosted decision tree algorithm, supplemented by a Shapley explanation model, predicts the likely antimicrobial drug resistance, with the odds of resistance informed by characteristics of the patient, admission data, and historical drug treatments and culture test results. Applying this AI-based system, we found that it substantially reduces the risk of mismatched treatment compared with the observed prescriptions. The Shapley values provide an intuitive association between observations/data and outcomes; the associations identified are broadly consistent with expectations based on prior knowledge from health specialists. The results, and the ability to attribute confidence and explanations, support the wider adoption of AI in healthcare.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1371/journal.pdig.0000162"
    },
    {
        "id": 793,
        "title": "AImedReport: A Prototype Tool to Facilitate Research Reporting and Translation of AI Technologies in Health Care",
        "authors": "Tracey A. Brereton, Momin M. Malik, Lauren M. Rost, Joshua W. Ohde, Lu Zheng, Kristelle A. Jose, Kevin J. Peterson, David Vidal, Mark A. Lifson, Joe Melnick, Bryce Flor, Jason D. Greenwood, Kyle Fisher, Shauna M. Overgaard",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mcpdig.2024.03.008"
    },
    {
        "id": 794,
        "title": "Digital therapy for depression in multiple sclerosis",
        "authors": " The Lancet Digital Health",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00182-6"
    },
    {
        "id": 795,
        "title": "Digital solutions for early breast cancer detection",
        "authors": " The Lancet Digital Health",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00159-0"
    },
    {
        "id": 796,
        "title": "Twitter, public health, and misinformation",
        "authors": " The Lancet Digital Health",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(23)00096-1"
    },
    {
        "id": 797,
        "title": "Epigenome-wide association analysis of infant bronchiolitis severity: a multicenter prospective cohort study",
        "authors": "Zhaozhong Zhu, Yijun Li, Robert J. Freishtat, Juan C. Celedón, Janice A. Espinola, Brennan Harmon, Andrea Hahn, Carlos A. Camargo, Liming Liang, Kohei Hasegawa",
        "published": "2023-9-7",
        "citations": 5,
        "abstract": "AbstractBronchiolitis is the most common lower respiratory infection in infants, yet its pathobiology remains unclear. Here we present blood DNA methylation data from 625 infants hospitalized with bronchiolitis in a 17-center prospective study, and associate them with disease severity. We investigate differentially methylated CpGs (DMCs) for disease severity. We characterize the DMCs based on their association with cell and tissues types, biological pathways, and gene expression. Lastly, we also examine the relationships of severity-related DMCs with respiratory and immune traits in independent cohorts. We identify 33 DMCs associated with severity. These DMCs are differentially methylated in blood immune cells. These DMCs are also significantly enriched in multiple tissues (e.g., lung) and cells (e.g., small airway epithelial cells), and biological pathways (e.g., interleukin-1-mediated signaling). Additionally, these DMCs are associated with respiratory and immune traits (e.g., asthma, lung function, IgE levels). Our study suggests the role of DNA methylation in bronchiolitis severity.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41467-023-41300-y"
    },
    {
        "id": 798,
        "title": "AI Living Lab: Quality Assurance for AI-based Health systems",
        "authors": "Valentina Lenarduzzi, Minna Isomursu",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cain58948.2023.00018"
    },
    {
        "id": 799,
        "title": "Digital transformation of ovarian cancer diagnosis and care",
        "authors": " The Lancet Digital Health",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s2589-7500(24)00027-x"
    },
    {
        "id": 800,
        "title": "AI-Based and Digital Mental Health Apps: Balancing Need and Risk",
        "authors": "Salah Hamdoun, Rebecca Monteleone, Terri Bookman, Katina Michael",
        "published": "2023-3",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mts.2023.3241309"
    }
]