[
    {
        "id": 4105,
        "title": "Fading memory as inductive bias in residual recurrent networks",
        "authors": "Igor Dubinin, Felix Effenberger",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2024.106179"
    },
    {
        "id": 4106,
        "title": "Two-timescale recurrent neural networks for distributed minimax optimization",
        "authors": "Zicong Xia, Yang Liu, Jiasen Wang, Jun Wang",
        "published": "2023-8",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.06.003"
    },
    {
        "id": 4107,
        "title": "Spatial–temporal recurrent reinforcement learning for autonomous ships",
        "authors": "Martin Waltz, Ostap Okhrin",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.06.015"
    },
    {
        "id": 4108,
        "title": "DyVGRNN: DYnamic mixture Variational Graph Recurrent Neural Networks",
        "authors": "Ghazaleh Niknam, Soheila Molaei, Hadi Zare, Shirui Pan, Mahdi Jalili, Tingting Zhu, David Clifton",
        "published": "2023-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.05.048"
    },
    {
        "id": 4109,
        "title": "User Re-Authentication via Mouse Movements and Recurrent Neural Networks",
        "authors": "Paul Houssel, Luis Leiva",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012296600003648"
    },
    {
        "id": 4110,
        "title": "Novel criteria of sampled-data synchronization controller design for gated recurrent unit neural networks under mismatched parameters",
        "authors": "Seungyong Han, Suneel Kumar Kommuri, Yongsik Jin",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.12.035"
    },
    {
        "id": 4111,
        "title": "Explainability Insights to Cellular Simultaneous Recurrent Neural Networks for Classical Planning",
        "authors": "Michaela Urbanovská, Antonín Komenda",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012375800003636"
    },
    {
        "id": 4112,
        "title": "Warming up recurrent neural networks to maximise reachable multistability greatly improves learning",
        "authors": "Gaspard Lambrechts, Florent De Geeter, Nicolas Vecoven, Damien Ernst, Guillaume Drion",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.07.023"
    },
    {
        "id": 4113,
        "title": "Time series prediction and anomaly detection with recurrent spiking neural networks",
        "authors": "Yann Cherdo, Benoit Miramond, Alain Pegatoquet",
        "published": "2023-6-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191614"
    },
    {
        "id": 4114,
        "title": "Generalisation of Feed-Forward Neural Networks and  Recurrent Neural Networks",
        "authors": "Rui Wang",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "This paper presents an in-depth analysis of Feed-Forward Neural Networks (FNNs) and Recurrent Neural Networks (RNNs), two powerful models in the field of artificial intelligence. Understanding these models and their applications is crucial for harnessing their potential. The study addresses the need to comprehend the unique characteristics and architectures of FNNs and RNNs. These models excel at processing sequential and temporal data, making them indispensable in tasks. Furthermore, the paper emphasises the importance of variables in FNNs and proposes a novel method to rank the importance of independent variables in predicting the output variable. By understanding the relationship between inputs and outputs, valuable insights can be gained into the underlying patterns and mechanisms driving the system being modelled. Additionally, the research explores the impact of initial weights on model performance. Contrary to conventional beliefs, the study provides evidence that neural networks with random weights can achieve competitive performance, particularly in situations with limited training datasets. This finding challenges the traditional notion that careful initialization is necessary for neural networks to perform well. In summary, this paper provides a comprehensive analysis of FNNs and RNNs while highlighting the importance of understanding the relationship between variables and the impact of initial weights on model performance. By shedding light on these crucial aspects, this research contributes to the advancement and effective utilisation of neural networks, paving the way for improved predictions and insights in various domains.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/40/20230659"
    },
    {
        "id": 4115,
        "title": "Quantum recurrent neural networks for sequential learning",
        "authors": "Yanan Li, Zhimin Wang, Rongbing Han, Shangshang Shi, Jiaxin Li, Ruimin Shang, Haiyong Zheng, Guoqiang Zhong, Yongjian Gu",
        "published": "2023-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.07.003"
    },
    {
        "id": 4116,
        "title": "Cascade Prediction with Recurrent Neural Networks and Diffusion Depth Distributions",
        "authors": "Shao Huang, Wangyang Yu",
        "published": "2023-2-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nnice58320.2023.10105676"
    },
    {
        "id": 4117,
        "title": "Dynamic Analysis and an Eigen Initializer for Recurrent Neural Networks",
        "authors": "Ran Dou, Jose Principe",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191986"
    },
    {
        "id": 4118,
        "title": "Sentiment Analysis With Lipschitz Recurrent Neural Networks",
        "authors": "Mahmudul Hasan, Sachin Shetty",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isncc58260.2023.10323619"
    },
    {
        "id": 4119,
        "title": "DRRNets: Dynamic Recurrent Routing via Low-Rank Regularization in Recurrent Neural Networks",
        "authors": "Dongjing Shan, Yong Luo, Xiongwei Zhang, Chao Zhang",
        "published": "2023-4",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2021.3105818"
    },
    {
        "id": 4120,
        "title": "Traffic forecasting with graph spatial–temporal position recurrent network",
        "authors": "Yibi Chen, Kenli Li, Chai Kiat Yeo, Keqin Li",
        "published": "2023-5",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.03.009"
    },
    {
        "id": 4121,
        "title": "Modeling Batch Tasks Using Recurrent Neural Networks in Co-Located Alibaba Workloads",
        "authors": "Hifza Khalid, Arunselvan Ramaswamy, Simone Ferlin, Alva Couch",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012392700003654"
    },
    {
        "id": 4122,
        "title": "Different Types of Neural Networks and Applications: Evidence from Feedforward, Convolutional and Recurrent Neural Networks",
        "authors": "Yumin Pan",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "Neural networks have achieved great process in the 90 years since they were officially introduced in 1943. Because of its wide application and huge research and development potential, this technology attracts more and more scientific and technological workers to the research of neural networks. Neural network technology is an essential component of AI development, and it is a significant indicator of a country's overall strength. In this paper, this study will demonstrate Feedforward Neural Network, Convolution Neural Network and Recurrent Neural networks and evaluate them through datasets from kaggle.com. and CSDN (China IT community). Through this paper, readers can have a better outlook and understanding of the operating principles of each type of neural network as well as their specific jobs (what kind of jobs they specialized in) and each application of these neural networks. So that this paper can promote readers' thoughts and help them start learning neural networks or be a supplement or reference for future scholars. In the end, this paper will present the outcome, which is the evaluation of the accuracy, loss curve, and accuracy curve of neural networks.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/6rn1wd81"
    },
    {
        "id": 4123,
        "title": "Exploring crude oil price movements as a complex time series using recurrent neural networks",
        "authors": "Rida El Abassi, Mohamed Oubraime, Jaafar Idrais, Abderrahim Sabour",
        "published": "2023-5-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3607720.3607731"
    },
    {
        "id": 4124,
        "title": "Least Redundant Gated Recurrent Neural Network",
        "authors": "Łukasz Neumann, Łukasz Lepak, Paweł Wawrzyński",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191895"
    },
    {
        "id": 4125,
        "title": "RECURRENT QUANTUM NEURAL NETWORKS: A REVIEW",
        "authors": "Gleydson Fernandes de Jesus, Valéria Loureiro da Silva",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5151/siintec2023-306159"
    },
    {
        "id": 4126,
        "title": "Predicting Opinions in Social Networks Using Recurrent Neural Networks",
        "authors": "Mohamed N. Zareer, Rastko R. Selmic",
        "published": "2023-6-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/med59994.2023.10185814"
    },
    {
        "id": 4127,
        "title": "An Inexact Sequential Quadratic Programming Method for Learning and Control of Recurrent Neural Networks",
        "authors": "Adeyemi D. Adeoye, Alberto Bemporad",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2024.3354855"
    },
    {
        "id": 4128,
        "title": "Continual learning with attentive recurrent neural networks for temporal data classification",
        "authors": "Shao-Yu Yin, Yu Huang, Tien-Yu Chang, Shih-Fang Chang, Vincent S. Tseng",
        "published": "2023-1",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2022.10.031"
    },
    {
        "id": 4129,
        "title": "Ensemble Recurrent Graph Neural Networks for Availability Prediction in Cellular Networks",
        "authors": "Ming-Yen Wu",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ickii58656.2023.10332614"
    },
    {
        "id": 4130,
        "title": "Fog-cloud based intrusion detection system using Recurrent Neural Networks and feature selection for IoT networks",
        "authors": "Naeem Firdous Syed, Mengmeng Ge, Zubair Baig",
        "published": "2023-4",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.comnet.2023.109662"
    },
    {
        "id": 4131,
        "title": "Semantically Layered Representation for Planning Problems and Its Usage for Heuristic Computation Using Cellular Simultaneous Recurrent Neural Networks",
        "authors": "Michaela Urbanovská, Antonín Komenda",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011691000003393"
    },
    {
        "id": 4132,
        "title": "Design of continuous-time recurrent neural networks with piecewise-linear activation function for generation of prescribed sequences of bipolar vectors",
        "authors": "Norikazu Takahashi, Tsuyoshi Yamakawa, Yasuhiro Minetoma, Tetsuo Nishi, Tsuyoshi Migita",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.05.013"
    },
    {
        "id": 4133,
        "title": "Exploring Neural Network Structure through Sparse Recurrent Neural Networks: A Recasting and Distillation of Neural Network Hyperparameters",
        "authors": "Quincy Hershey, Randy Paffenroth, Harsh Pathak",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00026"
    },
    {
        "id": 4134,
        "title": "Adversarial Attacks with Defense Mechanisms on Convolutional Neural Networks and Recurrent Neural Networks for Malware Classification",
        "authors": "Sharoug Alzaidy, Hamad Binsalleeh",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "In the field of behavioral detection, deep learning has been extensively utilized. For example, deep learning models have been utilized to detect and classify malware. Deep learning, however, has vulnerabilities that can be exploited with crafted inputs, resulting in malicious files being misclassified. Cyber-Physical Systems (CPS) may be compromised by malicious files, which can have catastrophic consequences. This paper presents a method for classifying Windows portable executables (PEs) using Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs). To generate malware executable adversarial examples of PE, we conduct two white-box attacks, Jacobian-based Saliency Map Attack (JSMA) and Carlini and Wagner attack (C&W). An adversarial payload was injected into the DOS header, and a section was added to the file to preserve the PE functionality. The attacks successfully evaded the CNN model with a 91% evasion rate, whereas the RNN model evaded attacks at an 84.6% rate. Two defense mechanisms based on distillation and training techniques are examined in this study for overcoming adversarial example challenges. Distillation and training against JSMA resulted in the highest reductions in the evasion rates of 48.1% and 41.49%, respectively. Distillation and training against C&W resulted in the highest decrease in evasion rates, at 48.1% and 49.9%, respectively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app14041673"
    },
    {
        "id": 4135,
        "title": "Differentiating brain states via multi-clip random fragment strategy-based interactive bidirectional recurrent neural network",
        "authors": "Shu Zhang, Enze Shi, Lin Wu, Ruoyang Wang, Sigang Yu, Zhengliang Liu, Shaochen Xu, Tianming Liu, Shijie Zhao",
        "published": "2023-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.06.040"
    },
    {
        "id": 4136,
        "title": "Next Word Prediction using Recurrent Neural Networks",
        "authors": "",
        "published": "2023-11-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.58257/ijprems32232"
    },
    {
        "id": 4137,
        "title": "Image Captioning System Using Merge Conventional and Recurrent Neural Networks",
        "authors": "Rasha Talib Gdeeb",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "Image captioning system is that operation where we create a group of captions defines the image content and depends specially on deep learning. This technology is used for a wide range in recent time because it can help as example the blind people by telling them about all the objects around them which Nvidia company has the lead of it. Many searches were done in this subject and may be the most important one that search done by Andrej Karpathy leader of artificial intelligent in Tesla company depending on Flicker database which gives a special result used by next researches. ICS (Image Captioning Systems) are end-to-end Sequence-to-Sequence systems where we can convert a series of image pixels descriptions into a series of words. For images objects recognition we can use conventional neural networks (CNN) and for the words recognition and text build we will use recurrent neural network",
        "keywords": "",
        "link": "http://dx.doi.org/10.47832/minarcongress9-17"
    },
    {
        "id": 4138,
        "title": "DESIGN AND DEVELOPMENT OF EFFICIENT WATER QUALITY PREDICTION MODELS USING VARIANTS OF RECURRENT NEURAL NETWORKS",
        "authors": "",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.48047/ecb/2023.12.si5.0143"
    },
    {
        "id": 4139,
        "title": "Soil Nutrient Evaluation System Based on Improved Recurrent Neural Network",
        "authors": "Yingbo Bu, Xinjie Yu, Yao Yang",
        "published": "2023-2-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nnice58320.2023.10105705"
    },
    {
        "id": 4140,
        "title": "SGORNN: Combining scalar gates and orthogonal constraints in recurrent networks",
        "authors": "Will Taylor-Melanson, Martha Dais Ferreira, Stan Matwin",
        "published": "2023-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2022.11.028"
    },
    {
        "id": 4141,
        "title": "Exploring a Basis Set of Intrinsic Functions Underlying Neural Computation by Symbolically Programming Recurrent Neural Networks.",
        "authors": "Daniel Calbick, Ilker Yildirim, Jason Kim",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32470/ccn.2023.1692-0"
    },
    {
        "id": 4142,
        "title": "Integrating Explicit Contexts with Recurrent Neural Networks for Improving Prognostic Models",
        "authors": "Rashmi Dutta Baruah, Mario Muñoz Organero",
        "published": "2023-3-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aero55745.2023.10115751"
    },
    {
        "id": 4143,
        "title": "A direct discretization recurrent neurodynamics method for time-variant nonlinear optimization with redundant robot manipulators",
        "authors": "Yang Shi, Wangrong Sheng, Shuai Li, Bin Li, Xiaobing Sun, Dimitrios K. Gerontitis",
        "published": "2023-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.04.040"
    },
    {
        "id": 4144,
        "title": "ENHANCING SEQUENCE LEARNING WITH MASKING IN RECURRENT NEURAL NETWORKS",
        "authors": "",
        "published": "2024-1-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets48489"
    },
    {
        "id": 4145,
        "title": "Characterising representation dynamics in recurrent neural networks for object recognition",
        "authors": "Sushrut Thorat, Adrien Doerig, Tim Kietzmann",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32470/ccn.2023.1088-0"
    },
    {
        "id": 4146,
        "title": "Advancing Recurrent Neural Networks and Generative Adversarial Networks: A Technical Framework for Enhanced Effectiveness Evaluation",
        "authors": "Xia Yu",
        "published": "2023-9-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciscae59047.2023.10393296"
    },
    {
        "id": 4147,
        "title": "Stability and Limit Cycles of Fuzzy Inferences in a Recurrent Petri-like Neural Network",
        "authors": "Lidia Ghosh, Dipanjan Konar, Amit Konar, Atulya K. Nagar",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191279"
    },
    {
        "id": 4148,
        "title": "Recurrent Neural Networks With More Flexible Memory: Better Predictions Than Rough Volatility",
        "authors": "Damien Challet, Vincent Ragel",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4514331"
    },
    {
        "id": 4149,
        "title": "Recurrent Neural Networks for Forecasting Social Processes",
        "authors": "Angelin Lalev, Alexandrina Alexandrova",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bdkcse59280.2023.10339767"
    },
    {
        "id": 4150,
        "title": "Trajectory-Based State-of-Charge Prediction Using LSTM Recurrent Neural Networks",
        "authors": "Adan Ernesto Vela",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dasc58513.2023.10311254"
    },
    {
        "id": 4151,
        "title": "‘Seeing’ the Future: Improving Macroeconomic Forecasts with Spatial Data Using Recurrent Convolutional Neural Networks",
        "authors": "Jonathan Leslie",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4350048"
    },
    {
        "id": 4152,
        "title": "Load Margin Assessment of Power Systems Using Recurrent Neural Networks",
        "authors": "Murilo E. C. Bento",
        "published": "2023-11-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/induscon58041.2023.10374951"
    },
    {
        "id": 4153,
        "title": "Learning of Cognitive Control during Task Switching in Recurrent Neural Networks",
        "authors": "Shengjie Xu, Tom Verguts, Senne Braem",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32470/ccn.2023.1253-0"
    },
    {
        "id": 4154,
        "title": "Phish-armour: phishing detection using deep recurrent neural networks",
        "authors": "P. Dhanavanthini, S. Sibi Chakkravarthy",
        "published": "2023-3-27",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00500-023-07962-y"
    },
    {
        "id": 4155,
        "title": "Retracted: Note Detection in Music Teaching Based on Intelligent Bidirectional Recurrent Neural Network",
        "authors": "",
        "published": "2023-8-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9850239"
    },
    {
        "id": 4156,
        "title": "Emotion Recognition in Reddit Comments Using Recurrent Neural\nNetworks",
        "authors": "Mahdi Rezapour",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "\nBackground:\nReddit comments are a valuable source of natural language data\nwhere emotion plays a key role in human communication. However, emotion recognition is a\ndifficult task that requires understanding the context and sentiment of the texts. In this paper,\nwe aim to compare the effectiveness of four recurrent neural network (RNN) models for classifying the emotions of Reddit comments.\n\n\nMethods:\nWe use a small dataset of 4,922 comments labeled with four emotions: approval,\ndisapproval, love, and annoyance. We also use pre-trained Glove.840B.300d embeddings as\nthe input representation for all models. The models we compare are SimpleRNN, Long ShortTerm Memory (LSTM), bidirectional LSTM, and Gated Recurrent Unit (GRU). We experiment with different text preprocessing steps, such as removing stopwords and applying stemming, removing negation from stopwords, and the effect of setting the embedding layer as\ntrainable on the models.\n\n\nResults:\nWe find that GRU outperforms all other models, achieving an accuracy of 74%. Bidirectional LSTM and LSTM are close behind, while SimpleRNN performs the worst. We observe that the low accuracy is likely due to the presence of sarcasm, irony, and complexity in\nthe texts. We also notice that setting the embedding layer as trainable improves the performance of LSTM but increases the computational cost and training time significantly. We analyze some examples of misclassified texts by GRU and identify the challenges and limitations\nof the dataset and the models\n\n\nConclusion:\nIn our study GRU was found to be the best model for emotion classification of\nReddit comments among the four RNN models we compared. We also discuss some future directions for research to improve the emotion recognition task on Reddit comments. Furthermore, we provide an extensive discussion of the applications and methods behind each technique in the context of the paper.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.2174/0126662558273325231201051141"
    },
    {
        "id": 4157,
        "title": "Memory capacity of recurrent neural networks with matrix representation",
        "authors": "Animesh Renanse, Alok Sharma, Rohitash Chandra",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neucom.2023.126824"
    },
    {
        "id": 4158,
        "title": "Quantifying and Maximizing the Information Flux in Recurrent Neural Networks",
        "authors": "Claus Metzner, Marius E. Yamakou, Dennis Voelkl, Achim Schilling, Patrick Krauss",
        "published": "2024-2-16",
        "citations": 1,
        "abstract": "Abstract\nFree-running recurrent neural networks (RNNs), especially probabilistic models, generate an ongoing information flux that can be quantified with the mutual information I[x→(t),x→(t+1)] between subsequent system states x→. Although previous studies have shown that I depends on the statistics of the network’s connection weights, it is unclear how to maximize I systematically and how to quantify the flux in large systems where computing the mutual information becomes intractable. Here, we address these questions using Boltzmann machines as model systems. We find that in networks with moderately strong connections, the mutual information I is approximately a monotonic transformation of the root-mean-square averaged Pearson correlations between neuron pairs, a quantity that can be efficiently computed even in large systems. Furthermore, evolutionary maximization of I[x→(t),x→(t+1)] reveals a general design principle for the weight matrices enabling the systematic construction of systems with a high spontaneous information flux. Finally, we simultaneously maximize information flux and the mean period length of cyclic attractors in the state-space of these dynamical networks. Our results are potentially useful for the construction of RNNs that serve as short-time memories or pattern generators.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1162/neco_a_01651"
    },
    {
        "id": 4159,
        "title": "Improved Recurrent Neural Networks for Text Classification and Dynamic Sylvester Equation Solving",
        "authors": "Weijie Chen, Jie Jin, Dimitrios Gerontitis, Lixin Qiu, Jingcan Zhu",
        "published": "2023-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-023-11176-6"
    },
    {
        "id": 4160,
        "title": "Motion Prediction Of Traffic Agents With Hybrid Recurrent-Convolutional Neural Networks",
        "authors": "Vasileios Lagoutaris, Konstantinos Moustakas",
        "published": "2023-6-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dsp58604.2023.10167941"
    },
    {
        "id": 4161,
        "title": "Fracture Estimation Based on Deformation History with Recurrent Neural Networks",
        "authors": "Muhammed Adil Yatkin, Mihkel Kõrgesaar",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00152"
    },
    {
        "id": 4162,
        "title": "Algorithm for Mobile Robot Localization Based on Recurrent Convolutional Neural Networks",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18178/wcse.2023.06.029"
    },
    {
        "id": 4163,
        "title": "Prediction of Deep Ice Layer Thickness Using Adaptive Recurrent Graph Neural Networks",
        "authors": "Benjamin Zalatan, Maryam Rahnemoonfar",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10222391"
    },
    {
        "id": 4164,
        "title": "Comparisons of Stock Prediction Methods Based on Recurrent Neural Networks",
        "authors": "George Shao",
        "published": "2023-2-28",
        "citations": 0,
        "abstract": "These instructions give you guidelines for preparing papers for DRP. Use this document as a template if you are using Microsoft Word 6.0 or later. Otherwise, use this document as an instruction set. The electronic file of your paper will be formatted further at DRP. Paper titles should be written in uppercase and lowercase letters, not all uppercase. Avoid writing long formulas with subscripts in the title; short formulas that identify the elements are fine (e.g., \"Nd-Fe-B\"). Do not write “(Invited)” in the title. Full names of authors are preferred in the author field, but are not required. Put a space between authors’ initials. The abstract must be a concise yet comprehensive reflection of what is in your article. In particular, the abstract must be self-contained, without abbreviations, footnotes, or references. It should be a microcosm of the full article. The abstract must be between 100 - 300 words. Be sure that you adhere to these limits; otherwise, you will need to edit your abstract accordingly. The abstract must be written as one paragraph, and should not contain displayed mathematical equations or tabular material. The abstract should include three or four different keywords or phrases, as this will help readers to find it. It is important to avoid over-repetition of such phrases as this can result in a page being rejected by search engines. Ensure that your abstract reads well and is grammatically correct.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v34i.5376"
    },
    {
        "id": 4165,
        "title": "Investigating the Use of Spatial Transformer Networks and Recurrent Neural Networks for Medical Image Segmentation",
        "authors": "Vineet Saxena, M N Nachappa, Ritu Shree",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470837"
    },
    {
        "id": 4166,
        "title": "Universal Recurrent Event Memories for Streaming Data",
        "authors": "Ran Dou, Jose Principe",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191277"
    },
    {
        "id": 4167,
        "title": "A Combined Model Based on Recurrent Neural Networks and Graph Convolutional Networks for Financial Time Series Forecasting",
        "authors": "Ana Lazcano, Pedro Javier Herrera, Manuel Monge",
        "published": "2023-1-2",
        "citations": 22,
        "abstract": "Accurate and real-time forecasting of the price of oil plays an important role in the world economy. Research interest in forecasting this type of time series has increased considerably in recent decades, since, due to the characteristics of the time series, it was a complicated task with inaccurate results. Concretely, deep learning models such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) have appeared in this field with promising results compared to traditional approaches. To improve the performance of existing networks in time series forecasting, in this work two types of neural networks are brought together, combining the characteristics of a Graph Convolutional Network (GCN) and a Bidirectional Long Short-Term Memory (BiLSTM) network. This is a novel evolution that improves existing results in the literature and provides new possibilities in the analysis of time series. The results confirm a better performance of the combined BiLSTM-GCN approach compared to the BiLSTM and GCN models separately, as well as to the traditional models, with a lower error in all the error metrics used: the Root Mean Squared Error (RMSE), the Mean Squared Error (MSE), the Mean Absolute Percentage Error (MAPE) and the R-squared (R2). These results represent a smaller difference between the result returned by the model and the real value and, therefore, a greater precision in the predictions of this model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math11010224"
    },
    {
        "id": 4168,
        "title": "Convolutional Recurrent Neural Networks for Medical Image Recognition",
        "authors": "Pankaj Saraswat, Rohaila Naaz, Kavitha R",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470932"
    },
    {
        "id": 4169,
        "title": "Artificial intelligence-based Medicine Recognition System using faster Recurrent Convolutional Neural Networks",
        "authors": "P.Ranjith Kumar, Tarun Jaiswal, Satyabrata Jena",
        "published": "2023",
        "citations": 0,
        "abstract": "Recently, chronic patients are taking multiple medications incorrectly and taking the wrong medications due to similarity of drugs.It is possible that taking the improper medication can result in hazardous interactions with other medications or they will counteract the intended benefits of the medications, resulting in extra severe repercussions such as acute complications. The conventional methods are failed to provide the maximum efficiency. Therefore, this article is focused on implementation of faster recurrent convolutional neural networks (FR-CNN), which is capable of extracting the features from images. FR-CNN mainly used to analyze the patterns of the medicines and extracts the deep features. Further, classification of medicines is carried out by comparing with ground truth labels. The simulation results shows that the proposed system resulted in superior performance as compared to state of art approaches.",
        "keywords": "",
        "link": "http://dx.doi.org/10.58599/ijsmien.2023.1105"
    },
    {
        "id": 4170,
        "title": "Uncertainty-Aware QoT Forecasting in Optical Networks with Bayesian Recurrent Neural Networks",
        "authors": "Nicola Di Cicco, Jacopo Talpini, Mëmëdhe Ibrahimi, Marco Savi, Massimo Tornatore",
        "published": "2023-5-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icc45041.2023.10278767"
    },
    {
        "id": 4171,
        "title": "Performing decision-making tasks through dynamics of recurrent neural networks trained with reinforcement learning",
        "authors": "Roman Kononov, Oleg Maslennikov",
        "published": "2023-9-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dcna59899.2023.10290321"
    },
    {
        "id": 4172,
        "title": "Fraud Detection using Recurrent Neural Networks for Digital Wallet Security",
        "authors": "Can Iscan, Fatma Patlar Akbulut",
        "published": "2023-9-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ubmk59864.2023.10286651"
    },
    {
        "id": 4173,
        "title": "Automating Medical Image Segmentation with Recurrent Neural Networks",
        "authors": "Neeraj Das, Ajay Kumar Upadhyay, Deepak Mehta",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470816"
    },
    {
        "id": 4174,
        "title": "Improving Wind Speed Uncertainty Forecasts Using Recurrent Neural Networks",
        "authors": "Juri Backes, Wolfgang Renz",
        "published": "2023-1-23",
        "citations": 0,
        "abstract": "For integration of growing amounts of volatile renewable energy in the European electricity system, reliable weather prognosis gains importance. But, depending on weather conditions, forecast reliability of wind speed for predicting wind power can vary drastically with time. Thus, relevance of risk-aware system operation strategies is increasing based on wind speed uncertainty a measure of which is provided by the standard deviations of ensemble forecasts of the German Weather Service. However, lacking validity of this measure is known as a long-standing problem.Therefore, this work investigates how machine learning based on a suitably selected set of physical quantities of weather ensemble data as well as historic wind data allows for a more realistic uncertainty quantification. A recurrent neural network (RNN) based sequence-to-sequence architecture is implemented and probabilistic wind speed forecasts are generated for a region in northern Germany.The results are evaluated and compared with the forecasts of the German Weather Service thereby revealing improved validity of such deep-learning based uncertainty measures.",
        "keywords": "",
        "link": "http://dx.doi.org/10.7557/18.6806"
    },
    {
        "id": 4175,
        "title": "Graph Generation with Recurrent and Graph Neural Networks",
        "authors": "Xikun Huang, Yangyang Li, Chaoqun Fei, Chuanqing Wang",
        "published": "2023-11-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/medai59581.2023.00033"
    },
    {
        "id": 4176,
        "title": "Recurrent Neural Networks for Improved Medical Image Classification",
        "authors": "Umesh Kumar Singh, Kavitha R, Pankaj Saraswat",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470908"
    },
    {
        "id": 4177,
        "title": "Reconstructing computational system dynamics from neural data with recurrent neural networks",
        "authors": "Daniel Durstewitz, Georgia Koppe, Max Ingo Thurm",
        "published": "2023-11",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41583-023-00740-7"
    },
    {
        "id": 4178,
        "title": "Recurrent Neural Networks (RNNs) to improve EEG-based person identification",
        "authors": "Youssef Mohamed, Ahmed M. Anter, Ahmed B. Zaky",
        "published": "2023-7-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/imsa58542.2023.10217750"
    },
    {
        "id": 4179,
        "title": "A Comparative Study of Convolutional Neural Networks and Recurrent Neural Networks for Chord Recognition",
        "authors": "Hania Nawaz Khan, Sibghatullah Bazai, Zubair Zaland, Sibghatullah Durrani, Saad Aslam, Angela Amphawan, Fatima Ali, Tse-Kian Neo",
        "published": "2023-9-5",
        "citations": 0,
        "abstract": "Using Mel-spectrograms, this study evaluates the effectiveness of Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNNs). Mel-spectrograms are justified by their non- linearity and similarity to the human hearing system. This study uses over 200 tracks by The Beatles and Queen collected through the Music Information Retrieval Evaluation Exchange. Data augmentation approaches are used to increase accuracy on unusual chords. This paper presents a 3-layer 2D CNN model trained on major and minor chords and then expanded to different types of chords. The dataset demonstrates that both models can recognize musical chords across various genres. We compare the proposed results to the existing literature and demonstrate the effectiveness of the proposed methodology. As a result of our analysis, we found that the CNN and RNN models were 79% and 76% accurate, respectively. The presented findings suggest that CNNs and RNNs are suitable models for chord recognition using Mel-spectrograms. Data augmentation can be an effective technique for improving accuracy on rare chords.",
        "keywords": "",
        "link": "http://dx.doi.org/10.15379/ijmst.v10i2.1837"
    },
    {
        "id": 4180,
        "title": "Combining recurrent and Graph Neural Networks to predict the next place’s category",
        "authors": "Cláudio G.S. Capanema, Guilherme S. de Oliveira, Fabrício A. Silva, Thais R.M.B. Silva, Antonio A.F. Loureiro",
        "published": "2023-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.adhoc.2022.103016"
    },
    {
        "id": 4181,
        "title": "Efficient Extraction and Automated Thyroid Prediction with an Optimized Gated Recurrent Unit in Recurrent Neural Networks",
        "authors": "Et al. Nagavali Saka",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "Computer-aided tools are becoming increasingly important in medical diagnostics. This paper introduces the Efficient Feature Extraction Based Recurrent Neural Network (FERNN) for computer-aided thyroid disease prediction. The FERNN model uses a Gated Recurrent Unit Recurrent Neural Network (GRU-RNN) optimized with the COOT Optimization Algorithm.The study begins by gathering data from an open-source system and preprocessing it using min-max normalization to address missing values. The preprocessed data undergoes a two-level feature extraction (TLFE) procedure. In the first level, a ranked filter feature set technique is used to prioritize features based on medical expert recommendations. In the second level, a variety of metrics, including information gain, gain ratio, chi-square, and relief, are used to rank and select features. A composite measure guided by fuzzy logic is then used to select a judicious subset of features. The FERNN model uses the GRU-RNN to classify thyroid diseases in the databases. To optimise, the COOT optimization method is employed. The model's weights. The FERNN model was put into practise in MATLAB and assessed with a variety of statistical metrics, including kappa, accuracy, precision, recall, sensitivity, specificity, and the F-measure. The proposed methodology was benchmarked against traditional techniques, including the deep belief neural network (DBN), artificial neural network (ANN), and support vector machine (SVM).",
        "keywords": "",
        "link": "http://dx.doi.org/10.17762/ijritcc.v11i9.9607"
    },
    {
        "id": 4182,
        "title": "Multi-Level Node Authorization using Recurrent Neural Networks for Secure Health Monitoring System",
        "authors": "V. Lakshman Narayana, P. Syamalatha, P. Vatsalya, V. SriCharitha, V. Akhila",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icscna58489.2023.10370543"
    },
    {
        "id": 4183,
        "title": "Optimal Energy Forecasting Using Hybrid Recurrent Neural Networks",
        "authors": "Elumalaivasan Poongavanam, Padmanathan Kasinathan, Kulothungan Kanagasabai",
        "published": "2023",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/iasc.2023.030101"
    },
    {
        "id": 4184,
        "title": "Methane Concentration Forecasting Based on Sentinel-5P Products and Recurrent Neural Networks",
        "authors": "Theofani Psomouli, Ioannis Kansizoglou, Antonios Gasteratos",
        "published": "2023-6-16",
        "citations": 0,
        "abstract": "The increase in the concentration of geological gas emissions in the atmosphere and particularly the increase of methane is considered by the majority of the scientific community as the main cause of global climate change. The main reasons that place methane at the center of interest, lie in its high global warming potential (GWP) and its lifetime in the atmosphere. Anthropogenic processes, like engineering geology ones, highly affect the daily profile of gasses in the atmosphere. Should direct measures be taken to reduce emissions of methane, immediate global warming mitigation could be achieved. Due to its significance, methane has been monitored by many space missions over the years and as of 2017 by the Sentinel-5P mission. Considering the above, we conclude that monitoring and predicting future methane concentration based on past data is of vital importance for the course of climate change over the next decades. To that end, we introduce a method exploiting state-of-the-art recurrent neural networks (RNNs), which have been proven particularly effective in regression problems, such as time-series forecasting. Aligned with the green artificial intelligence (AI) initiative, the paper at hand investigates the ability of different RNN architectures to predict future methane concentration in the most active regions of Texas, Pennsylvania and West Virginia, by using Sentinel-5P methane data and focusing on computational and complexity efficiency. We conduct several empirical studies and utilize the obtained results to conclude the most effective architecture for the specific use case, establishing a competitive prediction performance that reaches up to a 0.7578 mean squared error on the evaluation set. Yet, taking into consideration the overall efficiency of the investigated models, we conclude that the exploitation of RNN architectures with less number of layers and a restricted number of units, i.e., one recurrent layer with 8 neurons, is able to better compensate for competitive prediction performance, meanwhile sustaining lower computational complexity and execution time. Finally, we compare RNN models against deep neural networks along with the well-established support vector regression, clearly highlighting the supremacy of the recurrent ones, as well as discuss future extensions of the introduced work.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/geosciences13060183"
    },
    {
        "id": 4185,
        "title": "The Smart Intuitive Natural Language Understanding with Recurrent Neural Networks",
        "authors": "R Raghavendra, Megha Pandeya, Deepak Kumar",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470796"
    },
    {
        "id": 4186,
        "title": "Active Hypothesis Testing in Unknown Environments Using Recurrent Neural Networks and Model Free Reinforcement Learning",
        "authors": "George Stamatelis, Nicholas Kalouptsidis",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/eusipco58844.2023.10289731"
    },
    {
        "id": 4187,
        "title": "Location Estimation of Moving Targets by Passive Sonobuoy and Recurrent Deep Neural Network",
        "authors": "Hooshang Abbaspour, Ghazal Najafi",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isncc58260.2023.10323838"
    },
    {
        "id": 4188,
        "title": "Deep Learning for Marginal Bayesian Posterior Inference with Recurrent Neural Networks",
        "authors": "Thayer Fisher, Alex Luedtke, Marco Carone, Noah Simon",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5705/ss.202020.0348"
    },
    {
        "id": 4189,
        "title": "Recurrent Neural Networks for Solving Photovoltaic System Dynamics",
        "authors": "Md Rifat Hossain, Sumit Paudyal, Tuyen Vu",
        "published": "2023-11-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isgt-la56058.2023.10328292"
    },
    {
        "id": 4190,
        "title": "The Smart Improving of Translation Models Using Recurrent Neural Networks",
        "authors": "Anjali Singh, Mayur Agarwal, Gowrishankar J",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470485"
    },
    {
        "id": 4191,
        "title": "A Deep Convolutional Gated Recurrent Unit for CT Image Reconstruction",
        "authors": "Masaki Ikuta, Jun Zhang",
        "published": "2023-12",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2022.3169569"
    },
    {
        "id": 4192,
        "title": "Stability Analysis of Recurrent Neural Networks With Time-Varying Delay by Flexible Terminal Interpolation Method",
        "authors": "Zhanshan Wang, Yufeng Tian",
        "published": "2024-2",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2022.3188161"
    },
    {
        "id": 4193,
        "title": "Retracted: Prediction of IoT Traffic Using the Gated Recurrent Unit Neural Network- (GRU-NN-) Based Predictive Model",
        "authors": "",
        "published": "2023-12-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9820840"
    },
    {
        "id": 4194,
        "title": "User2Vec: A Novel Representation for the Information of the Social Networks for Stock Market Prediction Using Convolutional and Recurrent Neural Networks",
        "authors": "Pegah Eslamieh, Mehdi Shajari, Ahmad Nickabadi",
        "published": "2023-7-1",
        "citations": 1,
        "abstract": "Predicting stock market trends is an intriguing and complex problem, which has drawn considerable attention from the research community. In recent years, researchers have employed machine learning techniques to develop prediction models by using numerical market data and textual messages on social networks as their primary sources of information. In this article, we propose User2Vec, a novel approach to improve stock market prediction accuracy, which contributes to more informed investment decision making. User2Vec is a unique method that recognizes the unequal impact of different user opinions on specific stocks, and it assigns weights to these opinions based on the accuracy of their associated social metrics. The User2Vec model begins by encoding each message as a vector. These vectors are then fed into a convolutional neural network (CNN) to generate an aggregated feature vector. Following this, a stacked bi-directional long short-term memory (LSTM) model provides the final representation of the input data over a period. LSTM-based models have shown promising results by effectively capturing the temporal patterns in time series market data. Finally, the output is fed into a classifier that predicts the trend of the target stock price for the next day. In contrast to previous attempts, User2Vec considers not only the sentiment of the messages, but also the social information associated with the users and the text content of the messages. It has been empirically proven that this inclusion provides valuable information for predicting stock direction, thereby significantly enhancing prediction accuracy. The proposed model was rigorously evaluated using various combinations of market data, encoded messages, and social features. The empirical studies conducted on the Dow Jones 30 stock market showed the model’s superiority over existing state-of-the-art models. The findings of these experiments reveal that including social information about users and their tweets, in addition to the sentiment and textual content of their messages, significantly improves the accuracy of stock market prediction.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math11132950"
    },
    {
        "id": 4195,
        "title": "Maneuver Prediction Using Traffic Scene Graphs via Graph Neural Networks and Recurrent Neural Networks",
        "authors": "Petrit Rama, Naim Bajcinca",
        "published": "2023-9",
        "citations": 0,
        "abstract": " The driving process involves many layers of planning and navigation, in order to enable tractable solutions for the otherwise highly complex problem of autonomous driving. One such layer involves an inherent discrete layer of decision-making corresponding to tactical maneuvers. Inspired by this, the focus of this work is predicting high-level maneuvers for the ego-vehicle. As maneuver prediction is fundamentally feedback-structured, it requires modeling techniques that take into consideration the interaction awareness of the traffic agents involved. This work addresses this challenge by modeling the traffic scenario as an interaction graph and proposing three deep learning architectures for interaction-aware tactical maneuver prediction of the ego-vehicle. These architectures are based on graph neural networks (GNNs) for extracting spatial features among traffic agents and recurrent neural networks (RNNs) for extracting dynamic motion patterns of surrounding agents. These proposed architectures have been trained and evaluated using BLVD dataset. Moreover, this dataset is expanded using data augmentation, data oversampling and data undersampling approaches, to strengthen model’s resilience and enhance the learning process. Lastly, we compare proposed learning architectures for ego-vehicle maneuver prediction in various driving circumstances with various numbers of surrounding traffic agents in order to effectively verify the proposed architectures. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1142/s1793351x23620040"
    },
    {
        "id": 4196,
        "title": "Data-Driven Tabulation for Chemistry Integration Using Recurrent Neural Networks",
        "authors": "Yu Zhang, Qingguo Lin, Wenli Du, Feng Qian",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2022.3175301"
    },
    {
        "id": 4197,
        "title": "Daily Prediction Model of Photovoltaic Power Generation Using a Hybrid Architecture of Recurrent Neural Networks and Shallow Neural Networks",
        "authors": "Wilson Castillo-Rojas, Juan Bekios-Calfa, César Hernández",
        "published": "2023-4-18",
        "citations": 0,
        "abstract": "In recent years, photovoltaic energy has become one of the most implemented electricity generation options to help reduce environmental pollution suffered by the planet. Accuracy in this photovoltaic energy forecasting is essential to increase the amount of renewable energy that can be introduced to existing electrical grid systems. The objective of this work is based on developing various computational models capable of making short-term forecasting about the generation of photovoltaic energy that is generated in a solar plant. For the implementation of these models, a hybrid architecture based on recurrent neural networks (RNN) with long short-term memory (LSTM) or gated recurrent units (GRU) structure, combined with shallow artificial neural networks (ANN) with multilayer perceptron (MLP) structure, is established. RNN models have a particular configuration that makes them efficient for processing ordered data in time series. The results of this work have been obtained through controlled experiments with different configurations of its hyperparameters for hybrid RNN-ANN models. From these, the three models with the best performance are selected, and after a comparative analysis between them, the forecasting of photovoltaic energy production for the next few hours can be determined with a determination coefficient of 0.97 and root mean square error (RMSE) of 0.17. It is concluded that the proposed and implemented models are functional and capable of predicting with a high level of accuracy the photovoltaic energy production of the solar plant, based on historical data on photovoltaic energy production.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/2592405"
    },
    {
        "id": 4198,
        "title": "Modeling an intrusion detection using recurrent neural networks",
        "authors": "Mariam Ibrahim, Ruba Elhafiz",
        "published": "2023-3",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jer.2023.100013"
    },
    {
        "id": 4199,
        "title": "Building Performance Prediction Model Using CAD Technology and Recurrent Neural Networks",
        "authors": "Nian Wu, Zhao Ye",
        "published": "2024-1-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14733/cadaps.2024.s18.66-80"
    },
    {
        "id": 4200,
        "title": "Structural health monitoring of steel moment frame buildings via sequence-based recurrent neural networks",
        "authors": "Khashayar Heydarpour, Doeun Choe, Kyungyong Chung",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cai54212.2023.00154"
    },
    {
        "id": 4201,
        "title": "Research on Photovoltaic Power Generation Load Prediction based on Recurrent Neural Networks",
        "authors": "Zhitao Zhang, Yujia Dong",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icnepe60694.2023.10429183"
    },
    {
        "id": 4202,
        "title": "ES-dRNN: A Hybrid Exponential Smoothing and Dilated Recurrent Neural Network Model for Short-Term Load Forecasting",
        "authors": "Slawek Smyl, Grzegorz Dudek, Paweł Pełka",
        "published": "2024",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2023.3259149"
    },
    {
        "id": 4203,
        "title": "ICOR: improving codon optimization with recurrent neural networks",
        "authors": "Rishab Jain, Aditya Jain, Elizabeth Mauro, Kevin LeShane, Douglas Densmore",
        "published": "2023-4-4",
        "citations": 5,
        "abstract": "Abstract\nBackground\nIn protein sequences—as there are 61 sense codons but only 20 standard amino acids—most amino acids are encoded by more than one codon. Although such synonymous codons do not alter the encoded amino acid sequence, their selection can dramatically affect the expression of the resulting protein. Codon optimization of synthetic DNA sequences is important for heterologous expression. However, existing solutions are primarily based on choosing high-frequency codons only, neglecting the important effects of rare codons. In this paper, we propose a novel recurrent-neural-network based codon optimization tool, ICOR, that aims to learn codon usage bias on a genomic dataset of Escherichia coli. We compile a dataset of over 7,000 non-redundant, high-expression, robust genes which are used for deep learning. The model uses a bidirectional long short-term memory-based architecture, allowing for the sequential context of codon usage in genes to be learned. Our tool can predict synonymous codons for synthetic genes toward optimal expression in Escherichia coli.\n\nResults\nWe demonstrate that sequential context achieved via RNN may yield codon selection that is more similar to the host genome. Based on computational metrics that predict protein expression, ICOR theoretically optimizes protein expression more than frequency-based approaches. ICOR is evaluated on 1,481 Escherichia coli genes as well as a benchmark set of 40 select DNA sequences whose heterologous expression has been previously characterized. ICOR’s performance is measured across five metrics: the Codon Adaptation Index, GC-content, negative repeat elements, negative cis-regulatory elements, and codon frequency distribution.\n\nConclusions\nThe results, based on in silico metrics, indicate that ICOR codon optimization is theoretically more effective in enhancing recombinant expression of proteins over other established codon optimization techniques. Our tool is provided as an open-source software package that includes the benchmark set of sequences used in this study.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s12859-023-05246-8"
    },
    {
        "id": 4204,
        "title": "ODRNN: optimized deep recurrent neural networks for automatic detection of leukaemia",
        "authors": "K. Dhana Shree, S. Logeswari",
        "published": "2024-3-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11760-024-03062-y"
    },
    {
        "id": 4205,
        "title": "Multi-Scale Recurrent Neural Networks for Medical Image Classification",
        "authors": "Parag Agarwal, M N Nachappa, Chandra Kant Gautam",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470694"
    },
    {
        "id": 4206,
        "title": "Classification of Microbes with Recurrent Neural Networks",
        "authors": "Talha Burak ALAKUŞ",
        "published": "2023-9-1",
        "citations": 0,
        "abstract": "Mikroplar insan vücudunun hem içinde hem de dışında yaşayan ve hemen hemen her yerde bulunan tek hücreli küçük canlılardır. Zararlı olabileceği gibi zararı olmayan mikroplarda bulunmaktadır.  Bu yüzden mikroplar ekolojik dengenin sağlanmasında büyük bir rol üstlenmektedir. Ancak, bu mikropları birbirinden ayırt edebilmek çoğu zaman meşakkatli bir iş olmaktadır.  Mikropların çeşitli özelliklerini anlayan ve taksonomi nüanslarını yorumlayabilen bir uzman bilgisinin gerekmesi ve laboratuvar ihtiyacının olması bu süreci hem maliyetli hem de zaman alıcı yapmaktadır. Bundan dolayı, bilgisayar destekli sistemlerin bu alanda önemi artmış ve günümüzde yapay zeka teknolojileri mikropların sınıflandırılmasında kullanılmaya başlanmıştır. Makine öğrenmesi ve derin öğrenme teknolojilerinin bu alana uygulanmasıyla yüksek seviyede doğruluk skorları elde edilmekte ve biyoçeşitlilikle ilgili değerlendirmeler otomatik bir şekilde yapılabilmektedir. Bu çalışmada da derin öğrenme modellerinden biri olan tekrarlayıcı sinir ağları yapıları kullanılarak, mikropların sınıflandırılması yapılmıştır. Çalışma dört aşamadan meydana gelmiştir. Birinci aşamada, veriler elde edilmiştir. İkinci aşamada bu veriler normalleştirme işlemine tabi tutulmuş ve önişlemden geçirilmiştir. Üçüncü aşamada UKSB ve TSA modelleri tasarlanmış ve sınıflandırılmıştır. Son aşamada ise sınıflandırıcıların performansları doğruluk, kesinlik, duyarlılık, F1-skor ve AUC skoru ile belirlenmiştir. Çalışmanın sonunda TSA sınıflandırıcısı ile %92.53, UKSB sınıflandırıcısıyla ise %99.85 doğruluk skoru elde edilmiştir.",
        "keywords": "",
        "link": "http://dx.doi.org/10.35234/fumbd.1302903"
    },
    {
        "id": 4207,
        "title": "VBF Event Classification with Recurrent Neural Networks at ATLAS’s LHC Experiment",
        "authors": "Silvia Auricchio, Francesco Cirotto, Antonio Giannini",
        "published": "2023-3-4",
        "citations": 0,
        "abstract": "A novel machine learning (ML) approach based on a recurrent neural network (RNN) for event topology identification in high energy physics (HEP) is presented. The vector-boson fusion (VBF) production mechanism arising in proton-to-proton collisions is predicted both from the current theoretical model of the particle physics, the standard model, and from its extensions that foresee potential new physics phenomena. This physical process has a well-defined event topology in the final state and a distinctive detector signature. In this work, an ML approach based on the RNN architecture is developed to deal with hadronic-only event information in order to enhance the acceptance of this production mechanism in physics analysis of the data. This technique was applied to a physics analysis in the context of high-mass diboson resonance searches using data collected by the ATLAS experiment.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app13053282"
    },
    {
        "id": 4208,
        "title": "An Improved Time Feedforward Connections Recurrent Neural Networks",
        "authors": "Jin Wang, Yongsong Zou, Se-Jung Lim",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/iasc.2023.033869"
    },
    {
        "id": 4209,
        "title": "Statistical Online Learning in Recurrent and Feedforward Quantum Neural Networks",
        "authors": "S. V. Zuev",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1134/s1064562423701557"
    },
    {
        "id": 4210,
        "title": "Well On/Off Time Classification Using Recurrent Neural Networks and a Developed Transient Well Simulator",
        "authors": "Y. K. AlHammad, H. Hoteit",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "AbstractSupervised machine learning (ML) projects require data for model training, validation, and testing. However, the confidential nature of field and well production data often hinders the progress of ML projects. To address this issue, we developed a well simulator that generates realistic well production data based on physical, governing differential equations. The simulation models the reservoir, wellbore, flowline, and choke coupled using transient nodal analysis to solve for transient flow rate, pressure, and temperature as a function of variable choke opening over time in addition to a wide range of static parameters for each component. The simulator's output is then perturbed using the gauge transfer function to introduce systemic and random errors, creating a dataset for ML projects without the need for confidential production data.We then generated a simulated dataset to train a recurrent neural network (RNN) on the task of classifying well on/off times. This task typically requires a significant number of manhours to manually filter and verify data for hundreds or thousands of wells. Our RNN model achieves high accuracy in classifying the correct on/off labels, representing a promising step towards a fully-automated rate allocation process.Our simulator for well production data can be used for other ML projects, circumventing the need for confidential data, and enabling the study and development of different ML models to streamline and automate various oil and gas work processes. Overall, the success of our RNN model demonstrates the potential of ML to improve the operational efficiency of various oil and gas work processes.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2118/216789-ms"
    },
    {
        "id": 4211,
        "title": "Universal structural patterns in sparse recurrent neural networks",
        "authors": "Xin-Jie Zhang, Jack Murdoch Moore, Gang Yan, Xiang Li",
        "published": "2023-9-8",
        "citations": 0,
        "abstract": "AbstractSparse neural networks can achieve performance comparable to fully connected networks but need less energy and memory, showing great promise for deploying artificial intelligence in resource-limited devices. While significant progress has been made in recent years in developing approaches to sparsify neural networks, artificial neural networks are notorious as black boxes, and it remains an open question whether well-performing neural networks have common structural features. Here, we analyze the evolution of recurrent neural networks (RNNs) trained by different sparsification strategies and for different tasks, and explore the topological regularities of these sparsified networks. We find that the optimized sparse topologies share a universal pattern of signed motifs, RNNs evolve towards structurally balanced configurations during sparsification, and structural balance can improve the performance of sparse RNNs in a variety of tasks. Such structural balance patterns also emerge in other state-of-the-art models, including neural ordinary differential equation networks and continuous-time RNNs. Taken together, our findings not only reveal universal structural features accompanying optimized network sparsification but also offer an avenue for optimal architecture searching.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s42005-023-01364-0"
    },
    {
        "id": 4212,
        "title": "Using recurrent neural networks for tweet buzzer detection",
        "authors": "Dedi Trisnawarman, Muhammad Choirul Imam,  Hugeng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0126968"
    },
    {
        "id": 4213,
        "title": "Research on optical computing system architecture for simple recurrent neural networks",
        "authors": "Satoshi Kawakami",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "Moore’s Law, relating to the speed and capabilities of computers is becoming less applicable. In this ‘post-Moore’ era, a cross-disciplinary team based in the Constructive Electronics Laboratory, Kyushu University, Japan, is investigating optical computing system infrastructures,\n with a view to driving computing technology forward in a way that negates the need to comply with Moore’s Law. Associate Professor Satoshi Kawakami is an expert in electric circuits and computer architecture who is part of the team. The team’s expertise covers materials, devices,\n circuits, architectures and algorithms and is geared towards pioneering new computing technologies in the post-Moore era. Kawakami believes that the continuous improvement of computer systems with higher performance and lower power consumption/energy consumption will be essential to realise\n a sustainable advanced information society and wants to maximise the advantages of devices and hide their disadvantages at the system level, which will necessitate collaboration with higher system layers. Another important goal is reducing power consumption by improving the efficiency of computers.\n In one current project, the researchers are exploring optical computing system infrastructure for simple recurrent neural networks. The team is keen to re-examine the ideal state of optical circuits from the perspective of the entire system, including electrical memory and interfaces.",
        "keywords": "",
        "link": "http://dx.doi.org/10.21820/23987073.2024.1.51"
    },
    {
        "id": 4214,
        "title": "Prescribed attractivity region selection for recurrent neural networks based on deep reinforcement learning",
        "authors": "Gang Bao, Zhenyan Song, Rui Xu",
        "published": "2024-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00521-023-09191-8"
    },
    {
        "id": 4215,
        "title": "Enhancing Medical Image Segmentation with Attention-Based Recurrent Neural Networks",
        "authors": "Rakesh Kumar Dwivedi, Ananya Saha, Meenakshi Sharma",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470617"
    },
    {
        "id": 4216,
        "title": "Decoding Convolutional Hadamard Codes and Turbo Hadamard Codes using Recurrent Neural Networks",
        "authors": "Sheng Jiang, Francis C. M. Lau",
        "published": "2024-2-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/icact60172.2024.10472004"
    },
    {
        "id": 4217,
        "title": "Precipitated Handover Decision Detection in LTE Networks Through Recurrent Neural Networks",
        "authors": "Renata Kellen G. Reis, Jussif J. Abularach Arnez, Caio Bruno Bezerra De Souza, Maria G. Lima Damasceno",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/latincom59467.2023.10361888"
    },
    {
        "id": 4218,
        "title": "RESEARCH ON METHODS OF FORECASTING TIME SERIES IN TRANSPORT USING RECURRENT NEURAL NETWORKS",
        "authors": "G.M. Lysov, F.N. Prikhodko, A.A. Konovalova, K.A. Timoshenko",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.51691/2541-8327_2023_1_6"
    },
    {
        "id": 4219,
        "title": "Enhancing Battery Degradation Prediction using Recurrent and Convolutional Neural Networks",
        "authors": "Lahcene Rouani, Walid Merrouche, Jugurta Amara, Hamza Ouazene",
        "published": "2023-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceeat60471.2023.10425828"
    },
    {
        "id": 4220,
        "title": "Optimising Recurrent Neural Networks for System-Level Communication Results in Low-Entropy Structural Robustness",
        "authors": "Cornelia Sheeran, Duncan Astle, Jascha Achterberg, Danyal Akarca",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32470/ccn.2023.1318-0"
    },
    {
        "id": 4221,
        "title": "Exploring the Potential of Recurrent Neural Networks for Medical Image Segmentation",
        "authors": "Aaditya Jain, Sanjeev Kumar Mandal, Monika Abrol",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470661"
    },
    {
        "id": 4222,
        "title": "Aircraft Trajectory Prediction Based on Residual Recurrent Neural Networks",
        "authors": "Zhonghang Fan, Junqi Lu, Zhanghao Qin",
        "published": "2023-2-24",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eebda56825.2023.10090482"
    },
    {
        "id": 4223,
        "title": "Robust recurrent neural networks for time series forecasting",
        "authors": "Xueli Zhang, Cankun Zhong, Jianjun Zhang, Ting Wang, Wing W.Y. Ng",
        "published": "2023-3",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neucom.2023.01.037"
    },
    {
        "id": 4224,
        "title": "Photovoltaic generation forecasting using convolutional and recurrent neural networks",
        "authors": "A. Babalhavaeji, M. Radmanesh, M. Jalili, S.A. Gonzalez",
        "published": "2023-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.egyr.2023.09.149"
    },
    {
        "id": 4225,
        "title": "Exploring Spatio-Temporal Context with Recurrent Neural Networks for Medical Image Analysis",
        "authors": "Bhuvana J, Vaibhav Srivastav, Sunil Kumar",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470687"
    },
    {
        "id": 4226,
        "title": "Spectrum Occupancy Prediction based on adaptive Recurrent Neural Networks",
        "authors": "Kenta Umebayashi, Yoshiki Kasahara, Hiroki Iwata, Ahmed Al-Tahmeesschi, Johanna Vartiainen",
        "published": "2023-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wcnc55385.2023.10118623"
    },
    {
        "id": 4227,
        "title": "Spatially-embedded recurrent spiking neural networks reveal patterns of topologically structured computations",
        "authors": "Andrew Siyoon Ham, Duncan E. Astle, Jascha Achterberg, Danyal Akarca",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32470/ccn.2023.1139-0"
    },
    {
        "id": 4228,
        "title": "ODRNN: Optimized deep recurrent neural networks for automatic detection of Leukaemia",
        "authors": "K. Dhana Shree, S. Logeswari",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eij.2024.100453"
    },
    {
        "id": 4229,
        "title": "Keep moving: sensorimotor integration of fixational eye-movements yields human-like superresolution in recurrent neural networks",
        "authors": "Adrien Doerig, Kirubeswaran O.R., Tim Kietzmann",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32470/ccn.2023.1311-0"
    },
    {
        "id": 4230,
        "title": "A study of the transaction volume prediction problem based on recurrent neural networks",
        "authors": "Jingyu Hu",
        "published": "2023-12-26",
        "citations": 0,
        "abstract": "With the rapid development of artificial intelligence technology, intelligent fintech scenarios based on big data are receiving more and more attention, and through the analysis of massive financial class data, accurate decision support can be provided for its various scenarios. By predicting the transaction volume of a financial product of a bank, abnormal transaction flow and gradual change trend can be found 1 day in advance to provide decision support for business department program development, and provide decision support for system expansion and contraction, thus reducing system online pressure or releasing unnecessary system resources. Linear algorithms such as AR model, MA model, ARMA model, etc. have poor prediction results for transaction volumes during holidays in the non-stationary dataset handled in this study due to strong assumptions on historical data. In this paper, we design and implement an LSTM-based trading volume prediction model LSTM-WP (LSTM-WebPredict) using deep learning algorithm, which can improve the accuracy of prediction of holiday trading volume by about 8% based on the linear algorithm by discovering and learning the features of historical data, and the learning ability of the model will gradually increase with the increasing of training data; Not only that, the research of this algorithm also provides corresponding technical accumulation for other business scenarios of time series problems, such as trend prediction and capacity assessment.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/29/20230778"
    },
    {
        "id": 4231,
        "title": "HAND GESTURE RECOGNITION USING RECURRENT NEURAL NETWORKS AND SYNTHETIC DATA GENERATION",
        "authors": "Francesco Sabbarese, Luciano Magliulo, Pietro Carratù, Marco Romano",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.7712/150123.9875.445104"
    },
    {
        "id": 4232,
        "title": "Exploring Flip Flop memories and beyond: training Recurrent Neural Networks with key insights",
        "authors": "Cecilia Jarne",
        "published": "2024-3-27",
        "citations": 0,
        "abstract": "Training neural networks to perform different tasks is relevant across various disciplines. In particular, Recurrent Neural Networks (RNNs) are of great interest in Computational Neuroscience. Open-source frameworks dedicated to Machine Learning, such as Tensorflow and Keras have produced significant changes in the development of technologies that we currently use. This work contributes by comprehensively investigating and describing the application of RNNs for temporal processing through a study of a 3-bit Flip Flop memory implementation. We delve into the entire modeling process, encompassing equations, task parametrization, and software development. The obtained networks are meticulously analyzed to elucidate dynamics, aided by an array of visualization and analysis tools. Moreover, the provided code is versatile enough to facilitate the modeling of diverse tasks and systems. Furthermore, we present how memory states can be efficiently stored in the vertices of a cube in the dimensionally reduced space, supplementing previous results with a distinct approach.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fnsys.2024.1269190"
    },
    {
        "id": 4233,
        "title": "On the adaptation of recurrent neural networks for system identification",
        "authors": "Marco Forgione, Aneri Muni, Dario Piga, Marco Gallieri",
        "published": "2023-9",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.automatica.2023.111092"
    },
    {
        "id": 4234,
        "title": "A ‘programming’ framework for recurrent neural networks",
        "authors": "Manuel Beiran, Camille A. Spencer-Salmon, Kanaka Rajan",
        "published": "2023-6-12",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s42256-023-00674-w"
    },
    {
        "id": 4235,
        "title": "Recurrent Neural Networks Are Universal Approximators With Stochastic Inputs",
        "authors": "Xiuqiong Chen, Yangtianze Tao, Wenjie Xu, Stephen Shing-Toung Yau",
        "published": "2023-10",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2022.3148542"
    },
    {
        "id": 4236,
        "title": "Secured Federated Learning for DDoS Detection in Heterogenous Telecom Cloud Networks Using Recurrent Neural Networks",
        "authors": "Abdoul-Aziz Maiga, Edwin Ataro, Stanley Githinji",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14445/23488379/ijeee-v10i12p106"
    },
    {
        "id": 4237,
        "title": "Development of a Neural Network Module for Detecting Network Threats in Traffic Based on Convolutional and Recurrent Neural Networks",
        "authors": "Alexey Volkov, Sergey Sobko, Igor Sviridov, Alexandr Baskakov, Denis Fride",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/elcon61730.2024.10468509"
    },
    {
        "id": 4238,
        "title": "An Attention-Based Convolutional Recurrent Neural Networks for Scene Text Recognition",
        "authors": "Adil Abdullah Abdulhussein Alshawi, Jafar Tanha, Mohammad Ali Balafar",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2024.3352748"
    },
    {
        "id": 4239,
        "title": "Emergence of behavioral phenomena and adaptation effects in human numerosity decoder using recurrent neural networks",
        "authors": "Bhavesh K Verma, Rakesh Sengupta",
        "published": "2023-11-10",
        "citations": 0,
        "abstract": "AbstractHumans possess an innate ability to visually perceive numerosities, which refers to the cardinality of a set. Numerous studies indicate that the lateral intraparietal cortex (LIP) and other intraparietal sulcus (IPS) regions (region) of the brain contain the neurological substrates responsible for number processing. Existing computational models of number perception often focus on a limited range of numbers and fail to account for important behavioral characteristics like adaptation effects, despite simulating fundamental aspects such as size and distance effects. To address these limitations, our study develops (introduces) a novel computational model of number perception utilizing a network of neurons with self-excitatory and mutual inhibitory properties. Our approach assumes that the mean activation of the network at steady state can encode numerosity by exhibiting a monotonically increasing relationship with the input variable set size. By optimizing the total number of inhibition strengths required, we achieve coverage of the full range of numbers through three distinct intervals: 1 to 4, 5 to 17, and 21 to 50. Remarkably, this division aligns closely with the breakpoints in numerosity perception identified in behavioral studies. Furthermore, our study develops a method for decoding the mean activation into a continuous scale of numbers spanning from 1 to 50. Additionally, we propose a mechanism for dynamically selecting the inhibition strength based on current inputs, enabling the network to operate effectively across an extended (entire) range of numerosities. Our model not only sheds new light on the generation of diverse behavioral phenomena in the brain but also elucidates how continuous visual attributes and adaptation effects influence perceived numerosity.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-023-44535-3"
    },
    {
        "id": 4240,
        "title": "A deep learning technique for intrusion detection system using a Recurrent Neural Networks based framework",
        "authors": "Sydney Mambwe Kasongo",
        "published": "2023-2",
        "citations": 60,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.comcom.2022.12.010"
    },
    {
        "id": 4241,
        "title": "Time series forecasting of electricity consumption using hybrid model of recurrent neural networks and genetic algorithms",
        "authors": "Ali Hussein, Mohammed Awad",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.meaene.2024.100004"
    },
    {
        "id": 4242,
        "title": "Multi-atlas Graph Convolutional Networks and Convolutional Recurrent Neural Networks-Based Ensemble Learning for Classification of Autism Spectrum Disorders",
        "authors": "Manjunath Ramanna Lamani, P. Julian Benadit, Krishnakumar Vaithinathan",
        "published": "2023-2-17",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42979-022-01617-9"
    },
    {
        "id": 4243,
        "title": "Drive Cycle Temperature Prediction for PSM using Recurrent Neural Networks",
        "authors": "Christian Digel, Felix Hoffmann, Martin Doppelbauer",
        "published": "2023-5-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iemdc55163.2023.10238993"
    },
    {
        "id": 4244,
        "title": "Birdsong Of Common Birds In An Urban Soundscape As Evaluated With Recurrent Neural Networks",
        "authors": "P. Devos",
        "published": "2024-1-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.61782/fa.2023.0817"
    },
    {
        "id": 4245,
        "title": "Training Integer-Only Deep Recurrent Neural Networks",
        "authors": "Vahid Partovi Nia, Eyyüb Sari, Vanessa Courville, Masoud Asgharian",
        "published": "2023-6-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42979-023-01920-z"
    },
    {
        "id": 4246,
        "title": "Greenhouse Climatic Sensing through Agricultural Robots and Recurrent Neural Networks",
        "authors": "Elia Brentarolli, Sara Migliorini, Davide Quaglia, Claudio Tomazzoli",
        "published": "2023-11-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/metroagrifor58484.2023.10424311"
    },
    {
        "id": 4247,
        "title": "Comparative Study of Recurrent and Dense Neural Networks for Classifying Maritime Terms",
        "authors": "Despoina Mouratidis, Katia Kermanidis, Andreas Kanavos",
        "published": "2023-7-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iisa59645.2023.10345925"
    },
    {
        "id": 4248,
        "title": "Aspect Based Sentiment Analysis Using Recurrent Neural Networks (RNN) on Social Media Twitter",
        "authors": "Muhammad Afryan Saputra, Erwin Budi Setiawan",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icodsa58501.2023.10276768"
    },
    {
        "id": 4249,
        "title": "Integrating Recurrent Neural Networks with Convolutional Neural Networks for Enhanced Traffic Light Detection and Tracking",
        "authors": "Riadh Ayachi, Mouna Afif, Yahia Said, Mohamed Atri, Abdessalem Ben Abdelali",
        "published": "2023-12-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18280/ts.400620"
    },
    {
        "id": 4250,
        "title": "Recurrent Neural Network Based RACH Scheme Minimizing Collisions in 5G and Beyond Networks",
        "authors": "Siba Narayan Swain, Ashit Subudhi",
        "published": "2023-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/infocomwkshps57453.2023.10226096"
    },
    {
        "id": 4251,
        "title": "Learning-Based Congestion Control Assisted by Recurrent Neural Networks for Real-Time Communication",
        "authors": "Jingshun Du, Chaokun Zhang, Shen He, Wenyu Qu",
        "published": "2023-7-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iscc58397.2023.10218019"
    },
    {
        "id": 4252,
        "title": "Retracted: Analysis of Diabetes Clinical Data Based on Recurrent Neural Networks",
        "authors": "",
        "published": "2023-9-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9761378"
    },
    {
        "id": 4253,
        "title": "Symbolic-Based Recurrent Neural Networks for Metamodeling of Nonlinear Structural Models",
        "authors": "Yiming Jia, Mehrdad Sasani",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00047"
    },
    {
        "id": 4254,
        "title": "Cryptocurrency Price Prediction using LSTM and Recurrent Neural Networks",
        "authors": "Vijaya Kumar T, S. Santhi, K. G. Shanthi, Gokila M",
        "published": "2023-5-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaaic56838.2023.10141048"
    },
    {
        "id": 4255,
        "title": "Automatic detection of cell-cycle stages using recurrent neural networks",
        "authors": "Abin Jose, Rijo Roy, Daniel Moreno-Andrés, Johannes Stegmaier",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "Mitosis is the process by which eukaryotic cells divide to produce two similar daughter cells with identical genetic material. Research into the process of mitosis is therefore of critical importance both for the basic understanding of cell biology and for the clinical approach to manifold pathologies resulting from its malfunctioning, including cancer. In this paper, we propose an approach to study mitotic progression automatically using deep learning. We used neural networks to predict different mitosis stages. We extracted video sequences of cells undergoing division and trained a Recurrent Neural Network (RNN) to extract image features. The use of RNN enabled better extraction of features. The RNN-based approach gave better performance compared to classifier based feature extraction methods which do not use time information. Evaluation of precision, recall, and F-score indicates the superiority of the proposed model compared to the baseline. To study the loss in performance due to confusion between adjacent classes, we plotted the confusion matrix as well. In addition, we visualized the feature space to understand why RNNs are better at classifying the mitosis stages than other classifier models, which indicated the formation of strong clusters for the different classes, clearly confirming the advantage of the proposed RNN-based approach.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1371/journal.pone.0297356"
    },
    {
        "id": 4256,
        "title": "Solar Power Prediction Based on Recurrent Neural Networks Using LSTM and Dense Layer With ReLU Activation Function",
        "authors": "Deepanshu Gupta, Vanjari Venkata Ramana",
        "published": "2023-6-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/conit59222.2023.10205605"
    },
    {
        "id": 4257,
        "title": "Beam wander prediction with recurrent neural networks",
        "authors": "Dmitrii Briantcev, Mitchell A. Cox, Abderrahmen Trichili, Boon S. Ooi, Mohamed-Slim Alouini",
        "published": "2023-8-28",
        "citations": 1,
        "abstract": "Among the problems that prevent free-space optical communication systems from becoming a truly mainstream technology is beam wander, which is especially important for structured light beams since beam misalignment introduces additional crosstalk at the receiver. The paper suggests a recurrent neural network-based (RNN) solution to predict beam wander in free space optics (FSO). The approach uses past beam center of mass positions to predict future movement, significantly outperforming various prediction types. The proposed approach is demonstrated using under-sampled experimental data over a 260 m link as a worst-case and over-sampled simulated data as a best-case scenario. In addition to conventional Gaussian beams, Hermite- and Laguerre-Gaussian beam wander is also investigated. With a 20 to 40% improvement in error over naive and linear predictions, while predicting multiple samples ahead in typical situations and overall matching or outperforming considered predictions across all studied scenarios, this method could help mitigate turbulence-induced fading and has potential applications in intelligent re-transmits, quality of service, optimized error correction, maximum likelihood-type algorithms, and predictive adaptive optics.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1364/oe.496690"
    },
    {
        "id": 4258,
        "title": "Transductive Support Vector Machines (TSVM) With Hybrid Recurrent Neural Networks For Medical Image Filtering",
        "authors": "Ravi Kumar",
        "published": "2023-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ihcsp56702.2023.10127184"
    },
    {
        "id": 4259,
        "title": "Recurrent Neural Networks for Artifact Correction in HRV Data During Physical Exercise",
        "authors": "Jakob Svane, Tomasz Wiktorski, Stein Ørn, Trygve Christian Eftestøl",
        "published": "2023-5-22",
        "citations": 1,
        "abstract": "\r\n\r\n\r\nIn this paper, we propose the use of recurrent neural networks (RNNs) for artifact correction and analysis of heart rate variability (HRV) data. HRV can be a valuable metric for determining the function of the heart and the autonomic nervous system. When measured during exercise, motion artifacts present a significant challenge. Several methods for artifact correction have previously been proposed, none of them applying machine learning, and each presenting some limitations regarding an accurate representation of HRV metrics. RNNs offer the ability to capture patterns that might otherwise not be detected, yielding predictions where no prior physiological assumptions are needed.\r\nA hyperparameter search has been carried out to determine the best network configuration and the most important hyperparameters. The approach was tested on two extensive multi-subject data sets, one from a recreational bicycle race and the other from a laboratory experiment. The results demonstrate that RNNs outperform by order of magnitude existing methods with respect to the calculation of derived HRV metrics. However, they are not able to accurately fill in individual missing RR intervals in sequence. Future research should pursue improvements in the prediction of RR interval lengths and reduction in necessary training data.\r\n\r\n\r\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.5617/nmi.10140"
    },
    {
        "id": 4260,
        "title": "A novel locally connected recurrent neural network for identification of nonlinear dynamical system",
        "authors": "R Shobana., Rajesh Kumar, Bhavnesh Jaint",
        "published": "2023-3-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/spin57001.2023.10117315"
    },
    {
        "id": 4261,
        "title": "Attention-fused recurrent neural networks for DDoS attack detection based on blockchain technology",
        "authors": "shi zixin",
        "published": "2023-6-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2682327"
    },
    {
        "id": 4262,
        "title": "Abstractive Text Summarisation using Recurrent Neural Networks at the Paragraph Level",
        "authors": "Israel Christian Tchouya’a Ngoko, Boniface Kabaso",
        "published": "2023-11-9",
        "citations": 0,
        "abstract": "Continuous production of information has been facilitated by the easy access to new technology. This has made it difficult for many users to find relevant information, which are sometimes buried deeply inside mass-produced content. Without the development of new tools and technology to make this data more accessible, it potential remain unexploited. Abstractive text summarisation aims to extract the key points of the document. Because text generating techniques are still in their early stage, it has received little attention in the past. Recently, the application of recurrent neural network models has made significant progress in abstractive sentence summarisation. Despite the improvement in results, these models still tend to produce grammatical errors. Unfortunately, attempts in abstractive document summarisation are still in their early phases, and evaluation outcomes on benchmark datasets are noticeably inferior to human summarisation. In this study we propose a data-driven for abstractive document. Each word generated in the summary use an attention-based technique depending on the input paragraph. According to experimental findings, our model generates higher-quality summaries, achieving ROUGE-1 score of 44.44, ROUGE-2 score of 22.50, and ROUGEL score of 45.15 on the document understanding conference 2004 datasets.",
        "keywords": "",
        "link": "http://dx.doi.org/10.59200/icarti.2023.020"
    },
    {
        "id": 4263,
        "title": "Intention Estimation with Recurrent Neural Networks for Mixed Reality Environments",
        "authors": "Michael Fennel, Serge Garbay, Antonio Zea, Uwe D. Hanebeck",
        "published": "2023-6-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/fusion52260.2023.10224151"
    },
    {
        "id": 4264,
        "title": "Survey and Enhancements on Deploying LSTM Recurrent Neural Networks on Embedded Systems",
        "authors": "Ghalid Abib, Florian Castel, Nissrine Satouri, Hossam Afifi, Adel Mounir Said",
        "published": "2023-5-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icc45041.2023.10278766"
    },
    {
        "id": 4265,
        "title": "Intelligent auxiliary system for music performance under edge computing and long short-term recurrent neural networks",
        "authors": "Yi Wang",
        "published": "2023-5-8",
        "citations": 0,
        "abstract": "Music performance action generation can be applied in multiple real-world scenarios as a research hotspot in computer vision and cross-sequence analysis. However, the current generation methods of music performance actions have consistently ignored the connection between music and performance actions, resulting in a strong sense of separation between visual and auditory content. This paper first analyzes the attention mechanism, Recurrent Neural Network (RNN), and long and short-term RNN. The long and short-term RNN is suitable for sequence data with a strong temporal correlation. Based on this, the current learning method is improved. A new model that combines attention mechanisms and long and short-term RNN is proposed, which can generate performance actions based on music beat sequences. In addition, image description generative models with attention mechanisms are adopted technically. Combined with the RNN abstract structure that does not consider recursion, the abstract network structure of RNN-Long Short-Term Memory (LSTM) is optimized. Through music beat recognition and dance movement extraction technology, data resources are allocated and adjusted in the edge server architecture. The metric for experimental results and evaluation is the model loss function value. The superiority of the proposed model is mainly reflected in the high accuracy and low consumption rate of dance movement recognition. The experimental results show that the result of the loss function of the model is at least 0.00026, and the video effect is the best when the number of layers of the LSTM module in the model is 3, the node value is 256, and the Lookback value is 15. The new model can generate harmonious and prosperous performance action sequences based on ensuring the stability of performance action generation compared with the other three models of cross-domain sequence analysis. The new model has an excellent performance in combining music and performance actions. This paper has practical reference value for promoting the application of edge computing technology in intelligent auxiliary systems for music performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1371/journal.pone.0285496"
    },
    {
        "id": 4266,
        "title": "Accuracy Comparison between Recurrent Neural Networks and Statistical Methods for Temperature Forecasting",
        "authors": "Isurika Adikari, Sumudu Lakmali, Praveen Dhananjaya, Damayanthi Herath",
        "published": "2023-2-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icarc57651.2023.10145620"
    },
    {
        "id": 4267,
        "title": "Sequence Modeling with Recurrent Neural Networks (RNNs) for Student Learning Behavior Pattern Recognition in a Flipped Classroom",
        "authors": "Guangheng Tang",
        "published": "2024-4-4",
        "citations": 0,
        "abstract": "The flipped classroom model has become increasingly popular in education, altering the traditional methods of teaching. It is important to understand and acknowledge how students learn within this framework in order to optimize instructional strategies and promote personalized learning. This study investigates the use of Sequence Modeling with Recurrent Neural Networks (RNNs) to identify patterns in student learning behavior within a flipped classroom setting. The proposed deep learning architecture utilizes RNNs to analyze sequential patterns in students' interactions with the flipped classroom materials, while also incorporating attention mechanisms to better detect important patterns and temporal dynamics in the learning process. Multimodal learning techniques are also employed, combining data from various sources to gain a comprehensive understanding of student behavior. Additionally, clustering techniques using autoencoders are explored to group students with similar learning behaviors. Predictive models, such as RNN or LSTM networks, are developed to forecast future learning behaviors and provide insights into potential challenges or successes for individual students. The effectiveness of this framework is evaluated using real-world data from flipped classroom implementations, with performance metrics like recall, precision, and accuracy used to assess the success of the sequence modeling approach in recognizing and predicting student behavior patterns. Overall, the application of deep learning methods, specifically sequence modeling with RNNs, demonstrates potential for improving personalized learning experiences and facilitating proactive interventions to support diverse student needs.",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/jes.1306"
    },
    {
        "id": 4268,
        "title": "Identification of meningioma tumor using recurrent neural networks",
        "authors": "D. Anand, Osamah Ibrahim Khalaf, Ghaida Muttashar Abdulsahib, G. Rajesh Chandra",
        "published": "2023-12-12",
        "citations": 1,
        "abstract": "<p>By the calculations of national center for biotechnology information from COVID 19 pandemic, number of meningioma tumor patients are increasing in world. Identifying the meningioma tumor and its position in brain is not easy task by using deep neural networking based medical imaging. But it is needed to identify meningioma tumors in brain by using AI based medical imaging for the purpose of medical artificial intelligence technology innovation. Comparing to neural network results with recurrent neural network results can give accurate results. For identifying the patients’ present condition and prediction of future behavior by using recurrent neural network is need for us. Increase the accurate results for neural networking based medical imaging in health care is very expensive. By using recurrent neural networks (RNN) algorithm with many hidden layers for identification of tumor(s) in human brain with high accuracy by comparison of existing images in our data base with new unknown medical image with low cost. In this study first we are collecting the masks of skull from MRI image and dividing the masks to different types of datasets depending on age criteria like a child age, middle age and old age with two types male and female. Then we can get totally 6 types of datasets. All these masks of MRI images to binary imaging by using morphological erosion concept after that storing that masks in data sets then collect the new MRI image and comparing its mask part of skull with existing dataset in recurrent neural networks.</p>",
        "keywords": "",
        "link": "http://dx.doi.org/10.32629/jai.v7i2.653"
    },
    {
        "id": 4269,
        "title": "Rapid training of quantum recurrent neural networks",
        "authors": "Michał Siemaszko, Adam Buraczewski, Bertrand Le Saux, Magdalena Stobińska",
        "published": "2023-12",
        "citations": 2,
        "abstract": "AbstractTime series prediction is essential for human activities in diverse areas. A common approach to this task is to harness recurrent neural networks (RNNs). However, while their predictions are quite accurate, their learning process is complex and, thus, time and energy consuming. Here, we propose to extend the concept of RRNs by including continuous-variable quantum resources in it and to use a quantum-enhanced RNN to overcome these obstacles. The design of the continuous-variable quantum RNN (CV-QRNN) is rooted in the continuous-variable quantum computing paradigm. By performing extensive numerical simulations, we demonstrate that the quantum network is capable of learning-time dependence of several types of temporal data and that it converges to the optimal weights in fewer epochs than a classical network. Furthermore, for a small number of trainable parameters, it can achieve lower losses than its classical counterpart. CV-QRNN can be implemented using commercially available quantum-photonic hardware.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42484-023-00117-0"
    },
    {
        "id": 4270,
        "title": "Recurrent Attentive Neural Networks for Sequential Recommendation",
        "authors": "Lei Tan, Jinmao Xu, Daofu Gong, Fenlin Liu",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3640912.3640983"
    },
    {
        "id": 4271,
        "title": "Performance Evaluation of Recurrent Neural Networks-LSTM and GRU for Automatic Speech Recognition",
        "authors": "Dhiraj Kumar, Shahid Aziz",
        "published": "2023-6-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ic2e357697.2023.10262561"
    },
    {
        "id": 4272,
        "title": "Nonintrusive Load Monitoring Using Recurrent Neural Networks with Occupants Location Information in Residential Buildings",
        "authors": "Myeung-Hun Lee, Hyeun-Jun Moon",
        "published": "2023-4-25",
        "citations": 1,
        "abstract": "Nonintrusive load monitoring (NILM) is a process that disaggregates individual energy consumption based on the total energy consumption. In this study, an energy disaggregation model was developed and verified using an algorithm based on a recurrent neural network (RNN). It also aimed to evaluate the utility of the occupant location information, which is nonelectrical information. This study developed energy disaggregation models with RNN-based long short-term memory (LSTM) and gated recurrent unit (GRU). The performance of the suggested models was evaluated with a conventional method that uses the factorial hidden Markov model. As a result, when developing the GRU disaggregation model based on an RNN, the energy disaggregation performance improved in accuracy, F1-score, mean absolute error (MAE), and root mean square error (RMSE). In addition, when the location information of the occupants was used, the suggested model showed improved performance and good agreement with the real power and electricity consumption by each appliance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/en16093688"
    },
    {
        "id": 4273,
        "title": "Soil NOx Emission Prediction via Recurrent Neural Networks",
        "authors": "Zhaoan Wang, Shaoping Xiao, Cheryl Reuben, Qiyu Wang, Jun Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/cmc.2023.044366"
    },
    {
        "id": 4274,
        "title": "Neural Networks Referees in 2023",
        "authors": "",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s0893-6080(23)00713-x"
    },
    {
        "id": 4275,
        "title": "Neural Networks Referees in 2022",
        "authors": "",
        "published": "2023-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s0893-6080(22)00489-0"
    },
    {
        "id": 4276,
        "title": "Fault detection in industrial pumps based on recurrent autoencoder neural networks",
        "authors": "V. Meruane, T. Hansen, I. Huerta, E. Roa, L. Quinteros, J. Marin",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23967/latam.2023.001"
    },
    {
        "id": 4277,
        "title": "Fault detection in industrial pumps based on recurrent autoencoder neural networks",
        "authors": "V. Meruane, T. Hansen, I. Huerta, E. Roa, L. Quinteros, J. Marin",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23967/latam.2024.001"
    },
    {
        "id": 4278,
        "title": "Lung Cancer Detection Using Positron Emission Tomography Images Through Convolutional and Recurrent Neural Networks",
        "authors": "Adolfo Jara-Gavilanes, Remigio Hurtado-Ortiz, Stefania Guzmán-Ortiz",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/clei60451.2023.10346202"
    },
    {
        "id": 4279,
        "title": "Performance Comparison of Recurrent Neural Networks for Metamorphic Malware",
        "authors": "Shubh Mittal, Tisha Chawla, Jay Jajoo, Muskan Bansal, Harsha Parashar, Ruby D",
        "published": "2023-7-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdsns58469.2023.10245978"
    },
    {
        "id": 4280,
        "title": "A novel deep learning method for predicting athletes’ health using wearable sensors and recurrent neural networks",
        "authors": "Wael Y. Alghamdi",
        "published": "2023-6",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.dajour.2023.100213"
    },
    {
        "id": 4281,
        "title": "Commodity demand forecasting based on multimodal data and recurrent neural networks for E-commerce platforms",
        "authors": "Cunbing Li",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.iswa.2024.200364"
    },
    {
        "id": 4282,
        "title": "Physics-informed recurrent neural networks and hyper-parameter optimization for dynamic process systems",
        "authors": "Tuse Asrav, Erdal Aydin",
        "published": "2023-5",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compchemeng.2023.108195"
    },
    {
        "id": 4283,
        "title": "Application of Recurrent Neural Networks Based on Attentional Mechanisms in Classification Error Correction in English Teaching",
        "authors": "Chanjuan Chen",
        "published": "2024-1-1",
        "citations": 0,
        "abstract": "Abstract\nThe way teachers correct errors in English teaching can cause problems such as psychological pressure, and deep learning technology offers the possibility of automatic error correction. In this paper, the final states of left and right texts are computed by constructing two attention mechanisms, target word-independent and related, and the merged obtained vectors are inputted into the RNN model for grammatical error recognition. In collocation error recognition, a Rank-based word candidate set ranking method is added, and error correction for verb usage is semantically encoded using RNN. The study was analyzed and tested in terms of grammar, collocation, and verbs. The ATT-RNN model accuracy is 3.62 percentage points higher than CAMB, and the difference in recall and F\n0.5-value is not more than 0.5 percentage points, which indicates that the algorithmic model has some research value.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2478/amns.2023.2.01174"
    },
    {
        "id": 4284,
        "title": "Classification of Tweets Into Facts and Opinions Using Recurrent Neural Networks",
        "authors": "Murugan Pattusamy, Lakshmi Kanth",
        "published": "2023-3-10",
        "citations": 0,
        "abstract": "In the last few years, the growth rate of the number of people who are active on Twitter has been consistently spiking. In India, even the government agencies have started using Twitter accounts as they feel that they can get connected to a greater number of people in a short span of time. Apart from the social media platforms, there are an enormous number of blogging applications that have popped up providing another platform for the people to share their views. With all this, the authenticity of the content that is being generated is going for a toss. On that note, the authors have the task in hand of differentiating the genuineness of the content. In this process, they have worked upon various techniques that would maximize the authenticity of the content and propose a long short-term memory (LSTM) model that will make a distinction between the tweets posted on the Twitter platform. The model in combination with the manually engineered features and the bag of words model is able to classify the tweets efficiently.",
        "keywords": "",
        "link": "http://dx.doi.org/10.4018/ijthi.319358"
    },
    {
        "id": 4285,
        "title": "Dynamic task scheduling in edge cloud systems using deep recurrent neural networks and environment learning approaches",
        "authors": "S.K. Ammavasai",
        "published": "2024-3-23",
        "citations": 0,
        "abstract": "The rapid growth of the cloud computing landscape has created significant challenges in managing the escalating volume of data and diverse resources within the cloud environment, catering to a broad spectrum of users ranging from individuals to large corporations. Ineffectual resource allocation in cloud systems poses a threat to overall performance, necessitating the equitable distribution of resources among stakeholders to ensure profitability and customer satisfaction. This paper addresses the critical issue of resource management in cloud computing through the introduction of a Dynamic Task Scheduling with Virtual Machine allocation (DTS-VM) strategy, incorporating Edge-Cloud computing for the Internet of Things (IoT). The proposed approach begins by employing a Recurrent Neural Network (RNN) algorithm to classify user tasks into Low Priority, Mid Priority, and High Priority categories. Tasks are then assigned to Edge nodes based on their priority, optimizing efficiency through the application of the Spotted Hyena Optimization (SHO) algorithm for selecting the most suitable edge node. To address potential overloads on the edge, a Fuzzy approach evaluates offloading decisions using multiple metrics. Finally, optimal Virtual Machine allocation is achieved through the application of the Stable Matching algorithm. The seamless integration of these components ensures a dynamic and efficient allocation of resources, preventing the prolonged withholding of customer requests due to the absence of essential resources. The proposed system aims to enhance overall cloud system performance and user satisfaction while maintaining organizational profitability. The effectiveness of the DTS-VM strategy is validated through comprehensive testing and evaluation, showcasing its potential to address the challenges posed by the diverse and expanding cloud computing landscape.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/jifs-236838"
    },
    {
        "id": 4286,
        "title": "Rectified Attention Gate Unit in Recurrent Neural Networks for Effective Attention Computation",
        "authors": "Manh-Hung Ha, Oscal Tzyh-Chiang Chen",
        "published": "2023-7-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ssp53291.2023.10207931"
    },
    {
        "id": 4287,
        "title": "Using Recurrent and Convulation Neural Networks to Indentify the Fake Audio Messages",
        "authors": "Artem Khovrat, Volodymyr Kobziev",
        "published": "2023-10-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/msnmc61017.2023.10329236"
    },
    {
        "id": 4288,
        "title": "Neuromorphic Recurrent Spiking Neural Networks for EMG Gesture Classification and Low Power Implementation on Loihi",
        "authors": "Sai Sukruth Bezugam, Ahmed Shaban, Manan Suri",
        "published": "2023-5-21",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iscas46773.2023.10181510"
    },
    {
        "id": 4289,
        "title": "FedSL: Federated split learning on distributed sequential data in recurrent neural networks",
        "authors": "Ali Abedi, Shehroz S. Khan",
        "published": "2023-9-8",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-15184-5"
    },
    {
        "id": 4290,
        "title": "Enhancing Classification in UTD-MHAD Dataset: Utilizing Recurrent Neural Networks in Ensemble-Based Approach for Human Action Recognition",
        "authors": "Saketh Kilaru, Anushka Shah, Swoichha Adhikari",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bigmm59094.2023.00018"
    },
    {
        "id": 4291,
        "title": "Predicting the evolution trajectory of population-driven connectional brain templates using recurrent multigraph neural networks",
        "authors": "Oytun Demirbilek, Islem Rekik",
        "published": "2023-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.media.2022.102649"
    },
    {
        "id": 4292,
        "title": "Stability Analysis of Delayed Recurrent Neural Networks via a Quadratic Matrix Convex Combination Approach",
        "authors": "Shasha Xiao, Zhanshan Wang, Yufeng Tian",
        "published": "2023-6",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2021.3107427"
    },
    {
        "id": 4293,
        "title": "Embedding Graph Convolutional Networks in Recurrent Neural Networks for Predictive Monitoring",
        "authors": "Efrén Rama-Maneiro, Juan C. Vidal, Manuel Lama",
        "published": "2024-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tkde.2023.3286017"
    },
    {
        "id": 4294,
        "title": "Predicting ALICE Grid throughput using recurrent neural networks",
        "authors": "Mircea Popa, Costin Grigoras, Sofia Vallecorsa",
        "published": "2023-2-1",
        "citations": 0,
        "abstract": "Abstract\nThe Worldwide LHC Computing Grid (WLCG) is the infrastructure enabling the storage and processing of the large amount of data generated by the LHC experiments, and in particular the ALICE experiment. With the foreseen increase in the computing requirements of the future High Luminosity LHC experiments, a data placement strategy which increases the efficiency of the WLCG computing infrastructure becomes extremely relevant for the scientific success of the LHC scientific programme. Currently, the data placement at the ALICE Grid computing sites is determined by heuristic algorithms. Optimisation of the data storage could yield substantial benefits in terms of efficiency and time-to-result. This has however proven to be arduous due to the complexity of the problem. In this work we propose a modelisation of the behaviour of the system via principal component analysis, time series analysis and deep learning, starting from the detailed data collected by the MonALISA monitoring system. We show that it is possible to analyse and model the throughput of the ALICE Grid to a level that has not been possible before, comparing the performance of different deep learning architectures based on recurrent neural networks. Analyzing about six weeks of activity, the Grid I/O throughput trend is successfully predicted with a mean relative error of 4%, while the prediction of the throughput itself performs at 5%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1742-6596/2438/1/012059"
    },
    {
        "id": 4295,
        "title": "The Detection of State of Mental Health using Recurrent Neural Networks",
        "authors": "N. Moganarangan -, D. Rajesh -, B. Srivishnu -, S. Mithunkumar -, R. Praveenkumar -",
        "published": "2023-3-15",
        "citations": 0,
        "abstract": "In the recent days, the number of people affected by Mental Depression Disorder (MDD) is on the rise with age, occupation related stress levels and several other factors. Depression has been identified as the main cause behind various diseases in individuals. In most cases, mental depression disorder is diagnosed with the help of counselling given by psychiatrists. However, even after the counselling and clinical diagnosis, the symptoms of depression persist. Social stigma associated with depression results in reluctance on the part of individuals to consult psychiatrists to diagnose mental illness. Also the existing techniques or methods do not guarantee accurate prediction of the level of depression. In order to overcome these problems, a new emotional model is designed to analyze the depression in individuals. A set of questionnaires called Personal Survey Questionnaire (PSQ) is framed to collect responses from the tweeters to understand about their mindset and depression level. Based on the PSQ answers, E-Ranking is calculated and compared with the polarity value generated by the PSQ answers. The performance of the proposed questionnaire-based model is compared with seven existing model based on parameters such as estimate and P-Value.\n         Finally, the Recurrent Neural Network (RNN) is combined with Rule Based model (RB) to define the level and symptoms of depression. The blended RNN is compared with NLP process (Nature Language Processing) and it is proved that the Hybrid RNN and RB models give the best classification model for depression analysis.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36948/ijfmr.2023.v05i02.1769"
    },
    {
        "id": 4296,
        "title": "An Empirical Generation Technique on Background Music Using Gated Recurrent Neural Networks",
        "authors": "Varinya Phanichraksaphong, Wei-Ho Tsai",
        "published": "2023-7-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icce-taiwan58799.2023.10227055"
    },
    {
        "id": 4297,
        "title": "Conditional recurrent neural networks for broad applications in nonlinear optics",
        "authors": "Simone Lauria, Mohammed F. Saleh",
        "published": "2024-2-12",
        "citations": 0,
        "abstract": "We present a novel implementation of conditional long short-term memory recurrent neural networks that successfully predict the spectral evolution of a pulse in nonlinear periodically-poled waveguides. The developed networks offer large flexibility by allowing the propagation of optical pulses with ranges of energies and temporal widths in waveguides with different poling periods. The results show very high agreement with the traditional numerical models. Moreover, we are able to use a single network to calculate both the real and imaginary parts of the pulse complex envelope, allowing for successfully retrieving the pulse temporal and spectral evolution using the same network.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1364/oe.506519"
    },
    {
        "id": 4298,
        "title": "Soft Continuum Actuator Tip Position and Contact Force Prediction, Using Electrical Impedance Tomography and Recurrent Neural Networks",
        "authors": "Amirhosein Alian, George Mylonas, James Avery",
        "published": "2023-4-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/robosoft55895.2023.10121967"
    },
    {
        "id": 4299,
        "title": "Announcement of the Neural Networks Best Paper Award",
        "authors": "",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s0893-6080(23)00714-1"
    },
    {
        "id": 4300,
        "title": "Mapping prediction with recurrent neural networks for future LISP enabled networks",
        "authors": "Yue Li, Shuai Guo, Qipeng Song, Yao Wang, Xiaomin Wei, Jianfeng Ma",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jiixd.2023.04.003"
    },
    {
        "id": 4301,
        "title": "A recurrent Hopfield network for estimating meso-scale effective connectivity in MEG",
        "authors": "Giorgio Gosti, Edoardo Milanetti, Viola Folli, Francesco de Pasquale, Marco Leonetti, Maurizio Corbetta, Giancarlo Ruocco, Stefania Della Penna",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.11.027"
    },
    {
        "id": 4302,
        "title": "Retracted: Recurrent Neural Networks for Feature Extraction from Dengue Fever",
        "authors": "",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9823890"
    },
    {
        "id": 4303,
        "title": "Automatic tuning of PID controllers using deep recurrent neural networks with pruning based on tracking error",
        "authors": "Aghil Ahmadi, Reza Mahboobi Esfanjani",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "Abstract\nAlthough PID controllers are common in industry, they are\n  often poorly tuned; especially, in uncertain environments. Modern\n  industries, with increasing complexity, motivate us to employ new\n  intelligent methods in order to extend PID controllers beyond their\n  usual capabilities. In this paper, an advanced machine learning\n  scheme is utilized to improve PID controllers; for the first time, a\n  deep dynamic neural network is employed to tune online the\n  parameters of the traditional PID controller in order to overcome\n  the effects of uncertainties in the closed-loop control system. To\n  reduce the computational burden of deep recurrent neural network, a\n  novel structural learning technique is applied to optimize the\n  configuration. Unlike existing pruning methods, the network is\n  pruned based on the values of neurons and the total value of the\n  corresponding layer. Simulation of a benchmark CSTR system\n  demonstrate that the proposed scheme performs more efficiently\n  compared to a shallow network tuner, in the presence of\n  uncertainties.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1748-0221/19/02/p02028"
    },
    {
        "id": 4304,
        "title": "Validated Computation of Lipschitz Constant of Recurrent Neural Networks",
        "authors": "Yuhua Guo, Yiran Li, Amin Farjudian",
        "published": "2023-1-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3583788.3583795"
    }
]