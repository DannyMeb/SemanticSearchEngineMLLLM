[
    {
        "id": 5301,
        "title": "Modellierung zwischen „overfitting“ und „underfitting“",
        "authors": "Michael Brzoska",
        "published": "2018-12-17",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110600261-016"
    },
    {
        "id": 5302,
        "title": "Optimizing Convolutional Neural Network Performance by Mitigating Underfitting and Overfitting",
        "authors": "Qipei Li, Ming Yan, Jie Xu",
        "published": "2021-6-23",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icis51600.2021.9516868"
    },
    {
        "id": 5303,
        "title": "Overfitting and Underfitting Analysis for Deep Learning Based End-to-end Communication Systems",
        "authors": "Haotian Zhang, Lin Zhang, Yuan Jiang",
        "published": "2019-10",
        "citations": 48,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wcsp.2019.8927876"
    },
    {
        "id": 5304,
        "title": "ANALISA TERJADINYA OVERFITTING DAN UNDERFITTING PADA ALGORITMA NAIVE BAYES DAN DECISION TREE DENGAN TEKNIK CROSS VALIDATION",
        "authors": "Wildan Attariq Firmansyach, Umi Hayati, Yudhistira Arie Wijaya",
        "published": "2023-2-26",
        "citations": 0,
        "abstract": "Perkembangan digital dapat meringankan aktivitas manusia dalam menggunakan, serta mengelola informasi. Suatu informasi berdasarkan kumpulan data dengan dilakukannya proses data mining. Banyak masalah yang terjadi pada data mining dikarenakan hasil yang diperoleh dipengaruhi oleh adanya ketidak seimbangan data sehingga terjadinya overfitting dan underfitting biasanya disebabkan oleh data yang berlebihan atau data yang kurang sehingga model yang dihasilkan tidak dapat menangkap pola dari data yang digunakan. Tujuan dari penelitian ini mendapatkan hasil akurasi terbaik melalui perbandingan yang diperoleh supaya tidak terjadinya overfitting dan underfitting dalam hasil akurasi, untuk mengimplementasikan hasil akurasi darimachine learning meningkatkan kepastian dan menunjukan hasil keputusan, menggunakan data sampel Status Kelulusan Siswa SMA Jurusan IPA Jalur SNMPTN Di Indonesia yang dihimpun dari periode tahun 2022, data berjumlah 4.030 data dan 10 atribut. Metode yang digunakan untuk mendapatkan hasil evaluasi terbaik menggunakan algoritma Naïve Bayes dan Decision Tree dengan teknik Cross Validation. Hasil dari penelitian ini yaitu algoritma Naive Bayes mendapatkan skor akurasi sebesar 63%, serta algoritma Decision Tree mendapatkan skor akurasi sebesar 96%, dengan hasil skor akurasi yang diperoleh algoritma terbaik yaitu Decision Tree dengan menggunakan teknikValidasi silang.",
        "link": "http://dx.doi.org/10.36040/jati.v7i1.6329"
    },
    {
        "id": 5305,
        "title": "Determining overfitting and underfitting in generative adversarial networks using Fréchet distance",
        "authors": "ENES EKEN",
        "published": "2021-5-31",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3906/elk-2006-143"
    },
    {
        "id": 5306,
        "title": "Preventing Model Overfitting and Underfitting in Convolutional Neural Networks",
        "authors": "Andrei Dmitri Gavrilov, Alex Jordache, Maya Vasdani, Jack Deng",
        "published": "2018-10",
        "citations": 59,
        "abstract": "The current discourse in the machine learning domain converges to the agreement that machine learning methods emerged as some of the most prominent learning and classification approaches over the past decade. The CNN became one of most actively researched and broadly-applied deep machine learning methods. However, the training set has a large influence on the accuracy of a network and it is paramount to create an architecture that supports its maximum training and recognition performance. The problem considered in this article is how to prevent overfitting and underfitting. The deficiencies are addressed by comparing the statistics of CNN image recognition algorithms to the Ising model. Using a two-dimensional square-lattice array, the impact that the learning rate and regularization rate parameters have on the adaptability of CNNs for image classification are evaluated. The obtained results contribute to a better theoretical understanding of a CNN and provide concrete guidance on preventing model overfitting and underfitting when a CNN is applied for image recognition tasks.",
        "link": "http://dx.doi.org/10.4018/ijssci.2018100102"
    },
    {
        "id": 5307,
        "title": "Analysis of Underfitting and Overfitting in U-Net Semantic Segmentation for Lung Nodule Identification from X-ray Radiographs",
        "authors": "Tehreem Awan, Khan Bahadar Khan",
        "published": "2023-1-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icest56843.2023.10138850"
    },
    {
        "id": 5308,
        "title": "An Optimal Solution to the Overfitting and Underfitting Problem of Healthcare Machine Learning Models",
        "authors": "Anil Kumar Prajapati Anil, Umesh Kumar Singh",
        "published": "2023-10-3",
        "citations": 2,
        "abstract": "In the current technological era, artificial intelligence is becoming increasingly popular.  Machine learning, as the branch of AI is taking charge in every field such as healthcare, the Stock market, Automation, Robotics, Image Processing, and so on. In the current scenario, machine learning and/or deep learning are becoming very popular in medical science for disease prediction. Much research is underway in the form of disease prediction models by machine learning. To ensure the performance and accuracy of the machine learning model, it is important to keep some basic things in mind during training. The machine learning model has several issues which must be rectified duration of the training of the model so that the learning model works efficiently such as model selection, parameter tuning, dataset splitting, cross-validation, bias-variance tradeoff, overfitting, underfitting, and so on. Under- and over-fitting are the two main issues that affect machine learning models. This research paper mainly focuses on minimizing and/or preventing the problem of overfitting and underfitting machine learning models.",
        "link": "http://dx.doi.org/10.29207/joseit.v2i2.5460"
    },
    {
        "id": 5309,
        "title": "Overfitting, Underfitting and General Model Overconfidence and Under-Performance Pitfalls and Best Practices in Machine Learning and AI",
        "authors": "Constantin Aliferis, Gyorgy Simon",
        "published": "2024",
        "citations": 0,
        "abstract": "AbstractAvoiding over and under fitted analyses (OF, UF) and models is critical for ensuring as high generalization performance as possible and is of profound importance for the success of ML/AI modeling. In modern ML/AI practice OF/UF are typically interacting with error estimator procedures and model selection, as well as with sampling and reporting biases and thus need be considered together in context. The more general situations of over confidence (OC) about models and/or under-performing (UP) models can occur in many subtle and not so subtle ways especially in the presence of high-dimensional data, modest or small sample sizes, powerful learners and imperfect data designs. Because over/under confidence about models are closely related to model complexity, model selection, error estimation and sampling (as part of data design) we connect these concepts with the material of chapters “An Appraisal and Operating Characteristics of Major ML Methods Applicable in Healthcare and Health Science,” “Data Design,” and “Evaluation”. These concepts are also closely related to statistical significance and scientific reproducibility. We examine several common scenarios where over confidence in model performance and/or model under performance occur as well as detailed practices for preventing, testing and correcting them.",
        "link": "http://dx.doi.org/10.1007/978-3-031-39355-6_10"
    },
    {
        "id": 5310,
        "title": "Development of Overfitting and Underfitting Education Program for the Expanded Exploration of Machine Learning",
        "authors": "Yuri Hwang,  , Namje Park",
        "published": "2023-4-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14352/jkaie.2023.27.2.107"
    },
    {
        "id": 5311,
        "title": "Addressing overfitting and underfitting in Gaussian model-based clustering",
        "authors": "Jeffrey L. Andrews",
        "published": "2018-11",
        "citations": 23,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.csda.2018.05.015"
    },
    {
        "id": 5312,
        "title": "An Information-Theoretic Perspective on Overfitting and Underfitting",
        "authors": "Daniel Bashir, George D. Montañez, Sonia Sehra, Pedro Sandoval Segura, Julius Lauw",
        "published": "2020",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-64984-5_27"
    },
    {
        "id": 5313,
        "title": "Underfitting",
        "authors": "Andrew Murphy, Dimitrios Toumpanakis",
        "published": "2021-4-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.53347/rid-88650"
    },
    {
        "id": 5314,
        "title": "4 Underfitting",
        "authors": "",
        "published": "2021-3-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110671124-004"
    },
    {
        "id": 5315,
        "title": "overfitting, n.",
        "authors": "",
        "published": "2023-3-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/oed/3633056257"
    },
    {
        "id": 5316,
        "title": "Overfitting (diagram)",
        "authors": "Francis Fortin, Candace Moore",
        "published": "2019-4-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.53347/rid-67693"
    },
    {
        "id": 5317,
        "title": "Underfitting of a Calibration Model",
        "authors": "David B. Hibbert",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/iupac.88.0146"
    },
    {
        "id": 5318,
        "title": "Overfitting",
        "authors": "Andrew Murphy, Candace Moore",
        "published": "2019-4-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.53347/rid-67692"
    },
    {
        "id": 5319,
        "title": "Deep Learning in Python: Preventing Overfitting",
        "authors": "",
        "published": "2019",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4135/9781526493453"
    },
    {
        "id": 5320,
        "title": "Linguistic overfitting in empirical psychology",
        "authors": "Travis Riddle",
        "published": "No Date",
        "citations": 2,
        "abstract": "Recent controversies in psychology have highlighted disagreements about how science works and how science proceeds. Despite the existence of tools and data that can help to address some of these disagreements, psychologists have been slow to provide empirical evidence that speaks to these issues. Indeed, there is essentially no work on how scientists communicate their findings. In this paper, I use language from scientific literature to answer questions about scientific behavior. Specifically, I find that features of data analysis practices to be associated with two narrative features of these manuscripts -- hedging (diminishing claims) and boosting (amplifying claims). The use of hedging and boosting were found to be associated with statistical errors. Hedging and boosting were also found to be associated with and statistical overfitting, though this relationship is more uncertain. Additionally male first-authors are less likely to hedge. No other characteristics of the author were found to be associated with these linguistics features. Though the work is exploratory, the results are largely consistent with a linguistic overfitting hypothesis, in which the authors of a paper use language to amplify and diminish findings in a paper in order to create a more compelling narrative around theory. The flexibility of language is a powerful tool used to communicate research, but there is a fine line between effective interpretation of data and convenient overinterpretation, and it is worthwhile to be cognizant of when that line may be crossed.",
        "link": "http://dx.doi.org/10.31234/osf.io/qasde"
    },
    {
        "id": 5321,
        "title": "Texture Underfitting for Domain Adaptation",
        "authors": "Jan-Nico Zaech, Dengxin Dai, Martin Hahner, Luc Van Gool",
        "published": "2019-10",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/itsc.2019.8917059"
    },
    {
        "id": 5322,
        "title": "Overfitting",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4135/9781071812082.n423"
    },
    {
        "id": 5323,
        "title": "Undecidability of Underfitting in Learning Algorithms",
        "authors": "Sonia Sehra, David Flores, George D. Montanez",
        "published": "2021-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cds52072.2021.00107"
    },
    {
        "id": 5324,
        "title": "Why is the prediction wrong? Towards underfitting case explanation via meta-classification",
        "authors": "Sheng Zhou, Pierre Blanchart, Michel Crucianu, Marin Ferecatu",
        "published": "2022-10-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dsaa54385.2022.10032332"
    },
    {
        "id": 5325,
        "title": "Mechanism of Overfitting Avoidance Techniques for Training Deep Neural Networks",
        "authors": "Bihi Sabiri, Bouchra El Asri, Maryem Rhanoui",
        "published": "2022",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011114900003179"
    },
    {
        "id": 5326,
        "title": "Overfitting in Portfolio Optimization",
        "authors": "Matteo Maggiolo, Oleg Szehr",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4483959"
    },
    {
        "id": 5327,
        "title": "Overfitting",
        "authors": "Geoffrey I. Webb",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_960"
    },
    {
        "id": 5328,
        "title": "Overoptimism and Overfitting",
        "authors": "Steven E. Pav",
        "published": "2021-8-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003181057-10"
    },
    {
        "id": 5329,
        "title": "8 Overfitting",
        "authors": "",
        "published": "2021-3-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110671124-008"
    },
    {
        "id": 5330,
        "title": "Dealing with Overfitting in the Context of Liveness Detection Using FeatherNets with RGB Images",
        "authors": "Miguel Leão, Nuno Gonçalves",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011639600003411"
    },
    {
        "id": 5331,
        "title": "A Bayesian Approach to Backtest Overfitting",
        "authors": "Jiri Witzany",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3002503"
    },
    {
        "id": 5332,
        "title": "Gradient Masking Is a Type of Overfitting",
        "authors": "Yusuke Yanagita,  , Masayuki Yamamura",
        "published": "2018-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18178/ijmlc.2018.8.3.688"
    },
    {
        "id": 5333,
        "title": "Deep Patient Motion Estimation: Pretraining, Overfitting, or Pretraining and Overfitting?",
        "authors": "T. J. Herbst, J. Maier, M. Arheit, P. Paysan, M. Kachelrieß",
        "published": "2023-11-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/nssmicrtsd49126.2023.10338388"
    },
    {
        "id": 5334,
        "title": "Overfitting in propensity score model: a commentary on “propensity score model overfitting led to inflated variance of estimated odds ratios” by Schuster et al.",
        "authors": "David Hajage, Florence Tubach, Yann De Rycke",
        "published": "2017-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jclinepi.2017.05.011"
    },
    {
        "id": 5335,
        "title": "Overfitting",
        "authors": "Yigit Aydede",
        "published": "2023-8-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003381501-5"
    },
    {
        "id": 5336,
        "title": "A Bayesian Approach to Measurement of Backtest Overfitting",
        "authors": "Jiří Witzany",
        "published": "2021-1-8",
        "citations": 0,
        "abstract": "Quantitative investment strategies are often selected from a broad class of candidate models estimated and tested on historical data. Standard statistical techniques to prevent model overfitting such as out-sample backtesting turn out to be unreliable in situations when the selection is based on results of too many models tested on the holdout sample. There is an ongoing discussion of how to estimate the probability of backtest overfitting and adjust the expected performance indicators such as the Sharpe ratio in order to reflect properly the effect of multiple testing. We propose a consistent Bayesian approach that yields the desired robust estimates on the basis of a Markov chain Monte Carlo (MCMC) simulation. The approach is tested on a class of technical trading strategies where a seemingly profitable strategy can be selected in the naïve approach.",
        "link": "http://dx.doi.org/10.3390/risks9010018"
    },
    {
        "id": 5337,
        "title": "Limiting Machine Learning Overfitting Uncertainties Through Persistent Homology",
        "authors": "Kyle Haas",
        "published": "2020-5-20",
        "citations": 0,
        "abstract": "Abstract\nMachine learning techniques are powerful predictive tools that continue to gain prominence with increasingly available computational power. Engineering design professionals often view machine learning tools through a skeptical lens due to their perceived detachment from the underlying physics. Machine learning tools, such as artificial neural networks and regression models, are fueled by training data, obtained either analytically or through physical collection, the use of such surrogate models introduces an additional source of uncertainty. Sources of uncertainty associated with machine learning models can originate from the collected data or from the training process itself. Validation and verification methods are especially important for machine learning applications due to their perceived disconnect from underlying physics, sensitivity to data accumulation uncertainties, and potential for under or over training the model itself. Despite all of these potential pitfalls, sufficient testing of machine learning models against segregated testing data and use of regularization tools to diagnose overfitting is not always employed by industry practioners. This paper will illustrate the use of topological data analysis (TDA), specifically persistent homology, a subset of algebraic topology, as an alternative means to achieve generalization of a predictive manifold produced through a machine learning model. Persistent homology will be used to seek out and identify the most meaningful and connected components within the data that forms the predicted manifold, with less connected components treated as noise to be disregarded. Therefore, the uncertainties associated with overfitting can be limited. The proposed method will be demonstrated through its application to a simple single-degree-of-freedom structural system to demonstrate its effectiveness in generalizing the resulting manifold and limiting the associated uncertainty.",
        "link": "http://dx.doi.org/10.1115/vvs2020-8833"
    },
    {
        "id": 5338,
        "title": "Overfitting: Causes and Solutions (Seminar Slides)",
        "authors": "Marcos López de Prado",
        "published": "No Date",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3544431"
    },
    {
        "id": 5339,
        "title": "Model Parsimony and Overfitting",
        "authors": "Norman Matloff",
        "published": "2019-6-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780429401862-16"
    },
    {
        "id": 5340,
        "title": "Regularizers to the Rescue: Fighting Overfitting in DeepLearning-based Side-channel Analysis",
        "authors": "Azade Rezaeezade, Lejla Batina",
        "published": "No Date",
        "citations": 2,
        "abstract": "Abstract\nDespite considerable achievements of deep learning-based side-channel analysis, overfitting represents a significant obstacle in finding optimized neural network models. This issue is not unique to the side-channel domain. Regularization techniques are popular solutions to overfitting and have long been used in various domains. At the same time, the works in the side-channel domain show sporadic utilization of regularization techniques. What is more, no systematic study investigates these techniques’ effectiveness. In this paper, we aim to investigate the regularization effectiveness by applying four powerful and easy-to-use regularization techniques to six combinations of datasets, leakage models, and deep-learning topologies. The investigated techniques are L1, L2, dropout, and early stopping. Our results show that while all these techniques can improve performance in many cases, L1 and L2 are the most effective. Finally, if training time matters, early stopping is the best technique to choose.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2386625/v1"
    },
    {
        "id": 5341,
        "title": "Benign overfitting of fully connected Deep Nets:A Sobolev space viewpoint",
        "authors": "Stephane Chretien, Emmanuel Caron-Parte",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14428/esann/2021.es2021-37"
    },
    {
        "id": 5342,
        "title": "Why Overfitting is Not (Usually) a Problem in Partial Correlation Networks",
        "authors": "Donald Ray Williams, Josue E. Rodriguez",
        "published": "No Date",
        "citations": 1,
        "abstract": "Network psychometrics is undergoing a time of methodological reflection. In part, this was spurred by the revelation that l1-regularization does not reduce spurious associations in partial correlation networks. In this work, we address another motivation for the widespread use of regularized estimation: the thought that it is needed to mitigate overfitting. We first clarify important aspects of overfitting and the bias-variance tradeoff that are especially relevant for the network literature, where the number of nodes or items in a psychometric scale are not largecompared to the number of observations (i.e., a low p/n ratio). This revealed that bias and especially variance are most problematic in p=n ratios rarely encountered. We then introduce a nonregularized method, based on classical hypothesis testing, that fulfills two desiderata: (1) reducing or controlling the false positives rate and (2) quelling concerns of overfitting by providing accurate predictions. These were the primary motivations for initially adopting the graphical lasso (glasso). In several simulation studies, our nonregularized method provided more than competitive predictive performance, and, in many cases, outperformed glasso. Itappears to be nonregularized, as opposed to regularized estimation, that best satisfies these desiderata. We then provide insights into using our methodology. Here we discuss the multiple comparisons problem in relation to prediction: stringent alpha levels, resulting in a sparse network, can deteriorate predictive accuracy. We end by emphasizing key advantages of our approach that make it ideal for both inference and prediction in network analysis.",
        "link": "http://dx.doi.org/10.31234/osf.io/8pr9b"
    },
    {
        "id": 5343,
        "title": "Overfitting and Regularization",
        "authors": "",
        "published": "2022-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811254185_0014"
    },
    {
        "id": 5344,
        "title": "Generalization despite overfitting in quantum machine learning models",
        "authors": "Evan Peters, Maria Schuld",
        "published": "2023-12-20",
        "citations": 3,
        "abstract": "The widespread success of deep neural networks has revealed a surprise in classical machine learning: very complex models often generalize well while simultaneously overfitting training data. This phenomenon of benign overfitting has been studied for a variety of classical models with the goal of better understanding the mechanisms behind deep learning. Characterizing the phenomenon in the context of quantum machine learning might similarly improve our understanding of the relationship between overfitting, overparameterization, and generalization. In this work, we provide a characterization of benign overfitting in quantum models. To do this, we derive the behavior of a classical interpolating Fourier features models for regression on noisy signals, and show how a class of quantum models exhibits analogous features, thereby linking the structure of quantum circuits (such as data-encoding and state preparation operations) to overparameterization and overfitting in quantum models. We intuitively explain these features according to the ability of the quantum model to interpolate noisy data with locally \"spiky\" behavior and provide a concrete demonstration example of benign overfitting.",
        "link": "http://dx.doi.org/10.22331/q-2023-12-20-1210"
    },
    {
        "id": 5345,
        "title": "A Dropout Optimization Algorithm to Prevent Overfitting in Machine Learning",
        "authors": "",
        "published": "2023-3-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.38007/ml.2023.040103"
    },
    {
        "id": 5346,
        "title": "Overfitting in portfolio optimization",
        "authors": "Matteo Maggiolo, Oleg Szehr",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21314/jrmv.2023.005"
    },
    {
        "id": 5347,
        "title": "Towards Addressing the Patch Overfitting Problem",
        "authors": "Qi Xin",
        "published": "2017-5",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icse-c.2017.42"
    },
    {
        "id": 5348,
        "title": "Overfitting, Regularization, and Information Criteria",
        "authors": "Richard McElreath",
        "published": "2018-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315372495-6"
    },
    {
        "id": 5349,
        "title": "Exploring Robust Overfitting for Pre-trained Language Models",
        "authors": "Bin Zhu, Yanghui Rao",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.340"
    },
    {
        "id": 5350,
        "title": "Controlling the Overfitting of Heritability in Genomic Selection through Cross Validation",
        "authors": "Zhenyu Jia",
        "published": "2017-10-20",
        "citations": 21,
        "abstract": "AbstractIn genomic selection (GS), all the markers across the entire genome are used to conduct marker-assisted selection such that each quantitative trait locus of complex trait is in linkage disequilibrium with at least one marker. Although GS improves estimated breeding values and genetic gain, in most GS models genetic variance is estimated from training samples with many trait-irrelevant markers, which leads to severe overfitting in the calculation of trait heritability. In this study, we demonstrated overfitting heritability due to the inclusion of trait-irrelevant markers using a series of simulations, and such overfitting can be effectively controlled by cross validation experiment. In the proposed method, the genetic variance is simply the variance of the genetic values predicted through cross validation, the residual variance is the variance of the differences between the observed phenotypic values and the predicted genetic values, and these two resultant variance components are used for calculating the unbiased heritability. We also demonstrated that the heritability calculated through cross validation is equivalent to trait predictability, which objectively reflects the applicability of the GS models. The proposed method can be implemented with the Mixed Procedure in SAS or with our R package “GSMX” which is publically available at https://cran.r-project.org/web/packages/GSMX/index.html.",
        "link": "http://dx.doi.org/10.1038/s41598-017-14070-z"
    },
    {
        "id": 5351,
        "title": "Fine-tuning is not (always) overfitting artifacts",
        "authors": "Jérémie Bogaert, Emmanuel Jean, Cyril de Bodt, François-Xavier Standaert",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14428/esann/2023.es2023-152"
    },
    {
        "id": 5352,
        "title": "Specification Overfitting in Artificial Intelligence",
        "authors": "Benjamin Roth, Pedro Henrique Luz de Araujo, Yuxi Xia, Saskia Kaltenbrunner, Christoph Korab",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nMachine learning (ML) and artificial intelligence (AI) approaches are often criticized for their inherent bias and for their lack of control, accountability, and transparency. Consequently, regulatory bodies struggle with containing this technology's potential negative side effects. High-level requirements such as fairness and robustness need to be formalized into concrete specification metrics, imperfect proxies that capture isolated aspects of the underlying requirements. Given possible trade-offs between different metrics and their vulnerability to over-optimization, integrating specification metrics in system development processes is not trivial. This paper defines specification overfitting, a scenario where systems focus excessively on specified metrics to the detriment of high-level requirements and task performance. We present an extensive literature survey to categorize how researchers propose, measure, and optimize specification metrics in several AI fields (e.g., natural language processing, computer vision, reinforcement learning). Using a keyword-based search on papers from major AI conferences and journals between 2018 and mid-2023, we identify and analyze 74 papers that propose or optimize specification metrics. We find that although most papers implicitly address specification overfitting (e.g., by reporting more than one specification metric), they rarely discuss which role specification metrics should play in system development or explicitly define the scope and assumptions behind metric formulations.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-4106577/v1"
    },
    {
        "id": 5353,
        "title": "Why Does My Zestimate Fluctuate? Model Overfitting for Platform Ad Revenue",
        "authors": "Nikhil Malik, Runshan Fu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4403371"
    },
    {
        "id": 5354,
        "title": "A Practical Significant Technic in Solving Overfitting: Regularization",
        "authors": "Muyuan Li",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "The passage mainly discusses the solution to overfitting. Overfitting usually happens when people are training their machine learning models. When a model is overfitted, it only fits one particular dataset and misses most of the data points from another dataset. This problem affects the model's performance and makes it unable to use for its purpose. So how to solve this problem with significance and practical meaning? At the beginning of the passage, I will introduce some theoretical foundations for overfitting. Then I will define the concept of overfitting and show an example of overfitting in the machine learning model. After that, I will tell you how to pick the correct model with the testing set. Then, the passage focuses on the discussion of regularization, which is a helpful technique for solving overfitting. And I will compare the L1 and l2 regularization to help you find the suitable one.",
        "link": "http://dx.doi.org/10.54254/2753-8818/5/20230433"
    },
    {
        "id": 5355,
        "title": "Less is More? Reducing Biases and Overfitting in Machine Learning Return Predictions",
        "authors": "Clint Howard",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4497739"
    },
    {
        "id": 5356,
        "title": "Overfitting of a Calibration Model",
        "authors": "David B. Hibbert",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/iupac.88.0141"
    },
    {
        "id": 5357,
        "title": "Overfitting in Four-Layer-DNN-Based Nonlinear Equalizer for Optical Communication Systems",
        "authors": "Jinya Nakamura, Kai Ikuta, Moriya Nakamura",
        "published": "2021",
        "citations": 0,
        "abstract": "We compared overfitting in four-layer-DNN- and three-layer-ANN-based nonlinear equalizers used for nonlinearity compensation in optical communication systems. The results showed that the DNN-based nonlinear equalizer had stronger overfitting characteristics for both PRBS and a random sequence.",
        "link": "http://dx.doi.org/10.1364/oecc.2021.js2b.10"
    },
    {
        "id": 5358,
        "title": "Data adjustments, overfitting and representativeness",
        "authors": "Keith Ord",
        "published": "2020-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ijforecast.2019.02.014"
    },
    {
        "id": 5359,
        "title": "Alleviating overfitting for polysemous words for word representation estimation using lexicons",
        "authors": "Yuanzhi Ke, Masafumi Hagiwara",
        "published": "2017-5",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2017.7966117"
    },
    {
        "id": 5360,
        "title": "Interactions of Genetic and Environment Scores: Alternating Lasso Regularization Avoids Overfitting and Finds Interpretable Scores",
        "authors": "Philipp Doebler, Anna Doebler, Philip Buczak, Andreas Groll",
        "published": "No Date",
        "citations": 0,
        "abstract": "Regression models with interaction terms are common models for moderating relationships. When several predictors from one group, e.g., genetic variables, are potentially moderated by several predictors from another, e.g., environmental variables, many interaction terms result. This complicates model interpretation, especially when coefficient signs point in different directions. By first forming a score for each group of predictors, the interaction model's dimension is severely reduced. The hierarchical score model is an elegant one step approach: Score weights and regression model coefficients are estimated simultaneously by an alternating optimization (AO) algorithm. Especially in high dimensional settings, scores remain an effective technique to reduce interaction model dimension, and we propose regularization to ensure sparsity and interpretability of the score weights. A non-trivial extension of the original AO algorithm is presented, which adds a lasso  penalty, resulting in the alternating lasso optimization algorithm (ALOA). The hierarchical score model with ALOA is an interpretable statistical learning technique for moderation in potentially high dimensional applications, and encompasses generalized linear models for the main interaction model. In addition to the lasso regularization, a screening procedure called regularization and residualization (RR) is proposed to avoid spurious interactions. ALOA tuning parameter choice and the RR screening procedure are investigated by simulations, and an illustrative application to lifetime depression risk and gene x environment interactions is provided.",
        "link": "http://dx.doi.org/10.31234/osf.io/7k8xz"
    },
    {
        "id": 5361,
        "title": "Overfitting in Judgment-Based Economic Forecasts: The Case of IMF Growth Projections",
        "authors": "Klaus-Peter Hellwig",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3314593"
    },
    {
        "id": 5362,
        "title": "Robustness And Overfitting Behavior Of Implicit Background Models",
        "authors": "Shirley Liu, Charles Lehman, Ghassan AlRegib",
        "published": "2020-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icip40778.2020.9191361"
    },
    {
        "id": 5363,
        "title": "A geometrical viewpoint on the benign overfitting property of the minimum ℓ 2 -norm interpolant estimator and its universality",
        "authors": "Guillaume Lecué, Zong Shang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIn the linear regression model, the minimum ℓ 2-norm interpolant estimatorˆβestimatorˆ estimatorˆβ has received much attention since it was proved to be consistent even though it fits noisy data perfectly under some condition on the covariance matrix Σ of the input vector, known as benign overfitting. Motivated by this phenomenon, we study the generalization property of this estimator from a geometrical viewpoint. Our main results extend and improve the convergence rates as well as the deviation probability from [44]. Our proof differs from the classical bias/variance analysis and is based on the self-induced regularization property introduced in [3]: ˆ β can be written as a sum of a ridge estimatorˆβestimatorˆ estimatorˆβ 1:k and an overfitting componentˆβcomponentˆ componentˆβ k+1:p which follows a decomposition of the features space R p = V 1:k ⊕ ⊥ V k+1:p into the space V 1:k spanned by the top k eigenvectors of Σ and V k+1:p spanned by the p − k last ones. We also prove a matching lower bound for the expected prediction risk thus obtain the sufficient and necessary conditions for benign overfitting ofˆβofˆ ofˆβ. The two geometrical properties of random Gaussian matrices at the heart of our analysis are the Dvoretsky-Milman theorem and isomorphic and restricted isomorphic properties. In particular, the Dvoretsky dimension appearing naturally in our geometrical viewpoint, coincides with the effective rank from [2, 44] and is the key tool for handling the behavior of the design matrix restricted to the sub-space V k+1:p where overfitting happens. \nWe extend these results to heavy-tailed scenarii proving the universality of this phenomenon beyond exponential moment assumptions. This phenomenon is unknown before and is widely believed to be a significant challenge. This follows from an anistropic version of the probabilistic Dvoretsky-Milman theorem that holds for heavy-tailed vectors which is of independent interest.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3376547/v1"
    },
    {
        "id": 5364,
        "title": "A Vibrating Mechanism to Prevent Neural Networks from Overfitting",
        "authors": "Jian Xiong, Kai Zhang, Hao Zhang",
        "published": "2019-6",
        "citations": 17,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iwcmc.2019.8766500"
    },
    {
        "id": 5365,
        "title": "Research Design and Overfitting",
        "authors": "Chittaranjan Andrade",
        "published": "2022-4-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4088/jcp.21lr14371a"
    },
    {
        "id": 5366,
        "title": "Hands-on training about overfitting",
        "authors": "Janez Demšar, Blaž Zupan",
        "published": "2021-3-4",
        "citations": 34,
        "abstract": "Overfitting is one of the critical problems in developing models by machine learning. With machine learning becoming an essential technology in computational biology, we must include training about overfitting in all courses that introduce this technology to students and practitioners. We here propose a hands-on training for overfitting that is suitable for introductory level courses and can be carried out on its own or embedded within any data science course. We use workflow-based design of machine learning pipelines, experimentation-based teaching, and hands-on approach that focuses on concepts rather than underlying mathematics. We here detail the data analysis workflows we use in training and motivate them from the viewpoint of teaching goals. Our proposed approach relies on Orange, an open-source data science toolbox that combines data visualization and machine learning, and that is tailored for education in machine learning and explorative data analysis.",
        "link": "http://dx.doi.org/10.1371/journal.pcbi.1008671"
    },
    {
        "id": 5367,
        "title": "Overfitting to ‘predict’ suicidal ideation",
        "authors": "Timothy Verstynen, Konrad Paul Kording",
        "published": "2023-4-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41562-023-01560-6"
    },
    {
        "id": 5368,
        "title": "Overfitting in Judgment-based Economic Forecasts: The Case of IMF Growth Projections",
        "authors": "Klaus-Peter Hellwig",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5089/9781484386187.001"
    },
    {
        "id": 5369,
        "title": "Avoiding Overfitting of Decision Trees",
        "authors": "Max Bramer",
        "published": "2020",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4471-7493-6_9"
    },
    {
        "id": 5370,
        "title": "Overfitting of CNN model in cifar-10: Problem and solutions",
        "authors": "Zhangjie Xia",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": "CNN, proposed by Yann LeCun in the 1980s, has gained high attention and extensive research from both the academia and the industry. It has proved to be useful in a wide variety of fields, including image recognition, which aims to enable the computer to identify different objects in digital images. Despite its usefulness, problems like overfitting occur during the training process of a CNN model, which seriously harm the effectiveness of the model. Firstly, an initial CNN model is built to accomplish image recognition based on data from cifar-10. Secondly, after the presence of overfitting during the training and validation of the initial model, 4 methods, including shallower model, L2 regularization, dropout, data augmentation, are proposed to see how they handle overfitting respectively, and comparisons are made between different methods. Thirdly, the last three methods are combined to see how they handle overfitting together. Finally, conclusion and possible future work are presented. As it turns out, L2 regularization, dropout and data augmentation all reduce overfitting with some slight differences, but shallower model and the combined method cause underfitting rather than overfitting.",
        "link": "http://dx.doi.org/10.54254/2755-2721/37/20230511"
    },
    {
        "id": 5371,
        "title": "Data Anonymisation, Outlier Detection and Fighting Overfitting with Restricted Boltzmann Machines",
        "authors": "Alexei Kondratyev, Christian Schwarz, Blanka Horvath",
        "published": "No Date",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3526436"
    },
    {
        "id": 5372,
        "title": "Making AdaBoost Less Prone to Overfitting on Noisy Datasets",
        "authors": "Zainab Ghadiri Modarres, Mahmood Shabankhah, Ali Kamandi",
        "published": "2020-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icwr49608.2020.9122292"
    },
    {
        "id": 5373,
        "title": "On overfitting and post-selection uncertainty assessments",
        "authors": "L Hong, T A Kuffner, R Martin",
        "published": "2018-3-1",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/biomet/asx083"
    },
    {
        "id": 5374,
        "title": "Automated Program Repair and Test Overfitting: Measurements and Approaches using Formal Methods",
        "authors": "Amirfarhad Nilizadeh",
        "published": "2022-4",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icst53961.2022.00061"
    },
    {
        "id": 5375,
        "title": "Homogeneous intrinsic neuronal excitability induces overfitting to sensory noise: A robot model of neurodevelopmental disorder",
        "authors": "Hayato Idei, Shingo Murata, Yuichi Yamashita, Tetsuya Ogata",
        "published": "No Date",
        "citations": 2,
        "abstract": "Neurodevelopmental disorders, including autism spectrum disorder, have been intensively investigated at the neural, cognitive, and behavioral levels, but the accumulated knowledge remains fragmented. Here, we propose a mechanistic explanation that unifies the disparate observations via a hierarchical predictive coding and developmental learning framework, which is demonstrated in experiments using a neural network-controlled robot. The results show that, through the developmental learning process, homogeneous intrinsic neuronal excitability at the neural level induced via self-organization changes at the information-processing level, such as hyper sensory precision and overfitting to sensory noise. These changes led to inflexibility, reduced generalization, and motor clumsiness at the behavioral level. These findings might bridge various levels of understandings in autism spectrum and other neurodevelopmental disorders and provide insights into the disease processes underlying observed behaviors and brain activities in individual patients. This study shows the potential of neurorobotics frameworks for modeling how psychiatric disorders arise from dynamic interactions among the brain, body, and uncertain environments.",
        "link": "http://dx.doi.org/10.31234/osf.io/ah89z"
    },
    {
        "id": 5376,
        "title": "On Overfitting in Discrete Super-Resolution Recovery",
        "authors": "Wenzhe Lu, Heng Qiao",
        "published": "2021-6-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp39728.2021.9415033"
    },
    {
        "id": 5377,
        "title": "Limited Discriminator GAN using explainable AI model for overfitting problem",
        "authors": "Jiha Kim, Hyunhee Park",
        "published": "2023-4",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.icte.2021.12.014"
    },
    {
        "id": 5378,
        "title": "Overfitting Measurement of Deep Neural Networks Using No Data",
        "authors": "Satoru Watanabe, Hayato Yamana",
        "published": "2021-10-6",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dsaa53316.2021.9564119"
    },
    {
        "id": 5379,
        "title": "Low Curvature Activations Reduce Overfitting in Adversarial Training",
        "authors": "Vasu Singla, Sahil Singla, Soheil Feizi, David Jacobs",
        "published": "2021-10",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv48922.2021.01611"
    },
    {
        "id": 5380,
        "title": "Anomaly detection with partitioning overfitting autoencoder ensembles",
        "authors": "Boris Lorbeer, Max Botler",
        "published": "2022-3-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2622453"
    },
    {
        "id": 5381,
        "title": "Research on Curve Fitting and Overfitting Based on Bayesian Method",
        "authors": "Chao Bu, Zengping Zhang",
        "published": "2021-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iscipt53667.2021.00035"
    },
    {
        "id": 5382,
        "title": "Benign Overfitting in Binary Classification of Gaussian Mixtures",
        "authors": "Ke Wang, Christos Thrampoulidis",
        "published": "2021-6-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp39728.2021.9413946"
    },
    {
        "id": 5383,
        "title": "An Overview of Overfitting and its Solutions",
        "authors": "Xue Ying",
        "published": "2019-2",
        "citations": 710,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1088/1742-6596/1168/2/022022"
    },
    {
        "id": 5384,
        "title": "Overfitting",
        "authors": "Liangqu Long, Xiangming Zeng",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-7915-1_9"
    },
    {
        "id": 5385,
        "title": "A Method to Identify Overfitting Program Repair Patches Based on Expression Tree",
        "authors": "Yukun Dong, Xiaotong Cheng, Yufei Yang, Lulu Zhang, Shuqi Wang, Lingjie Kong",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4476243"
    },
    {
        "id": 5386,
        "title": "Decision tree underfitting in mining of gene expression data. An evolutionary multi-test tree approach",
        "authors": "Marcin Czajkowski, Marek Kretowski",
        "published": "2019-12",
        "citations": 34,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.eswa.2019.07.019"
    },
    {
        "id": 5387,
        "title": "ADDRESSING OVERFITTING ISSUES IN THE SPARSE IDENTIFICATION OF NONLINEAR DYNAMICAL SYSTEMS",
        "authors": "Leonardo Santos de Brito Alves",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26678/abcm.encit2020.cit20-0646"
    },
    {
        "id": 5388,
        "title": "Training With Cache: Specializing Object Detectors From Live Streams Without Overfitting",
        "authors": "Hayato Itsumi, Florian Beye, Yusuke Shinohara, Takanori Iwai",
        "published": "2020-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icip40778.2020.9191312"
    },
    {
        "id": 5389,
        "title": "Measuring Overfitting in Convolutional Neural Networks using Adversarial Perturbations and Label Noise",
        "authors": "Svetlana Pavlitskaya, Joel Oswald, J. Marius Zollner",
        "published": "2022-12-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ssci51031.2022.10022094"
    },
    {
        "id": 5390,
        "title": "How “Backtest Overfitting” in Finance Leads to False Discoveries",
        "authors": "David H. Bailey, Marcos López de Prado",
        "published": "2021-12-1",
        "citations": 2,
        "abstract": "AbstractFinancial investment strategies are often designed and tested using historical market data. But this can frequently give rise to “optimal” strategies that are statistical mirages and perform poorly out in the real world, as David H. Bailey and Marcos López de Prado explain",
        "link": "http://dx.doi.org/10.1111/1740-9713.01588"
    },
    {
        "id": 5391,
        "title": "Preventing Overfitting of LSTMs using Ant Colony Optimization",
        "authors": "Rikitaka Kinoyama, Edgar Ademir Morales Perez, Hitoshi Iba",
        "published": "2021-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iiai-aai53430.2021.00061"
    },
    {
        "id": 5392,
        "title": "Overfitting of ANN-based Nonlinear Equalizer for Multilevel Signals in Optical Communication Systems",
        "authors": "Kai Ikuta, Yuta Otsuka, Moriya Nakamura",
        "published": "2020-10-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/oecc48412.2020.9273641"
    },
    {
        "id": 5393,
        "title": "A Chaotic Neuron and its Ability to Prevent Overfitting",
        "authors": "Xiu Chen, Yi Wang",
        "published": "2023-9-12",
        "citations": 0,
        "abstract": "Chaotic neuron is a neural model based on chaos theory, which combines the complex dynamic behavior of biological neurons with the characteristics of chaotic systems. Inspired by the chaotic firing characteristics of biological neurons, a novel chaotic neuron model and its response activation function LMCU are proposed in this paper. Based on one-dimensional chaotic mapping, this chaotic neuron model takes the emissivity of chaotic firing characteristics of biological neurons as its response output, so that it has the nonlinear response and chaotic characteristics of biological neurons. Different from the traditional neuron model, it makes full use of the nonlinear dynamics of the chaotic system to achieve the activation output. In this paper, we apply the proposed chaotic neurons to artificial neural networks by using LeNet-5 models on MNIST and CIFAR-10 datasets, and compare them with common activation functions. The application of chaotic neurons can effectively reduce the overfitting phenomenon of artificial neural network, significantly reduce the generalization error of the model, and greatly improve the overall performance of artificial neural network. The innovative design of this chaotic neuron model provides a new cornerstone for the future development of artificial neural networks.",
        "link": "http://dx.doi.org/10.54097/fcis.v5i1.11673"
    },
    {
        "id": 5394,
        "title": "Coping with Overfitting Problems of Image Caption Models for Service Robotics Applications",
        "authors": "Ren C. Luo, Hsien Chang Lin",
        "published": "2019-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icphys.2019.8780257"
    },
    {
        "id": 5395,
        "title": "Mitigating robust overfitting via self-residual-calibration regularization",
        "authors": "Hong Liu, Zhun Zhong, Nicu Sebe, Shin'ichi Satoh",
        "published": "2023-4",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.artint.2023.103877"
    },
    {
        "id": 5396,
        "title": "Understanding and combating robust overfitting via input loss landscape analysis and regularization",
        "authors": "Lin Li, Michael Spratling",
        "published": "2023-4",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patcog.2022.109229"
    },
    {
        "id": 5397,
        "title": "Overfitting Identification in Machine Learning Models with the Person-Fit Indicator",
        "authors": "Ruihang He, Yongze Xu",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icceic60201.2023.10426639"
    },
    {
        "id": 5398,
        "title": "Understanding artificial intelligence based radiology studies: What is overfitting?",
        "authors": "Simukayi Mutasa, Shawn Sun, Richard Ha",
        "published": "2020-9",
        "citations": 119,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.clinimag.2020.04.025"
    },
    {
        "id": 5399,
        "title": "Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting",
        "authors": "Samuel Yeom, Irene Giacomelli, Matt Fredrikson, Somesh Jha",
        "published": "2018-7",
        "citations": 329,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/csf.2018.00027"
    },
    {
        "id": 5400,
        "title": "Combining multiple data sources in species distribution models while accounting for spatial dependence and overfitting with combined penalised likelihood maximisation",
        "authors": "Ian W. Renner, Julie Louvrier, Olivier Gimenez",
        "published": "No Date",
        "citations": 2,
        "abstract": "SummaryThe increase in availability of species data sets means that approaches to species distribution modelling that incorporate multiple data sets are in greater demand. Recent methodological developments in this area have led to combined likelihood approaches, in which a log-likelihood comprised of the sum of the log-likelihood components of each data source is maximised. Often, these approaches make use of at least one presence-only data set and use the log-likelihood of an inhomogeneous Poisson point process model in the combined likelihood construction. While these advancements have been shown to improve predictive performance, they do not currently address challenges in presence-only modelling such as checking and correcting for violations of the independence assumption of a Poisson point process model or more general challenges in species distribution modelling such as overfitting.In this paper, we present an extension of the combined likelihood frame-work which accommodates alternative presence-only likelihoods in the presence of spatial dependence as well as lasso-type penalties to account for potential overfitting. We compare the proposed combined penalised likelihood approach to the standard combined likelihood approach via simulation and apply the method to modelling the distribution of the Eurasian lynx in the Jura Mountains in eastern France.The simulations show that the proposed combined penalised likelihood approach has better predictive performance than the standard approach when spatial dependence is present in the data. The lynx analysis shows that the predicted maps vary significantly between the model fitted with the proposed combined penalised approach accounting for spatial dependence and the model fitted with the standard combined likelihood.This work highlights the benefits of careful consideration of the presence-only components of the combined likelihood formulation, and allows greater flexibility and ability to accommodate real datasets.",
        "link": "http://dx.doi.org/10.1101/615583"
    }
]