[
    {
        "id": 14171,
        "title": "Deep Learning for Robot Perception and Cognition",
        "authors": "",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/c2020-0-02902-6"
    },
    {
        "id": 14172,
        "title": "Copyright",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00003-8"
    },
    {
        "id": 14173,
        "title": "Preface",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00028-2"
    },
    {
        "id": 14174,
        "title": "Contents",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00004-x"
    },
    {
        "id": 14175,
        "title": "Index",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00027-0"
    },
    {
        "id": 14176,
        "title": "Factor Graphs for Robot Perception",
        "authors": "Frank Dellaert, Michael Kaess",
        "published": "2017",
        "citations": 67,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1561/9781680833270"
    },
    {
        "id": 14177,
        "title": "Editors biographies",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00030-0"
    },
    {
        "id": 14178,
        "title": "Front Matter",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00002-6"
    },
    {
        "id": 14179,
        "title": "Robot Perception and Sensing for Environmental Awareness",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.52783/tojqi.v11i4.10025"
    },
    {
        "id": 14180,
        "title": "Understanding the Perception of Incremental Robot Response in Human-Robot Interaction",
        "authors": "Lars Christian Jensen, Rosalyn Melissa Langedijk, Kerstin Fischer",
        "published": "2020-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ro-man47096.2020.9223615"
    },
    {
        "id": 14181,
        "title": "Perception is Only Real When Shared: A Mathematical Model for Collaborative Shared Perception in Human-Robot Interaction",
        "authors": "Marco Matarese, Francesco Rea, Alessandra Sciutti",
        "published": "2022-6-15",
        "citations": 4,
        "abstract": "Partners have to build a shared understanding of their environment in everyday collaborative tasks by aligning their perceptions and establishing a common ground. This is one of the aims of shared perception: revealing characteristics of the individual perception to others with whom we share the same environment. In this regard, social cognitive processes, such as joint attention and perspective-taking, form a shared perception. From a Human-Robot Interaction (HRI) perspective, robots would benefit from the ability to establish shared perception with humans and a common understanding of the environment with their partners. In this work, we wanted to assess whether a robot, considering the differences in perception between itself and its partner, could be more effective in its helping role and to what extent this improves task completion and the interaction experience. For this purpose, we designed a mathematical model for a collaborative shared perception that aims to maximise the collaborators’ knowledge of the environment when there are asymmetries in perception. Moreover, we instantiated and tested our model via a real HRI scenario. The experiment consisted of a cooperative game in which participants had to build towers of Lego bricks, while the robot took the role of a suggester. In particular, we conducted experiments using two different robot behaviours. In one condition, based on shared perception, the robot gave suggestions by considering the partners’ point of view and using its inference about their common ground to select the most informative hint. In the other condition, the robot just indicated the brick that would have yielded a higher score from its individual perspective. The adoption of shared perception in the selection of suggestions led to better performances in all the instances of the game where the visual information was not a priori common to both agents. However, the subjective evaluation of the robot’s behaviour did not change between conditions.",
        "link": "http://dx.doi.org/10.3389/frobt.2022.733954"
    },
    {
        "id": 14182,
        "title": "Acknowledgements",
        "authors": "Alexandros Iosifidis, Anastasios Tefas",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00029-4"
    },
    {
        "id": 14183,
        "title": "The Influence of Robot Number on Robot Group Perception—A Call for Action",
        "authors": "Ricarda Wullenkord, Friederike Eyssel",
        "published": "2020-12-31",
        "citations": 8,
        "abstract": "Research on robot groups has often applied psychological principles underlying group processes between humans to interactions with and between robots. However, such research has failed to test empirically whether these principles indeed apply to the robot context. For instance, the notion of a social group may be interpreted differently when facing human versus robot groups. Basic research on this issue is missing. Therefore, the present experiment aimed at integrating social psychological theorizing and research on robot groups by utilizing the principles of group entitativity. We examined the effect of robot number and similarity on the perception of these robots as a (social) group. To do so, participants saw pictures of one to ten robots, appearing low or high in similarity. Results showed that the aspects eliciting the perception of a social “group” in humans seem to differ from the factors evoking robot group perception. According to our findings, at least three robots seem necessary for the perception of a robot “group” to emerge. Social psychological research, however, has proposed that two persons suffice to elicit the notion of a human social group. Basic research is needed to substantiate assumptions drawn from social psychological theorizing before translating it into human-robot context.",
        "link": "http://dx.doi.org/10.1145/3394899"
    },
    {
        "id": 14184,
        "title": "Does a wearing change perception toward a robot?",
        "authors": "Natsuki Matsunaga, Masahiro Shiomi",
        "published": "2021-8-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ro-man50785.2021.9515366"
    },
    {
        "id": 14185,
        "title": "Relevant Perception Modalities for Flexible Human-Robot Teams",
        "authors": "Nico Hollerich, Dominik Henrich",
        "published": "2020-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ro-man47096.2020.9223593"
    },
    {
        "id": 14186,
        "title": "A Robot Experiment in Collective Perception",
        "authors": "Gabriele Valentini",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-53609-5_8"
    },
    {
        "id": 14187,
        "title": "Convolutional neural networks",
        "authors": "Jenni Raitoharju",
        "published": "2022",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00008-7"
    },
    {
        "id": 14188,
        "title": "Introduction",
        "authors": "Alexandros Iosifidis, Anastasios Tefas",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00006-3"
    },
    {
        "id": 14189,
        "title": "Enhancing a robot gripper with haptic perception for risk mitigation in physical human robot interaction",
        "authors": "Christoph Hellmann, Aulon Bajrami, Werner Kraus",
        "published": "2019-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/whc.2019.8816109"
    },
    {
        "id": 14190,
        "title": "Risk Perception and Risk Behavior in Response to Service Robot Anthropomorphism in Banking",
        "authors": "Martin Aubel, Indre Pikturniene, Yannick Joye",
        "published": "2022-6-15",
        "citations": 0,
        "abstract": "Purpose: This article explores how anthropomorphized service robots shape consumer risk perceptions and risk behavior via uncanniness as a function of individual differences in banking.  Methodology: An online between-subjects experiment (N = 293), set in a fictitious bank, featuring four levels of service robot anthropomorphism (low, medium, high, human), measured risk perceptions (psychological, functional, privacy, time), and risk behavior as DVs, uncanniness as mediator, technology readiness, and behavioral inhibition as moderators.  Findings: Risk perceptions are the lowest for medium (vs. high) anthropomorphism and are mediated by uncanniness. Risk behavior remains unaffected by the manipulation. Technology readiness overall attenuates the main effect on time risk perception but amplifies it for high anthropomorphism, whereas high behavioral inhibition increases risk behavior under the exposure of low anthropomorphism.  Implication: Banks who plan to place robots in service functions should be mostly concerned about experiential rather than behavioral consequences and are advised to use medium anthropomorphism robots since they appear to qualify as viable substitutes for human bank tellers.  Value: We contribute to the service robot and anthropomorphism literature by (1) distinguishing between dimensions of risk perceptions, (2) measuring actual risk behavior, and (3) setting our study in a business and marketing relevant context: banking",
        "link": "http://dx.doi.org/10.7206/cemj.2658-0845.74"
    },
    {
        "id": 14191,
        "title": "Simulation environments",
        "authors": "Charalampos Symeonidis, Nikos Nikolaidis",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00023-3"
    },
    {
        "id": 14192,
        "title": "Research on Perception and Control Technology for Robot Dexterous Operation",
        "authors": "Tengteng Zhang, Hongwei Mo",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nIn an unstructured environment, multiple objects are closely arranged, which leads to the complexity of robot grasping. Deep reinforcement learning(DRL) can take long-term reasoning, and make better and more robust decisions in a series of decisions, allowing the robot to continuously learn from its own experience. In this paper, we demonstrate that a new deep reinforcement learning algorithm based on Q-learning and attention mechanisms can effectively solve the robot grasping problem. In addition, we present a grasp and move strategy that reduces complexity by replacing hand-designed features with data-driven ones. The robot is used to move the objects to create a larger grasping space when the objects are densely distributed to improve the grasping success rate. The application of the proposed model on a simulated UR5 robot manipulator demonstrates the effectiveness and stability of the model. The results show that our proposed method outperforms the baseline framework in terms of grasping accuracy and efficiency.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1697958/v1"
    },
    {
        "id": 14193,
        "title": "Methods and Effects of Priming a Teloperator's Perception of Robot Capabilities",
        "authors": "Daniel J. Rea, James E. Young",
        "published": "2019-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/hri.2019.8673186"
    },
    {
        "id": 14194,
        "title": "Increasing Perception Space of a Ground Standing Robot via Data Transmission from an Aerial Robot",
        "authors": "Kiwon Sohn, Mohammad Manzur Murshid",
        "published": "2019-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icuas.2019.8798088"
    },
    {
        "id": 14195,
        "title": "The Development of Action Perception",
        "authors": "Janny Christina Stapel",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-46732-6_5"
    },
    {
        "id": 14196,
        "title": "Task Perception",
        "authors": "",
        "published": "2017-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119091882.ch2"
    },
    {
        "id": 14197,
        "title": "Tactile-GAT: Tactile Graph Attention Networks for Robot Tactile Perception Classification",
        "authors": "Lun Chen, Yingzhao Zhu",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nAs one of the most important senses in human beings, touch can also help robots better perceive and adapt to complex environmental information, improving their autonomous decision-making and execution capabilities. Compared to other perception methods, tactile perception needs to handle multi-channel tactile signals simultaneously, such as pressure, bending, temperature, and humidity. However, directly transferring deep learning algorithms that work well on temporal signals to tactile signal tasks does not make good use of the physical spatial connectivity information of tactile sensors. In this paper, we propose a tactile perception framework based on graph attention networks, which incorporates explicit and latent relation graphs. This framework can effectively utilize the structural information between different tactile signal channels. We constructed a tactile glove and collected a dataset of pressure and bending tactile signals during grasping and holding objects. And our method achieved 89.58% accuracy in object tactile signal classification with a small parameter size of 0.11M. Compared to existing time-series signal classification algorithms, our graph-based tactile perception algorithm can utilize and learn sensor spatial information, making it more suitable for processing multi-channel tactile data. Our method can serve as a general strategy to improve robot's tactile perception capabilities.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3261017/v1"
    },
    {
        "id": 14198,
        "title": "Priming and Timing in Human-Robot Interactions",
        "authors": "Allison Langer, Shelly Levy-Tzedek",
        "published": "2020",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-46732-6_16"
    },
    {
        "id": 14199,
        "title": "Online Decentralized Perception-Aware Path Planning for Multi-Robot Systems",
        "authors": "Nicola De Carli, Paolo Salaris, Paolo Robuffo Giordano",
        "published": "2021-11-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mrs50823.2021.9620694"
    },
    {
        "id": 14200,
        "title": "Perception of Power and Distance in Human-Human and Human-Robot Role-Based Relations",
        "authors": "Eleonore Lumer, Hendrik Buschmeier",
        "published": "2022-3-7",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/hri53351.2022.9889308"
    },
    {
        "id": 14201,
        "title": "The Neurophysiology of Action Perception",
        "authors": "Pauline M. Hilt, Pasquale Cardellicchio, Alessandro D’Ausilio",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-46732-6_2"
    },
    {
        "id": 14202,
        "title": "Deep learning in multiagent systems",
        "authors": "Lukas Esterle",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00022-1"
    },
    {
        "id": 14203,
        "title": "Effects of Colored LEDs in Robotic Storytelling on Storytelling Experience and Robot Perception",
        "authors": "Sophia C. Steinhaeusser, Birgit Lugrin",
        "published": "2022-3-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/hri53351.2022.9889469"
    },
    {
        "id": 14204,
        "title": "Robot-Centric Perception of Human Groups",
        "authors": "Angelique Taylor, Darren M. Chan, Laurel D. Riek",
        "published": "2020-9-30",
        "citations": 19,
        "abstract": "The robotics community continually strives to create robots that are deployable in real-world environments. Often, robots are expected to interact with human groups. To achieve this goal, we introduce a new method, the Robot-Centric Group Estimation Model (RoboGEM), which enables robots to detect groups of people. Much of the work reported in the literature focuses on dyadic interactions, leaving a gap in our understanding of how to build robots that can effectively team with larger groups of people. Moreover, many current methods rely on exocentric vision, where cameras and sensors are placed externally in the environment, rather than onboard the robot. Consequently, these methods are impractical for robots in unstructured, human-centric environments, which are novel and unpredictable. Furthermore, the majority of work on group perception is supervised, which can inhibit performance in real-world settings. RoboGEM addresses these gaps by being able to predict social groups solely from an egocentric perspective using color and depth (RGB-D) data. To achieve group predictions, RoboGEM leverages joint motion and proximity estimations. We evaluated RoboGEM against a challenging, egocentric, real-world dataset where both pedestrians and the robot are in motion simultaneously, and show RoboGEM outperformed two state-of-the-art supervised methods in detection accuracy by up to 30%, with a lower miss rate. Our work will be helpful to the robotics community, and serve as a milestone to building unsupervised systems that will enable robots to work with human groups in real-world environments.",
        "link": "http://dx.doi.org/10.1145/3375798"
    },
    {
        "id": 14205,
        "title": "Generation Differences in Perception of the Elderly Care Robot",
        "authors": "Weria Khaksar, Margot Neggers, Emilia Barakova, Jim Torresen",
        "published": "2021-8-8",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ro-man50785.2021.9515534"
    },
    {
        "id": 14206,
        "title": "Improving Visual Perception of a Social Robot for Controlled and In-the-wild Human-robot Interaction",
        "authors": "Wangjie Zhong, Leimin Tian, Duy Tho Le, Hamid Rezatofighi",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3610978.3640648"
    },
    {
        "id": 14207,
        "title": "Evaluating Social Perception of Human-to-Robot Handovers Using the Robot Social Attributes Scale (RoSAS)",
        "authors": "Matthew K.X.J. Pan, Elizabeth A. Croft, Günter Niemeyer",
        "published": "2018-2-26",
        "citations": 20,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3171221.3171257"
    },
    {
        "id": 14208,
        "title": "Knowledge distillation",
        "authors": "Nikolaos Passalis, Maria Tzelepi, Anastasios Tefas",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00013-0"
    },
    {
        "id": 14209,
        "title": "Brain-Inspired Bodily Self-Perception Model for Robot Rubber Hand Illusion",
        "authors": "Yuxuan Zhao, Enmeng Lu, Yi Zeng",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4444689"
    },
    {
        "id": 14210,
        "title": "Bayesian Eigenobjects: A Unified Framework for 3D Robot Perception",
        "authors": "Benjamin Burchfiel, George Konidaris",
        "published": "2017-7-12",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15607/rss.2017.xiii.011"
    },
    {
        "id": 14211,
        "title": "Battery-free UHF-RFID Sensors based SLAM for In-Pipe Robot Perception",
        "authors": "Amal Gunatilake, sarath kodagoda, Karthick Thiyagarajan",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Water utilities across the globe are concerned with the inspection and replacement of buried metallic water pipes due to corrosion-related structural damages. Internal pipe linings are commonly used as a renewal method to improve structural strength as they are regarded to be a less expensive alternative to costly and time-consuming pipe replacements. However, linings are also prone to failure as well. Therefore, water authorities regularly monitor lining performance, where defect evolution over a long period of time is an important parameter to note. It requires an accurate in-pipe robot localization technology. In this article, we propose a novel method for in-pipe robot localization and tag mapping that uses battery-free UHF-RFID sensor wireless signals. It utilizes a signal mapping approach in combination with a tailored pose-graph simultaneous localization and mapping algorithm. Evaluation results of a field-extracted pipe sample from Sydney Water's distribution network show the proposed approach is capable of localizing the robot within 2.5cm accuracy in a 50m equivalent pipe with an unknown UHF-RFID distribution. The proposed approach outperformed other reported similar work in the literature. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.21017185.v1"
    },
    {
        "id": 14212,
        "title": "Robot Perception",
        "authors": "Nguyen Van Toan",
        "published": "2023-2-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003352426-6"
    },
    {
        "id": 14213,
        "title": "Battery-free UHF-RFID Sensors based SLAM for In-Pipe Robot Perception",
        "authors": "Amal Gunatilake, sarath kodagoda, Karthick Thiyagarajan",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Water utilities across the globe are concerned with the inspection and replacement of buried metallic water pipes due to corrosion-related structural damages. Internal pipe linings are commonly used as a renewal method to improve structural strength as they are regarded to be a less expensive alternative to costly and time-consuming pipe replacements. However, linings are also prone to failure as well. Therefore, water authorities regularly monitor lining performance, where defect evolution over a long period of time is an important parameter to note. It requires an accurate in-pipe robot localization technology. In this article, we propose a novel method for in-pipe robot localization and tag mapping that uses battery-free UHF-RFID sensor wireless signals. It utilizes a signal mapping approach in combination with a tailored pose-graph simultaneous localization and mapping algorithm. Evaluation results of a field-extracted pipe sample from Sydney Water's distribution network show the proposed approach is capable of localizing the robot within 2.5cm accuracy in a 50m equivalent pipe with an unknown UHF-RFID distribution. The proposed approach outperformed other reported similar work in the literature. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.21017185"
    },
    {
        "id": 14214,
        "title": "Correspondence identification for collaborative multi-robot perception under uncertainty",
        "authors": "Peng Gao, Rui Guo, Hongsheng Lu, Hao Zhang",
        "published": "2022-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10514-021-10009-6"
    },
    {
        "id": 14215,
        "title": "A framework for an adaptive human-robot collaboration approach through perception-based real-time adjustments of robot behavior in industry",
        "authors": "Shitij Kumar, Ferat Sahin",
        "published": "2017-6",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/sysose.2017.7994967"
    },
    {
        "id": 14216,
        "title": "From Perception to Semantics: An Environment Representation Model Based on Human-Robot Interactions",
        "authors": "Yohan Breux, Sebastien Druon, Rene Zapata",
        "published": "2018-8",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/roman.2018.8525527"
    },
    {
        "id": 14217,
        "title": "Graph convolutional networks",
        "authors": "Negar Heidari, Lukas Hedegaard, Alexandros Iosifidis",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00009-9"
    },
    {
        "id": 14218,
        "title": "When Positive Perception of the Robot Has No Effect on Learning",
        "authors": "Jauwairia Nasir, Utku Norman, Barbara Bruno, Pierre Dillenbourg",
        "published": "2020-8",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ro-man47096.2020.9223343"
    },
    {
        "id": 14219,
        "title": "From active perception to deep learning",
        "authors": "Danica Kragic",
        "published": "2018-10-17",
        "citations": 3,
        "abstract": "Computer vision diverged from robotics and has focused on contests and data sets; reconnecting the two could solve real-world problems.",
        "link": "http://dx.doi.org/10.1126/scirobotics.aav1778"
    },
    {
        "id": 14220,
        "title": "Repetitive robot behavior impacts perception of intentionality and gaze-related attentional orienting.",
        "authors": "Abdulaziz Abubshait, Agnieszka Wykowska",
        "published": "No Date",
        "citations": 0,
        "abstract": "Gaze behavior is an important social signal between humans, as it communicates locations of interest. People typically orient their attention to where others look, as this informs about others’ intentions and future actions. Studies have shown that humans can engage in similar gaze behavior with robots, but presumably more so when they adopt the intentional stance towards them (i.e., believing robot behaviors are intentional). In laboratory settings, the phenomenon of attending towards the direction of others’ gaze has been examined with the use of the gaze-cueing paradigm. While the gaze-cueing paradigm has been successful in investigating the relationship between adopting the intentional stance towards robots and attention orient-ing to gaze cues, it is unclear if the repetitiveness of the gaze-cueing paradigm influences adopting the intentional stance. Here, we examined if the duration of exposure to repetitive robot gaze behavior in a gaze-cueing task has a negative impact on subjective attribution of intentionality. Participants performed a short, medium, or long face-to-face gaze-cueing paradigm with an embodied robot while subjective ratings were collected pre and post the interaction. Results show that participants in the long exposure condition had the smallest change in their intention attribution scores, if any, while those in the short exposure condition had a positive change in their intention attribution indicating that participants attributed more intention to the robot after short interactions. The results also show that attention orienting to ro-bot gaze-cues was positively related to how much intention was attributed to the robot, but this relationship became more negative as the length of exposure increased. In contrast to subjective ratings, the gaze cueing effects increased as a function of the duration of exposure to repetitive behavior. The data suggest a tradeoff between the desired number of trials needed for observing various mechanisms of social cognition, such as gaze cueing effects, and the likelihood of adopting the intentional stance towards a robot.",
        "link": "http://dx.doi.org/10.31219/osf.io/fh4dm"
    },
    {
        "id": 14221,
        "title": "Recurrent neural networks",
        "authors": "Avraam Tsantekidis, Nikolaos Passalis, Anastasios Tefas",
        "published": "2022",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00010-5"
    },
    {
        "id": 14222,
        "title": "Leveraging Human Perception in Robot Grasping and Manipulation Through Crowdsourcing and Gamification",
        "authors": "Gal Gorjup, Lucas Gerez, Minas Liarokapis",
        "published": "2021-4-29",
        "citations": 0,
        "abstract": "Robot grasping in unstructured and dynamic environments is heavily dependent on the object attributes. Although Deep Learning approaches have delivered exceptional performance in robot perception, human perception and reasoning are still superior in processing novel object classes. Furthermore, training such models requires large, difficult to obtain datasets. This work combines crowdsourcing and gamification to leverage human intelligence, enhancing the object recognition and attribute estimation processes of robot grasping. The framework employs an attribute matching system that encodes visual information into an online puzzle game, utilizing the collective intelligence of players to expand the attribute database and react to real-time perception conflicts. The framework is deployed and evaluated in two proof-of-concept applications: enhancing the control of a robotic exoskeleton glove and improving object identification for autonomous robot grasping. In addition, a model for estimating the framework response time is proposed. The obtained results demonstrate that the framework is capable of rapid adaptation to novel object classes, based purely on visual information and human experience.",
        "link": "http://dx.doi.org/10.3389/frobt.2021.652760"
    },
    {
        "id": 14223,
        "title": "Socio-cultural perception of robot backchannels",
        "authors": "Olov Engwall, Ronald Cumbal, Ali Reza Majlesi",
        "published": "2023-1-26",
        "citations": 1,
        "abstract": "Introduction: Backchannels, i.e., short interjections by an interlocutor to indicate attention, understanding or agreement regarding utterances by another conversation participant, are fundamental in human-human interaction. Lack of backchannels or if they have unexpected timing or formulation may influence the conversation negatively, as misinterpretations regarding attention, understanding or agreement may occur. However, several studies over the years have shown that there may be cultural differences in how backchannels are provided and perceived and that these differences may affect intercultural conversations. Culturally aware robots must hence be endowed with the capability to detect and adapt to the way these conversational markers are used across different cultures. Traditionally, culture has been defined in terms of nationality, but this is more and more considered to be a stereotypic simplification. We therefore investigate several socio-cultural factors, such as the participants’ gender, age, first language, extroversion and familiarity with robots, that may be relevant for the perception of backchannels.Methods: We first cover existing research on cultural influence on backchannel formulation and perception in human-human interaction and on backchannel implementation in Human-Robot Interaction. We then present an experiment on second language spoken practice, in which we investigate how backchannels from the social robot Furhat influence interaction (investigated through speaking time ratios and ethnomethodology and multimodal conversation analysis) and impression of the robot (measured by post-session ratings). The experiment, made in a triad word game setting, is focused on if activity-adaptive robot backchannels may redistribute the participants’ speaking time ratio, and/or if the participants’ assessment of the robot is influenced by the backchannel strategy. The goal is to explore how robot backchannels should be adapted to different language learners to encourage their participation while being perceived as socio-culturally appropriate.Results: We find that a strategy that displays more backchannels towards a less active speaker may substantially decrease the difference in speaking time between the two speakers, that different socio-cultural groups respond differently to the robot’s backchannel strategy and that they also perceive the robot differently after the session.Discussion: We conclude that the robot may need different backchanneling strategies towards speakers from different socio-cultural groups in order to encourage them to speak and have a positive perception of the robot.",
        "link": "http://dx.doi.org/10.3389/frobt.2023.988042"
    },
    {
        "id": 14224,
        "title": "The Visual Perception of Biological Motion in Adults",
        "authors": "Paul Hemeren, Yves Rybarczyk",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-46732-6_4"
    },
    {
        "id": 14225,
        "title": "3D object detection and tracking",
        "authors": "Illia Oleksiienko, Alexandros Iosifidis",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00018-x"
    },
    {
        "id": 14226,
        "title": "Human activity recognition",
        "authors": "Lukas Hedegaard, Negar Heidari, Alexandros Iosifidis",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00019-1"
    },
    {
        "id": 14227,
        "title": "Object detection and tracking",
        "authors": "Kateryna Chumachenko, Moncef Gabbouj, Alexandros Iosifidis",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00016-6"
    },
    {
        "id": 14228,
        "title": "Physical Human-Robot Interaction through a Jointly-held Object based on Kinesthetic Perception",
        "authors": "Ramin Jaberzadeh Ansari, Yiannis Karayiannidis, Jonas Sjober",
        "published": "2018-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/roman.2018.8525657"
    },
    {
        "id": 14229,
        "title": "Smooth Operator",
        "authors": "Frederic Anthony Robinson, Mari Velonaki, Oliver Bown",
        "published": "2021-3-8",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3434073.3444658"
    },
    {
        "id": 14230,
        "title": "Enhancing Robot Perception with Real-World HRI",
        "authors": "Maciej Wozniak",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3610978.3638363"
    },
    {
        "id": 14231,
        "title": "Deep reinforcement learning",
        "authors": "Avraam Tsantekidis, Nikolaos Passalis, Anastasios Tefas",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00011-7"
    },
    {
        "id": 14232,
        "title": "Perception-Constrained Robot Manipulator Planning for Satellite Servicing",
        "authors": "Tariq Zahroof, Andrew Bylard, Hesham Shageer, Marco Pavone",
        "published": "2019-3",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aero.2019.8741569"
    },
    {
        "id": 14233,
        "title": "Semantic scene segmentation for robotics",
        "authors": "Juana Valeria Hurtado, Abhinav Valada",
        "published": "2022",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00017-8"
    },
    {
        "id": 14234,
        "title": "Neural networks and backpropagation",
        "authors": "Adamantios Zaras, Nikolaos Passalis, Anastasios Tefas",
        "published": "2022",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00007-5"
    },
    {
        "id": 14235,
        "title": "Data-Driven Robot Perception in the Wild",
        "authors": "Karl Holmquist",
        "published": "2023-3-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3384/9789180750677"
    },
    {
        "id": 14236,
        "title": "Visual Perception Enabled Agriculture Intelligence: A   Selective Seedling Picking Transplanting Robot",
        "authors": "Mingyong Li, Xiaowu Zhu, Jiangtao Ji, Xin Jin",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4718077"
    },
    {
        "id": 14237,
        "title": "A Novel Radar Point Cloud Generation Method for Robot Environment Perception",
        "authors": "Yuwei Cheng, Jingran Su, Mengxin Jiang, Yimin Liu",
        "published": "2022-12",
        "citations": 17,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tro.2022.3185831"
    },
    {
        "id": 14238,
        "title": "Pose Measurement Based on Vision Perception",
        "authors": "Panfeng Huang, Zhongjie Meng, Jian Guo, Fan Zhang",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-812309-6.00003-8"
    },
    {
        "id": 14239,
        "title": "Robot perception errors and human resolution strategies in situated human–robot dialogue",
        "authors": "Niels Schütte, Brian Mac Namee, John Kelleher",
        "published": "2017-3-4",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/01691864.2016.1268973"
    },
    {
        "id": 14240,
        "title": "Design of a Human Multi-Robot Interaction Medium of Cognitive Perception",
        "authors": "Wonse Jo, Jee Hwan Park, Sangjun Lee, Ahreum Lee, Byung-Cheol Min",
        "published": "2019-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/hri.2019.8673188"
    },
    {
        "id": 14241,
        "title": "Impact of Trajectory Generation Methods on Viewer Perception of Robot Approaching Group Behaviors",
        "authors": "Fangkai Yang, Wenjie Yin, Marten Bjorkman, Christopher Peters",
        "published": "2020-8",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ro-man47096.2020.9223584"
    },
    {
        "id": 14242,
        "title": "Repetitive Robot Behavior Impacts Perception of Intentionality and Gaze-Related Attentional Orienting",
        "authors": "Abdulaziz Abubshait, Agnieszka Wykowska",
        "published": "2020-11-9",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3389/frobt.2020.565825"
    },
    {
        "id": 14243,
        "title": "The MuMMER Data Set for Robot Perception in Multi-party HRI Scenarios",
        "authors": "Olivier Canevet, Weipeng He, Petr Motlicek, Jean-Marc Odobez",
        "published": "2020-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ro-man47096.2020.9223340"
    },
    {
        "id": 14244,
        "title": "Lightweight deep learning",
        "authors": "Paraskevi Nousi, Maria Tzelepi, Nikolaos Passalis, Anastasios Tefas",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00012-9"
    },
    {
        "id": 14245,
        "title": "Space Robot Perception System",
        "authors": "Yaobing Wang",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-15-4902-1_9"
    },
    {
        "id": 14246,
        "title": "Research of AI Fire Fighting Robot Based on Big Data and Group Intelligence Perception",
        "authors": "Hong Zhang",
        "published": "2020-11-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac51589.2020.9327116"
    },
    {
        "id": 14247,
        "title": "Modelling Human Motion",
        "authors": "",
        "published": "2020",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-46732-6"
    },
    {
        "id": 14248,
        "title": "Endowing a NAO Robot With Practical Social-Touch Perception",
        "authors": "Rachael Bevill Burns, Hyosang Lee, Hasti Seifi, Robert Faulkner, Katherine J. Kuchenbecker",
        "published": "2022-4-19",
        "citations": 5,
        "abstract": "Social touch is essential to everyday interactions, but current socially assistive robots have limited touch-perception capabilities. Rather than build entirely new robotic systems, we propose to augment existing rigid-bodied robots with an external touch-perception system. This practical approach can enable researchers and caregivers to continue to use robotic technology they have already purchased and learned about, but with a myriad of new social-touch interactions possible. This paper presents a low-cost, easy-to-build, soft tactile-perception system that we created for the NAO robot, as well as participants’ feedback on touching this system. We installed four of our fabric-and-foam-based resistive sensors on the curved surfaces of a NAO’s left arm, including its hand, lower arm, upper arm, and shoulder. Fifteen adults then performed five types of affective touch-communication gestures (hitting, poking, squeezing, stroking, and tickling) at two force intensities (gentle and energetic) on the four sensor locations; we share this dataset of four time-varying resistances, our sensor patterns, and a characterization of the sensors’ physical performance. After training, a gesture-classification algorithm based on a random forest identified the correct combined touch gesture and force intensity on windows of held-out test data with an average accuracy of 74.1%, which is more than eight times better than chance. Participants rated the sensor-equipped arm as pleasant to touch and liked the robot’s presence significantly more after touch interactions. Our promising results show that this type of tactile-perception system can detect necessary social-touch communication cues from users, can be tailored to a variety of robot body parts, and can provide HRI researchers with the tools needed to implement social touch in their own systems.",
        "link": "http://dx.doi.org/10.3389/frobt.2022.840335"
    },
    {
        "id": 14249,
        "title": "Progressive and compressive learning",
        "authors": "Dat Thanh Tran, Moncef Gabbouj, Alexandros Iosifidis",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00014-2"
    },
    {
        "id": 14250,
        "title": "Humans' Perception of a Robot Moving Using a Slow in and Slow Out Velocity Profile",
        "authors": "Trenton Schulz, Patrick Holthaus, Farshid Amirabdollahian, Kheng Lee Koay",
        "published": "2019-3",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/hri.2019.8673239"
    },
    {
        "id": 14251,
        "title": "Evaluating People’s Perception of Trust of a Deceptive Robot with Theory of Mind in an Assistive Gaming Scenario",
        "authors": "Alessandra Rossi, Silvia Rossi",
        "published": "2023-8-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ro-man57019.2023.10309647"
    },
    {
        "id": 14252,
        "title": "The effects of the robot's information delivery types on users' perception toward the robot",
        "authors": "Dahyun Kang, Min-Gyu Kim, Sonya S. Kwak",
        "published": "2017-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/roman.2017.8172467"
    },
    {
        "id": 14253,
        "title": "Can you Tell the Robot by the Voice? An Exploratory Study on the Role of Voice in the Perception of Robots",
        "authors": "Conor McGinn, Ilaria Torre",
        "published": "2019-3",
        "citations": 54,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/hri.2019.8673305"
    },
    {
        "id": 14254,
        "title": "DPLVO: Direct Point-Line Monocular Visual Odometry",
        "authors": "Lipu Zhou, Shengze Wang, Michael Kaess",
        "published": "2021-10",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/lra.2021.3097052"
    },
    {
        "id": 14255,
        "title": "View Planning for Object Pose Estimation Using Point Clouds: An Active Robot Perception Approach",
        "authors": "Jie Hu, Prabhakar R. Pagilla",
        "published": "2022-10",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/lra.2022.3189821"
    },
    {
        "id": 14256,
        "title": "“The Robot-Arm Talks Back to Me” - Human Perception of Augmented Human-Robot Collaboration in Virtual Reality",
        "authors": "Alexander Arntz, Sabrina C. Eimler, H. Ulrich Hoppe",
        "published": "2020-12",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aivr50618.2020.00062"
    },
    {
        "id": 14257,
        "title": "A Novel Online Robot Design Research Platform to Determine Robot Mind Perception",
        "authors": "Daniel E. Pittman, Kerstin S. Haring, Pilyoung Kim, Benjamin Dossett, Gillian Ehman, Elizabeth Gutierrez-Gutierrez, Sneha Patil, Ashley Sanchez",
        "published": "2022-3-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/hri53351.2022.9889539"
    },
    {
        "id": 14258,
        "title": "Representation learning and retrieval",
        "authors": "Maria Tzelepi, Paraskevi Nousi, Nikolaos Passalis, Anastasios Tefas",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-32-385787-1.00015-4"
    },
    {
        "id": 14259,
        "title": "Adaptive gait parameters adjustment strategy for a hexapod robot walking on stairs based on 3D terrain perception",
        "authors": "",
        "published": "2020-8-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.13180/clawar.2020.24-26.08.09"
    },
    {
        "id": 14260,
        "title": "Human-Robot Relationship: long-term effects on disclosure, perception and well-being",
        "authors": "Guy Laban, Arvid Kappas, Val Morrison, Emily S. Cross",
        "published": "No Date",
        "citations": 2,
        "abstract": "Since interactions with social robots are novel and exciting for many people, one concern is the extent to which people's behavioural and emotional engagement with robots might develop from initial interactions with a robot, when a robot's novelty is especially salient, and sustained over time. This challenge is particularly noticeable in interactions designed to support people's well-being, with limited evidence for how social robots can support people's emotional health over time. Accordingly, this research is aimed at studying how long-term repeated interactions with a social robot affect people's self-disclosure behaviour toward the robot, perceptions of the robot, and how it affected factors related to well-being. We conducted a mediated long-term online experiment with participants conversing with the social robot Pepper 10 times over 5 weeks. We found that people self-disclose increasingly more to a social robot over time, and found the robot to be more social and competent over time. Participants' moods got better after talking to the robot and across sessions, they found the robot's responses to be more comforting over time, and they also reported feeling less lonely over time. Finally, our results stress that when the discussion theme was supposedly more emotional, participants felt lonelier and stressed. These results set the stage for addressing social robots as conversational partners and provide crucial evidence for their potential introduction as interventions supporting people's emotional health through encouraging self-disclosure.",
        "link": "http://dx.doi.org/10.31234/osf.io/6z5ry"
    },
    {
        "id": 14261,
        "title": "A survey on Perception Methods for Human Robot Interaction",
        "authors": "",
        "published": "2021-12-1",
        "citations": 0,
        "abstract": "Socialize and collaborate with people Everyday Life activities require Robots to Express human beings' \"intelligence\". Proper measurements in direct, face-to-face scenarios we will introduce the set, behavioral analysis of human partners. We summarize these robots and highlight key findings and key linkages with existing long-term studies. Artificial Emotional Intelligence (AEI) Human-Robot Identify Movements in Interactions (HRI). To provide robots with expressive capabilities Focuses on simulation and enhancing natural emotions. Robotics in America and Japan Observation of participants with researchers. Based on the data collected through interviews, this article is about the social impacts and robotics of scientists on acceptability Analyzing discourses. Reciprocal design And the architecture of co-production, robotics, and dynamic interactions between communities Explores, society, and technology Social as an alternative perspective on dynamics A for imagining and evaluating robots Also proposed as a framework. Social robotics researches the body in a socially interactive way and robots that can provide cognitive support focus on growth. Social robots User characteristics (age, gender, education, Some studies on the importance of robot familiarity, mood) previously explored.",
        "link": "http://dx.doi.org/10.46632/rmc/2/4/11"
    },
    {
        "id": 14262,
        "title": "Beyond Automatic Motor Mapping: New Insights into Top-Down Modulations on Action Perception",
        "authors": "Alessandra Finisguerra, Lucia Amoruso, Cosimo Urgesi",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-46732-6_3"
    },
    {
        "id": 14263,
        "title": "Fast and Accurate Recognition for Codes on Complex Backgrounds for Real-Life Industrial Applications",
        "authors": "Qiaokang Liang,  , Qiao Ge, Wei Sun, Dan Zhang, Yaonan Wang, Kunlin Zou,  ,  ,  ,  ,  ",
        "published": "2021-10-13",
        "citations": 0,
        "abstract": "In the food and beverage industry, the existing recognition of code characters on the surface of complex packaging usually suffers from low accuracy and low speed. This work presents an efficient and accurate inkjet code recognition system based on the combination of the deep learning and traditional image processing methods. The proposed system mainly consists of three sequential modules, i.e., the characters region extraction by modified YOLOv3-tiny network, the character processing by the traditional image processing methods such as binarization and the modified character projection segmentation, and the character recognition by a Convolutional recurrent neural network (CRNN) model based on a modified version of MobileNetV3. In this system, only a small amount of tag data has been made and an effective character data generator is designed to randomly generate different experimental data for the CRNN model training. To the best of our knowledge, this report for the first time describes that deep learning has been applied to the recognition of codes on complex background for the real-life industrial application. Experimental results have been provided to verify the accuracy and effectiveness of the proposed model, demonstrating a recognition accuracy of 0.986 and a processing speed of 100 ms per bottle in the end-to-end character recognition system.",
        "link": "http://dx.doi.org/10.36909/jer.10603"
    },
    {
        "id": 14264,
        "title": "Research on Perception and Control Technology for Dexterous Robot Operation",
        "authors": "Tengteng Zhang, Hongwei Mo",
        "published": "2023-7-13",
        "citations": 1,
        "abstract": "Robotic grasping in cluttered environments is a fundamental and challenging task in robotics research. The ability to autonomously grasp objects in cluttered scenes is crucial for robots to perform complex tasks in real-world scenarios. Conventional grasping is based on the known object model in a structured environment, but the adaptability of unknown objects and complicated situations is constrained. In this paper, we present a robotic grasp architecture of attention-based deep reinforcement learning. To prevent the loss of local information, the prominent characteristics of input images are automatically extracted using a full convolutional network. In contrast to previous model-based and data-driven methods, the reward is remodeled in an effort to address the sparse rewards. The experimental results show that our method can double the learning speed in grasping a series of randomly placed objects. In real-word experiments, the grasping success rate of the robot platform reaches 90.4%, which outperforms several baselines.",
        "link": "http://dx.doi.org/10.3390/electronics12143065"
    },
    {
        "id": 14265,
        "title": "Ev-Conv: Fast CNN Inference on Event Camera Inputs for High-Speed Robot Perception",
        "authors": "Sankeerth Durvasula, Yushi Guan, Nandita Vijaykumar",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/lra.2023.3259731"
    },
    {
        "id": 14266,
        "title": "A Study on Customer’s Perception of Robot Nonverbal Communication Skills in a Service Environment",
        "authors": "Nguyen Tan Viet Tuyen, Shintaro Okazaki, Oya Celiktutan",
        "published": "2023-8-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ro-man57019.2023.10309634"
    },
    {
        "id": 14267,
        "title": "Eye-Movement Dependency of Peripheral Visual Perception of Anthropomorphism Using an 80ms Robot Picture Stimulus",
        "authors": "Kolja Kühnlenz",
        "published": "2023-3-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3568294.3580083"
    },
    {
        "id": 14268,
        "title": "Soft robot perception using embedded soft sensors and recurrent neural networks",
        "authors": "Thomas George Thuruthel, Benjamin Shih, Cecilia Laschi, Michael Thomas Tolley",
        "published": "2019-1-30",
        "citations": 384,
        "abstract": "Recurrent neural networks with an unstructured redundant soft sensor topology allow robust multimodal proprioceptive capabilities.",
        "link": "http://dx.doi.org/10.1126/scirobotics.aav1488"
    },
    {
        "id": 14269,
        "title": "Perception and Action Augmentation for Teleoperation Assistance in Freeform Telemanipulation",
        "authors": "Tsung-Chi Lin, Achyuthan Unni Krishnan, Zhi Li",
        "published": "2024-3-31",
        "citations": 0,
        "abstract": "Teleoperation enables controlling complex robot systems remotely, providing the ability to impart human expertise from a distance. However, these interfaces can be complicated to use as it is difficult to contextualize information about robot motion in the workspace from the limited camera feedback. Thus, it is required to study the best manner in which assistance can be provided to the operator that reduces interface complexity and effort required for teleoperation. Some techniques that provide assistance to the operator while freeform teleoperating include: (1) perception augmentation, like augmented reality visual cues and additional camera angles, increasing the information available to the operator; (2) action augmentation, like assistive autonomy and control augmentation, optimized to reduce the effort required by the operator while teleoperating. In this article, we investigate: (1) which aspects of dexterous telemanipulation require assistance; (2) the impact of perception and action augmentation in improving teleoperation performance; and (3) what factors impact the usage of assistance and how to tailor these interfaces based on the operators’ needs and characteristics. The findings from this user study and resulting post-study surveys will help identify task-based and user-preferred perception and augmentation features for teleoperation assistance.",
        "link": "http://dx.doi.org/10.1145/3643804"
    },
    {
        "id": 14270,
        "title": "The Perception of Agency",
        "authors": "J. Gregory Trafton, J. Malcolm McCurry, Kevin Zish, Chelsea R. Frazier",
        "published": "2024-3-31",
        "citations": 1,
        "abstract": "The perception of agency in human robot interaction has become increasingly important as robots become more capable and more social. There are, however, no accepted or consistent methods of measuring perceived agency; researchers currently use a wide range of techniques and surveys. We provide a definition of perceived agency, and from that definition we create and psychometrically validate a scale to measure perceived agency. We then perform a scale evaluation by comparing the PA scale constructed in experiment 1 to two other existing scales. We find that our PA and PA-R (Perceived Agency–Rasch) scales provide a better fit to empirical data than existing measures. We also perform scale validation by showing that our scale shows the hypothesized relationship between perceived agency and morality.",
        "link": "http://dx.doi.org/10.1145/3640011"
    }
]