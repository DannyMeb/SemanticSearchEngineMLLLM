[
    {
        "id": 7001,
        "title": "Gradient boosting machines",
        "authors": "Brandon M. Greenwell",
        "published": "2022-5-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003089032-8"
    },
    {
        "id": 7002,
        "title": "Case Study: Gradient Boosting Machine vs Light GBM in Potential Landslide Detection",
        "authors": "Djarot Hindarto",
        "published": "2024-1-1",
        "citations": 0,
        "abstract": "An increasing demand for precise forecasts concerning the likelihood of landslides served as the impetus for this investigation. Human life, infrastructure, and the environment are all profoundly affected by this natural occasion. Constructing models capable of discerning intricate patterns among diverse factors that impact the likelihood of landslide occurrences constitutes the primary obstacle in landslide detection. Predicting potential landslides requires algorithms that are both accurate and efficient in their processing of vast quantities of data encompassing a variety of geographical, environmental, and ecological characteristics. An evaluation of the efficacy of both Gradient Boosting Machine and Light Gradient Boosting Machine in identifying patterns associated with landslides is accomplished by comparing their performance on a large and complex dataset. In the realm of potential landslide detection, the primary aim of this research endeavor is to assess the predictive precision, computation duration, and generalizability of Gradient Boosting Machine and Light Gradient Boosting Machine. This research aims to enhance comprehension regarding the comparative benefits of these two approaches in surmounting the obstacles associated with risk assessment and modeling pertaining to potential landslides, with a specific emphasis on efficiency and precision. The research findings are anticipated to serve as a valuable reference in the identification of more efficient approaches to reduce the likelihood of landslide-induced natural catastrophes. The accuracy of the GBM experiment reached 82% and LGBM reached 81%.",
        "link": "http://dx.doi.org/10.47709/cnahpc.v6i1.3374"
    },
    {
        "id": 7003,
        "title": "Predicting Determinants of Lifelong Learning Intention Using Gradient Boosting Machine (GBM) with Grid Search",
        "authors": "Chayoung Kim, Taejung Park",
        "published": "2022-4-27",
        "citations": 11,
        "abstract": "The purpose of this study is to explore the factors that have the most decisive influence on actual learning intention that leads to participation in adult education. For developing the predictive model, we used tree-based machine learning, with the longitudinal big data (2017~2020) of Korean adults. Based on the gradient boosting machine (GBM) results, among the eleven variables used, the most influential variables in predicting the possibility of lifelong education participation were self-pay education expenses and then highest level of education completed. After the grid search, not only the importance of the two variables but also the overall figures including the false positive rate improved. In future studies, it will be possible to improve the performance of the machine learning model by adjusting the hyper-parameters that can be directly set by less computational methods.",
        "link": "http://dx.doi.org/10.3390/su14095256"
    },
    {
        "id": 7004,
        "title": "Peer Review #1 of \"The determinants of chemoreception as evidenced by gradient boosting machines in broad molecular fingerprint spaces (v0.1)\"",
        "authors": "",
        "published": "2019-12-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-ochem.2v0.1/reviews/1"
    },
    {
        "id": 7005,
        "title": "Peer Review #2 of \"The determinants of chemoreception as evidenced by gradient boosting machines in broad molecular fingerprint spaces (v0.1)\"",
        "authors": "R Goswami",
        "published": "2019-12-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-ochem.2v0.1/reviews/2"
    },
    {
        "id": 7006,
        "title": "Peer Review #3 of \"The determinants of chemoreception as evidenced by gradient boosting machines in broad molecular fingerprint spaces (v0.1)\"",
        "authors": "A Goswami",
        "published": "2019-12-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-ochem.2v0.1/reviews/3"
    },
    {
        "id": 7007,
        "title": "CalixBoost: A Stock Market Index Predictor using Gradient Boosting Machines Ensemble",
        "authors": "Jarrett Yeo Shan Wei, Yeo Chai Kiat",
        "published": "2022-6-18",
        "citations": 0,
        "abstract": "The potential of machine learning has sustained the interest of both academia and industry in stock market prediction over the past decade. This paper aims to integrate modern techniques such as Gradient Boosting Machines (GBMs) into a novel ensemble called CalixBoost which is a resource-efficient and accurate stock index predictor. Data comprising macro-economic metrics and technical financial indicators, as well as sentiment analysis of social media using a simple and fast but effective rule-based model are used in this paper. Other techniques include model tuning with Bayesian Optimization, temporal consistency analysis for invariant feature selection over random trial-and-error, feature importance and inter-feature relationships analysis using a unified game theory approach using Shapley values. Lastly, the model will be evaluated using a novel holdout method, viz. on two separate test datasets whose datapoints are collected under (i) normal economic activity and (ii) during a black swan (financial downturn). The experimental results show that our model outperforms previous methods and can achieve a good prediction performance with 84.88% accuracy, 0.0956 RMSE, 0.0573 MAE and 4.19% MAPE.",
        "link": "http://dx.doi.org/10.5121/csit.2022.121009"
    },
    {
        "id": 7008,
        "title": "Application of the Catboost Gradient Boosting Method in Forecasting Solar Electricity",
        "authors": "D. Vasina, A. Gorshenin",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dynamics60586.2023.10349541"
    },
    {
        "id": 7009,
        "title": "A short-term wind power output forecasting model based on the enhanced gradient boosting machine (GBM) algorithms for high wind power penetrations",
        "authors": "S. Park, J. Hur",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1049/icp.2022.2779"
    },
    {
        "id": 7010,
        "title": "Habitat Models of Stream Invertebrate Community Improve with Predictors of Dam Impacts and Optimized Gradient Boosting Machines",
        "authors": "Nukazawa Kei, Ryo Tanaka, Haruki Mineda",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4463236"
    },
    {
        "id": 7011,
        "title": "Gradient Boosting Machines and Non-Life Insurance Pricing - Lecture Notes",
        "authors": "Bj&ouml;rn Johansson, Esbj&ouml;rn Ohlsson",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4294965"
    },
    {
        "id": 7012,
        "title": "32 Identifying feature importance in post-mortem outcome with gradient boosting machines",
        "authors": "John Booth, Ben Margetts, Neil Sebire",
        "published": "2019-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1136/archdischild-2019-gosh.32"
    },
    {
        "id": 7013,
        "title": "The determinants of chemoreception as evidenced by gradient boosting machines in broad molecular fingerprint spaces",
        "authors": "Sammy Sambu",
        "published": "2019-12-3",
        "citations": 2,
        "abstract": "The ability to identify and reject bitter molecules may determine evolutionary fitness. These molecules might be in potentially toxic or contaminated food. Surprisingly, the ability to identify but tolerate or even enjoy bitter foods and medicines may be beneficial. For example, the tolerance of bitterness as a spice or as a medicine may lead to better nutritional, immunological and health outcomes. More recently the ability of intensely bitter compounds to induce innate immune responses to counter infection has inspired the screening of new drugs and the repurposing of safe, known drugs to new uses. These avenues of study may also help to address long-standing questions regarding unexpected side-effects and placebo/nocebo effects. Therefore, to distinguish all these effects ranging from desire to aversion, there is a need to quantitatively determine the concentration thresholds and to position these bitter substances on a unified taste threshold spectrum. Such an understanding may help elucidate the concentration-based molecular drivers for the chemoreceptive response to bitter substances. This article reports the development of a gradient boosting machine (GBM) that enables a direct interrogation of molecular structure with no intermediary chemical properties. Using molecularly engineered simulations, it is shown that potassium acesulfame has a hidden bitterness motif that is centered on the chemoreceptive spectrum uniting bitterness and sweetness molecular motifs. The resultant shifted perception from a touchstone bitterness sensation to a bitter after-taste is attributable to this cached molecular motif.",
        "link": "http://dx.doi.org/10.7717/peerj-ochem.2"
    },
    {
        "id": 7014,
        "title": "A Note on Multi-Parametric Gradient Boosting Machines with Non-Life Insurance Applications",
        "authors": "Lukasz Delong, Mathias Lindholm, Henning Zakrisson",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4352505"
    },
    {
        "id": 7015,
        "title": "GBMPSO: Hybrid Gradient Boosting Machines with Particle Swarm Optimization in Cell Segmentation Data",
        "authors": "Temidayo Adeluwa, Eunjin Kim, Junguk Hur",
        "published": "2021-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ssci50451.2021.9660039"
    },
    {
        "id": 7016,
        "title": "Sports &amp; Nutrition Data Science using Gradient Boosting Machines",
        "authors": "Antonios Pantazopoulos, Manolis Maragoudakis",
        "published": "2018-7-9",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3200947.3201060"
    },
    {
        "id": 7017,
        "title": "Assessment of Deep Neural Network and Gradient Boosting Machines for Credit Risk Prediction Accuracy",
        "authors": "Sapiah Sakri",
        "published": "2022-12-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cicn56167.2022.10008264"
    },
    {
        "id": 7018,
        "title": "A scalable purchase intention prediction system using extreme gradient boosting machines with browsing content entropy",
        "authors": "Bichen Zheng, Bingwei Liu",
        "published": "2018-1",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icce.2018.8326351"
    },
    {
        "id": 7019,
        "title": "EEG Based Participant Independent Emotion Classification using Gradient Boosting Machines",
        "authors": "Sagar Aggarwal, Luv Aggarwal, Manshubh Singh Rihal, Swati Aggarwal",
        "published": "2018-12",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iadcc.2018.8692106"
    },
    {
        "id": 7020,
        "title": "A Novel Approach for Stock Price Prediction Using Gradient Boosting Machine with Feature Engineering (GBM-wFE)",
        "authors": "Rebwar M. Nabi, Soran Ab. M. Saeed, Habibollah Harron",
        "published": "2020-4-30",
        "citations": 8,
        "abstract": "The prediction of stock prices has become an exciting area for researchers as well as academicians due to its economic impact and potential business profits. This study proposes a novel multiclass classification ensemble learning approach for predicting stock prices based on historical data using feature engineering. The proposed approach comprises four main steps, which are pre-processing, feature selection, feature engineering, and ensemble methods. We use 11 datasets from Nasdaq and S&P 500 to ensure the accuracy of the proposed approach. Furthermore, eight feature selection algorithms are studied and implemented. More importantly, a feature engineering concept is applied to construct two new features, which are appears to be very auspicious in terms of improving classification accuracy, and this is considered the first study to use feature engineering for multiclass classification using ensemble methods. Finally, seven ensemble machine learning (ML) algorithms are used and compared to discover the ultimate collaboration prediction model. Besides, the best feature selection algorithm is proposed. This study proposes a novel multiclass classification approach called Gradient Boosting Machine with Feature Engineering (GBM-wFE) and Principal Component Analysis (PCA) as the feature selection. We find that GBM-wFE outperforms the previous studies and the overall prediction results are auspicious, as MAPE of 0.0406% is achieved, which is considered the best result compared to the available studies in the literature.",
        "link": "http://dx.doi.org/10.24017/science.2020.1.3"
    },
    {
        "id": 7021,
        "title": "Gradient Boosting Machines",
        "authors": "",
        "published": "2019-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811201967_0005"
    },
    {
        "id": 7022,
        "title": "Gradient Boosting Machine, Random Forest dan Light GBM untuk Klasifikasi Kacang Kering",
        "authors": "Indrawata Wardhana,  Musi Ariawijaya,  Vandri Ahmad Isnaini,  Rahmi Putri Wirman",
        "published": "2022-2-27",
        "citations": 0,
        "abstract": "Bean seed classification is critical in determining the quality of beans. Previously, the same dataset was tested using the MLP, SVM, KNN, and DT algorithms, with SVM producing the best results. The purpose of this study is to determine the most effective model through the use of the BoxCox transformation selection feature and the random forest (RF) algorithm, as well as the gradient boosting machine (GBM), light GBM, and repeated k-folds evaluation model. The bean dataset is available on the UCI Repository website. The BoxCox transformation and repeated k-folds improved the classification prediction's accuracy. The model is used in the optimal training phase for a random forest with decision tree parameters 50 and depth 10, a gradient boosting machine model with a learning rate of 1, and a light gradient boosting machine model with a learning rate of 0.5 and estimator of 500. The best training accuracy results are obtained with light GBM. which is 99 percent accurate, but only 91 percent accurate in terms of validation. According research, the Barbunya, Bombay, Cali, Dermason, Horoz, Seker, and Sira beans classes provided accuracy values of 91 percent, 100 percent, 92 percent, 92 percent, 95 percent, 94 percent, and 84 percent, respectively.  ",
        "link": "http://dx.doi.org/10.29207/resti.v6i1.3682"
    },
    {
        "id": 7023,
        "title": "Unveiling the Spark: Gradient Boosting Machine (GBM) Analysis of Economic Growth, Crime Rates, and Firecracker-Related Injuries/Death in the Philippines",
        "authors": "Vicente E. Montano, Claudio Bisares",
        "published": "2024",
        "citations": 0,
        "abstract": "The New Year celebration in the Philippines observes a surge in firecracker-related injuries and deaths, increasing concern beyond cultural significance. The Gradient Boosting Machine (GBM) proves the influence of economic growth and crime rates on firecracker-related injuries/deaths. The result of this research draws on the Strain Theory and Routine Activities Theory to reveal the potential influence of economic growth and crime rates on this phenomenon. Through the lens of Strain Theory, economic growth, despite its benefits, drives strain among excluded segments, driving risk-taking behavior, financial pressure, and limited access to safer alternatives, resulting in the use of dangerous fireworks. Routine Activities Theory maintains how high crime rates increase the availability of illegal fireworks and facilitate criminal misuse while also creating environments where riskier behaviors proliferate due to lax enforcement and limited safe options. The research concludes by focusing on the need for policy and interventions addressing economic disparities and crime prevention measures to promote safe and inclusive celebrations. Further research is recommended to probe deeper into regional variations, employ mixed methods approaches, and enhance data collection for targeted interventions and effective policy frameworks.",
        "link": "http://dx.doi.org/10.47772/ijriss.2024.801139"
    },
    {
        "id": 7024,
        "title": "Gender Voice Recognition Using Random Forest Recursive Feature Elimination with Gradient Boosting Machines",
        "authors": "Kudakwashe Zvarevashe, Oludayo O. Olugbara",
        "published": "2018-8",
        "citations": 20,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icabcd.2018.8465466"
    },
    {
        "id": 7025,
        "title": "Optimisation and economic analysis of industrial-scale anaerobic co-digestion (ACoD) of palm oil mill effluent (POME) and decanter cake (DC) using machine learning models: A comparative study of Gradient Boosting Machines (GBM), K-nearest neighbours (KNN), and random forest (RF)",
        "authors": "Pang Bo Yang, Yi Jing Chan, Sara Kazemi Yazdi, Jun Wei Lim",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jwpe.2023.104752"
    },
    {
        "id": 7026,
        "title": "RGBM: Regularized Gradient Boosting Machines for the Identification of Transcriptional Regulators of Discrete Glioma Subtypes",
        "authors": "Raghvendra Mall, Luigi Cerulo, Khalid Kunji, Halima Bensmail, Thais S. Sabedot, Houtan Noushmehr, Antonio Iavarone, Michele Ceccarelli",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractThe transcription factors (TF) which regulate gene expressions are key determinants of cellular phenotypes. Reconstructing large-scale genome-wide networks which capture the influence of TFs on target genes are essential for understanding and accurate modelling of living cells. We propose RGBM: a gene regulatory network (GRN) inference algorithm, which can handle data from heterogeneous information sources including dynamic time-series, gene knockout, gene knockdown, DNA microarrays and RNA-Seq expression profiles. RGBM allows to use an a priori mechanistic of active biding network consisting of TFs and corresponding target genes. RGBM is evaluated on the DREAM challenge datasets where it surpasses the winners of the competitions and other established methods for two evaluation metrics by about 10-15%.We use RGBM to identify the main regulators of the molecular subtypes of brain tumors. Our analysis reveals the identity and corresponding biological activities of the master regulators driving transformation of the G-CIMP-high into the G-CIMP-low subtype of glioma and PA-like into LGm6-GBM, thus, providing a clue to the yet undetermined nature of the transcriptional events driving the evolution among these novel glioma subtypes.RGBM is available for download on CRAN at https://cran.rproject.org/web/packages/RGBM/index.html",
        "link": "http://dx.doi.org/10.1101/132670"
    },
    {
        "id": 7027,
        "title": "New Findings from Explainable SYM-H Forecasting using Gradient Boosting Machines",
        "authors": "Daniel Iong, Yang Chen, Gabor Toth, Shasha Zou, Tuija I. Pulkkinen, Jiaen Ren, Enrico Camporeale, Tamas I. I. Gombosi",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/essoar.10508063.3"
    },
    {
        "id": 7028,
        "title": "A Method for Determining the Accuracy of Stock Prices using Gradient Boosting and the Support Vector Machines Algorithm",
        "authors": "P. Varshitha Reddy, S. Magesh Kumar",
        "published": "2022-10-20",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icosec54921.2022.9952143"
    },
    {
        "id": 7029,
        "title": "Probabilistic Gradient Boosting Machines for Large-Scale Probabilistic Regression",
        "authors": "Olivier Sprangers, Sebastian Schelter, Maarten de Rijke",
        "published": "2021-8-14",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3447548.3467278"
    },
    {
        "id": 7030,
        "title": "Estimation of monthly evaporation values using gradient boosting machines and mode decomposition techniques in the Southeast Anatolia Project (GAP) area in Turkey",
        "authors": "Metin Sarıgöl, Okan Mert Katipoğlu",
        "published": "2023-3-13",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11600-023-01067-8"
    },
    {
        "id": 7031,
        "title": "Financial default payment predictions using a hybrid of simulated annealing heuristics and extreme gradient boosting machines",
        "authors": "Bichen Zheng",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijitst.2019.10024064"
    },
    {
        "id": 7032,
        "title": "Financial default payment predictions using a hybrid of simulated annealing heuristics and extreme gradient boosting machines",
        "authors": "Bichen Zheng",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijitst.2019.102796"
    },
    {
        "id": 7033,
        "title": "Extending CART-based Multiple Imputation with Gradient Boosting Machines",
        "authors": "Justin M. Luningham, Gitta H. Lubke",
        "published": "2018-1-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/00273171.2017.1405785"
    },
    {
        "id": 7034,
        "title": "Real-time intelligent fault diagnosis of rotating machines based on Archimedes algorithm optimised Gradient Boosting",
        "authors": "Oguzhan Das",
        "published": "2024-2-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/10589759.2023.2274015"
    },
    {
        "id": 7035,
        "title": "A boosting ensemble learning based hybrid light gradient boosting machine and extreme gradient boosting model for predicting house prices",
        "authors": "Racheal Sibindi, Ronald Waweru Mwangi, Anthony Gichuhi Waititu",
        "published": "2023-4",
        "citations": 8,
        "abstract": "AbstractThe implementation of tree‐ensemble models has become increasingly essential in solving classification and prediction problems. Boosting ensemble techniques have been widely used as individual machine learning algorithms in predicting house prices. One of the techniques is LGBM algorithm that employs leaf wise growth strategy, reduces loss and improves accuracy during training which results in overfitting. However, XGBoost algorithm uses level wise growth strategy which takes time to compute resulting in higher computation time. Nevertheless, XGBoost has a regularization parameter, implements column sampling and weight reduction on new trees which combats overfitting. This study focuses on developing a hybrid LGBM and XGBoost model in order to prevent overfitting through minimizing variance whilst improving accuracy. Bayesian hyperparameter optimization technique is implemented on the base learners in order to find the best combination of hyperparameters. This resulted in reduced variance (overfitting) in the hybrid model since the regularization parameter values were optimized. The hybrid model is compared to LGBM, XGBoost, Adaboost and GBM algorithms to evaluate its performance in giving accurate house price predictions using MSE, MAE and MAPE evaluation metrics. The hybrid LGBM and XGBoost model outperformed the other models with MSE, MAE and MAPE of 0.193, 0.285, and 0.156 respectively.",
        "link": "http://dx.doi.org/10.1002/eng2.12599"
    },
    {
        "id": 7036,
        "title": "Site-scale estimation of Ozone in Northern Bavaria using Gradient Boosting Machines, Deterministic Regional Air Quality Models and a Hybrid Model",
        "authors": "seyed omid nabavi, Anke Nölscher, Leopold Haimberger, Juan Cuesta, Christoph Thomas, Andreas Held, Cyrus Samimi",
        "published": "No Date",
        "citations": 0,
        "abstract": "\n        &lt;p&gt;This study is part of the Mitigation of Urban Climate and Ozone Risks (MiSKOR) project. MiSKOR aims to use a collection of tools to mitigate the problems of the urban heat island effect and ozone (O3) pollution in and around medium sized cities in northern Bavaria (NB).&amp;#160; In this study, we developed modelling tools to estimate (hindcast), classify (O3 &gt;= 120 ug/m3 or O3 &lt; 120 ug/m3), and forecast hourly O3 concentrations at nine unmonitored sites in NB. Three machine learning algorithms (MLAs) including linear- and tree-based eXtreme Gradient Boosting Machines (MLR-XGBM and Tree-XGBM) and logistic regression (LR) are used for O3 modelling. MLAs are trained by using hourly observations of O3 and its chemical and meteorological precursors from seven monitored sites in NB. In addition, the daily average of surface O3 observations along 6-hour back trajectories, produced by HYSPLIT model, is fed into MLAs to provide a rough estimation of O3 transport in a local scale. MLAs are compared with two state of the art regional deterministic models (DMs) namely the ECMWF Copernicus Atmosphere Monitoring Service (CAMS) regional air quality model for Europe (CAMS-EU) and the DLR WRF-POLYPHEMUS air quality system (used only for O3 forecast purpose). Finally, we created a new hybrid model by combining the O3 estimations from the best MLA model and the regional air quality model CAMS-EU.&lt;/p&gt;&lt;p&gt;According to averaged metrics from leave-one-site-out cross-validation (LOOCV), MLR-XGBM outperformed other models in the estimation of O3. This model yielded summertime RMSE and Spearman correlation coefficient (SCC) of 13.6 &amp;#181;g/m3 and 0.91 respectively. Interestingly, the hybrid model significantly improved the accuracy of O3 estimations. It reduced the summertime seasonal RMSE to 11.4 &amp;#181;g/m3 and increased the lowest seasonal SCC to 0.95. MLR-XGBM also yielded the best performance in O3 forecast compared to CAMS-EU and WRF-POLYPHEMUS. With regard to O3 classification LR outperformed other models. We also found that using remotely sensed lower troposphere O3, from IASI/GOME2, improves the classification of high extreme O3 in summertime.&lt;/p&gt;\n        ",
        "link": "http://dx.doi.org/10.5194/egusphere-egu2020-11624"
    },
    {
        "id": 7037,
        "title": "An adaptive CU size decision algorithm based on gradient boosting machines for 3D-HEVC inter-coding",
        "authors": "Siham Bakkouri, Abderrahmane Elyousfi",
        "published": "2023-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11042-023-14540-9"
    },
    {
        "id": 7038,
        "title": "Carrier Frequency Offset Estimation in 5G NR: Introducing Gradient Boosting Machines",
        "authors": "Mostafa Hussien, Ahmed Abdelmoaty, Mahmoud Elsaadany, Mohammed F. A. Ahmed, Ghyslain Gagnon, Kim Khoa Nguyen, Mohamed Cheriet",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2023.3263053"
    },
    {
        "id": 7039,
        "title": "Detection of Epilepsy Through EEG Signals Using the DWT and Extreme Gradient Boosting Methods",
        "authors": "Erlina Agustin, Ade Eviyanti",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21070/ups.258"
    },
    {
        "id": 7040,
        "title": "Interpretable machine learning with an ensemble of gradient boosting machines",
        "authors": "Andrei V. Konstantinov, Lev V. Utkin",
        "published": "2021-6",
        "citations": 63,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.knosys.2021.106993"
    },
    {
        "id": 7041,
        "title": "Social Media Analysis for Sentiment Classification Using Gradient Boosting Machines",
        "authors": "Pradeep Kumar, Abdul Wahid",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-3246-4_70"
    },
    {
        "id": 7042,
        "title": "The role of frailty index in predicting readmission risk following total joint replacement using light gradient boosting machines",
        "authors": "Julie Slezak, Liam Butler, Oguz Akbilgic",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.imu.2021.100657"
    },
    {
        "id": 7043,
        "title": "A Generalized Stacking for Implementing Ensembles of Gradient Boosting Machines",
        "authors": "Andrei V. Konstantinov, Lev V. Utkin",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-67892-0_1"
    },
    {
        "id": 7044,
        "title": "PESM: predicting the essentiality of miRNAs based on gradient boosting machines and sequences",
        "authors": "Cheng Yan, Fang-Xiang Wu, Jianxin Wang, Guihua Duan",
        "published": "2020-12",
        "citations": 10,
        "abstract": "AbstractBackgroundMicroRNAs (miRNAs) are a kind of small noncoding RNA molecules that are direct posttranscriptional regulations of mRNA targets. Studies have indicated that miRNAs play key roles in complex diseases by taking part in many biological processes, such as cell growth, cell death and so on. Therefore, in order to improve the effectiveness of disease diagnosis and treatment, it is appealing to develop advanced computational methods for predicting the essentiality of miRNAs.ResultIn this study, we propose a method (PESM) to predict the miRNA essentiality based on gradient boosting machines and miRNA sequences. First, PESM extracts the sequence and structural features of miRNAs. Then it uses gradient boosting machines to predict the essentiality of miRNAs. We conduct the 5-fold cross-validation to assess the prediction performance of our method. The area under the receiver operating characteristic curve (AUC), F-measure and accuracy (ACC) are used as the metrics to evaluate the prediction performance. We also compare PESM with other three competing methods which include miES, Gaussian Naive Bayes and Support Vector Machine.ConclusionThe results of experiments show that PESM achieves the better prediction performance (AUC: 0.9117, F-measure: 0.8572, ACC: 0.8516) than other three computing methods. In addition, the relative importance of all features also further shows that newly added features can be helpful to improve the prediction performance of methods.",
        "link": "http://dx.doi.org/10.1186/s12859-020-3426-9"
    },
    {
        "id": 7045,
        "title": "A novel approach to improve accuracy in stock price prediction using gradient boosting machines algorithm compared with Random Forest algorithm",
        "authors": "P. Varshitha Reddy, S. Magesh Kumar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/5.0172961"
    },
    {
        "id": 7046,
        "title": "A Novel Approach to Improve Accuracy in Stock Price Prediction using Gradient Boosting Machines Algorithm compared with Naive Bayes Algorithm",
        "authors": "P. Varshitha Reddy, S. Magesh Kumar",
        "published": "2022-12-16",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icac3n56670.2022.10074387"
    },
    {
        "id": 7047,
        "title": "SimBoost: a read-across approach for predicting drug–target binding affinities using gradient boosting machines",
        "authors": "Tong He, Marten Heidemeyer, Fuqiang Ban, Artem Cherkasov, Martin Ester",
        "published": "2017-12",
        "citations": 213,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s13321-017-0209-z"
    },
    {
        "id": 7048,
        "title": "Artificial Neural Networks, Gradient Boosting and Support Vector Machines for electric vehicle battery state estimation: A review",
        "authors": "Aaruththiran Manoharan, K.M. Begam, Vimal Rau Aparow, Denesh Sooriamoorthy",
        "published": "2022-11",
        "citations": 60,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.est.2022.105384"
    },
    {
        "id": 7049,
        "title": "Perbandingan Gradient Boosting dan Light  Gradient Boosting  Dalam Melakukan Klasifikasi Rumah Sewa",
        "authors": "Rizka Dahlia, Cucu Ika Agustyaningrum",
        "published": "2022-12-29",
        "citations": 0,
        "abstract": "Abstrak— Persaingan antar perusahaan tidak akan dapat terhindarkan apalagi terkait tujuan perusahaan dalam mendapatkan omset sebesar-besarnya. Salah satu persaingan yang terjadi adalah dibidang property atau jika lebih spesifik lagi yaitu penyewaan rumah. Sebuah perusahaan harus menentukan strategi bagaimana rumah yang akan disewakan nantinya akan sebanding dengan harga pembangunan. Maka dari itu perusahaan dapat melakukan klasifikasi rumah sewa dalam menentukan hal tersebut. Penelitian ini menggunakan model Gradient Boosting dan Light Gradient Boosting. Hasil yang didapatkan adalah bahwa model Gradient Boosting adalah model yang cocok pada penelitian ini dengan mendapatkan hasil accuracy 84.38%, precision 83.33% dan recall 87.53%. Jika dilihat perbandingan dari confusion matrix, Gradient Boosting memiliki jumlah hasil prediksi data lebih besar dibanding dibanding Light  Gradient Boosting.Kata kunci: Rumah Sewa, Data Mining, Gradient Boosting, Light Gradient Boosting Abstract— Competition between companies cannot be avoided, especially regarding the company's goal of getting the maximum turnover. One of the competitions that occurs is in the property sector, or more specifically, house rental. A company must determine a strategy for how the house to be rented out will be comparable to the construction price. Therefore the company can classify rental houses in determining this. This study uses the Gradient Boosting and Light Gradient Boosting models. The results obtained are that the Gradient Boosting model is a suitable model in this study with 84.38% accuracy, 83.33% precision and 87.53% recall. If you look at the comparison of the confusion matrix, Gradient Boosting has a greater number of data prediction results than Light Gradient Boosting.Keywords : House for rent, Data Mining, Gradient Boosting, Light Gradient Boosting",
        "link": "http://dx.doi.org/10.32672/jnkti.v5i6.5460"
    },
    {
        "id": 7050,
        "title": "Referenceless image quality assessment by saliency, color-texture energy, and gradient boosting machines",
        "authors": "Pedro Garcia Freitas, Welington Y. L. Akamine, Mylène C. Q. Farias",
        "published": "2018-12",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s13173-018-0073-3"
    },
    {
        "id": 7051,
        "title": "Exploring nonlinear effects of air pollution on hospital admissions by disease using gradient boosting machines",
        "authors": "Carlos Minutti-Martinez, Antonio Galindo, Luis F. Valdez-Garduno, Miguel F. Mata-Rivera",
        "published": "2022-11-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cce56709.2022.9976027"
    },
    {
        "id": 7052,
        "title": "Wind power generation forecast by coupling numerical weather prediction model and gradient boosting machines in Yahyalı wind power plant",
        "authors": "Cem Özen, Umur Dinç, Ali Deniz, Haldun Karan",
        "published": "2021-10",
        "citations": 3,
        "abstract": " Forecasting of the wind speed and power generation for a wind farm has always been quite challenging and has importance in terms of balancing the electricity grid and preventing energy imbalance penalties. This study focuses on creating a hybrid model that uses both numerical weather prediction model and gradient boosting machines (GBM) for wind power generation forecast. Weather Research and Forecasting (WRF) model with a low spatial resolution is used to increase temporal resolutions of the computed new or existing variables whereas GBM is used for downscaling purposes. The results of the hybrid model have been compared with the outputs of a stand-alone WRF which is well configured in terms of physical schemes and has a high spatial resolution for Yahyalı wind farm over a complex terrain located in Turkey. Consequently, the superiority of the hybrid model in terms of both performance indicators and computational expense in detail is shown. ",
        "link": "http://dx.doi.org/10.1177/0309524x20972115"
    },
    {
        "id": 7053,
        "title": "Sentiment Analysis on Twitter about Domestic Violence Using Random Forest and Extreme Gradient Boosting Methods",
        "authors": "Robi'atul Asyaroh, Arif Senja Fitrani",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21070/ups.2459"
    },
    {
        "id": 7054,
        "title": "A Gradient Boosting Model to Predict the Milk Production",
        "authors": "floris herrema",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4493640"
    },
    {
        "id": 7055,
        "title": "PENERAPAN GRADIENT BOOSTING DENGAN HYPEROPT UNTUK MEMPREDIKSI KEBERHASILAN TELEMARKETING BANK",
        "authors": "Silvia Elsa Suryana, Budi Warsito, Suparti Suparti",
        "published": "2021-12-31",
        "citations": 1,
        "abstract": "Telemarketing is another form of marketing which is conducted via telephone. Bank can use telemarketing to offer its products such as term deposit. One of the most important strategy to the success of telemarketing is opting the potential customer to create effective telemarketing. Predicting the success of telemarketing can use machine learning. Gradient boosting is machine learning method with advanced decision tree. Gardient boosting involves many classification trees which are continually upgraded from previous tree. The optimal classification result cannot be separated from the role of the optimal hyperparameter.  Hyperopt is Python library that can be used to tune hyperparameter effectively because it uses Bayesian optimization. Hyperopt uses hyperparameter prior distribution to find optimal hyperparameter. Data in this study including 20 independent variables and binary dependent variable which has ‘yes’ and ‘no’ classes. The study showed that gradient boosting reached classification accuracy up to 90,39%, precision 94,91%, and AUC 0,939. These values describe gradient boosting method is able to predict both classes ‘yes’ and ‘no’ relatively accurate.",
        "link": "http://dx.doi.org/10.14710/j.gauss.v10i4.31335"
    },
    {
        "id": 7056,
        "title": "Predicting Overall Survival Time in Glioblastoma Patients Using Gradient Boosting Machines Algorithm and Recursive Feature Elimination Technique",
        "authors": "Golestan Karami, Marco Giuseppe Orlando, Andrea Delli Pizzi, Massimo Caulo, Cosimo Del Gratta",
        "published": "2021-10-4",
        "citations": 11,
        "abstract": "Despite advances in tumor treatment, the inconsistent response is a major challenge among glioblastoma multiform (GBM) that lead to different survival time. Our aim was to integrate multimodal MRI with non-supervised and supervised machine learning methods to predict GBM patients’ survival time. To this end, we identified different compartments of the tumor and extracted their features. Next, we applied Random Forest-Recursive Feature Elimination (RF-RFE) to identify the most relevant features to feed into a GBoost machine. This study included 29 GBM patients with known survival time. RF-RFE GBoost model was evaluated to assess the survival prediction performance using optimal features. Furthermore, overall survival (OS) was analyzed using univariate and multivariate Cox regression analyses, to evaluate the effect of ROIs and their features on survival. The results showed that a RF-RFE Gboost machine was able to predict survival time with 75% accuracy. The results also revealed that the rCBV in the low perfusion area was significantly different between groups and had the greatest effect size in terms of the rate of change of the response variable (survival time). In conclusion, not only integration of multi-modality MRI but also feature selection method can enhance the classifier performance.",
        "link": "http://dx.doi.org/10.3390/cancers13194976"
    },
    {
        "id": 7057,
        "title": "Interpretable machine learning for demand modeling with high-dimensional data using Gradient Boosting Machines and Shapley values",
        "authors": "Evgeny A. Antipov, Elena B. Pokryshevskaya",
        "published": "2020-10",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1057/s41272-020-00236-4"
    },
    {
        "id": 7058,
        "title": "Training Gradient Boosting Machines Using Curve-Fitting and Information-Theoretic Features for Causal Direction Detection",
        "authors": "Spyridon Samothrakis, Diego Perez, Simon Lucas",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-21810-2_11"
    },
    {
        "id": 7059,
        "title": "Estimation of daily maize transpiration using support vector machines, extreme gradient boosting, artificial and deep neural networks models",
        "authors": "Junliang Fan, Jing Zheng, Lifeng Wu, Fucang Zhang",
        "published": "2021-2",
        "citations": 100,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.agwat.2020.106547"
    },
    {
        "id": 7060,
        "title": "Abstract 2255: Using tumor sample gene expression data to infer tumor purity levels with stochastic gradient boosting machines",
        "authors": "YuanYuan Li, Adrienna Bingham, Qi-Jing Li, Yuan Zhuang, David M. Umbach, Leping Li",
        "published": "2018-7-1",
        "citations": 1,
        "abstract": "Abstract\nTumor purity is the percent of cancer cells present in a sample of tumor tissue. The noncancerous cells (stromal cells) in a tumor are thought to have an important role in tumor growth, metastatic progression, and drug resistance. They also strongly influence genomic analyses of tumor samples. The Cancer Genome Atlas (TCGA) has extensive RNA-seq data from tumor tissue samples as well as assessments of tumor purity for the samples. Our goal is to select a subset of genes whose expression levels are predictive of tumor purity for each tumor type as well as a subset of genes whose expression levels are predictive of all tumor type samples when pooled together. We hope that the genes selected may provide insight about the cell-type composition of tumor samples and about the similarities and differences in tumor microenvironments. We use data from the TCGA, which covers 11 different tumor types and includes genome-wide assessments on over 3,148 samples for gene expression. To identify predictive genes, we used XGBoost, a supervised machine learning algorithm based on the idea of a boosted regression tree ensemble. We carried out 100 repeated runs of 10-fold cross-validations (total of 1,000 train-test partitions) for each tumor type and, also, for all tumor types combined. Using the training-set samples, XGBoost selects a set of genes to predict tumor purity levels; the selected genes are subsequently used to predict the purity levels of the test-set samples. Across the 1,000 train-test partitions for all 11 tumor types, the average root-mean-squared error ranged from 0.09 to 0.16 for the test sets. For each tumor type, we selected the top 250 genes based on their aggregated feature importance scores, a measure of each gene's contribution to tumor purity estimation. No single gene was among the top 250 in all 11 tumor types; however, ACAP1, AMICA1, CSF2RB, CYTIP, GGT5, GLIPR1, IRF4, and PECAM1 were not only among the top 250 in more than 6 tumor types but also in the top 250 when all tumors were combined, suggesting those genes might serve as biomarkers for tumor purity. The most common pathways from gene ontology analysis of these top genes include various immune and signaling pathways. We used XGBoost to identify genes whose expression levels were associated with tumor purity levels in each tumor type. Our results suggest that assessed tumor purity levels in tumor samples can be faithfully recapitulated using certain subsets of genes. We believe that those genes selected for each tumor type by our unbiased approach might provide insight into the biology of the tumor microenvironment, e.g., the presence of cell type-specific marker genes would indicate the presence of specific cell types.\nCitation Format: YuanYuan Li, Adrienna Bingham, Qi-Jing Li, Yuan Zhuang, David M. Umbach, Leping Li. Using tumor sample gene expression data to infer tumor purity levels with stochastic gradient boosting machines [abstract]. In: Proceedings of the American Association for Cancer Research Annual Meeting 2018; 2018 Apr 14-18; Chicago, IL. Philadelphia (PA): AACR; Cancer Res 2018;78(13 Suppl):Abstract nr 2255.",
        "link": "http://dx.doi.org/10.1158/1538-7445.am2018-2255"
    },
    {
        "id": 7061,
        "title": "An innovative approach for early detection of negative psychological thoughts using xtreme gradient boosting model with comparisons of light gradient boosting model on Reddit data",
        "authors": "Vignesh Paranthaman, Rama Parvathy Lakshmanan",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/5.0115171"
    },
    {
        "id": 7062,
        "title": "Classification of Vacational High School Graduates’ Ability in Industry using Extreme Gradient Boosting (XGBoost), Random Forest And Logistic Regression",
        "authors": "Afikah Agustiningsih, Yulian Findawati",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21070/ups.734"
    },
    {
        "id": 7063,
        "title": "POINT-WISE CLASSIFICATION OF HIGH-DENSITY UAV-LIDAR DATA USING GRADIENT BOOSTING MACHINES",
        "authors": "E. Sevgen, S. Abdikan",
        "published": "2023-8-15",
        "citations": 0,
        "abstract": "Abstract. Point-wise classification of 3D point clouds is a challenging task in point cloud processing, whereas, in particular, its application to high-density point clouds needs special attention because a large number of point clouds affect computational efficiency negatively. Although deep learning based models have been gaining popularity in recent years and have reached state-of-the-art results in accuracy for point-wise classification, their requirements of the high number of training samples and computational resources make those models inefficient for high-density 3D point clouds. However, traditional machine learning classifiers require less training samples, so they are capable of reducing computational requirements, even considering the latest machine learning classifiers, particularly in ensemble learning of gradient boosting machines, the results can compete with deep learning models. In this study, we are studying the point-wise classification of high-density UAV LiDAR data and focusing on efficient feature extraction and a recent state-of-the-art gradient boosting machine learning classifier, LightGBM. Our proposed framework includes the following steps: at first, we are using point cloud sampling for creating sub-sampled point clouds, then we are calculating the features based on those scales implemented on GPU. Finally, we are using the LightGBM classifier for training and testing. For the evaluation of our framework, we used a publicly available benchmark dataset, Hessigheim 3D. According to the results, we achieved an overall accuracy of 87.59% and an average F1 score of 75.92%. Our framework has promising results and scores closer to deep learning models. However, more distinctive features are required to obtain more accurate results.\n                    ",
        "link": "http://dx.doi.org/10.5194/isprs-archives-xlviii-m-1-2023-587-2023"
    },
    {
        "id": 7064,
        "title": "Gradient Boosting with Extreme Learning Machines for the Optimization of Nonlinear Functionals",
        "authors": "Cristiano Cervellera, Danilo Macciò",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-34960-8_7"
    },
    {
        "id": 7065,
        "title": "Improved prediction of protein–protein interaction using a hybrid of functional-link Siamese neural network and gradient boosting machines",
        "authors": "Satyajit Mahapatra, Sitanshu Sekhar Sahu",
        "published": "2021-11-5",
        "citations": 10,
        "abstract": "Abstract\nIn this paper, for accurate prediction of protein–protein interaction (PPI), a novel hybrid classifier is developed by combining the functional-link Siamese neural network (FSNN) with the light gradient boosting machine (LGBM) classifier. The hybrid classifier (FSNN-LGBM) uses the fusion of features derived using pseudo amino acid composition and conjoint triad descriptors. The FSNN extracts the high-level abstraction features from the raw features and LGBM performs the PPI prediction task using these abstraction features. On performing 5-fold cross-validation experiments, the proposed hybrid classifier provides average accuracies of 98.70 and 98.38%, respectively, on the intraspecies PPI data sets of Saccharomyces cerevisiae and Helicobacter pylori. Similarly, the average accuracies for the interspecies PPI data sets of the Human-Bacillus and Human-Yersinia data sets are 98.52 and 97.40%, respectively. Compared with the existing methods, the hybrid classifier achieves higher prediction accuracy on the independent test sets and network data sets. The improved prediction performance obtained by the FSNN-LGBM makes it a flexible and effective PPI prediction model.",
        "link": "http://dx.doi.org/10.1093/bib/bbab255"
    },
    {
        "id": 7066,
        "title": "Predicting the climate impact of healthcare facilities using gradient boosting machines",
        "authors": "Hao Yin, Bhavna Sharma, Howard Hu, Fei Liu, Mehak Kaur, Gary Cohen, Rob McConnell, Sandrah P. Eckel",
        "published": "2024-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.cesys.2023.100155"
    },
    {
        "id": 7067,
        "title": "Análisis de la utilidad del algoritmo Gradient Boosting Machine (GBM) en la predicción del fracaso empresarial",
        "authors": "José Pozuelo Campillo, Julián Martínez Vargas, Pedro Carmona Ibáñez",
        "published": "2018-10-2",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/02102412.2018.1442039"
    },
    {
        "id": 7068,
        "title": "Cybersecurity Attack Detection using Gradient Boosting Classifier",
        "authors": "N. Chaitanya Kumar, Jasmine Sabeena",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIn the rapidly evolving digital landscape, cybersecurity attacks have become increasingly sophisticated, posing monumental threats to organi- zations and individuals alike. Among the myriad of cyber threats, our focus in this paper is on detecting anomalies indicative of potential cy- ber attacks, specifically targeting network traffic. Detecting these attacks promptly and accurately is not just a technical challenge but a necessity to ensure data integrity, user trust, and operational continuity. This paper presents a comprehensive approach to detect such cybersecurity anoma- lies using the Gradient Boosting Classifier, a machine learning algorithm renowned for its predictive prowess. Our proposed solution encompasses advanced data preprocessing techniques, meticulous feature engineering, and rigorous model evaluation metrics. The applications of such a detec- tion system are vast, spanning across sectors like finance, healthcare, and e-commerce, acting as a bulwark against data breaches and unauthorized intrusions. The paper outlines our methodology, from data acquisition and preprocessing to modeling and evaluation, providing a blueprint for effective cyber attack detection.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3711213/v1"
    },
    {
        "id": 7069,
        "title": "Day-ahead Forecasting of Solar Power Output from Photovoltaic Systems Utilising Gradient Boosting Machines",
        "authors": "Spyros Theocharides, Venizelos Venizelou, George Makrides, George E. Georghiou",
        "published": "2018-6",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/pvsc.2018.8547375"
    },
    {
        "id": 7070,
        "title": "Dynamic Early-Warning of Enterprise Financial Distress Based on Gradient Boosting Algorithm",
        "authors": "Ying Peng, Ziyi Chen, Jingyi Wang",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012022800003620"
    },
    {
        "id": 7071,
        "title": "Improving Accuracy and Speed of Network-based Intrusion Detection using Gradient Boosting Trees",
        "authors": "Ryosuke Terado, Morihiro Hayashida",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008963504900497"
    },
    {
        "id": 7072,
        "title": "Classification Performance Boosting for Interpolation Kernel Machines by Training Set Pruning Using Genetic Algorithm",
        "authors": "Jiaqi Zhang, Xiaoyi Jiang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012467200003654"
    },
    {
        "id": 7073,
        "title": "Gradient Boosting",
        "authors": "Brad Boehmke, Brandon Greenwell",
        "published": "2019-11-7",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780367816377-12"
    },
    {
        "id": 7074,
        "title": "State-of-Charge Estimation of Li-ion Battery Cell using Support Vector Regression and Gradient Boosting Techniques",
        "authors": "Eymen Ipek, M. Kerem Eren, Murat Yilmaz",
        "published": "2019-8",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/acemp-optim44294.2019.9007188"
    },
    {
        "id": 7075,
        "title": "Gradient Boosting Machine",
        "authors": "V Kishore Ayyadevara",
        "published": "2018",
        "citations": 52,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-3564-5_6"
    },
    {
        "id": 7076,
        "title": "Machine Learning Model Using Extreme Gradient Boosting (XGBoost) Feature Importance and Light Gradient Boosting Machine (LightGBM) to Improve Accurate Prediction of Bankruptcy",
        "authors": "Risma Moulidya Syafei, Devi Ajeng Efrilianda",
        "published": "2023-9-29",
        "citations": 0,
        "abstract": "Abstract. Humans have limitations in processing and analyzing large amounts of data in a short time, including in terms of analyzing bankruptcy data. Bankruptcy data is one of the data that has complex information, so it requires technology that can assist in the process of analyzing and processing data more quickly and efficiently. Data science technology enables data processing and analysis on a large scale, using parallel processing techniques. Parallel processing can be implemented in machine learning models.\r\nPurpose: Using parallel processing techniques, data science technologies enable data processing and analysis at scale. Parallel processing can be implemented in machine learning models. Therefore, this study aims to implement a machine learning model using the Light Gradient Boosting Machine (LightGBM) classification algorithm which is optimized using Extreme Gradient Boosting (XGBoost) Feature Importance to increase the accuracy of bankruptcy prediction.\r\nMethods/Study design/approach: Bankruptcy prediction is carried out by applying LightGBM as a classification model and optimized using the XGBoost algorithm as a Feature Importance technique to improve model accuracy. the dataset used is the Taiwanese Bankruptcy dataset collected from the Taiwan Economic Journal for 1999 to 2009 and has 6,819 data. Taiwanese Bankruptcy is unbalanced data, so this study applies random oversampling.\r\nResult/Findings: The results obtained after going through the model testing process using the confusion matrix obtained an accuracy of the performance of LightGBM+XGBoost Feature Importance of 99.227%.\r\nNovelty/Originality/Value: So it can be concluded that the implementation of XGBoost Feature Importance can be used to improve LightGBM's performance in bankruptcy prediction.",
        "link": "http://dx.doi.org/10.15294/rji.v1i2.71229"
    },
    {
        "id": 7077,
        "title": "Introducing Gradient Boosting as a universal gap filling tool for meteorological time series",
        "authors": "Philipp Körner, Rico Kronenberg, Sandra Genzel, Christian Bernhofer",
        "published": "2018-12-7",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1127/metz/2018/0908"
    },
    {
        "id": 7078,
        "title": "A Robust Boosting Model for detecting Cervical Cancer Using Histogram Boosting Gradient Classifier",
        "authors": "N. Meenakshisundaram, G. Ramkumar",
        "published": "2023-4-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iconstem56934.2023.10142889"
    },
    {
        "id": 7079,
        "title": "Phosphorylation site prediction using gradient tree boosting",
        "authors": "",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.28919/cmbn/4653"
    },
    {
        "id": 7080,
        "title": "Applying gradient tree boosting to QTL mapping with Shapley additive explanations",
        "authors": "Tomohiro Ishibashi, Akio Onogi",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractMapping quantitative trait loci (QTLs) is one of the major goals of quantitative genetics; however, identifying the interactions between QTLs remains challenging. Recently developed machine learning methods, such as deep learning and gradient boosting, are transforming the real world. These methods could advance QTL mapping methodologies because of their high capability for capturing complex relationships among features. One problem with applying such complex models to QTL mapping is evaluation of feature importance. In this study, XGBoost, a popular gradient tree boosting algorithm, was applied for QTL mapping in biparental populations with Shapley additive explanations (SHAPs). SHAP is a local (i.e., instance-wise) importance index with the desired properties as feature importance indices. The SHAP-assisted XGBoost (SHAP-XGB) was compared with conventional methods, including likelihood ratio tests (LRT), composite interval mapping (CIM), multiple interval mapping (MIM), and BayesC, using simulations and rice heading date data. SHAP-XGB performed comparable to CIM, MIM, and BayesC in mapping main QTL effects and was superior to conventional methods in mapping QTL interaction effects. As SHAP can evaluate local importance, interactions between markers can be visualized by plotting SHAP interaction values for each instance (plant/line). These results illustrated the strength of SHAP-XGB in detecting and interpreting epistatic QTLs and suggest the possibility that SHAP-XGB complements conventional methods.",
        "link": "http://dx.doi.org/10.1101/2024.01.15.575690"
    },
    {
        "id": 7081,
        "title": "Multioutput Regression Neural Network Training via Gradient Boosting",
        "authors": "seyedsaman emami, Gonzalo Martínez-Muñoz",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14428/esann/2022.es2022-95"
    },
    {
        "id": 7082,
        "title": "Stock Selection Based on Extreme Gradient Boosting",
        "authors": "Xiaoyun Zhang, Wanyi Chen",
        "published": "2019-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/chicc.2019.8865781"
    },
    {
        "id": 7083,
        "title": "Performance Analysis of Gradient Boosting Models for Forex Market Prediction",
        "authors": "Arash Eslami Ghayour, Ali Yousefi",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4450688"
    },
    {
        "id": 7084,
        "title": "Estimating energy savings of ultra-high-performance fibre-reinforced concrete facade panels at the early design stage of buildings using gradient boosting machines",
        "authors": "B. Abediniangerabi, A. Makhmalbaf, M. Shahandashti",
        "published": "2022-7-4",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/17512549.2021.2011410"
    },
    {
        "id": 7085,
        "title": "Predicting CKD progression using time-series clustering and light gradient boosting machines",
        "authors": "Hirotaka Saito, Hiroki Yoshimura, Kenichi Tanaka, Hiroshi Kimura, Kimio Watanabe, Masaharu Tsubokura, Hiroki Ejiri, Tianchen Zhao, Akihiko Ozaki, Sakumi Kazama, Michio Shimabukuro, Koichi Asahi, Tsuyoshi Watanabe, Junichiro J. Kazama",
        "published": "2024-1-19",
        "citations": 0,
        "abstract": "AbstractPredicting the transition of kidney function in chronic kidney disease is difficult as specific symptoms are lacking and often overlooked, and progress occurs due to complicating factors. In this study, we applied time-series cluster analysis and a light gradient boosting machine to predict the trajectories of kidney function in non-dialysis dependent chronic kidney disease patients with baseline estimated glomerular filtration rate (GFR) ≥ 45 mL/min/1.73 m2. Based on 5-year changes in estimated GFR, participants were stratified into groups with similar trajectories by cluster analysis. Next, we applied the light gradient boosting machine algorithm and Shapley addictive explanation to develop a prediction model for clusters and identify important parameters for prediction. Data from 780 participants were available for analysis. Participants were classified into five classes (Class 1: n = 78, mean [± standard deviation] estimated GFR 100 ± 19.3 mL/min/1.73 m2; Class 2: n = 176, 76.0 ± 9.3 mL/min/1.73 m2; Class 3: n = 191, 59.8 ± 5.9 mL/min/1.73 m2; Class 4: n = 261, 52.7 ± 4.6 mL/min/1.73 m2; and Class 5: n = 74, 53.5 ± 12.0 mL/min/1.73 m2). Declines in estimated GFR were 8.9% in Class 1, 12.2% in Class 2, 4.9% in Class 3, 12.0% in Class 4, and 45.1% in Class 5 during the 5-year period. The accuracy of prediction was 0.675, and the top three most important Shapley addictive explanation values were 1.61 for baseline estimated GFR, 0.12 for hemoglobin, and 0.11 for body mass index. The estimated GFR transition of patients with preserved chronic kidney disease mostly depended on baseline estimated GFR, and the borderline for estimated GFR trajectory was nearly 50 mL/min/1.73 m2.",
        "link": "http://dx.doi.org/10.1038/s41598-024-52251-9"
    },
    {
        "id": 7086,
        "title": "Identification of symptoms related to potato Verticillium wilt from UAV-based multispectral imagery using an ensemble of gradient boosting machines",
        "authors": "Ivan Lizarazo, Jorge Luis Rodriguez, Omar Cristancho, Felipe Olaya, Marlon Duarte, Flavio Prieto",
        "published": "2023-2",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.atech.2022.100138"
    },
    {
        "id": 7087,
        "title": "A Novel Purchase Target Prediction System using Extreme Gradient Boosting Machines",
        "authors": "Shambhu Nath Sharma,  , Dr. S. Prasanna,  ",
        "published": "2019-8-30",
        "citations": 1,
        "abstract": "In recent days, electronic business (E-trade) gives more changeto buyers as well as opens doors in web based promoting and advertising. Online promoters can see increasingly about buyer inclinations, dependent on their day by day web-based shopping and surfing. The advancement of big data and distributed computing systems further engage promoters and advertisers to have an information driven and purchaser explicit inclination proposal dependent on the web-basedsurfing narratives. In this article, a decision supportive network is proposed to anticipate a customer buy intentionin the middle of surfing. The proposed decision support framework classifies surfing sessions into sales based and common methods utilizing extreme boosting machines. The proposed technique further demonstrates its solid forecasting ability contrasted with other benchmark calculations which includes logistic retrogression and conventional ensemble brands. The suggested technique can be executed in actual time offering calculations for web-based publicizing methodologies. Promotion on surfing session with potential buying expectation enhance the successfulof ads.",
        "link": "http://dx.doi.org/10.35940/ijitee.j9331.0881019"
    },
    {
        "id": 7088,
        "title": "Predictive Performances of Ensemble Machine Learning Algorithms in Landslide Susceptibility Mapping Using Random Forest, Extreme Gradient Boosting (XGBoost) and Natural Gradient Boosting (NGBoost)",
        "authors": "Taskin Kavzoglu, Alihan Teke",
        "published": "2022-6",
        "citations": 87,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s13369-022-06560-8"
    },
    {
        "id": 7089,
        "title": "Detecting careless responding in survey data using stochastic gradient boosting",
        "authors": "Ulrich Schroeders, Christoph Schmidt, Timo Gnambs",
        "published": "No Date",
        "citations": 0,
        "abstract": "Careless responding is considered a bias in survey responses without regard to the actual item content which constitutes a threat to the factor structure, reliability, and validity of psychological measurements. Different approaches have been proposed to detect aberrant responses such as probing questions that directly assess test-taking behavior (e.g., bogus items), auxiliary or paradata (e.g., response times), or data-driven statistical techniques (e.g., Mahalanobis distance). In the present study, gradient boosted trees, a state-of-the art machine learning technique, are introduced to identify carleess responders. The performance of the approach was compared to established techniques previously described in the literature (e.g., statistical outlier methods, consistency analyses, and response pattern functions) using simulated data and empirical data from a web-based study, in which diligent vs. careless response behavior were induced. The comparison between the results of the simulation and the online study showed that simulations that rely on prototypical pattern of careless responses tend to overestimate the classification accuracy. Gradient boosted trees outperform traditional detection mechanisms in flagging aberrant responses, especially by including response times as paradata, but are not to be misunderstood as a panacea of data cleaning. We critically discuss the results with regard to their generalizability and provide recommendations for the detection of aberrant response patterns in survey research.",
        "link": "http://dx.doi.org/10.31234/osf.io/vs37k"
    },
    {
        "id": 7090,
        "title": "21 Extreme Gradient Boosting",
        "authors": "",
        "published": "2021-3-22",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110671124-021"
    },
    {
        "id": 7091,
        "title": "pGBF: Personalized Gradient Boosting Forest",
        "authors": "Batnyam Enkhtaivan, Isamu Teranishi",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191289"
    },
    {
        "id": 7092,
        "title": "Electrical Load Forecasting Using Hybrid of Extreme Gradient Boosting and Light Gradient Boosting Machine",
        "authors": "Eric Nziyumva, Rong Hu, Chih-Yu Hsu, Jovial Niyogisubizo",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-6963-7_95"
    },
    {
        "id": 7093,
        "title": "IMPLEMENTATION OF MULTI-CLASS GRADIENT BOOSTING TO CLASSIFY ANIMAL SPECIES IN ZOOS",
        "authors": " Sri Diantika,  Hiya Nalatissifa,  Riki Supriyadi,  Nurlaelatul Maulidah,  Ahmad Fauzi",
        "published": "2023-6-3",
        "citations": 0,
        "abstract": "Animals are one of the living things that have various types. Grouping types of animals based on similarities and differences in characteristics owned is one of the important activities carried out To make it easier to compare, recognize, study certain types of animals and be able to find out kinship relationships between animals, So if a new type of animal is found that does not yet have a name, it will be easier for us to give a name to the animal based on the type and based on the group. In research on the classification of animal species in zoos that have multi-class, the best classification is obtained by applying gradient boosting parameters with n_estimators of 50, max_depth 3, sub-sample of 1.0, learning rate of 0.1, and using criterion friedman Mse. And by implementing Split validation or division between training data by 80% for training data and 20% for testing data. The results stated that the proposed model was better than some other models that had also been tested with an accuracy value of 93.75%, recal of 94%, precision of 96% and MSE to measure the average magnitude of error in a series of classifications of 12.5%, the smaller the MSE value, the better it would be in classifying.",
        "link": "http://dx.doi.org/10.35457/antivirus.v17i1.2812"
    },
    {
        "id": 7094,
        "title": "Using an Extreme Gradient Boosting Learner for Mapping Hydrogeochemical Parameters in Germany",
        "authors": "Maximilian Nölscher, Stefan Broda",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Information on the spatial distribution of hydrogeochemical parameters is crucial for decision making. Machine learning based methods for the mapping of hydrogeochemical parameter concentrations have been already studied for many years to evolve from deterministic and geostatistical interpolation methods. However, the reflection of all relevant processes that the target variable depends on is often difficult to achieve, because of the mostly insufficient determination and/or availability of features. This is especially true if you limit yourself to freely accessible data.&lt;/p&gt;&lt;p&gt;In this study, we apply an extreme gradient boosting learner (XGB) to map major ion concentrations across Germany. The training data consist of water samples from approximately 50K observation wells across Germany and a wide range of environmental data as predictors. The water samples were collected between the 1950s and 2005 at anthropogenically undisturbed locations.&lt;/p&gt;&lt;p&gt;The environmental data includes hydrogeological units and parameters, soil type, lithology, digital elevation model (DEM) and DEM derived parameters etc. The values of these features at the respective water sample location were extracted on the basis of a polygon, approximately representing the area that has an impact on the target variable (ion concentration). For a comparison, different polygon shapes are used.&lt;/p&gt;&lt;p&gt;The model was set up as chained multioutput regression, meaning that the prediction of the previous model in a linear sequence of single-output models is used as input for the subsequent model.&lt;/p&gt;&lt;p&gt;The results are planned to serve for a comparison with state-of-the-art deep learning architectures.&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu21-12818"
    },
    {
        "id": 7095,
        "title": "Regional flood frequency analysis using extreme gradient boosting based on Bayesian optimization.",
        "authors": "Deva Jarajapu, Rathinasamy Maheswaran",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/essoar.10509264.1"
    },
    {
        "id": 7096,
        "title": "Detecting Careless Responding in Survey Data  Using Stochastic Gradient Boosting",
        "authors": "Ulrich Schroeders, Christoph Schmidt, Timo Gnambs",
        "published": "No Date",
        "citations": 1,
        "abstract": "Careless responding is considered a bias in survey responses without regard to the actual item content which constitutes a threat to the factor structure, reliability, and validity of psychological measurements. Different approaches have been proposed to detect aberrant responses such as probing questions that directly assess test-taking behavior (e.g., bogus items), auxiliary or paradata (e.g., response times), or data-driven statistical techniques (e.g., Mahalanobis distance). In the present study, gradient boosted trees, a state-of-the art machine learning technique, are introduced to identify carleess responders. The performance of the approach was compared to established techniques previously described in the literature (e.g., statistical outlier methods, consistency analyses, and response pattern functions) using simulated data and empirical data from a web-based study, in which diligent vs. careless response behavior were induced. The comparison between the results of the simulation and the online study showed that simulations that rely on prototypical pattern of careless responses tend to overestimate the classification accuracy. Gradient boosted trees outperform traditional detection mechanisms in flagging aberrant responses, especially by including response times as paradata, but are not to be misunderstood as a panacea of data cleaning. We critically discuss the results with regard to their generalizability and provide recommendations for the detection of aberrant response patterns in survey research.",
        "link": "http://dx.doi.org/10.31234/osf.io/f94zk"
    },
    {
        "id": 7097,
        "title": "Extreme Gradient Boosting algorithm classification for predicting lifespan-extending chemical compounds",
        "authors": "Mariia Yarmolenko, Brendan Howlin",
        "published": "No Date",
        "citations": 2,
        "abstract": "Abstract\nHuman ageing has a great impact on global economy and society’s health with the risk factors for many chronic diseases. Discovery of the pharmaceutical interventions with the potential of promoting longevity and delaying the onset of age-associated diseases is one of the most challenging tasks in anti-ageing research today.\nThe aim of this study was to build a new machine learning model based on the data of the DrugAge database to predict whether a chemical compound will extend the lifespan of the worm species Caenorhabditis elegans. The predictive models were built using the optimized Extreme Gradient Boosting algorithm with molecular fingerprints and molecular descriptors as features. The ranking of the models’ features was done with the built-in Extreme Gradient Boosting feature importance function and interpreted with confidence using Shapley values. The top 15 most important features included 2D molecular descriptors related to the subdivided surface areas, atom and bond counts, and electrostatic properties. The best performing model was applied to predict the class of compounds in the external database, DrugBank, consisting of approved small-molecules. The chemical compounds of the external database with a predictive probability of  for increasing the lifespan of Caenorhabditis elegans were broadly separated into (i) flavonoids and isoflavonoids, (ii) fatty acids and conjugates, and (iii) other classes of compounds.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2199002/v1"
    },
    {
        "id": 7098,
        "title": "New Findings From Explainable SYM‐H Forecasting Using Gradient Boosting Machines",
        "authors": "Daniel Iong, Yang Chen, Gabor Toth, Shasha Zou, Tuija Pulkkinen, Jiaen Ren, Enrico Camporeale, Tamas Gombosi",
        "published": "2022-8",
        "citations": 11,
        "abstract": "AbstractIn this work, we develop gradient boosting machines (GBMs) for forecasting the SYM‐H index multiple hours ahead using different combinations of solar wind and interplanetary magnetic field (IMF) parameters, derived parameters, and past SYM‐H values. Using Shapley Additive Explanation values to quantify the contributions from each input to predictions of the SYM‐H index from GBMs, we show that our predictions are consistent with physical understanding while also providing insight into the complex relationship between the solar wind and Earth's ring current. In particular, we found that feature contributions vary depending on the storm phase. We also perform a direct comparison between GBMs and neural networks presented in prior publications for forecasting the SYM‐H index by training, validating, and testing them on the same data. We find that the GBMs yield a statistically significant improvement in root mean squared error over the best published black‐box neural network schemes and the Burton equation.",
        "link": "http://dx.doi.org/10.1029/2021sw002928"
    },
    {
        "id": 7099,
        "title": "Computer Vision-Based Severity Classification of Asphalt Pavement Raveling Using Advanced Gradient Boosting Machines and Lightweight Texture Descriptors",
        "authors": "Hoang Nhat-Duc, Tran Van-Duc",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s40996-023-01138-2"
    },
    {
        "id": 7100,
        "title": "Enhanced Gradient Boosting Machines Fusion based on the Pattern of Majority Voting for Automatic Epilepsy Detection",
        "authors": "Dwi Sunaryono, Riyanarto Sarno, Joko Siswantoro, Diana Purwitasari, Shoffi Izza Sabilla, Rahadian Indarto Susilo, Adam Abelard Garibaldi",
        "published": "2022",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14569/ijacsa.2022.0130771"
    }
]