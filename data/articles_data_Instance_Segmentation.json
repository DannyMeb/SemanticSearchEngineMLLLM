[
    {
        "id": 12671,
        "title": "Instance Segmentation as Image Segmentation Annotation",
        "authors": "Thomio Watanabe, Denis F. Wolf",
        "published": "2019-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ivs.2019.8814026"
    },
    {
        "id": 12672,
        "title": "Object Detection and Instance Segmentation in Construction Sites",
        "authors": "Cong Zhang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4750768"
    },
    {
        "id": 12673,
        "title": "Semantic segmentation-assisted instance feature fusion for multi-level 3D part instance segmentation",
        "authors": "Chun-Yu Sun, Xin Tong, Yang Liu",
        "published": "2023-12",
        "citations": 1,
        "abstract": "AbstractRecognizing 3D part instances from a 3D point cloud is crucial for 3D structure and scene understanding. Several learning-based approaches use semantic segmentation and instance center prediction as training tasks and fail to further exploit the inherent relationship between shape semantics and part instances. In this paper, we present a new method for 3D part instance segmentation. Our method exploits semantic segmentation to fuse nonlocal instance features, such as center prediction, and further enhances the fusion scheme in a multi- and cross-level way. We also propose a semantic region center prediction task to train and leverage the prediction results to improve the clustering of instance points. Our method outperforms existing methods with a large-margin improvement in the PartNet benchmark. We also demonstrate that our feature fusion scheme can be applied to other existing methods to improve their performance in indoor scene instance segmentation tasks.\n",
        "link": "http://dx.doi.org/10.1007/s41095-022-0300-x"
    },
    {
        "id": 12674,
        "title": "Beyond Semantic to Instance Segmentation: Weakly-Supervised Instance Segmentation via Semantic Knowledge Transfer and Self-Refinement",
        "authors": "Beomyoung Kim, Youngjoon Yoo, Chae Eun Rhee, Junmo Kim",
        "published": "2022-6",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52688.2022.00424"
    },
    {
        "id": 12675,
        "title": "Instance Segmentation Based Graph Extraction for Handwritten Circuit Diagram Images",
        "authors": "Johannes Bayer, Amit Roy, Andreas Dengel",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011752600003411"
    },
    {
        "id": 12676,
        "title": "Seven benchmark datasets of instance segmentation of mitochondria: 6 diverse volume EM + 1 TEM (100 images) datasets",
        "authors": "Narayan K, Conrad RW",
        "published": "2022-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.6019/empiar-10982"
    },
    {
        "id": 12677,
        "title": "Adapting Video Instance Segmentation for Instance Search",
        "authors": "An Thi Nguyen",
        "published": "2023-9-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3617233.3617249"
    },
    {
        "id": 12678,
        "title": "Foveal Vision for Instance Segmentation of Road Images",
        "authors": "Benedikt Ortelt, Christian Herrmann, Dieter Willersinn, Jürgen Beyerer",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006616103710378"
    },
    {
        "id": 12679,
        "title": "Single-Class Instance Segmentation for Vectorization of Line Drawings",
        "authors": "Rhythm Vohra, Amanda Dash, Alexandra Branzan Albu",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012465900003660"
    },
    {
        "id": 12680,
        "title": "WormSwin: Instance segmentation of C. elegans using vision transformer",
        "authors": "Maurice Deserno, Katarzyna Bozek",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractThe possibility to extract motion of a single organism from video recordings at a large-scale provides means for the quantitative study of its behavior, both individual and collective. This task is particularly difficult for organisms that interact with one another, overlap, and occlude parts of their bodies in the recording. Here we propose WormSwin - an approach to extract single animal postures of Caenorhabditis elegans (C. elegans) from recordings of many organisms in a single microscope well. Based on transformer neural network architecture our method segments individual worms across a range of videos and images generated in different labs. Our solutions offers accuracy of 0.990 average precision (AP0.50) and comparable results on the benchmark image dataset BBBC010. Finally, it allows to segment challenging overlapping postures of mating worms with an accuracy sufficient to track the organisms with a simple tracking heuristic. An accurate and efficient method forC. eleganssegmentation opens up new opportunities for studying of its behaviors previously inaccessible due to the difficulty in the worm extraction from the video frames.",
        "link": "http://dx.doi.org/10.1101/2023.04.10.536324"
    },
    {
        "id": 12681,
        "title": "Semantic Instance Meets Salient Object: Study on Video Semantic Salient Instance Segmentation",
        "authors": "Trung-Nghia Le, Akihiro Sugimoto",
        "published": "2019-1",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wacv.2019.00194"
    },
    {
        "id": 12682,
        "title": "One Shot Learning for Generic Instance Segmentation in RGBD Videos",
        "authors": "Xiao Lin, Josep Casas, Montse Pardàs",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007259900002108"
    },
    {
        "id": 12683,
        "title": "Vehicle Instance Segmentation Polygonal Dataset for Private Surveillance System",
        "authors": "Najmath Ottakath, Somaya Al-Maadeed",
        "published": "No Date",
        "citations": 0,
        "abstract": "Vehicle identification is an important task in traffic monitoring because it allows for efficient inference and provides a cause for action. Vehicle classification via deep learning and other approaches such as segmentation is a critical tool for re-identification. In this paper, instance segmentation is used to identify vehicle makes with license plate detection, allowing for better unique vehicle recognition for re-identification. A dataset is annotated and modified, for example, by segmenting it with polygonal bounding boxes that capture the vehicle's unique frontal features. In addition, license plate localization is performed. The results showed improved classification as well as a high mAP for the dataset when compared to previous approaches based on CNN and deformed CNN. Furthermore, a deep residual network and fully connected layer-based classification were utilized as the backbone for feature representation. Instance segmentation detects objects by segmenting and classifying regions of interest. The imbalance in the dataset is resolved using a mosaic-tiled approach, which produces greater precision than other approaches.",
        "link": "http://dx.doi.org/10.20944/preprints202212.0475.v3"
    },
    {
        "id": 12684,
        "title": "Instance Segmentation of Event Camera Streams in Outdoor Monitoring Scenarios",
        "authors": "Tobias Bolten, Regina Pohle-Fröhlich, Klaus Tönnies",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012369100003660"
    },
    {
        "id": 12685,
        "title": "Melanoma Recognition and Lesion Segmentation using Multi-Instance Learning",
        "authors": "Yangling Ma, Zhouwang Yang",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nMelanoma is one of the deadliest forms of skin cancer, but early and accurate identification can significantly improve the survival rate of patients. In this paper, an end-to-end framework based on multi-instance learning is proposed for melanoma recognition and lesion segmentation simultaneously. To make full use from the information of high-resolution images, we take each image block (super-pixel) as an instance in a bag and use multi-instance learning based on a graph convolutional network to recognize melanoma. Moreover, skin lesion segmentation is derived from attention weights and is calibrated by classification probability vectors. As a result, the AUC of our method for melanoma recognition reaches 0.93, which is much higher compared with other related methods. Also, the Jaccard index (JA) of our method for melanoma-related skin lesion segmentation reaches 0.699. In our end-to-end approach, segmentation and recognition are treated as intimately coupled processes, and hence, a high JA is also an indication of the reliability of melanoma recognition. Collectively, these findings confirmed that our method effectively assists melanoma diagnosis.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-930865/v1"
    },
    {
        "id": 12686,
        "title": "Pixel Level Instance Segmentation using Single Shot Detectors and Semantic Segmentation Networks",
        "authors": "Akash C, Laseena C A",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3441530"
    },
    {
        "id": 12687,
        "title": "Indoor Instance-Aware Semantic Mapping Using Instance Segmentation",
        "authors": "Yinpeng Jiang, Xudong Ma, Fang Fang, Xuewen Kang",
        "published": "2021-5-22",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ccdc52312.2021.9602282"
    },
    {
        "id": 12688,
        "title": "One Shot Learning for Generic Instance Segmentation in RGBD Videos",
        "authors": "Xiao Lin, Josep Casas, Montse Pardàs",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007259902330239"
    },
    {
        "id": 12689,
        "title": "BiSeg: Simultaneous Instance Segmentation and Semantic Segmentation with Fully Convolutional Networks",
        "authors": "Viet Pham, Satoshi Ito, Tatsuo Kozakaya",
        "published": "2017",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5244/c.31.60"
    },
    {
        "id": 12690,
        "title": "Video Instance Segmentation by Instance Flow Assembly",
        "authors": "Xiang Li, Jinglu Wang, Xiao Li, Yan Lu",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tmm.2022.3222643"
    },
    {
        "id": 12691,
        "title": "Box-Supervised Dynamical Instance Segmentation for In-Field Cotton",
        "authors": "Yanan Li, Dingrun Zheng, Yifei Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4457370"
    },
    {
        "id": 12692,
        "title": "A Deep Learning Approach for Object Detection and Instance Segmentation using Mask RCNN",
        "authors": "Maibam Mangalleibi Chanu",
        "published": "2020-2-28",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5373/jardcs/v12sp3/20201242"
    },
    {
        "id": 12693,
        "title": "MilInst: Enhanced Instance Segmentation Framework for Military Camouflaged Targets Using Sparse Instance Activation",
        "authors": "Bing Li, Enze Zhu, Rongqian Zhou, Huang Cheng",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2023.3318486"
    },
    {
        "id": 12694,
        "title": "Spontaneous breaking of symmetry in overlapping cell instance segmentation using diffusion models",
        "authors": "Julius B. Kirkegaard",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractInstance segmentation is the task of assigning unique identifiers to individual objects in images. Solving this task requires breaking the inherent symmetry that semantically similar objects must result in distinct outputs. Deep learning algorithms bypass this break-of-symmetry by training specialized predictors or by utilizing intermediate label representations. However, many of these approaches break down when faced with overlapping labels that can appear, e.g., in biological cell layers. Here, we discuss the reason for this failure and offer a novel approach for instance segmentation based on diffusion models that breaks this symmetry spontaneously. Our method outputs pixel-level instance segmentations matching the performance of models such as cellpose on the cellpose fluorescent cell dataset while also permitting overlapping labels.",
        "link": "http://dx.doi.org/10.1101/2023.07.07.548066"
    },
    {
        "id": 12695,
        "title": "Polygonal Dataset for Vehicle Instance Segmentation for Private Surveillance System",
        "authors": "Najmath Ottakath, Somaya Al-Maadeed",
        "published": "No Date",
        "citations": 0,
        "abstract": "Vehicle identification is an important task in traffic monitoring because it allows for efficient inference and provides a cause for action. Vehicle classification via deep learning and other approaches such as segmentation is a critical tool for re-identification. In this paper, instance segmentation is used for vehicle make identification with license plate detection, allowing for better unique vehicle recognition for re-identification. An existing dataset is re-annotated and modified for polygonal segmentation of the vehicle&rsquo;s unique frontal features, resulting in representation of the vehicle with its frontal form learned. In addition, an additional license plate identification class is added for efficient re-identification further down the re-identification and tracking pipeline. Furthermore, an additional class of license plate identification is added for efficient re-identification further down the re-identification and tracking pipeline. The results showed improved classification as well as a high mAP for the dataset when compared to previous approaches based on CNN and deformed CNN. Furthermore, a deep residual network and fully connected layer-based classification were utilized as the backbone for feature representation. Instance segmentation detects objects by segmenting and classifying regions of interest. The imbalance in the dataset is resolved using a mosaic-tiled approach, which produces greater precision than other approaches evaluated for in the paper.",
        "link": "http://dx.doi.org/10.20944/preprints202212.0475.v1"
    },
    {
        "id": 12696,
        "title": "Polygonal Dataset for Vehicle Instance Segmentation for Private Surveillance System",
        "authors": "Najmath Ottakath, Somaya Al-Maadeed",
        "published": "No Date",
        "citations": 0,
        "abstract": "Vehicle identification is an important task in traffic monitoring because it allows for efficient inference and provides a cause for action. Vehicle classification via deep learning and other approaches such as segmentation is a critical tool for re-identification. In this paper, instance segmentation is used for vehicle make identification with license plate detection, allowing for better unique vehicle recognition for re-identification. An existing dataset is re-annotated and modified for polygonal segmentation of the vehicle&rsquo;s unique frontal features, resulting in representation of the vehicle with its frontal form learned. In addition, an additional license plate identification class is added for efficient re-identification further down the re-identification and tracking pipeline. Furthermore, an additional class of license plate identification is added for efficient re-identification further down the re-identification and tracking pipeline. The results showed improved classification as well as a high mAP for the dataset when compared to previous approaches based on CNN and deformed CNN. Furthermore, a deep residual network and fully connected layer-based classification were utilized as the backbone for feature representation. Instance segmentation detects objects by segmenting and classifying regions of interest. The imbalance in the dataset is resolved using a mosaic-tiled approach, which produces greater precision than other approaches evaluated for in the paper.",
        "link": "http://dx.doi.org/10.20944/preprints202212.0475.v2"
    },
    {
        "id": 12697,
        "title": "Corrections to “Ensemble of Instance Segmentation Models for Polyp Segmentation in Colonoscopy Images”",
        "authors": "Jaeyong Kang, Jeonghwan Gwak",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2020.2995611"
    },
    {
        "id": 12698,
        "title": "Anchor-Free Proposal Network for Two-Stage Instance Segmentation",
        "authors": "Guohua Zhu, Jaehan Joo, Suk Chan Kim",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4421667"
    },
    {
        "id": 12699,
        "title": "Transforming Semantic Segmentation into Instance Segmentation with a Guided U-Net",
        "authors": "Roman Lavrynenko, Nataliya Ryabova",
        "published": "2023-10-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/csit61576.2023.10324276"
    },
    {
        "id": 12700,
        "title": "Weakly Supervised Cell-Instance Segmentation with Two Types of Weak Labels by Single Instance Pasting",
        "authors": "Kazuya Nishimura, Ryoma Bise",
        "published": "2023-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00320"
    },
    {
        "id": 12701,
        "title": "Learning Instance Activation Maps for Weakly Supervised Instance Segmentation",
        "authors": "Yi Zhu, Yanzhao Zhou, Huijuan Xu, Qixiang Ye, David Doermann, Jianbin Jiao",
        "published": "2019-6",
        "citations": 47,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr.2019.00323"
    },
    {
        "id": 12702,
        "title": "Three-step Approach for Localization, Instance Segmentation and Multi-facet Classification of Individual Logs in Wooden Piles",
        "authors": "Christoph Praschl, Gerald Zwettler",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010892100003122"
    },
    {
        "id": 12703,
        "title": "Efficient Instance and Semantic Segmentation for Automated Driving",
        "authors": "Andra Petrovai, Sergiu Nedevschi",
        "published": "2019-6",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ivs.2019.8814177"
    },
    {
        "id": 12704,
        "title": "The MIS Check-Dam Dataset for Object Detection and Instance Segmentation Tasks",
        "authors": "Chintan Tundia, Rajiv Kumar, Om Damani, G. Sivakumar",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010799600003124"
    },
    {
        "id": 12705,
        "title": "N-MuPeTS: Event Camera Dataset for Multi-Person Tracking and Instance Segmentation",
        "authors": "Tobias Bolten, Christian Neumann, Regina Pohle-Fröhlich, Klaus Tönnies",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011680300003417"
    },
    {
        "id": 12706,
        "title": "Instance Segmentation and Detection of Children to Safeguard Vulnerable Traffic User by Infrastructure",
        "authors": "Shiva Agrawal, Savankumar Bhanderi, Sumit Amanagi, Kristina Doycheva, Gordon Elger",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011825400003479"
    },
    {
        "id": 12707,
        "title": "TLIS: Two-stage low-light image instance segmentation",
        "authors": "Wei Li, Ya Huang, Xinyuan Zhang, Guijin Han",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nCurrent instance segmentation models perform adequately under normal light conditions, but encounter significant challenges in low-light scenarios, where the feature information of objects becomes less discernible, thus impeding accurate segmentation. The present study proposes a two-stage methodology for instance segmentation in low-light images. In stage-I, we enhance the low-light images while denoising and enhancing the detail information. To mitigate degradation phenomena such as noise and loss of details caused by low-light image enhancement (LLIE), we propose a post-processing module for enhancing details while reducing noise. This module uses a diffusion approach with an attention mechanism to model the conditional distribution between under-enhanced and naturally illuminated images. The enhancement results from the first stage are used as input to the segmentation network in the second stage, and we observe that incorporating fine-grained features into the mask branch of the segmentation network positively affects the accurate delineation of finer masks. To achieve this objective, we devise a wavelet feature fusion module to effectively integrate the high-resolution and low-resolution features within the feature pyramid, thereby preserving more intricate details. We achieve great segmentation results on LIS, an extremely low-light instance segmentation dataset. Detailed Comparative experiments and ablation studies show the advantages and excellent generalization ability of our model.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3312463/v1"
    },
    {
        "id": 12708,
        "title": "Video Instance Segmentation",
        "authors": "Linjie Yang, Yuchen Fan, Ning Xu",
        "published": "2019-10",
        "citations": 226,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv.2019.00529"
    },
    {
        "id": 12709,
        "title": "Instance Segmentation on Distributed Deep Learning Big Data Cluster",
        "authors": "Mohammed Elhmadany, Islam Elmadah, Hossam E. Abdelmunim",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThis paper presents workflow in deep learning inference models in a distributed manner. This is often required in production environments where real-time predictions need to be made on a massive scale., optimization approaches were applied to the instance segmentation YOLACT model to improve the inference throughput. , and the experiments show that the execution time taken by the OpenVino (Open Visual Inference and Neural Network Optimization) model with 16 FP is the least compared to ONNX (Open Neural Network Exchange) and the original PyTorch model. ONNX and OpenVINO provide a set of tools for optimizing deep learning models for deployment on a range of edge devices such as smartphones, laptops, tablets, IoT devices, sensors, and other devices that collect, process, and transmit data between the end user and the cloud or datacenter. The model optimizer in these frameworks plays a critical role in preparing deployment models, by reducing their size and increasing their performance.YOLACT in OpenVino format we run it on a big data cluster using the BigDL framework to apply inference on spark stand-alone and yarn clusters. where BigDL is a distributed deep learning library for Apache Spark that provides a high-level programming interface for defining and training deep neural networks. It supports a wide range of deep learning models and is designed to be scalable, making it ideal for large-scale deep learning applications. In distributed deep learning reference, the input data is partitioned and sent to multiple machines in parallel for processing. Each machine runs its portion and produces a partial output, which is then combined with the outputs of other machines to produce a final result. Spark stand alone perform better depending on the obtaining results under different conditions whereas significant speedups can be achieved by increasing the number of executors across the cluster.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2957177/v1"
    },
    {
        "id": 12710,
        "title": "IAN: Instance-Augmented Net for 3D Instance Segmentation",
        "authors": "Zihao Wan, Jianhua Hu, Haojian Zhang, Yunkuan Wang",
        "published": "2023-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/lra.2023.3281905"
    },
    {
        "id": 12711,
        "title": "Collaborative Propagation on Multiple Instance Graphs for 3D Instance Segmentation with Single-point Supervision",
        "authors": "Shichao Dong, Ruibo Li, Jiacheng Wei, Fayao Liu, Guosheng Lin",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01528"
    },
    {
        "id": 12712,
        "title": "Railway Infrastructure Instance Segmentation Based on Convolutional Neural Networks",
        "authors": "V. A. Fedorov",
        "published": "2023-9-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/rusautocon58002.2023.10272908"
    },
    {
        "id": 12713,
        "title": "Attention-based Instance Segmentation Network for Cell Segmentation",
        "authors": "Dong gaojun, Xu lele, Ma zhongsong",
        "published": "2020-8-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3425577.3425588"
    },
    {
        "id": 12714,
        "title": "Cell Segmentation Using Multiple Instance Learning Based Support Vector Machines",
        "authors": "Soner Kaya, Gokhan Bilgin",
        "published": "2019-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tiptekno.2019.8895234"
    },
    {
        "id": 12715,
        "title": "Instance segmentation for real-time video detection using FPN and Mask R-CNN",
        "authors": "Anu Yadav, Ela Kumar",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nInstance segmentation of objects is a significant stage in real-time video detection. Object detection is the task of detecting the information of all types of objects in an image by marking the detected object's position in the image with a rectangular box. Using its great feature learning capabilities, deep learning attains a development in object detection research. Many researchers have performed object detection with different machine learning algorithms and focused on enhancing the accuracy of feature extraction. But the accuracy of the lower and higher-level features are not featured properly due to this error that occurred in the detection of the object at a lower level. To overcome this issue, FPN is used for feature extraction, which extracts both lower and higher-level features for accurate detection of an object, and the classification process is done by the proposed model (Mask R-CNN). The proposed model is implemented on python for finding the performance metrics such as accuracy, precision, execution time, error, etc. The accuracy for real-time object detection using FPN and Mask R-CNN is 97.8%, which is greater compared to the existing techniques such as TLD (Tracking-Learning detection), R-CNN, Fast R-CNN, Mask R-CNN and FPN. Thus, the designed model instantly segments the real-time video for object detection in an effective manner.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1477072/v1"
    },
    {
        "id": 12716,
        "title": "Peach Ripeness Classification Based on One-Stage Instance Segmentation Model",
        "authors": "Ziang Zhao, Yulia Hicks, Xianfang Sun, Chaoxi Luo",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4511081"
    },
    {
        "id": 12717,
        "title": "ImPartial: Partial Annotations for Cell Instance Segmentation",
        "authors": "Natalia Martinez, Guillermo Sapiro, Allen Tannenbaum, Travis J. Hollmann, Saad Nadeem",
        "published": "No Date",
        "citations": 5,
        "abstract": "Segmenting noisy multiplex spatial tissue images constitutes a challenging task, since the characteristics of both the noise and the biology being imaged differs significantly across tissues and modalities; this is compounded by the high monetary and time costs associated with manual annotations. It is therefore imperative to build algorithms that can accurately segment the noisy images based on a small number of annotations. Recently techniques to derive such an algorithm from a few scribbled annotations have been proposed, mostly relying on the refinement and estimation of pseudo-labels. Other techniques leverage the success of self-supervised denoising as a parallel task to potentially improve the segmentation objective when few annotations are available. In this paper, we propose a method that augments the segmentation objective via self-supervised multi-channel quantized imputation, meaning that each class of the segmentation objective can be characterized by a mixture of distributions. This approach leverages the observation that perfect pixel-wise reconstruction or denoising of the image is not needed for accurate segmentation, and introduces a self-supervised classification objective that better aligns with the overall segmentation goal. We demonstrate the superior performance of our approach for a variety of cancer datasets acquired with different highly-multiplexed imaging modalities in real clinical settings. Code for our method along with a benchmarking dataset is available at https://github.com/natalialmg/ImPartial.",
        "link": "http://dx.doi.org/10.1101/2021.01.20.427458"
    },
    {
        "id": 12718,
        "title": "Instance Segmentation of Microscopic Foraminifera",
        "authors": "Thomas Haugland Johansen, Steffen Aagaard Sørensen, Kajsa Møllersen, Fred Godtliebsen",
        "published": "No Date",
        "citations": 0,
        "abstract": "Foraminifera are single-celled marine organisms that construct shells that remain as fossils in the marine sediments. Classifying and counting these fossils are important in e.g. paleo-oceanographic and -climatological research. However, the identification and counting process has been performed manually since the 1800s and is laborious and time-consuming. In this work, we present a deep learning-based instance segmentation model for classifying, detecting, and segmenting microscopic foraminifera. Our model is based on the Mask R-CNN architecture, using model weight parameters that have learned on the COCO detection dataset. We use a fine-tuning approach to adapt the parameters on a novel object detection dataset of more than 7000 microscopic foraminifera and sediment grains. The model achieves a (COCO-style) average precision of 0.78±0.00 on the classification and detection task, and 0.80±0.00 on the segmentation task. When the model is evaluated without challenging sediment grain images, the average precision for both tasks increases to 0.84±0.00 and 0.86±0.00, respectively. Prediction results are analyzed both quantitatively and qualitatively and discussed. Based on our findings we propose several directions for future work, and conclude that our proposed model is an important step towards automating the identification and counting of microscopic foraminifera.",
        "link": "http://dx.doi.org/10.20944/preprints202105.0641.v1"
    },
    {
        "id": 12719,
        "title": "SIM: Semantic-aware Instance Mask Generation for Box-Supervised Instance Segmentation",
        "authors": "Ruihuang Li, Chenhang He, Yabin Zhang, Shuai Li, Liyi Chen, Lei Zhang",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00695"
    },
    {
        "id": 12720,
        "title": "Instance Segmentation based Recognition System Tracking Tomatoes by Ripeness in Natural Light Conditions",
        "authors": "Woo-Young Lee, KwangEun Ko, Jaehyeon Kang, HyunJi Park, Inhoon Jang",
        "published": "2020-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5302/j.icros.2020.20.0129"
    },
    {
        "id": 12721,
        "title": "Deep Learning Methods Applied to 3D Point Clouds Based Instance Segmentation: A Review",
        "authors": "Desire Mulindwa Burume, Shengzhi Du",
        "published": "No Date",
        "citations": 1,
        "abstract": "Beyond semantic segmentation,3D instance segmentation(a process to delineate objects of interest and also classifying the objects into a set of categories) is gaining more and more interest among researchers since numerous computer vision applications need accurate segmentation processes(autonomous driving, indoor navigation, and even virtual or augmented reality systems…) This paper gives an overview and a technical comparison of the existing deep learning architectures in handling unstructured Euclidean data for the rapidly developing 3D instance segmentation. First, the authors divide the 3D point clouds based instance segmentation techniques into two major categories which are proposal based methods and proposal free methods. Then, they also introduce and compare the most used datasets with regard to 3D instance segmentation. Furthermore, they compare and analyze these techniques performance (speed, accuracy, response to noise…). Finally, this paper provides a review of the possible future directions of deep learning for 3D sensor-based information and provides insight into the most promising areas for prospective research.",
        "link": "http://dx.doi.org/10.20944/preprints202111.0228.v1"
    },
    {
        "id": 12722,
        "title": "Application of a Deep Learning-Based Instance Segmentation Model for Behavior Classification of Pigs",
        "authors": "Ruihan Ma, Jin-Seong Park, Sung-Hoon Kim, Sang-Cheol Kim",
        "published": "2022-4-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5302/j.icros.2022.22.8001"
    },
    {
        "id": 12723,
        "title": "Depth-aware object instance segmentation",
        "authors": "Linwei Ye, Zhi Liu, Yang Wang",
        "published": "2017-9",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icip.2017.8296296"
    },
    {
        "id": 12724,
        "title": "An Instance Segmentation Algorithm Based On Signed Distance Field",
        "authors": "Hongbao Sun, Hongbo Yang",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/ccc58697.2023.10240547"
    },
    {
        "id": 12725,
        "title": "Improved Yolov8 Deep Learning Instance Segmentation Algorithm with Dilated Convolution: Real Time Precise Segmentation of Orchard Canopies in Natural Environment",
        "authors": "Zohaib Khan, Yue Shen, Hui Liu, Xiao Zeng",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4604445"
    },
    {
        "id": 12726,
        "title": "Image-Level Supervised Instance Segmentation Using Instance-Wise Boundary",
        "authors": "Yuyuan Yang, Ya-Li Hou, Zhijiang Hou, Xiaoli Hao, Yan Shen",
        "published": "2021-9-19",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icip42928.2021.9506011"
    },
    {
        "id": 12727,
        "title": "DISF: Dynamic Instance Segmentation with Semantic Features",
        "authors": "Hao Dong, Guodong Wang",
        "published": "2022-8-21",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icpr56361.2022.9956531"
    },
    {
        "id": 12728,
        "title": "Using a Monocular Camera for 360∘ Dynamic Object Instance Segmentation in Traffic",
        "authors": "Goran Oreski, Lucija Babic",
        "published": "2023-7-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3390/engproc2023041006"
    },
    {
        "id": 12729,
        "title": "SimpleMask: Parameter-free and Efficient Instance Segmentation",
        "authors": "Qunpo Liu, Zhiwei Lu, Ruxin Gao, Xuhui Bu, Naohiko Hanajima",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nTo resolve the problem that the segmentation result of the full convolutional neural network in the Mask R-CNN model is not fine enough, and that the number of loss function hyperparameters is too large, leadings to the time and resource consumption of parameter adjustment, we propose a parameter-free and efficient instance segmentation model in this paper. Aiming at the problem that the Mask R-CNN model does not pay attention to sample features, the method of fusing the visual attention network in the ResNet50 backbone network is adopted to achieve self-adaptation and long-range correlation in self-attention, so that the model can precisely recognize the target location and effectively detect and segment the target. The U-Net network is introduced into the segmentation, and the image is processed by stepwise upsampling and downsampling, so that the network segmentation accuracy for the pixel mask is more accurate. Considering the parameter tuning problem of the instance segmentation task, a parameter-connected loss is recommended to simplify the complexity of model training parameter tuning and further enhance the detection and segmentation performance of the model. We conduct extensive experiments on three extensive baselines, i.e., MiniCOCO, Cityscapes and PASCAL VOC2012, to assess the validity of our model. The experimental findings demonstrate that (1) in the MiniCOCO dataset, a box AP of 35.1 and a mask AP of 32.0 are obtained. Compared with the most advanced mask2former algorithm, the box AP and mask AP are 1.7 and 2.2 higher, respectively. (2) The AP value on Cityscapes is 38.1. In comparison to alternative instance segmentation models, the mAP of each category has been greatly improved. (3) The generalization experiment of our model on the PASCAL VOC2012 dataset shows that the box mAP and mask mAP are 75.5 and 63.6, respectively, which are improved by 3.9 and 1.9, respectively, when contrasting with the Mask R-CNN model. Our model has significant advantages in both detection and segmentation. The code will be available at https://gitee.com/zhiweilu111/simple-mask/tree/master.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3492655/v1"
    },
    {
        "id": 12730,
        "title": "OpSeF: Open source Python framework for collaborative instance segmentation of bioimages",
        "authors": "Tobias M. Rasse, Réka Hollandi, Péter Horváth",
        "published": "No Date",
        "citations": 2,
        "abstract": "AbstractVarious pre-trained deep learning models for the segmentation of bioimages have been made available as ‘developer-to-end-user’ solutions. They usually require neither knowledge of machine learning nor coding skills, are optimized for ease of use, and deployability on laptops. However, testing these tools individually is tedious and success is uncertain.Here, we present the ‘Op’en ‘Se’gmentation ‘F’ramework (OpSeF), a Python framework for deep learning-based instance segmentation. OpSeF aims at facilitating the collaboration of biomedical users with experienced image analysts. It builds on the analysts’ knowledge in Python, machine learning, and workflow design to solve complex analysis tasks at any scale in a reproducible, well-documented way. OpSeF defines standard inputs and outputs, thereby facilitating modular workflow design and interoperability with other software. Users play an important role in problem definition, quality control, and manual refinement of results. All analyst tasks are optimized for deployment on Linux workstations or GPU clusters, all user tasks may be performed on any laptop in ImageJ.OpSeF semi-automates preprocessing, convolutional neural network (CNN)-based segmentation in 2D or 3D, and post-processing. It facilitates benchmarking of multiple models in parallel. OpSeF streamlines the optimization of parameters for pre- and post-processing such, that an available model may frequently be used without retraining. Even if sufficiently good results are not achievable with this approach, intermediate results can inform the analysts in the selection of the most promising CNN-architecture in which the biomedical user might invest the effort of manually labeling training data.We provide Jupyter notebooks that document sample workflows based on various image collections. Analysts may find these notebooks useful to illustrate common segmentation challenges, as they prepare the advanced user for gradually taking over some of their tasks and completing their projects independently. The notebooks may also be used to explore the analysis options available within OpSeF in an interactive way and to document and share final workflows.Currently, three mechanistically distinct CNN-based segmentation methods, the U-Net implementation used in Cellprofiler 3.0, StarDist, and Cellpose have been integrated within OpSeF. The addition of new networks requires little, the addition of new models requires no coding skills. Thus, OpSeF might soon become both an interactive model repository, in which pre-trained models might be shared, evaluated, and reused with ease.",
        "link": "http://dx.doi.org/10.1101/2020.04.29.068023"
    },
    {
        "id": 12731,
        "title": "Video Instance Segmentation 2019: A Winning Approach for Combined Detection, Segmentation, Classification and Tracking",
        "authors": "Jonathon Luiten, Philip Torr, Bastian Leibe",
        "published": "2019-10",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccvw.2019.00088"
    },
    {
        "id": 12732,
        "title": "IAST: Instance Association Relying on Spatio-Temporal Features for Video Instance Segmentation",
        "authors": "Junhao Chen, Sheng Liu, Ruixiang Chen, Bingnan Guo, Feng Zhang",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10095641"
    },
    {
        "id": 12733,
        "title": "Hybrid Instance-Aware Temporal Fusion for Online Video Instance Segmentation",
        "authors": "Xiang Li, Jinglu Wang, Xiao Li, Yan Lu",
        "published": "2022-6-28",
        "citations": 3,
        "abstract": "Recently, transformer-based image segmentation methods have achieved notable success against previous solutions. While for video domains, how to effectively model temporal context with the attention of object instances across frames remains an open problem. In this paper, we propose an online video instance segmentation framework with a novel instance-aware temporal fusion method. We first leverage the representation, \\ie, a latent code in the global context (instance code) and CNN feature maps to represent instance- and pixel-level features. Based on this representation, we introduce a cropping-free temporal fusion approach to model the temporal consistency between video frames. Specifically, we encode global instance-specific information in the instance code and build up inter-frame contextual fusion with hybrid attentions between the instance codes and CNN feature maps. Inter-frame consistency between the instance codes is further enforced with order constraints. By leveraging the learned hybrid temporal consistency, we are able to directly retrieve and maintain instance identities across frames, eliminating the complicated frame-wise instance matching in prior methods. Extensive experiments have been conducted on popular VIS datasets, i.e. Youtube-VIS-19/21. Our model achieves the best performance among all online VIS methods. Notably, our model also eclipses all offline methods when using the ResNet-50 backbone.",
        "link": "http://dx.doi.org/10.1609/aaai.v36i2.20032"
    },
    {
        "id": 12734,
        "title": "Accurate Object Detection &amp; Instance Segmentation of Remote Sensing, Imagery Using Cascade Mask R-CNN With HRNet Backbone",
        "authors": "Durga Kumar",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Experiments are conducted on a series of remote sensing images (NWPU VHR-10). Detection & instance segmentation results demonstrate that our method provides better performance (significant improvement in accuracy) in terms of average precision (AP). The larger the value of AP is, the more accurate the prediction results and the better detection performance of the objects. Cascade Mask R-CNN framework with HRNet backbone for geospatial objects detection and instance segmentation from high-resolution remote sensing imagery.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.21345639.v1"
    },
    {
        "id": 12735,
        "title": "GeoMask : Foreign Object Debris Instance Segmentation Using Geodesic Representations",
        "authors": "Rasna A. Amit, C. Krishna Mohan",
        "published": "2022-3-5",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aero53065.2022.9843628"
    },
    {
        "id": 12736,
        "title": "Spatial-Temporal Decoupled Deformable Attention for Video Instance Segmentation",
        "authors": "Zhenghao Zhang, Fangtao Shao, Zilong Dong, Zuozhuo Dai, Siyu Zhu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4765637"
    },
    {
        "id": 12737,
        "title": "Accurate Object Detection &amp; Instance Segmentation of Remote Sensing, Imagery Using Cascade Mask R-CNN With HRNet Backbone",
        "authors": "Durga Kumar",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Experiments are conducted on a series of remote sensing images (NWPU VHR-10). Detection & instance segmentation results demonstrate that our method provides better performance (significant improvement in accuracy) in terms of average precision (AP). The larger the value of AP is, the more accurate the prediction results and the better detection performance of the objects. Cascade Mask R-CNN framework with HRNet backbone for geospatial objects detection and instance segmentation from high-resolution remote sensing imagery.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.21345639"
    },
    {
        "id": 12738,
        "title": "Automated Pruning Decisions in Dormant Canopies using Instance Segmentation",
        "authors": "Daniel Borrenpohl, Manoj Karkee",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.13031/aim.202200952"
    },
    {
        "id": 12739,
        "title": "Instance segmentation of mitochondria in electron microscopy images with a generalist deep learning model",
        "authors": "Ryan Conrad, Kedar Narayan",
        "published": "No Date",
        "citations": 5,
        "abstract": "AbstractMitochondria are extremely pleomorphic organelles. Automatically annotating each one accurately and precisely in any 2D or volume electron microscopy (EM) image is an unsolved computational challenge. Current deep learning-based approaches train models on images that provide limited cellular contexts, precluding generality. To address this, we amassed a highly heterogeneous ∼1.5 x 106 image 2D unlabeled cellular EM dataset, and segmented ∼135,000 mitochondrial instances therein. MitoNet, a model trained on these resources, performs well on challenging benchmarks and on previously unseen volume EM datasets containing tens of thousands of mitochondria. We release a new Python package and napari plugin, empanada, to rapidly run inference, visualize, and proofread instance segmentations.",
        "link": "http://dx.doi.org/10.1101/2022.03.17.484806"
    },
    {
        "id": 12740,
        "title": "Seg2Pose: Pose Estimations from Instance Segmentation Masks in One or Multiple Views for Traffic Applications",
        "authors": "Martin Ahrnbom, Ivar Persson, Mikael Nilsson",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010777700003124"
    },
    {
        "id": 12741,
        "title": "Cell Instance Segmentation Via Multi-Scale Non-Local Correlation",
        "authors": "Bin Duan, Jianfeng Cao, Wei Wang, Dawen Cai, Yan Yan",
        "published": "No Date",
        "citations": 0,
        "abstract": "ABSTRACTFor cell instance segmentation on Electron Microscopy (EM) images, state-of-the-art methods either conduct pixel-wise classification or follow a detection and segmentation manner. However, both approaches suffer from the enormous cell instances of EM images where cells are tightly close to each other and show inconsistent morphological properties and/or homogeneous appearances. This fact can easily lead to over-segmentation and under-segmentation problems for model prediction,i.e., falsely splitting and merging adjacent instances. In this paper, we propose a novel approach incorporating non-local correlation in the embedding space to make pixel features distinct or similar to their neighbors and thus address the over- and under-segmentation problems. We perform experiments on five different EM datasets where our proposed method yields better results than several strong baselines. More importantly, by using non-local correlation, we observe fewer false separations within one cell and fewer false fusions between cells.",
        "link": "http://dx.doi.org/10.1101/2023.01.24.525387"
    },
    {
        "id": 12742,
        "title": "Semi Supervised Deep Quick Instance Detection and Segmentation",
        "authors": "Ashish Kumar, L. Behera",
        "published": "2019-5",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icra.2019.8793595"
    },
    {
        "id": 12743,
        "title": "Deep Watershed Transform for Instance Segmentation",
        "authors": "Min Bai, Raquel Urtasun",
        "published": "2017-7",
        "citations": 320,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr.2017.305"
    },
    {
        "id": 12744,
        "title": "Early Fire Detection using LSTM based Instance Segmentation and IoTs for Disaster Management",
        "authors": "Sharaf J. Malebary",
        "published": "No Date",
        "citations": 0,
        "abstract": "Fire outbreaks continue to cause damage despite the improvements in fire-detection tools and algorithms. It is still challenging to implement a well performing and optimized approach, which is sufficiently accurate, and has tractable complexity and low false alarming rate.  Small amount of fire and identification of fire from a long distance is also a challenge in previously proposed techniques. In this study, we propose a novel hybrid model based on Convolutional Neural Networks (CNN) to detect and analyze fire intensity.  21 convolutional layers, 24 Rectified Linear Unit (ReLU) layers, 6 pooling layers, 3 fully connected layers, 2 dropout layers, and a softmax layer are included in the proposed 57-layer CNN model. Our proposed model performs instance segmentation in order to distinguish between fire and non-fire events. To reduce the intricacy of the proposed model, we also propose a key-frame extraction algorithm. The proposed model uses Internet of Things (IoT) devices to alert the relevant person by calculating the severity of fire. Our proposed model is tested on a publicly available dataset having fire and normal videos. The achievement of 95.25 % classification accuracy, 0.09% False Positive Rate (FPR), 0.65 percent False Negative Rate (FNR), and a prediction time of 0.08 seconds validates the proposed system.",
        "link": "http://dx.doi.org/10.20944/preprints202310.0065.v1"
    },
    {
        "id": 12745,
        "title": "VSLAM based on instance segmentation",
        "authors": "Yi Zhang, Feng Zhang",
        "published": "2020-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icmcce51767.2020.00450"
    },
    {
        "id": 12746,
        "title": "Boundary-Aware Instance Segmentation",
        "authors": "Zeeshan Hayder, Xuming He, Mathieu Salzmann",
        "published": "2017-7",
        "citations": 93,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr.2017.70"
    },
    {
        "id": 12747,
        "title": "Attention U-net for Cell Instance Segmentation",
        "authors": "Qianze Liu, Tong Mo, Yiya Yao, Yufei Zhang",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac59555.2023.10450733"
    },
    {
        "id": 12748,
        "title": "Automated Generation of Instance Segmentation Labels for Traffic Surveillance Models",
        "authors": "D. Scholte, T. T. G. Urselmann, M. H. Zwemer, E. Bondarev, P. H. N. de With",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012319500003660"
    },
    {
        "id": 12749,
        "title": "Multi-Stage Instance Segmentation",
        "authors": "Guohua Zhu, Suk Chan Kim",
        "published": "2022-10-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ictc55196.2022.9952485"
    },
    {
        "id": 12750,
        "title": "ISBNet: a 3D Point Cloud Instance Segmentation Network with Instance-aware Sampling and Box-aware Dynamic Convolution",
        "authors": "Tuan Duc Ngo, Binh-Son Hua, Khoi Nguyen",
        "published": "2023-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01302"
    },
    {
        "id": 12751,
        "title": "Sparse Instance Activation for Real-Time Instance Segmentation",
        "authors": "Tianheng Cheng, Xinggang Wang, Shaoyu Chen, Wenqiang Zhang, Qian Zhang, Chang Huang, Zhaoxiang Zhang, Wenyu Liu",
        "published": "2022-6",
        "citations": 49,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52688.2022.00439"
    },
    {
        "id": 12752,
        "title": "Fault Detection by Using Instance Segmentation",
        "authors": "Donglin Zhu, Lei Li, Rui Guo, Shifan Zhan",
        "published": "2021-3-16",
        "citations": 0,
        "abstract": "Abstract\nFault detection is an important, but time-consuming task in seismic data interpretation. Traditionally, seismic attributes, such as coherency (Marfurt et al., 1998) and curvature (Al-Dossary et al., 2006) are used to detect faults. Recently, machine learning methods, such as convolution neural networks (CNNs) are used to detect faults, by applying various semantic segmentation algorithms to the seismic data (Wu et al., 2019). The most used algorithm is U-Net (Ronneberger et al., 2015), which can accurately and efficiently provide probability maps of faults.\nHowever, probabilities of faults generated by semantic segmentation algorithms are not sufficient for direct recognition of fault types and reconstruction of fault surfaces. To address this problem, we propose, for the first time, a workflow to use instance segmentation algorithm to detect different fault lines. Specifically, a modified CNN (LaneNet; Neven et al., 2018) is trained using automatically generated synthetic seismic images and corresponding labels. We then test the trained CNN using both synthetic and field collected seismic data. Results indicate that the proposed workflow is accurate and effective at detecting faults.",
        "link": "http://dx.doi.org/10.2523/iptc-21249-ms"
    },
    {
        "id": 12753,
        "title": "An Instance Segmentation Algorithm Based on Improved Mask R-CNN",
        "authors": "Qijuan Yang, Enzeng Dong, Lin Zhu",
        "published": "2020-11-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac51589.2020.9326740"
    },
    {
        "id": 12754,
        "title": "Fast Instance Segmentation for Line Drawing Vectorization",
        "authors": "Naoto Inoue, Toshihiko Yamasaki",
        "published": "2019-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigmm.2019.00-14"
    },
    {
        "id": 12755,
        "title": "Sam-Based Instance Segmentation Models for the Automation of Structural Damage Detection",
        "authors": "Zehao Ye, Lucy Lovell, Asaad Faramarzi, J. Ninić",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4750668"
    },
    {
        "id": 12756,
        "title": "Pointly-Supervised Instance Segmentation",
        "authors": "Bowen Cheng, Omkar Parkhi, Alexander Kirillov",
        "published": "2022-6",
        "citations": 43,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52688.2022.00264"
    },
    {
        "id": 12757,
        "title": "Sparse Shape Encoding for Topologically Improved Instance Segmentation",
        "authors": "Keyi Liu, James H. Elder",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/crv60082.2023.00014"
    },
    {
        "id": 12758,
        "title": "Instance Segmentation Based Semantic Matting for Compositing Applications",
        "authors": "Guanqing Hu, James Clark",
        "published": "2019-5",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/crv.2019.00026"
    },
    {
        "id": 12759,
        "title": "Instance segmentation nei tumori delle vie areo-digestive superiori",
        "authors": "Alberto Paderno, Francesca Pia Villani, Milena Fior, Giulia Berretti, Francesca Gennarini, Gabriele Zigliani, Emanuela Ulaj, Claudia Montenegro, Alessandra Sordi, Claudio Sampieri, Giorgio Peretti, Sara Moccia, Cesare Piazza",
        "published": "2023-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14639/0392-100x-n2336"
    },
    {
        "id": 12760,
        "title": "Predicting Signed Distance Functions for Visual Instance Segmentation",
        "authors": "Emil Brissman, Joakim Johnander, Michael Felsberg",
        "published": "2021-6-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/sais53221.2021.9484039"
    },
    {
        "id": 12761,
        "title": "Two-Level Temporal Relation Model for Online Video Instance Segmentation",
        "authors": "Cagan Selim Coban, Oguzhan Keskin, Jordi Pont-Tuset, Fatma Güney",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4370106"
    },
    {
        "id": 12762,
        "title": "Efficient Instance Segmentation Network",
        "authors": "Chenquan Huang, Weiping Wu, Zhihua Lei",
        "published": "2020-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icaiis49377.2020.9194856"
    },
    {
        "id": 12763,
        "title": "Instance Segmentation Based on Improved YOLACT",
        "authors": "Lingyu Li, Ming Fang, Feiran Fu",
        "published": "2020-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icvrv51359.2020.00042"
    },
    {
        "id": 12764,
        "title": "A Real-Time Counting Method of Fish based on the Instance Segmentation",
        "authors": "Rui Lin, Yonggui Liu",
        "published": "2022-11-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac57257.2022.10054787"
    },
    {
        "id": 12765,
        "title": "Radar Instance Transformer: Reliable Moving Instance Segmentation in Sparse Radar Point Clouds",
        "authors": "Matthias Zeller, Vardeep S. Sandhu, Benedikt Mersch, Jens Behley, Michael Heidingsfeld, Cyrill Stachniss",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tro.2023.3338972"
    },
    {
        "id": 12766,
        "title": "Instance Sequence Queries for Video Instance Segmentation with Transformers",
        "authors": "Zhujun Xu, Damien Vivet",
        "published": "2021-6-30",
        "citations": 2,
        "abstract": "Existing methods for video instance segmentation (VIS) mostly rely on two strategies: (1) building a sophisticated post-processing to associate frame level segmentation results and (2) modeling a video clip as a 3D spatial-temporal volume with a limit of resolution and length due to memory constraints. In this work, we propose a frame-to-frame method built upon transformers. We use a set of queries, called instance sequence queries (ISQs), to drive the transformer decoder and produce results at each frame. Each query represents one instance in a video clip. By extending the bipartite matching loss to two frames, our training procedure enables the decoder to adjust the ISQs during inference. The consistency of instances is preserved by the corresponding order between query slots and network outputs. As a result, there is no need for complex data association. On TITAN Xp GPU, our method achieves a competitive 34.4% mAP at 33.5 FPS with ResNet-50 and 35.5% mAP at 26.6 FPS with ResNet-101 on the Youtube-VIS dataset.",
        "link": "http://dx.doi.org/10.3390/s21134507"
    },
    {
        "id": 12767,
        "title": "A Review on Instance Segmentation Using Mask-RCNN",
        "authors": "Sreya Ramesh C, Vinod Kumar V",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3791106"
    },
    {
        "id": 12768,
        "title": "MrisNet: Robust Ship Instance Segmentation in Challenging Marine Radar Environments",
        "authors": "Feng Ma, Zhe Kang, Chen Chen, Jie Sun, Jizhu Deng",
        "published": "No Date",
        "citations": 0,
        "abstract": "In high-traffic harbor waters, marine radar frequently encounters signal interference stemming from various obstructive elements, thereby presenting formidable obstacles in the precise identification of ships. To achieve precise pixel-level ship identification in the complex environments, a customized neural network-based ship segmentation algorithm named MrisNet is proposed. MrisNet employs a lightweight and efficient FasterYOLO network to extract features from radar images at different levels, capturing fine-grained edge information and deep semantic features of ship pixels. To address the limitation of deep features in the backbone network lacking detailed shape and structured information, an adaptive attention mechanism is introduced after the FasterYOLO network to enhance crucial ship features. To fully utilize the multi-dimensional feature outputs, MrisNet incorporates a Transformer structure to reconstruct the PANet feature fusion network, allowing for the fusion of contextual information and capturing more essential ship information and semantic correlations. In the prediction stage, MrisNet optimizes the target position loss using the EIoU function, enabling the algorithm to adapt to ship position deviations and size variations, thereby improving segmentation accuracy and convergence speed. Experimental results demonstrate that MrisNet achieves high recall and precision rates of 94.8% and 95.2%, respectively, in ship instance segmentation, outperforming various YOLO and other single-stage algorithms. Moreover, MrisNet has a model parameter size of 13.8M and real-time computational cost of 23.5G, demonstrating notable advantages in terms of convolutional efficiency. In conclusion, MrisNet accurately segments ships with different spot features and under diverse environmental conditions in marine radar images. It exhibits outstanding performance, particularly in extreme scenarios and challenging interference conditions, showcasing robustness and applicability.",
        "link": "http://dx.doi.org/10.20944/preprints202311.1787.v1"
    },
    {
        "id": 12769,
        "title": "CenterInst: Center-Based Real-Time Instance Segmentation",
        "authors": "Shu Tian, Liang Ren",
        "published": "2024-2-28",
        "citations": 0,
        "abstract": "Instance segmentation is a computer vision task that aims to give each pixel in an image an instance-specific label. Recently, researchers have shown growing interest in real-time instance segmentation. In this paper, we propose a novel center-based real-time instance segmentation method (CenterInst), which follows the FastInst meta-architecture. Key design aspects include a center-guided query selector, a center-guided sampling-based query decoder, and a lightweight dual-path decoder. The center-guided query selector selects queries via the per-pixel prediction of center point probabilities, avoiding excessive query proposals for single instances. The center-guided sampling-based query decoder adaptively generates local sampling points based on center positions, employing adaptive mixing to update queries without irrelevant sampling disturbances. The lightweight dual-path decoder enhances inference speed and maintains accuracy via pixel decoding on every layer during training but only utilizing the final layer’s decoder during inference. The experimental results show CenterInst achieves superior accuracy and speed compared to state-of-the-art real-time instance segmentation methods.",
        "link": "http://dx.doi.org/10.3390/app14051999"
    },
    {
        "id": 12770,
        "title": "Bridging the Gap Between Semantic Segmentation and Instance Segmentation",
        "authors": "Chengxiang Yin, Jian Tang, Tongtong Yuan, Zhiyuan Xu, Yanzhi Wang",
        "published": "2022",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tmm.2021.3114541"
    }
]