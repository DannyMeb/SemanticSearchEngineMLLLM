[
    {
        "id": 5701,
        "title": "Introduction to Dimensionality Reduction",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-1"
    },
    {
        "id": 5702,
        "title": "Comparative Analysis of Dimensionality Reduction Techniques",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-14"
    },
    {
        "id": 5703,
        "title": "Dimensionality Reduction Using Band Optimisation",
        "authors": "Arati Paul, Nabendu Chaki",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-42667-4_6"
    },
    {
        "id": 5704,
        "title": "Dimensionality Reduction: State of the Art",
        "authors": "Arati Paul, Nabendu Chaki",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-42667-4_2"
    },
    {
        "id": 5705,
        "title": "What Is Dimensionality Reduction (DR)?",
        "authors": "Lih-Yuan Deng, Max Garzon, Nirman Kumar",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-05371-9_3"
    },
    {
        "id": 5706,
        "title": "Laplacian-Based Dimensionality Reduction",
        "authors": "Benyamin Ghojogh, Mark Crowley, Fakhri Karray, Ali Ghodsi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-10602-6_9"
    },
    {
        "id": 5707,
        "title": "Unsupervised Learning Approaches for Dimensionality Reduction and Data Visualization",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554"
    },
    {
        "id": 5708,
        "title": "Stress Functions for Supervised Dimensionality Reduction",
        "authors": "Sylvain Lespinats, Benoit Colange, Denys Dutykh",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-81026-9_6"
    },
    {
        "id": 5709,
        "title": "Stress Functions for Unsupervised Dimensionality Reduction",
        "authors": "Sylvain Lespinats, Benoit Colange, Denys Dutykh",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-81026-9_5"
    },
    {
        "id": 5710,
        "title": "Dimensionality reduction",
        "authors": "Andrew Murphy, David Wang",
        "published": "2018-7-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.53347/rid-61720"
    },
    {
        "id": 5711,
        "title": "Dimensionality Reduction in Cheminformatics",
        "authors": "Corin Wagen",
        "published": "No Date",
        "citations": 0,
        "abstract": "In many applications, including cheminformatics, it’s common to have datasets that have too many dimensions to analyze conveniently. For instance, chemical fingerprints are typically 2048-length binary vectors, meaning that “chemical space” as encoded by fingerprints is 2048-dimensional.",
        "link": "http://dx.doi.org/10.59350/qbbfd-7x616"
    },
    {
        "id": 5712,
        "title": "Isomap",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-7"
    },
    {
        "id": 5713,
        "title": "Dimensionality Reduction with Evolutionary Shephard-Kruskal Embeddings",
        "authors": "Oliver Kramer",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006645904780481"
    },
    {
        "id": 5714,
        "title": "Dual PCA",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-3"
    },
    {
        "id": 5715,
        "title": "Kernel PCA",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-4"
    },
    {
        "id": 5716,
        "title": "Spectral Clustering",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-10"
    },
    {
        "id": 5717,
        "title": "Random Projections",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-8"
    },
    {
        "id": 5718,
        "title": "Dimensionality Reduction",
        "authors": "",
        "published": "2020-1-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108684163.012"
    },
    {
        "id": 5719,
        "title": "Dimensionality reduction",
        "authors": "Frederic Ros, Rabia Riad",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-48743-9_2"
    },
    {
        "id": 5720,
        "title": "Laplacian Eigenmap",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-11"
    },
    {
        "id": 5721,
        "title": "Applications of Dimensionality Reduction to the Diagnosis of Energy Systems",
        "authors": "Sylvain Lespinats, Benoit Colange, Denys Dutykh",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-81026-9_8"
    },
    {
        "id": 5722,
        "title": "Locally Linear Embedding",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-9"
    },
    {
        "id": 5723,
        "title": "Maximum Variance Unfolding",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-12"
    },
    {
        "id": 5724,
        "title": "Multidimensional Scaling (MDS)",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-6"
    },
    {
        "id": 5725,
        "title": "Canonical Correlation Analysis (CCA)",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-5"
    },
    {
        "id": 5726,
        "title": "Principal Component Analysis (PCA)",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-2"
    },
    {
        "id": 5727,
        "title": "Dimensionality Reduction",
        "authors": "",
        "published": "2018-11-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781351032742-19"
    },
    {
        "id": 5728,
        "title": "Intrinsic Dimensionality",
        "authors": "Sylvain Lespinats, Benoit Colange, Denys Dutykh",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-81026-9_2"
    },
    {
        "id": 5729,
        "title": "t-Distributed Stochastic Neighbor Embedding (t-SNE)",
        "authors": "B. K. Tripathy, S Anveshrithaa, Shrusti Ghela",
        "published": "2021-7-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003190554-13"
    },
    {
        "id": 5730,
        "title": "Nonlinear Dimensionality Reduction",
        "authors": "",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-63416-2_300329"
    },
    {
        "id": 5731,
        "title": "Dimensionality reduction applied to logical judgments",
        "authors": "Yuanyuan Cheng",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract:Purpose: To study the effect of the application of the dimensionality reduction in logical judgment (or logical reasoning, logical inference) programs. Methods: Use enumeration and dimensionality reduction methods to solve logical judgment problems.The effect of the two methods is illustrated in the form of a case study. Results: For logical judgmentproblems, using enumeration method to find the best answer is a comprehensive and fundamental method, but the disadvantage is that it is computationally intensive and computationally inefficient. Compared with the ideas of parallel treatment of known conditions by enumeration method, the application of dimensionality reduction thinking was built on the basis of fully mining information for feature extraction and feature selection. Conclusions: The dimensionality reduction method was applied to the logical judgment problems, and on the basis of fully mining information, the dimensionality reduction principle of statistics were applied to stratify and merge variables with the same or similar characteristics to achieve the purpose of streamlining variables, simplifying logical judgment steps, reducing computation and improving algorithm efficiency.",
        "link": "http://dx.doi.org/10.31219/osf.io/k93fs"
    },
    {
        "id": 5732,
        "title": "Dimensionality Reduction",
        "authors": "Poornachandra Sarang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-45633-6_2"
    },
    {
        "id": 5733,
        "title": "A Dimensionality Reduction Method for Data Visualization using Particle Swarm Optimization",
        "authors": "Panagiotis Petrantonakis, Ioannis Kompatsiaris",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010020601310138"
    },
    {
        "id": 5734,
        "title": "Review for \"Dimensionality reduction of multielement glass evidence to calculate likelihood ratios\"",
        "authors": "",
        "published": "2020-5-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/cem.3298/v1/review2"
    },
    {
        "id": 5735,
        "title": "Dimensionality Reduction",
        "authors": "Eisaku Maeda",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-63416-2_652"
    },
    {
        "id": 5736,
        "title": "Dimensionality Reduction of Hyperspectral Imagery",
        "authors": "Arati Paul, Nabendu Chaki",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-42667-4"
    },
    {
        "id": 5737,
        "title": "A biological model of nonlinear dimensionality reduction",
        "authors": "Kensuke Yoshida, Taro Toyoizumi",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractObtaining appropriate low-dimensional representations from high-dimensional sensory inputs in an unsupervised manner is essential for straightforward downstream processing. Although nonlinear dimensionality reduction methods such as t-distributed stochastic neighbor embedding (t-SNE) have been developed, their implementation in simple biological circuits remains unclear. Here, we develop a biologically plausible dimensionality reduction algorithm compatible with t-SNE, which utilizes a simple three-layer feedforward network mimicking the Drosophila olfactory circuit. The proposed learning rule, described as three-factor Hebbian plasticity, is effective for datasets such as entangled rings and MNIST, comparable to t-SNE. We further show that the algorithm could be working in olfactory circuits in Drosophila by analyzing the multiple experimental data in previous studies. We finally suggest that the algorithm is also beneficial for association learning between inputs and rewards, allowing the generalization of these associations to other inputs not yet associated with rewards.",
        "link": "http://dx.doi.org/10.1101/2024.03.13.584757"
    },
    {
        "id": 5738,
        "title": "Dimensionality Reduction",
        "authors": "Heng Tao Shen",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4614-8265-9_551"
    },
    {
        "id": 5739,
        "title": "Dimensionality Reduction*",
        "authors": "",
        "published": "2019-5-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108654937.014"
    },
    {
        "id": 5740,
        "title": "Review for \"Dimensionality reduction of multielement glass evidence to calculate likelihood ratios\"",
        "authors": "",
        "published": "2020-4-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/cem.3298/v1/review1"
    },
    {
        "id": 5741,
        "title": "Review for \"Dimensionality reduction of multielement glass evidence to calculate likelihood ratios\"",
        "authors": "",
        "published": "2020-8-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/cem.3298/v2/review2"
    },
    {
        "id": 5742,
        "title": "Review for \"Dimensionality reduction of multielement glass evidence to calculate likelihood ratios\"",
        "authors": "",
        "published": "2020-7-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/cem.3298/v2/review1"
    },
    {
        "id": 5743,
        "title": "Enhancing Emotion Recognition from ECG Signals using Supervised Dimensionality Reduction",
        "authors": "Hany Ferdinando, Tapio Seppänen, Esko Alasaarela",
        "published": "2017",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006147801120118"
    },
    {
        "id": 5744,
        "title": "Dimensionality Reduction of Speech Signals using Singular Value Decomposition and Karhunen-Loeve",
        "authors": "Domy Kristomo, Yudhi Kusnanto",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009432200780084"
    },
    {
        "id": 5745,
        "title": "An Ensemble-based Dimensionality Reduction for Service Monitoring Time-series",
        "authors": "Farzana Anowar, Samira Sadaoui, Hardik Dalal",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011273700003277"
    },
    {
        "id": 5746,
        "title": "\"Why Here and not There?\": Diverse Contrasting Explanations of Dimensionality Reduction",
        "authors": "André Artelt, Alexander Schulz, Barbara Hammer",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011618300003411"
    },
    {
        "id": 5747,
        "title": "Haisu: Hierarchical Supervised Nonlinear Dimensionality Reduction",
        "authors": "Kevin C. VanHorn, Murat Can Çobanoğlu",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractWe propose a novel strategy for incorporating hierarchical supervised label information into nonlinear dimensionality reduction techniques. Specifically, we extend t-SNE, UMAP, and PHATE to include known or predicted class labels and demonstrate the efficacy of our approach on multiple single-cell RNA sequencing datasets. Our approach, “Haisu,” is applicable across domains and methods of nonlinear dimensionality reduction. In general, the mathematical effect of Haisu can be summarized as a variable perturbation of the high dimensional space in which the original data is observed. We thereby preserve the core characteristics of the visualization method and only change the manifold to respect known or assumed class labels when provided. Our strategy is designed to aid in the discovery and understanding of underlying patterns in a dataset that is heavily influenced by parent-child relationships. We show that using our approach can also help in semi-supervised settings where labels are known for only some datapoints (for instance when only a fraction of the cells is labeled). In summary, Haisu extends existing popular visualization methods to enable a user to incorporate known, relevant relationships via a user-defined hierarchical distancing factor.Availabilitygithub.com/Cobanoglu-Lab/Haisu",
        "link": "http://dx.doi.org/10.1101/2020.10.05.324798"
    },
    {
        "id": 5748,
        "title": "Dimensionality Reduction and Bandwidth Selection for Spatial Kernel Discriminant Analysis",
        "authors": "Soumia Boumeddane, Leila Hamdad, Hamid Haddadou, Sophie Dabo-Niang",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010269002780285"
    },
    {
        "id": 5749,
        "title": "Dimensionality reduction for neural population decoding",
        "authors": "Charles R. Heller, Stephen V. David",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractRapidly developing technology for large scale neural recordings has allowed researchers to measure the activity of hundreds to thousands of neurons at single cell resolution in vivo. Neural decoding analyses are a widely used tool used for investigating what information is represented in this complex, high-dimensional neural population activity. Most population decoding methods assume that correlated activity between neurons has been estimated accurately. In practice, this requires large amounts of data, both across observations and across neurons. Unfortunately, most experiments are fundamentally constrained by practical variables that limit the number of times the neural population can be observed under a single stimulus and/or behavior condition. Therefore, new analytical tools are required to study neural population coding while taking into account these limitations. Here, we present a simple and interpretable method for dimensionality reduction that allows neural decoding metrics to be calculated reliably, even when experimental trial numbers are limited. We illustrate the method using simulations and compare its performance to standard approaches for dimensionality reduction and decoding by applying it to single-unit electrophysiological data collected from auditory cortex.",
        "link": "http://dx.doi.org/10.1101/2021.04.18.440336"
    },
    {
        "id": 5750,
        "title": "Dimensionality Reduction",
        "authors": "",
        "published": "2022-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009122092.012"
    },
    {
        "id": 5751,
        "title": "A Diffusion Dimensionality Reduction Approach to Background Subtraction in Video Sequences",
        "authors": "Dina Dushnik, Alon Schclar, Amir Averbuch, Raid Saabni",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010125702940300"
    },
    {
        "id": 5752,
        "title": "Dimensionality Reduction in Supervised Models-based for Heart Failure Prediction",
        "authors": "Anna Escamilla, Amir El Hassani, Emmanuel Andres",
        "published": "2019",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007313703880395"
    },
    {
        "id": 5753,
        "title": "Dimensionality Reduction and Latent Variable Modeling",
        "authors": "Sergios Theodoridis",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-818803-3.00031-3"
    },
    {
        "id": 5754,
        "title": "Dimensionality Reduction",
        "authors": "Erik Lee Nylen, Pascal Wallisch",
        "published": "2017",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-804043-0.00008-8"
    },
    {
        "id": 5755,
        "title": "Dimensionality Reduction",
        "authors": "Harry G. Perros",
        "published": "2021-3-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003139041-7"
    },
    {
        "id": 5756,
        "title": "Dimensionality Reduction",
        "authors": "",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811263903_0008"
    },
    {
        "id": 5757,
        "title": "Dimensionality reduction and clustering",
        "authors": "Paul Geertsema",
        "published": "2023-4-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003330929-8"
    },
    {
        "id": 5758,
        "title": "Dimensionality Reduction",
        "authors": "",
        "published": "2020-1-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108564175.009"
    },
    {
        "id": 5759,
        "title": "YAMB: metagenome binning using nonlinear dimensionality reduction and density-based clustering",
        "authors": "Aleksei Korzhenkov",
        "published": "No Date",
        "citations": 3,
        "abstract": "AbstractSummaryYAMB is a novel metagenome binning tool, which uses tetranucletotide composition and average contig coverage and performs t-SNE dimensionality reduction and sequential DBSCAN data clusterization. YAMB provided with metagenomics assembly and reads may be used for straightforward metagenome binning on a recent personal computer running Linux OS.Availability and ImplementationSource code of YAMB is freely available on GitHub (https://github.com/laxeye/YAMB), implemented in R, Perl and Bash and supported on Linux.ContactKorzhenkov_AA@nrcki.ru",
        "link": "http://dx.doi.org/10.1101/521286"
    },
    {
        "id": 5760,
        "title": "Dimensionality Reduction",
        "authors": "Michail Vlachos",
        "published": "2017",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_71"
    },
    {
        "id": 5761,
        "title": "Recovering Single-cell Heterogeneity Through Information-based Dimensionality Reduction",
        "authors": "Benjamin DeMeo, Bonnie Berger",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractDimensionality reduction is crucial to summarizing the complex transcriptomic landscape of single cell datasets for downstream analyses. However, current dimensionality reduction approaches favor large cellular populations defined by many genes, at the expense of smaller and more subtly-defined populations. Here, we present surprisal component analysis (SCA), a technique that leverages the information-theoretic notion of surprisal for dimensionality reduction, and demonstrate its ability to improve the representation of clinically important populations that are indistinguishable using existing pipelines. For example, in cytotoxic T-cell data, SCA cleanly separates the gamma-delta and MAIT cell subpopulations, which are not detectable via PCA, ICA, scVI, or a wide array of specialized rare cell recovery tools. We also show that, when used instead of PCA, SCA improves downstream imputation to more accurately restore mRNA dropouts and recover important gene-gene relationships. SCA’s information-theoretic paradigm opens the door to more meaningful signal extraction, with broad applications to the study of complex biological tissues in health and disease.",
        "link": "http://dx.doi.org/10.1101/2021.01.19.427303"
    },
    {
        "id": 5762,
        "title": "Dimensionality Reduction",
        "authors": "Rafael E. Banchs",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-87695-1_10"
    },
    {
        "id": 5763,
        "title": "Geometric Approaches",
        "authors": "Nirman Kumar",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-05371-9_5"
    },
    {
        "id": 5764,
        "title": "Visualizing chemical space: Practical applications and insights from parametric dimensionality reduction techniques",
        "authors": "Sergey Sosnin",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1021/scimeetings.3c10074"
    },
    {
        "id": 5765,
        "title": "Dimensionality Reduction in EH&amp;S Data Analysis",
        "authors": "Jon Judge",
        "published": "2022-4-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.20935/al4109"
    },
    {
        "id": 5766,
        "title": "Dimensionality Reduction",
        "authors": "Italia De Feis",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-809633-8.20336-1"
    },
    {
        "id": 5767,
        "title": "Dimensionality Reduction",
        "authors": "Eisaku Maeda",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-03243-2_652-1"
    },
    {
        "id": 5768,
        "title": "Dimensionality Reduction",
        "authors": "Heng Tao Shen",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7993-3_551-2"
    },
    {
        "id": 5769,
        "title": "Dimensionality Reduction",
        "authors": "A. C. Faul",
        "published": "2019-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781351204750-7"
    },
    {
        "id": 5770,
        "title": "Stable Random Projection: Lightweight, General-Purpose Dimensionality Reduction for Digitized Libraries",
        "authors": "Benjamin Schmidt",
        "published": "No Date",
        "citations": 5,
        "abstract": "Digital libraries today distribute their contents in a way that limits the sort of work that can be done with them. Modern libraries are so large-often containing millions of books or articles-that the technical resources needed to work with them can be immense. Beginning researchers and students often cannot practically obtain more than a few thousand books at a time. Advanced researchers must use (often incomplete) metadata to decide which books are of interest for their projects; and libraries themselves lack ways for make their full-text holdings easily discoverable by researchers or integrated with other collections.",
        "link": "http://dx.doi.org/10.31235/osf.io/36neu"
    },
    {
        "id": 5771,
        "title": "Sufficient Dimension Reduction and Kernel Dimension Reduction",
        "authors": "Benyamin Ghojogh, Mark Crowley, Fakhri Karray, Ali Ghodsi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-10602-6_15"
    },
    {
        "id": 5772,
        "title": "Ridge Regression based Missing Data Estimation with Dimensionality Reduction: Microarray Gene Expression Data",
        "authors": "Ashfaq Ahmed K., Dr. Shaheda Akthar",
        "published": "2022-1-20",
        "citations": 0,
        "abstract": "Data is considered to be the important element in the field of Data Science and Machine Learning. Performance of Machine Learning and Data Mining algorithms greatly influenced by the characteristics of data and data with missing values. Performance of all these Machine Learning algorithms greatly improved and they can give accurate results when the data is in full without missing values. So before applying these algorithms; dataset and its missing values are completely filled. To impute these missing values in the dataset there are numerous methods were proposed. In this paper we used micro array gene expression dataset; by introducing various percentages of missing values a new methodology is proposed to impute these missing values in the data set. The nature of micro array gene expression dataset is huge in dimensionality, so at first, we used recursive feature elimination method to select the best features which contributes much for model was selected then we apply the Ridge Regression for imputation. Imputations with other methods are compared. We evaluate the performance of all models by using the metrics like MSE, MAE, R-square. To select the best model in the set of models we used Normalized Criteria Distance (NCD) to rank the models under proposed metrics. The model with least NCD rank selected as the best model among other models, in our paper proposed model has got the lowest value among other models and considered to be the best model among other models.",
        "link": "http://dx.doi.org/10.14704/web/v19i1/web19271"
    },
    {
        "id": 5773,
        "title": "Decision letter for \"Dimensionality reduction of multielement glass evidence to calculate likelihood ratios\"",
        "authors": "",
        "published": "2020-8-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/cem.3298/v2/decision1"
    },
    {
        "id": 5774,
        "title": "Exploration, Exploitation Phenomena and Regression Analysis: Propensity Metric, Anomaly Reduction, Dimensionality Reduction",
        "authors": "Chaman Lal Sabharwal",
        "published": "2018-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.17562/pb-57-2"
    },
    {
        "id": 5775,
        "title": "Dimensionality reduction and statistical modeling of scGET-seq data",
        "authors": "Stefano de Pretis, Davide Cittaro",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractSingle cell multiomics approaches are innovative techniques with the ability to profile orthogonal features in the same single cell, giving the opportunity to dig more deeply into the stochastic nature of individual cells. We recently developed scGET-seq, a technique that exploits a Hybrid Transposase (tnH) along with the canonical enzyme (tn5), which is able to profile altogether closed and open chromatin in a single experiment. This technique adds an important feature to the classic scATAC-seq assays. In fact, the lack of a closed chromatin signal in scATAC: (i) restricts sampling of DNA sequence to a very small portion of the chromosomal landscapes, substantially reducing the ability to investigate copy number alteration and sequence variations, and (ii) hampers the opportunity to identify regions of closed chromatin, that cannot be distinguished between non-sampled open regions and truly closed. scGET-seq overcomes these issues in the context of single cells. In this work, we describe the latest advances in the statistical analysis and modeling of scGET-seq data, touching several aspects of the computational framework: from dimensionality reduction, to statistical modeling, and trajectory analysis.",
        "link": "http://dx.doi.org/10.1101/2022.06.29.498092"
    },
    {
        "id": 5776,
        "title": "Dimensionality reduction of hyperspectral images based on the linear mixture model and dimensionality estimation",
        "authors": "Evgeny V. Myasnikov",
        "published": "2020-1-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2559412"
    },
    {
        "id": 5777,
        "title": "Self-supervised Dimensionality Reduction with Neural Networks and Pseudo-labeling",
        "authors": "Mateus Espadoto, Nina Hirata, Alexandru Telea",
        "published": "2021",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010184800270037"
    },
    {
        "id": 5778,
        "title": "SDR-NNP: Sharpened Dimensionality Reduction with Neural Networks",
        "authors": "Youngjoo Kim, Mateus Espadoto, Scott Trager, Jos Roerdink, Alexandru Telea",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010820900003124"
    },
    {
        "id": 5779,
        "title": "Introduction",
        "authors": "Arati Paul, Nabendu Chaki",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-42667-4_1"
    },
    {
        "id": 5780,
        "title": "Dimensionality Reduction and Metric Learning",
        "authors": "Zhi-Hua Zhou",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-15-1967-3_10"
    },
    {
        "id": 5781,
        "title": "Dimensionality Reduction with Principal Component Analysis",
        "authors": "",
        "published": "2020-2-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108679930.012"
    },
    {
        "id": 5782,
        "title": "Short review of dimensionality reduction methods for failure detection",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4467/20838476si.17.006.8152"
    },
    {
        "id": 5783,
        "title": "Decision letter for \"Dimensionality reduction of multielement glass evidence to calculate likelihood ratios\"",
        "authors": "",
        "published": "2020-5-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/cem.3298/v1/decision1"
    },
    {
        "id": 5784,
        "title": "Chapter 7: Dimensionality Reduction",
        "authors": "",
        "published": "2023-11-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9781683929482-008"
    },
    {
        "id": 5785,
        "title": "Editor's evaluation: Sparse dimensionality reduction approaches in Mendelian randomisation with highly correlated exposures",
        "authors": "Siming Zhao",
        "published": "2022-7-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7554/elife.80063.sa0"
    },
    {
        "id": 5786,
        "title": "Detecting anomalous payments networks: A dimensionality reduction approach",
        "authors": "Carlos León",
        "published": "2019-12-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32468/be.1098"
    },
    {
        "id": 5787,
        "title": "Reduction of Dimensionality",
        "authors": "Marco Fattore",
        "published": "2018-8-14",
        "citations": 0,
        "abstract": "Abstract\nIn data analysis, the expression “Reduction of dimensionality”, or “Dimensionality reduction”, refers to the process of mapping a set of high‐dimensional statistical units into a lower‐dimensional space, minimizing the approximation, or reconstruction, error and preserving, as much as possible, the structure and the features of the input data. Dimensionality reduction is usually performed in order to simplify multidimensional data, to clean them from noise, to visualize them, to identify patterns of statistical units, or as a preliminary step before other kinds of statistical analysis (e.g., prediction and supervised classification). Many different algorithms for dimensionality reduction exist; they differ as to the kind of input data (categorical, ordinal, or numerical), to the mathematical setting they are based on (e.g., linear and nonlinear procedures) and to the emphasis they put on minimizing the approximation error or on providing less precise but more easily interpretable results. Given the increasing availability of increasingly complex data systems, dimensionality reduction is often a key step in real‐world statistical and data science processes and is a lively area of multivariate statistical and machine learning research.",
        "link": "http://dx.doi.org/10.1002/9781118445112.stat08100"
    },
    {
        "id": 5788,
        "title": "A Review Paper on Dimensionality Reduction Techniques",
        "authors": "",
        "published": "2022-1-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47750/pnr.2022.13.s03.198"
    },
    {
        "id": 5789,
        "title": "Dimensionality reduction",
        "authors": "Maria Deprez, Emma C. Robinson",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-822904-0.00010-8"
    },
    {
        "id": 5790,
        "title": "Dimensionality Reduction Techniques",
        "authors": "Shekhar Khandelwal, Rik Das",
        "published": "2022-4-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003217381-6"
    },
    {
        "id": 5791,
        "title": "Fairness-Aware Dimensionality Reduction",
        "authors": "O. Deniz Kose, Yanning Shen",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/eusipco58844.2023.10289717"
    },
    {
        "id": 5792,
        "title": "Dimensionality Reduction of Microconfined High-Pressure Transcritical Fluid Turbulence",
        "authors": "Lluís Jofre, Marc Bernades, Francesco Capuano",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4351875"
    },
    {
        "id": 5793,
        "title": "Dimensionality Reduction Techniques for Nearest-Neighbor Computations",
        "authors": "Alexander Thomasian",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4614-8265-9_80771"
    },
    {
        "id": 5794,
        "title": "Quantisation-aware Dimensionality Reduction",
        "authors": "Ce Guo, Wayne Luk",
        "published": "2020-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icfpt51103.2020.00041"
    },
    {
        "id": 5795,
        "title": "Bridging stimulus generalization and representation learning via rational dimensionality reduction",
        "authors": "Lukas Michael Neugebauer, Christian Büchel",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractGeneralization, the transfer of knowledge to novel situations, has been studied in distinct disciplines that focus on different aspects. Here we propose a Bayesian model that assumes an exponential mapping from psychological space to outcome probabilities. This model is applicable to probabilistic reinforcement and integrates representation learning by tracking the relevance of stimulus dimensions. Since the belief state about this mapping is dependent on prior knowledge, we designed three experiments that emphasized this aspect. In all studies, we found behavior to be influenced by prior knowledge in a way that is consistent with the model. In line with the literature on representation learning, we found the representational geometry in the middle frontal gyrus to correspond to the behavioral preference for one over the other stimulus dimension and to be updated as predicted by the model. We interpret these findings as support for a common mechanism of generalization.",
        "link": "http://dx.doi.org/10.1101/2023.08.09.549352"
    },
    {
        "id": 5796,
        "title": "Feature Dimensionality Reduction Via Homological",
        "authors": "Marcello Trovati, Suleman Awan",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4166556"
    },
    {
        "id": 5797,
        "title": "Transformer-based dimensionality reduction",
        "authors": "Ruisheng Ran, Tianyu Gao, Wenfeng Zhang, Shunshun Peng, Bin Fang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nRecently, Transformer is much popular and plays an important role in the fields of Machine Learning (ML), Natural Language Processing (NLP), and Computer Vision (CV), etc. In this paper, based on the Vision Transformer (ViT) model, a new dimensionality reduction (DR) model is proposed, named Transformer-DR. From data visualization, image reconstruction and face recognition, the representation ability of Transformer-DR after dimensionality reduction is studied, and it is compared with some representative DR methods to understand the difference between Transformer-DR and existing DR methods. The experimental results show that Transformer-DR is an effective dimensionality reduction method.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2417990/v1"
    },
    {
        "id": 5798,
        "title": "Dimensionality reduction in the time domain",
        "authors": "Dževad Belkić",
        "published": "2019-8-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780429146534-10"
    },
    {
        "id": 5799,
        "title": "Dimensionality reduction in the frequency domain",
        "authors": "Dževad Belkić",
        "published": "2019-8-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780429146534-9"
    },
    {
        "id": 5800,
        "title": "Machine Learning Approaches",
        "authors": "Deepak Venugopal, Max Garzon",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-05371-9_9"
    }
]