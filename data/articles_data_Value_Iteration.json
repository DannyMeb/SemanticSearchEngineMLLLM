[
    {
        "id": 14671,
        "title": "Model Based Reinforcement Learning: Policy Iteration, Value Iteration, and Dynamic Programming",
        "authors": "Steven L. Brunton",
        "published": "No Date",
        "citations": 0,
        "abstract": "Here we introduce dynamic programming, which is a cornerstone of model-based reinforcement learning. We demonstrate dynamic programming for policy iteration and value iteration, leading to the quality function and Q-learning.",
        "link": "http://dx.doi.org/10.52843/cassyni.6fs4s9"
    },
    {
        "id": 14672,
        "title": "Relational Value Iteration",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_100410"
    },
    {
        "id": 14673,
        "title": "The Value of Iteration",
        "authors": "",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009429924.003"
    },
    {
        "id": 14674,
        "title": "Coding the Environment and MDP Solution",
        "authors": "Mohit Sewak",
        "published": "2019",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-13-8285-7_3"
    },
    {
        "id": 14675,
        "title": "An Optimal Value Iteration Algorithm for Parity Games",
        "authors": "Nathanaël Fijalkow",
        "published": "2018-3-23",
        "citations": 3,
        "abstract": "The quest for a polynomial time algorithm for solving parity games gained momentum in 2017 when two different quasipolynomial time algorithms were constructed. In this paper, we further analyse the second algorithm due to Jurdzinski and Lazic and called the succinct progress measure algorithm. It was presented as an improvement over a previous algorithm called the small progress measure algorithm, using a better data structure.The starting point of this paper is the observation that the underlying data structure for both progress measure algorithms are (subgraph-)universal trees. We show that in fact any universal tree gives rise to a value iteration algorithm à la succinct progress measure, and the complexity of the algorithm is proportional to the size of the chosen universal tree. We extract from both algorithms the construction of a universal tree, respectively of exponential size (for small progress measure) and of quasipolynomial size (for succinct progress measure).The technical result of this paper is to show that the latter construction is asymptotically tight: universal trees have at least quasipolynomial size. This suggests that the succinct progress measure algorithm of Jurdzinski and Lazic is in this framework optimal, and that constructing a polynomial time algorithm for parity games is hiding someplace else.",
        "link": "http://dx.doi.org/10.29007/k2nm"
    },
    {
        "id": 14676,
        "title": "Comparison of Value Iteration, Policy Iteration and Q-Learning for solving Decision-Making problems",
        "authors": "Mohand Hamadouche, Catherine Dezan, David Espes, Kalinka Branco",
        "published": "2021-6-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icuas51884.2021.9476691"
    },
    {
        "id": 14677,
        "title": "Theoretical analysis of stabilizing value iteration with approximation errors",
        "authors": "Ali Heydari",
        "published": "2017-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/acc.2017.7963780"
    },
    {
        "id": 14678,
        "title": "A Hardware Approach to Value Function Iteration",
        "authors": "Alessandro Peri",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3345379"
    },
    {
        "id": 14679,
        "title": "Approximate Dynamic Programming: Value Iteration",
        "authors": "Ilya O. Ryzhov",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-54621-2_801-1"
    },
    {
        "id": 14680,
        "title": "Cache Efficient Value Iteration",
        "authors": "Anuj Jain, Sartaj Sahni",
        "published": "2019-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iscc47284.2019.8969635"
    },
    {
        "id": 14681,
        "title": "Value Iteration with Memristors",
        "authors": "Idongesit Ebong, Pinaki Mazumder",
        "published": "2022-9-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003338918-6"
    },
    {
        "id": 14682,
        "title": "Approximate value iteration with a fuzzy representation",
        "authors": "",
        "published": "2017-7-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781439821091-9"
    },
    {
        "id": 14683,
        "title": "Value Iteration Solver Networks",
        "authors": "Evalds Urtans, Valters Vecins",
        "published": "2020-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icoias49312.2020.9081856"
    },
    {
        "id": 14684,
        "title": "Value Iteration Networks on Multiple Levels of Abstraction",
        "authors": "Daniel Schleich, Tobias Klamt, Sven Behnke",
        "published": "2019-6-22",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15607/rss.2019.xv.014"
    },
    {
        "id": 14685,
        "title": "Value-gradient iteration with quadratic approximate value functions",
        "authors": "Alan Yang, Stephen Boyd",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.arcontrol.2023.100917"
    },
    {
        "id": 14686,
        "title": "Use of Worksheet events in Excel to save solver objective cell value from each iteration",
        "authors": "Prasanth Sambaraju",
        "published": "No Date",
        "citations": 0,
        "abstract": "Solver is a Microsoft Excel add-in program which is used to find an optimal value for a formula in the objective cell. Solver accomplishes this either by maximizing, minimizing or setting the objective cell value to a specific value. The article presents the utility of in built worksheet events in Excel VBA to save the value of objective cell from each iteration when solver is used for optimization.",
        "link": "http://dx.doi.org/10.3897/arphapreprints.e79014"
    },
    {
        "id": 14687,
        "title": "Encrypted Value Iteration and Temporal Difference Learning over Leveled Homomorphic Encryption",
        "authors": "Jihoon Suh, Takashi Tanaka",
        "published": "2021-5-25",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/acc50511.2021.9483184"
    },
    {
        "id": 14688,
        "title": "Value set iteration for two-person zero-sum Markov games",
        "authors": "Hyeong Soo Chang",
        "published": "2017-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.automatica.2016.10.010"
    },
    {
        "id": 14689,
        "title": "Robust Value Iteration for Continuous Control Tasks",
        "authors": "Michael Lutter, Shie Mannor, Jan Peters, Dieter Fox, Animesh Garg",
        "published": "2021-7-12",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15607/rss.2021.xvii.007"
    },
    {
        "id": 14690,
        "title": "Optimal parameter of the SOR-like iteration method for solving absolute value equations",
        "authors": "Cairong Chen, Bo Huang, Dongmei Yu, Deren Han",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe SOR-like iteration method for solvingthe system of absolute value equations~(AVE) of finding a vector $x$ such that $Ax - |x| - b = 0$ with $\\nu = \\|A^{-1}\\|_2 < 1$ is investigated. The convergence conditions of the SOR-like iteration method proposed by Ke and Ma ([{\\em Appl. Math. Comput.}, 311:195--202, 2017]) are revisited and a new proof is given, which exhibits some insights in determining the convergent region and the optimal iteration parameter. Along this line, the optimal parameter which minimizes $\\|T_\\nu(\\omega)\\|_2$ with$$T_\\nu(\\omega) = \\left(\\begin{array}{cc} |1-\\omega| & \\omega^2\\nu \\\\ |1-\\omega| & |1-\\omega| +\\omega^2\\nu \\end{array}\\right)$$and the approximate optimal parameter which minimizes an upper bound of $\\|T_\\nu(\\omega)\\|_2$are explored. The optimal and approximate optimal parameters are iteration-independent and the bigger value of $\\nu$ is, the smaller convergent region of the iteration parameter $\\omega$ is. Numerical results are presented to demonstrate that the SOR-like iteration method with the optimal parameter is superior to that with the approximate optimal parameter proposed by Guo, Wu and Li ([{\\em Appl. Math. Lett.}, 97:107--113, 2019]).",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3163783/v1"
    },
    {
        "id": 14691,
        "title": "Approximate Value Iteration in the Reinforcement Learning Context. Application to Electrical Power System Control.",
        "authors": "Damien Ernst, Mevludin Glavic, Pierre Geurts, Louis Wehenkel",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/energyo.0034.00204"
    },
    {
        "id": 14692,
        "title": "Figure 3 from: Sambaraju P (2022) Use of Worksheet events in Excel to save solver objective cell value from each iteration. Research Ideas and Outcomes 8: e79006. https://doi.org/10.3897/rio.8.e79006",
        "authors": "Prasanth Sambaraju",
        "published": "2022-2-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3897/rio.8.e79006.figure3"
    },
    {
        "id": 14693,
        "title": "Consensus-Based Value Iteration for Multiagent Cooperative Control",
        "authors": "Jing Wang, Elias Wilson, Alvaro Velasquez",
        "published": "2021-12-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc45484.2021.9682831"
    },
    {
        "id": 14694,
        "title": "Value Iteration on Multicore Processors",
        "authors": "Anuj Jain, Sartaj Sahni",
        "published": "2020-12-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isspit51521.2020.9408773"
    },
    {
        "id": 14695,
        "title": "The new iteration methods for solving absolute value equations",
        "authors": "Rashid Ali, Kejia Pan",
        "published": "2023-2-1",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21136/am.2021.0055-21"
    },
    {
        "id": 14696,
        "title": "Learning Urban Navigation via Value Iteration Network",
        "authors": "Shu Yang, Jinglin Li, Jie Wang, Zhihan Liu, Fangchun Yang",
        "published": "2018-6",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ivs.2018.8500517"
    },
    {
        "id": 14697,
        "title": "Parameter Sensitivity Analysis of Controlled Invariant Sets via Value Iteration",
        "authors": "Liren Yang, Denise Rizzo, Matthew Castanier, Necmiye Ozay",
        "published": "2020-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/acc45564.2020.9147377"
    },
    {
        "id": 14698,
        "title": "Sumudu Transform and Variational Iteration Method to Solve Two Point Second Order Linear Boundary Value Problems",
        "authors": "",
        "published": "2020-11-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32802/asmscj.2020.sm26(4.22)"
    },
    {
        "id": 14699,
        "title": "A medium-shifted splitting iteration method for a diagonal-plus-Toeplitz linear system from spatial fractional Schrödinger equations",
        "authors": "Ruiping Wen, Peipei Zhao",
        "published": "2018-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1186/s13661-018-0967-1"
    },
    {
        "id": 14700,
        "title": "Autonomous Soaring Policy Initialization Through Value Iteration",
        "authors": "Benjamin J. Rothaupt, Stefan Notter, Walter Fichter",
        "published": "2021-1-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2514/6.2021-2012"
    },
    {
        "id": 14701,
        "title": "Two numerical iteration methods for solving absolute value equations",
        "authors": "Jun He, Yanmin Liu, Junkang Tian",
        "published": "2018",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2306/scienceasia1513-1874.2018.44.040"
    },
    {
        "id": 14702,
        "title": "A Neighborhood-Based Value Iteration Algorithm for POMDP Problems",
        "authors": "Feng Liu, Zheng Liu",
        "published": "2018-11",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ictai.2018.00126"
    },
    {
        "id": 14703,
        "title": "On Some Geometric Behavior of Value Iteration on the Orthant: Switching System Perspective",
        "authors": "Donghwan Lee",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc49753.2023.10383253"
    },
    {
        "id": 14704,
        "title": "Value Iteration Networks",
        "authors": "Aviv Tamar, Yi Wu, Garrett Thomas, Sergey Levine, Pieter Abbeel",
        "published": "2017-8",
        "citations": 95,
        "abstract": "We introduce the value iteration network (VIN): a fully differentiable neural network with a `planning module' embedded within. VINs can learn to plan, and are suitable for predicting outcomes that involve planning-based reasoning, such as policies for reinforcement learning. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation.We evaluate VIN based policies on discrete and continuous path-planning domains, and on a natural-language based search task. We show that by learning an explicit planning computation, VIN policies generalize better to new, unseen domains.This paper is a significantly abridged and IJCAI audience targeted version of the original NIPS 2016 paper with the same title, available here: https://arxiv.org/abs/1602.02867",
        "link": "http://dx.doi.org/10.24963/ijcai.2017/700"
    },
    {
        "id": 14705,
        "title": "Accelerated value iteration via Anderson mixing",
        "authors": "Yujun Li",
        "published": "2021-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11432-019-2889-x"
    },
    {
        "id": 14706,
        "title": "Use of Worksheet events in Excel to save solver objective cell value from each iteration",
        "authors": "Prasanth Sambaraju",
        "published": "2022-2-25",
        "citations": 0,
        "abstract": "Solver is a Microsoft Excel add-in program which is used to find an optimal value for a formula in the objective cell. Solver accomplishes this either by maximizing, minimizing or setting the objective cell value to a specific value. The article presents the utility of in built worksheet events in Excel VBA to save the value of objective cell from each iteration when solver is used for optimization.",
        "link": "http://dx.doi.org/10.3897/rio.8.e79006"
    },
    {
        "id": 14707,
        "title": "Point-based Value Iteration for VAR-POMDPs",
        "authors": "Wei Zheng, Hai Lin",
        "published": "2021-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/acc50511.2021.9482843"
    },
    {
        "id": 14708,
        "title": "Value Iteration Proof of the Three-Server Heterogeneous Server Problem",
        "authors": "Yu Zhang, Shiliang Cui, Kaili Li, Jinting Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3306578"
    },
    {
        "id": 14709,
        "title": "Optimal State Tracking Control for Linear Discrete-time Systems Via Value Iteration",
        "authors": "Yingying Liu, Zhan Shi, Zhanshan Wang",
        "published": "2019-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ccdc.2019.8832847"
    },
    {
        "id": 14710,
        "title": "Point-Based Value Iteration for Finite-Horizon POMDPs",
        "authors": "Erwin Walraven, Matthijs T. J. Spaan",
        "published": "2019-7-11",
        "citations": 13,
        "abstract": "Partially Observable Markov Decision Processes (POMDPs) are a popular formalism for sequential decision making in partially observable environments. Since solving POMDPs to optimality is a difficult task, point-based value iteration methods are widely used. These methods compute an approximate POMDP solution, and in some cases they even provide guarantees on the solution quality, but these algorithms have been designed for problems with an infinite planning horizon. In this paper we discuss why state-of-the-art point-based algorithms cannot be easily applied to finite-horizon problems that do not include discounting. Subsequently, we present a general point-based value iteration algorithm for finite-horizon problems which provides solutions with guarantees on solution quality. Furthermore, we introduce two heuristics to reduce the number of belief points considered during execution, which lowers the computational requirements. In experiments we demonstrate that the algorithm is an effective method for solving finite-horizon POMDPs.",
        "link": "http://dx.doi.org/10.1613/jair.1.11324"
    },
    {
        "id": 14711,
        "title": "Value-iteration-based Adaptive Optimal Reagents Control for Antimony Flotation Process",
        "authors": "Zhongmei Li, Mengzhe Huang, Weihua Gui, Zhong-ping Jiang",
        "published": "2020-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/ccc50068.2020.9188349"
    },
    {
        "id": 14712,
        "title": "Modified Variational Iteration Method Approach for Fuzzy Initial Value Problem",
        "authors": "Maath S. Awad",
        "published": "2023-1-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.24237/asj.01.01.627c"
    },
    {
        "id": 14713,
        "title": "Goal-HSVI: Heuristic Search Value Iteration for Goal POMDPs",
        "authors": "Karel Horák, Branislav Bošanský, Krishnendu Chatterjee",
        "published": "2018-7",
        "citations": 7,
        "abstract": "Partially observable Markov decision processes (POMDPs) are the standard models for planning under uncertainty with both finite and infinite horizon. Besides the well-known discounted-sum objective, indefinite-horizon objective (aka Goal-POMDPs) is another classical objective for POMDPs. In this case, given a set of target states and a positive cost for each transition, the optimization objective is to minimize the expected total cost until a target state is reached.\n\nIn the literature, RTDP-Bel or heuristic search value iteration (HSVI) have been used for solving Goal-POMDPs. Neither of these algorithms has theoretical convergence guarantees, and HSVI may even fail to terminate its trials. We give the following contributions: (1) We discuss the challenges introduced in Goal-POMDPs and illustrate how they prevent the original HSVI from converging. (2) We present a novel algorithm inspired by HSVI, termed Goal-HSVI, and show that our algorithm has convergence guarantees. (3) We show that Goal-HSVI outperforms RTDP-Bel on a set of well-known examples.",
        "link": "http://dx.doi.org/10.24963/ijcai.2018/662"
    },
    {
        "id": 14714,
        "title": "Value iteration via output feedback for LQ optimal control of SISO systems*",
        "authors": "Corrado Possieri",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ifacol.2023.10.590"
    },
    {
        "id": 14715,
        "title": "Cache efficient Value Iteration using clustering and annealing",
        "authors": "Anuj Jain, Sartaj Sahni",
        "published": "2020-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.comcom.2020.04.058"
    },
    {
        "id": 14716,
        "title": "Randomized function fitting-based empirical value iteration",
        "authors": "William B. Haskell, Pengqian Yu, Hiteshi Sharma, Rahul Jain",
        "published": "2017-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc.2017.8264011"
    },
    {
        "id": 14717,
        "title": "Improved value iteration network for path planning",
        "authors": "Shijia Chai",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "Abstract\nIn this study, a series of improved path planning algorithms are designed for path planning tasks in autonomous control based on deep reinforcement learning. The Value Iteration Network (VIN) is used to deal with the path planning problem. Origin VIN performs well on small size maps, but when it comes to a bigger size of map on test set, the success rate decreased. In order to solve the problem that origin VIN lacks long-distance multi-step planning ability on large maps and generalization ability is insufficient, a three-step improvement was made. First of all, in view of the inconvenient data flow and the disappearance of gradients caused by the network being too deep, the jump connection structure is used to obtain the deeper VIN, in which the accuracy of the experiment is improved. Secondly, with the purpose of solving the problem that the complexity of the model is greatly increased due to the deepening of the network, Batch normalization is used to obtain a new network with dueling architecture plus batch normalization layer, which further accelerates the convergence speed of the network. Third, to deal with the global path planning problem on the big map, the hierarchical network structure is adopted for hierarchical value iteration, and the Hierarchical Structure VIN is obtained. In Hierarchical Structure VIN, the long-term planning ability and generalization ability of the algorithm have been significantly improved, and the algorithm could figure out the large-scale and complex path planning problem.",
        "link": "http://dx.doi.org/10.1088/1742-6596/2634/1/012033"
    },
    {
        "id": 14718,
        "title": "New matrix splitting iteration method for generalized absolute value equations",
        "authors": "Wan-Chen Zhao, Xin-Hui Shao",
        "published": "2023",
        "citations": 0,
        "abstract": "<abstract><p>In this paper, a relaxed Newton-type matrix splitting (RNMS) iteration method is proposed for solving the generalized absolute value equations, which includes the Picard method, the modified Newton-type (MN) iteration method, the shift splitting modified Newton-type (SSMN) iteration method and the Newton-based matrix splitting (NMS) iteration method. We analyze the sufficient convergence conditions of the RNMS method. Lastly, the efficiency of the RNMS method is analyzed by numerical examples involving symmetric and non-symmetric matrices.</p></abstract>",
        "link": "http://dx.doi.org/10.3934/math.2023536"
    },
    {
        "id": 14719,
        "title": "State Aggregation for Distributed Value Iteration in Dynamic Programming",
        "authors": "Nikolaus Vertovec, Kostas Margellos",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/lcsys.2023.3285655"
    },
    {
        "id": 14720,
        "title": "Two effective inexact iteration methods for solving the generalized absolute value equations",
        "authors": "Miao Guo, Qingbiao Wu",
        "published": "2022",
        "citations": 1,
        "abstract": "<abstract><p>Modified Newton-type methods are efficient for addressing the generalized absolute value equations. In this paper, to further speed up the modified Newton-type methods, two new inexact modified Newton-type iteration methods are proposed. The sufficient conditions for the convergence of the two proposed inexact iteration methods are given. Moreover, to demonstrate the efficacy of the new method, several numerical examples are provided.</p></abstract>",
        "link": "http://dx.doi.org/10.3934/math.20221027"
    },
    {
        "id": 14721,
        "title": "Two-Player Stackelberg Game for Linear System via Value Iteration Algorithm",
        "authors": "Man Li, Jiahu Qin, Lei Ding",
        "published": "2019-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isie.2019.8781191"
    },
    {
        "id": 14722,
        "title": "Value-Iteration-Based Neuro-Optimal Tracking Control for Affine Systems with Completely Unknown Dynamics",
        "authors": "Mingming Ha, Ding Wang, Derong Liu",
        "published": "2020-7",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/ccc50068.2020.9188706"
    },
    {
        "id": 14723,
        "title": "Analytical approximate solution of higher order boundary value problems via variational iteration method",
        "authors": "Jamshad Ahmad, Zobia Hamid",
        "published": "2017-12-19",
        "citations": 0,
        "abstract": "In this paper, application of variational iteration method has been successfully extended to obtain approximate solutions of some higher order boundary value problems. We emphasize the power of the method by testing three different mathematical models of distinct orders. The results are obtained by using only little iteration.  BIBECHANA 15 (2018) 37-42",
        "link": "http://dx.doi.org/10.3126/bibechana.v15i0.18347"
    },
    {
        "id": 14724,
        "title": "A generalization of the AOR iteration method for solving absolute value equations",
        "authors": "Cui-Xia Li",
        "published": "2022",
        "citations": 3,
        "abstract": "<abstract><p>In this paper, based on the accelerated over relaxation (AOR) iteration method, a generalization of the AOR iteration method is presented to solve the absolute value equations (AVE), which is called the GAOR method. The convergence conditions of the GAOR method are obtained. Numerical experiments are presented in order to verify the feasibility of the GAOR method.</p></abstract>",
        "link": "http://dx.doi.org/10.3934/era.2022056"
    },
    {
        "id": 14725,
        "title": "&lt;strong&gt;Residual Value Iteration Algorithm based on Function Approximation&lt;/strong&gt;",
        "authors": "wen Hu",
        "published": "2017-1-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3390/mol2net-02-03871"
    },
    {
        "id": 14726,
        "title": "Perception-Aware Point-Based Value Iteration for Partially Observable Markov Decision Processes",
        "authors": "Mahsa Ghasemi, Ufuk Topcu",
        "published": "2019-8",
        "citations": 5,
        "abstract": "In conventional partially observable Markov decision processes, the observations that the agent receives originate from fixed known distributions. However, in a variety of real-world scenarios, the agent has an active role in its perception by selecting which observations to receive. We avoid combinatorial expansion of the action space from integration of planning and perception decisions, through a greedy strategy for observation selection that minimizes an information-theoretic measure of the state uncertainty. We develop a novel point-based value iteration algorithm that incorporates this greedy strategy to pick perception actions for each sampled belief point in each iteration. As a result, not only the solver requires less belief points to approximate the reachable subspace of the belief simplex, but it also requires less computation per iteration. Further, we prove that the proposed algorithm achieves a near-optimal guarantee on value function with respect to an optimal perception strategy, and demonstrate its performance empirically.",
        "link": "http://dx.doi.org/10.24963/ijcai.2019/329"
    },
    {
        "id": 14727,
        "title": "Approximate Value Iteration with Temporally Extended Actions  (Extended Abstract)",
        "authors": "Timothy A. Mann, Shie Mannor, Doina Precup",
        "published": "2017-8",
        "citations": 1,
        "abstract": "The options framework provides a concrete way to implement and reason about temporally extended actions. Existing literature has demonstrated the value of planning with options empirically, but there is a lack of theoretical analysis formalizing when planning with options is more efficient than planning with primitive actions. We provide a general analysis of the convergence rate of a popular Approximate Value Iteration (AVI) algorithm called Fitted Value Iteration (FVI) with options. Our analysis reveals that longer duration options and a pessimistic estimate of the value function both lead to faster convergence. Furthermore, options can improve convergence even when they are suboptimal and sparsely distributed throughout the state space. Next we consider generating useful options for planning based on a subset of landmark states. This suggests a new algorithm, Landmark-based AVI (LAVI), that represents the value function only at landmark states. We analyze OFVI and LAVI using the proposed landmark-based options and compare the two algorithms. Our theoretical and experimental results demonstrate that options can play an important role in AVI by decreasing approximation error and inducing fast convergence.",
        "link": "http://dx.doi.org/10.24963/ijcai.2017/717"
    },
    {
        "id": 14728,
        "title": "Value iteration based approximate dynamic programming for mobile robot trajectory tracking with persistent inputs",
        "authors": "Md Suruz Miah",
        "published": "2017-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iris.2017.8250096"
    },
    {
        "id": 14729,
        "title": "How Scenario Iteration Drives Value Creation in Digital Transformation： A Case Study of Oil &amp; Gas Sales in China",
        "authors": "Zixian Wan, Si Zhang, Xin-zhi Chang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4602680"
    },
    {
        "id": 14730,
        "title": "Empirical Q-Value Iteration",
        "authors": "Dileep Kalathil, Vivek S. Borkar, Rahul Jain",
        "published": "2021-3",
        "citations": 2,
        "abstract": " We propose a new simple and natural algorithm for learning the optimal [Formula: see text]-value function of a discounted-cost Markov decision process (MDP) when the transition kernels are unknown. Unlike the classical learning algorithms for MDPs, such as [Formula: see text]-learning and actor-critic algorithms, this algorithm does not depend on a stochastic approximation-based method. We show that our algorithm, which we call the empirical [Formula: see text]-value iteration algorithm, converges to the optimal [Formula: see text]-value function. We also give a rate of convergence or a nonasymptotic sample complexity bound and show that an asynchronous (or online) version of the algorithm will also work. Preliminary experimental results suggest a faster rate of convergence to a ballpark estimate for our algorithm compared with stochastic approximation-based algorithms. ",
        "link": "http://dx.doi.org/10.1287/stsy.2019.0062"
    },
    {
        "id": 14731,
        "title": "Figure 4 from: Sambaraju P (2022) Use of Worksheet events in Excel to save solver objective cell value from each iteration. Research Ideas and Outcomes 8: e79006. https://doi.org/10.3897/rio.8.e79006",
        "authors": "Prasanth Sambaraju",
        "published": "2022-2-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3897/rio.8.e79006.figure4"
    },
    {
        "id": 14732,
        "title": "Efficient UAV path planning using coverage map‐based value iteration",
        "authors": "Zhaozhou Wu, Xingqi Zhang",
        "published": "2023-7",
        "citations": 0,
        "abstract": "AbstractThis letter presents an efficient coverage map‐based unmanned aerial vehicle (UAV) navigation framework in cellular communication systems. Unlike previous research that focused on viewing UAV navigation as a Markov decision process in unknown continuous state space and leveraged various model‐free and deep neural network‐based reinforcement learning algorithms, a more straightforward and efficient model‐based value iteration algorithm is proposed. The algorithm leverages prior knowledge obtained through empirical channel models to develop a sampled coverage map that can be used in value iteration. A deep neural network is subsequently trained with supervised learning to approximate the optimal Q function in continuous state space. Finally, the trained neural network is applied to obtain a UAV trajectory that optimizes the objective function.",
        "link": "http://dx.doi.org/10.1049/ell2.12867"
    },
    {
        "id": 14733,
        "title": "Focused Topological Value Iteration",
        "authors": "Peng Dai,  Mausam, Daniel Weld",
        "published": "2021-5-24",
        "citations": 1,
        "abstract": "\n\n\nTopological value iteration (TVI) is an effective algorithm for solving Markov decision processes (MDPs) optimally, which 1) divides an MDP into strongly-connected components, and 2) solves these components sequentially. Yet, TVI’s usefulness tends to degrade if an MDP has large components, because the cost of the division process isn’t offset by gains during solution. This paper presents a new algorithm to solve MDPs optimally, focused topological value iteration (FTVI). FTVI addresses TVI’s limitations by restricting its attention to connected components that are relevant for solving the MDP. Specifically, FTVI uses a small amount of heuristic search to eliminate provably sub-optimal actions; this pruning allows FTVI to find smaller connected components, thus running faster. We demonstrate that our new algorithm outperforms TVI by an order of magnitude, averaged across several domains. Surprisingly, FTVI also significantly outperforms popular ‘heuristically-informed’ MDP algorithms such as LAO*, LRTDP, and BRTDP in many domains, sometimes by as much as two orders of magnitude. Finally, we characterize the type of domains where FTVI excels — suggesting a way to an informed choice of solver.\n\n\n",
        "link": "http://dx.doi.org/10.1609/icaps.v19i1.18138"
    },
    {
        "id": 14734,
        "title": "Value Iteration is Optic Composition",
        "authors": "Jules Hedges, Riu Rodríguez Sakamoto",
        "published": "2023-8-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4204/eptcs.380.24"
    },
    {
        "id": 14735,
        "title": "Theoretical Analysis of Value-Iteration-Based Q-Learning with Approximation Errors",
        "authors": "Zhantao Liang, Mingming Ha, Derong Liu",
        "published": "2022-10-14",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icist55546.2022.9926794"
    },
    {
        "id": 14736,
        "title": "Relaxed modified Newton-based iteration method for generalized absolute value equations",
        "authors": "Xin-Hui Shao, Wan-Chen Zhao",
        "published": "2023",
        "citations": 1,
        "abstract": "<abstract><p>Many problems in different fields may lead to solutions of absolute value equations, such as linear programming problems, linear complementarity problems, quadratic programming, mixed integer programming, the bimatrix game and so on. In this paper, by introducing a nonnegative real parameter to the modified Newton-based iteration scheme, we present a new relaxed modified Newton-based (RMN) iteration method for solving generalized absolute value equations. The famous Picard iteration method and the modified Newton-type iteration method are the exceptional cases of the RMN iteration method. The convergence property of the new method is discussed. Finally, the validity and feasibility of the RMN iteration method are verified by experimental examples.</p></abstract>",
        "link": "http://dx.doi.org/10.3934/math.2023233"
    },
    {
        "id": 14737,
        "title": "On the relative value iteration with a risk-sensitive criterion",
        "authors": "Ari Arapostathis, Vivek S. Borkar",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4064/bc122-1"
    },
    {
        "id": 14738,
        "title": "A Probabilistic Forward Search Value Iteration Algorithm for POMDP",
        "authors": "Feng Liu, Cheng Lei, Hanyi Liu, Chongjun Wang",
        "published": "2019-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ictai.2019.00061"
    },
    {
        "id": 14739,
        "title": "Value Iteration and Data-Driven Optimal Output Regulation of Linear Continuous-Time Systems",
        "authors": "Yi Jiang, Weinan Gao",
        "published": "2022-8-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ccdc55256.2022.10033453"
    },
    {
        "id": 14740,
        "title": "Application of the variational iteration method for system of initial value problems delay differential equations",
        "authors": "Hamood. M. Yousef, A. I. B. MD. Ismail",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/1.4995896"
    },
    {
        "id": 14741,
        "title": "Analysis of the Risk Sensitive Value Iteration Algorithm",
        "authors": "Igor Oliveira Borges, Karina Valdivia Delgado, Valdinei Freire",
        "published": "2018-10-22",
        "citations": 0,
        "abstract": " This paper shows an empirical study of Value Iteration Risk Sensitive algorithm proposed by Mihatsch and Neuneier (2002). This approach makes use of a risk factor that allows dealing with different types of risk attitude (prone, neutral or averse) by using a discount factor. We show experiments with the domain of Crossing the River in two different scenarios and we analyze the influence of discount factor and risk factor under two aspects: optimal policy and processing time to convergence. We observed that: (i) the processing cost in extreme risk policies is high with both risk-averse and risk-prone attitude; (ii) a high discount increases time to convergence and reinforces the chosen risk attitude; and (iii) policies with intermediate risk factor values have a low computational cost and show a certain sensitivity to risk based on the discount factor.\n\n",
        "link": "http://dx.doi.org/10.5753/eniac.2018.4431"
    },
    {
        "id": 14742,
        "title": "Multiagent value iteration algorithms in dynamic programming and reinforcement learning",
        "authors": "Dimitri Bertsekas",
        "published": "2020-12",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.rico.2020.100003"
    },
    {
        "id": 14743,
        "title": "Iteration Trees",
        "authors": "",
        "published": "2017-3-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781316718315.006"
    },
    {
        "id": 14744,
        "title": "Bisection Value Iteration",
        "authors": "Jia Lu, Ming Xu",
        "published": "2022-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/apsec57359.2022.00023"
    },
    {
        "id": 14745,
        "title": "VARIATIONAL ITERATION METHOD FOR SOLVING FUZZY BOUNDARY VALUE PROBLEMS",
        "authors": " Mohammed Ali Ahmed",
        "published": "2023-4-16",
        "citations": 0,
        "abstract": "Abstract: \r\nThis paper will find the approximate solution to the linear and nonlinear fuzzy boundary value problems using the variational iteration method. The numerical scheme is based on analyzing the fuzzy problem into two crisp sub-problems. The first is for the upper solution and the second is for the lower solution of the fuzzy solution. Also, the convergence of the obtained variational iteration formula has been proved to converge to the exact solution of the problem under consideration in each illustrative example, since there is no general formula that may be obtained for the correction functional related to the problem under consideration which is due to the variation of the general Lagrange multiplier from one problem to another.\r\nKeywords:Fuzzy boundary value problems, variational iteration method, solution of fuzzy differential equations using variational iteration method.",
        "link": "http://dx.doi.org/10.35950/cbej.v29i118.10261"
    },
    {
        "id": 14746,
        "title": "Adaptive Optimal Flight Control for a Fixed-wing Unmanned Aerial Vehicle using Incremental Value Iteration",
        "authors": "Yifei Li, Erik-Jan van Kampen",
        "published": "2023-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icm54990.2023.10101984"
    },
    {
        "id": 14747,
        "title": "Reduced State Value Iteration for Multi-Drone Persistent Surveillance with Charging Constraints",
        "authors": "Patrick H. Washington, Mac Schwager",
        "published": "2021-9-27",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iros51168.2021.9636160"
    },
    {
        "id": 14748,
        "title": "Analyzing Approximate Value Iteration Algorithms",
        "authors": "Arunselvan Ramaswamy, Shalabh Bhatnagar",
        "published": "2022-8",
        "citations": 3,
        "abstract": " In this paper, we consider the stochastic iterative counterpart of the value iteration scheme wherein only noisy and possibly biased approximations of the Bellman operator are available. We call this counterpart the approximate value iteration (AVI) scheme. Neural networks are often used as function approximators, in order to counter Bellman’s curse of dimensionality. In this paper, they are used to approximate the Bellman operator. Because neural networks are typically trained using sample data, errors and biases may be introduced. The design of AVI accounts for implementations with biased approximations of the Bellman operator and sampling errors. We present verifiable sufficient conditions under which AVI is stable (almost surely bounded) and converges to a fixed point of the approximate Bellman operator. To ensure the stability of AVI, we present three different yet related sets of sufficient conditions that are based on the existence of an appropriate Lyapunov function. These Lyapunov function–based conditions are easily verifiable and new to the literature. The verifiability is enhanced by the fact that a recipe for the construction of the necessary Lyapunov function is also provided. We also show that the stability analysis of AVI can be readily extended to the general case of set-valued stochastic approximations. Finally, we show that AVI can also be used in more general circumstances, that is, for finding fixed points of contractive set-valued maps. ",
        "link": "http://dx.doi.org/10.1287/moor.2021.1202"
    },
    {
        "id": 14749,
        "title": "Parameterized value iteration for output reference model tracking of a high order nonlinear aerodynamic system",
        "authors": "Timotei Lala, Mircea-Bogdan Radac",
        "published": "2019-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/med.2019.8798580"
    },
    {
        "id": 14750,
        "title": "Stopping Criteria for Value Iteration on Stochastic Games with Quantitative Objectives",
        "authors": "Jan Křetínský, Tobias Meggendorfer, Maximilian Weininger",
        "published": "2023-6-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/lics56636.2023.10175771"
    },
    {
        "id": 14751,
        "title": "Advanced Affine Optimal Tracking Control Through Online Value Iteration and Its Stability Proof",
        "authors": "Junlong Wu, Ding Wang, Mingming Ha, Mingming Zhao, Jin Ren",
        "published": "2022-7-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/ccc55666.2022.9901577"
    },
    {
        "id": 14752,
        "title": "Polyhedral Value Iteration for Discounted Games and Energy Games",
        "authors": "Alexander Kozachinskiy",
        "published": "2021-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1137/1.9781611976465.37"
    },
    {
        "id": 14753,
        "title": "On computational procedures for Value Iteration in inventory control",
        "authors": "Eligius M.T. Hendrix, Cleo Kortenhorst, Gloria L. Ortega",
        "published": "2019",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ifacol.2019.11.409"
    },
    {
        "id": 14754,
        "title": "A New Constrained Cost Value Iteration for Optimal Control of Discrete-Time Nonlinear Systems",
        "authors": "Tao Li, Qinglai Wei",
        "published": "2021-10-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac53003.2021.9727847"
    },
    {
        "id": 14755,
        "title": "A First-Order Approach to Accelerated Value Iteration",
        "authors": "Vineet Goyal, Julien Grand-Clément",
        "published": "2023-3",
        "citations": 2,
        "abstract": " Markov decision processes (MDPs) are used to model stochastic systems in many applications, but computing good policies becomes hard when the effective horizon become very large. In “A First-Order Approach to Accelerated Value Iteration,” Goyal and Grand-Clément present a connection between value iteration (VI) algorithms and gradient descent methods from convex optimization and use acceleration and momentum to design faster algorithms, with convergence guarantees for the computation of the value function of a fixed policy for reversible MDP instances. The authors provide a lower bound on the convergence properties of any first-order algorithm for solving MDPs, where no algorithm can converge faster than VI. Finally, the authors introduce safe accelerated value iteration (S-AVI), which alternates between accelerated updates and value iteration updates. The algorithm S-AVI is worst-case optimal and retains the theoretical convergence properties of VI while exhibiting strong empirical performances and providing significant speedups when compared with classical approaches for a large test bed of MDP instances. ",
        "link": "http://dx.doi.org/10.1287/opre.2022.2269"
    },
    {
        "id": 14756,
        "title": "Model-Free Value Iteration Solution for Dynamic Graphical Games",
        "authors": "Mohammed Abouheaf, Wail Gueaieb",
        "published": "2018-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/civemsa.2018.8439974"
    },
    {
        "id": 14757,
        "title": "Autonomous Soaring Policy Initialization Through Value Iteration",
        "authors": "",
        "published": "2020-1-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2514/6.2021-2012.vid"
    },
    {
        "id": 14758,
        "title": "Optimal variational iteration method for parametric boundary value problem",
        "authors": "Qura Tul Ain, Muhammad Nadeem, Shazia Karim, Ali Akgül, Fahd Jarad",
        "published": "2022",
        "citations": 8,
        "abstract": "<abstract>\n\t\t\t<p>Mathematical applications in engineering have a long history. One of the most well-known analytical techniques, the optimal variational iteration method (OVIM), is utilized to construct a quick and accurate algorithm for a special fourth-order ordinary initial value problem. Many researchers have discussed the problem involving a parameter <italic>c</italic>. We solve the parametric boundary value problem that can't be addressed using conventional analytical methods for greater values of <italic>c</italic> using a new method and a convergence control parameter <italic>h</italic>. We achieve a convergent solution no matter how huge <italic>c</italic> is. For the approximation of the convergence control parameter <italic>h</italic>, two strategies have been discussed. The advantages of one technique over another have been demonstrated. Optimal variational iteration method can be seen as an effective technique to solve parametric boundary value problem.</p>\n\t\t</abstract>",
        "link": "http://dx.doi.org/10.3934/math.2022912"
    },
    {
        "id": 14759,
        "title": "A new acceleration of variational iteration method for initial value problems",
        "authors": "Mohammad Shirazian",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.matcom.2023.07.002"
    },
    {
        "id": 14760,
        "title": "Caputo’s finite difference solution of fractional two-point boundary value problems using SOR iteration",
        "authors": "R. Rahman, N. A. M. Ali, J. Sulaiman, F. A. Muhiddin",
        "published": "2018",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/1.5054233"
    },
    {
        "id": 14761,
        "title": "A hardware approach to value function iteration",
        "authors": "Alessandro Peri",
        "published": "2020-5",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jedc.2020.103894"
    },
    {
        "id": 14762,
        "title": "Value Iteration Based Continuous-time Nonlinear Constrained Optimal Tracking Controller Design",
        "authors": "Geyang Xiao, Boyang Zhou, Kaiyi Lou, Zhengrong Chen",
        "published": "2020-11-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac51589.2020.9327451"
    },
    {
        "id": 14763,
        "title": "Parallel Hierarchical Pre-Gauss-Seidel Value Iteration Algorithm",
        "authors": "Sanaa Chafik, Abdelhadi Larach, Cherki Daoui",
        "published": "2018-4-1",
        "citations": 0,
        "abstract": "The standard Value Iteration (VI) algorithm, referred to as Value Iteration Pre-Jacobi (PJ-VI) algorithm, is the simplest Value Iteration scheme, and the well-known algorithm for solving Markov Decision Processes (MDPs). In the literature, several versions of VI algorithm were developed in order to reduce the number of iterations: the VI Jacobi (VI-J) algorithm, the Value Iteration Pre-Gauss-Seidel (VI-PGS) algorithm and the VI Gauss-Seidel (VI-GS) algorithm. In this article, the authors combine the advantages of VI Pre Gauss-Seidel algorithm, the decomposition technique and the parallelism in order to propose a new Parallel Hierarchical VI Pre-Gauss-Seidel algorithm. Experimental results show that their approach performs better than the traditional VI schemes in the case where the global problem can be decomposed into smaller problems.",
        "link": "http://dx.doi.org/10.4018/ijdsst.2018040101"
    },
    {
        "id": 14764,
        "title": "A new parallelized of hierarchical value iteration algorithm for discounted Markov decision processes",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3934/dcdss.2022189"
    },
    {
        "id": 14765,
        "title": "Approximate Value Iteration Based on Numerical Quadrature",
        "authors": "Julia Vinogradska, Bastian Bischoff, Jan Peters",
        "published": "2018-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/lra.2018.2798279"
    },
    {
        "id": 14766,
        "title": "SOR-like iteration method for solving absolute value equations",
        "authors": "Yi-Fen Ke, Chang-Feng Ma",
        "published": "2017-10",
        "citations": 31,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.amc.2017.05.035"
    },
    {
        "id": 14767,
        "title": "Numerical Solution of the Absolute Value Equation Using Modified Iteration Methods",
        "authors": "Rashid Ali",
        "published": "2022-7-25",
        "citations": 0,
        "abstract": "This article suggests two new modified iteration methods called the modified Gauss-Seidel (MGS) method and the modified fixed point (MFP) method to solve the absolute value equation. Using appropriate assumptions, we examine the convergence of the given methods. Lastly, numerical examples illustrate the usefulness of the new strategies.",
        "link": "http://dx.doi.org/10.1155/2022/2828457"
    },
    {
        "id": 14768,
        "title": "Variational Iteration Algorithm-I with an Auxiliary Parameter for Solving Boundary Value Problems",
        "authors": "Hijaz Ahmad, Muhammad Rafiq, Clemente Cesarano, Hulya Durur",
        "published": "2020-2-26",
        "citations": 15,
        "abstract": "In this article, the variational iteration algorithm-I with an auxiliary parameter (VIA-I with AP) is elaborated to initial and boundary value problems. The effectiveness, absence of difficulty and accuracy of the proposed method is remarkable and its tractability is well suitable for the use of these type of problems. Some examples have been given to show the effectiveness and utilization of this technique. A comparison of variational iteration algorithm-I (VIA-I) along VIA-I with AP has been carried out. It can be seen that this technique is more appropriate than as VIA-I.",
        "link": "http://dx.doi.org/10.34198/ejms.3220.229247"
    },
    {
        "id": 14769,
        "title": "Asynchronous Value Iteration for Markov Decision Processes with Continuous State Spaces",
        "authors": "Xiangyu Yang, Jian-Qiang Hu, Jiaqiao Hu, Yijie Peng",
        "published": "2020-12-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wsc48552.2020.9384120"
    },
    {
        "id": 14770,
        "title": "Figure 5 from: Sambaraju P (2022) Use of Worksheet events in Excel to save solver objective cell value from each iteration. Research Ideas and Outcomes 8: e79006. https://doi.org/10.3897/rio.8.e79006",
        "authors": "Prasanth Sambaraju",
        "published": "2022-2-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3897/rio.8.e79006.figure5"
    }
]