[
    {
        "id": 10260,
        "title": "All You Need Is LSD",
        "authors": "",
        "published": "2018-10-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5040/9781350101272.00000005"
    },
    {
        "id": 10261,
        "title": "Attention Is Indeed All You Need: Semantically Attention-Guided Decoding for Data-to-Text NLG",
        "authors": "Juraj Juraska, Marilyn Walker",
        "published": "2021",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.inlg-1.45"
    },
    {
        "id": 10262,
        "title": "Rapid Speaker Adaptation for Conformer Transducer: Attention and Bias Are All You Need",
        "authors": "Yan Huang, Guoli Ye, Jinyu Li, Yifan Gong",
        "published": "2021-8-30",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-1884"
    },
    {
        "id": 10263,
        "title": "All You Need Is Love(s)",
        "authors": "Maureen Sie",
        "published": "2018-2-15",
        "citations": 0,
        "abstract": "In this chapter, Maureen Sie argues that our nature as loving beings can explain our nature as moral beings. Because love and morality seem to be similar phenomena in many ways, she distinguishes several kinds of loves and explains how they relate to different moral dimensions of our existence, taking as her starting point C. S. Lewis’s work on the subject and renaming his fourth kind of love “kindness.” She argues that recent findings in affective neuroscience suggest that this fourth kind is a natural kind of love. She discusses the dynamics of Lewis’s account, showing that each of the loves that he distinguishes requires the fourth love (kindness) to keep them from taking a nasty turn. She concludes by explaining why this kind of love actually fits the naturalist picture well if the recent finding that oxytocin is involved in our trusting interactions with strangers is correct.",
        "link": "http://dx.doi.org/10.1093/oso/9780190460723.003.0003"
    },
    {
        "id": 10264,
        "title": "All the attention you need: Global-local, spatial-channel attention for image retrieval",
        "authors": "Chull Hwan Song, Hye Joo Han, Yannis Avrithis",
        "published": "2022-1",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wacv51458.2022.00051"
    },
    {
        "id": 10265,
        "title": "Hydrogen bonds meet self-attention: all you need for general-purpose protein structure embedding",
        "authors": "Cheng Chen, Yuguo Zha, Daming Zhu, Kang Ning, Xuefeng Cui",
        "published": "No Date",
        "citations": 3,
        "abstract": "AbstractGeneral-purpose protein structure embedding can be used for many important protein biology tasks, such as protein design, drug design and binding affinity prediction. Recent researches have shown that attention-based encoder layers are more suitable to learn high-level features. Based on this key observation, we treat low-level representation learning and high-level representation learning separately, and propose a two-level general-purpose protein structure embedding neural network, called ContactLib-ATT. On the local embedding level, a simple yet meaningful hydrogen-bond representation is learned. On the global embedding level, attention-based encoder layers are employed for global representation learning. In our experiments, ContactLib-ATT achieves a SCOP superfamily classification accuracy of 82.4% (i.e., 6.7% higher than state-of-the-art method) on the SCOP40 2.07 dataset. Moreover, ContactLib-ATT is demonstrated to successfully simulate a structure-based search engine for remote homologous proteins, and our top-10 candidate list contains at least one remote homolog with a probability of 91.9%. Source codes: https://github.com/xfcui/contactlib.",
        "link": "http://dx.doi.org/10.1101/2021.01.31.428935"
    },
    {
        "id": 10266,
        "title": "Attention Is (not) All You Need for Commonsense Reasoning",
        "authors": "Tassilo Klein, Moin Nabi",
        "published": "2019",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/p19-1477"
    },
    {
        "id": 10267,
        "title": "Attention Is All You Need for Chinese Word Segmentation",
        "authors": "Sufeng Duan, Hai Zhao",
        "published": "2020",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.emnlp-main.317"
    },
    {
        "id": 10268,
        "title": "11 Attention Is All You Need: Humans and Computers in the Time of Neural Networks",
        "authors": "Nick Seaver",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7312/burn21118-012"
    },
    {
        "id": 10269,
        "title": "Attention in a Little Network is All You Need to Go Green",
        "authors": "Dipayan Dewan, Anupam Borthakur, Debdoot Sheet",
        "published": "2023-4-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isbi53787.2023.10230379"
    },
    {
        "id": 10270,
        "title": "Is attention all you need for intraday Forex trading?",
        "authors": "Przemysław Grądzki, Piotr Wójcik",
        "published": "2024-2",
        "citations": 1,
        "abstract": "AbstractThe main objective of this paper is to analyse whether the Transformer neural network, which has become one of the most influential algorithms in Artificial Intelligence over the last few years, exhibits predictive capabilities for high‐frequency Forex data. The prediction task is to classify short‐term Forex movements for six currency pairs and five different time intervals from 60 to 720 min. We find that the Transformer exhibits high predictive power in the context of intraday Forex trading. This performance is slightly better than for the carefully selected benchmark – ResNet‐LSTM, which currently is a state‐of‐the‐art algorithm. Since intraday Forex trading based on deep learning models is largely unexplored, we offer insight on which currency pair and time interval are amenable to devising a profitable trading strategy. We also show that high predictive accuracy can be misleading in real world trading for short time intervals, as models trained on OHLC data tend to report the highest accuracy when the spread cost is the highest. This renders assessment based on typical machine learning metrics overly optimistic. Therefore, it is critical to backtest frequent intraday Forex trading strategies with realistic cost assumptions, which is rarely the case in empirical literature. Lastly, sensitivity analysis shows that the length of the time interval used for training does not play a critical role in the Transformer's predictive capabilities, whereas features derived from technical analysis are essential.",
        "link": "http://dx.doi.org/10.1111/exsy.13317"
    },
    {
        "id": 10271,
        "title": "Not all parameters are born equal: Attention is mostly what you need",
        "authors": "Nikolay Bogoychev",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.blackboxnlp-1.28"
    },
    {
        "id": 10272,
        "title": "Is attention to bounding boxes all you need for pedestrian action prediction?",
        "authors": "Lina Achaji, Julien Moreau, Thibault Fouqueray, Francois Aioun, Francois Charpillet",
        "published": "2022-6-5",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iv51971.2022.9827084"
    },
    {
        "id": 10273,
        "title": "Faculty Opinions recommendation of Protein structure prediction by AlphaFold2: are attention and symmetries all you need?",
        "authors": "Jia-Huai Wang",
        "published": "2021-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3410/f.740551959.793588208"
    },
    {
        "id": 10274,
        "title": "Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine",
        "authors": "Stefan Harrer",
        "published": "2023-4",
        "citations": 94,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ebiom.2023.104512"
    },
    {
        "id": 10275,
        "title": "Fake News Spreaders Detection: Sometimes Attention Is Not All You Need",
        "authors": "Marco Siino, Elisa Di Nuovo, Ilenia Tinnirello, Marco La Cascia",
        "published": "2022-9-9",
        "citations": 16,
        "abstract": "Guided by a corpus linguistics approach, in this article we present a comparative evaluation of State-of-the-Art (SotA) models, with a special focus on Transformers, to address the task of Fake News Spreaders (i.e., users that share Fake News) detection. First, we explore the reference multilingual dataset for the considered task, exploiting corpus linguistics techniques, such as chi-square test, keywords and Word Sketch. Second, we perform experiments on several models for Natural Language Processing. Third, we perform a comparative evaluation using the most recent Transformer-based models (RoBERTa, DistilBERT, BERT, XLNet, ELECTRA, Longformer) and other deep and non-deep SotA models (CNN, MultiCNN, Bayes, SVM). The CNN tested outperforms all the models tested and, to the best of our knowledge, any existing approach on the same dataset. Fourth, to better understand this result, we conduct a post-hoc analysis as an attempt to investigate the behaviour of the presented best performing black-box model. This study highlights the importance of choosing a suitable classifier given the specific task. To make an educated decision, we propose the use of corpus linguistics techniques. Our results suggest that large pre-trained deep models like Transformers are not necessarily the first choice when addressing a text classification task as the one presented in this article. All the code developed to run our tests is publicly available on GitHub.",
        "link": "http://dx.doi.org/10.3390/info13090426"
    },
    {
        "id": 10276,
        "title": "Cross-Attention is All You Need: Adapting Pretrained Transformers for Machine Translation",
        "authors": "Mozhdeh Gheini, Xiang Ren, Jonathan May",
        "published": "2021",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.emnlp-main.132"
    },
    {
        "id": 10277,
        "title": "Master GAN: Multiple Attention is all you Need: A Multiple Attention Guided Super Resolution Network for Dems",
        "authors": "Azhan Mohammed, Mohammad Kashif, Md Haider Zama, Mohammed Abbas Ansari, Saquib Ali",
        "published": "2023-7-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/igarss52108.2023.10283196"
    },
    {
        "id": 10278,
        "title": "Re-Label Is All You Need",
        "authors": "TechOnly Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.",
        "link": "http://dx.doi.org/10.36227/techrxiv.17128475.v7"
    },
    {
        "id": 10279,
        "title": "Re-Label Is All You Need",
        "authors": "TechOnly Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.",
        "link": "http://dx.doi.org/10.36227/techrxiv.17128475.v8"
    },
    {
        "id": 10280,
        "title": "Re-Label Is All You Need",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.",
        "link": "http://dx.doi.org/10.36227/techrxiv.17128475.v12"
    },
    {
        "id": 10281,
        "title": "Inflow is all you need",
        "authors": "Javier Sanz Rodrigo",
        "published": "2023-9-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5194/wes-2023-101-rc1"
    },
    {
        "id": 10282,
        "title": "Re-Label Is All You Need",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.",
        "link": "http://dx.doi.org/10.36227/techrxiv.17128475.v10"
    },
    {
        "id": 10283,
        "title": "Re-Label Is All You Need",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.",
        "link": "http://dx.doi.org/10.36227/techrxiv.17128475.v6"
    },
    {
        "id": 10284,
        "title": "Re-Label Is All You Need",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.",
        "link": "http://dx.doi.org/10.36227/techrxiv.17128475.v9"
    },
    {
        "id": 10285,
        "title": "Re-Label Is All You Need",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.",
        "link": "http://dx.doi.org/10.36227/techrxiv.17128475.v11"
    },
    {
        "id": 10286,
        "title": "Re-Label Is All You Need",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.",
        "link": "http://dx.doi.org/10.36227/techrxiv.17128475.v4"
    },
    {
        "id": 10287,
        "title": "Re-Label Is All You Need",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.",
        "link": "http://dx.doi.org/10.36227/techrxiv.17128475.v3"
    },
    {
        "id": 10288,
        "title": "Re-Label Is All You Need",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "In industry deep learning application, our manually labeled data has a certain number of noisy data. To solve this problem and achieve more than 90 score in dev dataset, we present a simple method to find the noisy data and re-label the noisy data by human, given the model predictions as references in human labeling. In this paper, we illustrate our idea for a broad set of deep learning tasks, includes classification, sequence tagging, object detection, sequence generation, click-through rate prediction. The experimental results and human evaluation results verify our idea.",
        "link": "http://dx.doi.org/10.36227/techrxiv.17128475.v5"
    },
    {
        "id": 10289,
        "title": "Attention Is All You Need In Speech Separation",
        "authors": "Cem Subakan, Mirco Ravanelli, Samuele Cornell, Mirko Bronzi, Jianyuan Zhong",
        "published": "2021-6-6",
        "citations": 207,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp39728.2021.9413901"
    },
    {
        "id": 10290,
        "title": "Looking at CTR Prediction Again: Is Attention All You Need?",
        "authors": "Yuan Cheng, Yanbo Xue",
        "published": "2021-7-11",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3404835.3462936"
    },
    {
        "id": 10291,
        "title": "Yes, \"Attention Is All You Need\", for Exemplar based Colorization",
        "authors": "Wang Yin, Peng Lu, Zhaoran Zhao, Xujun Peng",
        "published": "2021-10-17",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3474085.3475385"
    },
    {
        "id": 10292,
        "title": "A Little Bit Attention Is All You Need for Person Re-Identification",
        "authors": "Markus Eisenbach, Jannik Lübberstedt, Dustin Aganian, Horst-Michael Gross",
        "published": "2023-5-29",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icra48891.2023.10160304"
    },
    {
        "id": 10293,
        "title": "Internal abdominal hernias: All you need to know",
        "authors": "Elmar Merkle",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26226/morressier.60b507c485c68bde00a35624"
    },
    {
        "id": 10294,
        "title": "Turns Out You Take It All with You",
        "authors": "",
        "published": "2022-3-22",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1s5nzc3.9"
    },
    {
        "id": 10295,
        "title": "All You Need Is Tea",
        "authors": "Catherine E. Herrold",
        "published": "2020-5-21",
        "citations": 0,
        "abstract": "Chapter 4 presents the democracy building strategies of Egypt’s philanthropic foundations and development NGOs. Amidst widespread government repression of civil society and heightened suspicion of Western efforts to promote democracy, local organizations stepped in. They harnessed citizens’ desires to take part in Egypt’s trajectory and positioned themselves as facilitators of citizen-led initiatives. Instead of creating and imposing their own reform initiatives, Egyptian foundations and development NGOs worked closely with grassroots communities to cultivate democracy on their terms. Egyptians wanted political, economic, and social justice, not necessarily a Western-style democracy. The approach taken by local groups both respected grassroots priorities and cultures and allowed the organizations to evade government crackdowns.",
        "link": "http://dx.doi.org/10.1093/oso/9780190093235.003.0005"
    },
    {
        "id": 10296,
        "title": "Neural HMMS Are All You Need (For High-Quality Attention-Free TTS)",
        "authors": "Shivam Mehta, Eva Szekely, Jonas Beskow, Gustav Eje Henter",
        "published": "2022-5-23",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp43922.2022.9746686"
    },
    {
        "id": 10297,
        "title": "Equity‐premium prediction: Attention is all you need",
        "authors": "Luiz Renato Lima, Lucas Lúcio Godeiro",
        "published": "2023-1",
        "citations": 3,
        "abstract": "SummaryPredictions of stock returns are greatly improved relative to low‐dimensional forecasting regressions when the forecasts are based on the estimated factor of large data sets, also known as the diffusion index (DI) model. However, when applied to text data, DI models do not perform well. This paper shows that by simply using text data in a DI model does not improve equity‐premium forecasts over the naive historical‐average model, but substantial gains are obtained when one selects the most predictive words before computing the factors and allows the dictionary to be updated over time.",
        "link": "http://dx.doi.org/10.1002/jae.2939"
    },
    {
        "id": 10298,
        "title": "Oral cavity and oropharynx: All you need to know",
        "authors": "PiotrGolofit PiotrGolofit",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26226/morressier.60dc80a65d86378f03b41197"
    },
    {
        "id": 10299,
        "title": "Measuring absolute poverty: shame is all you need",
        "authors": "Robert Walker",
        "published": "2019-4-3",
        "citations": 2,
        "abstract": "As a heuristic polemic, it is proposed that, while poverty is objective, multidimensional and inherently relative, it should be quantified using a single, absolute and subjective measure: namely, poverty-related shame. The concepts of poverty and absolute poverty is first interrogated before, following Amartya Sen, arguing that shame is an absolutely essential component of poverty and, moreover, that poverty-related shame offers a measure of poverty that is universal in the sense that it is evidenced in all countries irrespective of their level of economic development. Manifestations of poverty-related shame are then considered before exploring its potential value as a universal measure of poverty. Its universality is considered with respect to conceptual, functional, metric and political equivalence.",
        "link": "http://dx.doi.org/10.1332/policypress/9781447341284.003.0005"
    },
    {
        "id": 10300,
        "title": "Differentiable Channels Are All You Need",
        "authors": "Corey Cooke, Jeremy Till",
        "published": "2022-5-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2172/1881079"
    },
    {
        "id": 10301,
        "title": "Response to “Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine”",
        "authors": "Markus Trengove, Robert Vandersluis, Lea Goetz",
        "published": "2023-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ebiom.2023.104671"
    },
    {
        "id": 10302,
        "title": "Grassroots fundraising: you already know all the people you need to know to raise all the money you want to raise",
        "authors": "Kim Klein",
        "published": "2023-4-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781003145936-31"
    },
    {
        "id": 10303,
        "title": "Response to M. Trengove &amp; coll regarding “Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine”",
        "authors": "Stefan Harrer",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ebiom.2023.104672"
    },
    {
        "id": 10304,
        "title": "Re-Attention Is All You Need: Memory-Efficient Scene Text Detection via Re-Attention on Uncertain Regions",
        "authors": "Hsiang-Chun Chang, Hung-Jen Chen, Yu-Chia Shen, Hong-Han Shuai, Wen-Huang Cheng",
        "published": "2021-9-27",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iros51168.2021.9636510"
    },
    {
        "id": 10305,
        "title": "All you need is … CLIL",
        "authors": "Claudia Bartholemy",
        "published": "2021-10-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.37307/j.2194-1823.2021.65.09"
    },
    {
        "id": 10306,
        "title": "Channel Attention Is All You Need for Video Frame Interpolation",
        "authors": "Myungsub Choi, Heewon Kim, Bohyung Han, Ning Xu, Kyoung Mu Lee",
        "published": "2020-4-3",
        "citations": 164,
        "abstract": "Prevailing video frame interpolation techniques rely heavily on optical flow estimation and require additional model complexity and computational cost; it is also susceptible to error propagation in challenging scenarios with large motion and heavy occlusion. To alleviate the limitation, we propose a simple but effective deep neural network for video frame interpolation, which is end-to-end trainable and is free from a motion estimation network component. Our algorithm employs a special feature reshaping operation, referred to as PixelShuffle, with a channel attention, which replaces the optical flow computation module. The main idea behind the design is to distribute the information in a feature map into multiple channels and extract motion information by attending the channels for pixel-level frame synthesis. The model given by this principle turns out to be effective in the presence of challenging motion and occlusion. We construct a comprehensive evaluation benchmark and demonstrate that the proposed approach achieves outstanding performance compared to the existing models with a component for optical flow computation.",
        "link": "http://dx.doi.org/10.1609/aaai.v34i07.6693"
    },
    {
        "id": 10307,
        "title": "Attention is all you need: An interpretable transformer-based asset allocation approach",
        "authors": "Tian Ma, Wanwan Wang, Yu Chen",
        "published": "2023-11",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.irfa.2023.102876"
    },
    {
        "id": 10308,
        "title": "DPP: this will tell you all you need to know",
        "authors": " Michael Sprack",
        "published": "2017-2-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.13169/socialistlawyer.75.0046"
    },
    {
        "id": 10309,
        "title": "When Parkinson’s Is Keeping You Up All Night",
        "authors": "",
        "published": "2020-10-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv15wxnsd.42"
    },
    {
        "id": 10310,
        "title": "All you need to you know about resistant ovary syndrome: a systematic review and foundation for future research",
        "authors": "Caroline Zundel",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26226/morressier.5af300b2738ab10027aa995b"
    },
    {
        "id": 10311,
        "title": "Introduction",
        "authors": "",
        "published": "2017-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc7767n.5"
    },
    {
        "id": 10312,
        "title": "Hold it all",
        "authors": "",
        "published": "2022-3-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctv1s5nzc3.15"
    },
    {
        "id": 10313,
        "title": "Hydrogen bonds meet self-attention: all you need for protein structure embedding",
        "authors": "Cheng Chen, Yuguo Zha, Daming Zhu, Kang Ning, Xuefeng Cui",
        "published": "2021-12-9",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bibm52615.2021.9669557"
    },
    {
        "id": 10314,
        "title": "Attention Is All You Need For Blind Room Volume Estimation",
        "authors": "Chunxi Wang, Maoshen Jia, Meiran Li, Changchun Bao, Wenyu Jin",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447723"
    },
    {
        "id": 10315,
        "title": "GAN Vocoder: Multi-Resolution Discriminator Is All You Need",
        "authors": "Jaeseong You, Dalhyun Kim, Gyuhyeon Nam, Geumbyeol Hwang, Gyeongsu Chae",
        "published": "2021-8-30",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-41"
    },
    {
        "id": 10316,
        "title": "What Slides Will You Need?",
        "authors": "Haje Jan Kamps",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6065-4_4"
    },
    {
        "id": 10317,
        "title": "Conclusion",
        "authors": "",
        "published": "2017-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc775f3.22"
    },
    {
        "id": 10318,
        "title": "Bibliography",
        "authors": "",
        "published": "2021-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108992879.023"
    },
    {
        "id": 10319,
        "title": "Preface",
        "authors": "",
        "published": "2021-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108992879.001"
    },
    {
        "id": 10320,
        "title": "Geometry",
        "authors": "",
        "published": "2021-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108992879.009"
    },
    {
        "id": 10321,
        "title": "Bijections",
        "authors": "",
        "published": "2017-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc775f3.9"
    },
    {
        "id": 10322,
        "title": "Series",
        "authors": "",
        "published": "2017-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc775f3.21"
    },
    {
        "id": 10323,
        "title": "Countability",
        "authors": "",
        "published": "2017-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc775f3.10"
    },
    {
        "id": 10324,
        "title": "Hypothesis Testing",
        "authors": "",
        "published": "2017-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc7767n.26"
    },
    {
        "id": 10325,
        "title": "All you need to know about using smart infusion pumps",
        "authors": "",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1211/pj.2017.20203076"
    },
    {
        "id": 10326,
        "title": "Convergence",
        "authors": "",
        "published": "2017-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc775f3.16"
    },
    {
        "id": 10327,
        "title": "Discrete Distributions",
        "authors": "",
        "published": "2017-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc7767n.16"
    },
    {
        "id": 10328,
        "title": "Stirling’s Formula",
        "authors": "",
        "published": "2017-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc7767n.22"
    },
    {
        "id": 10329,
        "title": "Back Matter",
        "authors": "",
        "published": "2017-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc7767n.36"
    },
    {
        "id": 10330,
        "title": "Introduction",
        "authors": "",
        "published": "2017-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc775f3.3"
    },
    {
        "id": 10331,
        "title": "Index",
        "authors": "",
        "published": "2021-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108992879.024"
    },
    {
        "id": 10332,
        "title": "Algorithms",
        "authors": "",
        "published": "2021-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108992879.020"
    },
    {
        "id": 10333,
        "title": "Tools:",
        "authors": "",
        "published": "2017-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc7767n.13"
    },
    {
        "id": 10334,
        "title": "Algebra",
        "authors": "",
        "published": "2021-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108992879.012"
    },
    {
        "id": 10335,
        "title": "Front Matter",
        "authors": "",
        "published": "2017-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc7767n.1"
    },
    {
        "id": 10336,
        "title": "To make hydrogen peroxide, all you need is water",
        "authors": "",
        "published": "2019-9-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/pt.6.1.20190926a"
    },
    {
        "id": 10337,
        "title": "Attention And Positional Encoding Are (Almost) All You Need For Shape Matching",
        "authors": "Alessandro Raganato, Gabriella Pasi, Simone Melzi",
        "published": "2023-8",
        "citations": 2,
        "abstract": "AbstractThe fast development of novel approaches derived from the Transformers architecture has led to outstanding performance in different scenarios, from Natural Language Processing to Computer Vision. Recently, they achieved impressive results even in the challenging task of non‐rigid shape matching. However, little is known about the capability of the Transformer‐encoder architecture for the shape matching task, and its performances still remained largely unexplored. In this paper, we step back and investigate the contribution made by the Transformer‐encoder architecture compared to its more recent alternatives, focusing on why and how it works on this specific task. Thanks to the versatility of our implementation, we can harness the bi‐directional structure of the correspondence problem, making it more interpretable. Furthermore, we prove that positional encodings are essential for processing unordered point clouds. Through a comprehensive set of experiments, we find that attention and positional encoding are (almost) all you need for shape matching. The simple Transformer‐encoder architecture, coupled with relative position encoding in the attention mechanism, is able to obtain strong improvements, reaching the current state‐of‐the‐art.",
        "link": "http://dx.doi.org/10.1111/cgf.14912"
    },
    {
        "id": 10338,
        "title": "Linear Algebra",
        "authors": "",
        "published": "2021-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108992879.002"
    },
    {
        "id": 10339,
        "title": "Special Sequences",
        "authors": "",
        "published": "2017-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc775f3.20"
    },
    {
        "id": 10340,
        "title": "Topological Definitions",
        "authors": "",
        "published": "2017-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc775f3.11"
    },
    {
        "id": 10341,
        "title": "Re-Label By Data Pattern Is All You Need For Knowledge Driven Deep Learning",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In industry deep learning application, we should fix the badcase by human evaluation after we achieve more than 95% accuracy at dev dataset. The badcase reason is from the wrong rule/knowledge of human labeling and will cause low accuracy under human evaluation. In this paper, we propose the pattern-based method to fix the badcase for industry application inference. We propose the pipeline to solve the problem and improve the accuracy of human evaluation. The experiment results verify our idea, which means label-edit is the method to implement controllable deep learning application.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.20485917.v6"
    },
    {
        "id": 10342,
        "title": "Re-Label By Data Pattern Is All You Need For Knowledge Driven Deep Learning",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In industry deep learning application, we should fix the badcase by human evaluation after we achieve more than 95% accuracy at dev dataset. The badcase reason is from the wrong rule/knowledge of human labeling and will cause low accuracy under human evaluation. In this paper, we propose the pattern-based method to fix the badcase for industry application inference. We propose the pipeline to solve the problem and improve the accuracy of human evaluation. The experiment results verify our idea, which means label-edit is the method to implement controllable deep learning application.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.20485917.v8"
    },
    {
        "id": 10343,
        "title": "Re-Label By Data Pattern Is All You Need For Knowledge Driven Deep Learning",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In industry deep learning application, we should fix the badcase by human evaluation after we achieve more than 95% accuracy at dev dataset. The badcase reason is from the wrong rule/knowledge of human labeling and will cause low accuracy under human evaluation. In this paper, we propose the pattern-based method to fix the badcase for industry application inference. We propose the pipeline to solve the problem and improve the accuracy of human evaluation. The experiment results verify our idea, which means label-edit is the method to implement controllable deep learning application.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.20485917.v7"
    },
    {
        "id": 10344,
        "title": "Lebesgue Integration",
        "authors": "",
        "published": "2021-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108992879.016"
    },
    {
        "id": 10345,
        "title": "Re-Label By Data Pattern Is All You Need For Knowledge Driven Deep Learning",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In industry deep learning application, we should fix the badcase after we achieve more than 95% accuracy at dev dataset. The badcase reason is from the wrong rule/knowledge of human labeling and will cause low accuracy under human evaluation. In this paper, we propose the pattern-based method to fix the badcase for industry application inference. We propose the pipeline to solve the problem and improve the accuracy of human evaluation. The experiment results verify our idea, which means label-edit is the method to implement controllable deep learning application.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.20485917.v3"
    },
    {
        "id": 10346,
        "title": "Basic Probability Laws",
        "authors": "",
        "published": "2017-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc7767n.6"
    },
    {
        "id": 10347,
        "title": "Counting I:",
        "authors": "",
        "published": "2017-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc7767n.7"
    },
    {
        "id": 10348,
        "title": "Subsequential Limits",
        "authors": "",
        "published": "2017-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc775f3.19"
    },
    {
        "id": 10349,
        "title": "Set Theory",
        "authors": "",
        "published": "2017-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc775f3.5"
    },
    {
        "id": 10350,
        "title": "Front Matter",
        "authors": "",
        "published": "2017-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc775f3.1"
    },
    {
        "id": 10351,
        "title": "Re-Label By Data Pattern Is All You Need For Knowledge Driven Deep Learning",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In industry deep learning application, we should fix the badcase after we achieve more than 95% accuracy at dev dataset. The badcase reason is from the wrong rule/knowledge of human labeling and will cause low accuracy under human evaluation. In this paper, we propose the pattern-based method to fix the badcase for industry application inference. We propose the pipeline to solve the problem and improve the accuracy of human evaluation. The experiment results verify our idea.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.20485917.v2"
    },
    {
        "id": 10352,
        "title": "Re-Label By Data Pattern Is All You Need For Knowledge Driven Deep Learning",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In industry deep learning application, we should fix the badcase after we achieve more than 95% accuracy at dev dataset. The badcase reason is from the wrong rule/knowledge of human labeling and will cause low accuracy under human evaluation. In this paper, we propose the pattern-based method to fix the badcase for industry application inference. We propose the pipeline to solve the problem and improve the accuracy of human evaluation. The experiment results verify our idea.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.20485917.v1"
    },
    {
        "id": 10353,
        "title": "Re-Label By Data Pattern Is All You Need For Knowledge Driven Deep Learning",
        "authors": "TechOnly Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In industry deep learning application, we should fix the badcase by human evaluation after we achieve more than 95% accuracy at dev dataset. The badcase reason is from the wrong rule/knowledge of human labeling and will cause low accuracy under human evaluation. In this paper, we propose the pattern-based method to fix the badcase for industry application inference. We propose the pipeline to solve the problem and improve the accuracy of human evaluation. The experiment results verify our idea, which means label-edit is the method to implement controllable deep learning application.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.20485917.v5"
    },
    {
        "id": 10354,
        "title": "Equivalence Relations",
        "authors": "",
        "published": "2021-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108992879.022"
    },
    {
        "id": 10355,
        "title": "Differential Equations",
        "authors": "",
        "published": "2021-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108992879.018"
    },
    {
        "id": 10356,
        "title": "Table of Contents",
        "authors": "",
        "published": "2017-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2307/j.ctvc7767n.2"
    },
    {
        "id": 10357,
        "title": "Re-Label By Data Pattern Is All You Need For Knowledge Driven Deep Learning",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In industry deep learning application, we should fix the badcase by human evaluation after we achieve more than 95% accuracy at dev dataset. The badcase reason is from the wrong rule/knowledge of human labeling and will cause low accuracy under human evaluation. In this paper, we propose the pattern-based method to fix the badcase for industry application inference. We propose the pipeline to solve the problem and improve the accuracy of human evaluation. The experiment results verify our idea, which means label-edit is the method to implement controllable deep learning application.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.20485917.v9"
    },
    {
        "id": 10358,
        "title": "Complex Analysis",
        "authors": "",
        "published": "2021-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108992879.014"
    },
    {
        "id": 10359,
        "title": "Fourier Analysis",
        "authors": "",
        "published": "2021-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108992879.017"
    }
]