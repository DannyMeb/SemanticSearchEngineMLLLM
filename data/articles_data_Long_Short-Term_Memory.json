[
    {
        "id": 905,
        "title": "Prediksi Harga Forex Menggunakan Algoritma Long Short-Term Memory",
        "authors": "Mohammad Rezza Pahlevi",
        "published": "2023-9-30",
        "citations": 0,
        "abstract": "Trillions of dollars per day of foreign currency trading activity occur in the forex market, which has very volatile movements in foreign currency trading. Trade based on bid and ask prices. The market determines foreign exchange rates based on supply and demand rules. Currency trading in pairs such as EUR/USD is a comparison of the value of the Euro against the Dollar as a basis for research, rising and falling currency prices in forex move fluctuatingly, so a market participant must be able to decide on buying and selling positions. Because wrong decisions can lead to losses. One of the ways to reduce risk in making decisions in buying and selling in forex can be using forecasting. This study uses the LSTM method in predicting forex prices which will be tested on several scales of dataset distribution. The smallest error results using a total dataset of 2631 with a dataset division of 70:15:15, which is divided into 70% data for training, 15% data for validation and 15% data for testing produces an RMSE value of 0.038, MAPE 2.5%. In measuring how well the regression model used with Rsquare on the data distribution is 70:15:15 and the total dataset used is 4979 to get the best results, namely 97%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36802/jnanaloka.2022.v3-no2-69-76"
    },
    {
        "id": 906,
        "title": "Curvature-Informed Attention Mechanism for Long Short-Term Memory Networks",
        "authors": "Lynda Ayachi",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012463500003636"
    },
    {
        "id": 907,
        "title": "Implementasi Long Short Term Memory (LSTM) dan Bidirectional Long Short Term Memory (BiLSTM) Dalam Prediksi Harga Saham Syariah",
        "authors": "Dian Islamiaty Puteri",
        "published": "2023-5-29",
        "citations": 0,
        "abstract": "The development of the stock market in Indonesia is currently growing quite rapidly. This can be seen based on the number of investors who have increased every year. In 2011, sharia stocks were launched for the first time in Indonesia, and it can be seen that the price of the stock is not always stable or can experience increases or decreases. For investors, a strategy is needed to predict stock prices in order to make the right decisions in investing. In this study, stock prediction was carried out using the Long Short-Term Memory (LSTM) and Bidirectional Long Short-Term Memory (BiLSTM) methods. The data used in this study is historical closing price data for three Sharia stocks, namely PT Aneka Tambang Tbk, PT Unilever Indonesia Tbk, and PT Indofood Sukses Makmur Tbk. In building the best predictive model in this study based on tuning parameters such as epoch, batch, neurons, as well as an optimizer and dropout regulation techniques to prevent overfitting of the model. The test results show that from the three stock data used, the smallest MAPE value is obtained in the BiLSTM model. The MAPE values obtained for each stock data in this study are sequentially 2,59%, 1,77%, and 1,05%. Based on the MAPE value criteria, the prediction model is included in the very accurate criteria.",
        "keywords": "",
        "link": "http://dx.doi.org/10.34312/euler.v11i1.19791"
    },
    {
        "id": 908,
        "title": "Stock Price Prediction Using Long Short-term Memory",
        "authors": "",
        "published": "2023-12-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17756/nwj.2023-s4-080"
    },
    {
        "id": 909,
        "title": "Long Short-Term Memory and Bidirectional Long Short-Term Memory Modeling and Prediction of Hexavalent and Total Chromium Removal Capacity Kinetics of Cupressus lusitanica Bark",
        "authors": "Juan Crescenciano Cruz-Victoria, Alma Rosa Netzahuatl-Muñoz, Eliseo Cristiani-Urbina",
        "published": "2024-3-29",
        "citations": 0,
        "abstract": "Hexavalent chromium [Cr(VI)] is a high-priority environmental pollutant because of its toxicity and potential to contaminate water sources. Biosorption, using low-cost biomaterials, is an emerging technology for removing pollutants from water. In this study, Long Short-Term Memory (LSTM) and bidirectional LSTM (Bi-LSTM) neural networks were used to model and predict the kinetics of the removal capacity of Cr(VI) and total chromium [Cr(T)] using Cupressus lusitanica bark (CLB) particles. The models were developed using 34 experimental kinetics datasets under various temperature, pH, particle size, and initial Cr(VI) concentration conditions. Data preprocessing via interpolation was implemented to augment the sparse time-series data. Early stopping regularization prevented overfitting, and dropout techniques enhanced model robustness. The Bi-LSTM models demonstrated a superior performance compared to the LSTM models. The inherent complexities of the process and data limitations resulted in a heavy-tailed and left-skewed residual distribution, indicating occasional deviations in the predictions of capacities obtained under extreme conditions. K-fold cross-validation demonstrated the stability of Bi-LSTM models 38 and 43, while response surfaces and validation with unseen datasets assessed their predictive accuracy and generalization capabilities. Shapley additive explanations analysis (SHAP) identified the initial Cr(VI) concentration and time as the most influential input features for the models. This study highlights the capabilities of deep recurrent neural networks in comprehending and predicting complex pollutant removal kinetic phenomena for environmental applications.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/su16072874"
    },
    {
        "id": 910,
        "title": "Short-term Load Forecasting with Distributed Long Short-Term Memory",
        "authors": "Yi Dong, Yang Chen, Xingyu Zhao, Xiaowei Huang",
        "published": "2023-1-16",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isgt51731.2023.10066368"
    },
    {
        "id": 911,
        "title": "Investigation of Long Short-Term Memory Networks in Short-Term Electric Vehicle Charging Load Modeling",
        "authors": "Egemen Karabiyik, Aysegul Sari Karabiyik",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eleco60389.2023.10416026"
    },
    {
        "id": 912,
        "title": "Sentiment assessment of electronic money application using long short-term memory and bidirectional long short term memory",
        "authors": "Dwi Intan Af’idah, Sharfina Febbi Handayani, Dairoh Dairoh, Riszki Wijayatun Pratiwi",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0199034"
    },
    {
        "id": 913,
        "title": "Penerapan Algoritma Long Short-Term Memory untuk Prediksi Produksi Kelapa Sawit",
        "authors": "Fahri Husaini, Inggih Permana, M. Afdal, Febi Nur Salisah",
        "published": "2024-2-5",
        "citations": 0,
        "abstract": "Kelapa sawit memberikan kontribusi yang besar bagi perkembangan perekonomian Indonesia. Salah satunya ekspor non migas negara dan yang terus mengalami pertumbuhan yang dilakukan perusahaan kelapa sawit. PT XYZ merupakan salah satu perusahaan kelapa sawit yang mengolah kelapa sawit menjadi minyak kelapa sawit. Dalam menghadapi permintaan minyak kelapa sawit dunia yang terus meningkat, PT. XYZ berkomitmen untuk meningkatkan produksinya. Untuk meningkatkan produksi, PT XYZ telah menetapkan target produksi dengan melakukan prediksi produksi kelapa sawit menggunakan metode Global Telling. Namun, metode ini kurang efektif karena tidak dilakukan secara berkala. Untuk itu, diperlukan suatu metode yang dapat mempelajari pola panen setiap bulannya untuk membuat target produksi. Penelitian ini menerapkan Algoritma Long Short-Term Memory dengan percobaan beberapa parameter untuk menemukan model terbaik yang dapat memprediksi produksi kelapa sawit secara akurat. Berdasarkan hasil percobaan, model dengan optimizer RMSprop, learning rate 0.001, dan batch size 8 merupakan model dengan parameter terbaik dengan nilai RMSE 0.1725, MAPE 0.5087, dan R2 0.0578. Model tersebut memprediksi bahwa produksi kelapa sawit akan mengalami penurunan",
        "keywords": "",
        "link": "http://dx.doi.org/10.57152/malcom.v4i2.1187"
    },
    {
        "id": 914,
        "title": "Short-Term Stock Price Prediction Based on Long-Short Term Memory Neural Network Model",
        "authors": "Baofeng Li, Yangyang Li",
        "published": "2023-9-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciscae59047.2023.10392876"
    },
    {
        "id": 915,
        "title": "Bayesian-Optimization-Based Long Short-Term Memory (LSTM) Super Learner Approach for Modeling Long-Term Electricity Consumption",
        "authors": "Salma Hamad Almuhaini, Nahid Sultana",
        "published": "2023-9-7",
        "citations": 2,
        "abstract": "This study utilized different methods, namely classical multiple linear regression (MLR), statistical approach exponential smoothing (EXPS), and deep learning algorithm long short-term memory (LSTM) to forecast long-term electricity consumption in the Kingdom of Saudi Arabia. The originality of this research lies in (1) specifying exogenous variables that significantly affect electrical consumption; (2) utilizing the Bayesian optimization algorithm (BOA) to develop individual super learner BOA-LSTM models for forecasting the residential and total long-term electric energy consumption; (3) measuring forecasting performances of the proposed super learner models with classical and statistical models, viz. MLR and EXPS, by employing the broadly used evaluation measures regarding the computational efficiency, model accuracy, and generalizability; and finally (4) estimating forthcoming yearly electric energy consumption and validation. Population, gross domestic products, imports, and refined oil products significantly impact residential and total annual electricity consumption. The coefficient of determination (R2) for all the proposed models is greater than 0.93, representing an outstanding fitting of the models with historical data. Moreover, the developed BOA-LSTM models have the best performance with R2>0.99, enhancing the predicting accuracy (Mean Absolute Percentage Error (MAPE)) by 59.6% and 54.8% compared to the MLR and EXPS models, respectively, of total annual electricity consumption. This forecasting accuracy in residential electricity consumption for the BOA-LSTM model is improved by 62.7% and 68.9% compared to the MLR and EXPS models. This study achieved a higher accuracy and consistency of the proposed super learner model in long-term electricity forecasting, which can be utilized in energy strategy management to secure the sustainability of electric energy.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/su151813409"
    },
    {
        "id": 916,
        "title": "Short-Term Electricity Load Forecasting Based on Ensemble Empirical Mode Decomposition and Long Short-Term Memory Neural Network",
        "authors": "Haiyan Xu, Yong Zhang, Yong Zhao",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icei60179.2023.00058"
    },
    {
        "id": 917,
        "title": "Attentional Refreshing in the Absence of Long-Term Memory Content: Role of Short-Term and Long-Term Consolidation",
        "authors": "Maximilien Labaronne, Gabriel Jarjat, Gaën Plancher",
        "published": "2023-1-11",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5334/joc.246"
    },
    {
        "id": 918,
        "title": "Bi-Lingual Machine Translation Approach using Long Short–Term Memory Model for Asian Languages",
        "authors": "A Shalini Divya Prasanna, C Beulah Christalin Latha",
        "published": "2023-5-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17485/ijst/v16i18.176"
    },
    {
        "id": 919,
        "title": "Video Normalization in Identifying Fake Videos Using a Long Short-Term Memory Model",
        "authors": "Kirtan Thakkar, Dan Lo",
        "published": "2023-4-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/southeastcon51012.2023.10115139"
    },
    {
        "id": 920,
        "title": "Predicting Future Wave Heights by Using Long Short-Term Memory",
        "authors": "Jannik Klemm, Alexander Gabriel, Frank Sill Torres",
        "published": "2023-6-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/oceanslimerick52467.2023.10244329"
    },
    {
        "id": 921,
        "title": "Memory long and short term time series network for ultra-short-term photovoltaic power forecasting",
        "authors": "Congzhi Huang, Mengyuan Yang",
        "published": "2023-9",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.energy.2023.127961"
    },
    {
        "id": 922,
        "title": "Short-Term Bus Load Forecasting Model Based on KICEEMDAN and IWOA Optimized Bidirectional Long- and Short-Term Memory Network",
        "authors": "Junfeng Xiang, Keying Yin",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icipca59209.2023.10257953"
    },
    {
        "id": 923,
        "title": "Flight short-term booking demand forecasting based on a long short-term memory network",
        "authors": "Haonan He, Liangyu Chen, Shanyong Wang",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cie.2023.109707"
    },
    {
        "id": 924,
        "title": "Improving short-term stability of fiber-optic radio frequency transfer using long short-term memory prediction",
        "authors": "Jiahui Cheng, Yaojun Qiao, Hao Gao, Song Yu, Chenxia Liu",
        "published": "2023-2-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/1.oe.62.2.026101"
    },
    {
        "id": 925,
        "title": "Short-term Power Load Forecasting Based on Particle Swarm Optimization Long Short-term Memory Neural Network",
        "authors": "Ziteng Zhang, Wenhao Xu, Qingdong Gong",
        "published": "2023-2-24",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eebda56825.2023.10090722"
    },
    {
        "id": 926,
        "title": "Long-term and short-term memory network based movie comment sentiment analysis",
        "authors": "Ruoxue Bi",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": "This paper proposes an emotional analysis method of movie reviews based on Long-term and Short-term Memory(LSTM) Network model. Emotional analysis is widely used in movie recommendation system, which can recommend and judge movies by understanding the audiences emotional response to movies. However, due to the characteristics of movie text and the complexity of emotional expression, traditional methods such as machine learning have limitations and shortcomings in emotional analysis. However, the LSTM models better memory is utilized by the method proposed in this paper and the ability to capture the long-term correlation in movie texts, which obviously improves the accuracy and reliability of emotional analysis, and demonstrates the advantages of the LSTM model in emotional analysis compared to the traditional model. Future research can further explore other deep learning models and algorithms, so as to make emotional analysis more accurate and provide users with reliable movie recommendation information.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/36/20230437"
    },
    {
        "id": 927,
        "title": "Build A Module for Improvement Real Time Speech enhancement using Long Short-term Memory Approach",
        "authors": "Van Vo, Bach Son Le, Huy Phuc Vo, Huong Thi Cam Nguyen, Phuong Huu Khanh Lam",
        "published": "2023-2-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3591569.3591614"
    },
    {
        "id": 928,
        "title": "LONG SHORT TERM MEMORY FOR STOCK MARKET FORECAST",
        "authors": "",
        "published": "2023-5-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets38317"
    },
    {
        "id": 929,
        "title": "Prediction of Travel Purpose Based on the Long Short-Term Memory Network",
        "authors": "Yan Zhang, De Zhao",
        "published": "2023-8-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1061/9780784484869.099"
    },
    {
        "id": 930,
        "title": "Time Series Prediction Analysis of Long Short Term Memory Models",
        "authors": "Mutasem Jarrah",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icci61671.2024.10485015"
    },
    {
        "id": 931,
        "title": "A short-term prediction model of global ionospheric VTEC based on the combination of long short-term memory and convolutional long short-term memory",
        "authors": "Peng Chen, Rong Wang, Yibin Yao, Hao Chen, Zhihao Wang, Zhiyuan An",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00190-023-01744-y"
    },
    {
        "id": 932,
        "title": "Recognition memory decisions made with short- and long-term retrieval",
        "authors": "Shuchun Lea Lai, Rui Cao, Richard M. Shiffrin",
        "published": "2024-2-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3758/s13421-024-01518-7"
    },
    {
        "id": 933,
        "title": "Short-term runoff forecasting in an alpine catchment with a long short-term memory neural network",
        "authors": "Corinna Frank, Marc Rußwurm, Javier Fluixa-Sanmartin, Devis Tuia",
        "published": "2023-4-17",
        "citations": 0,
        "abstract": "The governing hydrological processes are expected to shift under climate change in the alpine regions of Switzerland. This raises the need for more adaptive and accurate methods to estimate river flow. In high-altitude catchments influenced by snow and glaciers, short-term flow forecasting is challenging, as the exact mechanisms of transient melting processes are difficult to model mathematically and are poorly understood to this date. Machine learning methods, particularly temporally aware neural networks, have been shown to compare well and often outperform process-based hydrological models on medium and long-range forecasting. In this work, we evaluate a Long Short-Term Memory neural network (LSTM) for short-term prediction (up to three days) of hourly river flow in an alpine headwater catchment (Goms Valley, Switzerland). We compare the model with the regional standard, an existing process-based model (named MINERVE) that is used by local authorities and is calibrated on the study area. We found that the LSTM was more accurate than the process-based model on high flows and better represented the diurnal melting cycles of snow and glacier in the area of interest. It was on par with MINERVE in estimating two flood events: the LSTM captures the dynamics of a precipitation-driven flood well, while underestimating the peak discharge during an event with varying conditions between rain and snow. Finally, we analyzed feature importances and tested the transferability of the trained LSTM on a neighboring catchment showing comparable topographic and hydrological features. The accurate results obtained highlight the applicability and competitiveness of data-driven temporal machine learning models with the existing process-based model in the study area.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/frwa.2023.1126310"
    },
    {
        "id": 934,
        "title": "Prediction of Long-Term Stock returns using Long Short Term Memory Neural Network",
        "authors": "Ch. Anuradha, D. Prem Sai Ganesh Babu, A. Abhinava Reddy",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icacic59454.2023.10435336"
    },
    {
        "id": 935,
        "title": "Load Recognition by Long Short-Term Memory considering Long and Short Term Operation of Mechanical Equipment",
        "authors": "Jung Ho Kang,  ",
        "published": "2024-2-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14775/ksmpe.2024.23.2.069"
    },
    {
        "id": 936,
        "title": "A short-term wind power prediction approach based on ensemble empirical mode decomposition and improved long short-term memory",
        "authors": "Tianyue Jiang, Yutong Liu",
        "published": "2023-9",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compeleceng.2023.108830"
    },
    {
        "id": 937,
        "title": "Short-term photovoltaic power forecasting using meta-learning and numerical weather prediction independent Long Short-Term Memory models",
        "authors": "Elissaios Sarmas, Evangelos Spiliotis, Efstathios Stamatopoulos, Vangelis Marinakis, Haris Doukas",
        "published": "2023-11",
        "citations": 23,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.renene.2023.118997"
    },
    {
        "id": 938,
        "title": "Air Quality Index Prediction Based on a Long Short-Term Memory Artificial Neural Network Model",
        "authors": "Chen Wang Chen Wang, Bingchun Liu Chen Wang, Jiali Chen Bingchun Liu, Xiaogang Yu Jiali Chen",
        "published": "2023-4",
        "citations": 0,
        "abstract": "\n                        <p>Air pollution has become one of the important challenges restricting the sustainable development of cities. Therefore, it is of great significance to achieve accurate prediction of Air Quality Index (AQI). Long Short Term Memory (LSTM) is a deep learning method suitable for learning time series data. Considering its superiority in processing time series data, this study established an LSTM forecasting model suitable for air quality index forecasting. First, we focus on optimizing the feature metrics of the model input through Information Gain (IG). Second, the prediction results of the LSTM model are compared with other machine learning models. At the same time the time step aspect of the LSTM model is used with selective experiments to ensure that model validation works properly. The results show that compared with other machine learning models, the LSTM model constructed in this paper is more suitable for the prediction of air quality index.</p>\n<p>&nbsp;</p>\n                    ",
        "keywords": "",
        "link": "http://dx.doi.org/10.53106/199115992023043402006"
    },
    {
        "id": 939,
        "title": "State of Charge Estimation of Lithium-Ion Batteries Using Long Short-Term Memory and Bi-directional Long Short-Term Memory Neural Networks",
        "authors": "Kannan Madhavan Namboothiri, K. Sundareswaran, P. Srinivasa Rao Nayak, Sishaj P. Simon",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s40031-023-00947-3"
    },
    {
        "id": 940,
        "title": "Stock Price Prediction Using Long Short Term Memory Algorithm",
        "authors": "Dhruv Sharma, Damandeep Kaur",
        "published": "2023-10-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/gcat59970.2023.10353382"
    },
    {
        "id": 941,
        "title": "Long Short-term Memory Applied on Amazon's Stock Prediction",
        "authors": "Chenze Zhou",
        "published": "2023-2-28",
        "citations": 1,
        "abstract": "More and more investors are paying attention to how to use data mining technology into stock investing decisions as a result of the introduction of big data and the quick expansion of financial markets. Machine learning can automatically apply complex mathematical calculations to big data repeatedly and faster. The machine model can analyze all the factors and indicators affecting stock price and achieve high efficiency. Based on the Amazon stock price published on Kaggle, this paper adopts the Long Short-term Memory (LSTM) method for model training. The Keras package in the Python program is used to normalize the data. The Sequence model in Keras establishes a two-layer LSTM network and a three-layer LSTM network to compare and analyze the fitting effect of the model on stock prices. By calculating RMSE and RMPE, the study found that the stock price prediction accuracy of two-layer LSTM is similar to that of three-layer LSTM. In terms of F-measure and Accuracy, the LSTM model of the three-layer network is significantly better than the LSTM model of the two-layer network layer. In general, the LSTM model can accurately predict stock price. Therefore, investors will know the upward or downward trend of stock prices in advance according to the prediction results of the model to make corresponding decisions.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v34i.5380"
    },
    {
        "id": 942,
        "title": "Reliability Estimation Using Long Short-Term Memory Networks",
        "authors": "Alex Davila-Frias, Phattara Khumprom, Om Prakash Yadav",
        "published": "2023-1-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/rams51473.2023.10088225"
    },
    {
        "id": 943,
        "title": "Stock price prediction with long short-term memory",
        "authors": "Jialuo He",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "Stock forecasting aims to predict future stock prices based on past price changes in the market, playing an essential role in the field of financial transactions. However, since the stock market is highly uncertain, stock prediction is complex and challenging. This paper uses the long short-term memory (LSTM) model to predict the stock market and compares it with the current stock prediction algorithm. Firstly, we preprocessed the raw dataset and normalized data into the range from 0 to 1. Secondly, we introduced the LSTM model and improved its performance by tuning four parameters: learning rate, number of hidden layers, number of epochs, and batch size. Finally, we use four evaluation metrics to evaluate models: mean average error (MAE), root mean square error (RMSE), coefficient of determination (R2), and mean absolute error percentage (MAPE). Our LSTM model performs better than the previous model in experiments in terms of MAE, RMSE, R2, and MAPE.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/4/20230428"
    },
    {
        "id": 944,
        "title": "Long short-term memory with activation on gradient",
        "authors": "Chuan Qin, Liangming Chen, Zangtai Cai, Mei Liu, Long Jin",
        "published": "2023-7",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.04.026"
    },
    {
        "id": 945,
        "title": "Near-term forecasting of water reservoir storage capacities using long short-term memory",
        "authors": "Eric Rohli, Nicholas Woolsey, David Sathiaraj",
        "published": "2023",
        "citations": 0,
        "abstract": "Abstract\nPredicting reservoir storage capacities is an important planning activity for effective conservation and water release practices. Weather events such as drought and precipitation impact water storage capacities in reservoirs. Predictive insights on reservoir storage levels are beneficial for water planners and stakeholders in effective water resource management. A deep learning (DL) neural network (NN) based reservoir storage prediction approach is proposed that learns from climate, hydrological, and storage information within the reservoir’s associated watershed. These DL models are trained and evaluated for 17 reservoirs in Texas, USA. Using the trained models, reservoir storage predictions were validated with a test data set spanning 2 years. The reported results show promise for longer-term water planning decisions.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1017/eds.2023.25"
    },
    {
        "id": 946,
        "title": "Transition of short-term to long-term memory of Cu/TaOx/CNT conductive bridge random access memory for neuromorphic engineering",
        "authors": "Jihyung Kim, Jin Hyeong Choi, Sunghun Kim, Changsoon Choi, Sungjun Kim",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.carbon.2023.118438"
    },
    {
        "id": 947,
        "title": "Combining fuzzy clustering and improved long short-term memory neural networks for short-term load forecasting",
        "authors": "Fu Liu, Tian Dong, Qiaoliang Liu, Yun Liu, Shoutao Li",
        "published": "2024-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.epsr.2023.109967"
    },
    {
        "id": 948,
        "title": "Sentiment Analysis using Long Short-Term Memory",
        "authors": "B. Prabha, S. Maheshwari, P. Durgadevi",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10306792"
    },
    {
        "id": 949,
        "title": "Diabetes Prediction Using Bi-directional Long Short-Term Memory",
        "authors": "Sushma Jaiswal, Priyanka Gupta",
        "published": "2023-5-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42979-023-01831-z"
    },
    {
        "id": 950,
        "title": "A long short-term memory approach for CO2 emission estimation",
        "authors": "Jialin Wu",
        "published": "2023-10-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3005940"
    },
    {
        "id": 951,
        "title": "Stock Price Prediction based on Long Short-Term Memory Model",
        "authors": "Ziji Liu",
        "published": "2023-4-1",
        "citations": 0,
        "abstract": "The stock market is a place that brings investors opportunity to gain profit. Meanwhile, the stock market also brings investors high risks, which requires machine learning methods to improve the accuracy of prediction. This paper uses the Long Short-Term Memory (LSTM) model to predict stock prices. In the study, the daily stock historical data of Sinopec, Moutai and SPD Bank in the past 21 years are used as samples, including the date, the trade volume, the highest price, the lowest price, and the opening and closing prices. After the LSTM model has been trained, the three companies' predictions of opening price have achieved good results, and the predicted opening price curve and the actual opening price curve seem to be quite consistent. In terms of evaluation indicators, MAPE of the three companies is less than 1%. These results can provide some help for investors to predict stocks and shed light on guiding further studies.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v39i.6621"
    },
    {
        "id": 952,
        "title": "Prediction of Ethereum Prices Using Linear Regression and Long Short-term Memory",
        "authors": "Wenni Zhang",
        "published": "2023-3-2",
        "citations": 0,
        "abstract": "Contemporarily, the popularity and use of cryptocurrencies has risen along with their prices and Ethereum is the second most popular and largest cryptocurrency after Bitcoin. Cryptocurrencies are based on the blockchain, which is a decentralized technology that has the power to change any banking system. They have become an attractive investment for both traders and individuals looking to invest. The price of Ethereum fluctuates and is affected by various factors, e.g., the crypto trading exchange as well as supply and demand. Ethereum is so valuable because it can be used as cash and one also pay Ethereum in full or in part to someone in exchange. Besides, it is easily guaranteed by the blockchain. Unlike stocks, the price of Ethereum is much more variable because it is traded 24 hours a day and there are no closing times. On this basis, this paper compares the results of two different models, namely linear regression and Long Short-Term Memory networks (LSTM). The dataset comprised in the closing prices of the last 372 days for Ethereum. The performance of the obtained models is critically evaluated using statistical indicators Root Mean Squared Error (RMSE) and the study have drawn our conclusions based on the RMSE result. The paper demonstrates a technique for using time series data in both models and determining each model's RMSE. These results shed light on guiding further exploration of prediction Ethereum prices and trends.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54691/bcpbm.v38i.4179"
    },
    {
        "id": 953,
        "title": "Vehicle Driving Intent Recognition Based on Enhanced Bidirectional Long Short-Term Memory Network",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23977/jaip.2023.060504"
    },
    {
        "id": 954,
        "title": "Predict Stock Price Movement Using Long Short-Term Memory Recurrent Neural Network and Support Vector Machin",
        "authors": "",
        "published": "2023-1-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.47750/qas/24.194.06"
    },
    {
        "id": 955,
        "title": "Transformer and long short-term memory networks for long sequence time sequence forecasting problem",
        "authors": "Wei Fang",
        "published": "2023-3-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2667895"
    },
    {
        "id": 956,
        "title": "Intelligent Mining and Retrieval of Music Data Based on Long-Term and Short-Term Memory Neural Network",
        "authors": "Yan Gao, Lin Gao",
        "published": "2023-8-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdsi60108.2023.00015"
    },
    {
        "id": 957,
        "title": "Multiple decomposition‐aided long short‐term memory network for enhanced short‐term wind power forecasting",
        "authors": "Mehmet Balci, Emrah Dokur, Ugur Yuzgec, Nuh Erdogan",
        "published": "2024-2",
        "citations": 0,
        "abstract": "AbstractWith the increasing penetration of grid‐scale wind energy systems, accurate wind power forecasting is critical to optimizing their integration into the power system, ensuring operational reliability, and enabling efficient system asset utilization. Addressing this challenge, this study proposes a novel forecasting model that combines the long‐short‐term memory (LSTM) neural network with two signal decomposition techniques. The EMD technique effectively extracts stable, stationary, and regular patterns from the original wind power signal, while the VMD technique tackles the most challenging high‐frequency component. A deep learning‐based forecasting model, i.e. the LSTM neural network, is used to take advantage of its ability to learn from longer sequences of data and its robustness to noise and outliers. The developed model is evaluated against LSTM models employing various decomposition methods using real wind power data from three distinct offshore wind farms. It is shown that the two‐stage decomposition significantly enhances forecasting accuracy, with the proposed model achieving  values up to 9.5% higher than those obtained using standard LSTM models.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/rpg2.12919"
    },
    {
        "id": 958,
        "title": "Long Short-Term Memory for Short Term Load Forecasting with Singular Spectrum Analysis and Whale Optimization Algorithm",
        "authors": "Ruixiang Zhang, Meng Yuan, Zhaorui Jin, Ziyu Zhu, Yuanhui Chen, Yu Wang, Yaojie Sun, Longjun Zhao",
        "published": "2023-3-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aeees56888.2023.10114086"
    },
    {
        "id": 959,
        "title": "Short Term Photovoltaic Power Prediction based on Sparrow Algorithm Optimized Long-short Term Memory Neural Network",
        "authors": "Liu Liu, Junyong Zhao, Liang Ma, Peng Zhang",
        "published": "2023-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/acpee56931.2023.10135743"
    },
    {
        "id": 960,
        "title": "Ultra-short-term Photovoltaic Power Prediction Based on Multi-head ProbSparse Self-attention and Long Short-term Memory",
        "authors": "Tianyi Yang, Quanming Zhao, Yifan Meng",
        "published": "2023-8-1",
        "citations": 1,
        "abstract": "Abstract\nTo provide accurate predictions of photovoltaic (PV) power generation, an MHPSA-LSTM ultra-short-term multipoint PV power prediction model combining Multi-head ProbSparse self-attention (MHPSA) and long short-term memory (LSTM) network is posited. The MHPSA is first used to capture information dependencies at a distance. Secondly, the LSTM is used to enhance the local correlation. At last, a pooling layer is added after LSTM to reduce the parameters of the fully-connected layer and alleviate overfitting, thus improving the prediction accuracy. The MHPSA-LSTM model is validated on a PV plant at the Desert Knowledge Australia Solar Centre as an example, and the RMSE, MAE, and R2 of MHPSA-LSTM are 0.527, 0.264, and 0.917, respectively. MHPSA-LSTM has higher prediction accuracy compared with BP, LSTM, GRU, and CNN-LSTM.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1742-6596/2558/1/012007"
    },
    {
        "id": 961,
        "title": "Short-term load prediction of electric vehicle charging station based on Long-Short-Term Memory Neural Network",
        "authors": "Zhipeng Su, Zhiwen Yu, Li Ma, Jianlin Tang, Bin Qian, Xiaoming Lin, Fan Zhang",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icceic60201.2023.10426741"
    },
    {
        "id": 962,
        "title": "Short-Term Traffic Prediction Using Deep Learning Long Short-Term Memory: Taxonomy, Applications, Challenges, and Future Trends",
        "authors": "Anwar Khan, Mostafa M. Fouda, Dinh-Thuan Do, Abdulaziz Almaleh, Atiq Ur Rahman",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3309601"
    },
    {
        "id": 963,
        "title": "A Review on Long Short Term Memory based Stock Price Prediction Techniques",
        "authors": "Kandlagunta Divyavalli, P Raghuraman",
        "published": "2023-1-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccci56745.2023.10128285"
    },
    {
        "id": 964,
        "title": "Retail Demand Forecasting Using Sequence to Sequence Long Short-Term Memory Networks",
        "authors": "Mon Myat Phyu, Myat Thiri Khine",
        "published": "2023-2-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icca51723.2023.10181450"
    },
    {
        "id": 965,
        "title": "Long Short-Term Memory (LSTM) Based Deep Learning Models for Predicting Univariate Time Series Data",
        "authors": "",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18178/ijml.2024.14.1.1154"
    },
    {
        "id": 966,
        "title": "Integration of Bidirectional Long Short-Term Memory (Bilstm) and Two-Dimensional Convolutional Neural Networks (CONV2D) for Improved Hepatitis A and B Prediction",
        "authors": "Oyinlola Dupe Sharon",
        "published": "2024-1-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.55248/gengpi.5.0124.0122"
    },
    {
        "id": 967,
        "title": "A Long Short-Term Memory-Based Prototype Model for Drought Prediction",
        "authors": "William Villegas-Ch, Joselin García-Ortiz",
        "published": "2023-9-20",
        "citations": 1,
        "abstract": "This study presents the development of a deep learning model to predict droughts in the coastal region of Ecuador. Historical information from local meteorological stations was used, including data on precipitation, temperature, humidity, evapotranspiration, and soil moisture. A multi-layered artificial neural network was used. It was trained and evaluated by cross-validation, comparing it with other machine learning algorithms. The results demonstrate that the proposed model achieved a remarkable accuracy of 98.5% and a high sensitivity of 97.2% in predicting drought events in the coastal region of Ecuador. This exceptional performance underscores the model’s potential for effective decision making to prevent and mitigate droughts. In addition, the study’s limitations are discussed, and possible improvements are proposed, such as the incorporation of satellite data and the analysis of other environmental variables. This study highlights the importance of deep learning models in drought prediction and their potential to contribute to sustainable management in areas vulnerable to this climatic phenomenon.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12183956"
    },
    {
        "id": 968,
        "title": "Long Short-Term Memory (LSTM) Network Applications in Stock Price Prediction",
        "authors": "Kaimao Wang",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aikiie60097.2023.10390445"
    },
    {
        "id": 969,
        "title": "COVID-19 Epidemic Trend Prediction using Long Short-term Memory Network",
        "authors": "Tianren Zhang",
        "published": "2023-4-1",
        "citations": 0,
        "abstract": "The COVID-19 pandemic is continuously spreading in various countries and different regions. It produces serious economic shock worldwide and negatively impacts the life and work of people. Although many control measures are conducted to contain its spread, it is still not known when the epidemic will end. Predicting the trend of COVID-19 accurately is extremely important. It can improve the resource allocation rate and make better preventive and control measures for the epidemic. In this paper, Long Short-term Memory (LSTM) models are leveraged for predicting the epidemic in different countries, including Germany, Japan, Russia, and Italy. The LSTM is a type of recurrent neural network (RNN), which is effective for predicting sequential data such as the time series. In this work, a visualization analysis is firstly conducted for demonstrating the trends of COVID-19 in various countries. Then the performances of the LSTM network are validated on the data of four countries.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v39i.6537"
    },
    {
        "id": 970,
        "title": "Forecasting Oil Recovery Using Long Short Term Memory Neural Machine Learning Technique",
        "authors": "Jonathan Asante, William Ampomah, Martha Carther",
        "published": "2023-5-15",
        "citations": 0,
        "abstract": "Abstract\nThis paper focuses on using a timeseries neural network to forecast the oil recovery of a mature oil reservoir undergoing tertiary CO2 water alternating gas (WAG) enhanced oil recovery (EOR). Estimating future oil recovery is a necessity for planning an effective EOR strategy. Because of the high uncertainty associated with numerical modeling input parameters, modeling is not necessarily an accurate predictor of future performance for a specific well or even an entire field. The evolution of machine learning algorithms has shown that data-driven models can make decisions based on trends and pattern recognition to achieve tractable, robust, and cost-effective solutions.\nThe methodology is validated by analyzing a five-spot pattern from the study field. The one injector well and four producers within the pattern are considered to be mutually connected. The multivariate timeseries (MTS) field data utilized in the model construction include production bottom-hole pressure, injection pressure, WAG cycles, and injection volumes. These MTS input data were preprocessed into a format that is more understandable and useful for the model. A Long-Short-Term Memory (LSTM) neural network model was established to determine patterns and trends, discover relationships from MTS data, and subsequently predict oil recovery through model-fitting. During the model construction, the preprocessed dataset was split into training and testing sets based on production time periods. The largest portion of the data set is apportioned to train the model, and it also corresponds to the earliest part of the production. The model is tested on the remaining data set chronologically.\nAnalysis of field history calibration through loss iteration of the training dataset shows a low mean squared error of 7.16 and a relatively high R-squared value of 0.92. The developed model was validated using a test set, and results showed high-level model predictability of an R-squared value of 0.88. Additional model validation was performed using other wells’ information within the pattern as a blind test dataset. An average R-squared of 0.88 was observed for the other producing wells. The validated model was used to forecast oil recovery into the future with a reasonable outcome. From the forecast, uncertainty increased with the increasing length of time in the future, and the alteration of the WAG cycle significantly impacted the oil recovery. The LSTM model can predict oil recovery with a high level of accuracy. The successful predictions and reasonable forecasting of the oil recovery prove the effectiveness and usefulness of data-driven models.\nThe workflow presented in this paper predicts the oil recovery without a detailed geological model and/or numerical simulation; it only considers time-changing parameters. Analyzing the LSTM model's results provides robust guidance to adjust real-time field development plans.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2118/212967-ms"
    },
    {
        "id": 971,
        "title": "Long Short-Term Memory for Improved Transients in Neural Network Adaptive Control",
        "authors": "Emirhan Inanc, Yigit Gurses, Abdullah Habboush, Yildiray Yildiz",
        "published": "2023-5-31",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/acc55779.2023.10155805"
    },
    {
        "id": 972,
        "title": "Multi-Step Ahead Prediction of Freezing Depth via Deep Learning with Long Short-Term Memory",
        "authors": "Aynaz Biniyaz, Zhen Liu",
        "published": "2024-2-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1061/9780784485330.075"
    },
    {
        "id": 973,
        "title": "YAP_LSTM: yoga asana prediction using pose estimation and long short-term memory",
        "authors": "J. Palanimeera, K. Ponmozhi",
        "published": "2023-8-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00500-023-09044-5"
    },
    {
        "id": 974,
        "title": "South African inflation modelling using bootstrapped long short-term memory methods",
        "authors": "Sihle Kubheka",
        "published": "2023-6-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43546-023-00490-9"
    },
    {
        "id": 975,
        "title": "Supervised Fusion Music Composition Through Long Short-Term Memory and Stochastic Modelling",
        "authors": "Matthew Lee",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "Music composition has witnessed significant advancements with the infusion of artificial intelligence, particularly using Long Short-Term Memory (LSTM) networks. However, most existing algorithms offer minimal control to composers in influencing the genre fusion process, thereby potentially undermining their creative preferences. This study introduces a novel, two-phase algorithm for personalized fusion music generation that reflects the composer's individual preferences. In the first phase, melodies are generated for individual genres using Recurrent Neural Networks (RNNs) employing techniques like Sequential, Dense, and one-hot encoding. These generated melodies serve as input for the second phase, where an LSTM network fuses them into a coherent composition. Notably, the algorithm incorporates weights set by the composer for each genre, allowing for a personalized composition. A stochastic approach is employed in both phases to introduce creative variance while balancing structural coherence. We demonstrate this balance through various metrics offering a more tailored fused music generation experience enriched by stochastic modeling.",
        "keywords": "",
        "link": "http://dx.doi.org/10.47611/jsrhs.v12i4.5919"
    },
    {
        "id": 976,
        "title": "Development of Resolver Circuit with Long Short Term Memory and Reinforcement Learning Algorithms",
        "authors": "Yusuf Çağlayan",
        "published": "2023-8-19",
        "citations": 0,
        "abstract": "In our age, the usage areas of artificial intelligence have increased considerably. These areas were particularly concerned with the correct predictability of future data using available data. It has become necessary to work on various machine learning algorithms to  be  used  in  the  calculations  of the resolver circuit, which is a feedback element used for tracking the position and position information of the electric motor unit used in various vehicles. The use of machine learning algorithms in the design and implementation of the resolver circuit, which is one of the most important elements   of electric motor designs,  will  shed  light  on  future  studies.  In this study, it is focused on the use of machine learning algorithms in the calculation of the resolver circuit, position and position information and the performance differences between each other. In this study, LSTM (Long Short Term Memory) and Reinforcement Learning (RL) algorithms were compared. While comparing these algorithms, the types of LSTM and RL algorithms were also studied and compared.   As a result of the results obtained, it was aimed that the motor designs would be less costly, and the results obtained in terms  of more reliable motor position and position information to     be used were promising. In addition, with this study, a basis was created for working on machine learning algorithms in   the calculation of different parameters. With this study,  a  great way has been achieved in integrating algorithms used in electric vehicles, which are quite obsolete today, into AI-based algorithms.\n\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.58190/icat.2023.23"
    },
    {
        "id": 977,
        "title": "A Comparative Study of Long Short-Term Memory and Gated Recurrent Unit",
        "authors": "Sebastian Obeta, Enrico Grisan, Chinazor Vivian Kalu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4442677"
    },
    {
        "id": 978,
        "title": "Long short-term memory networks for window operation modeling in open-plan offices",
        "authors": "Farzan Banihashemi, Manuel Weber, Werner Lang",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4508089"
    },
    {
        "id": 979,
        "title": "Enhancing Aircraft Safety through Advanced Engine Health Monitoring with Long Short-Term Memory",
        "authors": "Suleyman Yildirim, Zeeshan A. Rana",
        "published": "2024-1-14",
        "citations": 0,
        "abstract": "Predictive maintenance holds a crucial role in various industries such as the automotive, aviation and factory automation industries when it comes to expensive engine upkeep. Predicting engine maintenance intervals is vital for devising effective business management strategies, enhancing occupational safety and optimising efficiency. To achieve predictive maintenance, engine sensor data are harnessed to assess the wear and tear of engines. In this research, a Long Short-Term Memory (LSTM) architecture was employed to forecast the remaining lifespan of aircraft engines. The LSTM model was evaluated using the NASA Turbofan Engine Corruption Simulation dataset and its performance was benchmarked against alternative methodologies. The results of these applications demonstrated exceptional outcomes, with the LSTM model achieving the highest classification accuracy at 98.916% and the lowest mean average absolute error at 1.284%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s24020518"
    },
    {
        "id": 980,
        "title": "Long Short-Term Memory Network for High-Fidelity Tracking of Greenhouse Gas Emission",
        "authors": "V. Kumar, A. Roy, S. Misra",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "AbstractThis paper investigates the use of machine learning to rapidly predict the solutions of a high-fidelity, complex physics model using a simpler physics model. Two different closed-form solutions of the advection-diffusion partial differential equation (A-D PDE), known as the Gaussian plume model and Gaussian puff model, are typically used to model the atmospheric dispersion of gas emission. The Gaussian puff model is a more complex physics-based model that requires more computational effort to generate the high-fidelity solutions, as compared to the simpler Gaussian plume model that has several assumptions and approximations. An encoder-decoder architecture of Long Short-Term Memory (LSTM) network is trained to predict the solutions of the more complex Gaussian puff model using the solutions of the simpler Gaussian plume model for various leak rate, wind speed, and wind direction. The LSTM model, with 3 LSTM layers with 16 neurons each, efficiently simulated the concentrations of the entire set of 2014 samples in a mere 1.34 minutes. This presents a significant contrast to the traditional software's time-consuming simulation process, which took 14 hours to achieve similar concentration outcomes in this study. The implementation of LSTM network has achieved a computational speed up of 625.15 times.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2118/216003-ms"
    },
    {
        "id": 981,
        "title": "Performance Analysis of Long Short-Term Memory Predictive Neural Networks on Time Series Data",
        "authors": "Roland Bolboacă, Piroska Haller",
        "published": "2023-3-15",
        "citations": 10,
        "abstract": "Long short-term memory neural networks have been proposed as a means of creating accurate models from large time series data originating from various fields. These models can further be utilized for prediction, control, or anomaly-detection algorithms. However, finding the optimal hyperparameters to maximize different performance criteria remains a challenge for both novice and experienced users. Hyperparameter optimization algorithms can often be a resource-intensive and time-consuming task, particularly when the impact of the hyperparameters on the performance of the neural network is not comprehended or known. Teacher forcing denotes a procedure that involves feeding the ground truth output from the previous time-step as input to the current time-step during training, while during testing feeding back the predicted values. This paper presents a comprehensive examination of the impact of hyperparameters on long short-term neural networks, with and without teacher forcing, on prediction performance. The study includes testing long short-term memory neural networks, with two variations of teacher forcing, in two prediction modes, using two configurations (i.e., multi-input single-output and multi-input multi-output) on a well-known chemical process simulation dataset. Furthermore, this paper demonstrates the applicability of a long short-term memory neural network with a modified teacher forcing approach in a process state monitoring system. Over 100,000 experiments were conducted with varying hyperparameters and in multiple neural network operation modes, revealing the direct impact of each tested hyperparameter on the training and testing procedures.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math11061432"
    },
    {
        "id": 982,
        "title": "Long Short Term Memory-based Sentiment Analysis of Healthcare Reviews",
        "authors": "Biswambar Pradhan, Soumya P. Panda",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaihc59020.2023.10431432"
    },
    {
        "id": 983,
        "title": "Digital Twin of Lithium-Ion Batteries for Long Short-Term Memory-Based Temperature Estimation",
        "authors": "Xingchen Zhang, Yujie Wang",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icpe59729.2023.10469605"
    },
    {
        "id": 984,
        "title": "Supporting Learning Information System through Knowledge Management Optimization using Long Short-Term Memory Method",
        "authors": "Ria Rizki Amelia, Doddy Teguh Yuwono",
        "published": "2024-3-12",
        "citations": 0,
        "abstract": "Effective information and knowledge management is vital in many areas, including higher education. The use of artificial intelligence (AI) technology, especially the long short-term memory (LSTM) information system performance patterns in the educational world. This article explores the application of LSTM to optimize knowledge management in colleges, focusing on the prediction of information systems performance. The proposed methods include text classification steps, with measures such as data collection, data pre-processing, word representation, classification, and evaluation. The test results showed that the LSTM model managed to classify reviews labeled positive, neutral, and negative with an accuracy of 33.33%. However, the success of the model was limited by the size of the data set and the pre-processing involved. This research recommends further development with the addition of experimental data, proper preprocessing adjustments, and better hyperparameter identification to improve the accuracy of the prediction results.\r\nKeywords: information management, artificial intelegence, LSTM, text classification, knowledge management, accurate prediction",
        "keywords": "",
        "link": "http://dx.doi.org/10.18502/kss.v9i6.15285"
    },
    {
        "id": 985,
        "title": "Ship Trajectory Prediction Based on Bidirectional Long Short-Term Memory",
        "authors": "Yu Hu, Guoyou Shi",
        "published": "2023-9-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eiecs59936.2023.10435594"
    },
    {
        "id": 986,
        "title": "Classification of Rolling Bearing Fault Based on Long Short Term Memory Neural Network",
        "authors": "Sujit Kumar, D. Ganga",
        "published": "2023-3-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/inocon57975.2023.10101096"
    },
    {
        "id": 987,
        "title": "Applying Long Short-Term Memory Algorithm for Spam  Detection on Ministry Websites",
        "authors": "",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.33168/jsms.2024.0201"
    },
    {
        "id": 988,
        "title": "Music Genre Classification Based on Song Titles with Long Short-Term Memory",
        "authors": "Onur Sahin",
        "published": "2023-2-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sceecs57921.2023.10063028"
    },
    {
        "id": 989,
        "title": "False Comment Detection Based on BERT and Long Short-Term Memory",
        "authors": "Qingyang Chen",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "In the beginning and ending of an article of the rapid development of e-commerce, almost all e-commerce websites support consumers to rate and comment on the workmanship, express delivery, and price of products. Publishing many messages and comments on the network platform has become a popular form of the Internet. Nowadays, online paid Internet platforms are also in the process of continuous evolution. The comments written are more and more authentic and highly misleading. It is a waste of time and easy to be confused to distinguish by the naked eye alone. This article manually annotates a valid dataset containing 4000 snack product reviews and proposes a false review detection model based on Bidirectional Encoder Representation from Transformers (BERT) and Long Short-Term Memory (LSTM). The experimental results show that the accuracy of the BERT and LSTM false comment detection model and BERT false comment detection model is above 50% and effective. The BERT and LSTM model is slightly better than the BERT model regarding loss rate and accuracy. The experiments were scientific and effective, and the data provided by the two experimental models are of the reference value.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/8/20230283"
    },
    {
        "id": 990,
        "title": "Low-Cost Hardware Design Approach for Long Short-Term Memory (LSTM)",
        "authors": "Kasem Khalil, Tamador Mohaidat, Magdy Bayoumi",
        "published": "2023-5-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iscas46773.2023.10182030"
    },
    {
        "id": 991,
        "title": "Rancang Bangun Aplikasi Peramalan Jumlah Penumpang Menggunakan Long Short-Term Memory (LSTM)",
        "authors": "Muhammad Davi, Edi Winarko",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "Public services such as public transportation are closely related to user satisfaction. Busway DKI Jakarta is one of the first public transportation services in Southeast and South Asia. In order to maintain passenger satisfaction, the management of Busway continues to improve services such as adding buses and opening a new line. Opening a new lane or adding buses must necessarily be adjusted also with the increasing number of passengers. So to know the number of passengers in the future, it is necessary to forecast the number of passengers through existing historical data. The historical data used is time series data from January 2015 to January 2016. The method used in forecasting is Long Short-Term Memory (LSTM), one of the machine learning methods. The method is measured in accuracy using Root Mean Squared Error (RMSE) and Mean Absolute Percentage Error (MAPE). As a comparison of LSTM accuracy in forecasting, we also use the Exponential Smoothing method. Based on the results of forecasting, the most and least dominant method of producing RMSE and MAPE is the LSTM method. Only in corridor 3 LSTM can not provide RMSE and MAPE values below baseline values. While corridor 5 LSTM can give better results after the data transformation process by using exponential smoothing. However, overall the LSTM method provides the best accuracy based on the lowest average RMSE and MAPE values, namely RMSE of 2640.53 and MAPE of 9.14%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.35970/infotekmesin.v14i2.1911"
    },
    {
        "id": 992,
        "title": "River Flood Prediction Based on Physics-Informed Long Short-Term Memory Model",
        "authors": "Xiyu Pan, Neda Mohammadi, John E. Taylor",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1061/9780784485279.022"
    },
    {
        "id": 993,
        "title": "Stock Prices Prediction Using Long Short Term Memory",
        "authors": "Nayanika Das, Barnali Goswami, Ritu Nazneen Ara Begum",
        "published": "2023-3-16",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/i3cs58314.2023.10127443"
    },
    {
        "id": 994,
        "title": "Assessing English Language Writing and Readability Skills using Long Short-Term Memory Model",
        "authors": "Ahmad Jaber Mayahi, Emman Naser Alshatti",
        "published": "2023-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cats58046.2023.10424106"
    },
    {
        "id": 995,
        "title": "Exploiting Long Short-term Memory Neural Network for Stock Price Prediction",
        "authors": "Zihui Chen",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "Stock as a high yield, high risk investment has been favored by the public. In order to increase the return on investing in stocks, investors need to predict stock prices. In the past, investors used traditional mathematical methods to make predictions. Now, neural networks are used by investors to predict stocks, which can improve the accuracy of stock forecasting. To further verify the effectiveness of these methods, this work discusses the effects of different network structures and hyperparameters on stock prediction models using short-term memory (LSTM) neural networks. The results show that deeper network layer can get better training effect, but it needs more training time, resulting in a lot of time waste. In addition, this experiment tests the prediction effect under different dropout parameters. The results show that the dropout function should not be too large or too small. Multiple experiments are needed to find an appropriate dropout value.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/8/20230277"
    },
    {
        "id": 996,
        "title": "Power Load Forecasting Model Based Long Short-Term Memory Neural Network",
        "authors": "Yahang Ji, Yufan Shi",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icipca59209.2023.10257954"
    },
    {
        "id": 997,
        "title": "Stock price prediction based on the long short-term memory network",
        "authors": "Suqin Zhang",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "Stock analysis is a challenging task that involves modelling complex and nonlinear dynamics of stock prices and volumes. Long Short-Term Memory (LSTM) is a type of recurrent neural network that can capture long-term dependencies and temporal patterns in time series data. In this paper, a stock analysis method based on LSTM is proposed that can predict future stock prices and transactions using historical data. Yfinance is used to obtain stock data of four technology companies (i.e. Apple, Google, Microsoft, and Amazon) and apply LSTM to extract features and forecast trends. Various techniques are also used such as moving average, correlation analysis, and risk assessment to evaluate the performance and risk of different stocks. When compare the method in this paper with other neural network models such as RNN and GRU, the result show that LSTM achieves better accuracy and stability in stock prediction. This paper demonstrates the effectiveness and applicability of LSTM method through experiments on real-world data sets.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/18/20230958"
    },
    {
        "id": 998,
        "title": "Long-Term Prediction of Multistress Accelerated Aging of Capacitors by Long Short-Term Memory Network",
        "authors": "Hao Liu, Tim Claeys, Davy Pissoort, Guy A. E. Vandenbosch",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tim.2021.3076837"
    },
    {
        "id": 999,
        "title": "Short-term forecasting electricity load by long short-term memory and reinforcement learning for optimization of hyper-parameters",
        "authors": "Ngoc Anh Nguyen, Tien Dat Dang, Elena Verdú, Vijender Kumar Solanki",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s12065-023-00869-5"
    },
    {
        "id": 1000,
        "title": "Short‐term wind power prediction based on combined long short‐term memory",
        "authors": "Yuyang Zhao, Lincong Li, Yingjun Guo, Boming Shi, Hexu Sun",
        "published": "2024-3",
        "citations": 0,
        "abstract": "AbstractWind power is an exceptionally clean source of energy; its rational utilization can fundamentally alleviate the energy, environment, and development problems, especially under the goals of ‘carbon peak’ and ‘carbon neutrality’. A combined short‐term wind power prediction based on long short‐term memory  (LSTM) artificial neural network has been studied aiming at the non‐linearity and volatility of wind energy. Due to the large amount of historical data required to predict the wind power precisely, the ambient temperature and wind speed, direction, and power are selected as model input. The Complete Ensemble Empirical Mode Decomposition with Adaptive Noise has been introduced as data preprocessing to decompose wind power data and reduce the noise. And the Particle Swarm Optimization is conducted to optimize the LSTM network parameters. The combined prediction model with high accuracy for different sampling intervals has been verified by the wind farm data of Chongli Demonstration Project in Hebei Province. The results illustrate that the algorithm can effectively overcome the abnormal data influence and wind power volatility, thereby providing a theoretical reference for precise short‐term wind power prediction.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/gtd2.12996"
    },
    {
        "id": 1001,
        "title": "Short-time Prediction of Image Motion Trajectories Based on Convolutional Long and Short-term Memory Neural Networks",
        "authors": "Junjie Lu, Chenglin Tang",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccasit58768.2023.10351678"
    },
    {
        "id": 1002,
        "title": "EFL learners’ short-term and long-term memory: does learning additional languages matter?",
        "authors": "Rana Zeynali Hamied, Sima Modirkhamene",
        "published": "2024-2-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/14790718.2023.2294955"
    },
    {
        "id": 1003,
        "title": "Classification of comments on social media based on long short-term memory",
        "authors": "Chenyue Qiu",
        "published": "2024-3-29",
        "citations": 0,
        "abstract": "Social media has assumed a pivotal role in contemporary society, significantly enhancing the convenience of daily lives. Nonetheless, the prevalence of toxic comments on social media platforms has led to varying degrees of harm for individuals. The conventional practice of manually categorizing and blocking such toxic comments has proven to be highly inefficient. To address this issue, this study employs artificial intelligence natural language processing technology to classify social media comments, offering a more effective solution.  In the past few years, many algorithms for handling text classification tasks have been introduced and applied in various scenarios. In this work, the author used an LSTM model that can effectively handle long sequence dependency problems to implement text classification. This study achieved an accuracy of 99.4% after training on the Kaggle toxic comments datasets. During the training process, the training accuracy is greater than the validation accuracy while the validation loss is lower than the training loss. After training, the trained model can accurately predict an input sentence and the results are within the expected range.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/54/20241432"
    },
    {
        "id": 1004,
        "title": "Multi-Speaker Diarization using Long-Short Term Memory Network",
        "authors": "Nayyer Aafaq, Usama Qamar, Sohaib Ali Khan, Zeashan Hameed Khan",
        "published": "2023-2-22",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icai58407.2023.10136670"
    },
    {
        "id": 1005,
        "title": "Understanding Long Short-Term Memory LSTM Models  in IBM SPSS Statistics",
        "authors": "",
        "published": "2023-3-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.46632/jitl/2/1/3"
    },
    {
        "id": 1006,
        "title": "Quantitative trading prediction model based on Long Short-Term Memory",
        "authors": "Changfeng Xiao, Fanyi Tang",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3650215.3650336"
    },
    {
        "id": 1007,
        "title": "Well Integrity Operations Experience Transfer Using Long Short-Term Memory (LSTM) Recurrent Neural Network",
        "authors": "David Semwogerere, Alexey Pavlov, Sigbjørn Sangesland",
        "published": "2023-6-11",
        "citations": 0,
        "abstract": "Abstract\nWell integrity is critical throughout the lifecycle of a well. During well operations especially for new fields, inexperienced engineers encounter many well integrity challenges which require a fast-learning curve. This ranges from downhole problems such as lost circulation and kicks to equipment damage due to lack of experience during installation, etc. The success of well integrity as a criterion in wells operations therefore heavily depends in the experience of the humans involved. For offshore operations this lack of experience can translate into very expensive consequences in case of loss of well integrity. Damaged equipment, lost time, injury to personnel and contamination of the environment are some of the consequences of blowouts. In oil and gas well construction and service operations petabytes of data in form of logs, reports and other sensor data are generated which contain vast information. By using machine learning and other statistical data analytic techniques on the data, insights on well integrity can be generated.\nWhile yet most well data analytics focuses more on the numerical indicators of well integrity for example pressure, temperature, and casing thickness, text in well integrity reports gives elaborate description on the nature, context and experience applied in well integrity problems encountered. It’s important to transfer this experience in a faster way to the next well operation without laboring through the unstructured data repositories by using advanced text analysis. This smoothens the learning curve for the engineers, saving costs and improving well integrity.\nIn this paper, a language model for experience transfer using the Long Short-Term Memory (LSTM) recurrent neural network that reads well integrity problem description text from a report and classifies it into a root cause is proposed. It is benchmarked against the state-of the art Bidirectional Encoder Representation from Transformer (BERT) model. The pitfalls of current state of the art language models in processing datasets of oil and gas well operations text are discussed using the Volve end of well reports as an example.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1115/omae2023-108149"
    },
    {
        "id": 1008,
        "title": "Exploring Long Short Term Memory Algorithms for Low Energy Data Aggregation",
        "authors": "Gi Hwan Oh",
        "published": "2024-1-5",
        "citations": 0,
        "abstract": "Long short-term memory methods are employed for data consolidation in intricate low-energy devices. It has enabled accurate and efficient aggregation of statistics in limited electricity settings, facilitating the review and retrieval of data while minimizing electricity wastage. The LSTM rules analyze, organize, and consolidate vast datasets inside weakly connected structures. It has employed a recurrent neural network to handle data processing, particularly nonlinear interactions. The machine's capabilities are subsequently examined and stored utilizing memory blocks. Memory blocks retain extended temporal connections within the data, facilitating adaptive and precise information aggregation. These blocks facilitate the system's ability to shop and utilize relevant capabilities for quick retrieval. The proposed algorithm offers realistic tuning capabilities such as learning rate scheduling and total regularization based on dropout like green information aggregation. These enable systems to reduce over fitting while permitting precise adjustment of the settings. It allows for optimizing the algorithm to provide highly dependable performance within weak structures, enhancing data aggregation techniques' energy efficiency. Standard algorithms provide an efficient, accurate solution for aggregating information in low-power systems. It facilitates evaluating, retrieving, and aggregating accurate and reliable information using memory blocks, adaptive tuning, and efficient learning rate scheduling.",
        "keywords": "",
        "link": "http://dx.doi.org/10.53759/7669/jmc202404008"
    },
    {
        "id": 1009,
        "title": "Retracted: Neural Reversible Steganography with Long Short-Term Memory",
        "authors": "",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9841508"
    },
    {
        "id": 1010,
        "title": "An Improved Long Short-Term Memory Algorithm for Cardiovascular Disease Prediction",
        "authors": "T.K. Revathi, Sathiyabhama Balasubramaniam, Vidhushavarshini Sureshkumar, Seshathiri Dhanasekaran",
        "published": "2024-1-23",
        "citations": 0,
        "abstract": "Cardiovascular diseases, prevalent as leading health concerns, demand early diagnosis for effective risk prevention. Despite numerous diagnostic models, challenges persist in network configuration and performance degradation, impacting model accuracy. In response, this paper introduces the Optimally Configured and Improved Long Short-Term Memory (OCI-LSTM) model as a robust solution. Leveraging the Salp Swarm Algorithm, irrelevant features are systematically eliminated, and the Genetic Algorithm is employed to optimize the LSTM’s network configuration. Validation metrics, including the accuracy, sensitivity, specificity, and F1 score, affirm the model’s efficacy. Comparative analysis with a Deep Neural Network and Deep Belief Network establishes the OCI-LSTM’s superiority, showcasing a notable accuracy increase of 97.11%. These advancements position the OCI-LSTM as a promising model for accurate and efficient early diagnosis of cardiovascular diseases. Future research could explore real-world implementation and further refinement for seamless integration into clinical practice.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/diagnostics14030239"
    },
    {
        "id": 1011,
        "title": "Prediksi Tingkat Kejahatan dengan Metode Long Short Term Memory (Studi Kasus: Kota Makassar)",
        "authors": "Elly Warni",
        "published": "2023-6-9",
        "citations": 0,
        "abstract": "Kota Makassar sebagai pusat dari Provinsi Sulawesi Selatan merupakan surga bagi para pelaku kejahatan. Hal ini berdasarkan tingginya kasus kriminalitas yang terjadi di kota Makassar. Berdasarkan data Kepolisian Resor Kota Besar Makassar angka kriminalitas yang terjadi di Kota Makassar pada tahun 2018 tercatat sebanyak 997 kasus. Angka tersebut menempatkan Makassar peringkat pertama tingkat kriminalitas dibandingkan daerah lainnya di Sulawesi Selatan. Dalam melakukan prediksi digunakan algoritma Long Short Term memory. Adapun parameter yang digunakan yaitu jumlah hidden layer, unit, epoch, batch size, dan learning rate. Didapatkan fungsi pelatihan dengan parameter Unit=64, Epoch=200, Batch size =16, Learning rate =0,001 dengan nilai RMSE 4,74. Dari hasil penelitian lokasi yang memiliki tingkat kriminal tertinggi terdapat pada kecamatan ujung pandang dengan jenis kejahatan yang paling sering terjadi yaitu penganiaayaan.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33395/jmp.v12i1.12522"
    },
    {
        "id": 1012,
        "title": "Attention-based Bi-directional Long and Short Term Memory Networks for Electricity Load Forecasting",
        "authors": "Haoxiang Wang",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsece58870.2023.10263486"
    },
    {
        "id": 1013,
        "title": "A Multi-scalar SPEI Drought Index Prediction Using Long Short-Term Memory",
        "authors": "Ulul Azmiati Auliyah, Andi Sunyoto",
        "published": "2023-11-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icoiact59844.2023.10455932"
    },
    {
        "id": 1014,
        "title": "Predicting Multi-Mode Dynamic Responses of Structures Using Long Short-Term Memory Neural Networks",
        "authors": "Yabin Liao, Aviad Golan, Mark Sensmeier",
        "published": "2023-10-29",
        "citations": 0,
        "abstract": "Abstract\nThis paper reports the progress of a research project of using Long Short-Time Memory (LSTM) deep learning neural networks for modeling structural dynamics of complex structures and predicting the structures’ vibration responses due to random excitation. In a prior study, the feasibility of the approach was investigated. The LSTM networks were applied to the responses of various simulated systems subjected to random excitation loads. While the networks demonstrated promising capabilities of modeling and predicting responses of a single dynamic mode, they exhibited difficulties in modeling responses of multiple modes accurately. To resolve the multi-mode issue, this paper presents an improved approach that converts a multi-mode problem into a set of single-mode problems. The multi-mode responses are separated into individual modal response components. A set of mode-specific sub-LSTM networks are obtained, with each trained by using the original input data and a particular modal response component. These sub-LSTM networks are then combined to yield an equivalent LSTM network to model and predict the multi-mode responses. The proposed multi-mode approach is applied to a tapered, cambered wing structure numerically modeled with finite elements and subjected to a random force excitation. The multi-mode approach shows significant improvement over the original direct approach and yields an excellent match between the actual and predicted responses.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1115/imece2023-112497"
    },
    {
        "id": 1015,
        "title": "Car drag coefficient prediction using long–short term memory neural network and LASSO",
        "authors": "Shengrong Shen, Tian Han, Jiachen Pang",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.measurement.2023.113982"
    },
    {
        "id": 1016,
        "title": "Prediction of Sunspot Activity Cycle Based on Long Short-Term Memory (LSTM) Network Models",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25236/ajcis.2023.061325"
    },
    {
        "id": 1017,
        "title": "Bi-Directional Long Short-Term Memory Network (BiDLSTM) Model Based Air Pollution Prediction",
        "authors": "Gaurav Pandey, Rajneesh Sharma, Amit Kukker",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/incoft60753.2023.10425306"
    },
    {
        "id": 1018,
        "title": "Stock Price Prediction using Long-Short Term Memory and Temporal Convolutional Network",
        "authors": " Caroline, Ronsen Purba, Muhammad Fermi Pasha",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icic60109.2023.10381930"
    },
    {
        "id": 1019,
        "title": "Deep Long-Short Term Memory networks: Stability properties and Experimental validation",
        "authors": "Fabio Bonassi, Alessio La Bella, Giulio Panzani, Marcello Farina, Riccardo Scattolini",
        "published": "2023-6-13",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/ecc57647.2023.10178405"
    },
    {
        "id": 1020,
        "title": "Audio Podcast and Video Practical for Short and Long-Term Memory Student",
        "authors": "Nuki Dhamayanti",
        "published": "2023-2-14",
        "citations": 0,
        "abstract": "Listening items on the Marlins Test are more varied with various nationality accents. Seafarers' listening ability can be improved by listening to different language accents. This research used here is a quasi-experimental research design. The sampling method used for Non-Probability Sampling.  Based on the results of the analysis and discussion, the following conclusions are obtained: there is no significant difference between Using Audio Podcast and Video Practical Training (Students with Short Term and Long-Term Memory) groups; there is no significant difference between Student Short Term Memory – Student Long Term Memory; there is a significant difference between the two Audio Podcast groups (Student Short Term Memory – Student Long Term Memory); there is no significant difference between the two Video Practical Training groups (Student Short Term Memory – Student Long Term Memory). The use of audio podcasts in teaching listening needs to be increased because it is effective for students inside and outside the classroom. The existence of podcasting contributes to helping teaching and learning activities run well. That is because listening comprehension becomes a complex process to understand spoken language in English Foreign Language learners. The use of audio podcasts in achieving listening skills in teaching activities needs to be investigated further. Literature research using the systematic review method to determine the effectiveness of audio podcasts in teaching listening at all levels of students needs to be studied further. The use of audio podcasts in teaching listening needs to be increased because it is effective for students inside and outside the classroom.",
        "keywords": "",
        "link": "http://dx.doi.org/10.26877/eternal.v14i1.14588"
    },
    {
        "id": 1021,
        "title": "Application of Long Short-Term Memory Networks for Natural Gas Demand Prediction",
        "authors": "Nikhil Soni, Pramod Kumar Singh",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cict59886.2023.10455229"
    },
    {
        "id": 1022,
        "title": "Hybrid model based on K-means++ algorithm, optimal similar day approach, and long short-term memory neural network for short-term photovoltaic power prediction",
        "authors": "Ruxue Bai, Yuetao Shi, Meng Yue, Xiaonan Du",
        "published": "2023-4",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.gloei.2023.04.006"
    },
    {
        "id": 1023,
        "title": "Short- and Mid-Term Forecasting of Pan-Arctic Sea Ice Volume Using Variational Mode Decomposition and Bidirectional Long Short-Term Memory",
        "authors": "Aymane Ahajjam, Jaakko Putkonen, Timothy J. Pasch, Xun Zhu",
        "published": "2023-11-29",
        "citations": 0,
        "abstract": "The well-documented decrease in the annual minimum Arctic sea ice extent over the past few decades is an alarming indicator of current climate change. However, much less is known about the thickness of the Arctic sea ice. Developing accurate forecasting models is critical to better predict its changes and monitor the impacts of global warming on the total Arctic sea ice volume (SIV). Significant improvements in forecasting performance are possible with the advances in signal processing and deep learning. Accordingly, here, we set out to utilize the recent advances in machine learning to develop non-physics-based techniques for forecasting the sea ice volume with low computational costs. In particular, this paper aims to provide a step-wise decision process required to develop a more accurate forecasting model over short- and mid-term horizons. This work integrates variational mode decomposition (VMD) and bidirectional long short-term memory (BiLSTM) for multi-input multi-output pan-Arctic SIV forecasting. Different experiments are conducted to identify the impact of several aspects, including multivariate inputs, signal decomposition, and deep learning, on forecasting performance. The empirical results indicate that (i) the proposed hybrid model is consistently effective in time-series processing and forecasting, with average improvements of up to 60% compared with the case of no decomposition and over 40% compared with other deep learning models in both forecasting horizons and seasons; (ii) the optimization of the VMD level is essential for optimal performance; and (iii) the use of the proposed technique with a divide-and-conquer strategy demonstrates superior forecasting performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/geosciences13120370"
    },
    {
        "id": 1024,
        "title": "Demonstration of Synaptic Behaviour in a Spintronic Device for On-Chip Learning in Long Short Term Memory (LSTM) Networks",
        "authors": "Ram Singh Yadav, Pankhuri Gupta, Aniket Sadashiva, Pranaba K. Muduli, Debanjan Bhowmik",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/intermagshortpapers58606.2023.10228682"
    },
    {
        "id": 1025,
        "title": "Production Forecasting in Tight Gas Reservoirs Using Long Short-Term Memory Methods (LSTM)",
        "authors": "Afrah Qoqandi, Omar Alfaleh, Moemen Ramadan, Uchenna Odi",
        "published": "2023-3-7",
        "citations": 0,
        "abstract": "AbstractForecasting the estimated ultimate recovery (EUR) for extremely tight gas sites with long-term transient behaviors is not an easy task. Because older, more established methods used to predict wells with these characteristics have shown important limitations, researchers have relied on new techniques, like long short-term memory (LSTM) deep learning methods. This study assesses the performance of LSTM estimations, compared to that of a physics-based reservoir simulation process.With the goal of obtaining reliable EUR forecasts, unconventional tight gas reservoir data is generated via simulation and analyzed with LSTM deep learning techniques, tailored for sequential data. Simultaneously, a reservoir simulation model that is based on the same data is generated for comparison purposes. The LSTM forecasting model has the added benefit of considering operational interventions in the well, so that the machine learning (ML) framework is not disrupted by interferences that do not reflect the actual physics of the production mechanism on well behavior.The comparison of the data-driven LSTM deep learning model and the physics-based reservoir simulation model estimations was performed using the latter framework as a benchmark. Findings show that the AI-assisted LSTM model provides predictions similarly accurate to the ones estimated by the physics-based reservoir model, but with the added capability for long-term forecasting. These data-driven EUR models show great promise when analyzing unusually tight gas reservoirs that feature time series well information, which can improve estimations about recovery and point engineers towards better decisions regarding the future of reservoirs. Therefore, exploring deep learning methods featuring varying types of artificial neural networks in greater detail has the potential to significantly benefit the oil and gas sector.When compared to other machine learning methods, novel deep learning techniques have advantages that remain underexplored in the literature. This paper helps fill this gap by providing a valuable comparison between older prediction methods and new estimation simulations based on neural networks that can predict long-term behaviors.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2118/213343-ms"
    },
    {
        "id": 1026,
        "title": "PREDIKSI HARGA EMAS DUNIA MENGGUNAKAN METODE LONG-SHORT TERM MEMORY",
        "authors": "Tania Giovani Lasijan, Rukun Santoso, Arief Rachman Hakim",
        "published": "2023-7-28",
        "citations": 0,
        "abstract": "Gold investment is one of the investments that is quite lot of interest by the public and also is considered safer because it has relatively low risk and tends to be stable compared to other investment instruments, especially amid the uncertainty of global economic conditions caused by the COVID-19 pandemic. Awareness about gold price predictions can provide information to people who want to invest in gold so they have higher opportunity to earn profits and minimize the risks obtained. The gold prices prediction method used in this study is Long-Short Term Memory (LSTM) using RStudio. LSTM is one of the method that is widely used to predict time series data. LSTM is a variation of the Recurrent Neural Network (RNN) that is used as a solution to overcome the occurrence of exploding gradient or vanishing gradient in RNN when processing long sequential data. The best LSTM model in this study for predicting gold prices is  the model with MAPE value 2,70601, which is a model with a training data and testing data comparison 70% : 30% and hyperparameters batch size 1, units 1, AdaGrad optimizer, and learning rate 0,1 with 500 epochs.",
        "keywords": "",
        "link": "http://dx.doi.org/10.14710/j.gauss.12.2.287-295"
    },
    {
        "id": 1027,
        "title": "Bearing Fault Diagnosis Based on Wide Deep Convolutional Neural Network and Long Short Term Memory",
        "authors": "",
        "published": "2023-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17559/tv-20220512135354"
    },
    {
        "id": 1028,
        "title": "Sparse Signal Recovery through Long Short-Term Memory Networks for Compressive Sensing-Based Speech Enhancement",
        "authors": "Vasundhara Shukla, Preety D. Swami",
        "published": "2023-7-17",
        "citations": 1,
        "abstract": "This paper presents a novel speech enhancement approach based on compressive sensing (CS) which uses long short-term memory (LSTM) networks for the simultaneous recovery and enhancement of the compressed speech signals. The advantage of this algorithm is that it does not require an iterative process to recover the compressed signals, which makes the recovery process fast and straight forward. Furthermore, the proposed approach does not require prior knowledge of signal and noise statistical properties for sensing matrix optimization because the used LSTM can directly extract and learn the required information from the training data. The proposed technique is evaluated against white, babble, and f-16 noises. To validate the effectiveness of the proposed approach, perceptual evaluation of speech quality (PESQ), short-time objective intelligibility (STOI), and signal-to-distortion ratio (SDR) were compared to other variants of OMP-based CS algorithms The experimental outcomes show that the proposed approach achieves the maximum improvements of 50.06%, 43.65%, and 374.16% for PESQ, STOI, and SDR respectively, over the different variants of OMP-based CS algorithms.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12143097"
    },
    {
        "id": 1029,
        "title": "Long Short Term Memory Based Sign Language Detection System",
        "authors": "Ahaan Shah, Keyaan Shah, Vinay Vishwakarma",
        "published": "2023-11-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icrais59684.2023.10367076"
    },
    {
        "id": 1030,
        "title": "Predicting Style Factor Returns and Group/sector Returns Using Long and Short-term Memory ('LSTM') Deep Learning Neural Networks",
        "authors": "Sanele Makamo",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4542403"
    },
    {
        "id": 1031,
        "title": "Early Detection of Rolling Bearing Faults Using Long Short-Term Memory",
        "authors": "Nam Du Nguyen Hoang, Khang Huynh, Kjell G.Robbersmyr",
        "published": "2023-5-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccri58865.2023.00016"
    },
    {
        "id": 1032,
        "title": "Retracted: Evolving Long Short-Term Memory Network-Based Text Classification",
        "authors": "",
        "published": "2023-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9827632"
    },
    {
        "id": 1033,
        "title": "Modelling of a Non-Linear Dynamic System Using Long Short-Term Memory",
        "authors": "Richa Sahu, Smriti Srivastava, Rajesh Kumar",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccis60361.2023.10425027"
    },
    {
        "id": 1034,
        "title": "Predicting climate change using an autoregressive long short-term memory model",
        "authors": "Seokhyun Chin, Victoria Lloyd",
        "published": "2024-1-23",
        "citations": 0,
        "abstract": "Climate change is a pressing global issue. Mathematical models and global climate models have traditionally been invaluable tools in understanding the Earth’s climate system, however there are several limitations. Researchers are increasingly integrating machine learning techniques into environmental science related to time-series data; however, its application in the context of climate predictions remains open. This study develops a baseline machine learning model based on an autoregressive recurrent neural network with a long short-term memory implementation to predict the climate. The data were retrieved from the ensemble-mean version of the ERA5 dataset. The model developed in this study could predict the general trends of the Earth when used to predict both the climate and weather. When predicting climate, the model could achieve reasonable accuracy for a long period, with the ability to predict seasonal patterns, which is a feature that other researchers could not achieve with the complex reanalysis data utilized in this study. This study demonstrates that machine learning models can be utilized in a climate forecasting approach as a viable alternative to mathematical models and can be utilized to supplement current work that is mostly successful in short-term predictions.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fenvs.2024.1301343"
    },
    {
        "id": 1035,
        "title": "Long Short-Term Memory for Discharge Estimation in Coastal Neretva River",
        "authors": "Anna Maria Mihel, Nino Krvavica, Jonatan Lerga",
        "published": "2023-6-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/splitech58164.2023.10193648"
    },
    {
        "id": 1036,
        "title": "Forecasting salmon market volatility using long short-term memory (LSTM)",
        "authors": "Mikaella Zitti",
        "published": "2023-9-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/13657305.2023.2255346"
    },
    {
        "id": 1037,
        "title": "LQ45 stock prediction optimization based on long short-term memory",
        "authors": "Syakur Syakur, Mustafid Mustafid, Kusworo Adi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0141902"
    },
    {
        "id": 1038,
        "title": "A Sequence-to-Sequence Text Summarization Using Long Short-Term Memory Based Neural Approach",
        "authors": "",
        "published": "2023-2-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.22266/ijies2023.0430.12"
    },
    {
        "id": 1039,
        "title": "Spatiotemporal convolutional long short-term memory for regional streamflow predictions",
        "authors": "Abdalla Mohammed, Gerald Corzo",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jenvman.2023.119585"
    },
    {
        "id": 1040,
        "title": "Prediction of Gait Speed from Acceleration Based on Long Short-Term Memory",
        "authors": "Shuhei Kambashi, Jun Inoue",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smc53992.2023.10393976"
    },
    {
        "id": 1041,
        "title": "Sentiment analysis based on long short-term memory model",
        "authors": "Jiahao Deng, Qing Wang, Zi Ye",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "An important area of natural language processing is text emotion analysis. Emotion analysis is a very meaningful research work and has a broad application prospect, such as social media monitoring, reputation research of commodity brands, market research, and so on. By analyzing the time and content factors of the data, considering the final application scenario, and finally comparing the advantages and disadvantages of the methods, There are three main techniques for analyzing emotions in text: emotion analysis using an emotion dictionary, emotion analysis using machine learning, and emotion analysis using deep learning. Among them, Convolutional neural networks (CNN), recurrent neural networks (RNN), and long short-term memory networks (LSTM) are examples of deep learning-based techniques. For processing temporal relate issues such as video, speech, and text, CNN algorithms often consume a large amount of computational time, especially for processing image datasets, which may encounter specific problems. To address this issue, RNN is more suitable for solving temporal related issues such as video, voice, and text. In natural language, word order is an extremely important feature. RNN may potentially process sequences of any length, add memory units based on the original neural network, handle pre- and post-word dependencies, and process sequences of any length. The main work is as follows: LSTM adds or deletes unit states through a structure called gate, Determine the experimental thinking of text analysis, Crawl and train data sets through AI Studio, pycharm and other tools.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/39/20230583"
    },
    {
        "id": 1042,
        "title": "A Bidirectional Long Short-Term Memory Autoencoder Transformer for Remaining Useful Life Estimation",
        "authors": "Zhengyang Fan, Wanru Li, Kuo-Chu Chang",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "Estimating the remaining useful life (RUL) of aircraft engines holds a pivotal role in enhancing safety, optimizing operations, and promoting sustainability, thus being a crucial component of modern aviation management. Precise RUL predictions offer valuable insights into an engine’s condition, enabling informed decisions regarding maintenance and crew scheduling. In this context, we propose a novel RUL prediction approach in this paper, harnessing the power of bi-directional LSTM and Transformer architectures, known for their success in sequence modeling, such as natural languages. We adopt the encoder part of the full Transformer as the backbone of our framework, integrating it with a self-supervised denoising autoencoder that utilizes bidirectional LSTM for improved feature extraction. Within our framework, a sequence of multivariate time-series sensor measurements serves as the input, initially processed by the bidirectional LSTM autoencoder to extract essential features. Subsequently, these feature values are fed into our Transformer encoder backbone for RUL prediction. Notably, our approach simultaneously trains the autoencoder and Transformer encoder, different from the naive sequential training method. Through a series of numerical experiments carried out on the C-MAPSS datasets, we demonstrate that the efficacy of our proposed models either surpasses or stands on par with that of other existing methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math11244972"
    },
    {
        "id": 1043,
        "title": "Hyperparameter Optimization of Long Short Term Memory Models for Interpretable Electrical Fault Classification",
        "authors": "Biju G. M., G. N. Pillai",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3330056"
    },
    {
        "id": 1044,
        "title": "Reservoir parameters prediction based on spatially transferred long short-term memory network",
        "authors": "Wancheng Huang, Yuan Tian",
        "published": "2024-1-30",
        "citations": 0,
        "abstract": "Reservoir reconstruction, where parameter prediction plays a key role, constitutes an extremely important part in oil and gas reservoir exploration. With the mature development of artificial intelligence, parameter prediction methods are gradually shifting from previous petrophysical models to deep learning models, which bring about obvious improvements in terms of accuracy and efficiency. However, it is difficult to achieve large amount of data acquisition required for deep learning due to the cost of detection, technical difficulties, and the limitations of complex geological parameters. To address the data shortage problem, a transfer learning prediction model based on long short-term memory neural networks has been proposed, and the model structure has been determined by parameter search and optimization methods in this paper. The proposed approach transfers knowledge from historical data to enhance new well prediction by sharing some parameters in the neural network structure. Moreover, the practicality and effectiveness of this method was tested by comparison based on two block datasets. The results showed that this method could significantly improve the prediction accuracy of the reservoir parameters in the event of data shortage.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1371/journal.pone.0296506"
    },
    {
        "id": 1045,
        "title": "Reliable routing in MANET with mobility prediction via long short-term memory",
        "authors": "Manjula A. Biradar, Sujata Mallapure",
        "published": "2023-11-29",
        "citations": 0,
        "abstract": "A MANET consists of a self-configured group of transportable mobile nodes that lacks a central infrastructure to manage network traffic. To facilitate communication, govern route discovery, and manage resources, all moving nodes in multi-hop wireless networks (MANETs) work together. These networks struggle with dependability, energy consumption, and collision avoidance. The goal of this research project is to establish a new, dependable MANET routing model, where the selection of predictor nodes comes first. For selecting predictor nodes based on factors like distance, security (risk), Receiver Signal Strength Indicator (RSSI), Packet Delivery Ratio (PDR), and energy, the adaptive weighted clustering algorithm (AWCA) is used in this case. Using the Interfused Slime and Battle Royale Optimization with Arithmetic Crossover (IS&BRO–AC) model, the node with the lower weight is selected as the Cluster Head (CH). Additionally, mobility prediction is carried out, in which the node mobility is forecast using Improved Long Short Term Memory (LSTM) while taking distance and Receiver Signal Strength Indicator (RSSI) into account. Based on the forecast, trustworthy data transfer is implemented, ensuring more accurate and dependable MANET routing. The examination of RSSI, PDR, and other metrics is completed at the end.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/web-220110"
    },
    {
        "id": 1046,
        "title": "Long short-term memory models to quantify long-term evolution of streamflow discharge and groundwater depth in Alabama",
        "authors": "Hossein Gholizadeh, Yong Zhang, Jonathan Frame, Xiufen Gu, Christopher T. Green",
        "published": "2023-11",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.scitotenv.2023.165884"
    },
    {
        "id": 1047,
        "title": "A Short-Term Prediction Model of Wind Power with Outliers: An Integration of Long Short-Term Memory, Ensemble Empirical Mode Decomposition, and Sample Entropy",
        "authors": "Yuanzhuo Du, Kun Zhang, Qianzhi Shao, Zhe Chen",
        "published": "2023-4-6",
        "citations": 1,
        "abstract": "Wind power generation is a type of renewable energy that has the advantages of being pollution-free and having a wide distribution. Due to the non-stationary characteristics of wind power caused by atmospheric chaos and the existence of outliers, the prediction effect of wind power needs to be improved. Therefore, this study proposes a novel hybrid prediction method that includes data correlation analyses, power decomposition and reconstruction, and novel prediction models. The Pearson correlation coefficient is used in the model to analyze the effects between meteorological information and power. Furthermore, the power is decomposed into different sub-models by ensemble empirical mode decomposition. Sample entropy extracts the correlations among the different sub-models. Meanwhile, a long short-term memory model with an asymmetric error loss function is constructed considering outliers in the power data. Wind power is obtained by stacking the predicted values of subsequences. In the analysis, compared with other methods, the proposed method shows good performance in all cases.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/su15076285"
    },
    {
        "id": 1048,
        "title": "Refining Short-Term Power Load Forecasting: An Optimized Model with Long Short-Term Memory Network",
        "authors": "Sile Hu, Wenbin Cai, Jun Liu, Hao Shi, Jiawei Yu",
        "published": "2024-4-4",
        "citations": 0,
        "abstract": "Short-term power load forecasting involves the stable operation and optimal scheduling of the power system. Accurate load forecasting can improve the safety and economy of the power grid. Therefore, how to predict power load quickly and accurately has become one of the urgent problems to be solved. Based on the optimization parameter selection and data preprocessing of the improved Long Short-Term Memory Network, the study first integrated particle swarm optimization algorithm to achieve parameter optimization. Then, combined with convolutional neural network, the power load data were processed to optimize the data and reduce noise, thereby enhancing model performance. Finally, simulation experiments were conducted. The PSO-CNN-LSTM model was tested on the GEFC dataset and demonstrated stability of up to 90%. This was 22% higher than the competing CNN-LSTM model and at least 30% higher than the LSTM model. The PSO-CNN-LSTM model was trained with a step size of 1.9×10^4, the relative mean square error was 0.2345×10^-4. However, when the CNN-LSTM and LSTM models were trained for more than 2.0×10^4 steps, they still did not achieve the target effect. In addition, the fitting error of the PSOCNN-LSTM model in the GEFC dataset was less than 1.0×10^-7. In power load forecasting, the PSOCNN- LSTM model's predicted results had an average absolute error of less than 1.0% when compared to actual data. This was an improvement of at least 0.8% compared to the average absolute error of the CNNLSTM prediction model. These experiments confirmed that the prediction model that combined two methods had further improved the speed and accuracy of power load prediction compared to traditional prediction models, providing more guarantees for safe and stable operation of the power system.",
        "keywords": "",
        "link": "http://dx.doi.org/10.20532/cit.2023.1005730"
    },
    {
        "id": 1049,
        "title": "PI-LSTM: Physics-informed long short-term memory network for structural response modeling",
        "authors": "Fangyu Liu, Junlin Li, Linbing Wang",
        "published": "2023-10",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.engstruct.2023.116500"
    },
    {
        "id": 1050,
        "title": "Healthy food chatbot application using long short term memory",
        "authors": "Fifi Kumalasari, Viny Christanti Mawardi, Janson Hendryli",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0126927"
    },
    {
        "id": 1051,
        "title": "Speech Emotion Recognition using Long Short-Term Memory Models and Grey Wolf Optimization",
        "authors": "Suryakant Tyagi, Sándor Szénási",
        "published": "2023-9-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sisy60376.2023.10417879"
    },
    {
        "id": 1052,
        "title": "Intraday Stock Trading Strategy Based on Analysis Using Bidirectional Long Short-Term Memory Networks",
        "authors": "Phurinut Pholsri, Pittipol Kantavat",
        "published": "2023-5-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaibd57115.2023.10206361"
    },
    {
        "id": 1053,
        "title": "An improved long short term memory network for intrusion detection",
        "authors": "Asmaa Ahmed Awad, Ahmed Fouad Ali, Tarek Gaber",
        "published": "2023-8-1",
        "citations": 3,
        "abstract": "Over the years, intrusion detection system has played a crucial role in network security by discovering attacks from network traffics and generating an alarm signal to be sent to the security team. Machine learning methods, e.g., Support Vector Machine, K Nearest Neighbour, have been used in building intrusion detection systems but such systems still suffer from low accuracy and high false alarm rate. Deep learning models (e.g., Long Short-Term Memory, LSTM) have been employed in designing intrusion detection systems to address this issue. However, LSTM needs a high number of iterations to achieve high performance. In this paper, a novel, and improved version of the Long Short-Term Memory (ILSTM) algorithm was proposed. The ILSTM is based on the novel integration of the chaotic butterfly optimization algorithm (CBOA) and particle swarm optimization (PSO) to improve the accuracy of the LSTM algorithm. The ILSTM was then used to build an efficient intrusion detection system for binary and multi-class classification cases. The proposed algorithm has two phases: phase one involves training a conventional LSTM network to get initial weights, and phase two involves using the hybrid swarm algorithms, CBOA and PSO, to optimize the weights of LSTM to improve the accuracy. The performance of ILSTM and the intrusion detection system were evaluated using two public datasets (NSL-KDD dataset and LITNET-2020) under nine performance metrics. The results showed that the proposed ILSTM algorithm outperformed the original LSTM and other related deep-learning algorithms regarding accuracy and precision. The ILSTM achieved an accuracy of 93.09% and a precision of 96.86% while LSTM gave an accuracy of 82.74% and a precision of 76.49%. Also, the ILSTM performed better than LSTM in both datasets. In addition, the statistical analysis showed that ILSTM is more statistically significant than LSTM. Further, the proposed ISTLM gave better results of multiclassification of intrusion types such as DoS, Prob, and U2R attacks.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1371/journal.pone.0284795"
    },
    {
        "id": 1054,
        "title": "Earthquake Prediction using Long Short Term Memory on Spatio-Temporally Segmented Data",
        "authors": "Ankit Sonthalia, Sumanta Pasari, Sonu Devi",
        "published": "2023-2-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icais56108.2023.10073687"
    },
    {
        "id": 1055,
        "title": "Short-term wind speed forecasting using an optimized three-phase convolutional neural network fused with bidirectional long short-term memory network model",
        "authors": "Lionel P. Joseph, Ravinesh C. Deo, David Casillas-Pérez, Ramendra Prasad, Nawin Raj, Sancho Salcedo-Sanz",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.apenergy.2024.122624"
    },
    {
        "id": 1056,
        "title": "Daily Solar Radiation Forecasting for Northwest Nigeria Using Long Short-Term Memory",
        "authors": "Muhammad Isma’il, Salisu Aliyu",
        "published": "2023-3-31",
        "citations": 0,
        "abstract": "In order to ensure energy security and environmental sustainability, transition to renewable energy sources is required. One of the most viable and sustainable renewable energy sources is solar. However, developing solar energy systems requires solar radiation data which is scarce for most locations including Northwest Nigeria. In order to address this challenge, solar radiation is usually estimated from the available meteorological parameters. Several previous studies have used various methods including geospatial techniques and machine learning to predict monthly and yearly solar radiation, while few studies have focused on the estimation of daily solar radiation. Meanwhile, providing daily solar radiation data is necessary for the development of solar energy systems. Deep learning has been shown to be effective in solar radiation forecasting. To evaluate the performance of the deep learning method for daily solar radiation prediction, a Long Short-Term Memory (LSTM) based deep learning model was developed in this study. The forecasting model was created using daily solar radiation data collected over a 21-year period by the Nigerian Meteorological Agency in three major towns in North West Nigeria: Kano, Kaduna, and Katsina. The model was evaluated using two statistical indicators: coefficient of determination (R2) and Root Mean Square Error (RMSE). Results showed that R2 of 0.79 and 0.78 were obtained for the training and testing datasets respectively, while RMSE of 0.46 and 0.47 were obtained for the training and testing datasets respectively. Overall, the LSTM deep learning model has been proven to be effective in forecasting daily solar radiation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.57233/ijsgs.v9i1.407"
    },
    {
        "id": 1057,
        "title": "Advertisement design in dynamic interactive scenarios using DeepFM and long short-term memory (LSTM)",
        "authors": "Lingling Zeng, Muhammad Asif",
        "published": "2024-3-27",
        "citations": 0,
        "abstract": "This article addresses the evolving landscape of data advertising within network-based new media, seeking to mitigate the accuracy limitations prevalent in traditional film and television advertising evaluations. To overcome these challenges, a novel data-driven nonlinear dynamic neural network planning approach is proposed. Its primary objective is to augment the real-time evaluation precision and accuracy of film and television advertising in the dynamic interactive realm of network media. The methodology primarily revolves around formulating a design model for visual advertising in film and television, customized for the dynamic interactive milieu of network media. Leveraging DeepFM+long short-term memory (LSTM) modules in deep learning neural networks, the article embarks on constructing a comprehensive information statistics and data interest model derived from two public datasets. It further engages in feature engineering for visual advertising, crafting self-learning association rules that guide the data-driven design process and system flow. The article concludes by benchmarking the proposed visual neural network model against other models, using F1 and root mean square error (RMSE) metrics for evaluation. The findings affirm that the proposed model, capable of handling dynamic interactions among images, visual text, and more, excels in capturing nonlinear and feature-mining aspects. It exhibits commendable robustness and generalization capabilities within various contexts.",
        "keywords": "",
        "link": "http://dx.doi.org/10.7717/peerj-cs.1937"
    },
    {
        "id": 1058,
        "title": "An Aspect-Based Sentiment Analysis Model to Classify the Sentiment of Twitter Data using Long-Short Term Memory Classifier",
        "authors": "Rakshitha Prabhu,  , Chandrashekara Seesandra Nashappa",
        "published": "2024-1-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17485/ijst/v17i2.2715"
    },
    {
        "id": 1059,
        "title": "Konfigurasi Hyperparameter Long Short Term Memory untuk Optimalisasi Prediksi Penjualan",
        "authors": "Ali Khumaidi, Dhistianti Mei Rahmawan Tari, Nuke L. Chusna",
        "published": "2023-1-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.30998/faktorexacta.v15i4.15286"
    },
    {
        "id": 1060,
        "title": "Forecasting JPFA Share Price using Long Short Term Memory Neural Network",
        "authors": "I Ketut Agung Enriko, Fikri Nizar Gustiyana, Hedi Krishna",
        "published": "2023-3-10",
        "citations": 0,
        "abstract": "To invest or buy and sell on the stock exchange requires understanding in the field of data analysis. The movement of the curve in the stock market is very dynamic, so it requires data modeling to predict stock prices in order to get prices with a high degree of accuracy. Machine Learning currently has a good level of accuracy in processing and predicting data. In this study, we modeled data using the Long-Short Term Memory (LSTM) algorithm to predict the stock price of a company called Japfa Comfeed. The main objective of this journal is to analyze the level of accuracy of Machine Learning algorithms in predicting stock price data and to analyze the number of epochs in forming an optimal model. The results of our research show that the LSTM algorithm has a good level of accurate prediction shown in mape values and the data model obtained on variations in epochs values. All optimization models show that the higher the epoch value, the lower the loss value. Adam's Optimization Model is the model with the highest accuracy value of 98.44%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.32497/jaict.v8i1.4285"
    },
    {
        "id": 1061,
        "title": "Weather Prediction using Long Short Term Memory (LSTM) model",
        "authors": "Koduru Nitesh, Yanamala Abhiram, Rayapudi Krishna Teja, S. Kavitha",
        "published": "2023-1-23",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icssit55814.2023.10061039"
    },
    {
        "id": 1062,
        "title": "Pengujian Long-Short Term Memory (LSTM) Pada Prediksi Trafik Lalu Lintas Menggunakan Multi Server",
        "authors": "Riesa Krisna Astuti Sakir",
        "published": "2023-5-30",
        "citations": 0,
        "abstract": "This study presents a test of the long short term memory (LSTM) algorithm on traffic prediction with multi edge server and cloud server architectures. IoT sensors located on the roadside such as cameras and location data on each driver are used and stored in the data center. When a driver sends a travel time request to a nearby edge server, traffic predictions will be made on the edge server or cloud server. Server selection is made based on the destination location of the driver's request. If the destination is in the edge server area, traffic predictions are made on the edge server. However, if the destination is in the cloud server area, traffic predictions are made on the cloud server. Then to predict traffic traffic is done with LSTM. following modeling is made with a density of 128 and a density of 256. By learning from previous traffic, LSTM with a greater density gets a proportion of errors, namely RMSE 10.78%, MAE 8.24%, and MAPE 19.87%. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.31963/elekterika.v20i1.4242"
    },
    {
        "id": 1063,
        "title": "Research on Stock History Data Mining and Prediction Algorithm Based on Long Short-Term Memory Network",
        "authors": "Zhuo Lu",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmnwc60182.2023.10435794"
    },
    {
        "id": 1064,
        "title": "Using Long Short-Term Memory (LSTM) networks with the toy model concept for compressible pulsatile flow metering",
        "authors": "Indranil Brahma",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.measurement.2023.113782"
    },
    {
        "id": 1065,
        "title": "Research on the Construction of New Media Social Culture Based on Long Short-term Memory",
        "authors": "Yuanyuan Sun, Wei Zhang",
        "published": "2023-1-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14733/cadaps.2023.s7.186-197"
    },
    {
        "id": 1066,
        "title": "IoT Network Intrusion Detection Using Long Short-Term Memory Recurrent Neural Network",
        "authors": "Yee Mon Thant, Mie Mie Su Thwin, Chaw Su Htwe",
        "published": "2023-2-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icca51723.2023.10182005"
    },
    {
        "id": 1067,
        "title": "Long-Short Term Memory Based Stock Market Analysis",
        "authors": "Shounak Choudhury, Saptarshee Basak, Saumik Roy, Amit Kumar Das",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iementech60402.2023.10423465"
    },
    {
        "id": 1068,
        "title": "Analisis Sentimen Terhadap Kenaikan Harga Bahan Bakar Minyak Menggunakan Long Short-Term Memory",
        "authors": "Muhammad Ikhsan",
        "published": "2023-2-11",
        "citations": 0,
        "abstract": "Pada tahun 2022 terjadi kenaikan harga bahan bakar minyak dunia. Dengan naiknya harga bahan bakar minyak ini secara tidak langsung akan berpengaruh terhadap harga material, inflasi, dan biaya hidup. Kenaikan harga bahan bakar minyak menjadi kontroversi hingga terjadi demo di berbagai wilayah. Kebijakan dinaikan harga bahan bakar minyak ini mendapat berbagai respons dari pengguna Twitter. Penelitian ini bertujuan untuk mengetahui akurasi prediksi dan pola sentimen model LSTM (Long Short-Term Memory) dari opini pengguna Twitter terhadap topik kenaikan harga bahan bakar minyak pada bulan Juli 2022. Data yang digunakan adalah data berbahasa English dengan dua kelas sentimen yaitu negative dan positive. Model LSTM dilakukan percobaan sebanyak lima kali. Hasil penelitian ini menunjukan bahwa akurasi tertinggi terdapat pada percobaan ke-1 dan ke-3 yaitu 90% dan pola sentimen cenderung positif.",
        "keywords": "",
        "link": "http://dx.doi.org/10.59095/ijcsr.v2i1.29"
    },
    {
        "id": 1069,
        "title": "Annual changes of Neohelice granulata cognitive abilities indicate opposition between short- and long-term memory retention",
        "authors": "Rosso Anahi, Freudenthal Ramiro",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.isci.2023.108161"
    },
    {
        "id": 1070,
        "title": "Convolutional Long Short-Term Memory Two-Dimensional Bidirectional Graph Convolutional Network for Taxi Demand Prediction",
        "authors": "Yibo Cao, Lu Liu, Yuhan Dong",
        "published": "2023-5-11",
        "citations": 6,
        "abstract": "With the rise of the online ride-hailing market, taxi demand prediction has received more and more research interest in intelligent transportation. However, most traditional research methods mainly focused on the demand based on the original point and ignored the intention of the passenger’s destination. At the same time, many forecasting methods need sufficient investigation and data processing, which undoubtedly increases the complexity and operability of forecasting problems. Therefore, we regard the current taxi demand prediction as an origin–destination problem in order to provide more accurate predictions for the taxi demand problem. By combining a spatial network based on graph convolutional network (GCN) and a temporal network of convolutional long short-term memory (Conv-LSTM), we propose a new spatial-temporal model of Conv-LSTM two-dimensional bidirectional GCN (CTBGCN) to uncover the potential correlation between origin and destination. We utilize the temporal network for effective temporal information and the spatial network of multi-layers to get the implicit origin–destination correlation. Numerical results suggest that the proposed method outperforms the state-of-the-art baseline and other traditional methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/su15107903"
    },
    {
        "id": 1071,
        "title": "ROBOT TASK RECOGNITION USING DEEP CONVOLUTIONAL LONG SHORT-TERM MEMORY, 106-113. SI",
        "authors": "M. S. Midhun, James Kurian",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2316/j.2023.201-0353"
    },
    {
        "id": 1072,
        "title": "A Dual Long Short-Term Memory Model in Forecasting the Number of COVID-19 Infections",
        "authors": "Jung-Pin Lai, Ping-Feng Pai",
        "published": "2023-2-2",
        "citations": 0,
        "abstract": "Since the outbreak of the Coronavirus Disease 2019 (COVID-19), the spread of the epidemic has been a major international public health issue. Hence, various forecasting models have been used to predict the infectious spread of the disease. In general, forecasting problems often involve prediction accuracy decreasing as the horizon increases. Thus, to extend the forecasting horizon without decreasing performance or prediction, this study developed a Dual Long Short-Term Memory (LSTM) with Genetic Algorithms (DULSTMGA) model. The model employed predicted values generated by LSTM models in short-forecasting horizons as inputs for the long-term prediction of LSTM in a rolling manner. Genetic algorithms were applied to determine the parameters of LSTM models, allowing long-term forecasting accuracy to increase as long as short-term forecasting was accurate. In addition, the compartment model was utilized to simulate the state of COVID-19 and generate numbers of infectious cases. Infectious cases in three countries were employed to examine the feasibility and performance of the proposed DULSTMGA model. Numerical results indicated that the DULSTMGA model could obtain satisfactory forecasting accuracy and was superior to many previous studies in terms of the mean absolute percentage error. Therefore, the designed DULSTMGA model is a feasible and promising alternative for forecasting the number of infectious COVID-19 cases.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12030759"
    },
    {
        "id": 1073,
        "title": "Fault Detection and Diagnosis of Air-Conditioning System using  Long Short-Term Memory Recurrent Neural Network",
        "authors": "Noor SULAIMAN",
        "published": "2023-9-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.15199/48.2023.09.21"
    },
    {
        "id": 1074,
        "title": "Predicting Perceptual Centers Located at Vowel Onset in German Speech Using Long Short-Term Memory Networks",
        "authors": "Felicia Schulz, Mirella De Sisto, M. Paula Roncaglia-Denissen, Peter Hendrix",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-2154"
    },
    {
        "id": 1075,
        "title": "Prediction of Organic Chemical Reactions Using Cyclical Learning Rate Based Long-Short Term Memory",
        "authors": "Ping Lv, Yuan Zhang",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmnwc60182.2023.10435783"
    },
    {
        "id": 1076,
        "title": "Long Short-Term Memory Networks for Email Spam Classification",
        "authors": "V.Sri Vinitha, D. Karthika Renuka, L. Ashok Kumar",
        "published": "2023-2-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciscois56541.2023.10100445"
    },
    {
        "id": 1077,
        "title": "Sentiment Analysis Using Deep Neural Network 1D Convolutional with Long Short Term Memory",
        "authors": "Ashutosh Badal, Mahesh Parmar",
        "published": "2023-4-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceeict56924.2023.10157420"
    },
    {
        "id": 1078,
        "title": "Movie sentiment analysis based on Long Short-Term Memory Network",
        "authors": "Siyao Li, Rui Qin, Zijian Zhou",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": "An important task in the study of Natural Language Processing (NLP) is the analysis of movie reviews. It finishes the task of classifying movie review texts into sentiment, such as positive, negative or neutral sentiment. Previous works mainly follow the pipeline of LSTM (Long Short-Term Memory Network). The network model is a variant of Recurrent Neural Network (RNN) and particularly suitable for processing natural language texts. Though existing LSTM-based works have improved the performance significantly, we argue that most of them deal with the problem of analyzing the sentiment of movie reviews while ignore analyze the model performance in different application scenarios, such as different lengths of the reviews and the frequency of sentiment adverbs in the reviews. To alleviate the above issue, in this paper, we constructed a simple LSTM model containing an embedding layer, a batch normalization layer, a dropout layer, a one-dimensional convolutional layer, a maximal pooling layer, a bi-directional LSTM layer and a fully connected layer. We used the existing IMDB movie review dataset to train the model, and  selected two research scenarios of movie review length and frequency of occurrence of sentiment adverbs to test the model, respectively. From the experimental results, we proposed a model for the scenarios in which the LSTM model handles the problem of sentiment analysis with respect to the dataset construction, model stability and generalization ability, text fragment processing, data preprocessing and feature extraction, model optimization and improvement.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/38/20230524"
    },
    {
        "id": 1079,
        "title": "Predicting Stock Market Movements Using Long Short-Term Memory (LSTM)",
        "authors": "Achmad Fauzan, Maria SusanAnggreainy, Nicholas Nathaniel, Afdhal Kurniawan",
        "published": "2023-9-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aidas60501.2023.10284713"
    },
    {
        "id": 1080,
        "title": "Interaction and psychological characteristics of art teaching based on Openpose and Long Short-Term Memory network",
        "authors": "Chen Qi",
        "published": "2023-3-21",
        "citations": 1,
        "abstract": "As living standards improve, people’s demand for appreciation and learning of art is growing gradually. Unlike the traditional learning model, art teaching requires a specific understanding of learners’ psychology and controlling what they have learned so that they can create new ideas. This article combines the current deep learning technology with heart rate to complete the action recognition of art dance teaching. The video data processing and recognition are conducted through the Openpose network and graph convolution network. The heart rate data recognition is completed through the Long Short-Term Memory (LSTM) network. The optimal recognition model is established through the data fusion of the two decision levels through the adaptive weight analysis method. The experimental results show that the accuracy of the classification fusion model is better than that of the single-mode recognition method, which is improved from 85.0% to 97.5%. The proposed method can evaluate the heart rate while ensuring high accuracy recognition. The proposed research can help analyze dance teaching and provide a new idea for future combined research on teaching interaction.",
        "keywords": "",
        "link": "http://dx.doi.org/10.7717/peerj-cs.1285"
    },
    {
        "id": 1081,
        "title": "Attention-based convolutional neural network-long short-term memory network wind power forecasting",
        "authors": "Limin Zhou, Renxiang Lu",
        "published": "2023-9-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/neessc59976.2023.10349338"
    },
    {
        "id": 1082,
        "title": "Mathematical Model of Yield Forecast Based on Long and Short-Term Memory Image Neural Network",
        "authors": "Xiao Zhou, M.M. Kamruzzaman, Yulin Luo",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2020.3019072"
    },
    {
        "id": 1083,
        "title": "Penerapan Metode Long Short Term Memory Untuk Klasifikasi  Pada Hate Speech",
        "authors": "Bagus Arief Hamdi Kholifatullah, Agus Prihanto",
        "published": "2023-1-25",
        "citations": 1,
        "abstract": "Hate Speech atau ujaran kebencian merupakan tindakan seseorang atau kelompok dalam bentuk provokasi atau hinaaan kepada seseorang atau kelompok lain dalam berbagai faktor seperti suku, agama, ras, antar golongoan, gender, cacat, warna kulit, kewarganegaraan dan orientasi seksual yang dapat dilakukan dengan berbagai cara. Maka dilakukan penelitian dengan membentuk model pendeteksi Hate Speech menggunakan Metode Long Short Term Memory (LSTM). Metode LSTM merupakan suatu metode Deep Learning yang mampu mengingat informasi dari masa lalu dalam proses pembelajaran modelnya. Pada penelitian ini dataset didapat dari website kaggle dengan jumlah 13170 data. Dimana dataset tersebut dipisah menjadi 2 yaitu data latih dan data validasi dengan rasio perbandingan data latih dan data validasi sebesar 80% : 20%.\r\nHasil pengujian menunjukkan bahwa : 1) Metode LSTM dapat diterapkan pada model untuk proses klasifikasi pada hate speech menggunakan data dari situs kaggle yaitu Indonesian Abusive and Hate Speech. Model yang dibentuk terdiri dari Embedding Layer, LSTM Layer, 2 Dense Layer dengan fungsi aktivasi ReLu, Dropout Layer dan Fully Connected Layer dengan fungsi aktivasi softmax dan fungsi rugi Binary Cross Entropy, 2) Model memiliki peforma terbaik dengan menggunakan 256 neuron LSTM. Akurasi yang diperoleh pada data latih sebesar 86.23% dan akurasi pada data validasi sebesar 87.10% dengan epoch sebanyak 10.",
        "keywords": "",
        "link": "http://dx.doi.org/10.26740/jinacs.v4n03.p292-297"
    },
    {
        "id": 1084,
        "title": "Long Short-Term Memory (LSTM) Estimation of Chair Reaction Force during Sit-to-Stand Movements",
        "authors": "Naoto Otomori, Asuka Takai",
        "published": "2023-10-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/iccas59377.2023.10317053"
    },
    {
        "id": 1085,
        "title": "Perfect dispatch learning model based on adaptive Long Short-term Memory neural networks",
        "authors": "Xiangfei Meng, Long Zhao, Yijun Sun, Xin Tian, Bin Yang, Changcheng Li",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.egyr.2023.05.169"
    },
    {
        "id": 1086,
        "title": "Wind and PV Power Ramp Events Prediction Based on Long Short-Term Memory Network",
        "authors": "Zengwei Wang, Zhendong Li, Yutian Liu, Huan Ma",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ispec58282.2023.10402807"
    },
    {
        "id": 1087,
        "title": "An energy prediction approach using bi-directional long short-term memory for a hydropower plant in Laos",
        "authors": "Suriya Kaewarsa, Vanhkham Kongpaseuth",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00202-023-02096-8"
    },
    {
        "id": 1088,
        "title": "Implementation of Long Short-Term Memory (LSTM) Networks for Stock Price Prediction",
        "authors": "Vivek Deshpande",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "In this research, we explore the potential of Long Short-Term Memory (LSTM) networks for predicting stock prices. Due to the complexities of the financial markets and the inherent volatility of stock prices, accurate forecasting is now crucial for investors and financial specialists. It has been shown that LSTM, a type of recurrent neural network (RNN), can recognise temporal correlations and patterns in serial data. Training and assessing LSTM models in this work involves analysing stock price data, relevant financial measures, and market sentiment indicators. We looked into other ideas, hyper parameters, and preprocessing methods to see if we might boost the networks' performance. To further improve the model's generalizability, we utilise series normalisation and removal to reduce overfitting. The outcomes demonstrate that the LSTM network outperforms more standard series temporal prediction methods in capturing and anticipating shifts in action pricing. We also conduct extensive back testing and evaluation, using measures like mean squared error (MSE) and mean absolute error (MAE), to assess the model's accuracy and resilience. The results of this study shed light on how deep learning techniques, in particular LSTM networks, can be applied to the prediction of stock prices, potentially assisting traders, investors, and other financial decision-makers in navigating complex and volatile financial markets.",
        "keywords": "",
        "link": "http://dx.doi.org/10.52710/rjcse.74"
    },
    {
        "id": 1089,
        "title": "Question Assessment Recommendation System Based on Personalization using Collaborative Filtering and Long-Short Term Memory",
        "authors": "Hartawan Bahari Mulyadi, Saiful Bukhori, Gayatri Dwi Santika",
        "published": "2023-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isec57711.2023.10402350"
    },
    {
        "id": 1090,
        "title": "Unlocking the Power of Long Short-Term Memory Networks: A Text Classification Approach",
        "authors": "A. Pandiaraj, N. Ramshankar, R. Venkatesan",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10308054"
    },
    {
        "id": 1091,
        "title": "Adopting Convolutional Long Short-Term Memory Network to Detect Seizures",
        "authors": "Arpana Mahajan, Kavitha Somaraj, Md. Shahid Jamal, Mustafa Sameer",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10306872"
    },
    {
        "id": 1092,
        "title": "Optimized Investment Strategy Based on Long Short-Term Memory Networks (LSTMs)",
        "authors": "Qingyun Wang, Yayuan Xiao",
        "published": "2024-2-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.12691/ajams-12-1-3"
    },
    {
        "id": 1093,
        "title": "Long Short-Term Memory and Word Embedding For Sentiment Analysis of User Review",
        "authors": "Lia Silviana, Erna Budhiarti Nababan, Muhammad Zarlis",
        "published": "2023-7-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ice-smartech59237.2023.10461949"
    },
    {
        "id": 1094,
        "title": "Improved Long Short-Term Memory-Based Periodic Traffic Volume Prediction Method",
        "authors": "Yuguang Chen, Jincheng Guo, Hongbin Xu, Jintao Huang, Linyong Su",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3305398"
    },
    {
        "id": 1095,
        "title": "The application of Long Short-Term Memory algorithm in American multinational technology company stock prediction",
        "authors": "Yufei Wang",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "The fast development in American multinational technology companies has attracted both professional and new investors to buy the stocks. However, the price of these companies are unstable and therefore hard to be predicted. The focus of this article is to use AI and deep learning algorithms to find a pattern of the stock price. Long Short-Term Memory Algorithm (LSTM) is the main algorithm used to predict the trend, and other methods including Autoregressive integrated moving average (ARIMA), Seasonal autoregressive integrated moving average (SARIMA), and prophet are also discussed in this piece.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/13/20230719"
    },
    {
        "id": 1096,
        "title": "Research on the Application of Long Short-Term Memory Neural Network in Power Load Forecasting",
        "authors": "Tianyi Hu, Zhen Zhang",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icecai58670.2023.10176504"
    },
    {
        "id": 1097,
        "title": "Automatic Human Action Recognition Model Based on Adaptive Long Short Term Memory",
        "authors": "Badhagouni Suresh Kumar, Dr. S. Viswanadha Raju, Dr. H. Venkateswara Reddy",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4381032"
    },
    {
        "id": 1098,
        "title": "Detection of Abnormal Network Traffic Using Bidirectional Long Short-Term Memory",
        "authors": "Nga Nguyen Thi Thanh, Quang H. Nguyen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/csse.2023.032107"
    },
    {
        "id": 1099,
        "title": "Estimating Stock Price Based on Information from Financial Statements Using Long Short-Term Memory Network",
        "authors": "Thitikun Kunathananon, Pittipol Kantavat",
        "published": "2023-5-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaibd57115.2023.10206328"
    },
    {
        "id": 1100,
        "title": "Long short-term memory-based chatbot for vocational registration information services",
        "authors": "Yudo Sembodo Hastoro Langgeng",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.47738/jads.v4i4.128"
    },
    {
        "id": 1101,
        "title": "Attention-based bidirectional-long short-term memory for abnormal human activity detection",
        "authors": "Manoj Kumar, Anoop Kumar Patel, Mantosh Biswas, S. Shitharth",
        "published": "2023-9-2",
        "citations": 3,
        "abstract": "AbstractAbnormal human behavior must be monitored and controlled in today’s technology-driven era, since it may cause damage to society in the form of assault or web-based violence, such as direct harm to a person or the propagation of hate crimes through the internet. Several authors have attempted to address this issue, but no one has yet come up with a solution that is both practical and workable. Recently, deep learning models have become popular as a means of handling massive amounts of data but their potential to categorize the aberrant human activity remains unexplored. Using a convolutional neural network (CNN), a bidirectional long short-term memory (Bi-LSTM), and an attention mechanism to pay attention to the unique spatiotemporal characteristics of raw video streams, a deep-learning approach has been implemented in the proposed framework to detect anomalous human activity. After analyzing the video, our suggested architecture can reliably assign an abnormal human behavior to its designated category. Analytic findings comparing the suggested architecture to state-of-the-art algorithms reveal an accuracy of 98.9%, 96.04%, and 61.04% using the UCF11, UCF50, and subUCF crime datasets, respectively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-023-41231-0"
    },
    {
        "id": 1102,
        "title": "Depression Detection on e-Risk 2017 using Long Short-term Memory Models",
        "authors": "Farnaz Sheikhi, Laya Fakher, Danial Chekani",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aisp61396.2024.10475293"
    },
    {
        "id": 1103,
        "title": "Stock Price Prediction based on Time Series Model and Long Short-term Memory Method",
        "authors": "Dazhi Song, Dazhi Song",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "This study conducts a comparative analysis of two prominent methodologies, Time Series Analysis and Long Short-Term Memory Neural Networks (LSTM), for the prediction of stock prices, utilizing historical data from Netflix. The primary purpose of conducting this research is to evaluate their efficacy in terms of predictive accuracy. Time Series Analysis encompasses stationarity tests, rolling statistics, and the application of the Autoregressive Integrated Moving Average model. In contrast, LSTM Neural Networks involve data normalization, reshaping, and the development of LSTM-based models. Performance assessment metrics such as Mean Absolute Error, Mean Squared Error, Root Mean Squared Error, and visual comparisons are utilized. The results prominently favor long short-term memory Neural Network, which consistently outperforms in predictive accuracy, yielding reduced forecasting errors. This study contributes significant insights into stock price prediction methodologies and offers implications for refining model parameters, bolstering adaptability to evolving market dynamics, and addressing computational efficiency concerns in both Time Series Analysis and LSTM Neural Networks. In summary, LSTM model emerges as the preferred approach, advancing understanding of effective strategies for stock price prediction in financial markets.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/e75xgk49"
    },
    {
        "id": 1104,
        "title": "Multi-Step Long-Short Term Memory (LSTM) Time Series Ocean Waves Forecasting Model for Wave Energy Converters (WEC)",
        "authors": "Saqib Iqbal, Kamyar Mehran",
        "published": "2023-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ecce53617.2023.10362250"
    }
]