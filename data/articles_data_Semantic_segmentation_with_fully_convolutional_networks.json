[
    {
        "id": 14305,
        "title": "A Smoothing Layer for SAR Image Semantic Segmentation with Fully Convolutional Networks",
        "authors": "Ilter Turkmenli, Koray Kayabol, Erchan Aptoula",
        "published": "2023-5-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/jurse57346.2023.10144152"
    },
    {
        "id": 14306,
        "title": "ADVANCEMENTS IN SEMANTIC SEGMENTATION: A COMPREHENSIVE REVIEW AND COMPARATIVE ANALYSIS OF FULLY CONVOLUTIONAL NETWORKS (FCN)",
        "authors": "",
        "published": "2024-1-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets48360"
    },
    {
        "id": 14307,
        "title": "Learning CRF potentials through fully convolutional networks for satellite image semantic segmentation",
        "authors": "Martina Pastorino, Gabriele Moser, Sebastiano B. Serpico, Josiane Zerubia",
        "published": "2023-11-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sitis61268.2023.00023"
    },
    {
        "id": 14308,
        "title": "Classification of semantic segmentation using fully convolutional networks based unmanned aerial vehicle application",
        "authors": "Shouket Abdulrahman Ahmed, Hazry Desa, Abadal-Salam T. Hussain",
        "published": "2023-6-1",
        "citations": 0,
        "abstract": "The classification of semantic segmentation-based unmanned aerial vehicle (UAV) application based on the datasets used in this work and the necessary data preprocessing steps for the optimization and implementation of the models are also involved. The optimization of the various models was done using the evaluation metrics and loss functions because deep neural networks (DNNs) are just about writing a cost function and its subsequent optimization. convolutional neural network (CNN) is a common type of artificial neural network (ANN) that has found application in numerous tasks, such as image and video recognition, image classification, recommender systems, financial time series, medical image analysis, and natural language processing. CNN is developed to automatically and adaptively learn spatial feature hierarchies via backpropagation using numerous building blocks, such as pooling, convolution, and fully connected layers. The result of identification was excellent. The image segmentation was detected and comprehend the actual components of an image down to the pixel level. The result created an entire image segmentation masks with instances using the new label editor in the label box.",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijai.v12.i2.pp641-647"
    },
    {
        "id": 14309,
        "title": "RSFNet:  a method for remote sensing image semantic segmentation based on fully convolutional neural networks",
        "authors": "Chuanhao Wei, Dezhao Kong, Xuelian Sun, Yu Zhou",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3000799"
    },
    {
        "id": 14310,
        "title": "Semantic segmentation of ultra-high resolution remote sensing images based on fully convolutional neural networks",
        "authors": "Hua Zhang, Zhengang Jiang, Jun Xu, Xuekun Yao",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10164846"
    },
    {
        "id": 14311,
        "title": "Retracted: Segmentation Algorithm of Magnetic Resonance Imaging Glioma under Fully Convolutional Densely Connected Convolutional Networks",
        "authors": "",
        "published": "2023-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9842197"
    },
    {
        "id": 14312,
        "title": "Scene Parsing Using Fully Convolutional Network for Semantic Segmentation",
        "authors": "Nisar Ali, Ali Zeeshan Ijaz, Raja Hashim Ali, Zain Ul Abideen, Abdul Bais",
        "published": "2023-9-24",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ccece58730.2023.10288934"
    },
    {
        "id": 14313,
        "title": "Semantic Segmentation using Convolutional Neural Networks",
        "authors": "Bhavadharshini V, Mridula S, Sakthipriya B, J. Jeffin Gracewell",
        "published": "2023-2-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccmc56507.2023.10084064"
    },
    {
        "id": 14314,
        "title": "Filter pruning for convolutional neural networks in semantic image segmentation",
        "authors": "Clara I. López-González, Esther Gascó, Fredy Barrientos-Espillco, Eva Besada-Portas, Gonzalo Pajares",
        "published": "2024-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.11.010"
    },
    {
        "id": 14315,
        "title": "Semantic Face Segmentation Using Convolutional Neural Networks With a Supervised Attention Module",
        "authors": "Akiyoshi Hizukuri, Yuto Hirata, Ryohei Nakayama",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3326420"
    },
    {
        "id": 14316,
        "title": "Multi-Scale Fully Convolutional Network-Based Semantic Segmentation for Mobile Robot Navigation",
        "authors": "Thai-Viet Dang, Ngoc-Tam Bui",
        "published": "2023-1-20",
        "citations": 11,
        "abstract": "In computer vision and mobile robotics, autonomous navigation is crucial. It enables the robot to navigate its environment, which consists primarily of obstacles and moving objects. Robot navigation employing impediment detections, such as walls and pillars, is not only essential but also challenging due to real-world complications. This study provides a real-time solution to the problem of obtaining hallway scenes from an exclusive image. The authors predict a dense scene using a multi-scale fully convolutional network (FCN). The output is an image with pixel-by-pixel predictions that can be used for various navigation strategies. In addition, a method for comparing the computational cost and precision of various FCN architectures using VGG-16 is introduced. The binary semantic segmentation and optimal obstacle avoidance navigation of autonomous mobile robots are two areas in which our method outperforms the methods of competing works. The authors successfully apply perspective correction to the segmented image in order to construct the frontal view of the general area, which identifies the available moving area. The optimal obstacle avoidance strategy is comprised primarily of collision-free path planning, reasonable processing time, and smooth steering with low steering angle changes.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12030533"
    },
    {
        "id": 14317,
        "title": "SEP: stage-enhanced panoptic segmentation based on fully convolutional networks",
        "authors": "Shucheng Ji, Xiaochen Yuan, Junqi Bao",
        "published": "2024-3-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3023068"
    },
    {
        "id": 14318,
        "title": "Real-Time Semantic Segmentation of Medical Images Using Convolutional Neural Networks",
        "authors": "Aishwary Awasthi, Ramesh Chandra Tripathi, T Thiruvenkadam",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470555"
    },
    {
        "id": 14319,
        "title": "Deep semantic segmentation of unmanned aerial vehicle remote sensing images based on fully convolutional neural network",
        "authors": "Guoxun Zheng, Zhengang Jiang, Hua Zhang, Xuekun Yao",
        "published": "2023-3-28",
        "citations": 1,
        "abstract": "In the era of artificial intelligence and big data, semantic segmentation of images plays a vital role in various fields, such as people’s livelihoods and the military. The accuracy of semantic segmentation results directly affects the subsequent data analysis and intelligent applications. Presently, semantic segmentation of unmanned aerial vehicle (UAV) remote-sensing images is a research hotspot. Compared with manual segmentation and object-based segmentation methods, semantic segmentation methods based on deep learning are efficient and highly accurate segmentation methods. The author has seriously studied the implementation principle and process of the classical deep semantic segmentation model—the fully convolutional neural network (FCN), including convolution and pooling in the encoding stage, deconvolution and upsampling, etc., in the decoding stage. The author has applied the three structures (i.e., FCN-32s, FCN-16s, and FCN-8s) to the UAV remote sensing image dataset AeroScapes. And the results show that the accuracy of vegetation recognition is stable at about 94%. The accuracy of road recognition can reach up to more than 88%. The mean pixel accuracy rate of the whole test dataset is above 91%. Applying full convolution neural network to semantic segmentation of UAV remote sensing images can improve the efficiency and accuracy of semantic segmentation significantly.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/feart.2023.1115805"
    },
    {
        "id": 14320,
        "title": "Semantic Image Segmentation of Hybrid Rocket Fuel Combustion Data using Convolutional Neural Networks",
        "authors": "Oliver Assenmacher, Alexander Rüttgers, Anna Petrarolo, Riccardo Gelain",
        "published": "2024-1-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2514/6.2024-0799"
    },
    {
        "id": 14321,
        "title": "Retracted: A Lightweight Semantic Segmentation Algorithm Based on Deep Convolutional Neural Networks",
        "authors": "",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9790234"
    },
    {
        "id": 14322,
        "title": "Lane Marking Semantic Segmentation Using Convolutional Neural Networks",
        "authors": "Aleksandr R. Muzalevskiy, Elena V. Serykh, Mihail M. Kopichev, Evgenij V. Druian, Maksim A. Chernyshev",
        "published": "2023-5-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/scm58628.2023.10159034"
    },
    {
        "id": 14323,
        "title": "Self-Constructing Graph Convolutional Networks for Semantic Segmentation of Historical Maps",
        "authors": "Lukas Arzoumanidis, Julius Knechtel, Jan-Henrik Haunert, Youness Dehbi",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.5194/ica-abs-6-11-2023"
    },
    {
        "id": 14324,
        "title": "Architecture of Deep Convolutional Encoder-Decoder Networks for Building Footprint Semantic Segmentation",
        "authors": "Abderrahim Norelyaqine, Rida Azmi, Abderrahim Saadane",
        "published": "2023-4-25",
        "citations": 1,
        "abstract": "Building extraction from high-resolution aerial images is critical in geospatial applications such as telecommunications, dynamic urban monitoring, updating geographic databases, urban planning, disaster monitoring, and navigation. Automatic building extraction is a massive task because buildings in various places have varied spectral and geometric qualities. As a result, traditional image processing approaches are insufficient for autonomous building extraction from high-resolution aerial imaging applications. Automatic object extraction from high-resolution images has been achieved using semantic segmentation and deep learning models, which have become increasingly important in recent years. In this study, the U-Net model was used for building extraction, initially designed for biomedical image analysis. The encoder part of the U-Net model has been improved with ResNet50, VGG19, VGG16, DenseNet169, and Xception. However, three other models have been implemented to test the performance of the model studied: PSPNet, FPN, and LinkNet. The performance analysis through the intersection of union method has shown that U-Net with the VGG16 encoder presents the best results compared to the other models with a high IoU score of 83.06%. This research aims to examine the effectiveness of these four approaches for extracting buildings from high-resolution aerial data.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/8552624"
    },
    {
        "id": 14325,
        "title": "Convolutional Neural Networks with Modified Evaluation Functions for Image Semantic Segmentation",
        "authors": "Zhenyu Song, Lvxing Zhao, Mengyi Zhao, Jiayang Zhao, Tao Liang, Daoli Tan",
        "published": "2023-6-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ainit59027.2023.10212539"
    },
    {
        "id": 14326,
        "title": "A comparative analysis between two convolutional networks architectures for semantic segmentation of histopathology breast cancer images",
        "authors": "Johan Albarracin, Fabián Cano, Eduardo Romero, Angel Cruz-Roa",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sipaim56729.2023.10373477"
    },
    {
        "id": 14327,
        "title": "EEvoU-Net: An ensemble of evolutionary deep fully convolutional neural networks for medical image segmentation",
        "authors": "Tahereh Hassanzadeh, Daryl Essam, Ruhul Sarker",
        "published": "2023-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.asoc.2023.110405"
    },
    {
        "id": 14328,
        "title": "Convolutional Networks Versus Transformers: A Comparison in Prostate Segmentation",
        "authors": "Fernando Vásconez, Maria Baldeon Calisto, Daniel Riofrío, Zhouping Wei, Yoga Balagurunathan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011717600003393"
    },
    {
        "id": 14329,
        "title": "Convolutional neural networks rarely learn shape for semantic segmentation",
        "authors": "Yixin Zhang, Maciej A. Mazurowski",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2023.110018"
    },
    {
        "id": 14330,
        "title": "Semantic Segmentation of Images Based on Multi-Feature Fusion and Convolutional Neural Networks",
        "authors": "Zhenyu Wang, Juan Xiao, Shuai Zhang, Baoqiang Qi",
        "published": "2024-4",
        "citations": 0,
        "abstract": " Image semantic segmentation technology is one of the core research contents in the field of computer vision. With the improvement of computer performance and the continuous development of deep learning technology, researchers have more and more enthusiasm to study the actual effect and performance of image semantic segmentation. The results of deep semantic segmentation allow computers to have a more detailed and accurate understanding of images, and have a wide range of application needs in the fields of autonomous driving, intelligent security, medical imaging, remote sensing images, etc. However, the existing image semantic segmentation algorithms have the disadvantages of easy discontinuous results and insufficient prediction accuracy. In this paper, we take deep learning-based image semantic segmentation technology as the research object to explore the improvement of the image semantic segmentation algorithm and its application in road scenarios. First, this paper proposes MCU-Net method based on residual fusion and multi-scale contextual information. MCU-Net uses residual fusion module to deepen the network structure and improve the ability of U-Net to acquire deeper features. Then a top-down and bottom-up path is constructed for feature information between different levels, and the spatial and semantic information contained in shallow and deep features in the network is fully utilized by fusing features from different levels. In addition, an enhanced void space pyramid pooling module is added for feature information between the same levels, which enables the output features to have a larger range of semantic information. Second, this paper proposes the DAMCU-Net method based on attention mechanism and edge detection based on MCU-Net. DAMCU-Net extracts global contextual information by the attention mechanism optimization module, while fusing features using dense jump connections to facilitate the network to recover more spatial detail information during upsampling, and uses the FReLU activation function to improve the segmentation capability of the network for complex targets. For the edge information lost in the feature extraction process, the edge detection branch is added to supplement the feature information of the main path by feature fusion to achieve the optimization of the edge information. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1142/s0218126624501020"
    },
    {
        "id": 14331,
        "title": "SDDS-Net: Space and Depth Encoder-Decoder Convolutional Neural Networks for Real-Time Semantic Segmentation",
        "authors": "Hatem Ibrahem, Ahmed Salem, Hyun-Soo Kang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3327323"
    },
    {
        "id": 14332,
        "title": "Land monitoring system: Comparison of traditional machine learning and U-Net convolutional neural networks approaches applied to semantic segmentation of drone imagery",
        "authors": "Ibrahima Diagne, Ibrahima Ngom, Ousmane Sadio, Adama Coulibaly, Marc Momar Tall, Moustapha Ndiaye, Abdou Diop",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icngn59831.2023.10396752"
    },
    {
        "id": 14333,
        "title": "Improved fully convolutional neuron networks on small retinal vessel segmentation using local phase as attention",
        "authors": "Xihe Kuang, Xiayu Xu, Leyuan Fang, Ehsan Kozegar, Huachao Chen, Yue Sun, Fan Huang, Tao Tan",
        "published": "2023-3-1",
        "citations": 2,
        "abstract": "Retinal images have been proven significant in diagnosing multiple diseases such as diabetes, glaucoma, and hypertension. Retinal vessel segmentation is crucial for the quantitative analysis of retinal images. However, current methods mainly concentrate on the segmentation performance of overall retinal vessel structures. The small vessels do not receive enough attention due to their small percentage in the full retinal images. Small retinal vessels are much more sensitive to the blood circulation system and have great significance in the early diagnosis and warning of various diseases. This paper combined two unsupervised methods, local phase congruency (LPC) and orientation scores (OS), with a deep learning network based on the U-Net as attention. And we proposed the U-Net using local phase congruency and orientation scores (UN-LPCOS), which showed a remarkable ability to identify and segment small retinal vessels. A new metric called sensitivity on a small ship (Sesv) was also proposed to evaluate the methods’ performance on the small vessel segmentation. Our strategy was validated on both the DRIVE dataset and the data from Maastricht Study and achieved outstanding segmentation performance on both the overall vessel structure and small vessels.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fmed.2023.1038534"
    },
    {
        "id": 14334,
        "title": "XNet: Wavelet-Based Low and High Frequency Fusion Networks for Fully- and Semi-Supervised Semantic Segmentation of Biomedical Images",
        "authors": "Yanfeng Zhou, Jiaxing Huang, Chenlong Wang, Le Song, Ge Yang",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01928"
    },
    {
        "id": 14335,
        "title": "Comparing the Semantic Segmentation of High-Resolution Images Using Deep Convolutional\n      Networks: SegNet, HRNet, CSE-HRNet and RCA-FCN",
        "authors": "Nafiseh Sadeghi, Homayoun Mahdavi-Nasab, Mansoor Zeinali, Hossein Pourghasem",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.61186/jist.39680.11.44.359"
    },
    {
        "id": 14336,
        "title": "Fully Automatic Thoracic Cavity Segmentation in Dynamic Contrast Enhanced Breast MRI Using Deep Convolutional Neural Networks",
        "authors": "Marco Berchiolli, Susann Wolfram, Wamadeva Balachandran, Tat-Hean Gan",
        "published": "2023-9-9",
        "citations": 0,
        "abstract": "Dynamic Contrast Enhanced Magnetic Resonance Imaging (DCE-MRI) is regarded as one of the main diagnostic tools for breast cancer. Several methodologies have been developed to automatically localize suspected malignant breast lesions. Changes in tissue appearance in response to the injection of the contrast agent (CA) are indicative of the presence of malignant breast lesions. However, these changes are extremely similar to the ones of internal organs, such as the heart. Thus, the task of chest cavity segmentation is necessary for the development of lesion detection. In this work, a data-efficient approach is proposed, to automatically segment breast MRI data. Specifically, a study on several UNet-like architectures (Dynamic UNet) based on ResNet is presented. Experiments quantify the impact of several additions to baseline models of varying depth, such as self-attention and the presence of a bottlenecked connection. The proposed methodology is demonstrated to outperform the current state of the art both in terms of data efficiency and in terms of similarity index when compared to manually segmented data.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app131810160"
    },
    {
        "id": 14337,
        "title": "Mask RFCT: Recursive Fully Convolutional Tracker for Video Instance Segmentation",
        "authors": "Yunda Shi, Jianming Hu, Yi Zhang",
        "published": "2023-2-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nnice58320.2023.10105756"
    },
    {
        "id": 14338,
        "title": "Residual Graph Convolutional Network for Bird’s-Eye-View Semantic Segmentation",
        "authors": "Qiuxiao Chen, Xiaojun Qi",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00329"
    },
    {
        "id": 14339,
        "title": "A Lightweight and Dynamic Convolutional Network for Real-time Semantic Segmentation",
        "authors": "Chunyu Zhang, Fang Xu, Chengdong Wu",
        "published": "2023-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ccdc58219.2023.10326480"
    },
    {
        "id": 14340,
        "title": "Brain Tumor Segmentation of Lower-Grade Glioma Across MRI Images Using Hybrid Convolutional Neural Networks",
        "authors": "Amal Jlassi, Khaoula ElBedoui, Walid Barhoumi",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011895900003393"
    },
    {
        "id": 14341,
        "title": "Improvement of semantic segmentation through transfer learning of multi-class regions with convolutional neural networks on supine and prone breast MRI images",
        "authors": "Sungwon Ham, Minjee Kim, Sangwook Lee, Chuan-Bing Wang, BeomSeok Ko, Namkug Kim",
        "published": "2023-4-27",
        "citations": 2,
        "abstract": "AbstractSemantic segmentation of breast and surrounding tissues in supine and prone breast magnetic resonance imaging (MRI) is required for various kinds of computer-assisted diagnoses for surgical applications. Variability of breast shape in supine and prone poses along with various MRI artifacts makes it difficult to determine robust breast and surrounding tissue segmentation. Therefore, we evaluated semantic segmentation with transfer learning of convolutional neural networks to create robust breast segmentation in supine breast MRI without considering supine or prone positions. Total 29 patients with T1-weighted contrast-enhanced images were collected at Asan Medical Center and two types of breast MRI were performed in the prone position and the supine position. The four classes, including lungs and heart, muscles and bones, parenchyma with cancer, and skin and fat, were manually drawn by an expert. Semantic segmentation on breast MRI scans with supine, prone, transferred from prone to supine, and pooled supine and prone MRI were trained and compared using 2D U-Net, 3D U-Net, 2D nnU-Net and 3D nnU-Net. The best performance was 2D models with transfer learning. Our results showed excellent performance and could be used for clinical purposes such as breast registration and computer-aided diagnosis.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-023-33900-x"
    },
    {
        "id": 14342,
        "title": "Railway Infrastructure Instance Segmentation Based on Convolutional Neural Networks",
        "authors": "V. A. Fedorov",
        "published": "2023-9-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/rusautocon58002.2023.10272908"
    },
    {
        "id": 14343,
        "title": "Burned area semantic segmentation: A novel dataset and evaluation using convolutional networks",
        "authors": "Tiago F.R. Ribeiro, Fernando Silva, José Moreira, Rogério Luís de C. Costa",
        "published": "2023-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.isprsjprs.2023.07.002"
    },
    {
        "id": 14344,
        "title": "Pixel-Wise Gradient Uncertainty for Convolutional Neural Networks Applied to Out-of-Distribution Segmentation",
        "authors": "Kira Maag, Tobias Riedlinger",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012353300003660"
    },
    {
        "id": 14345,
        "title": "Enhancing Semantic Segmentation: Design and Analysis of Improved U-Net Based Deep Convolutional Neural Networks",
        "authors": "Akash Saxena, Prashant Johri, Winner Chukwuemeka Ihechiluru, Vivek Sharma, Megha Rathore, Dharmendra Yadav",
        "published": "2023-9-21",
        "citations": 0,
        "abstract": "In this research, we provide a state-of-the-art method for semantic segmentation that makes use of a modified version of the U-Net architecture, which is itself based on deep convolutional neural networks (CNNs). This research delves into the ins and outs of this cutting-edge approach to semantic segmentation in an effort to boost its precision and productivity. To perform semantic segmentation, a crucial operation in computer vision, each pixel in an image must be assigned to one of many predefined item classes. The proposed Improved U-Net architecture makes use of deep CNNs to efficiently capture complex spatial characteristics while preserving associated context. The study illustrates the efficacy of the Improved U-Net in a variety of real-world circumstances through thorough experimentation and assessment. Intricate feature extraction, down-sampling, and up-sampling are all part of the network's design in order to produce high-quality segmentation results. The study demonstrates comparative evaluations against classic U-Net and other state-of-the-art models and emphasizes the significance of hyperparameter fine-tuning. The suggested architecture shows excellent performance in terms of accuracy and generalization, demonstrating its promise for a variety of applications. Finally, the problem of semantic segmentation is addressed in a novel way. The experimental findings validate the relevance of the architecture's design decisions and demonstrate its potential to boost computer vision by enhancing segmentation precision and efficiency.",
        "keywords": "",
        "link": "http://dx.doi.org/10.17762/ijritcc.v12i1.7911"
    },
    {
        "id": 14346,
        "title": "The Fully Convolutional Transformer for Medical Image Segmentation",
        "authors": "Athanasios Tragakis, Chaitanya Kaul, Roderick Murray-Smith, Dirk Husmeier",
        "published": "2023-1",
        "citations": 32,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00365"
    },
    {
        "id": 14347,
        "title": "Semantic segmentation-based semantic communication system for image transmission",
        "authors": "Jiale Wu, Celimuge Wu, Yangfei Lin, Tsutomu Yoshinaga, Lei Zhong, Xianfu Chen, Yusheng Ji",
        "published": "2023-2",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.dcan.2023.02.006"
    },
    {
        "id": 14348,
        "title": "A Multi-Path Semantic Segmentation Network Based on Convolutional Attention Guidance",
        "authors": "Chenyang Feng, Shu Hu, Yi Zhang",
        "published": "2024-2-29",
        "citations": 0,
        "abstract": "Due to the efficiency of self-attention mechanisms in encoding spatial information, Transformer-based models have recently taken a dominant position among semantic segmentation methods. However, Transformer-based models have the disadvantages of requiring a large amount of computation and lacking attention to detail, so we look back to the CNN model. In this paper, we propose a multi-path semantic segmentation network with convolutional attention guidance (dubbed MCAG). It has a multi-path architecture, and feature guidance from the main path is used in other paths, which forces the model to focus on the object’s boundaries and details. It also explores multi-scale convolutional features through spatial attention. Finally, it captures both local and global contexts in spatial and channel dimensions in an adaptive manner. Extensive experiments were conducted on popular benchmarks, and it was found that MCAG surpasses other SOTA methods by achieving 47.7%, 82.51% and 43.6% mIoU on ADE20K, Cityscapes and COCO-Stuff, respectively. Specifically, the experimental results prove that the proposed model has high segmentation precision for small objects, which demonstrates the effectiveness of convolutional attention mechanisms and multi-path strategies. The results show that the CNN model can achieve good segmentation effects with a lower amount of calculation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app14052024"
    },
    {
        "id": 14349,
        "title": "Remote Sensing Image Semantic Segmentation Method Based on a Deep Convolutional Neural Network and Multiscale Feature Fusion",
        "authors": "Guangzhen Zhang, Wangyang Jiang",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "There are many problems with remote sensing images, such as large data scales, complex illumination conditions, occlusion, and dense targets. The existing semantic segmentation methods for remote sensing images are not accurate enough for small and irregular target segmentation results, and the edge extraction results are poor. The authors propose a remote sensing image segmentation method based on a DCNN and multiscale feature fusion. Firstly, an end-to-end remote sensing image segmentation model using complete residual connection and multiscale feature fusion was designed based on a deep convolutional encoder–decoder network. Secondly, weighted high-level features were obtained using an attention mechanism, which better preserved the edges, texture, and other information of remote sensing images. The experimental results on ISPRS Potsdam and Urban Drone datasets show that compared with the comparison methods, this method has better segmentation effect on small and irregular objects and achieves the best segmentation performance while ensuring the computation speed.",
        "keywords": "",
        "link": "http://dx.doi.org/10.4018/ijswis.333712"
    },
    {
        "id": 14350,
        "title": "IFAS: improved fully automatic segmentation convolutional neural network model along with morphological segmentation for brain tumor detection",
        "authors": "Akanksha Kulshreshtha, Arpita Nagpal",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s41870-023-01572-5"
    },
    {
        "id": 14351,
        "title": "A convolutional vision transformer for semantic segmentation of side-scan sonar data",
        "authors": "Hayat Rajani, Nuno Gracias, Rafael Garcia",
        "published": "2023-10",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.oceaneng.2023.115647"
    },
    {
        "id": 14352,
        "title": "A Study on the Strategic Application of Semantic Segmentation Based on Improved Convolutional Neural Networks on English-Chinese Interaction",
        "authors": "Xi Yang, Bei Yang",
        "published": "2023-5-8",
        "citations": 0,
        "abstract": "Teachers need to provide numerous examples sentences for students to translate in the process of teaching English, but the number of sentences given by teachers to practice subjectively is not enough. Therefore, the study constructs a text generation model using an improved convolutional neural network semantic segmentation method, where the corpus utterances are keyword extracted and new shorter utterances are generated based on the keywords for language learners to practice translation. The research first uses the textRank algorithm to extract semantic keywords to obtain a dataset, and then uses CNN to construct an encoder to achieve semantic encoding of the keyword dataset. However, during the research process, it was found that traditional CNN models are relatively sensitive to the location of input data. Therefore, the research introduces the idea of Decomposition Machine (FM) to improve the encoder. In order to control text generation, research has introduced a weighted additive attention mechanism in the decoding process to associate the meaning of the generated text sequence with the meaning of the keyword set. Based on this, a text generation model for generating a translation related corpus in English teaching is constructed. This results in a text generation model that can be used to generate a translation-linked corpus for English language teaching. The average BLEU value of model 1 is 0.924, Inform value is 98.40, the Success value is 97.64, and the Combine value is 101.24, which can achieve high-quality text generation by the keyword lexical meaning and provide technical guarantee for the establishment of the corpus in educating in English.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3596493"
    },
    {
        "id": 14353,
        "title": "Multi-Scale Convolutional Vision Transformer for Semantic Segmentation",
        "authors": "Rostislav R. Otyrba, Alexander A. Sirota",
        "published": "2023-11-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/summa60232.2023.10349661"
    },
    {
        "id": 14354,
        "title": "Processing of micro-CT images of granodiorite rock samples using convolutional neural networks (CNN), Part II: Semantic segmentation using a 2.5D CNN",
        "authors": "A. Roslin, M. Marsh, B. Provencher, T.R. Mitchell, I.A. Onederra, C.R. Leonardi",
        "published": "2023-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mineng.2023.108027"
    },
    {
        "id": 14355,
        "title": "Semantic segmentation of surface defects of smooth parts based on deep convolutional neural networks",
        "authors": "Huaishu Hou, Runze Zhang, Chaofei Jiao, Zhifan Zhao, Xinchong Fang, Jinhao Li, Dachuan Xu",
        "published": "2023-2-1",
        "citations": 0,
        "abstract": "Machine vision plays an increasingly important role in industrial product quality detection. During processing, scratches, dents and other defects are inevitable on the surface of a smooth part. Although surface defects do not affect the overall performance of the product, their existence\n is unacceptable when a perfect product is required. The surface defect detection method based on machine vision and deep convolutional neural networks overcomes, to a certain extent, the problem of low detection efficiency, high false detection and missing detection rates in the traditional\n detection method. In this paper, a multistream semantic segmentation neural network is proposed to identify defects on smooth parts. Taking a seatbelt buckle as an example, the scratch and crush defects on the surface are classified. The network takes DeepLabV3+ as the framework and three\n types of image stream as the input of the network. In the backbone feature extraction network, the Xception structure is improved to MobilenetV2 and the convolutional block attention module (CBAM) is introduced into the decoding network, which improves the operational efficiency and accuracy.\n Compared with other classical networks, this network demonstrates good performance in the image dataset of the seatbelt buckle and realises fast and accurate semantic segmentation and classification of surface defects. The evaluation results of the network model have been significantly improved.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1784/insi.2023.65.2.103"
    },
    {
        "id": 14356,
        "title": "Semantic segmentation of anomalous diffusion using deep convolutional networks",
        "authors": "Xiang Qu, Yi Hu, Wenjie Cai, Yang Xu, Hu Ke, Guolong Zhu, Zihan Huang",
        "published": "2024-1-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1103/physrevresearch.6.013054"
    },
    {
        "id": 14357,
        "title": "A benchmark study of convolutional neural networks in fully automatic segmentation of aortic root",
        "authors": "Tingting Yang, Guangyu Zhu, Li Cai, Joon Hock Yeo, Yu Mao, Jian Yang",
        "published": "2023-6-15",
        "citations": 2,
        "abstract": "Recent clinical studies have suggested that introducing 3D patient-specific aortic root models into the pre-operative assessment procedure of transcatheter aortic valve replacement (TAVR) would reduce the incident rate of peri-operative complications. Tradition manual segmentation is labor-intensive and low-efficient, which cannot meet the clinical demands of processing large data volumes. Recent developments in machine learning provided a viable way for accurate and efficient medical image segmentation for 3D patient-specific models automatically. This study quantitively evaluated the auto segmentation quality and efficiency of the four popular segmentation-dedicated three-dimensional (3D) convolutional neural network (CNN) architectures, including 3D UNet, VNet, 3D Res-UNet and SegResNet. All the CNNs were implemented in PyTorch platform, and low-dose CTA image sets of 98 anonymized patients were retrospectively selected from the database for training and testing of the CNNs. The results showed that despite all four 3D CNNs having similar recall, Dice similarity coefficient (DSC), and Jaccard index on the segmentation of the aortic root, the Hausdorff distance (HD) of the segmentation results from 3D Res-UNet is 8.56 ± 2.28, which is only 9.8% higher than that of VNet, but 25.5% and 86.4% lower than that of 3D UNet and SegResNet, respectively. In addition, 3D Res-UNet and VNet also performed better in the 3D deviation location of interest analysis focusing on the aortic valve and the bottom of the aortic root. Although 3D Res-UNet and VNet are evenly matched in the aspect of classical segmentation quality evaluation metrics and 3D deviation location of interest analysis, 3D Res-UNet is the most efficient CNN architecture with an average segmentation time of 0.10 ± 0.04 s, which is 91.2%, 95.3% and 64.3% faster than 3D UNet, VNet and SegResNet, respectively. The results from this study suggested that 3D Res-UNet is a suitable candidate for accurate and fast automatic aortic root segmentation for pre-operative assessment of TAVR.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fbioe.2023.1171868"
    },
    {
        "id": 14358,
        "title": "Corrigendum to CrackDenseLinkNet: a deep convolutional neural network for semantic segmentation of cracks on concrete surface images",
        "authors": "",
        "published": "2023-9-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1177/14759217231199536"
    },
    {
        "id": 14359,
        "title": "Evaluating robotic-assisted partial nephrectomy surgeons with fully convolutional segmentation and multi-task attention networks",
        "authors": "Yihao Wang, Zhongjie Wu, Jessica Dai, Tara N. Morgan, Alaina Garbens, Hal Kominsky, Jeffrey Gahan, Eric C. Larson",
        "published": "2023-6-27",
        "citations": 1,
        "abstract": "AbstractWe use machine learning to evaluate surgical skill from videos during the tumor resection and renography steps of a robotic assisted partial nephrectomy (RAPN). This expands previous work using synthetic tissue to include actual surgeries. We investigate cascaded neural networks for predicting surgical proficiency scores (OSATS and GEARS) from RAPN videos recorded from the DaVinci system. The semantic segmentation task generates a mask and tracks the various surgical instruments. The movements from the instruments found via semantic segmentation are processed by a scoring network that regresses (predicts) GEARS and OSATS scoring for each subcategory. Overall, the model performs well for many subcategories such as force sensitivity and knowledge of instruments of GEARS and OSATS scoring, but can suffer from false positives and negatives that would not be expected of human raters. This is mainly attributed to limited training data variability and sparsity.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11701-023-01657-0"
    },
    {
        "id": 14360,
        "title": "A Fully Convolutional Network with Waterfall Atrous Spatial Pooling and Localized Active Contour Loss for Fish Segmentation",
        "authors": "Thanh Viet Le, Van Yem Vu, Van Truong Pham, Thi-Thao Tran",
        "published": "2023-4-20",
        "citations": 0,
        "abstract": "Accurate measurements and statistics of fish data are important for sustainable development of aqua-enviroment and marine fisheries. For data measurements and statistics, automatic segmentation of fish is one of key tasks. The fish segmentation however is a challenging task due to arterfacts in underwater images. In this study, we introduce a deep-learning approach, namely FCN-WRN-WASP for automatic fish segmentation from the underwater images. In particular, we introduce a computational-efficient variation called Waterfall Atrous Spatial Pooling (WASP) module into a Fully convolutional network with Wide ResNet baseline. We also proposed a loss function inspired from active contour approach that can exploit the local intensity information from the input image. The approach has been validated on the DeepFish data and the SIUM data set. The results are promissing for fish segmentation, with higher Intersection over Union (IoU) scores compared to state of the arts. The evaluation results showed that the incorporation of the image based active contour loss helps increase the segmentation performance. In addition, the use of the WASP in the architecture is effective especially for forground fish segmentation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.4108/eetinis.v10i1.2942"
    },
    {
        "id": 14361,
        "title": "A Novel Local–Global Graph Convolutional Method for Point Cloud Semantic Segmentation",
        "authors": "Zijin Du, Hailiang Ye, Feilong Cao",
        "published": "2024-4",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2022.3155282"
    },
    {
        "id": 14362,
        "title": "Simple Implementation of Terrain Classification Models via Fully Convolutional Neural Networks",
        "authors": "Assiya Sarinova, Leila Rzayeva, Noyan Tendikov, Ibraheem Shayea",
        "published": "2023-10-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wincom59760.2023.10323012"
    },
    {
        "id": 14363,
        "title": "Attention aware fully convolutional deep learning model for retinal blood vessel segmentation",
        "authors": "C. Gobinath, M.P. Gopinath",
        "published": "2023-4-3",
        "citations": 0,
        "abstract": "Recent reports indicate a rise in retinal issues, and automatic artery vein categorization offers data that is particularly instructive for the medical evaluation of serious retinal disorders including glaucoma and diabetic retinopathy. This work presents a competent and precise deep-learning model designed for vessel segmentation in retinal fundus imaging. This article aims to segment the retinal images using an attention-based dense fully convolutional neural network (A-DFCNN) after removing uncertainty. The artery extraction layers encompass vessel-specific convolutional blocks to focus the tiny blood vessels and dense layers with skip connections for feature propagation. Segmentation is associated with artery extraction layers via individual loss function. Blood vessel maps produced from individual loss functions are authenticated for performance. The proposed technique attains improved outcomes in terms of Accuracy (0.9834), Sensitivity (0.8553), and Specificity (0.9835) from DRIVE, STARE, and CHASE-DB1 datasets. The result demonstrates that the proposed A-DFCNN is capable of segmenting minute vessel bifurcation breakdowns during the training and testing phases.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/jifs-224229"
    },
    {
        "id": 14364,
        "title": "Retracted: Rethinking Separable Convolutional Encoders for End-to-End Semantic Image Segmentation",
        "authors": "",
        "published": "2023-7-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9825140"
    },
    {
        "id": 14365,
        "title": "Pre-Processing Training Data Improves Accuracy and Generalisability of Convolutional Neural Network Based Landscape Semantic Segmentation",
        "authors": "Andrew Clark, Stuart Phinn, Peter Scarth",
        "published": "2023-6-21",
        "citations": 1,
        "abstract": "Data pre-processing for developing a generalised land use and land cover (LULC) deep learning model using earth observation data is important for the classification of a different date and/or sensor. However, it is unclear how to approach deep learning segmentation problems in earth observation data. In this paper, we trialled different methods of data preparation for Convolutional Neural Network (CNN) training and semantic segmentation of LULC features within aerial photography over the Wet Tropics and Atherton Tablelands, Queensland, Australia. This was conducted by trialling and ranking various training patch selection sampling strategies, patch and batch sizes, data augmentations and scaling and inference strategies. Our results showed: a stratified random sampling approach for producing training patches counteracted class imbalances; a smaller number of larger patches (small batch size) improves model accuracy; data augmentations and scaling are imperative in creating a generalised model able to accurately classify LULC features in imagery from a different date and sensor; and producing the output classification by averaging multiple grids of patches and three rotated versions of each patch produced a more accurate and aesthetic result. Combining the findings from the trials, we fully trained five models on the 2018 training image and applied the model to the 2015 test image. The output LULC classifications achieved an average kappa of 0.84, user accuracy of 0.81, and producer accuracy of 0.87. Future research using CNNs and earth observation data should implement the findings of this project to increase LULC model accuracy and transferability.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/land12071268"
    },
    {
        "id": 14366,
        "title": "SEM-FCNET: Semantic Feature Enhancement and Fully Convolutional Network Model for Remote Sensing Object Detection",
        "authors": "Jing Chen, Debo Cheng, Jiacheng Jiang, Zhongyi Yu, Shichao Zhang",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10223139"
    },
    {
        "id": 14367,
        "title": "Hypergraph Convolutional Network Based Weakly Supervised Point Cloud Semantic Segmentation with Scene-Level Annotations",
        "authors": "Zhuheng Lu, Peng Zhang, Yuewei Dai, weiqing li, zhiyong su",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4348441"
    },
    {
        "id": 14368,
        "title": "Automated polyp segmentation based on a multi-distance feature dissimilarity-guided fully convolutional network",
        "authors": "Nan Mu, Jinjia Guo, Rong Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "<abstract>\n   <p>Colorectal malignancies often arise from adenomatous polyps, which typically begin as solitary, asymptomatic growths before progressing to malignancy. Colonoscopy is widely recognized as a highly efficacious clinical polyp detection method, offering valuable visual data that facilitates precise identification and subsequent removal of these tumors. Nevertheless, accurately segmenting individual polyps poses a considerable difficulty because polyps exhibit intricate and changeable characteristics, including shape, size, color, quantity and growth context during different stages. The presence of similar contextual structures around polyps significantly hampers the performance of commonly used convolutional neural network (CNN)-based automatic detection models to accurately capture valid polyp features, and these large receptive field CNN models often overlook the details of small polyps, which leads to the occurrence of false detections and missed detections. To tackle these challenges, we introduce a novel approach for automatic polyp segmentation, known as the multi-distance feature dissimilarity-guided fully convolutional network. This approach comprises three essential components, i.e., an encoder-decoder, a multi-distance difference (MDD) module and a hybrid loss (HL) module. Specifically, the MDD module primarily employs a multi-layer feature subtraction (MLFS) strategy to propagate features from the encoder to the decoder, which focuses on extracting information differences between neighboring layers' features at short distances, and both short and long-distance feature differences across layers. Drawing inspiration from pyramids, the MDD module effectively acquires discriminative features from neighboring layers or across layers in a continuous manner, which helps to strengthen feature complementary across different layers. The HL module is responsible for supervising the feature maps extracted at each layer of the network to improve prediction accuracy. Our experimental results on four challenge datasets demonstrate that the proposed approach exhibits superior automatic polyp performance in terms of the six evaluation criteria compared to five current state-of-the-art approaches.</p>\n  </abstract>",
        "keywords": "",
        "link": "http://dx.doi.org/10.3934/mbe.2023891"
    },
    {
        "id": 14369,
        "title": "Semantic Segmentation of Fish and Underwater Environments Using Deep Convolutional Neural Networks and Learned Active Contours",
        "authors": "Miguel Chicchon, Hector Bedon, Carlos R. Del-Blanco, Ivan Sipiran",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3262649"
    },
    {
        "id": 14370,
        "title": "Fusion attention-ASPP and context semantic for complex scene semantic segmentation",
        "authors": "Yinghao Lin, Shihao Zhao, Kun Cai, Baojun Qiao",
        "published": "2023-4-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2674281"
    },
    {
        "id": 14371,
        "title": "SEMANTIC POINT CLOUD SEGMENTATION IN URBAN ENVIRONMENTS WITH 1D CONVOLUTIONAL NEURAL NETWORKS",
        "authors": "S. M. González-Collazo, N. Canedo-González, E. González, J. Balado",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "Abstract. Convolutional Neural Networks (CNNs) have been widely recognized for their efficacy in image analysis tasks. This paper investigates the application of the 1D-CNN variant CNNs for the semantic segmentation of urban point clouds obtained through Mobile Laser Scanning. Ten well-known local geometric features of point clouds were used as input for the 1D CNN. Through an empirical analysis on the Santiago Urban Dataset, the 1D CNN was optimized in terms of numbers of convolution layers, neurons, pooling layers, dropout layers, dense layers, training epochs, and batch size. The performance of the proposed 1D CNN was compared with Support Vector Machine (SVM), Random Forest (RF), and PointNet++. Despite demonstrating a F1-score weighted at 70.3%, outperforming SVM but slightly lagging RF (71.6%) and significantly trailing PointNet++ (90.3%), the proposed 1D-CNN showcases a cost-effective potential for the segmentation of road and building classes. The relative computational requirements of the models were also discussed, highlighting the practical advantages and limitations of each approach.\n                    ",
        "keywords": "",
        "link": "http://dx.doi.org/10.5194/isprs-archives-xlviii-4-w9-2024-205-2024"
    },
    {
        "id": 14372,
        "title": "Classification and Segmentation of Brain Tumor MRI Images Using Convolutional Neural Networks",
        "authors": "César Borja Ruiz",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icev59168.2023.10329651"
    },
    {
        "id": 14373,
        "title": "Extended U-Net for Satellite Image Semantic Segmentation",
        "authors": "Jin Won Jung, Yoan Shin",
        "published": "2023-7-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icufn57995.2023.10200474"
    },
    {
        "id": 14374,
        "title": "Segmentation-Assisted Fully Convolutional Neural Network Enhances Deep Learning Performance to Identify Proliferative Diabetic Retinopathy",
        "authors": "Minhaj Alam, Emma Zhao, Carson Lam, Daniel Rubin",
        "published": "2023-1-3",
        "citations": 8,
        "abstract": "With the progression of diabetic retinopathy (DR) from the non-proliferative (NPDR) to proliferative (PDR) stage, the possibility of vision impairment increases significantly. Therefore, it is clinically important to detect the progression to PDR stage for proper intervention. We propose a segmentation-assisted DR classification methodology, that builds on (and improves) current methods by using a fully convolutional network (FCN) to segment retinal neovascularizations (NV) in retinal images prior to image classification. This study utilizes the Kaggle EyePacs dataset, containing retinal photographs from patients with varying degrees of DR (mild, moderate, severe NPDR and PDR. Two graders annotated the NV (a board-certified ophthalmologist and a trained medical student). Segmentation was performed by training an FCN to locate neovascularization on 669 retinal fundus photographs labeled with PDR status according to NV presence. The trained segmentation model was used to locate probable NV in images from the classification dataset. Finally, a CNN was trained to classify the combined images and probability maps into categories of PDR. The mean accuracy of segmentation-assisted classification was 87.71% on the test set (SD = 7.71%). Segmentation-assisted classification of PDR achieved accuracy that was 7.74% better than classification alone. Our study shows that segmentation assistance improves identification of the most severe stage of diabetic retinopathy and has the potential to improve deep learning performance in other imaging problems with limited data availability.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/jcm12010385"
    },
    {
        "id": 14375,
        "title": "Foreground segmentation network using transposed convolutional neural networks and up sampling for multiscale feature encoding",
        "authors": "Vishruth B. Gowda, M.T. Gopalakrishna, J. Megha, Shilpa Mohankumar",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.11.015"
    },
    {
        "id": 14376,
        "title": "Interactive Segmentation of Art Images Based on Hypergraph Convolutional Networks",
        "authors": "Rongjuan Wang, Yuan Tian",
        "published": "2023-9-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icosec58147.2023.10276190"
    },
    {
        "id": 14377,
        "title": "FastPlane: A Fully Convolutional Network for Real-time 3D Plane Segmentation",
        "authors": "Haijun Zhang, Qingji Ren, Li Dong, Kim Fung Tsang",
        "published": "2024-1-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icce59016.2024.10444446"
    },
    {
        "id": 14378,
        "title": "Deep semantic segmentation-based unlabeled positive CNN’s loss function for fully automated human finger vein identification",
        "authors": "Adil Al-Azzawi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0164356"
    },
    {
        "id": 14379,
        "title": "Research on virtual color restoration algorithm for printmaking art images based on semantic segmentation and convolutional neural network",
        "authors": "Yongbo Wang",
        "published": "2024-1-1",
        "citations": 0,
        "abstract": "Abstract\nIn this paper, semantic segmentation based on a convolutional neural network is used to guide the image color restoration process. In order to avoid the problem of content mismatch, higher-order features are first extracted from the basic dimensions of the input image, and the convolutional operation is done on the feature map by the excitation function. Then the network parameters are optimized and updated by the backpropagation algorithm to minimize the error between the prediction result and the real result. Finally, in image processing, the dilated convolution technique is introduced to perform noise reduction on the semantic segmented image pixels to optimize the restoration quality. In order to prove the effectiveness of the method in this paper, an experimental analysis of the method is conducted. The experimental results show that the peak signal-to-noise ratio of the model proposed in this paper is higher than 42.986db on average, the structural similarity reaches 0.8%, and the fit is around 0.75. And its color difference can reach at least 11.2% with the increase of iterations. It indicates that the reduction algorithm of semantic segmentation and convolutional neural network greatly improves the accuracy of color reduction results and can obtain printmaking images with higher color quality.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2478/amns.2023.2.00545"
    },
    {
        "id": 14380,
        "title": "Semantic Food Segmentation Using Convolutional Deconvolutional Pyramid Network for Health Monitoring",
        "authors": "Mazhar Hussain, Alessandro Ortis, Riccardo Polosa, Sebastiano Battiato",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.7763/ijcte.2023.v15.1346"
    },
    {
        "id": 14381,
        "title": "Lightweight convolutional neural networks for real-time lane segmentation",
        "authors": "Zhengxiao Yu",
        "published": "2024-3-25",
        "citations": 0,
        "abstract": "Autonomous driving depends on reliable perception systems that involve various perception modules and advanced computer vision techniques. One crucial component of these systems is lane detection, which traditional methods often rely on basic features like color or edges that are sensitive to lighting and perspective changes. Recently, convolutional neural networks (CNNs), have revolutionized lane detection. Nevertheless, existing methods still have some limitations, such as the need for pixel-level labeling and computational inefficiency for real-time applications. To address these challenges, this work leverages PP-LiteSeg for real-time semantic segmentation. PP-LiteSegs key elements are its Simple Pyramid Pooling Module (SPPM), Unified Attention Fusion Module (UAFM), and Flexible and Lightweight Decoder (FLD), which optimize lane detection efficiency. The FLD flexibly adjusts computational costs between the encoder and decoder, balancing efficiency and accuracy. The UAFM enhances feature representations using attention mechanisms, increasing segmentation accuracy. The SPPM efficiently aggregates contextual information while reducing computational complexity. The comprehensive method for lane segmentation achieves competitive results on popular lane detection datasets. The proposed model can adapt to different computational capabilities and significantly enhances lane detection efficiency for real-time applications.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/51/20241283"
    },
    {
        "id": 14382,
        "title": "Fully automated clinical target volume segmentation for glioblastoma radiotherapy using a deep convolutional neural network",
        "authors": "Sogand Sadeghi, Mostafa Farzin, Somayeh Gholami",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5114/pjr.2023.124434"
    },
    {
        "id": 14383,
        "title": "Evaluation on Computer Region Location Algorithm Based on Fully Convolutional Network",
        "authors": "Feng Gao, Qixiang Zhu",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icngn59831.2023.10396745"
    },
    {
        "id": 14384,
        "title": "Computer vision model for food identification in meals from the segmentation obtained by a set of fully convolutional networks",
        "authors": "Marcos A. Carvalho, Tales C. Pimenta, Alessandra C. P. Silvério, Jaqueline C. S. Carvalho",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s12652-023-04703-9"
    },
    {
        "id": 14385,
        "title": "Semantic Enhancement Based Knowledge Graph Completion for Graph Convolutional Neural Networks",
        "authors": "Qiang Rao, Tiejun Wang",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icemce60359.2023.10490589"
    },
    {
        "id": 14386,
        "title": "DSENet: a deep sub-ensembles convolutional neural network for robust semantic segmentation",
        "authors": "Huilin Yin, Xiang Xu, Qian Meng",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2678919"
    },
    {
        "id": 14387,
        "title": "HAF-Net: A Fully Convolutional Segmentation Network Based on Hybrid Attention for Skin Lesion Segmentation",
        "authors": "Gaoxi Zhou, Min Wang, Xun Wang, Zhichao Wu",
        "published": "2023-5-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/10584587.2023.2191544"
    },
    {
        "id": 14388,
        "title": "Semantic Segmentation of Urban Area using Pix2Pix Generative Adversarial Networks",
        "authors": "Khyat Patel, Pratham Shah, Ruchi Gajjar",
        "published": "2023-2-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icort56052.2023.10249202"
    },
    {
        "id": 14389,
        "title": "Tool wear segmentation in blanking processes with fully convolutional networks based digital image processing",
        "authors": "Clemens Schlegel, Dirk Alexander Molitor, Christian Kubik, Daniel Michael Martin, Peter Groche",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jmatprotec.2023.118270"
    },
    {
        "id": 14390,
        "title": "A two-stage segmentation of sublingual veins based on compact fully convolutional networks for Traditional Chinese Medicine images",
        "authors": "Hua Xu, Xiaofei Chen, Peng Qian, Fufeng Li",
        "published": "2023-4-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13755-023-00214-1"
    },
    {
        "id": 14391,
        "title": "Dysphonia detection using a fully convolutional neural network adapted to dynamic speech lengths",
        "authors": "Dosti Aziz, Dávid Sztahó",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3311/wins2024-003"
    },
    {
        "id": 14392,
        "title": "Ensemble convolutional neural networks and transformer-based segmentation methods for achieving accurate sclera segmentation in eye images",
        "authors": "Adel Al-Zebari",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11760-023-02891-7"
    },
    {
        "id": 14393,
        "title": "SwimmerNET: Underwater 2D Swimmer Pose Estimation Exploiting Fully Convolutional Neural Networks",
        "authors": "Nicola Giulietti, Alessia Caputo, Paolo Chiariotti, Paolo Castellini",
        "published": "2023-2-20",
        "citations": 6,
        "abstract": "Professional swimming coaches make use of videos to evaluate their athletes’ performances. Specifically, the videos are manually analyzed in order to observe the movements of all parts of the swimmer’s body during the exercise and to give indications for improving swimming technique. This operation is time-consuming, laborious and error prone. In recent years, alternative technologies have been introduced in the literature, but they still have severe limitations that make their correct and effective use impossible. In fact, the currently available techniques based on image analysis only apply to certain swimming styles; moreover, they are strongly influenced by disturbing elements (i.e., the presence of bubbles, splashes and reflections), resulting in poor measurement accuracy. The use of wearable sensors (accelerometers or photoplethysmographic sensors) or optical markers, although they can guarantee high reliability and accuracy, disturb the performance of the athletes, who tend to dislike these solutions. In this work we introduce swimmerNET, a new marker-less 2D swimmer pose estimation approach based on the combined use of computer vision algorithms and fully convolutional neural networks. By using a single 8 Mpixel wide-angle camera, the proposed system is able to estimate the pose of a swimmer during exercise while guaranteeing adequate measurement accuracy. The method has been successfully tested on several athletes (i.e., different physical characteristics and different swimming technique), obtaining an average error and a standard deviation (worst case scenario for the dataset analyzed) of approximately 1 mm and 10 mm, respectively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23042364"
    },
    {
        "id": 14394,
        "title": "BRAIN TUMOR SEGMENTATION AND DIAGNOSIS USING CONVOLUTIONAL NEURAL NETWORKS IN MRI IMAGES",
        "authors": "",
        "published": "2023-5-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets38891"
    },
    {
        "id": 14395,
        "title": "A Novel 3D Multi-Layer Convolutional Neural Networks for Lung Cancer Segmentation in CT Images",
        "authors": "P L Chithra,  , P Bhavani",
        "published": "2024-3-25",
        "citations": 0,
        "abstract": "Background/Objectives: A novel three-dimensional efficient Multi-Layer Convolutional Neural Network (3D-MLCNN) is proposed for detecting lung tumors accurately using Computerized Tomography (CT) lung tumor images. The proposed K-means segmentation algorithm for labeling the tumor region automatically. This proposed K-means segmentation algorithm automatically labels the tumor regions to process with the 3D MLCNN model to predict tiny tumors and extract tumor regions accurately. Methods: The proposed 3DMLCNN network goal is to extract the tumor region in CT lung images to classify the lung tumor volume by pixel-wise segmentation model. Findings: The proposed 3D MLCNN segmentation model for detecting the segmenting tumors produces outperforming results for predicting even tiny tumors in the lung images. Experimental results demonstrated with lung cancer CT images in TCIA datasets show that the proposed model 3D-MLCNN achieved a dice coefficient (9.6%), Intersection over Union (IoU) (80%), F1-Score (9.33%), Sensitivity (17.11%), and Accuracy (98%) respectively. However, the proposed model 3D MLCNN was evaluated and compared with the existing state-of-the-art segmentation methods, which shows a 10% improvement in the segmentation process. Novelty: A novel 3D MLCNN model enhances the tumor region and predicts the tumor accurately by labeling the tumor using K-means labeling techniques.  Keywords: 3D Convolutional Neural Networks, Lung Cancer CT Images, K - Means Labeling, Feature Visualization, Deep Learning",
        "keywords": "",
        "link": "http://dx.doi.org/10.17485/ijst/v17i13.2081"
    },
    {
        "id": 14396,
        "title": "Mushroom Segmentation and 3D Pose Estimation from Point Clouds using Fully Convolutional Geometric Features and Implicit Pose Encoding",
        "authors": "George Retsinas, Niki Efthymiou, Petros Maragos",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00666"
    },
    {
        "id": 14397,
        "title": "Optimizing Fully Convolutional Encoder-Decoder Network for Segmentation of Diabetic Eye Disease",
        "authors": "Abdul Qadir Khan, Guangmin Sun, Yu Li, Anas Bilal, Malik Abdul Manan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/cmc.2023.043239"
    },
    {
        "id": 14398,
        "title": "Soma Segmentation Using U-Shaped Convolutional Neural Networks with Weight Boundary Mechanism",
        "authors": "",
        "published": "2023-2-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.53469/jrse.2023.05(02).25"
    },
    {
        "id": 14399,
        "title": "Evaluating synthetic neuroimaging data augmentation for automatic brain tumour segmentation with a deep fully-convolutional network",
        "authors": "Fawad Asadi, Thanate Angsuwatanakul, Jamie A. O’Reilly",
        "published": "2024-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ibneur.2023.12.002"
    },
    {
        "id": 14400,
        "title": "Semantic segmentation of thermal defects in belt conveyor idlers using thermal image augmentation and U-Net-based convolutional neural networks",
        "authors": "Mohammad Siami, Tomasz Barszcz, Jacek Wodecki, Radoslaw Zimroz",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "AbstractThe belt conveyor (BC) is the main means of horizontal transportation of bulk materials at mining sites. The sudden fault in BC modules may cause unexpected stops in production lines. With the increasing number of applications of inspection mobile robots in condition monitoring (CM) of industrial infrastructure in hazardous environments, in this article we introduce an image processing pipeline for automatic segmentation of thermal defects in thermal images captured from BC idlers using a mobile robot. This study follows the fact that CM of idler temperature is an important task for preventing sudden breakdowns in BC system networks. We compared the performance of three different types of U-Net-based convolutional neural network architectures for the identification of thermal anomalies using a small number of hand-labeled thermal images. Experiments on the test data set showed that the attention residual U-Net with binary cross entropy as the loss function handled the semantic segmentation problem better than our previous research and other studied U-Net variations.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-024-55864-2"
    },
    {
        "id": 14401,
        "title": "Retracted: A Segmentation Algorithm of Image Semantic Sequence Data Based on Graph Convolution Network",
        "authors": "",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9898176"
    },
    {
        "id": 14402,
        "title": "Depth-Aware Feature Pyramid Network for Semantic Segmentation",
        "authors": "Taehyeon Kim, Seho Park, Kyung-Taek Lee",
        "published": "2023-7-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icufn57995.2023.10199328"
    },
    {
        "id": 14403,
        "title": "XRANet: an extra-wide, residual and attention-based deep convolutional neural network for semantic segmentation",
        "authors": "Roger Booto Tokime, Moulay A. Akhloufi",
        "published": "2023-7-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2692337"
    },
    {
        "id": 14404,
        "title": "BASeg: Boundary aware semantic segmentation for autonomous driving",
        "authors": "Xiaoyang Xiao, Yuqian Zhao, Fan Zhang, Biao Luo, Lingli Yu, Baifan Chen, Chunhua Yang",
        "published": "2023-1",
        "citations": 20,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2022.10.034"
    },
    {
        "id": 14405,
        "title": "An Overview and Application of Deep Convolutional Neural Networks for Medical Image Segmentation",
        "authors": "Sanskruti Patel",
        "published": "2023-2-2",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icais56108.2023.10073857"
    },
    {
        "id": 14406,
        "title": "Semantic Communication System Based on Convolutional Neural Networks",
        "authors": "Jiawei Wang, Xiaohui Jia, Keyan Deng",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccasit58768.2023.10351623"
    },
    {
        "id": 14407,
        "title": "Ensembles of Convolutional Neural Networks and Transformers for Polyp Segmentation",
        "authors": "Loris Nanni, Carlo Fantozzi, Andrea Loreggia, Alessandra Lumini",
        "published": "2023-5-12",
        "citations": 4,
        "abstract": "In the realm of computer vision, semantic segmentation is the task of recognizing objects in images at the pixel level. This is done by performing a classification of each pixel. The task is complex and requires sophisticated skills and knowledge about the context to identify objects’ boundaries. The importance of semantic segmentation in many domains is undisputed. In medical diagnostics, it simplifies the early detection of pathologies, thus mitigating the possible consequences. In this work, we provide a review of the literature on deep ensemble learning models for polyp segmentation and develop new ensembles based on convolutional neural networks and transformers. The development of an effective ensemble entails ensuring diversity between its components. To this end, we combined different models (HarDNet-MSEG, Polyp-PVT, and HSNet) trained with different data augmentation techniques, optimization methods, and learning rates, which we experimentally demonstrate to be useful to form a better ensemble. Most importantly, we introduce a new method to obtain the segmentation mask by averaging intermediate masks after the sigmoid layer. In our extensive experimental evaluation, the average performance of the proposed ensembles over five prominent datasets beat any other solution that we know of. Furthermore, the ensembles also performed better than the state-of-the-art on two of the five datasets, when individually considered, without having been specifically trained for them.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23104688"
    },
    {
        "id": 14408,
        "title": "The Improved Fully Convolutional Network applied in Segmentation and Detection for Pavement Crack",
        "authors": "Qian Yang, Wenlong Wu, Yuezhi Yang, Wenchen Wu, Zhihao Su",
        "published": "2023-7-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3613330.3613343"
    },
    {
        "id": 14409,
        "title": "A Multi-Task Convolutional Neural Network for Semantic Segmentation and Event Detection in Laparoscopic Surgery",
        "authors": "Giorgia Marullo, Leonardo Tanzi, Luca Ulrich, Francesco Porpiglia, Enrico Vezzetti",
        "published": "2023-2-25",
        "citations": 8,
        "abstract": "The current study presents a multi-task end-to-end deep learning model for real-time blood accumulation detection and tools semantic segmentation from a laparoscopic surgery video. Intraoperative bleeding is one of the most problematic aspects of laparoscopic surgery. It is challenging to control and limits the visibility of the surgical site. Consequently, prompt treatment is required to avoid undesirable outcomes. This system exploits a shared backbone based on the encoder of the U-Net architecture and two separate branches to classify the blood accumulation event and output the segmentation map, respectively. Our main contribution is an efficient multi-task approach that achieved satisfactory results during the test on surgical videos, although trained with only RGB images and no other additional information. The proposed multi-tasking convolutional neural network did not employ any pre- or postprocessing step. It achieved a Dice Score equal to 81.89% for the semantic segmentation task and an accuracy of 90.63% for the event detection task. The results demonstrated that the concurrent tasks were properly combined since the common backbone extracted features proved beneficial for tool segmentation and event detection. Indeed, active bleeding usually happens when one of the instruments closes or interacts with anatomical tissues, and it decreases when the aspirator begins to remove the accumulated blood. Even if different aspects of the presented methodology could be improved, this work represents a preliminary attempt toward an end-to-end multi-task deep learning model for real-time video understanding.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/jpm13030413"
    },
    {
        "id": 14410,
        "title": "Semantic Queries with Transformer for Referring Image Segmentation",
        "authors": "Yukun Zhai",
        "published": "2023-6-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3605801.3605832"
    },
    {
        "id": 14411,
        "title": "Convolutional Neural Networks for Glioma Segmentation and Prognosis: A Systematic Review",
        "authors": "Janette Herr, Radka Stoyanova, Eric Mellon",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1615/critrevoncog.2023050852"
    },
    {
        "id": 14412,
        "title": "Segmentation and Classification of 3D Lung Tumor Diagnoses Using Convolutional Neural Networks",
        "authors": "S. Lalitha, D. Murugan",
        "published": "2023-8-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaiss58487.2023.10250625"
    },
    {
        "id": 14413,
        "title": "Convolutional neural networks for real-time wood plank detection and defect segmentation",
        "authors": "Mazhar Mohsin, Oluwafemi Samson Balogun, Keijo Haataja, Pekka Toivanen",
        "published": "2023-3-23",
        "citations": 1,
        "abstract": "Background: Defect detection and segmentation on product surfaces in industry has become one of the most important steps in quality control. There are many sophisticated hardware and software tools used in the industry for this purpose. The need for the real-time classification and detection of defects in industrial quality control has become a crucial requirement. Most algorithms and deep neural network architectures require expensive hardware to perform inference in real-time. This necessitates the design of architectures that are light-weight and suitable for deployment in industrial environments. Methods: In this study, we introduce a novel method for detecting wood planks on a fast-moving conveyor and using a convolutional neural network (CNN) to segment surface defects in real-time. A backbone network is trained with a large-scale image dataset. A dataset of 5000 images is created with proper annotation of wood planks and defects. In addition, a data augmentation technique is employed to enhance the accuracy of the model. Furthermore, we examine both statistical and deep learning-based approaches to identify and separate defects using the latest methods. Results: Our plank detection method achieved an impressive mean average precision of 97% and 96% of global pixel accuracy for defect segmentation. This remarkable performance is made possible by the real-time processing capabilities of our system, which can run at 30 frames per second (FPS) without sacrificing accuracy. Conclusions: The results of our study demonstrate the potential of our method not only in industrial wood processing applications but also in other industries where materials undergo similar processes of defect detection and segmentation. By utilizing our method, these industries can expect to see improved efficiency, accuracy, and overall productivity.",
        "keywords": "",
        "link": "http://dx.doi.org/10.12688/f1000research.131905.1"
    },
    {
        "id": 14414,
        "title": "Video segmentation of industrial smoke based on dynamic fully convolutional network-Gaussian mixture model and multi-scale fusion attention module",
        "authors": "Ding Wenyu, Liu Hui, Chen Fugang",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/1.jei.32.3.033038"
    },
    {
        "id": 14415,
        "title": "Advanced Liver Tumor Detection: Cascaded Fully Convolutional Neural Networks for Enhanced Precision",
        "authors": "S Balasubramanian, T Sampath, L Manikandan",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdsaai59313.2023.10452562"
    },
    {
        "id": 14416,
        "title": "Deep Learning for Medical Image Segmentation Using Convolutional Neural Networks",
        "authors": "Prabha S, Sachin Gupta, Sri Prakash Pandey",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470841"
    },
    {
        "id": 14417,
        "title": "Detection and Segmentation of Rice Diseases Using Deep Convolutional Neural Networks",
        "authors": "Chitranjan Kumar Rai, Roop Pahuja",
        "published": "2023-6-29",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42979-023-02014-6"
    },
    {
        "id": 14418,
        "title": "Contour Based Hand Segmentation Using Deep Convolutional Neural Networks",
        "authors": "Tsung-Han Tsai, Po-Ting Chi, Yuan-Chen Ho",
        "published": "2023-7-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icce-taiwan58799.2023.10226822"
    },
    {
        "id": 14419,
        "title": "Semantic segmentation of rodent burrows using deep convolutional\narchitectures",
        "authors": "Mikhail Uzdiaev, Marina Astapova, Maksim Letenkov",
        "published": "2023-1-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2669446"
    },
    {
        "id": 14420,
        "title": "Gabor Fully Convolutional Network and Ellipse Fitting Technique for Fetal Head Segmentation and Biometry Measurement",
        "authors": "Radhouane Rachdi, Hanene Sahli, Ahmed Zaafouri, Mounir Sayadi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijbet.2023.10062348"
    },
    {
        "id": 14421,
        "title": "Exploring Compact and Efficient Neural Networks for Real-Time Semantic Segmentation",
        "authors": "Zijia Li, ZhenZhong Xiao, Zhan Song",
        "published": "2023-9-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/itsc57777.2023.10421923"
    },
    {
        "id": 14422,
        "title": "Class Based Thresholding in Early Exit Semantic Segmentation Networks",
        "authors": "Alperen Görmez, Erdem Koyuncu",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/lsp.2024.3386110"
    },
    {
        "id": 14423,
        "title": "An efficient FPGA based convolutional neural networks by fully pipelined accelerator",
        "authors": "Vani Kasireddy, Suman Mishra",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0125188"
    },
    {
        "id": 14424,
        "title": "FatNet: High-Resolution Kernels for Classification Using Fully Convolutional Optical Neural Networks",
        "authors": "Riad Ibadulla, Thomas M. Chen, Constantino Carlos Reyes-Aldasoro",
        "published": "2023-4-3",
        "citations": 3,
        "abstract": "This paper describes the transformation of a traditional in silico classification network into an optical fully convolutional neural network with high-resolution feature maps and kernels. When using the free-space 4f system to accelerate the inference speed of neural networks, higher resolutions of feature maps and kernels can be used without the loss in frame rate. We present FatNet for the classification of images, which is more compatible with free-space acceleration than standard convolutional classifiers. It neglects the standard combination of convolutional feature extraction and classifier dense layers by performing both in one fully convolutional network. This approach takes full advantage of the parallelism in the 4f free-space system and performs fewer conversions between electronics and optics by reducing the number of channels and increasing the resolution, making this network faster in optics than off-the-shelf networks. To demonstrate the capabilities of FatNet, it was trained with the CIFAR100 dataset on GPU and the simulator of the 4f system. A comparison of the results against ResNet-18 shows 8.2 times fewer convolution operations at the cost of only 6% lower accuracy. This demonstrates that the optical implementation of FatNet results in significantly faster inference than the optical implementation of the original ResNet-18. These are promising results for the approach of training deep learning with high-resolution kernels in the direction toward the upcoming optics era.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ai4020018"
    },
    {
        "id": 14425,
        "title": "Memory-efficient semantic segmentation of large microscopy images using graph-based neural networks",
        "authors": "Atishay Jain, David H Laidlaw, Peter Bajcsy, Ritambhara Singh",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "Abstract\nWe present a graph neural network (GNN)–based framework applied to large-scale microscopy image segmentation tasks. While deep learning models, like convolutional neural networks (CNNs), have become common for automating image segmentation tasks, they are limited by the image size that can fit in the memory of computational hardware. In a GNN framework, large-scale images are converted into graphs using superpixels (regions of pixels with similar color/intensity values), allowing us to input information from the entire image into the model. By converting images with hundreds of millions of pixels to graphs with thousands of nodes, we can segment large images using memory-limited computational resources. We compare the performance of GNN- and CNN-based segmentation in terms of accuracy, training time and required graphics processing unit memory. Based on our experiments with microscopy images of biological cells and cell colonies, GNN-based segmentation used one to three orders-of-magnitude fewer computational resources with only a change in accuracy of ‒2 % to +0.3 %. Furthermore, errors due to superpixel generation can be reduced by either using better superpixel generation algorithms or increasing the number of superpixels, thereby allowing for improvement in the GNN framework’s accuracy. This trade-off between accuracy and computational cost over CNN models makes the GNN framework attractive for many large-scale microscopy image segmentation tasks in biology.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1093/jmicro/dfad049"
    },
    {
        "id": 14426,
        "title": "Disaster Remote Sensing Image Semantic Segmentation model with boundary constraints based on SegNeXt",
        "authors": "Ziquan Wang",
        "published": "2023-2-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nnice58320.2023.10105751"
    },
    {
        "id": 14427,
        "title": "Segmentation for Lumbar Spinal Stenosis Using Convolutional Neural Networks",
        "authors": "Abhinav Shukla, Saurabh Bhardwaj, Mandeep Singh",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.procs.2023.01.197"
    },
    {
        "id": 14428,
        "title": "Sleep Disorder Detection using Fully Convolutional Neural Networks for Sleep Arrhythmia Analysis",
        "authors": "M. Arun Kumar, Arvind Chakrapani",
        "published": "2023-10-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaeeci58247.2023.10370933"
    },
    {
        "id": 14429,
        "title": "Convolutional Neural Networks for the Segmentation of Coronary Arteries",
        "authors": "Milos Anic, Dimitrios Fotiadis, Vassiliki Potsika",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bibe60311.2023.00057"
    },
    {
        "id": 14430,
        "title": "FCCNs: Fully Complex-valued Convolutional Networks using Complex-valued Color Model and Loss Function",
        "authors": "Saurabh Yadav, Koteswar Rao Jerripothula",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00981"
    },
    {
        "id": 14431,
        "title": "An Urban Road Semantic Segmentation Method Based on Bilateral Segmentation Network",
        "authors": "Linshan Du, Ye Zhang, Bin Liu, He Yan",
        "published": "2023-2-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nnice58320.2023.10105801"
    },
    {
        "id": 14432,
        "title": "Prototype Comparison Convolutional Networks for One-Shot Segmentation",
        "authors": "Lingbo Li, Zhichun Li, Fusen Guo, Haoyu Yang, Jingtian Wei, Zhengyi Yang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2024.3387742"
    },
    {
        "id": 14433,
        "title": "Semantic Segmentation Using Y-Net Architecture for Change Detection on Hyperspectral Imagery",
        "authors": "Indira Bidari, Satyadhyan Chickerur, Srishti Kadam",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icscna58489.2023.10370098"
    },
    {
        "id": 14434,
        "title": "Semantic Segmentation Using U-Net Architecture for Change Detection on Hyperspectral Imagery",
        "authors": "Indira Bidari, Satyadhyan Chickerur, Srishti Kadam",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icscna58489.2023.10370358"
    },
    {
        "id": 14435,
        "title": "Application of Deep Neural Network Structures in Semantic Segmentation for Road Scene Understanding",
        "authors": " Qusay Sellat,  Kanagachidambaresan Ramasubramanian",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3103/s1060992x23020108"
    },
    {
        "id": 14436,
        "title": "Building a Fully-Automatized Active Learning Framework for the Semantic Segmentation of Geospatial 3D Point Clouds",
        "authors": "Michael Kölle, Volker Walter, Uwe Sörgel",
        "published": "2024-4-3",
        "citations": 0,
        "abstract": "AbstractIn recent years, significant progress has been made in developing supervised Machine Learning (ML) systems like Convolutional Neural Networks. However, it’s crucial to recognize that the performance of these systems heavily relies on the quality of labeled training data. To address this, we propose a shift in focus towards developing sustainable methods of acquiring such data instead of solely building new classifiers in the ever-evolving ML field. Specifically, in the geospatial domain, the process of generating training data for ML systems has been largely neglected in research. Traditionally, experts have been burdened with the laborious task of labeling, which is not only time-consuming but also inefficient. In our system for the semantic interpretation of Airborne Laser Scanning point clouds, we break with this convention and completely remove labeling obligations from domain experts who have completed special training in geosciences and instead adopt a hybrid intelligence approach. This involves active and iterative collaboration between the ML model and humans through Active Learning, which identifies the most critical samples justifying manual inspection. Only these samples (typically $$\\ll 1{\\%}$$\n\n≪\n1\n%\n\n of Passive Learning training points) are subject to human annotation. To carry out this annotation, we choose to outsource the task to a large group of non-specialists, referred to as the crowd, which comes with the inherent challenge of guiding those inexperienced annotators (i.e., “short-term employees”) to still produce labels of sufficient quality. However, we acknowledge that attracting enough volunteers for crowdsourcing campaigns can be challenging due to the tedious nature of labeling tasks. To address this, we propose employing paid crowdsourcing and providing monetary incentives to crowdworkers. This approach ensures access to a vast pool of prospective workers through respective platforms, ensuring timely completion of jobs. Effectively, crowdworkers become human processing units in our hybrid intelligence system mirroring the functionality of electronic processing units.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s41064-024-00281-3"
    },
    {
        "id": 14437,
        "title": "EFFECTS OF SEGMENTATION AND SCALING ON ANOMALY DETECTION USING CONVOLUTIONAL NEURAL NETWORKS",
        "authors": "Yash Nimish Padhye",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "Anomaly detection have been a successful technique in real world applications and mostly in industrial applications where precision is to be valued the most. Images are a day-to-day part of our lives, so here I have tried to present an approach for solving the issue of anomaly detection using Convolutional Neural Networks. The Neural network has been trained on diverse images of both anomalous images and Good (Normal) image. Neural Networks have been an integral and also emerged as a effective Deep Learning approach for tasks like image classification, anomaly detection and many such classification tasks. In recent years convolutional neural networks have been emerged as favorites for image classification tasks because of its various functionalities. The implications of this research are to present the effects of Scaling and Edge Preservation, Segmentation on images gives us different results of similar Neural network and to choose best of them. Thus, experimenting the Convolutional Neural Networks on different parameters yields us various results.  Key Words: Convolutional Neural Networks, Image Segmentation, Edge Preservation",
        "keywords": "",
        "link": "http://dx.doi.org/10.55041/ijsrem24917"
    },
    {
        "id": 14438,
        "title": "Y-Net: Convolutional Networks for Multi-Domain Image Segmentation",
        "authors": "Fenyong Li, Yizheng Lin, Xiangmin Li, Yuping Yang, LiHua Huang",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eei59236.2023.10212856"
    },
    {
        "id": 14439,
        "title": "Advancing Weather Image Classification Using Deep Convolutional Neural Networks",
        "authors": "Orestis Papadimitriou, Athanasios Kanavos, Phivos Mylonas, Manolis Maragoudakis",
        "published": "2023-9-25",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smap59435.2023.10255190"
    },
    {
        "id": 14440,
        "title": "Mapping Marine Macroalgae along the Norwegian Coast Using Hyperspectral UAV Imaging and Convolutional Nets for Semantic Segmentation",
        "authors": "Martin H. Skjelvareid, Eli Rinde, Kasper Hancke, Katalin Blix, Galice G. Hoarau",
        "published": "2023-7-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/igarss52108.2023.10282809"
    },
    {
        "id": 14441,
        "title": "A new real-time image semantic segmentation framework based on a lightweight deep convolutional encoder-decoder architecture for robotic environment sensing",
        "authors": "Yuxia Yuan, Yachao Zhang",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "Background: Image semantic segmentation can be understood as the allocation of a predefined category label to each pixel in the image to achieve the region segmentation of the image. Different categories in the image are identified with different colors. While achieving pixel classification, the position information of pixel points of different categories in the image is retained. Purpose: Due to the influence of background and complex environment, the traditional semantic segmentation methods have low accuracy. To alleviate the above problems, this paper proposes a new real-time image semantic segmentation framework based on a lightweight deep convolutional encoder-decoder architecture for robotic environment sensing. Methodology: This new framework is divided into three stages: encoding stage, decoding stage and dimension reduction stage. In the coding stage, a cross-layer feature map fusion (CLFMF) method is proposed to improve the effect of feature extraction. In the decoding stage, a new lightweight decoder (LD) structure is designed to reduce the number of convolutional layers to speed up model training and prediction. In the dimension reduction stage, the convolution dimension reduction method (CDR) is presented to connect the encoder and decoder layer by layer to enhance the decoder effect. Results: Compared with other state-of-the-art image semantic segmentation methods, we conduct comparison experiments on datasets Cityscapes, SUN RGB-D, CamVid, KITTI. The Category iIoU combined with the proposed method is more than 70%, and the Category IoU is as high as 89.7%. Conclusion: The results reflect that the new method can achieve the better semantic segmentation effect.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/jifs-222221"
    },
    {
        "id": 14442,
        "title": "Egyptian Hieroglyphs Segmentation with Convolutional Neural Networks",
        "authors": "Tommaso Guidi, Lorenzo Python, Matteo Forasassi, Costanza Cucci, Massimiliano Franci, Fabrizio Argenti, Andrea Barucci",
        "published": "2023-2-1",
        "citations": 4,
        "abstract": "The objective of this work is to show the application of a Deep Learning algorithm able to operate the segmentation of ancient Egyptian hieroglyphs present in an image, with the ambition to be as versatile as possible despite the variability of the image source. The problem is quite complex, the main obstacles being the considerable amount of different classes of existing hieroglyphs, the differences related to the hand of the scribe as well as the great differences among the various supports, such as papyri, stone or wood, where they are written. Furthermore, as in all archaeological finds, damage to the supports are frequent, with the consequence that hieroglyphs can be partially corrupted. In order to face this challenging problem, we leverage on the well-known Detectron2 platform, developed by the Facebook AI Research Group, focusing on the Mask R-CNN architecture to perform segmentation of image instances. Likewise, for several machine learning studies, one of the hardest challenges is the creation of a suitable dataset. In this paper, we will describe a hieroglyph dataset that has been created for the purpose of segmentation, highlighting its pros and cons, and the impact of different hyperparameters on the final results. Tests on the segmentation of images taken from public databases will also be presented and discussed along with the limitations of our study.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/a16020079"
    },
    {
        "id": 14443,
        "title": "Improvements to the Brain Tumor Segmentation and Classification System Using Convolutional Neural Networks",
        "authors": "Gaurav Kumar Verma, Shailendra Kumar",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "The analysis of medical imaging for the diagnosis and treatment of brain tumors must include the segmentation of the tumor. The complexity of the brain's structure and the heterogeneity of the tumors make it difficult to segment brain cancers from magnetic resonance imaging (MRI) pictures. Deep learning approaches have recently demonstrated encouraging outcomes in the segmentation of brain tumors from MRI images. Due to its capability to handle high-resolution pictures and segment the entire tumor region, the U-Net model is one of them and is frequently utilized. For the diagnosis and planning of brain tumor treatments, accurate segmentation of brain tumors using multi-contrast MRI images is essential. Deep learning models including U-Net, PSPNet, DeepLabV3+, and ResNet50 have demonstrated encouraging outcomes in the segmentation of brain tumors. With the use of the BraTS 2018 dataset, we compare these models in this research. We assess the models' performance using a variety of measures, including the Hausdorff Distance (HD), the Dice Similarity Coefficient (DSC), and the Absolute Volume Difference (AVD), and we look into how data augmentation and transfer learning approaches affect the models' effectiveness. The findings demonstrate that the 3D U-Net model, which had a DSC of 0.90, HD of 10.69mm, and AVD of 11.15%, had the best performance. Similar performance was attained by the PSPNet model, which had a DSC of 0.89, HD of 11.37mm, and AVD of 12.24%. Performance was lower for the DeepLabV3+ and ResNet50 models, with DSCs of 0.85 and 0.83, respectively. The 3D U- Net and PSPNet models in particular saw a considerable improvement in performance thanks to the data augmentation strategies. The performance of all models, especially the DeepLabV3+ and ResNet50 models, was greatly enhanced by the transfer learning technique as well. The 3D U-Net model with data augmentation and transfer learning is suggested for brain tumor segmentation using multi-contrast MRI images based on the findings and analyses. The study shows the potential of deep learning models for segmenting medical images and emphasizes the significance of using the best model and optimization methods for the particular application.",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/tjjpt.v44.i2.153"
    },
    {
        "id": 14444,
        "title": "Stochastic properties of coastal flooding events – Part 1: convolutional-neural-network-based semantic segmentation for water detection",
        "authors": "Byungho Kang, Rusty A. Feagin, Thomas Huff, Orencio Durán Vinent",
        "published": "2024-1-3",
        "citations": 1,
        "abstract": "Abstract. The frequency and intensity of coastal flooding is expected to accelerate in low-elevation coastal areas due to sea level rise. Coastal flooding due to wave overtopping affects coastal communities and infrastructure; however, it can be difficult to monitor in remote and vulnerable areas. Here we use a camera-based system to measure beach and back-beach flooding as part of the after-storm recovery of an eroded beach on the Texas coast. We analyze high-temporal resolution images of the beach using convolutional neural network (CNN)-based semantic segmentation to study the stochastic properties of flooding events. In the first part of this work, we focus on the application of semantic segmentation to identify water and overtopping events. We train and validate a CNN with over 500 manually classified images and introduce a post-processing method to reduce false positives. We find that the accuracy of CNN predictions of water pixels is around 90 % and strongly depends on the number and diversity of images used for training.\n                    ",
        "keywords": "",
        "link": "http://dx.doi.org/10.5194/esurf-12-1-2024"
    },
    {
        "id": 14445,
        "title": "Improving Semantic Segmentation Performance of Deep Networks for Autonomous Driving through Loss Functions",
        "authors": "Saquib Mazhar, Nadeem Atif, M. K. Bhuyan, S. R. Ahamad",
        "published": "2023-6-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/gcon58516.2023.10183416"
    },
    {
        "id": 14446,
        "title": "Hybrid Spiking Fully Convolutional Neural Network for Semantic Segmentation",
        "authors": "Tao Zhang, Shuiying Xiang, Wenzhuo Liu, Yanan Han, Xingxing Guo, Yue Hao",
        "published": "2023-8-23",
        "citations": 1,
        "abstract": "The spiking neural network (SNN) exhibits distinct advantages in terms of low power consumption due to its event-driven nature. However, it is limited to simple computer vision tasks because the direct training of SNNs is challenging. In this study, we propose a hybrid architecture called the spiking fully convolutional neural network (SFCNN) to expand the application of SNNs in the field of semantic segmentation. To train the SNN, we employ the surrogate gradient method along with backpropagation. The accuracy of mean intersection over union (mIoU) for the VOC2012 dataset is higher than that of existing spiking FCNs by almost 30%. The accuracy of mIoU can reach 39.6%. Moreover, the proposed hybrid SFCNN achieved excellent segmentation performance for other datasets such as COCO2017, DRIVE, and Cityscapes. Our hybrid SFCNN is a valuable and interesting contribution to extending the functionality of SNNs, especially for power-constrained applications.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12173565"
    },
    {
        "id": 14447,
        "title": "Senet: spatial information enhancement for semantic segmentation neural networks",
        "authors": "Yifang Huang, Peng Shi, Haitao He, Hongdou He, Bowen Zhao",
        "published": "2023-8-10",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00371-023-03043-1"
    },
    {
        "id": 14448,
        "title": "Multi-Scale Depth-Aware Unsupervised Domain Adaption in Semantic Segmentation",
        "authors": "Congying Xing, Lefei Zhang",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191271"
    },
    {
        "id": 14449,
        "title": "Design and Implementation of Brain Tumor Segmentation Using Convolutional Neural Networks in MRI Images",
        "authors": "Madhumitha R, R. Mohanabharathi",
        "published": "2024-3-5",
        "citations": 0,
        "abstract": "Functional magnetic resonance imaging (fMRI) is a neuroimaging technique that uses MRI technology to quantify brain activity by detecting changes in blood flow and applying the Blood-oxygen-level dependent (BOLD) contrast. Current neuroscience research suggests a modular brain structure. To understand the complex patterns of interaction between brain areas. The proposed system makes use of the CNN algorithm, which is an efficient method for dividing segmentation. A brain area is defined as a collection of subjects who exhibit a similar pattern of interaction between their brain areas. A thorough experimental examination utilizing benchmark data demonstrates that our technique is both effective and efficient. Two real-world fMRI studies found that the rifleman technique has the potential to improve comprehension of both normal brain activity and the abnormalities associated with psychiatric diseases. That is, mental diseases are typically defined by How an individual feels, acts, thinks, or perceives events. This is typically linked to specific areas or functions of the brain or the rest of the nervous system. This is unacceptable for a variety of time series sectors. As a result, we provide the statistical region merging approach, which is applied to picture segmentation. The method evaluates the values inside a regional range and combines them using the merging criteria, resulting in a smaller list. . As a result, we gather additional information and compare the findings to those already in the database. As a result, we decide if a person is normal or aberrant, as well as whether they are unwell.",
        "keywords": "",
        "link": "http://dx.doi.org/10.48001/joipir.2024.1118-23"
    },
    {
        "id": 14450,
        "title": "Multi-task learning for arousal and sleep stage detection using fully convolutional networks",
        "authors": "Hasan Zan, Abdulnasır Yildiz",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "Abstract\n\nObjective. Sleep is a critical physiological process that plays a vital role in maintaining physical and mental health. Accurate detection of arousals and sleep stages is essential for the diagnosis of sleep disorders, as frequent and excessive occurrences of arousals disrupt sleep stage patterns and lead to poor sleep quality, negatively impacting physical and mental health. Polysomnography is a traditional method for arousal and sleep stage detection that is time-consuming and prone to high variability among experts. Approach. In this paper, we propose a novel multi-task learning approach for arousal and sleep stage detection using fully convolutional neural networks. Our model, FullSleepNet, accepts a full-night single-channel EEG signal as input and produces segmentation masks for arousal and sleep stage labels. FullSleepNet comprises four modules: a convolutional module to extract local features, a recurrent module to capture long-range dependencies, an attention mechanism to focus on relevant parts of the input, and a segmentation module to output final predictions. Main results. By unifying the two interrelated tasks as segmentation problems and employing a multi-task learning approach, FullSleepNet achieves state-of-the-art performance for arousal detection with an area under the precision-recall curve of 0.70 on Sleep Heart Health Study and Multi-Ethnic Study of Atherosclerosis datasets. For sleep stage classification, FullSleepNet obtains comparable performance on both datasets, achieving an accuracy of 0.88 and an F1-score of 0.80 on the former and an accuracy of 0.83 and an F1-score of 0.76 on the latter. Significance. Our results demonstrate that FullSleepNet offers improved practicality, efficiency, and accuracy for the detection of arousal and classification of sleep stages using raw EEG signals as input.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1741-2552/acfe3a"
    },
    {
        "id": 14451,
        "title": "Can deep convolutional networks explain the semantic structure that humans see in photographs?",
        "authors": "Siddharth Suresh, Kushin Mukherjee, Timothy T. Rogers",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.5634"
    },
    {
        "id": 14452,
        "title": "Color-Difference Correntropy Guided Convolution Network for Point Cloud Semantic Segmentation",
        "authors": "Zhou Jiang, Jing Yang, Chunyu Xuan, Dong Zhang, Shaoyi Du",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191093"
    },
    {
        "id": 14453,
        "title": "Segmentation of 3D MRI Using 2D Convolutional Neural Networks in Infants’ Brain",
        "authors": "Hamed Karimi, Mohammad Hamghalam",
        "published": "2023-9-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-16790-z"
    },
    {
        "id": 14454,
        "title": "Fully-convolutional neural networks ensemble for comet segmentation in single cell gel electrophoresis assay images",
        "authors": "Daniel Ruz-Suarez, Anabel Martin-Gonzalez, Carlos Brito-Loeza, Victor Uc-Cetina",
        "published": "2023-9-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/21681163.2023.2203279"
    },
    {
        "id": 14455,
        "title": "Sea Ice Segmentation from SAR Data by Convolutional Transformer Networks",
        "authors": "Nicolae-Cătălin Ristea, Andrei Anghel, Mihai Datcu",
        "published": "2023-7-16",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/igarss52108.2023.10283427"
    },
    {
        "id": 14456,
        "title": "M-DDC: MRI based demyelinative diseases classification with U-Net segmentation and convolutional network",
        "authors": "Deyang Zhou, Lu Xu, Tianlei Wang, Shaonong Wei, Feng Gao, Xiaoping Lai, Jiuwen Cao",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.10.010"
    },
    {
        "id": 14457,
        "title": "Image-to-Image Translation on Defined Highlighting Regions by Semi-Supervised Semantic Segmentation",
        "authors": "Ching-Yu Chang, Chun-Ting Ye, Tzer-Jen Wei",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191189"
    },
    {
        "id": 14458,
        "title": "Semantic Segmentation of Spine and Femur Bone Using Atrous Spatial Pyramid Pooling-based U-Net with Fully Connected CRF",
        "authors": "Yuki Tani, Keiko Ono, Sohei Yamakawa, Shoma Yakushijin, Daisuke Tawara",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smc53992.2023.10394455"
    },
    {
        "id": 14459,
        "title": "DRSU-net: Depth-Residual Separable U-net model for Semantic Segmentation",
        "authors": "Mohamed Arbane, Mohamed Essaid Khanouche, Ghazaleh Khodabandelou, Chibani Abdelghani, Yacine Amirat",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191106"
    },
    {
        "id": 14460,
        "title": "Prototypical Contrastive Learning for Domain Adaptive Semantic Segmentation",
        "authors": "Quansheng Liu, Chengdao Pu, Fang Gao, Jun Yu",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191998"
    },
    {
        "id": 14461,
        "title": "Deep Multi - Resolution Network for Real- Time Semantic Segmentation in Street Scenes",
        "authors": "Yalun Wang, Shidong Chen, Huicong Bian, Weixiao Li, Qin Lu",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191758"
    },
    {
        "id": 14462,
        "title": "Image segmentation using convolutional neural networks in multi-sensor information fusion",
        "authors": "Wenying Zhang, Min Dong, Li Jiang",
        "published": "2023-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00500-023-09271-w"
    },
    {
        "id": 14463,
        "title": "Estimation of incomplete organ-coverage using 3D fully convolutional networks",
        "authors": "Hrishikesh Deshpande, Axel Saalbach, Tim Harder, Edna Coetser, Shlomo Gotman, Thomas Buelow, Christian Wülker",
        "published": "2023-4-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2653986"
    },
    {
        "id": 14464,
        "title": "3D Kronecker Convolutional Feature Pyramid for Brain Tumor Semantic Segmentation in MR Imaging",
        "authors": "Kainat Nazir, Tahir Mustafa Madni, Uzair Iqbal Janjua, Umer Javed, Muhammad Attique Khan, Usman Tariq, Jae-Hyuk Cha",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/cmc.2023.039181"
    },
    {
        "id": 14465,
        "title": "Fully Convolutional Network-Based Self-Supervised Learning for Semantic Segmentation",
        "authors": "Zhengeng Yang, Hongshan Yu, Yong He, Wei Sun, Zhi-Hong Mao, Ajmal Mian",
        "published": "2024-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2022.3172423"
    },
    {
        "id": 14466,
        "title": "Enhancing COVID-19 Diagnosis from Chest X-Ray Images Using Deep Convolutional Neural Networks",
        "authors": "Athanasios Kanavos, Orestis Papadimitriou, Manolis Maragoudakis",
        "published": "2023-9-25",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smap59435.2023.10255200"
    },
    {
        "id": 14467,
        "title": "Brain tumor segmentation using convolutional neural networks",
        "authors": "Syambabu Vadlamudi, B. Sridhar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0116212"
    },
    {
        "id": 14468,
        "title": "DDA-SSNets: Dual decoder attention-based semantic segmentation networks for COVID-19 infection segmentation and classification using chest X-Ray images",
        "authors": "Anandbabu Gopatoti, Ramya Jayakumar, Poornaiah Billa, Vijayalakshmi Patteeswaran",
        "published": "2024-4-6",
        "citations": 0,
        "abstract": "BACKGROUND: COVID-19 needs to be diagnosed and staged to be treated accurately. However, prior studies’ diagnostic and staging abilities for COVID-19 infection needed to be improved. Therefore, new deep learning-based approaches are required to aid radiologists in detecting and quantifying COVID-19-related lung infections. OBJECTIVE: To develop deep learning-based models to classify and quantify COVID-19-related lung infections. METHODS: Initially, Dual Decoder Attention-based Semantic Segmentation Networks (DDA-SSNets) such as Dual Decoder Attention-UNet (DDA-UNet) and Dual Decoder Attention-SegNet (DDA-SegNet) are proposed to facilitate the dual segmentation tasks such as lung lobes and infection segmentation in chest X-ray (CXR) images. The lung lobe and infection segmentations are mapped to grade the severity of COVID-19 infection in both the lungs of CXRs. Later, a Genetic algorithm-based Deep Convolutional Neural Network classifier with the optimum number of layers, namely GADCNet, is proposed to classify the extracted regions of interest (ROI) from the CXR lung lobes into COVID-19 and non-COVID-19. RESULTS: The DDA-SegNet shows better segmentation with an average BCSSDC of 99.53% and 99.97% for lung lobes and infection segmentations, respectively, compared with DDA-UNet with an average BCSSDC of 99.14% and 99.92%. The proposed DDA-SegNet with GADCNet classifier offered excellent classification results with an average BCCAC of 99.98%, followed by the GADCNet with DDA-UNet with an average BCCAC of 99.92% after extensive testing and analysis. CONCLUSIONS: The results show that the proposed DDA-SegNet has superior performance in the segmentation of lung lobes and COVID-19-infected regions in CXRs, along with improved severity grading compared to the DDA-UNet and improved accuracy of the GADCNet classifier in classifying the CXRs into COVID-19, and non-COVID-19.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/xst-230421"
    },
    {
        "id": 14469,
        "title": "Lightweight convolutional neural network models for semantic segmentation of in-field cotton bolls",
        "authors": "Naseeb Singh, V.K. Tewari, P.K. Biswas, L.K. Dhruw",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.aiia.2023.03.001"
    },
    {
        "id": 14470,
        "title": "Comprehensive mining of information in Weakly Supervised Semantic Segmentation: Saliency semantics and edge semantics",
        "authors": "Shaohui Wang, Youjia Shao, Na Tian, Wencang Zhao",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.10.009"
    },
    {
        "id": 14471,
        "title": "Weighted Sparse Convolutional Networks for Semantic Segmentation of 3-Dimensional Data",
        "authors": "Jung Su An, Young-Rae Cho",
        "published": "2023-9-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14801/jkiit.2023.21.9.153"
    },
    {
        "id": 14472,
        "title": "Crack Size Measurements on Fracture Surface Images Using Deep Neural Networks for Semantic Segmentation",
        "authors": "Johannes Rosenberger, Johannes Tlatlik, Sebastian Münstermann",
        "published": "2023-7-16",
        "citations": 0,
        "abstract": "Abstract\nFor the safe evaluation of nuclear-relevant safety components, a precise and reliable analysis of the fracture surfaces after the test procedure is required. Within the scope of the studies a framework for automated crack size measurements based on image segmentation has been developed, capable of accelerating the standardized but tedious measurement procedure. Different known image segmentation architectures have been trained and assessed based on a specially created fracture surface image dataset. The fracture surfaces originate from SE(B) specimens made of the German reactor pressure vessel steel 22NiMoCr3-7 and its weld material. The evaluation of the model performances via the mIoU metric show that the investigated architectures are very well suited for the pixel-fine classification of fracture mechanisms. Based on the obtained prediction masks, the initial crack size a0 could be measured using the so-called area average (AA) method. The results have been compared to manual 5-point average (5PA) measurements. The automated crack length measurements show statistically verifiable very high precision, comparability, and economic efficiency.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1115/pvp2023-106773"
    },
    {
        "id": 14473,
        "title": "Adaptive Canny and Semantic Segmentation Networks Based on Feature Fusion for Road Crack Detection",
        "authors": "Jie Luo, Huazhi Lin, Xiaoxu Wei, Yongsheng Wang",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3279888"
    },
    {
        "id": 14474,
        "title": "Beyond Pixel-Wise Unmixing: Spatial–Spectral Attention Fully Convolutional Networks for Abundance Estimation",
        "authors": "Jiaxiang Huang, Puzhao Zhang",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "Spectral unmixing poses a significant challenge within hyperspectral image processing, traditionally addressed by supervised convolutional neural network (CNN)-based approaches employing patch-to-pixel (pixel-wise) methods. However, such pixel-wise methodologies often necessitate image splitting into overlapping patches, resulting in redundant computations and potential information leakage between training and test samples, consequently yielding overoptimistic outcomes. To overcome these challenges, this paper introduces a novel patch-to-patch (patch-wise) framework with nonoverlapping splitting, mitigating the need for repetitive calculations and preventing information leakage. The proposed framework incorporates a novel neural network structure inspired by the fully convolutional network (FCN), tailored for patch-wise unmixing. A highly efficient band reduction layer is incorporated to reduce the spectral dimension, and a specialized abundance constraint module is crafted to enforce both the Abundance Nonnegativity Constraint and the Abundance Sum-to-One Constraint for unmixing tasks. Furthermore, to enhance the performance of abundance estimation, a spatial–spectral attention module is introduced to activate the most informative spatial areas and feature maps. Extensive quantitative experiments and visual assessments conducted on two synthetic datasets and three real datasets substantiate the superior performance of the proposed algorithm. Significantly, the method achieves an impressive RMSE loss of 0.007, which is at least 4.5 times lower than that of other baselines on Urban hyperspectral images. This outcome demonstrates the effectiveness of our approach in addressing the challenges of spectral unmixing.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/rs15245694"
    },
    {
        "id": 14475,
        "title": "Highly accurate tumour region segmentation from magnetic resonance images using customized convolutional neural networks",
        "authors": "B. Ramu, Sandeep Bansal",
        "published": "2023-4-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-15480-0"
    },
    {
        "id": 14476,
        "title": "A Hybrid Approach of Semantic Weight Based Re-Propagation For Convolutional Neural Networks in Content Based Medical Image Retrieval",
        "authors": "Gourav Sood",
        "published": "2023-4-29",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdcece57866.2023.10151427"
    },
    {
        "id": 14477,
        "title": "Semantic segmentation mask-guided diffusion models: A pathway to enriched datasets in autonomous systems",
        "authors": "Katica Bozsó, András Béres, Bálint Gyires-Tóth",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3311/wins2024-014"
    },
    {
        "id": 14478,
        "title": "Residual learning with annularly convolutional neural networks for classification and segmentation of 3D point clouds",
        "authors": "R. Hassan, M.M. Fraz, A. Rajput, M. Shahzad",
        "published": "2023-3",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neucom.2023.01.026"
    },
    {
        "id": 14479,
        "title": "Convolutional Neural Networks for Medical Image Segmentation and Classification: A\n      Review",
        "authors": "Jenifer S, Carmel Mary Belinda M J",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.61186/jist.37936.11.44.347"
    },
    {
        "id": 14480,
        "title": "Semi-Symmetrical, Fully Convolutional Masked Autoencoder for TBM Muck Image Segmentation",
        "authors": "Ke Lei, Zhongsheng Tan, Xiuying Wang, Zhenliang Zhou",
        "published": "2024-2-12",
        "citations": 0,
        "abstract": "Deep neural networks are effectively utilized for the instance segmentation of muck images from tunnel boring machines (TBMs), providing real-time insights into the surrounding rock condition. However, the high cost of obtaining quality labeled data limits the widespread application of this method. Addressing this challenge, this study presents a semi-symmetrical, fully convolutional masked autoencoder designed for self-supervised pre-training on extensive unlabeled muck image datasets. The model features a four-tier sparse encoder for down-sampling and a two-tier sparse decoder for up-sampling, connected via a conventional convolutional neck, forming a semi-symmetrical structure. This design enhances the model’s ability to capture essential low-level features, including geometric shapes and object boundaries. Additionally, to circumvent the trivial solutions in pixel regression that the original masked autoencoder faced, Histogram of Oriented Gradients (HOG) descriptors and Laplacian features have been integrated as novel self-supervision targets. Testing shows that the proposed model can effectively discern essential features of muck images in self-supervised training. When applied to subsequent end-to-end training tasks, it enhances the model’s performance, increasing the prediction accuracy of Intersection over Union (IoU) for muck boundaries and regions by 5.9% and 2.4%, respectively, outperforming the enhancements made by the original masked autoencoder.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/sym16020222"
    },
    {
        "id": 14481,
        "title": "An Efficient Brain Tumor Segmentation Approach Using Cascade Convolutional Neural Networks",
        "authors": "Ahmed Boudaka, Abdelrahman Hamed, Ahmed Hechri",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijbet.2023.10057111"
    },
    {
        "id": 14482,
        "title": "Watermark Detection in CMOS Image Sensors Using Cosine-Convolutional Semantic Networks",
        "authors": "Carlos Solorzano, Du-Ming Tsai",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tsm.2023.3245606"
    },
    {
        "id": 14483,
        "title": "Cascaded convolutional networks for unsupervised brain tissue segmentation and bias field estimation",
        "authors": "Hongming Li, Yong Fan",
        "published": "2023-9-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2676893"
    },
    {
        "id": 14484,
        "title": "Collaborative networks of transformers and convolutional neural networks are powerful and versatile learners for accurate 3D medical image segmentation",
        "authors": "Yong Chen, Xuesong Lu, Qinlan Xie",
        "published": "2023-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compbiomed.2023.107228"
    },
    {
        "id": 14485,
        "title": "A systematic review of retinal fundus image segmentation and classification methods using convolutional neural networks",
        "authors": "Ademola E. Ilesanmi, Taiwo Ilesanmi, Gbenga A. Gbotoso",
        "published": "2023-12",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.health.2023.100261"
    },
    {
        "id": 14486,
        "title": "Texture and semantic convolutional auto‐encoder for anomaly detection and segmentation",
        "authors": "Jintao Luo, Can Gao, Da Wan, Linlin Shen",
        "published": "2023-10",
        "citations": 1,
        "abstract": "AbstractAnomaly detection is a challenging task, especially detecting and segmenting tiny defect regions in images without anomaly priors. Although deep encoder‐decoder‐based convolutional neural networks have achieved good anomaly detection results, existing methods operate uniformly on all extracted image features without considering disentangling these features. To fully explore the texture and semantic information of images, A novel unsupervised anomaly detection method is proposed. Specifically, discriminative features are extracted from images by using a deep pre‐trained network, where shallow and deep features are aggregated into texture and semantic modules, respectively. Then, a feature fusion module is developed to interactively enable feature information in two different modules. The texture and semantic segmentation results are obtained by comparing the texture features and semantic features before and after reconstruction, respectively. Finally, an anomaly segmentation module is designed to generate anomaly detection results by integrating the results of the texture and semantic modules by setting a threshold. Experimental results on benchmark datasets for anomaly detection demonstrate that our proposed method can efficiently and effectively detect anomalies, outperforming some state‐of‐the‐art methods by 2.7% and 0.6% in classification and segmentation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12200"
    },
    {
        "id": 14487,
        "title": "Deep U-Net Architecture for Semantic Segmentation of Dental Carries",
        "authors": "Prathap Kumar Gorantla, Suryanarayana Gunnam, Rakesh Saripineni, Manusha Kaki, Sravani Dhanavath",
        "published": "2023-3-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iscon57294.2023.10111940"
    },
    {
        "id": 14488,
        "title": "High-Resolution Fine-Grained Wetland Mapping Based on Class-Balanced Deep Semantic Segmentation Networks",
        "authors": "Yingxin Wu, Yinhe Liu, Sunan Shi, Yanfei Zhong",
        "published": "2023-7-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/igarss52108.2023.10282910"
    },
    {
        "id": 14489,
        "title": "FGCN: Image-Fused Point Cloud Semantic Segmentation with Fusion Graph Convolutional Network",
        "authors": "Kun Zhang, Rui Chen, Zidong Peng, Yawei Zhu, Xiaohong Wang",
        "published": "2023-10-9",
        "citations": 0,
        "abstract": "In interpreting a scene for numerous applications, including autonomous driving and robotic navigation, semantic segmentation is crucial. Compared to single-modal data, multi-modal data allow us to extract a richer set of features, which is the benefit of improving segmentation accuracy and effect. We propose a point cloud semantic segmentation method, and a fusion graph convolutional network (FGCN) which extracts the semantic information of each point involved in the two-modal data of images and point clouds. The two-channel k-nearest neighbors (KNN) module of the FGCN was created to address the issue of the feature extraction’s poor efficiency by utilizing picture data. Notably, the FGCN utilizes the spatial attention mechanism to better distinguish more important features and fuses multi-scale features to enhance the generalization capability of the network and increase the accuracy of the semantic segmentation. In the experiment, a self-made semantic segmentation KITTI (SSKIT) dataset was made for the fusion effect. The mean intersection over union (MIoU) of the SSKIT can reach 88.06%. As well as the public datasets, the S3DIS showed that our method can enhance data features and outperform other methods: the MIoU of the S3DIS can reach up to 78.55%. The segmentation accuracy is significantly improved compared with the existing methods, which verifies the effectiveness of the improved algorithms.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23198338"
    },
    {
        "id": 14490,
        "title": "Image Enhancement of Cardiac MR motion Image for High-Quality Segmentation using combined Fuzzy Pooling Layer in Convolutional Neural Networks",
        "authors": "S B Tharun, S Jagatheswari",
        "published": "2023-8-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icoac59537.2023.10249287"
    },
    {
        "id": 14491,
        "title": "Multi-Scale Feature Map Aggregation and Supervised Domain Adaptation of Fully Convolutional Networks for Urban Building Footprint Extraction",
        "authors": "Jagannath Aryal, Bipul Neupane",
        "published": "2023-1-13",
        "citations": 8,
        "abstract": "Automated building footprint extraction requires the Deep Learning (DL)-based semantic segmentation of high-resolution Earth observation images. Fully convolutional networks (FCNs) such as U-Net and ResUNET are widely used for such segmentation. The evolving FCNs suffer from the inadequate use of multi-scale feature maps in their backbone of convolutional neural networks (CNNs). Furthermore, the DL methods are not robust in cross-domain settings due to domain-shift problems. Two scale-robust novel networks, namely MSA-UNET and MSA-ResUNET, are developed in this study by aggregating the multi-scale feature maps in U-Net and ResUNET with partial concepts of the feature pyramid network (FPN). Furthermore, supervised domain adaptation is investigated to minimise the effects of domain-shift between the two datasets. The datasets include the benchmark WHU Building dataset and a developed dataset with 5× fewer samples, 4× lower spatial resolution and complex high-rise buildings and skyscrapers. The newly developed networks are compared to six state-of-the-art FCNs using five metrics: pixel accuracy, adjusted accuracy, F1 score, intersection over union (IoU), and the Matthews Correlation Coefficient (MCC). The proposed networks outperform the FCNs in the majority of the accuracy measures in both datasets. Compared to the larger dataset, the network trained on the smaller one shows significantly higher robustness in terms of adjusted accuracy (by 18%), F1 score (by 31%), IoU (by 27%), and MCC (by 29%) during the cross-domain validation of MSA-UNET. MSA-ResUNET shows similar improvements, concluding that the proposed networks when trained using domain adaptation increase the robustness and minimise the domain-shift between the datasets of different complexity.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/rs15020488"
    },
    {
        "id": 14492,
        "title": "Redefining brain tumor segmentation: a cutting-edge convolutional neural networks-transfer learning approach",
        "authors": "Shoffan Saifullah, Rafał Dreżewski",
        "published": "2024-6-1",
        "citations": 0,
        "abstract": "Medical image analysis has witnessed significant advancements with deep learning techniques. In the domain of brain tumor segmentation, the ability to precisely delineate tumor boundaries from magnetic resonance imaging (MRI) scans holds profound implications for diagnosis. This study presents an ensemble convolutional neural network (CNN) with transfer learning, integrating the state-of-the-art Deeplabv3+ architecture with the ResNet18 backbone. The model is rigorously trained and evaluated, exhibiting remarkable performance metrics, including an impressive global accuracy of 99.286%, a high-class accuracy of 82.191%, a mean intersection over union (IoU) of 79.900%, a weighted IoU of 98.620%, and a Boundary F1 (BF) score of 83.303%. Notably, a detailed comparative analysis with existing methods showcases the superiority of our proposed model. These findings underscore the model’s competence in precise brain tumor localization, underscoring its potential to revolutionize medical image analysis and enhance healthcare outcomes. This research paves the way for future exploration and optimization of advanced CNN models in medical imaging, emphasizing addressing false positives and resource efficiency.",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijece.v14i3.pp2583-2591"
    },
    {
        "id": 14493,
        "title": "Fully Convolutional Networks for Dense Water Flow Intensity Prediction in Swedish Catchment Areas",
        "authors": "Aleksis Pirinen, Olof Mogren, Mårten Västerdal",
        "published": "2023-6-9",
        "citations": 0,
        "abstract": "Intensifying climate change will lead to more extreme weather events, including heavy rainfall and drought. Accurate streamflow prediction models which are adaptable and robust to new circumstances in a changing climate will be an important source of information for decisions on climate adaptation efforts, especially regarding mitigation of the risks of and damages associated with flooding. In this work we propose a machine learning-based approach for predicting water flow intensities in inland watercourses based on the physical characteristics of the catchment areas, obtained from geospatial data (including elevation and soil maps, as well as satellite imagery), in addition to temporal information about past rainfall quantities and temperature variations. We target the one-day-ahead regime, where a fully convolutional neural network model receives spatio-temporal inputs and predicts the water flow intensity in every coordinate of the spatial input for the subsequent day. To the best of our knowledge, we are the first to tackle the task of dense water flow intensity prediction; earlier works have considered the prediction of flow intensities at a sparse set of locations at a time. An extensive set of model evaluations and ablations are performed, which empirically justify our various design choices. Code and preprocessed data have been made publicly available at https://github.com/aleksispi/fcn-water-flow.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3384/ecp199002"
    },
    {
        "id": 14494,
        "title": "Automatic left ventricle segmentation via <scp>edge‐shape</scp> feature‐based fully convolutional neural network",
        "authors": "K. Gayathri, N. Uma Maheswari, R. Venkatesh, Ahilan Appathurai",
        "published": "2024-1",
        "citations": 0,
        "abstract": "AbstractLeft ventricle (LV) segmentation is essential to identify the cardiac functions for treating cardiovascular disorders. Cardiovascular magnetic resonance (CMRI) imaging is a non‐invasive technique for diagnosing cardiovascular diseases. CMRI is widely used to assess the functional integrity of the left and right ventricles for detecting changes in myocardial structure. Clinical parameters of the LV are often retrieved from CMRI scans, such as LV volumes, and ejection fraction. Moreover, manually segmenting cardiac diseases and evaluating such functions is time‐consuming and difficult for medical professionals. Deep learning networks require a lot of time, cost, and knowledge. To overcome this issue, a novel Edge and Shape feature‐based Fully Convolutional Neural Network (ES‐FCN) has been proposed for automatic LV segmentation. The ES‐FCN model segments MRI images based on edge maps instead of using gray‐scale images, which accelerates the performance of the FCN. The fuzzy‐based canny edge detection algorithm leverages fuzzy logic to detect structural changes in the LV and generate binary images. Additionally, binary‐valued kernels are used for convolution operations, where the binary values are influenced by biases derived from edge map shape descriptors. In ES‐FCN, bias values are learned from ground truth segmentation. The proposed ES‐FCN model achieves the Jaccard indices of 0.9484 ± 0.0188 for the ACDC dataset and 0.9476 ± 0.0237 for the LVSC dataset, and the dice index of 0.9319 ± 0.0188 for the ACDC dataset and 0.9314 ± 0.0237 for LVSC dataset respectively. The experimental results also reveal that the proposed ES‐FCN model is faster and requires minimal resources compared to state‐of‐the‐art models.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/ima.22947"
    },
    {
        "id": 14495,
        "title": "An adaptive watershed segmentation based medical image denoising using deep convolutional neural networks",
        "authors": "Ambika Annavarapu, Surekha Borra",
        "published": "2024-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.bspc.2024.106119"
    },
    {
        "id": 14496,
        "title": "U2ESPNet—A lightweight and high-accuracy convolutional neural network for real-time semantic segmentation of visible branches",
        "authors": "Hao Wan, Xilei Zeng, Zeming Fan, Shanshan Zhang, Meilin Kang",
        "published": "2023-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compag.2022.107542"
    },
    {
        "id": 14497,
        "title": "Traversability Learning from Aerial Images with Fully Convolutional Neural Networks",
        "authors": "Carlos David Braga Borges, Jarbas Joaci de Mesquita Sá Junior",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11063-023-11406-x"
    },
    {
        "id": 14498,
        "title": "Two-stage semantic segmentation in neural networks",
        "authors": "Diana Teixeira e Silva, Ricardo Cruz, Tiago Gonçalves, Diogo Carneiro",
        "published": "2023-6-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2679881"
    },
    {
        "id": 14499,
        "title": "Correction to: Highly accurate tumour region segmentation from magnetic resonance images using customized convolutional neural networks",
        "authors": "B. Ramu, Sandeep Bansal",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-18055-1"
    },
    {
        "id": 14500,
        "title": "A Survey on the Deployability of Semantic Segmentation Networks for Fluvial Navigation",
        "authors": "Reeve Lambert, Jianwen Li, Jalil Chavez-Galaviz, Nina Mahmoudian",
        "published": "2023-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacvw58289.2023.00032"
    },
    {
        "id": 14501,
        "title": "Fully-automatic aortic valve landmarks detection with two-stage-based convolutional neural networks",
        "authors": "Qixiang Ma, Léo Lemarchand, Diane Chan-Sock-Line, Louis Rigal, Antoine Simon, Pascal Haigron",
        "published": "2023-4-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2645635"
    },
    {
        "id": 14502,
        "title": "Fully Automated Analysis of the Anatomic and Mechanical Axes From Pediatric Standing Lower Limb Radiographs Using Convolutional Neural Networks",
        "authors": "Yousif Murad, Harpreet Chhina, Anthony Cooper",
        "published": "2024-4",
        "citations": 0,
        "abstract": "\nBackground:\nLower limb alignment is the quantification of a set of parameters that are commonly measured radiographically to test for and track a wide range of skeletal pathologies. Determining limb alignment is a commonly performed yet laborious task in the pediatric orthopaedic setting and is therefore an interesting goal for automation.\n\n\nMethods:\nWe employ a machine learning approach using convolutional neural networks (CNNs) to segment pediatric weight-bearing lower limb radiographs. The results are then used with custom Matlab code to extract anatomic landmarks and to determine lower limb alignment parameters.\n\n\nResults:\nMeasurements obtained from the automated workflow proposed here were compared with manual measurements performed by orthopaedic surgery fellows. Mechanical axis deviation was determined within a mean of 2.02 mm. Lateral distal femoral angle and medial proximal tibial angle were determined with a mean deviation of 1.73 and 2.90 degrees, respectively. The calculation speed for the full set of mechanical and anatomic axis parameters was found to be ~2 seconds per radiograph.\n\n\nConclusions:\nThe CNN-based approach proposed in this work was shown to produce results comparable to orthopaedic surgery fellows at fast calculation speed. Although further work is needed to validate these results against radiographs and measurements from other centers, we see this as a promising start and a functional path that can be employed in further research.\n\n\nClinical Relevance:\nCNNs are a promising approach to automating commonly performed, repetitive tasks, especially those pertaining to image processing. The time savings are particularly important in clinical research applications where large sets of radiographs are routinely available and require analysis. With further development of these algorithms, we anticipate significantly improved agreement with expert-measured results and the calculation speed.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.1097/bpo.0000000000002611"
    },
    {
        "id": 14503,
        "title": "Cell classification framework using U-Net: convolutional networks for cervix cell segmentation",
        "authors": "Tugce Ermis, Emre Sener, Meltem Elitas",
        "published": "2023-9-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2677423"
    },
    {
        "id": 14504,
        "title": "Fully automated imaging protocol independent system for pituitary adenoma segmentation: a convolutional neural network—based model on sparsely annotated MRI",
        "authors": "Martin Černý, Jan Kybic, Martin Májovský, Vojtěch Sedlák, Karin Pirgl, Eva Misiorzová, Radim Lipina, David Netuka",
        "published": "2023-5-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10143-023-02014-3"
    }
]