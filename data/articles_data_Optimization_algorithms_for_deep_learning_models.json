[
    {
        "id": 20171,
        "title": "Parameter Optimization of Deep Learning Models by Evolutionary Algorithms",
        "authors": "Levente Peto, Janos Botzheim",
        "published": "2019-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iwobi47054.2019.9114508"
    },
    {
        "id": 20172,
        "title": "Machine Learning, Deep Learning-Based Optimization in Multilayered Cloud",
        "authors": "Punit Gupta, Mayank Kumar Goyal",
        "published": "2022-1-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003185376-2"
    },
    {
        "id": 20173,
        "title": "Data Mining and Deep Learning",
        "authors": "Xin-She Yang",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-821986-7.00023-8"
    },
    {
        "id": 20174,
        "title": "Deep Learning in Radiology",
        "authors": "Madhura Ingalhalikar",
        "published": "2021-5-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2174/9781681088266121010005"
    },
    {
        "id": 20175,
        "title": "Bayesian Optimization",
        "authors": "Tanay Agrawal",
        "published": "2021",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6579-6_4"
    },
    {
        "id": 20176,
        "title": "Design and Analysis of Robust Deep Learning Models for Stock Price Prediction",
        "authors": "Jaydip Sen, Sidra Mehtab",
        "published": "2021-12-22",
        "citations": 3,
        "abstract": "Building predictive models for robust and accurate prediction of stock prices and stock price movement is a challenging research problem to solve. The well-known efficient market hypothesis believes in the impossibility of accurate prediction of future stock prices in an efficient stock market as the stock prices are assumed to be purely stochastic. However, numerous works proposed by researchers have demonstrated that it is possible to predict future stock prices with a high level of precision using sophisticated algorithms, model architectures, and the selection of appropriate variables in the models. This chapter proposes a collection of predictive regression models built on deep learning architecture for robust and precise prediction of the future prices of a stock listed in the diversified sectors in the National Stock Exchange (NSE) of India. The Metastock tool is used to download the historical stock prices over a period of two years (2013–2014) at 5 minutes intervals. While the records for the first year are used to train the models, the testing is carried out using the remaining records. The design approaches of all the models and their performance results are presented in detail. The models are also compared based on their execution time and accuracy of prediction.",
        "link": "http://dx.doi.org/10.5772/intechopen.99982"
    },
    {
        "id": 20177,
        "title": "Histopathological Image and Lymphoma Image Classification using customized Deep Learning models and different optimization algorithms",
        "authors": "Ambarish Ganguly, Rik Das, S. K. Setua",
        "published": "2020-7",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icccnt49239.2020.9225616"
    },
    {
        "id": 20178,
        "title": "Applications of Deep learning models in Bioinformatics",
        "authors": "Preeti Thareja, Rajender Singh Chhillar",
        "published": "2022-12-15",
        "citations": 0,
        "abstract": "Deep learning (DL) models have had an influence on machine learning-based in bioinformatics applications since they allow for the learning of complicated non-linear interactions between functionalities. Deep learning models also enable information utilized from large unlabeled data that is unrelated to the problem under investigation. Protein-protein interactions (PPIs) are important in a variety of biological functions, including cell signaling, immune function, and cellular organization. PPIs analysis is thus vital, as it may spotlight the detection of targeted proteins and their role in the disease and thus help in designing treatments for it. PPIs play critical roles in life processes, and abnormal interactions are linked to a variety of disorders. Identification of interaction sites is critical for understanding disease mechanisms and designing new drugs. Because of the overall cost of experimental methods, effective and efficient computational methods for PPI prediction are extremely valuable. Machine learning and deep learning techniques have produced remarkable results, but their efficacy is highly reliant on protein interpretation and feature extraction. This chapter will explain various deep learning models that can be used in Bioinformatics as well as the challenges they face.",
        "link": "http://dx.doi.org/10.36647/mlaida/2022.12.b1.ch009"
    },
    {
        "id": 20179,
        "title": "Deep Learning Model Optimization",
        "authors": "Jianfeng Ren",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-8040-6_2"
    },
    {
        "id": 20180,
        "title": "Hyperparameter Optimization in Machine Learning",
        "authors": "Tanay Agrawal",
        "published": "2021",
        "citations": 42,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6579-6"
    },
    {
        "id": 20181,
        "title": "Optimization of deep learning models for forecasting performance in the water industry using genetic algorithms",
        "authors": "Christian Kazadi Mbamba, Damien J. Batstone",
        "published": "2023-7",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.compchemeng.2023.108276"
    },
    {
        "id": 20182,
        "title": "Hyperparameter Optimization Using Scikit-Learn",
        "authors": "Tanay Agrawal",
        "published": "2021",
        "citations": 17,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6579-6_2"
    },
    {
        "id": 20183,
        "title": "Deep Learning Models for Object Detection in Self-Driven Cars",
        "authors": "Anish M. Lal, D. Aju",
        "published": "2021-7-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003038450-2"
    },
    {
        "id": 20184,
        "title": "Learning Algorithms",
        "authors": "Ekaba Bisong",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-4470-8_17"
    },
    {
        "id": 20185,
        "title": "Adaptation of nature inspired optimization algorithms for deep learning",
        "authors": "Yeshwant Singh, Anupam Biswas",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/bs.adcom.2023.12.005"
    },
    {
        "id": 20186,
        "title": "Zeroth-Order Optimization Attacks on Deep Reinforcement Learning-Based Lane Changing Algorithms for Autonomous Vehicles",
        "authors": "Dayu Zhang, Nasser Azad, Sebastian Fischmeister, Stefan Marksteiner",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012187700003543"
    },
    {
        "id": 20187,
        "title": "Analysis of Conventional Feature Learning Algorithms and Advanced Deep Learning Models",
        "authors": "Toshihiro Endo",
        "published": "2023-1-5",
        "citations": 0,
        "abstract": "Representation learning or feature learning refers to a collection of methods employed in machine learning, which allows systems to autonomously determine representations needed for classifications or feature detection from unprocessed data. Representation learning algorithms are specifically crafted to acquire knowledge of conceptual features that define data. The field of state representation learning is centered on a specific type of representation learning that involves the acquisition of low-dimensional learned features that undergo temporal evolution and are subject to the influence of an agent's actions. Over the past few years, deep architecture have been widely employed for representation learning and have demonstrated exceptional performance in various tasks, including but not limited to object detection, speech recognition, and image classification. This article provides a comprehensive overview of the evolution of techniques for data representation learning. Our research focuses on the examination of conventional feature learning algorithms and advanced deep learning models. This paper presents an introduction to data representation learning history, along with a comprehensive list of available resources such as online courses, tutorials, and books. Additionally, various tool-boxes are also provided for further exploration in this field. In conclusion, this article presents remarks and future prospects for data representation learning.",
        "link": "http://dx.doi.org/10.53759/9852/jrs202301001"
    },
    {
        "id": 20188,
        "title": "Sparse Nonlinear Dynamics Models with SINDy, Part 5: The Optimization Algorithms",
        "authors": "Steven L. Brunton",
        "published": "No Date",
        "citations": 0,
        "abstract": "This video discusses the various machine learning optimization schemes that may be used for the Sparse Identification of Nonlinear Dynamics (SINDy) algorithm. We discuss the LASSO sparse regression, sequential thresholded least squares (STLS), and the sparse relaxed regularized regression (SR3) algorithms. We also discuss how to enforce partially known physics, such as energy conservation in incompressible fluid flows, by constraining the sparse least squares regression.",
        "link": "http://dx.doi.org/10.52843/cassyni.f1bn05"
    },
    {
        "id": 20189,
        "title": "Ensemble Deep Learning Models for Forecasting Cryptocurrency Time-Series",
        "authors": "Ioannis E. Livieris, Emmanuel Pintelas, Stavros Stavroyiannis, Panagiotis Pintelas",
        "published": "2020-5-10",
        "citations": 73,
        "abstract": "Nowadays, cryptocurrency has infiltrated almost all financial transactions; thus, it is generally recognized as an alternative method for paying and exchanging currency. Cryptocurrency trade constitutes a constantly increasing financial market and a promising type of profitable investment; however, it is characterized by high volatility and strong fluctuations of prices over time. Therefore, the development of an intelligent forecasting model is considered essential for portfolio optimization and decision making. The main contribution of this research is the combination of three of the most widely employed ensemble learning strategies: ensemble-averaging, bagging and stacking with advanced deep learning models for forecasting major cryptocurrency hourly prices. The proposed ensemble models were evaluated utilizing state-of-the-art deep learning models as component learners, which were comprised by combinations of long short-term memory (LSTM), Bi-directional LSTM and convolutional layers. The ensemble models were evaluated on prediction of the cryptocurrency price on the following hour (regression) and also on the prediction if the price on the following hour will increase or decrease with respect to the current price (classification). Additionally, the reliability of each forecasting model and the efficiency of its predictions is evaluated by examining for autocorrelation of the errors. Our detailed experimental analysis indicates that ensemble learning and deep learning can be efficiently beneficial to each other, for developing strong, stable, and reliable forecasting models.",
        "link": "http://dx.doi.org/10.3390/a13050121"
    },
    {
        "id": 20190,
        "title": "Optimizing Speech Emotion Recognition with Deep Learning and Grey Wolf Optimization: A Multi-Dataset Approach",
        "authors": "Suryakant Tyagi, Sándor Szénási",
        "published": "2024-2-20",
        "citations": 0,
        "abstract": "Machine learning and speech emotion recognition are rapidly evolving fields, significantly impacting human-centered computing. Machine learning enables computers to learn from data and make predictions, while speech emotion recognition allows computers to identify and understand human emotions from speech. These technologies contribute to the creation of innovative human–computer interaction (HCI) applications. Deep learning algorithms, capable of learning high-level features directly from raw data, have given rise to new emotion recognition approaches employing models trained on advanced speech representations like spectrograms and time–frequency representations. This study introduces CNN and LSTM models with GWO optimization, aiming to determine optimal parameters for achieving enhanced accuracy within a specified parameter set. The proposed CNN and LSTM models with GWO optimization underwent performance testing on four diverse datasets—RAVDESS, SAVEE, TESS, and EMODB. The results indicated superior performance of the models compared to linear and kernelized SVM, with or without GWO optimizers.",
        "link": "http://dx.doi.org/10.3390/a17030090"
    },
    {
        "id": 20191,
        "title": "Learning deep models of optimization landscapes",
        "authors": "Shumeet Baluja",
        "published": "2017-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ssci.2017.8280793"
    },
    {
        "id": 20192,
        "title": "Fault-Aware Machine Learning and Deep Learning-Based Algorithm for Cloud Architecture",
        "authors": "Deepika Agarwal, Sneha Agrawal, Punit Gupta",
        "published": "2022-1-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003185376-7"
    },
    {
        "id": 20193,
        "title": "Generative Models in Deep Learning",
        "authors": "Sergey I. Nikolenko",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-75178-4_4"
    },
    {
        "id": 20194,
        "title": "Deep Learning Model Optimization",
        "authors": "Jianfeng Ren, Dong Xia",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-2897-2_8"
    },
    {
        "id": 20195,
        "title": "Probabilistic Optimization of Machine Learning Algorithms for Heart Disease Prediction",
        "authors": "Jaspreet Kaur, Bharti Joshi, Rajashree Shedge",
        "published": "2022-4-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119792673.ch1"
    },
    {
        "id": 20196,
        "title": "Neural Network and Deep Learning-Based Resource Allocation Model for Multilayered Cloud",
        "authors": "Sanjit Bhagat, Punit Gupta",
        "published": "2022-1-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003185376-5"
    },
    {
        "id": 20197,
        "title": "Machine Learning and Deep Learning Algorithms for Cancer Diagnostic Optimization",
        "authors": "IJSREM Journal",
        "published": "2022-10-13",
        "citations": 0,
        "abstract": "Recently, advances in machine learning and artificial intelligence have made these techniques increasingly prominent. Companies and institutions have begun investing in healthcare research to improve the accuracy of disease prediction because of its widespread popularity and effective pattern detection and categorization capabilities. However, there are numerous difficulties that arise while employing these methods. The lack of a huge data set for medical pictures is one of the biggest challenges. This study aims to provide a reasonable introduction to deep learning in medical image processing, beginning with theoretical foundations and progressing to practical implementations. Deep learning (DL) has become increasingly popular due to a number of computer science discoveries, according to a new study. To get a better grasp of neural networks, the next step was to familiarise ourselves with the principles. That's why convolutional neural networks (CNNs) and deep learning are used. This gives us a better idea of why deep learning is advancing so quickly in so many different application domains, including medical image processing. Key Words: Machine Learning, Deep Learning, CNN, Cancer, Algorithm, ANN.",
        "link": "http://dx.doi.org/10.55041/ijsrem15395"
    },
    {
        "id": 20198,
        "title": "Optimization algorithms and regularization techniques using deep learning",
        "authors": "M.K. Sharma, Tarun Kumar, Sadhna Chaudhary",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1049/pbhe049e_ch3"
    },
    {
        "id": 20199,
        "title": "Investigation of Heat Source Layout Optimization in Using Deep Learning Surrogate Models",
        "authors": "Ji Lang, Qianqian Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4499133"
    },
    {
        "id": 20200,
        "title": "Bio-inspired optimization algorithms for machine learning in agriculture applications",
        "authors": "P.R. MahiDar, Deepika Ghai",
        "published": "2021-1-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/b22627-4"
    },
    {
        "id": 20201,
        "title": "Meta-Heuristic Algorithms for Optimization",
        "authors": "K. Thippeswamy",
        "published": "2022-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003355960-8"
    },
    {
        "id": 20202,
        "title": "Investigation of Heat Source Layout Optimization by Using Deep Learning Surrogate Models",
        "authors": "Ji Lang, Qianqian Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4571129"
    },
    {
        "id": 20203,
        "title": "Real Estate Price Prediction Using Machine Learning Algorithms",
        "authors": "Palak Furia, Anand Khandare",
        "published": "2022-5-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119792437.ch2"
    },
    {
        "id": 20204,
        "title": "6G enabled UAV traffic management models using deep learning algorithms",
        "authors": "Gaojie Zhang",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11276-023-03485-4"
    },
    {
        "id": 20205,
        "title": "Optuna and AutoML",
        "authors": "Tanay Agrawal",
        "published": "2021",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6579-6_5"
    },
    {
        "id": 20206,
        "title": "Introduction to Hyperparameters",
        "authors": "Tanay Agrawal",
        "published": "2021",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6579-6_1"
    },
    {
        "id": 20207,
        "title": "Game theory, optimization algorithms and regularization techniques using deep learning in medical imaging",
        "authors": "Ali Hamidoğlu",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1049/pbhe049e_ch10"
    },
    {
        "id": 20208,
        "title": "Detection of Breast Cancer by Using Various Machine Learning and Deep Learning Algorithms",
        "authors": "Yogesh Jadhav, Harsh Mathur",
        "published": "2021-9-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003138020-3"
    },
    {
        "id": 20209,
        "title": "Optimization Algorithms and Classical Training Algorithms",
        "authors": "Mohammad Ehteram, Zohreh Sheikh Khozani, Saeed Soltani-Mohammadi, Maliheh Abbaszadeh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-8106-7_4"
    },
    {
        "id": 20210,
        "title": "Edge Computing Optimization Using Mathematical Modeling, Deep Learning Models, and Evolutionary Algorithms",
        "authors": "P. Vijayakumar, Prithiviraj Rajalingam, S. V. K. R. Rajeswari",
        "published": "2021-9-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119785521.ch2"
    },
    {
        "id": 20211,
        "title": "Deep Learning Models for Yoga Pose Monitoring",
        "authors": "Debabrata Swain, Santosh Satapathy, Biswaranjan Acharya, Madhu Shukla, Vassilis C. Gerogiannis, Andreas Kanavos, Dimitris Giakovis",
        "published": "2022-10-31",
        "citations": 12,
        "abstract": "Activity recognition is the process of continuously monitoring a person’s activity and movement. Human posture recognition can be utilized to assemble a self-guidance practice framework that permits individuals to accurately learn and rehearse yoga postures without getting help from anyone else. With the use of deep learning algorithms, we propose an approach for the efficient detection and recognition of various yoga poses. The chosen dataset consists of 85 videos with 6 yoga postures performed by 15 participants, where the keypoints of users are extracted using the Mediapipe library. A combination of Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) has been employed for yoga pose recognition through real-time monitored videos as a deep learning model. Specifically, the CNN layer is used for the extraction of features from the keypoints and the following LSTM layer understands the occurrence of sequence of frames for predictions to be implemented. In following, the poses are classified as correct or incorrect; if a correct pose is identified, then the system will provide user the corresponding feedback through text/speech. This paper combines machine learning foundations with data structures as the synergy between these two areas can be established in the sense that machine learning techniques and especially deep learning can efficiently recognize data schemas and make them interoperable.",
        "link": "http://dx.doi.org/10.3390/a15110403"
    },
    {
        "id": 20212,
        "title": "A Study of the Optimization Algorithms in Deep Learning",
        "authors": "Raniah Zaheer, Humera Shaziya",
        "published": "2019-1",
        "citations": 63,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icisc44355.2019.9036442"
    },
    {
        "id": 20213,
        "title": "Risk Parity Models for Portfolio Optimization: A Study of the Toronto Stock Exchange",
        "authors": "Dhanya Jothimani, Ayse Bener",
        "published": "2019-8",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/deep-ml.2019.00014"
    },
    {
        "id": 20214,
        "title": "Benchmark Assessment for Optimization Andacceleration Libraries in Deep Learning-Based Models",
        "authors": "Gongbo Liang, Izzat Alsmadi, Xin Xin",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nDeep Learning (DL) models are widely used in machine learning due to their performance and abilityto deal with large datasets while producing high accuracy and performance metrics. The size ofsuch datasets and the complexity of DL models cause such models to be complex, consuming largeamount of resources and time to train. Many recent libraries and applications are introduced todeal with DL complexity and efficiency issues. Neural network-based models have utilized stateof the art optimization and acceleration libraries to scale up the size of training datasets and thenumber of parameters in the models themselves. In this paper, we evaluated one example, MicrosoftDeepSpeed library through classification tasks. DeepSpeed public sources reported classificationperformance metrics on the LeNet architecture. We extended this through evaluating the libraryon several modern neural network architectures, including convolutional neural networks (CNNs)and Vision Transformer (ViT). Results indicated that neural network models for imaging tasks areimproved through using the DeepSpeed library in general.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1773886/v1"
    },
    {
        "id": 20215,
        "title": "Meta-Heuristic Algorithms for Power Efficiency in Cloud Computing",
        "authors": " Shally Vats, Sanjay Kumar Sharma, Sunil Kumar",
        "published": "2022-1-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003185376-9"
    },
    {
        "id": 20216,
        "title": "A Comparison of Machine Learning and Deep Learning Models with Advanced Word Embeddings: The Case of Internal Audit Reports",
        "authors": "Gustavo Fleury Soares, Induraj Pudhupattu Ramamurthy",
        "published": "2022-3-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119902881.ch6"
    },
    {
        "id": 20217,
        "title": "Design and Optimization of a Recommendation System Based on Deep Learning Algorithms",
        "authors": "",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.53469/jrse.2023.05(11).12"
    },
    {
        "id": 20218,
        "title": "Autoencoder-based Deep Learning Approach for Intrusion Detection System using Firefly Optimization Algorithms",
        "authors": "Narendra kumar Bukka, S. Jagadeesh, K Sivanagi Reddy",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIntrusion Detection System (IDS) is software that specializes in analysing activities that has taken place on a computer system and aims to uncover indications on whether the computer system has been maliciously misused. IDS are majorly classified into two categories such as anomaly-based and signature based. Signature based systems rely on having an understanding of manually identified patterns for which rules is defined for detecting them. Anomaly-based systems are systems that attempt to automatically identify anomalies from examples of normal data and perhaps abnormal data. Traditionally, several machine learning algorithms are used to find the anomalies in the network data. In last decade, researchers are shifted the attention to deep learning techniques to detect the anomalies in the different types of standard datasets. Unlike classification and regression tasks, there is no straightforward way to program neural networks to detect anomalies. In this work, a deep learning technique of autoencoders is used to detect the anomalies in the CSE-CIC IDS dataset. The autoencoders contains encoder and decoder networks. The encoder network compresses the input samples and decoder network reconstruct input from the compressed input samples. The autoencoder identify the anomalies based on the reconstruction error which is the amount of difference in original input sample and reconstructed sample. When the reconstruction error is higher than the threshold value the connection is treated as anomaly. The performance of autoencoder mainly depends on the features that are used in the encryption process of input samples. In this work, a firefly optimization algorithm is used as a feature selection algorithm to find the most relevant features for the experiment. The proposed autoencoder based deep learning approach attained best accuracy of 99.2% for intrusion detection.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-4076341/v1"
    },
    {
        "id": 20219,
        "title": "Predicting Student Performance Using Feature Selection Algorithms for Deep Learning Models",
        "authors": "Padilha Thereza P. P., Gernel Lumacad, Richard Catrambone",
        "published": "2021-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/laclo54177.2021.00009"
    },
    {
        "id": 20220,
        "title": "Solving Time and Memory Constraints",
        "authors": "Tanay Agrawal",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6579-6_3"
    },
    {
        "id": 20221,
        "title": "<scp>ML</scp>\n            Supervised Learning",
        "authors": "",
        "published": "2023-10-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781394209118.ch2"
    },
    {
        "id": 20222,
        "title": "Optimization Techniques in Deep Learning Scenarios: An Empirical Comparison",
        "authors": "Ajeet K. Jain, PVRD Prasad Rao, K. Venkatesh Sharma",
        "published": "2022-5-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119792437.ch11"
    },
    {
        "id": 20223,
        "title": "Development of lumbar spine MRI referrals vetting models using machine learning and deep learning algorithms: Comparison models vs healthcare professionals",
        "authors": "A.H. Alanazi, A. Cradock, L. Rainford",
        "published": "2022-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.radi.2022.05.005"
    },
    {
        "id": 20224,
        "title": "A Survey: Optimization Algorithms In Deep Learning",
        "authors": "Anshul Tripathi, Uday Chourasia, Shivendra Dubey, Arundhati Arjaria, Priyanka Dixit",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3564978"
    },
    {
        "id": 20225,
        "title": "Images Segmentation using Deep Learning Algorithms and Metaheuristics",
        "authors": "El Abassi Fouzia, Darouichi Aziz, Ouaarab Aziz",
        "published": "2022-10-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icoa55659.2022.9934130"
    },
    {
        "id": 20226,
        "title": "Heuristic hyperparameter optimization of deep learning models for genomic prediction",
        "authors": "Junjie Han, Cedric Gondro, Kenneth Reid, Juan P. Steibel",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractThere is a growing interest among quantitative geneticists and animal breeders in the use of deep learning (DL) for genomic prediction. However, the performance of DL is affected by hyperparameters that are typically manually set by users. These hyperparameters do not simply specify the architecture of the model, they are also critical for the efficacy of the optimization and model fitting process. To date, most DL approaches used for genomic prediction have concentrated on identifying suitable hyperparameters by exploring discrete options from a subset of the hyperparameter space. Enlarging the hyperparameter optimization search space with continuous hyperparameters is a daunting combinatorial problem. To deal with this problem, we propose using differential evolution (DE) to perform an efficient search of arbitrarily complex hyperparameter spaces in DL models and we apply this to the specific case of genomic prediction of livestock phenotypes. This approach was evaluated on two pig and cattle datasets with real genotypes and simulated phenotypes (N=7,539 animals and M=48,541 markers) and one real dataset (N=910 individuals and M=28,916 markers). Hyperparameters were evaluated using cross validation. We compared the predictive performance of DL models using hyperparameters optimized by DE against DL models with “best practice” hyperparameters selected from published studies and baseline DL models with randomly specified hyperparameters. Optimized models using DE showed clear improvement in predictive performance across all three datasets.DE optimized hyperparameters also resulted in DL models with less overfitting and less variation in predictive performance over repeated retraining compared to non-optimized DL models.",
        "link": "http://dx.doi.org/10.1101/2020.11.25.398800"
    },
    {
        "id": 20227,
        "title": "A Comprehensive Research on Deep Learning Based Routing Optimization Algorithms in Software Defined Networks",
        "authors": "Gaurav Kumar, Girisha G. S, Shamanth N",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/easct59475.2023.10392911"
    },
    {
        "id": 20228,
        "title": "SURROGATE MODEL OPTIMIZATION OF A ‘MICRO CORE’ PWR FUEL ASSEMBLY ARRANGEMENT USING DEEP LEARNING MODELS",
        "authors": "Andy Whyte, Geoff Parks",
        "published": "No Date",
        "citations": 0,
        "abstract": "This paper investigates the applicability of surrogate model optimization (SMO) usingdeep learning regression models to automatically embed knowledge about the objective function into the optimization process. This paper demonstrates two deep learning SMO methods for calculating simple neutronics parameters. Using these models, SMO returns results comparable with those from the early stages of direct iterative optimization. However, for this study, the cost of creating the training set outweighs the benefits of the surrogate models.",
        "link": "http://dx.doi.org/10.31224/osf.io/aq3dt"
    },
    {
        "id": 20229,
        "title": "EASE: Energy Optimization through Adaptation  – A Review of Runtime Energy-Aware Approximate Deep Learning Algorithms",
        "authors": "Salar Shakibhamedan, Amin Aminifar, Nima Taherinejad, Axel Jantsch",
        "published": "No Date",
        "citations": 0,
        "abstract": "This survey provides an overview of the state-of-the-art in runtime\nadaptive Approximate Computing (AxC) for Deep Learning (DL) algorithms,\nhighlighting the challenges and opportunities in the field. The survey\ncovers a broad spectrum of applications, including medical applications,\ncomputer vision, and natural language processing. Various\npower-constrained platforms, such as System-on-Chips (SoCs), Application\nSpecific Integrated Circuits (ASICs), and Field Programmable Gate Arrays\n(FPGAs), are explored for their utilization in implementing runtime\nadaptive AxC. The survey explores various techniques, such as dynamic\nquantization, adaptive pruning, and low-rank approximations, offering a\ndetailed discussion of their advantages and disadvantages. Specifically,\nin some surveyed research works, the runtime approximation is achieved\nthrough the utilization of machine learning algorithms, with a notable\nemphasis on Reinforcement Learning (RL). These approaches aim to realize\nruntime conditions and exploit them appropriately. By providing insights\ninto the advancements and trends in runtime adaptive AxC, this survey\nserves as a valuable resource for researchers and practitioners\ninterested in this rapidly evolving area of computing. This survey\nconducts an in-depth investigation into the application, challenges, and\nscope of runtime adaptive AxC techniques, aiming to mitigate energy\nconsumption while preserving acceptable levels of accuracy in DL models.\nOur primary focus lies on Convolutional Neural Networks (CNNs), with an\nemphasis on their application in diverse domains. In striving for\ncomprehensiveness, the survey encompasses selected research works that\nextend beyond CNNs, including alternative DL models like Recurrent\nNeural Networks (RNNs). our scope of applications, focuses on CNNs;\nhowever, to make a comprehensive survey, we cover some surveyed research\nworks that contain other DL models, such as RNNs. It also highlights the\nimportance of considering specific application requirements and\navailable resources when choosing the appropriate technique.",
        "link": "http://dx.doi.org/10.36227/techrxiv.170723230.09169589/v1"
    },
    {
        "id": 20230,
        "title": "Hybrid models based on deep learning neural network and optimization algorithms for the spatial prediction of tropical forest fire susceptibility in Nghe An province, Vietnam",
        "authors": "Huu Duy Nguyen",
        "published": "2022-12-13",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/10106049.2022.2048904"
    },
    {
        "id": 20231,
        "title": "Edge Intelligence in the Making: Optimization, Deep Learning, and Applications",
        "authors": "Sen Lin, Zhi Zhou, Zhaofeng Zhang, Xu Chen, Junshan Zhang",
        "published": "2020-10-20",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2200/s01054ed1v01y202009lna025"
    },
    {
        "id": 20232,
        "title": "Optimization for Machine Learning: Gradient Descent",
        "authors": "Ekaba Bisong",
        "published": "2019",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-4470-8_16"
    },
    {
        "id": 20233,
        "title": "Credit Scoring Using Deep Learning Driven by Optimization Algorithms",
        "authors": "Paul Diaconescu, Victor-Emil Neagoe",
        "published": "2020-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ecai50035.2020.9223139"
    },
    {
        "id": 20234,
        "title": "Deep Machine Learning of MobileNet, Efficient, and Inception Models",
        "authors": "Monika Rybczak, Krystian Kozakiewicz",
        "published": "2024-2-22",
        "citations": 0,
        "abstract": "Today, specific convolution neural network (CNN) models assigned to specific tasks are often used. In this article, the authors explored three models: MobileNet, EfficientNetB0, and InceptionV3 combined. The authors were interested in investigating how quickly an artificial intelligence model can be taught with limited computer resources. Three types of training bases were investigated, starting with a simple base verifying five colours, then recognizing two different orthogonal elements, followed by more complex images from different families. This research aimed to demonstrate the capabilities of the models based on training base parameters such as the number of images and epoch types. Architectures proposed by the authors in these cases were chosen based on simulation studies conducted on a virtual machine with limited hardware parameters. The proposals present the advantages and disadvantages of the different models based on the TensorFlow and Keras libraries in the Jupiter environment based on the Python programming language. An artificial intelligence model with a combination of MobileNet, proposed by Siemens, and Efficient and Inception, selected by the authors, allows for further work to be conducted on image classification, but with limited computer resources for industrial implementation on a programmable logical controller (PLC). The study showed a 90% success rate, with a learning time of 180 s.",
        "link": "http://dx.doi.org/10.3390/a17030096"
    },
    {
        "id": 20235,
        "title": "Edge-Cloud Collaborative Learning via Distributionally Robust Optimization",
        "authors": "Sen Lin, Zhi Zhou, Zhaofeng Zhang, Xu Chen, Junshan Zhang",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-02380-4_4"
    },
    {
        "id": 20236,
        "title": "Evolutionary Optimization of Hyperparameters in Deep Learning Models",
        "authors": "Jin-Young Kim, Sung-Bae Cho",
        "published": "2019-6",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cec.2019.8790354"
    },
    {
        "id": 20237,
        "title": "Deep Learning",
        "authors": "",
        "published": "2020-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7551/mitpress/11884.003.0009"
    },
    {
        "id": 20238,
        "title": "Pre-trained Deep Learning Models for UAV-based Weed Recognition",
        "authors": "Faiza Mekhalfa, Fouad Yacef, Mahmoud Belhocine",
        "published": "2023-9-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/spa59660.2023.10274449"
    },
    {
        "id": 20239,
        "title": "More on Optimization Techniques",
        "authors": "Ekaba Bisong",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-4470-8_33"
    },
    {
        "id": 20240,
        "title": "Waterflooding Optimization under Geological Uncertainties by Using Deep Reinforcement Learning Algorithms",
        "authors": "Hongze Ma, Gaoming Yu, Yuehui She, Yongan Gu",
        "published": "2019-9-23",
        "citations": 19,
        "abstract": "AbstractRecently, substantial technical progress has been made to solve complex tasks in the field of artificial intelligence (AI) by incorporating deep neural networks into reinforcement learning (RL). In this paper, four state-of-the-art deep RL algorithms are applied to optimize the net present value (NPV) of waterflooding (WF) under geological uncertainties by adjusting the water injection rate. They include the deep Q-network (DQN), double DQN (DDQN), dueling DDQN, and deep deterministic policy gradient (DDPG). A set of fifty reservoir realizations are generated by using a geostatistical technique to account for the geological uncertainties. It is found that the deep RL algorithms can optimize the WF in a 3-D 3-phase (oil-water-gas) reservoir under geological uncertainties. More specifically, both DQN and particle swarm optimization (PSO) converge to the same highest NPV, whereas the other three deep RL algorithms can find some local optimum NPVs due to the exploration-exploitation problem. DDPG converges faster than PSO and requires the least numerical simulation runs among all deep RL algorithms. The optimum water injection rate determined in the consideration of geological uncertainties not only increases the expected NPV but also reduces its standard deviation. The optimum WF starting time is found to be in the middle of the primary production. In this way, the solution-gas drive is continued and the water-cut is decreased. The production performances are compared under three different water injection scenarios: no-control, reactive-control, and optimum-control. The optimum-control scenario achieves a low water-cut and a stable oil production rate.",
        "link": "http://dx.doi.org/10.2118/196190-ms"
    },
    {
        "id": 20241,
        "title": "Optimization of Deep Learning Algorithms for Image Segmentation in High-Dimensional Data Environments",
        "authors": "",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18280/ts.400430"
    },
    {
        "id": 20242,
        "title": "Energy Efficiency Optimization in Clustered Wireless Sensor Networks via Machine Learning Algorithms",
        "authors": "T. Sudarson Rama Perumal, V. Muthumanikandan, S. Mohanalakshmi",
        "published": "2021-8-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003107477-4"
    },
    {
        "id": 20243,
        "title": "Distributed Optimization in Machine Learning",
        "authors": "Gauri Joshi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-19067-4_1"
    },
    {
        "id": 20244,
        "title": "Deep Learning Techniques for Crime Hotspot Detection",
        "authors": "Sankar N. Nair, E. S. Gopi",
        "published": "2020",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-15-0994-0_2"
    },
    {
        "id": 20245,
        "title": "Analysis on the latest research hotspots of computer deep learning optimization algorithms",
        "authors": "Xiaokang Guo",
        "published": "2022-9-30",
        "citations": 1,
        "abstract": "Deep learning can effectively learn the characteristics of data, which is of great significance to the development of artificial intelligence. This article first outlines the development of deep learning, then describes four typical deep learning algorithms, and then presents the progress of the current deep learning in the optimization of learning algorithms After a review, it finally discusses the advantages and disadvantages of deep learning in data analysis, model building, and algorithm optimization, as well as the problems that need to be further studied and resolved.",
        "link": "http://dx.doi.org/10.54097/hset.v9i.1732"
    },
    {
        "id": 20246,
        "title": "DeepOWT: A global offshore wind turbine data set derived with deep learning from Sentinel-1 data",
        "authors": "Thorsten Hoeser, Stefanie Feuerstein, Claudia Kuenzer",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract. Offshore wind energy is at the advent of a massive global expansion. Driven by carbon neutral alternatives for energy generation, offshore wind energy receives growing attention as a renewable energy source. Despite the large amount of unused wind energy capacities worldwide, offshore wind farms have to be integrated into already intensively used maritime economic areas. The optimal choice of offshore wind farm locations is as crucial as compatibility with other stakeholders while minimising ecological impacts. Thus, a spatiotemporal data set for offshore wind turbine deployment is necessary to involve all stakeholders and exchange knowledge during the upcoming massive expansion of offshore wind farms. To that end, we introduce the DeepOWT data set (global offshore wind turbines derived with deep learning; available at: https://doi.org/10.5281/zenodo.5933967  (Hoeser and Kuenzer, 2022), which provides 9,941 locations of offshore wind energy infrastructure along with their deployment stages on a global scale. DeepOWT is based on freely accessible Earth observation data from 2016 until 2021. The locations were derived from radar imagery of the Sentinel-1 mission by applying deep learning based object detection, trained on synthetic training examples. The entire deployment process is reported in a quarterly frequency and spatially contextualised for each single wind turbine location in a ready to use GIS format. Therewith, the DeepOWT data set can directly be used to enable spatial planning, environmental investigations and to optimise location decisions and the deployment process.\n                        ",
        "link": "http://dx.doi.org/10.5194/essd-2022-115"
    },
    {
        "id": 20247,
        "title": "Optimization of Deep Learning Classification Models Using Point Cloud Qube Query",
        "authors": "Guizhen He, Yiming Liu, Jie Yang, Yuxin Zhong, Yixin Lu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4654404"
    },
    {
        "id": 20248,
        "title": "Algorithms for the Development of Deep Learning Models for Classification and Prediction of Behaviour in MOOCS",
        "authors": "Jose Edmond Meku Fotso, Bernabe Batchakui, Roger Nkambou, George Okereke",
        "published": "2020-9-29",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/lwmoocs50143.2020.9234363"
    },
    {
        "id": 20249,
        "title": "Deep learning models",
        "authors": "KC Santosh, Nibaran Das, Swarnendu Ghosh",
        "published": "2022",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-823504-1.00013-1"
    },
    {
        "id": 20250,
        "title": "Exploration on Evaluation Methods Combining Psychological Algorithms and Deep Learning Models",
        "authors": "Juhua Yang, Lintao He",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icmnwc60182.2023.10435663"
    },
    {
        "id": 20251,
        "title": "An Exploration of the Optimization of Network Security Technology Based on Deep Learning Algorithms",
        "authors": "Shangtao Zhang",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "With the development of society into the information age, artificial intelligence is developing rapidly, and its influence on various industries through machine learning and deep learning cannot be underestimated. Machine learning, as a branch of the field of artificial intelligence, allows computers to autonomously learn from data while performing tasks, to achieve the purpose of strengthening the combination of man and machine to adapt to changes in the environment, and ultimately to enhance the ability to find problems and solve problems. With the continuous exploration and development in the field of computer learning, deep learning using neural network algorithms has emerged and gradually played a key role in the field of network security. Therefore, this paper discusses the optimization scheme of network security technology based on deep learning algorithm with the background of network security, in order to provide certain reference for the solution of network security technology problems.",
        "link": "http://dx.doi.org/10.56028/aetr.9.1.832.2024"
    },
    {
        "id": 20252,
        "title": "Learning deep",
        "authors": "",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.17875/gup2020-1338"
    },
    {
        "id": 20253,
        "title": "LSTM Deep Learning vs ARIMA Algorithms for Univariate Time Series Forecasting: A case study",
        "authors": "Jouilil Youness, Mentagui Driss",
        "published": "2022-10-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icoa55659.2022.9934119"
    },
    {
        "id": 20254,
        "title": "Bitcoin Price Prediction Using Machine Learning and Deep Learning Algorithms",
        "authors": "Bhavay Malhotra, Chittaranjan Chandwani, Pratham Agarwala, Suman Mann",
        "published": "2022-10-13",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icrito56286.2022.9964677"
    },
    {
        "id": 20255,
        "title": "Using deep learning for SAR image optimization",
        "authors": "Peter John-Baptiste, Edmund Zelnio, Graeme E. Smith",
        "published": "2018-4-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2305860"
    },
    {
        "id": 20256,
        "title": "Optimization Algorithms and Applications",
        "authors": "Wengang Zhang, Yanmei Zhang, Xin Gu, Chongzhi Wu, Liang Han",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-6835-7_5"
    },
    {
        "id": 20257,
        "title": "Deep learning and optimization algorithms based PV power forecast for an effective hybrid system energy management",
        "authors": "",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.20508/ijrer.v12i1.12608.g8382"
    },
    {
        "id": 20258,
        "title": "Investigating the Performance of Optimization Techniques on Deep Learning Models to Identify Dota2 Game Events",
        "authors": "Matheus Faria, Etienne Julia, Henrique Fernandes, Marcelo Zanchetta do Nascimento, Rita Julia",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011691800003417"
    },
    {
        "id": 20259,
        "title": "Deep Networks and Deep Learning Algorithms",
        "authors": "Tannu Kumari, Anjana Mishra",
        "published": "2020-10-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780367854737-12"
    },
    {
        "id": 20260,
        "title": "Comparing Deep Neural Networks to Traditional Models for Sentiment Analysis in Turkish Language",
        "authors": "Savaş Yildirim",
        "published": "2020",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-15-1216-2_12"
    },
    {
        "id": 20261,
        "title": "Foundation of Deep Machine Learning in Neural Networks",
        "authors": "Chih-Cheng Hung, Enmin Song, Yihua Lan",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-13773-1_9"
    },
    {
        "id": 20262,
        "title": "Towards Robustness: Enhancing Deep Learning Models Through Meta-Learning and Bilevel Optimization for Accurate Car Damage Classification",
        "authors": "Soufiane Mallem, Amir Nakib",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10222457"
    },
    {
        "id": 20263,
        "title": "Quality of Pre-trained Deep-Learning Models for Palmprint Recognition",
        "authors": "Valentin Rosca, Anca Ignat",
        "published": "2020-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/synasc51798.2020.00041"
    },
    {
        "id": 20264,
        "title": "Wind Turbine Control in Partial Load Operation by Using the Optimization Algorithms from the Deep Learning Techniques",
        "authors": "Adrian Gambier, Yul Yunazwin Nazaruddin",
        "published": "2022-11-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cacs55319.2022.9969794"
    },
    {
        "id": 20265,
        "title": "Optimization of Machine Learning and Deep Learning Algorithms for Diagnosis of Cancer",
        "authors": "Hari Krishna D, Anand M, Saravanan D, Pushpalatha K",
        "published": "2022-4-24",
        "citations": 2,
        "abstract": "Machine learning and artificial intelligence has recently become a prominent technology. Given its popularity and strength in pattern recognition and categorization, many corporations and institutions have begun investing in healthcare research to improve illness prediction accuracy. Using these strategies, however, has several drawbacks. One of the primary issues is the lack of huge datasets for medical pictures. An introduction to deep learning in medical image processing from theoretical foundations to real-world applications. The article examines the general appeal of deep learning (DL), a collection of computer science advances. The next step was to learn the basics of neural networks. That explains the use of deep learning and CNNs. So we can see why deep learning is rapidly advancing in various application fields, including medical image processing. The goal of this research was to use innovative methodologies on cancer datasets to explore the feasibility of combining machine learning and deep learning algorithms for cancer detection. This study used text and picture databases to classify cancer. This article provides optimization methods that outperform the suggested approaches' accuracy. Using two alternative training methods, Levenberg Marquardt (lm) and Resilient back propagation (rp), two classification algorithms were evaluated with different groups of neurons to identify benign and malignant patients. Cascade correlation utilizing the train (rp) outperformed feed forward back propagation using the train (lm). The second deep neural network model presented a technique (based on CNN) for automated brain tumor identification using MRI data.",
        "link": "http://dx.doi.org/10.1149/10701.9389ecst"
    },
    {
        "id": 20266,
        "title": "Combining Evolutionary Algorithms and Deep Learning for Hardware/Software Interface Optimization",
        "authors": "Lorenzo Servadei, Edoardo Mosca, Michael Werner, Volkan Esen, Robert Wille, Wolfgang Ecker",
        "published": "2019-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlcad48534.2019.9142090"
    },
    {
        "id": 20267,
        "title": "Learning Algorithms and Implementation",
        "authors": "Olga Krestinskaya, Alex Pappachen James",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-14524-8_7"
    },
    {
        "id": 20268,
        "title": "Edge Intelligence in the Making",
        "authors": "Sen Lin, Zhi Zhou, Zhaofeng Zhang, Xu Chen, Junshan Zhang",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-02380-4"
    },
    {
        "id": 20269,
        "title": "Machine learning and deep learning algorithms in disease prediction",
        "authors": "Prisilla Jayanthi",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824145-5.00009-5"
    },
    {
        "id": 20270,
        "title": "Mathematical Models and Algorithms for Power System Optimization",
        "authors": "",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/c2014-0-04257-8"
    }
]