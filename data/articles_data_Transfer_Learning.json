[
    {
        "id": 8001,
        "title": "Transfer Learning in Reinforcement Learning",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.010"
    },
    {
        "id": 8002,
        "title": "Adversarial Transfer Learning",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.009"
    },
    {
        "id": 8003,
        "title": "Transfer Learning Theory",
        "authors": "",
        "published": "2020-1-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.012"
    },
    {
        "id": 8004,
        "title": "Transitive Transfer Learning",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.013"
    },
    {
        "id": 8005,
        "title": "Heterogeneous Transfer Learning",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.008"
    },
    {
        "id": 8006,
        "title": "Relation-Based Transfer Learning",
        "authors": "",
        "published": "2020-1-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.007"
    },
    {
        "id": 8007,
        "title": "Instance-Based Transfer Learning",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.004"
    },
    {
        "id": 8008,
        "title": "Privacy-Preserving Transfer Learning",
        "authors": "",
        "published": "2020-1-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.018"
    },
    {
        "id": 8009,
        "title": "Model-Based Transfer Learning",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.006"
    },
    {
        "id": 8010,
        "title": "Feature-Based Transfer Learning",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.005"
    },
    {
        "id": 8011,
        "title": "Transfer Learning in Bioinformatics",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.023"
    },
    {
        "id": 8012,
        "title": "Transfer Learning in Dialogue Systems",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.021"
    },
    {
        "id": 8013,
        "title": "Transfer Learning in Recommender Systems",
        "authors": "",
        "published": "2020-1-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.022"
    },
    {
        "id": 8014,
        "title": "Transfer Learning in Computer Vision",
        "authors": "",
        "published": "2020-1-31",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.019"
    },
    {
        "id": 8015,
        "title": "Transfer Learning in Urban Computing",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.025"
    },
    {
        "id": 8016,
        "title": "AutoTL: Learning to Transfer Automatically",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.014"
    },
    {
        "id": 8017,
        "title": "Transfer Learning in Activity Recognition",
        "authors": "",
        "published": "2020-1-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.024"
    },
    {
        "id": 8018,
        "title": "Instance-based transfer learning",
        "authors": "Jindong Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-1109-7_2"
    },
    {
        "id": 8019,
        "title": "Feature-based transfer learning",
        "authors": "Jindong Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-1109-7_3"
    },
    {
        "id": 8020,
        "title": "Transfer Learning in Natural Language Processing",
        "authors": "",
        "published": "2020-1-31",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.020"
    },
    {
        "id": 8021,
        "title": "Parameter-based transfer learning",
        "authors": "Jindong Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-1109-7_4"
    },
    {
        "id": 8022,
        "title": "Transfer Learning via Representation Learning",
        "authors": "Mohammad Rostami, Hangfeng He, Muhao Chen, Dan Roth",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-11748-0_10"
    },
    {
        "id": 8023,
        "title": "Lifelong Machine Learning",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.016"
    },
    {
        "id": 8024,
        "title": "Multi-task Learning",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.011"
    },
    {
        "id": 8025,
        "title": "Few-Shot Learning",
        "authors": "",
        "published": "2020-1-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.015"
    },
    {
        "id": 8026,
        "title": "Multitask Learning or Transfer Learning? Application to Cancer Detection",
        "authors": "Stephen Obonyo, Daniel Ruiru",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008495805480555"
    },
    {
        "id": 8027,
        "title": "From Machine Learning to Transfer Learning",
        "authors": "Jindong Wang, Yiqiang Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-7584-4_2"
    },
    {
        "id": 8028,
        "title": "Transfer Learning, Multi-task Learning, Continual Learning, and Meta-learning",
        "authors": "",
        "published": "2022-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009072205.018"
    },
    {
        "id": 8029,
        "title": "Adversarial Transfer Learning",
        "authors": "Jindong Wang, Yiqiang Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-7584-4_10"
    },
    {
        "id": 8030,
        "title": "Deep Transfer Learning",
        "authors": "Jindong Wang, Yiqiang Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-7584-4_9"
    },
    {
        "id": 8031,
        "title": "Heat Transfer",
        "authors": "Naseem Uddin",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003428404-1"
    },
    {
        "id": 8032,
        "title": "Generalization in Transfer Learning",
        "authors": "Jindong Wang, Yiqiang Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-7584-4_11"
    },
    {
        "id": 8033,
        "title": "Overview of Transfer Learning Algorithms",
        "authors": "Jindong Wang, Yiqiang Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-7584-4_3"
    },
    {
        "id": 8034,
        "title": "Transfer Learning for Computer Vision",
        "authors": "Jindong Wang, Yiqiang Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-7584-4_15"
    },
    {
        "id": 8035,
        "title": "Transfer Learning for Speech Recognition",
        "authors": "Jindong Wang, Yiqiang Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-7584-4_17"
    },
    {
        "id": 8036,
        "title": "Safe and Robust Transfer Learning",
        "authors": "Jindong Wang, Yiqiang Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-7584-4_12"
    },
    {
        "id": 8037,
        "title": "Transfer Learning in Complex Environments",
        "authors": "Jindong Wang, Yiqiang Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-7584-4_13"
    },
    {
        "id": 8038,
        "title": "Transfer Learning for Activity Recognition",
        "authors": "Jindong Wang, Yiqiang Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-7584-4_18"
    },
    {
        "id": 8039,
        "title": "Modeling Individual Humans via a Secondary Task Transfer Learning Method",
        "authors": "Anmol Mahajan, Matthew Guzdial",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-11748-0_11"
    },
    {
        "id": 8040,
        "title": "Proposed Smart 5G Framework: Incorporating Federated Learning and Transfer Learning",
        "authors": "Peyman Khordadpour",
        "published": "No Date",
        "citations": 2,
        "abstract": "<p>This research aims to develop a secure and intelligent framework for 5G networks by incorporating federated learning (FL)<br>\nand transfer learning (TL) strategies. The primary objective is to enhance network evaluation metrics, such as capacity, service rate,<br>\nprivacy preservation, low latency, and energy consumption, in the selection of access networks. The proposed framework will tackle<br>\nexisting challenges in wireless communication systems, such as mobility, limited bandwidth, energy constraints, and limited feedback<br>\nfrom a receiver to a transmitter. The secondary objective is to address privacy preservation and scalability concerns during user<br>\nauthentication in 5G networks. The federated user authentication model leverages the privacy preservation benefits of FL and secure<br>\naggregation protocols during model averaging. The research methodology consists of five stages: literature review, classification of<br>\nobjectives, determination of state metrics, definition of evaluation functions, and selection of FL and RL techniques. The resulting<br>\nframework is expected to provide a robust, secure, and efficient solution for 5G networks, ensuring enhanced quality of service and<br>\noptimization </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22814831.v1"
    },
    {
        "id": 8041,
        "title": "Overcoming the failure of ‘silicon somewheres’: learning in policy transfer processes",
        "authors": "Sarah Giest",
        "published": "2020-1-15",
        "citations": 0,
        "abstract": "This chapter discusses the impact of different types of learning on the success and failure of the transfer of the famous Silicon Valley Model (SVM) of innovation. Working with the idea of ‘adaptive learning’, it underlines the importance of understanding the learning process, and critically, the depth of learning that underpins policy transfer. Policy transfer is ‘a process in which knowledge about policies, administrative arrangements, institutions and ideas in one political setting (past or present) is used in the development of policies, administrative arrangements, institutions and ideas in another political setting’. Thus, knowledge exchange is highly dependent on the setting it occurs in as well as on the individuals involved in the process. There are different degrees of transfer: copying, emulation, combinations, and inspiration. These categories move from direct and complete transfer to searching for inspiration to create policy change. The chapter looks at four cases to demonstrate how different learning processes generated by actors at the meso-level, mainly networks of stakeholders and experts, mediate the extent to which policy transfer is a success or failure.",
        "link": "http://dx.doi.org/10.1332/policypress/9781447352006.003.0003"
    },
    {
        "id": 8042,
        "title": "Multi-agent Transfer Learning in Reinforcement Learning-based Ride-sharing Systems",
        "authors": "Alberto Castagna, Ivana Dusparic",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010785200003116"
    },
    {
        "id": 8043,
        "title": "Transfer Learning",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_100487"
    },
    {
        "id": 8044,
        "title": "Proposed Smart 5G Framework: Incorporating Federated Learning and Transfer Learning",
        "authors": "Peyman Khordadpour",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>This research aims to develop a secure and intelligent framework for 5G networks by incorporating federated learning (FL)<br>\nand transfer learning (TL) strategies. The primary objective is to enhance network evaluation metrics, such as capacity, service rate,<br>\nprivacy preservation, low latency, and energy consumption, in the selection of access networks. The proposed framework will tackle<br>\nexisting challenges in wireless communication systems, such as mobility, limited bandwidth, energy constraints, and limited feedback<br>\nfrom a receiver to a transmitter. The secondary objective is to address privacy preservation and scalability concerns during user<br>\nauthentication in 5G networks. The federated user authentication model leverages the privacy preservation benefits of FL and secure<br>\naggregation protocols during model averaging. The research methodology consists of five stages: literature review, classification of<br>\nobjectives, determination of state metrics, definition of evaluation functions, and selection of FL and RL techniques. The resulting<br>\nframework is expected to provide a robust, secure, and efficient solution for 5G networks, ensuring enhanced quality of service and<br>\noptimization </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22814831"
    },
    {
        "id": 8045,
        "title": "Transfer Learning for Natural Language Processing",
        "authors": "Jindong Wang, Yiqiang Chen",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-7584-4_16"
    },
    {
        "id": 8046,
        "title": "Transfer Learning-Based Classification Comparison of Stroke",
        "authors": "Rusul Ali Jabbar ALHATEMİ, Serkan SAVAŞ",
        "published": "2022-9-16",
        "citations": 8,
        "abstract": "One type of brain disease that significantly harms people's lives and health is stroke. The diagnosis and management of strokes both heavily rely on the quantitative analysis of brain Magnetic Resonance (MR) images. The early diagnosis process is of great importance for the prevention of stroke cases. Stroke prediction is made possible by deep neural networks with the capacity for enormous data learning. Therefore, in thus study, several deep neural network models, including DenseNet121, ResNet50, Xception, MobileNet, VGG16, and EfficientNetB2 are proposed for transfer learning to classify MR images into two categories (stroke and non-stroke) in order to study the characteristics of the stroke lesions and achieve full intelligent automatic detection. The study dataset comprises of 1901 training images, 475 validation images, and 250 testing images. On the training and validation sets, data augmentation was used to increase the number of images to improve the models’ learning. The experimental results outperform all the state of arts that were used the same dataset. The overall accuracy of the best model is 98.8% and the same value for precision, recall, and f1-score using the EfficientNetB2 model for transfer learning.",
        "link": "http://dx.doi.org/10.53070/bbd.1172807"
    },
    {
        "id": 8047,
        "title": "Rethinking Importance Weighting for Transfer Learning",
        "authors": "Nan Lu, Tianyi Zhang, Tongtong Fang, Takeshi Teshima, Masashi Sugiyama",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-11748-0_9"
    },
    {
        "id": 8048,
        "title": "Convolutional Neural Network for Roadside Barriers Detection: Transfer Learning versus Non-Transfer Learning",
        "authors": "Mahdi Rezapour, Khaled Ksaibati",
        "published": "2021-2-1",
        "citations": 3,
        "abstract": "Increasingly more governmental organizations in the U.S. have started to implement artificial intelligence to enhance the asset management process with an objective of controlling the costs of data collection. To help the Wyoming Department of Transportation (WYDOT) to automate the data collections process, related to various assets in the state, an automated assets management data collection was proposed. As an example, the automated traffic barriers asset dataset would collect geometric characteristics, and barriers’ materials’ conditions, e.g., being rusty or not. The information would be stored and accessed for asset-management-decision-making and optimization process to fulfill various objectives such as traffic safety improvement, or assets’ enhancement. For instance, the State of Wyoming has more than a million feet of roadside barriers, worth more than 100 million dollars. One-time collection of various characteristics of those barriers has cost the state more than half a million dollars. Thus, this study, as a first step for comprehensive data collection, proposed a novel approach in identification of roadside barrier types. Pre-trained inception v3, denseNet 121, and VGG 19 were implemented in this study. Transfer learning was used as there were only 250 images for training of the dataset for each category. For that method, the topmost layers were removed, along with adding two more new layers while freezing the remaining layers. This study achieved an accuracy of 97% by the VGG 19 network, training only the few last layers of the model along with adding two dense layers for top layers. The results indicated that although there are not enough observations related to traffic barrier images, a transfer learning application could be considered in data collection. A simple architecture non-transfer model was also implemented. This model achieved an accuracy of 85%, being better that the two other transfer learning techniques. It should be reiterated that although non-transfer learning technique outperformed inception and denseNet networks, it comes short significantly when it come to the VGG network.",
        "link": "http://dx.doi.org/10.3390/signals2010007"
    },
    {
        "id": 8049,
        "title": "Federated Transfer Reinforcement Learning for Autonomous Driving",
        "authors": "Xinle Liang, Yang Liu, Tianjian Chen, Ming Liu, Qiang Yang",
        "published": "2023",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-11748-0_15"
    },
    {
        "id": 8050,
        "title": "Fault diagnosis and prognosis driven by deep transfer learning",
        "authors": "Ruqiang Yan, Fei Shen",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-99989-2.00001-3"
    },
    {
        "id": 8051,
        "title": "Transfer Learning für visuelle Kontrollaufgaben/Potentials of Transfer Learning",
        "authors": "Hubert Würschinger, Matthias Mühlbauer, Nico Hanenkamp",
        "published": "2020",
        "citations": 0,
        "abstract": "In der industriellen Praxis wird eine Vielzahl von Prozess- und Qualitätskontrollaufgaben visuell von Mitarbeitern oder mithilfe von Kamerasystemen durchgeführt. Durch den Einsatz Künstlicher Intelligenz (KI) lässt sich die Programmierung und damit die Implementierung von Kamerasystemen effizienter gestalten. Im Bereich der Bildanalyse können dabei vortrainierte Künstliche Neuronale Netze verwendet werden. Das Anwenden dieser Netze auf neue Aufgaben wird dabei Transfer Learning genannt.\n&nbsp;\nIn industrial practice, a large number of process and quality control tasks are performed visually by employees or with the aid of camera systems. By using artificial intelligence, the programming effort and thus the implementation of camera systems can be made more efficient. Pre-trained ^neural networks can be used for image analysis. The application of these networks to new tasks is called transfer learning. ",
        "link": "http://dx.doi.org/10.37544/1436-4980-2020-04-98"
    },
    {
        "id": 8052,
        "title": "An Introduction to Federated and Transfer Learning",
        "authors": "Roozbeh Razavi-Far, Boyu Wang, Matthew E. Taylor, Qiang Yang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-11748-0_1"
    },
    {
        "id": 8053,
        "title": "Transfer and Learning: Do They Go Together?",
        "authors": "David P. Dolowitz",
        "published": "2017-5-24",
        "citations": 0,
        "abstract": "While a phenomena dating back to antiquity, it wasn’t until the 1960s that American and European social scientists began seriously discussing occurrences in which it appeared as if localities, states and nations in close proximity were adopting similar policies and programs. These early diffusion studies led to a new field that has variously been referred to under titles such as policy transfer, lesson drawing, policy translations, and policy mobility. While having different focuses and agendas, all of these studies attempt to address issues associated with the movement (or active rejection of a possible movement) of ideas, information, policies, and programs from one political system to another.\nWhile all transfer studies have helped focus social scientists’ attention on the processes and actors involved in the transfer of ideas, techniques, policies, information, and programs, a better link to the knowledge utilization and learning literatures would help advance the usefulness of transfer studies. At a minimum, by considering the insights from the learning and utilization literatures, social scientists should begin understanding some of the outlook changes that individuals involved in transfer undertake that impact individual and institutional long-term understanding of the process and results. It will also start to help opening up the policymaking process to further scrutiny, particularly in relation to where information is flowing and how it is being used as a policy develops and changes.",
        "link": "http://dx.doi.org/10.1093/acrefore/9780190228637.013.269"
    },
    {
        "id": 8054,
        "title": "Foundations on transfer learning in machine fault diagnosis and prognosis",
        "authors": "Ruqiang Yan, Fei Shen",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-323-99989-2.00011-6"
    },
    {
        "id": 8055,
        "title": "Transfer Learning for Tabular Data",
        "authors": "Leonid Joffe",
        "published": "No Date",
        "citations": 1,
        "abstract": "Deep learning models for tabular data are restricted to a specific\ntable format. Computer vision models, on the other hand, have\na broader applicability; they work on all images and can learn\nuniversal features. This allows them to be trained on enormous\ncorpora and have very wide transferability and applicability.\nInspired by these properties, this work presents an architecture\nthat aims to capture useful patterns across arbitrary tables. The\nmodel is trained on randomly sampled subsets of features from\na table, processed by a convolutional network. This internal representation captures feature interactions that appear in the table.\nExperimental results show that the embeddings produced by this\nmodel are useful and transferable across many commonly used\nmachine learning benchmarks datasets. Specifically, that using the\nembeddings produced by the network as additional features, improves the performance of a number of classifiers.",
        "link": "http://dx.doi.org/10.36227/techrxiv.16974124.v1"
    },
    {
        "id": 8056,
        "title": "Transfer Learning for Tabular Data",
        "authors": "Leonid Joffe",
        "published": "No Date",
        "citations": 0,
        "abstract": "Deep learning models for tabular data are restricted to a specific\ntable format. Computer vision models, on the other hand, have\na broader applicability; they work on all images and can learn\nuniversal features. This allows them to be trained on enormous\ncorpora and have very wide transferability and applicability.\nInspired by these properties, this work presents an architecture\nthat aims to capture useful patterns across arbitrary tables. The\nmodel is trained on randomly sampled subsets of features from\na table, processed by a convolutional network. This internal representation captures feature interactions that appear in the table.\nExperimental results show that the embeddings produced by this\nmodel are useful and transferable across many commonly used\nmachine learning benchmarks datasets. Specifically, that using the\nembeddings produced by the network as additional features, improves the performance of a number of classifiers.",
        "link": "http://dx.doi.org/10.36227/techrxiv.16974124"
    },
    {
        "id": 8057,
        "title": "Index",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.027"
    },
    {
        "id": 8058,
        "title": "Preface",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.001"
    },
    {
        "id": 8059,
        "title": "From Theoretical to Practical Transfer Learning: The ADAPT Library",
        "authors": "Antoine de Mathelin, Francois Deheeger, Mathilde Mougeot, Nicolas Vayatis",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-11748-0_12"
    },
    {
        "id": 8060,
        "title": "Lyapunov Robust Constrained-MDPs for Sim2Real Transfer Learning",
        "authors": "Reazul Hasan Russel, Mouhacine Benosman, Jeroen van Baar, Radu Corcodel",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-11748-0_13"
    },
    {
        "id": 8061,
        "title": "Federated and Transfer Learning: A Survey on Adversaries and Defense Mechanisms",
        "authors": "Ehsan Hallaji, Roozbeh Razavi-Far, Mehrdad Saif",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-11748-0_3"
    },
    {
        "id": 8062,
        "title": "Review of metric learning with transfer learning",
        "authors": "Jiajun Pan",
        "published": "2017",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/1.4992857"
    },
    {
        "id": 8063,
        "title": "Pre-training and Transfer Learning",
        "authors": "",
        "published": "2021-1-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108332873.018"
    },
    {
        "id": 8064,
        "title": "Skin Cancer Detection using Multi ScaleDeep Learning and Transfer Learning",
        "authors": "Mohammadreza Hajiarbabi",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nSkin Cancer is on the rise and Melanoma is the most threatening typeamong the skin cancers. Early detection of skin cancer is vital in order toprevent the cancer to be spread to other parts. In this paper a transfer-learning based system is proposed for Melanoma lesions detection. In theproposed system first, the images are preprocessed for removing the noiseand illumination effect. In the next step a convolutional neural networkis trained based on transfer learning using the weights of ImageNet dataset. In the third step the network is fine-tuned to become more specializedfor detecting the Melanoma versus other types of benign cancers. Theproposed system uses the information from the image in 3 stages. In eachstage the focus will be more concentrate on the center on the image wherethe suspicious part is. The results from these parts are combined andapplied to a fully connected neural network. Results shows the superiorityof the proposed methods compare to other state-of-the arts methods.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2790927/v1"
    },
    {
        "id": 8065,
        "title": "Deep Transfer Learning in der Arbeitsplanung/Deep transfer learning in process planning – A concept for applying deep transfer learning in process planning using the example of manufacturing operations selection",
        "authors": "Marco Hussong, Moritz Glatt, Jan C. Aurich",
        "published": "2023",
        "citations": 0,
        "abstract": "Für die Nutzung von Deep Learning zur Unterstützung der Prozesse innerhalb der Arbeitsplanung wird eine Vielzahl von Daten benötigt. In der industriellen Praxis ist die Aufbereitung solcher Datensätze sehr komplex und mit hohen Aufwand verbunden. Durch die Nutzung von Deep Transfer Learning kann die benötigte Datenmenge reduziert werden. Am Beispiel der Fertigungsvorgangsermittlung wird ein Konzept vorgestellt, das die Anwendung von Deep Transfer Learning innerhalb der Arbeitsplanung ermöglicht. \n \nA large amount of data is required for the use of deep learning to support process planning. In industrial practice, the preparation of such data sets is very complex and requires a lot of manual effort. By using deep transfer learning, the required amount of data can be reduced. Therefore, using the example of manufacturing operation selection, a concept is introduced that enables the application of deep transfer learning within process planning.",
        "link": "http://dx.doi.org/10.37544/1436-4980-2023-06-16"
    },
    {
        "id": 8066,
        "title": "Corn Disease Detection Using Transfer Learning",
        "authors": "Cevher ÖZDEN",
        "published": "2023-10-15",
        "citations": 2,
        "abstract": "Detecting plant disease is a complicated yet important task to enable sustainable production in agriculture. Especially, early and on-field disease detection provides an opportunity to producers to take necessary precautions before it causes dramatic losses. Corn is one of the most important agricultural products for many countries around the world. It constitutes the main nutrient intake for large populations. This study examines and analyzes the applicability of the pretrained models in corn disease detection. A number of well-known pretrained models including Xception, ResNet50, VGG16, EfficientNetB0, MobileNet and InceptionV3 have been employed for this purpose. SMOTE is employed to solve the imbalanced data and resulting bias problem, which is a common problem in plant disease dataset. The study results indicate that SMOTE provides a good solution to the imbalanced data problem and MobileNet, VGG16 and Xception can be used as base models to develop AI applications to detect corn diseases.",
        "link": "http://dx.doi.org/10.34248/bsengineering.1322907"
    },
    {
        "id": 8067,
        "title": "Heat Transfer along Phase Change",
        "authors": "Naseem Uddin",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003428404-12"
    },
    {
        "id": 8068,
        "title": "Transfer learning",
        "authors": "Dimitrios Toumpanakis, Edward Chmiel",
        "published": "2019-7-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.53347/rid-69192"
    },
    {
        "id": 8069,
        "title": "Introduction",
        "authors": "",
        "published": "2020-1-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.003"
    },
    {
        "id": 8070,
        "title": "Fundamentals of Convective Heat Transfer",
        "authors": "Naseem Uddin",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003428404-7"
    },
    {
        "id": 8071,
        "title": "Intra-Agent Transfer Methods",
        "authors": "Felipe Leno da Silva, Anna Helena Reali Costa",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-01591-5_4"
    },
    {
        "id": 8072,
        "title": "Inter-Agent Transfer Methods",
        "authors": "Felipe Leno da Silva, Anna Helena Reali Costa",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-01591-5_5"
    },
    {
        "id": 8073,
        "title": "Sparse Time-Frequency Transform Via Deep Learning and Transfer Learning: Part Ii-Transfer Learning and Field Data Application",
        "authors": "Y. Zhang, N. Liu, Y. Yang, Z. Wang, J. Gao, X. Jiang",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3997/2214-4609.202210126"
    },
    {
        "id": 8074,
        "title": "Transfer of Learning in the Learning Society",
        "authors": "Knud Illeris",
        "published": "2018-10-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9781315620565-10"
    },
    {
        "id": 8075,
        "title": "Asymmetric Heterogeneous Transfer Learning: A Survey",
        "authors": "Magda Friedjungová, Marcel Jiřina",
        "published": "2017",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006396700170027"
    },
    {
        "id": 8076,
        "title": "Learning Transfer",
        "authors": "J. Kevin Ford",
        "published": "2020-11-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4324/9780429260018-7"
    },
    {
        "id": 8077,
        "title": "TRCLA: A Transfer Learning Approach to Reduce Negative Transfer for Cellular Learning Automata",
        "authors": "Seyyed Amir Hadi Minoofam, Azam Bastanfard, Mohammad Reza Keyvanpour",
        "published": "2023-5",
        "citations": 22,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tnnls.2021.3106705"
    },
    {
        "id": 8078,
        "title": "Using VGG19 Transfer Learning to Diagnose and Classify Brain Tumors Based on CNN, and Predict with Deep Learning-Based ANN Transfer Learning via MR Images",
        "authors": "Bitasadat Jamshidi, Mohsen Rostamy-Malkhalifeh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4624936"
    },
    {
        "id": 8079,
        "title": "Machine learning in heat transfer",
        "authors": "C. Balaji, Balaji Srinivasan, Sateesh Gedupudi",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-818503-2.00010-1"
    },
    {
        "id": 8080,
        "title": "Transfer Learning through Embedding Spaces",
        "authors": "Mohammad Rostami",
        "published": "2021-5-18",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003146032"
    },
    {
        "id": 8081,
        "title": "Review for \"A chemometrician's guide to transfer learning\"",
        "authors": "",
        "published": "2021-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/cem.3373/v1/review1"
    },
    {
        "id": 8082,
        "title": "Using Learning Analytics to Augment Feedback Processing and Transfer of Learning",
        "authors": "Nikki James",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3102/ip.23.2016285"
    },
    {
        "id": 8083,
        "title": "Deep Reinforcement Learning and Transfer Learning Methods Used in Autonomous Financial Trading Agents",
        "authors": "Ciprian Paduraru, Catalina Patilea, Stefan Iordache",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012194000003636"
    },
    {
        "id": 8084,
        "title": "Monitoring GLOFs via deep learning-based remote sensing and transfer learning",
        "authors": "Thomas Y. Chen",
        "published": "No Date",
        "citations": 0,
        "abstract": "As glacial melting and permafrost melting increase in intensity, regions with glaciers experience higher rates of flooding, which can cause immense economic loss and hundreds of lives lost in glacial lake outburst floods (GLOFs). By training a convolutional neural network (CNN) for this problem on multitemporal satellite imagery, we propose enabling deployable technologies that predict GLOF events and impacts on surrounding areas. In particular, we collect high-resolution satellite imagery data from previous GLOFs around the world, such as in Iceland, Alaska (United States), Pakistan, and Tibet, utilizing repositories provided by ESA and NASA. We curate a dataset based on paired images (pre- and post-GLOF). In this way, we can train the CNN on the change detected between these two instances, which can further aid in predictions in the form of an output from 0 to 10 indicating the severity of damage caused. However, because machine learning algorithms require a large quantity of data, we must also employ transfer learning. We propose a Markov logic network framework to achieve this, incorporating data from events that were not necessarily GLOFs but included glacial movement and/or flooding. When deployed, models like the one we propose can allow for both the monitoring of GLOFs in action as well as predict GLOFs in the near future by assessing changes using data collected from satellites in real time.&#160;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-11207"
    },
    {
        "id": 8085,
        "title": "Concluding Remarks",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.026"
    },
    {
        "id": 8086,
        "title": "Introduction to transfer learning",
        "authors": "Jindong Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-1109-7"
    },
    {
        "id": 8087,
        "title": "Review for \"A chemometrician's guide to transfer learning\"",
        "authors": "",
        "published": "2021-5-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/cem.3373/v1/review2"
    },
    {
        "id": 8088,
        "title": "Improving Remote Sensing Classification with Transfer Learning: Exploring the Impact of Heterogenous Transfer Learning",
        "authors": "Maria Rouba, Mohammed El Amin Larabi",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3390/asec2023-15505"
    },
    {
        "id": 8089,
        "title": "Classification of Skin Cancer with Deep Transfer Learning Method",
        "authors": "Doaa Khalid Abdulridha AL-SAEDİ, Serkan SAVAŞ",
        "published": "2022-9-16",
        "citations": 4,
        "abstract": "Skin cancer is a serious health hazard for human society. This disease is developed when the pigments that produce skin color become cancerous. Dermatologists face difficulties in diagnosing skin cancer since many skin cancer colors seem identical. As a result, early diagnosis of lesions (the foundation of skin cancer) is very crucial and beneficial in totally curing skin cancer patients. Significant progress has been made in creating automated methods with the development of artificial intelligence (AI) technologies to aid dermatologists in the identification of skin cancer. The widespread acceptance of AI-powered technologies has enabled the use of a massive collection of photos of lesions and benign sores authorized by histology. This research compares six alternative transfer learning networks (deep networks) for skin cancer classification using the International Skin Imaging Collaboration (ISIC) dataset. DenseNet, Xception, InceptionResNetV2, ResNet50, and MobileNet were the transfer learning networks employed in the investigation which were successful in different studies recently. To compensate for the imbalance in the ISIC dataset, the photos of classes with low frequencies are augmented. The results show that augmentation is appropriate for the classification success, with high classification accuracies and F-scores with decreased false negatives. With an accuracy rate of 98.35%, modified DenseNet121 was the most successful model against the rest of the transfer learning nets utilized in the study.",
        "link": "http://dx.doi.org/10.53070/bbd.1172782"
    },
    {
        "id": 8090,
        "title": "Chapter 2. L2 writing and L2 learning: Transfer, self-regulation, and identities",
        "authors": "Alister Cumming",
        "published": "2020-11-15",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1075/lllt.56.02cum"
    },
    {
        "id": 8091,
        "title": "Numerical Weather Forecast Post-processing with Ensemble Learning and Transfer Learning",
        "authors": "Yuwen Chen, Xiaomeng Huang",
        "published": "No Date",
        "citations": 1,
        "abstract": "\n        &lt;p&gt;Statistical approaches have been used for decades to augment and interpret numerical weather forecasts. The emergence of artificial intelligence algorithms has provided new perspectives in this field, but the extension of algorithms developed for station networks with rich historical records to include newly-built stations remains a challenge. To address this, we design a framework that combines two machine learning methods: temperature prediction based on ensemble of multiple machine learning models and transfer learning for newly-built stations. We then evaluate this framework by post-processing temperature forecasts provided by a leading weather forecast center and observations from 301 weather stations in China. Station clustering reduces forecast errors by 24.4% averagely, while transfer learning improves predictions by 13.4% for recently-built sites with only one year of data available. This work demonstrates how ensemble learning and transfer learning can be used to supplement weather forecasting.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;\n        ",
        "link": "http://dx.doi.org/10.5194/egusphere-egu2020-3885"
    },
    {
        "id": 8092,
        "title": "Transfer Learning Technique to Enhance High School Learning Capability",
        "authors": "Mumta Lulwani, Ramesh Tahrpaa",
        "published": "No Date",
        "citations": 0,
        "abstract": "Transfer Learning Technique to Enhance High School LearningCapability",
        "link": "http://dx.doi.org/10.31219/osf.io/jwbh7"
    },
    {
        "id": 8093,
        "title": "Machine Learning on Biomedical Images: Interactive Learning, Transfer Learning, Class Imbalance, and Beyond",
        "authors": "Naimul Khan, Nabila Abraham, Marcia Hon, Ling Guan",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In this paper, we highlight three issues that limit performance of machine learning on biomedical images, and tackle them through 3 case studies: 1) Interactive Machine Learning (IML): we show how IML can drastically improve exploration time and quality of direct volume rendering. 2) transfer learning: we show how transfer learning along with intelligent pre-processing can result in better Alzheimer's diagnosis using a much smaller training set 3) data imbalance: we show how our novel focal Tversky loss function can provide better segmentation results taking into account the imbalanced nature of segmentation datasets. The case studies are accompanied by in-depth analytical discussion of results with possible future directions.</p>",
        "link": "http://dx.doi.org/10.32920/22734299"
    },
    {
        "id": 8094,
        "title": "Parameter-Transfer Learning for Low-Resource Individualization of Head-Related Transfer Functions",
        "authors": "Xiaoke Qi, Lu Wang",
        "published": "2019-9-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2019-2558"
    },
    {
        "id": 8095,
        "title": "Machine Learning on Biomedical Images: Interactive Learning, Transfer Learning, Class Imbalance, and Beyond",
        "authors": "Naimul Khan, Nabila Abraham, Marcia Hon, Ling Guan",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In this paper, we highlight three issues that limit performance of machine learning on biomedical images, and tackle them through 3 case studies: 1) Interactive Machine Learning (IML): we show how IML can drastically improve exploration time and quality of direct volume rendering. 2) transfer learning: we show how transfer learning along with intelligent pre-processing can result in better Alzheimer's diagnosis using a much smaller training set 3) data imbalance: we show how our novel focal Tversky loss function can provide better segmentation results taking into account the imbalanced nature of segmentation datasets. The case studies are accompanied by in-depth analytical discussion of results with possible future directions.</p>",
        "link": "http://dx.doi.org/10.32920/22734299.v1"
    },
    {
        "id": 8096,
        "title": "Review for \"Transfer Learning for a Foundational Chemistry Model\"",
        "authors": "",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1039/d3sc04928k/v1/review2"
    },
    {
        "id": 8097,
        "title": "Review for \"Transfer Learning for a Foundational Chemistry Model\"",
        "authors": "",
        "published": "2023-10-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1039/d3sc04928k/v1/review1"
    },
    {
        "id": 8098,
        "title": "Review for \"Transfer Learning for a Foundational Chemistry Model\"",
        "authors": "",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1039/d3sc04928k/v2/review2"
    },
    {
        "id": 8099,
        "title": "Review for \"Transfer Learning for a Foundational Chemistry Model\"",
        "authors": "",
        "published": "2023-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1039/d3sc04928k/v2/review1"
    },
    {
        "id": 8100,
        "title": "Impact of base learning dataset on transfer learning for maize disease detection",
        "authors": "Subodh Bansal, Anuj Kumar",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/5.0086035"
    }
]