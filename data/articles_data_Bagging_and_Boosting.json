[
    {
        "id": 5901,
        "title": "Bagging and Boosting",
        "authors": "",
        "published": "2022-12-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009218276.014"
    },
    {
        "id": 5902,
        "title": "Boosting and Bagging Approaches",
        "authors": "",
        "published": "2017-9-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139028271.018"
    },
    {
        "id": 5903,
        "title": "A comparative study of ensemble methods in the field of education: Bagging and Boosting algorithms",
        "authors": "Hikmet ŞEVGİN",
        "published": "2023-9-22",
        "citations": 0,
        "abstract": "This study aims to conduct a comparative study of Bagging and Boosting algorithms among ensemble methods and to compare the classification performance of TreeNet and Random Forest methods using these algorithms on the data extracted from ABİDE application in education. The main factor in choosing them for analyses is that they are Ensemble methods combining decision trees via Bagging and Boosting algorithms and creating a single outcome by combining the outputs obtained from each of them. The data set consists of mathematics scores of ABİDE (Academic Skills Monitoring and Evaluation) 2016 implementation and various demographic variables regarding students. The study group involves 5000 students randomly recruited.  On the deletion of loss data and assignment procedures, this number decreased to 4568. The analyses showed that the TreeNet method performed more successfully in terms of classification accuracy, sensitivity, F1-score and AUC value based on sample size, and the Random Forest method on specificity and accuracy. It can be alleged that the TreeNet method is more successful in all numerical estimation error rates for each sample size by producing lower values compared to the Random Forest method.  When comparing both analysis methods based on ABİDE data, considering all the conditions, including sample size, cross validity and performance criteria following the analyses, TreeNet can be said to exhibit higher classification performance than Random Forest. Unlike a single classifier or predictive method, the classification or prediction of multiple methods by using Boosting and Bagging algorithms is considered important for the results obtained in education.",
        "link": "http://dx.doi.org/10.21449/ijate.1167705"
    },
    {
        "id": 5904,
        "title": "Ensemble Methods: Bagging and Boosting",
        "authors": "",
        "published": "2022-3-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108919371.007"
    },
    {
        "id": 5905,
        "title": "Prediction of Asphalt Binder Elastic Recovery Using Tree-Based Ensemble Bagging and Boosting Models",
        "authors": "Babak Asadi, Ramez Hajj",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4549281"
    },
    {
        "id": 5906,
        "title": "Ensemble Learning for AI Developers",
        "authors": "Alok Kumar, Mayank Jain",
        "published": "2020",
        "citations": 22,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-5940-5"
    },
    {
        "id": 5907,
        "title": "Ensemble Learning mittels Bagging und Boosting",
        "authors": "Jörg Frochte",
        "published": "2020-11-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3139/9783446463554.010"
    },
    {
        "id": 5908,
        "title": "Regressions- und Klassifikationsbäume; Bagging, Boosting und Random Forests",
        "authors": "Stefan Richter",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-662-59354-7_6"
    },
    {
        "id": 5909,
        "title": "Boosting and bagging",
        "authors": "Luiz Paulo Fávero, Patrícia Belfiore, Rafael de Freitas Souza",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824271-1.00017-2"
    },
    {
        "id": 5910,
        "title": "Comparing Boosting and Bagging Algorithms for Image Classification",
        "authors": "Chetan Chaudhary, Arun Gupta, R Murugan",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470582"
    },
    {
        "id": 5911,
        "title": "Tree-Based Bagging and Boosting Algorithms for Proactive Invoice Management",
        "authors": "Mohd. Atir, Mark Haydoutov",
        "published": "2020-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aect47998.2020.9194200"
    },
    {
        "id": 5912,
        "title": "Mixing Combinations",
        "authors": "Alok Kumar, Mayank Jain",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-5940-5_4"
    },
    {
        "id": 5913,
        "title": "Mixing Models",
        "authors": "Alok Kumar, Mayank Jain",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-5940-5_3"
    },
    {
        "id": 5914,
        "title": "Construction of Sewage Treatment System Integrating Boosting and Bagging Algorithms and Artificial Intelligence",
        "authors": "",
        "published": "2022-6-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.38007/wppcp.2022.030205"
    },
    {
        "id": 5915,
        "title": "Intrusion Detection System Based on Ada boosting and Bagging Algorithm",
        "authors": "",
        "published": "2022-6-30",
        "citations": 0,
        "abstract": "Computer worms execute damaging functions in the network systems, compromising system security. Although researchers use a variety of methods to detect worms and prevent their spread. Detecting worms remains a challenge for the following reasons: First, a huge volume of irrelevant data affects classification accuracy. Second, frequently used individual classifiers in systems are poor at detecting all types of worms, Third, many systems are built on out-of-date information, rendering them useless for new worm species. As a result, providing a network intrusion detection system is vital for ensuring security and reducing the harm caused by worms on networks to information systems. The goal of the study is to discover computer worms in the computer networks and protect the systems from their damages. The proposed method uses the UNSW NB15 dataset to train and test the ensemble Ada boosting and Bagging algorithms with the Support Vector Nachine (SVM) as a contribution rather than a decision tree. Due to Correlation Feature Selection (CFS) identifying relationships between features and classes, and Chi-square (Chi2) determining whether features and classes are independent or not, we combined these two algorithms as a contribution in a method called CFS&Chi2fs to select the relevant features and reduce the time. The system achieved accuracy reaching 0.998 with Bagging(SVM), and 0.989 with Ada boost(SVM).\n\nIndex Terms— Intrusion Detection System, Computer Worms, Ada boosting, Bagging.",
        "link": "http://dx.doi.org/10.33103/uot.ijccce.22.2.8"
    },
    {
        "id": 5916,
        "title": "Mixing Training Data",
        "authors": "Alok Kumar, Mayank Jain",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-5940-5_2"
    },
    {
        "id": 5917,
        "title": "Application of Bagging and Boosting Approaches Using Decision Tree-Based Algorithms in Diabetes Risk Prediction",
        "authors": "Pelin Yildirim Taser",
        "published": "2021-3-4",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3390/proceedings2021074006"
    },
    {
        "id": 5918,
        "title": "Bagging and boosting techniques in prediction of particulate matters",
        "authors": "D. Triana, S. Osowski",
        "published": "2020-9-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.24425/bpasts.2020.134659"
    },
    {
        "id": 5919,
        "title": "Forensic document examination system using boosting and bagging methodologies",
        "authors": "Surbhi Gupta, Munish Kumar",
        "published": "2020-4",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00500-019-04297-5"
    },
    {
        "id": 5920,
        "title": "CUDA-BASED PARALLELIZATION OF GRADIENT BOOSTING AND BAGGING ALGORITHM FOR DIAGNOSING DIABETES",
        "authors": "Lesia Mochurad",
        "published": "2023-6-29",
        "citations": 0,
        "abstract": "Data, its volume, structure, and form of presentation are among the most significant problems in working in the medical field. The probability of error is very high without innovative high-tech data analysis tools. It is easy to miss an important factor that is critical but lost among other, less important information. This work aims to study the proposed parallel gradient boosting algorithm in combination with the Bagging algorithm in the classification of diabetes to achieve greater stability and higher accuracy, reduce computational complexity and improve performance in medicine. The methods of parallelization of the Gradient Boosting algorithm in combination with the Bagging algorithm are investigated in the paper. Performance scores were obtained: approximately 7 using ThreadPoolExecutor and an eight-core computer system and 9.5 based on CUDA technology. Performance indicators that go to the unit are calculated. This, in turn, confirms the effectiveness of the proposed parallel algorithm. Another significant result of the study is improving algorithm accuracy by increasing the number of algorithms in the composition. The problem of diagnosing a patient's diabetes based on specific measurements included in the data set is considered. Detailed analysis and pre-processing of the selected dataset were performed. The parallelization of the proposed algorithm is implemented using the multi-core architecture of modern computers and CUDA technology. The process of learning models and training samples was parallelized. The theoretical estimation of the computational complexity of the offered parallel algorithm is given. A comparison of serial and parallel algorithm execution time using ThreadPoolExecutor when varying the number of threads and algorithms in the composition is presented. And also, the comparative analysis of time expenses at consecutive and parallel execution based on CPU and GPU is carried out.",
        "link": "http://dx.doi.org/10.31891/csit-2023-2-1"
    },
    {
        "id": 5921,
        "title": "Comparative study of boosting and bagging based methods for fault detection in a chemical process",
        "authors": "Rahul Shrivastava",
        "published": "2021-3-25",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icais50930.2021.9395905"
    },
    {
        "id": 5922,
        "title": "Tips and Best Practices",
        "authors": "Alok Kumar, Mayank Jain",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-5940-5_6"
    },
    {
        "id": 5923,
        "title": "Evaluating and comparing bagging and boosting of hybrid learning for breast cancer screening",
        "authors": "Asma Zizaan, Ali Idri",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.sciaf.2023.e01989"
    },
    {
        "id": 5924,
        "title": "Using Ensemble Learning Libraries",
        "authors": "Alok Kumar, Mayank Jain",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-5940-5_5"
    },
    {
        "id": 5925,
        "title": "Zero-Day Malware Detection and Effective Malware Analysis Using Shapley Ensemble Boosting and Bagging Approach",
        "authors": "Rajesh Kumar, Geetha Subbiah",
        "published": "2022-4-6",
        "citations": 14,
        "abstract": "Software products from all vendors have vulnerabilities that can cause a security concern. Malware is used as a prime exploitation tool to exploit these vulnerabilities. Machine learning (ML) methods are efficient in detecting malware and are state-of-art. The effectiveness of ML models can be augmented by reducing false negatives and false positives. In this paper, the performance of bagging and boosting machine learning models is enhanced by reducing misclassification. Shapley values of features are a true representation of the amount of contribution of features and help detect top features for any prediction by the ML model. Shapley values are transformed to probability scale to correlate with a prediction value of ML model and to detect top features for any prediction by a trained ML model. The trend of top features derived from false negative and false positive predictions by a trained ML model can be used for making inductive rules. In this work, the best performing ML model in bagging and boosting is determined by the accuracy and confusion matrix on three malware datasets from three different periods. The best performing ML model is used to make effective inductive rules using waterfall plots based on the probability scale of features. This work helps improve cyber security scenarios by effective detection of false-negative zero-day malware.",
        "link": "http://dx.doi.org/10.3390/s22072798"
    },
    {
        "id": 5926,
        "title": "Why Ensemble Techniques Are Needed",
        "authors": "Alok Kumar, Mayank Jain",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-5940-5_1"
    },
    {
        "id": 5927,
        "title": "Comparative Analysis of Bagging and Boosting Algorithms for Sentiment Analysis",
        "authors": "Aman Sawarn,  Ankit, Monika Gupta",
        "published": "2020",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.procs.2020.06.025"
    },
    {
        "id": 5928,
        "title": "Bagging and Boosting of Classification Models",
        "authors": "Igor I. Baskin, Gilles Marcou, Dragos Horvath, Alexandre Varnek",
        "published": "2017-7-28",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119161110.ch15"
    },
    {
        "id": 5929,
        "title": "Bagging and Boosting of Regression Models",
        "authors": "Igor I. Baskin, Gilles Marcou, Dragos Horvath, Alexandre Varnek",
        "published": "2017-7-28",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119161110.ch16"
    },
    {
        "id": 5930,
        "title": "Review of Bagging and Boosting Classification Performance on Unbalanced Binary Classification",
        "authors": "Yash Singhal, Ayushi Jain, Shrey Batra, Yash Varshney, Megha Rathi",
        "published": "2018-12",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iadcc.2018.8692138"
    },
    {
        "id": 5931,
        "title": "Heart Stroke Prediction Using Bagging and Boosting Classifiers",
        "authors": "Sowmya Sri Reddy Baddam",
        "published": "2022-6-30",
        "citations": 0,
        "abstract": "Abstract: Forecast of coronary illness is one of the superb regions where AI can yield an extreme benefit. Electrocardiographic (ECG) measures and AI for ECG highlights can be applied to foresee the Heart Stroke by utilizing a dataset made out of ECG highlights. Electrocardiogram (ECG) is one of the significant biomedical signs. Rather than utilizing general arrangement procedures whose precision goes from restricted to acceptable, this undertaking points on investigating outfit grouping. The sole point is to research the changes to the exactness with the utilization of gathering characterization models that work on the correctness of powerless calculations by joining various classifiers. Tests are carried out on a clinical procured heart ecg highlights dataset. An examination is made to recognize the better of the outfit models than to be tried. While the rationale is to further develop the precision the venture additionally targets stressing the exactness of troupe models and furthermore their commitment restoratively to work on the pace of heart stroke forecast. As trusted the outcomes were supposed to show a good exactness accomplished. A most extreme increment of seven percent exactness is assessed to increment from that of feeble classifiers.The troupe procedures or classifiers embraced for the situation are bootstrap conglomerating classifier and slope helping classifier with the choice component from various classifiers' expectation as larger part casting a ballot. The venture targets foreseeing the Heart Stroke event by investigating a dataset consisting of the previously mentioned ECG highlights by utilizing Gradient Boosting characterization and Bagging grouping strategies.",
        "link": "http://dx.doi.org/10.22214/ijraset.2022.44297"
    },
    {
        "id": 5932,
        "title": "Ensemble Approach Based on Bagging and Boosting for Identification the Computer System State",
        "authors": "Svitlana Gavrylenko, Viktor Chelak, Oleksii Hornostal",
        "published": "2021-9-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mma52675.2021.9610949"
    },
    {
        "id": 5933,
        "title": "Delamination Localization in the Composite Thin Plates Using Ensemble Learning: Bagging and Boosting Techniques",
        "authors": "Oguzhan Das, Duygu Bagci Das",
        "published": "2023-4-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.24200/sci.2023.59136.6072"
    },
    {
        "id": 5934,
        "title": "Coastal Wetland Mapping Using Ensemble Learning Algorithms: A Comparative Study of Bagging, Boosting and Stacking Techniques",
        "authors": "Li Wen, Michael Hughes",
        "published": "2020-5-25",
        "citations": 73,
        "abstract": "Coastal wetlands are a critical component of the coastal landscape that are increasingly threatened by sea level rise and other human disturbance. Periodically mapping wetland distribution is crucial to coastal ecosystem management. Ensemble algorithms (EL), such as random forest (RF) and gradient boosting machine (GBM) algorithms, are now commonly applied in the field of remote sensing. However, the performance and potential of other EL methods, such as extreme gradient boosting (XGBoost) and bagged trees, are rarely compared and tested for coastal wetland mapping. In this study, we applied the three most widely used EL techniques (i.e., bagging, boosting and stacking) to map wetland distribution in a highly modified coastal catchment, the Manning River Estuary, Australia. Our results demonstrated the advantages of using ensemble classifiers to accurately map wetland types in a coastal landscape. Enhanced bagging decision trees, i.e., classifiers with additional methods to increasing ensemble diversity such as RF and weighted subspace random forest, had comparably high predictive power. For the stacking method evaluated in this study, our results are inconclusive, and further comprehensive quantitative study is encouraged. Our findings also suggested that the ensemble methods were less effective at discriminating minority classes in comparison with more common classes. Finally, the variable importance results indicated that hydro-geomorphic factors, such as tidal depth and distance to water edge, were among the most influential variables across the top classifiers. However, vegetation indices derived from longer time series of remote sensing data that arrest the full features of land phenology are likely to improve wetland type separation in coastal areas.",
        "link": "http://dx.doi.org/10.3390/rs12101683"
    },
    {
        "id": 5935,
        "title": "Comparative Analysis for Detecting Malicious packets in LAN Network using Bagging and Boosting Techniques",
        "authors": "A.Vinitha, B. Rosiline Jeetha",
        "published": "2023-9-11",
        "citations": 0,
        "abstract": "The security is the important one in sharing the data through the network. The intrusion detection system helps to classify the data as the normal or anomaly by using the machine learning algorithms. There is the large pool of machine learning algorithms which helps to find the anomaly.  The algorithms have to find the connection that is normal or abnormal. The attacks are classified into four categories. Using the machine learning algorithm, the prediction is done to classify the packet as the normal or anomaly. The dataset used in this paper is communication of the LAN network which is happened in the very sensitive environments like military and Airforce. Various models are used to predict the anomaly but the bagging performs well in predicting the anomaly. There are various features associated in the dataset which helps to classify the network connection. The algorithms like adaboost was done with 10 iteration and the time for execution is 1.55 seconds and the accuracy are 94 %, bagging the time taken to execute the algorithm is 2.27 seconds, accuracy is 99%. Among these two algorithms the bagging performs well in predicting the abnormal data. Totally 42 attributes have been taken for the training and the testing purposes.",
        "link": "http://dx.doi.org/10.52783/tjjpt.v44.i3.724"
    },
    {
        "id": 5936,
        "title": "Novel Ensemble-Based Machine Learning Models Based on The Bagging, Boosting and Random Subspace Methods for Landslide Susceptibility Mapping",
        "authors": "Ali Nouh Mabdeh, Akif Al-Fugara, Mohammad Ahmadlou, Biswajeet Pradhan",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nIndivisual machine learning models show different limitations such as low generalization power for modeling nonlinear phenomena with complex behavior. In recent years, one of the best approaches to this issue is to use ensemble models. The purpose of this paper is to investigate the predictive power and modeling of three novel ensemble models constructed with four machine learning models: Decision Tree (DT), Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Naive Bayes (NB) models based on three approaches of Bagging, boosting and Random Subspace (RS) in landslide susceptibility mapping (LSM) in the Province of Ajloun in Jordan. A total number of 91 landslide locations along with 16 conditioning factors in LSM were identified and used. Also, before modeling, the selection of effective conditioning factors in LSM was done using genetic algorithm and four single models including DT, KNN, NB and SVM. The selected factors were used in modeling with individual and ensemble models. The results show that the area under the receiver operating characteristic curve (AUROC) for ensemble models is significantly higher than the individual models and the AUC for ensemble models was on average 14% higher than individual models. Based on the results, the most accurate models were RS ensemble model (AUROC = 0.850), Boosting (AUROC = 0.848) and Bagging (AUROC = 0.814), respectively. This study showed that by combining the results of simple machine learning models and making ensemble models, models with the desired accuracy can be achieved.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-649364/v1"
    },
    {
        "id": 5937,
        "title": "Friedman and Wilcoxon Evaluations Comparing SVM, Bagging, Boosting, K-NN and Decision Tree Classifiers",
        "authors": "Vinai George Biju, CM Prashanth",
        "published": "2017-6-1",
        "citations": 7,
        "abstract": "Abstract\nThis paper describes a number of experiments to compare and validate the performance of machine learning classifiers. Creating machine learning models for data with wide varieties has huge applications in predictive modelling across multiple domain of science. This work reviews state of the art techniques in machine learning classifiers methods with several extent of magnitude in statistics and key findings that will be helpful in establishing best methodological practices for class predictions. Comprehensive comparative review analysis with statistical validations for various machine learning algorithm for SVM, Bagging, Boosting, Decision Trees and Nearest Neighborhood algorithm on multiple data sets is carried out. Focus on the statistical analysis of the results using Friedman-Test and Wilcoxon Test as well as other interpretative metrics like classification rate, ROC, F-measure are evaluated to benchmark results.",
        "link": "http://dx.doi.org/10.1515/jacsm-2017-0002"
    },
    {
        "id": 5938,
        "title": "Hybrid Approach to Predict Prostate Cancer by IPCA Analysis with Boosting and Bagging Classifier",
        "authors": "Gundloori Mubarak, Rajabhushanam C",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icacite57410.2023.10182926"
    },
    {
        "id": 5939,
        "title": "Email spam detection using bagging and boosting of machine learning classifiers",
        "authors": "Uma Bhardwaj, Priti Sharma",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijaip.2023.128084"
    },
    {
        "id": 5940,
        "title": "A Comparative Evaluation use Bagging and Boosting Ensemble Classifiers",
        "authors": "Hanae Aoulad Ali, Chrayah Mohamed, Bouzidi Abdelhamid, Nabil Ourdani, Taha El Alami",
        "published": "2022-5-18",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iscv54655.2022.9806080"
    },
    {
        "id": 5941,
        "title": "Credit Card Fraud Detection using Bagging and Boosting Algorithm",
        "authors": "Kanishka R. Deogade, Dhanashree B. Thorat, Snehal V. Kale, Seema Rajput, Harjeet Kaur",
        "published": "2022-8-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iconsip49665.2022.10007446"
    },
    {
        "id": 5942,
        "title": "Email spam detection using bagging and boosting of machine learning classifiers",
        "authors": "Priti Sharma, Uma Bhardwaj",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijaip.2023.10052961"
    },
    {
        "id": 5943,
        "title": "COVID-19 Hastalarının Mortalitesini Tahmin Etmek için Torbalama ve Arttırma Yöntemleri",
        "authors": "Hilal ARSLAN",
        "published": "2022-5-8",
        "citations": 0,
        "abstract": "COVID-19 pandemic has been going on for more than two years and an increasing number of deaths has been occurring. Ensemble learning techniques are effectively employed to predict the outcome of the patients with COVID-19. The mortality prediction of the COVID-19 patient is crucial to reduce the risk of imminent death as well as to apply effective clinical treatment strategy. In this study, we perform bagging and boosting methods to predict mortality of the patients with COVID-19. The six different decision tree methods, C4.5, Random tree, REPTree, Logistic Model Tree, Decision Stump, and Hoeffding Tree are employed for base learners in bagging and boosting. The results are obtained using a real-world dataset including information obtained from 1085 patients. Experimental results present that bagging using REPTree as a base learner achieves an accuracy of 97.24%.  Furthermore, when we compare our results with other classification algorithms, the proposed method has a higher performance with respect to the accuracy, and presents an admirable performance.",
        "link": "http://dx.doi.org/10.24012/dumf.1095858"
    },
    {
        "id": 5944,
        "title": "Benchmarking the Bagging and Boosting (B &amp; B) Algorithms for Modeling Optimized Autonomous Intrusion Detection Systems (AIDS)",
        "authors": "Shreya Upadhyaya, Deepti Mehrotra",
        "published": "2023-6-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s42979-023-01914-x"
    },
    {
        "id": 5945,
        "title": "Comparison of Bagging and Boosting in Imbalanced Multilabel of Al-Quran Dataset",
        "authors": "Muhammad Rizqi Choirulfikri,  Adiwijaya, Arie Ardiyanti Suryani",
        "published": "2022-11-23",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icadeis56544.2022.10037462"
    },
    {
        "id": 5946,
        "title": "Comparison of Bagging and Boosting Ensemble Machine Learning Methods for Face Recognition",
        "authors": "Mehmet Akif Yaman, Frank Rattay, Abdulhamit Subasi",
        "published": "2021",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.procs.2021.10.074"
    },
    {
        "id": 5947,
        "title": "Application of machine learning boosting and bagging methods to predict compressive and flexural strength of marble cement mortar",
        "authors": "Zhiqiang Chen",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.mtcomm.2024.108600"
    },
    {
        "id": 5948,
        "title": "Smartphone-Based Human Activity Recognition Using Bagging and Boosting",
        "authors": "Abdulhamit Subasi, Asalah Fllatah, Kholoud Alzobidi, Tayeb Brahimi, Akila Sarirete",
        "published": "2019",
        "citations": 25,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.procs.2019.12.086"
    },
    {
        "id": 5949,
        "title": "Adapting Bagging and Boosting to Learning Classifier Systems",
        "authors": "Yi Liu, Will N. Browne, Bing Xue",
        "published": "2018",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-77538-8_28"
    },
    {
        "id": 5950,
        "title": "Classification of the placement success in the undergraduate placement examination according to decision trees with bagging and boosting methods",
        "authors": "Tuğba TUĞ KAROĞLU, Hayrettin OKUT",
        "published": "2020-3-22",
        "citations": 2,
        "abstract": "The purpose of this study is to classify the data set which is created by taking students who placed to universities from 81 provinces, in accordance with Undergraduate Placement Examination between the years 2010-2013 in Turkey, with Bagging and Boosting methods which are Ensemble algorithms. The data set which is used in the study was taken from the archives of Turk-Stat. (Turkish Statistical Institute) and OSYM (Assessment, Selection and Placement Center) and MATLAB statistical software program was used. In order to evaluate Bagging and Boosting classification performances better, the success rates of the students were grouped into two groups. According to this, the provinces that were above the average were coded as 1, and the provinces below the average were coded as 0 and dependent variables were created. The Bagging and Boosting ensemble algorithms were run accordingly. In order to evaluate the prediction abilities of the Bagging and Boosting algorithms, the data set was divided into training and testing. For this purpose, while the data between 2010-2012 yearrs were used as training data, the data of the year 2013 were used as testing data. Accuracy, precision, recall and f-measure were used to demonstrate the performance of the methods in the study. As a result, the performance in consequence of \"Bagging” and “Boosting” methods were compared. According to this; it was determined that in all performance measure marginally  “Boosting” method produced better results than the “Bagging” method.",
        "link": "http://dx.doi.org/10.17776/csj.544639"
    },
    {
        "id": 5951,
        "title": "Bagging or boosting? Empirical evidence from financial statement fraud detection",
        "authors": "Xiaowei Chen, Cong Zhai",
        "published": "2023-12",
        "citations": 0,
        "abstract": "AbstractEnsemble learning, specifically bagging and boosting, has been widely used in the financial field for detecting financial fraud, but their relative performance still lacks consensus. This study compares the performance of five ensemble learning models based on bagging and boosting, using data from Chinese A‐share listed companies from 2012 to 2022, including the COVID‐19 pandemic period. Results show that bagging outperforms boosting in various evaluation indicators, with profitability and asset quality positively affecting financial fraud. This study reveals the mechanism by which ensemble learning affects financial fraud detection and expands related research in the financial field.",
        "link": "http://dx.doi.org/10.1111/acfi.13159"
    },
    {
        "id": 5952,
        "title": "Handling Class Imbalance in Customer Churn Prediction in Telecom Sector Using Sampling Techniques, Bagging and Boosting Trees",
        "authors": "Sajjad Shumaly, Pedram Neysaryan, Yanhui Guo",
        "published": "2020-10-29",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccke50421.2020.9303698"
    },
    {
        "id": 5953,
        "title": "Bagging and Boosting for Predicting Bank Customer Churn",
        "authors": "Dinda Dwi Ninditha Silalahi,  Marsella, Alexandro Alvin Valentino, Ivan Sebastian Edbert, Derwin Suhartono",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icamimia60881.2023.10427686"
    },
    {
        "id": 5954,
        "title": "Predicting Insolvency of Insurance Companies in Egyptian Market Using Bagging and Boosting Ensemble Techniques",
        "authors": "Ahmed A. Khalil, Zaiming Liu, Ahmad Salah, Ahmed Fathalla, Ahmed Ali",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2022.3210032"
    },
    {
        "id": 5955,
        "title": "Machinery Faults Prediction Using Ensemble Tree Classifiers: Bagging or Boosting?",
        "authors": "Somayeh Bakkhtiari Ramezani, Amin Amirlatifi, Thomas Kirby, Shahram Rahimi, Maria Seale",
        "published": "2021-11-24",
        "citations": 0,
        "abstract": "One of the main goals of predictive maintenance is to accurately classify the temporal trends as early as possible, detect faulty states and pinpoint the root cause of the fault. Undoubtedly, neither late nor early maintenance is desirable and incurs additional operating costs; however, early identification of faulty trends and scheduling on-time maintenance is crucial to smooth machinery operation. Various data-driven techniques have been used to identify faults; nevertheless, many of these techniques fail to perform when faced with missing values at run time or lack any explanation on the root cause of the fault. The present work offers a comprehensive study on different techniques used for fault type classification and compares their performance in identifying the mode of operation for the PHME21 dataset. We also evaluate the robustness of such classifiers against missing values. This study shows that tree-based techniques are best suited to perform root cause analysis for each faulty state and establish rules for faulty conditions.",
        "link": "http://dx.doi.org/10.36001/phmconf.2021.v13i1.3063"
    },
    {
        "id": 5956,
        "title": "Eye Blink Classification for Assisting Disability to Communicate Using Bagging and Boosting",
        "authors": "Luthfi Ardi, Noor Akhmad Setiawan, Sunu Wibirama",
        "published": "2021-12-24",
        "citations": 0,
        "abstract": "Disability is a physical or mental impairment. People with disability have more barriers to do certain activity than those without disability. Moreover, several conditions make them having difficulty to communicate with other people. Currently, researchers have helped people with disabilities by developing brain-computer interface (BCI) technology, which uses artifact on electroencephalograph (EEG) as a communication tool using blinks. Research on eye blinks has only focused on the threshold and peak amplitude, while the difference in how many blinks can be detected using peak amplitude has not been the focus yet. This study used primary data taken using a Muse headband on 15 subjects. This data was used as a dataset classified using bagging (random forest) and boosting (XGBoost) methods with python; 80% of the data was allocated for learning and 20% was for testing. The classified data was divided into ten times of testing, which were then averaged. The number of eye blinks’ classification results showed that the accuracy value using random forest was 77.55%, and the accuracy result with the XGBoost method was 90.39%. The result suggests that the experimental model is successful and can be used as a reference for making applications that help people to communicate by differentiating the number of eye blinks. This research focused on developing the number of eye blinks. However, in this study, only three blinking were used so that further research could increase these number.",
        "link": "http://dx.doi.org/10.22146/ijitee.63515"
    },
    {
        "id": 5957,
        "title": "ANALISIS PEMBANDINGAN TEKNIK ENSEMBLE SECARA BOOSTING(XGBOOST) DAN BAGGING (RANDOMFOREST) PADA KLASIFIKASI KATEGORI SAMBATAN SEKUENS DNA",
        "authors": "Iswaya Maalik Syahrani",
        "published": "2019-10-1",
        "citations": 1,
        "abstract": "<p class=\"JGI-AbstractIsi\">Bioinformatics research currently supported by rapid growth of computation technology and algorithm. Ensemble decision tree is common method for classifying large and complex dataset such as DNA sequence. By implementing two classification methods with ensemble technique like xgboost and random Forest might improve the accuracy result on classifying DNA Sequence splice junction type. With 96,24% of xgboost accuracy and 95,11% of Random Forest accuracy, our conclusions  the xgboost and random forest methods using right parameter setting are highly effective tool for classifying small example dataset. Analyzing both methods with their characteristics will give an overview on how they work to meet the needs in DNA splicing.</p>",
        "link": "http://dx.doi.org/10.17933/jppi.2019.090103"
    },
    {
        "id": 5958,
        "title": "Klasifikasi Varietas Unggul Padi Menggunakan Metode Bagging, Boosting, dan Extremely Randomized Trees",
        "authors": "Lukmanul Hakim, Asep Saefuddin, Sausan Nisrina",
        "published": "2022-12-28",
        "citations": 0,
        "abstract": "Rice is one of the agricultural products which is the main commodity in Indonesia. Supporting factors that play a very important role in efforts to increase rice production are superior varieties. Superior rice varieties have characteristics that are similar to one another. Thus, farmers must choose the varieties used through a classification process to determine the appropriate type of rice. At this stage, three methods are used: bagging, boosting, and extremely randomized trees. From the analysis results, the overall method of extremely randomized trees has more optimal capabilities compared to the bagging and boosting methods. This is indicated by the three parameters, sensitivity, specificity, and accuracy, which have the highest values.",
        "link": "http://dx.doi.org/10.29313/statistika.v22i2.1455"
    },
    {
        "id": 5959,
        "title": "Prediction of gross calorific value from coal analysis using decision tree-based bagging and boosting techniques",
        "authors": "Tanveer Alam Munshi, Labiba Nusrat Jahan, M. Farhad Howladar, Mahamudul Hashan",
        "published": "2024-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.heliyon.2023.e23395"
    },
    {
        "id": 5960,
        "title": "Application of bagging, boosting and stacking ensemble and EasyEnsemble methods to landslide susceptibility mapping in the Three Gorges Reservoir area of China",
        "authors": "Xueling Wu, Junyang Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract. Since the impoundment of the Three Gorges Reservoir area in 2003, the potential risks of geological disasters in the reservoir area have increased significantly, among which the hidden dangers of landslides are particularly prominent. To reduce casualties and damage, efficient and precise landslide susceptibility evaluation methods are important. Multiple ensemble models have been used to evaluate the susceptibility of the upper part of Badong County to landslides. In this study, EasyEnsemble technology was used to solve the imbalance between landslide and nonlandslide sample data. The extracted evaluation factors were input into three ensemble models, bagging, boosting, and stacking models, for training, and landslide susceptibility maps (LSMs) were drawn. According to the importance analysis, the important factors affecting the occurrence of landslides are altitude, terrain surface texture (TST), distance to residents, distance to rivers and land use. Comparing the influences of different grid sizes on the susceptibility results, a larger grid was found to lead to the overfitting of the prediction results. Therefore, a 30 m grid was selected as the evaluation unit. The accuracy rate, area under the curve (AUC), recall rate, test set precision, and Kappa coefficient of the multigrained cascade forest (gcForest) model under the stacking method were 0.958, 0.991, 0.965, 0.946, and 0.91, respectively, which were significantly better than the values produced by the other two models.\n                        ",
        "link": "http://dx.doi.org/10.5194/egusphere-2022-697"
    },
    {
        "id": 5961,
        "title": "Bagging and Boosting Ensemble Classifiers for Classification of Multispectral, Hyperspectral and PolSAR Data: A Comparative Evaluation",
        "authors": "Hamid Jafarzadeh, Masoud Mahdianpari, Eric Gill, Fariba Mohammadimanesh, Saeid Homayouni",
        "published": "2021-11-2",
        "citations": 58,
        "abstract": "In recent years, several powerful machine learning (ML) algorithms have been developed for image classification, especially those based on ensemble learning (EL). In particular, Extreme Gradient Boosting (XGBoost) and Light Gradient Boosting Machine (LightGBM) methods have attracted researchers’ attention in data science due to their superior results compared to other commonly used ML algorithms. Despite their popularity within the computer science community, they have not yet been well examined in detail in the field of Earth Observation (EO) for satellite image classification. As such, this study investigates the capability of different EL algorithms, generally known as bagging and boosting algorithms, including Adaptive Boosting (AdaBoost), Gradient Boosting Machine (GBM), XGBoost, LightGBM, and Random Forest (RF), for the classification of Remote Sensing (RS) data. In particular, different classification scenarios were designed to compare the performance of these algorithms on three different types of RS data, namely high-resolution multispectral, hyperspectral, and Polarimetric Synthetic Aperture Radar (PolSAR) data. Moreover, the Decision Tree (DT) single classifier, as a base classifier, is considered to evaluate the classification’s accuracy. The experimental results demonstrated that the RF and XGBoost methods for the multispectral image, the LightGBM and XGBoost methods for hyperspectral data, and the XGBoost and RF algorithms for PolSAR data produced higher classification accuracies compared to other ML techniques. This demonstrates the great capability of the XGBoost method for the classification of different types of RS data.",
        "link": "http://dx.doi.org/10.3390/rs13214405"
    },
    {
        "id": 5962,
        "title": "Ensemble: Bagging and Boosting",
        "authors": "Poornachandra Sarang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-02363-7_5"
    },
    {
        "id": 5963,
        "title": "Classifier Ensembling: Dataset Learning Using Bagging and Boosting",
        "authors": "Santosh S. Lomte, Sanket G. Torambekar",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-13-7150-9_9"
    },
    {
        "id": 5964,
        "title": "Dual-IDS: A bagging-based gradient boosting decision tree model for network anomaly intrusion detection system",
        "authors": "Maya Hilda Lestari Louk, Bayu Adhi Tama",
        "published": "2023-3",
        "citations": 46,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.eswa.2022.119030"
    },
    {
        "id": 5965,
        "title": "Prediction of asphalt binder elastic recovery using tree-based ensemble bagging and boosting models",
        "authors": "Babak Asadi, Ramez Hajj",
        "published": "2024-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.conbuildmat.2023.134154"
    },
    {
        "id": 5966,
        "title": "Comparation Analysis of Ensemble Technique With Boosting(Xgboost) and Bagging (Randomforest) For Classify Splice Junction DNA Sequence Category",
        "authors": "Iswaya Maalik Syahrani",
        "published": "2019-10-1",
        "citations": 0,
        "abstract": "Bioinformatics research currently supported by rapid growth of computation technology and algorithm. Ensemble decision tree is common method for classifying large and complex dataset such as DNA sequence. By implementing two classification methods with ensemble technique like xgboost and random Forest might improve the accuracy result on classifying DNA Sequence splice junction type. With 96,24% of xgboost accuracy and 95,11% of Random Forest accuracy, our conclusions  the xgboost and random forest methods using right parameter setting are highly effective tool for classifying small example dataset. Analyzing both methods with their characteristics will give an overview on how they work to meet the needs in DNA splicing.",
        "link": "http://dx.doi.org/10.17933/jppi.v9i1.249"
    },
    {
        "id": 5967,
        "title": "Solving class imbalance problem using bagging, boosting techniques, with and without using noise filtering method",
        "authors": "G. Rekha, Amit Kumar Tyagi, V. Krishna Reddy",
        "published": "2019-6-13",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3233/his-190261"
    },
    {
        "id": 5968,
        "title": "Comparing Boosting and Bagging for Decision Trees of Rankings",
        "authors": "Antonella Plaia, Simona Buscemi, Johannes Fürnkranz, Eneldo Loza Mencía",
        "published": "2022-3",
        "citations": 6,
        "abstract": "AbstractDecision tree learning is among the most popular and most traditional families of machine learning algorithms. While these techniques excel in being quite intuitive and interpretable, they also suffer from instability: small perturbations in the training data may result in big changes in the predictions. The so-called ensemble methods combine the output of multiple trees, which makes the decision more reliable and stable. They have been primarily applied to numeric prediction problems and to classification tasks. In the last years, some attempts to extend the ensemble methods to ordinal data can be found in the literature, but no concrete methodology has been provided for preference data. In this paper, we extend decision trees, and in the following also ensemble methods to ranking data. In particular, we propose a theoretical and computational definition of bagging and boosting, two of the best known ensemble methods. In an experimental study using simulated data and real-world datasets, our results confirm that known results from classification, such as that boosting outperforms bagging, could be successfully carried over to the ranking case.",
        "link": "http://dx.doi.org/10.1007/s00357-021-09397-2"
    },
    {
        "id": 5969,
        "title": "Teknik Bagging Dan Boosting Pada Algoritma CART Untuk Klasifikasi Masa Studi Mahasiswa",
        "authors": "Ahmad Rusadi Arrahimi, Muhammad Khairi Ihsan, Dwi Kartini, Mohammad Reza Faisal, Fatma Indriani",
        "published": "2019-7-14",
        "citations": 2,
        "abstract": "Undergraduate Students data in academic information systems always increases every year. Data collected can be processed using data mining to gain new knowledge. The author tries to mine undergraduate students data to classify the study period on time or not on time. The data is analyzed using CART with bagging techniqu, and CART with boosting technique. The classification results using 49 testing data, in the CART algorithm with bagging techniques 13 data (26.531%) entered into the classification on time and 36 data (73.469%) entered into the classification not on time. In the CART algorithm with boosting technique 16 data (32,653%) entered into the classification on time and 33 data (67,347%) entered into the classification not on time. The accuracy value of the classification of study period of undergraduate students using the CART algorithm is 79.592%, the CART algorithm with bagging technique is 81.633%, and the CART algorithm with boosting technique is 87.755%. In this study, the CART algorithm with boosting technique has the best accuracy value.",
        "link": "http://dx.doi.org/10.34128/jsi.v5i1.171"
    },
    {
        "id": 5970,
        "title": "Application of machine learning to groundwater spring potential mapping using averaging, bagging, and boosting techniques",
        "authors": "Aihua Wei, Duo Li, Xiaoli Bai, Rui Wang, Xiaogang Fu, Jieqing Yu",
        "published": "2022-8-1",
        "citations": 5,
        "abstract": "Abstract\nDetermining groundwater potential is vital for groundwater resource management. This study aims to present a comparative analysis of three widely used ensemble techniques (averaging, bagging, and boosting) in groundwater spring potential mapping. Firstly, 12 spring-related factors and a total of 79 groundwater spring locations were collected and used as the dataset. Secondly, three typical ensemble models were adopted to predict groundwater spring potential, namely, Bayesian model averaging (BMA), random forest (RF), and the gradient boosting decision tree (GBDT). The area under the receiver operating characteristics curve (AUC) and four statistical indexes (accuracy, sensitivity, specificity, and the root mean square error (RMSE)) were used to estimate the model's accuracy. The results indicate that the three models had a good predictive performance and that the AUC values of the GBDT, RF, and BMA were 0.88, 0.84, and 0.78, respectively. Furthermore, the GBDT had the best performance (accuracy = 0.89, sensitivity = 0.91, specificity = 0.87, and RMSE = 0.33) in terms of the four indexes, followed by RF (accuracy = 0.87, sensitivity = 0.91, specificity = 0.83, and RMSE = 0.36) and BMA (accuracy = 0.76, sensitivity = 0.87, specificity = 0.65, and RMSE = 0.49). This research can provide effective guidance for using ensemble models for mapping groundwater spring potential in the future.",
        "link": "http://dx.doi.org/10.2166/ws.2022.283"
    },
    {
        "id": 5971,
        "title": "8 Meta-learning through ensemble approach: bagging, boosting, and random forest strategies",
        "authors": "S. Ramasamy, H. C. Kantharaju, N. Bindu Madhavi, M. P. Haripriya",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783111323749-008"
    },
    {
        "id": 5972,
        "title": "Failure prediction of Indian Banks using SMOTE, Lasso regression, bagging and boosting",
        "authors": "Santosh Shrivastava, P Mary Jeyanthi, Sarbjit Singh",
        "published": "2020-1-1",
        "citations": 34,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/23322039.2020.1729569"
    },
    {
        "id": 5973,
        "title": "Which are best for successful aging prediction? Bagging, boosting, or simple machine learning algorithms?",
        "authors": "Razieh Mirzaeian, Raoof Nopour, Zahra Asghari Varzaneh, Mohsen Shafiee, Mostafa Shanbehzadeh, Hadi Kazemi-Arpanahi",
        "published": "2023-8-29",
        "citations": 1,
        "abstract": "Abstract\nBackground\nThe worldwide society is currently facing an epidemiological shift due to the significant improvement in life expectancy and increase in the elderly population. This shift requires the public and scientific community to highlight successful aging (SA), as an indicator representing the quality of elderly people’s health. SA is a subjective, complex, and multidimensional concept; thus, its meaning or measuring is a difficult task. This study seeks to identify the most affecting factors on SA and fed them as input variables for constructing predictive models using machine learning (ML) algorithms.\n\nMethods\nData from 1465 adults aged ≥ 60 years who were referred to health centers in Abadan city (Iran) between 2021 and 2022 were collected by interview. First, binary logistic regression (BLR) was used to identify the main factors influencing SA. Second, eight ML algorithms, including adaptive boosting (AdaBoost), bootstrap aggregating (Bagging), eXtreme Gradient Boosting (XG-Boost), random forest (RF), J-48, multilayered perceptron (MLP), Naïve Bayes (NB), and support vector machine (SVM), were trained to predict SA. Finally, their performance was evaluated using metrics derived from the confusion matrix to determine the best model.\n\nResults\nThe experimental results showed that 44 factors had a meaningful relationship with SA as the output class. In total, the RF algorithm with sensitivity = 0.95 ± 0.01, specificity = 0.94 ± 0.01, accuracy = 0.94 ± 0.005, and F-score = 0.94 ± 0.003 yielded the best performance for predicting SA.\n\nConclusions\nCompared to other selected ML methods, the effectiveness of the RF as a bagging algorithm in predicting SA was significantly better. Our developed prediction models can provide, gerontologists, geriatric nursing, healthcare administrators, and policymakers with a reliable and responsive tool to improve elderly outcomes.\n",
        "link": "http://dx.doi.org/10.1186/s12938-023-01140-9"
    },
    {
        "id": 5974,
        "title": "Software fault proneness prediction: a comparative study between bagging, boosting, and stacking ensemble and base learner methods",
        "authors": "Iyad Alazzam, Izzat Alsmadi, Mohammed Akour",
        "published": "2017",
        "citations": 25,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijdats.2017.10003991"
    },
    {
        "id": 5975,
        "title": "Random Forest, Bagging, and Boosting of Decision Trees",
        "authors": "Niladri Syam, Rajeeve Kaul",
        "published": "2021-3-10",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1108/978-1-80043-880-420211006"
    },
    {
        "id": 5976,
        "title": "Improved Recognition Results of Medieval Handwritten Gurmukhi Manuscripts Using Boosting and Bagging Methodologies",
        "authors": "Munish Kumar, Simpel Rani Jindal, M. K. Jindal, Gurpreet Singh Lehal",
        "published": "2019-8",
        "citations": 42,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11063-018-9913-6"
    },
    {
        "id": 5977,
        "title": "Prediction of water quality indexes with ensemble learners: Bagging and boosting",
        "authors": "Ali Aldrees, Hamad Hassan Awan, Muhammad Faisal Javed, Abdeliazim Mustafa Mohamed",
        "published": "2022-12",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.psep.2022.10.005"
    },
    {
        "id": 5978,
        "title": "Prediction model for rice husk ash concrete using AI approach: Boosting and bagging algorithms",
        "authors": "Muhammad Nasir Amin, Bawar Iftikhar, Kaffayatullah Khan, Muhammad Faisal Javed, Abdullah Mohammad AbuArab, Muhammad Faisal Rehman",
        "published": "2023-4",
        "citations": 39,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.istruc.2023.02.080"
    },
    {
        "id": 5979,
        "title": "pdi-Bagging: A Proposal of Bagging-Type Ensemble Method Generating Virtual Data",
        "authors": "Honoka Irie, Isao Hayashi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011827600003393"
    },
    {
        "id": 5980,
        "title": "Boosting and bagging classification for computer science journal",
        "authors": "Nastiti Susetyo Fanany Putri, Aji Prasetya Wibawa, Harits Ar Rasyid, Andrew Nafalski, Ummi Rabaah Hasyim",
        "published": "2023-3-15",
        "citations": 1,
        "abstract": "In recent years, data processing has become an issue across all disciplines. Good data processing can provide decision-making recommendations. Data processing is covered in academic data processing publications, including those in computer science. This topic has grown over the past three years, demonstrating that data processing is expanding and diversifying, and there is a great deal of interest in this area of study. Within the journal, groupings (quartiles) indicate the journal's influence on other similar studies. SCImago provides this category. There are four quartiles, with the highest quartile being 1 and the lowest being 4. There are, however, numerous differences in class quartiles, with different quartile values for the same journal in different disciplines. Therefore, a method of categorization is provided to solve this issue. Classification is a machine-learning technique that groups data based on the supplied label class. Ensemble Boosting and Bagging with Decision Tree (DT) and Gaussian Nave Bayes (GNB) were utilized in this study. Several modifications were made to the ensemble algorithm's depth and estimator settings to examine the influence of adding values on the resultant precision. In the DT algorithm, both variables are altered, whereas, in the GNB algorithm, just the estimator's value is modified. Based on the average value of the accuracy results, it is known that the best algorithm for computer science datasets is GNB Bagging, with values of 68.96%, 70.99%, and 69.05%. Second-place XGBDT has 67.75% accuracy, 67.69% precision, and 67.83 recall. The DT Bagging method placed third with 67.31 percent recall, 68.13 percent precision, and 67.30 percent accuracy. The fourth sequence is the XGBoost GNB approach, which has an accuracy of 67.07%, a precision of 68.85%, and a recall of 67.18%. The Adaboost DT technique ranks in the fifth position with an accuracy of 63.65%, a precision of 64.21 %, and a recall of 63.63 %. Adaboost GNB is the least efficient algorithm for this dataset since it only achieves 43.19 % accuracy, 48.14 % precision, and 43.2% recall. The results are still quite far from the ideal. Hence the proposed method for journal quartile inequality issues is not advised.",
        "link": "http://dx.doi.org/10.26555/ijain.v9i1.985"
    },
    {
        "id": 5981,
        "title": "Towards a NIR Spectroscopy ensemble learning technique competing with the standard ASTM-CFR: An optimal boosting and bagging extreme learning machine algorithms for gasoline octane number prediction",
        "authors": "Noureddine GHOGGALI, Fouzi DOUAK, Walid GHOGGALI",
        "published": "2022-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ijleo.2022.168813"
    },
    {
        "id": 5982,
        "title": "An Experimental Study of Diversity of Diabetes Disease Features by Bagging and Boosting Ensemble Method with Rule Based Machine Learning Classifier Algorithms",
        "authors": "Dhyan Chandra Yadav, Saurabh Pal",
        "published": "2021-2",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s42979-020-00446-y"
    },
    {
        "id": 5983,
        "title": "Performance Evaluation and Comparison of Ensemble Based Bagging and Boosting Machine Learning Methods for Automated Early Prediction of Myocardial Infarction",
        "authors": "Md. Azizul Hakim, Nusrat Jahan, Zannat Ara Zerin, Amena Begum Farha",
        "published": "2021-7-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icccnt51525.2021.9580063"
    },
    {
        "id": 5984,
        "title": "Decision Tree for Uncertain Numerical Data Using Bagging and Boosting",
        "authors": "Santosh S. Lomte, Sanket Gunderao Torambekar",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-6369-7_47"
    },
    {
        "id": 5985,
        "title": "Evaluation of Feature Selection Methods using Bagging and Boosting Ensemble Techniques on High Throughput Biological Data",
        "authors": "Jiamin Wu, Shengjia Chen, Wenbin Zhou, Ningya Wang, Ziling Fan",
        "published": "2020-9-15",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3397391.3397403"
    },
    {
        "id": 5986,
        "title": "Mammographic Classification Using Stacked Ensemble Learning with Bagging and Boosting Techniques",
        "authors": "Nirase Fathima Abubacker, Ibrahim Abaker Targio Hashem, Lim Kun Hui",
        "published": "2020-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s40846-020-00567-y"
    },
    {
        "id": 5987,
        "title": "Comparative study of bagging, boosting and convolutional neural network for text classification",
        "authors": "S Ramraj, S Saranya, K Yashwant",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5958/0976-5506.2018.01138.5"
    },
    {
        "id": 5988,
        "title": "Comparative Analysis of Bagging and Boosting Algorithms on the Classification of the Popularity of Educational-themed Youtube Videos",
        "authors": "Utomo Pujianto, Agusta Rakhmat Taufani, Luis Devvi Ratna Kus Anggraini, Deni Sutaji",
        "published": "2021-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iceeie52663.2021.9616918"
    },
    {
        "id": 5989,
        "title": "Predicting traffic crash severity using hybrid of balanced bagging classification and light gradient boosting machine",
        "authors": "Jovial Niyogisubizo, Lyuchao Liao, Fumin Zou, Guangjie Han, Eric Nziyumva, Ben Li, Yuyuan Lin",
        "published": "2023-1-30",
        "citations": 2,
        "abstract": "Accident severity prediction is a hot topic of research aimed at ensuring road safety as well as taking precautionary measures for anticipated future road crashes. In the past decades, both classical statistical methods and machine learning algorithms have been used to predict traffic crash severity. However, most of these models suffer from several drawbacks including low accuracy, and lack of interpretability for people. To address these issues, this paper proposed a hybrid of Balanced Bagging Classification (BBC) and Light Gradient Boosting Machine (LGBM) to improve the accuracy of crash severity prediction and eliminate the issues of bias and variance. To the best of the author’s knowledge, this is one of the pioneer studies which explores the application of BBC-LGBM to predict traffic crash severity. On the accident dataset of Great Britain (UK) from 2013 to 2019, the proposed model has demonstrated better performance when compared with other models such as Gaussian Naïve Bayes (GNB), Support vector machines (SVM), and Random Forest (RF). More specifically, the proposed model managed to achieve better performance among all metrics for the testing dataset (accuracy = 77.7%, precision = 75%, recall = 73%, F1-Score = 68%). Moreover, permutation importance is used to interpret the results and analyze the importance of each factor influencing crash severity. The accuracy-enhanced model is significant to several stakeholders including drivers for early alarm and government departments, insurance companies, and even hospitals for the services concerned about human lives and property damage in road crashes.",
        "link": "http://dx.doi.org/10.3233/ida-216398"
    },
    {
        "id": 5990,
        "title": "Comparison of Bagging and Boosting Ensemble Machine Learning Methods for Automated EMG Signal Classification",
        "authors": "Emine Yaman, Abdulhamit Subasi",
        "published": "2019-10-31",
        "citations": 60,
        "abstract": "The neuromuscular disorders are diagnosed using electromyographic (EMG) signals. Machine learning algorithms are employed as a decision support system to diagnose neuromuscular disorders. This paper compares bagging and boosting ensemble learning methods to classify EMG signals automatically. Even though ensemble classifiers’ efficacy in relation to real-life issues has been presented in numerous studies, there are almost no studies which focus on the feasibility of bagging and boosting ensemble classifiers to diagnose the neuromuscular disorders. Therefore, the purpose of this paper is to assess the feasibility of bagging and boosting ensemble classifiers to diagnose neuromuscular disorders through the use of EMG signals. It should be understood that there are three steps to this method, where the step number one is to calculate the wavelet packed coefficients (WPC) for every type of EMG signal. After this, it is necessary to calculate statistical values of WPC so that the distribution of wavelet coefficients could be demonstrated. In the last step, an ensemble classifier used the extracted features as an input of the classifier to diagnose the neuromuscular disorders. Experimental results showed the ensemble classifiers achieved better performance for diagnosis of neuromuscular disorders. Results are promising and showed that the AdaBoost with random forest ensemble method achieved an accuracy of 99.08%, F-measure 0.99, AUC 1, and kappa statistic 0.99.",
        "link": "http://dx.doi.org/10.1155/2019/9152506"
    },
    {
        "id": 5991,
        "title": "Assessment of Jiangsu Regional Logistics Space Nonequilibrium Situation by Boosting and Bagging Algorithms",
        "authors": "Zhifeng Wang",
        "published": "2022-6-14",
        "citations": 0,
        "abstract": "This study aims to solve the problem of unbalanced regional economic development in Jiangsu and deeply excavates the relevant theories of regional logistics and the unbalanced spatial situation. The classification of regional logistics and spatial disequilibrium and the dimensions involved are studied. At present, the development status of Jiangsu logistics has locked the main reason for the unbalanced situation of the regional logistics space in Jiangsu. The basic principles, application scope, and methods of Bagging and Boosting algorithms are deeply studied. Then, the Jiangsu logistics space nonequilibrium situation assessment model is established based on the Bagging and Boosting algorithms, and the input data is sorted and summarized. Finally, the results are obtained through experiments evaluating the model and analyzed and summarized. The core issues, the factors affecting development, and the uneven development situation have been comprehensively assessed. The conclusion drawn is as follows: the imbalance of the logistics productivity of various regions in Jiangsu will inevitably lead to the imbalance of the regional logistics space in Jiangsu, which affects the coordinated and healthy development of the regional logistics in Jiangsu. These conclusions are significant to the inherent causes and effects of regional logistics spatial disequilibrium and can promote the coordination, synergy, and common development of Jiangsu logistics regions.",
        "link": "http://dx.doi.org/10.1155/2022/2884711"
    },
    {
        "id": 5992,
        "title": "Bagging-gradient boosting decision tree based milling cutter wear status prediction modelling",
        "authors": "Weiping Xu, Wendi Li, Yao Zhang, Taihua Zhang, Huawei Chen",
        "published": "2021-12",
        "citations": 2,
        "abstract": "AbstractAiming to monitor wear condition of milling cutters in time and provide tool change decisions to ensure manufacturing safety and product quality, a tool wear monitoring model based on Bagging-Gradient Boosting Decision Tree (Bagging-GBDT) is proposed. In order to avoid incomplete tool state information contained in a single domain feature parameter, a multi-domain combination method is used to extract candidate characteristic parameter sets from time domain, frequency domain, and time–frequency domain. Then top 21 significant features are screened by eXtreme Gradient Boosting selection method. Synthetic Minority Oversampling Technique technology is integrated during feature selection to overly sample feature vectors, so that wear condition categories can be well balanced. Bagging idea is then introduced for parallel calculation of the gradient boosting decision tree and to improve its generalization ability. A Bagging-GBDT milling cutter wear condition prediction model is constructed and verified by public ball-end milling data set. Experiments show that random features and training samples selection can effectively improve prediction performance and generalization ability of prediction model. Our Bagging-GBDT model gains F1 score of 0.99350, which is 0.2% and 13.2% higher than the random forest algorithm and basic GBDT model, respectively.",
        "link": "http://dx.doi.org/10.1007/s42452-021-04856-2"
    },
    {
        "id": 5993,
        "title": "Deep learning-based active contour technique with bagging and boosting algorithms hybrid approach for detecting bone Cancer from Mri scan images",
        "authors": "Ediga Lingappa, L Rama Parvathy",
        "published": "2023-9",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11042-023-14811-5"
    },
    {
        "id": 5994,
        "title": "Boosting, Bagging and Ensembles in the Real World: An Overview, some Explanations and a Practical Synthesis for Holistic Global Wildlife Conservation Applications Based on Machine Learning with Decision Trees",
        "authors": "Falk Huettmann",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-96978-7_3"
    },
    {
        "id": 5995,
        "title": "Estimation and comparison of gabion weir oxygen mass transfer by ensemble learnings of bagging, boosting, and stacking algorithms",
        "authors": "KM Luxmi, N. K Tiwari, S Ranjan",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/09715010.2023.2203109"
    },
    {
        "id": 5996,
        "title": "Bagging and Boosting Fine-tuning for Ensemble Learning",
        "authors": "Changming Zhao, Ruimin Peng, Dongrui Wu",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tai.2023.3296685"
    },
    {
        "id": 5997,
        "title": "Bagging- and Boosting-Based Latent Fingerprint Image Classification and Segmentation",
        "authors": "Megha Chhabra, Manoj Kumar Shukla, Kiran Kumar Ravulakollu",
        "published": "2021",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-15-5148-2_17"
    },
    {
        "id": 5998,
        "title": "From “Bagging” Patients to Bagging Dr. Heidbrink, Maker of Anesthesia Machines",
        "authors": "",
        "published": "2018-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1097/aln.0000000000002449"
    },
    {
        "id": 5999,
        "title": "Modeling Daily Reference Evapotranspiration from Climate Variables: Assessment of Bagging and Boosting Regression Approaches",
        "authors": "Jayashree T R, NV Subba Reddy, U Dinesh Acharya",
        "published": "2023-2",
        "citations": 9,
        "abstract": "AbstractThe increasing frequency of droughts and floods due to climate change has severely affected water resources across the globe in recent years. An optimal design for the scheduling and management of irrigation is thus urgently needed to adapt agricultural activities to the changing climate. The accurate estimation of reference crop evapotranspiration (ET0), a vital hydrological component of the water balance and crop water need, is a tiresome task if all the relevant climatic variables are unavailable. This study investigates the potential of four ensemble techniques for estimating precise values of the daily ET0 at representative stations in 10 agro-climatic zones in the state of Karnataka, India, from 1979 to 2014. The performance of these models was evaluated by using several combinations of climatic variables as inputs by using tenfold cross-validation. The outcomes indicated that predictions of ET0 by all four ensemble models based on all climatic variables were the most accurate in comparison with other input combinations. The random forest regressor was found to deliver the best performance among the four models on all measures considered (Nash–Sutcliffe efficiency, 1.0, root-mean-squared error, 0.016 mm/day, and mean absolute error, 0.011 mm/day). However, it incurred the highest computational cost, whereas the computational cost of the bagging model for linear regression was the lowest. The extreme gradient-boosting model delivered the most stable performance with a modified training dataset. The work here shows that these models can be recommended for daily ET0 estimation based on the users’ interests.",
        "link": "http://dx.doi.org/10.1007/s11269-022-03399-4"
    },
    {
        "id": 6000,
        "title": "Comparison of bagging, boosting and stacking algorithms for surface soil moisture mapping using optical-thermal-microwave remote sensing synergies",
        "authors": "Bappa Das, Pooja Rathore, Debasish Roy, Debashis Chakraborty, Raghuveer Singh Jatav, Deepak Sethi, Praveen Kumar",
        "published": "2022-10",
        "citations": 24,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.catena.2022.106485"
    }
]