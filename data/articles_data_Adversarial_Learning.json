[
    {
        "id": 4301,
        "title": "Adversarial Machine Learning Challenges",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.009"
    },
    {
        "id": 4302,
        "title": "Overview of Adversarial Learning",
        "authors": "",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009315647.002"
    },
    {
        "id": 4303,
        "title": "Adversarial robustness in meta-learning and contrastive learning",
        "authors": "Pin-Yu Chen, Cho-Jui Hsieh",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00028-4"
    },
    {
        "id": 4304,
        "title": "Adaug: Learning Differentiable Augmentations Through Adversarial Attacksadaug: Learning Differentiable Augmentations Through Adversarial Attacks",
        "authors": "Arpit Rai",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4229734"
    },
    {
        "id": 4305,
        "title": "Adversarial Transfer Learning",
        "authors": "",
        "published": "2020-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781139061773.009"
    },
    {
        "id": 4306,
        "title": "Test-Time Evasion Attacks (Adversarial Inputs)",
        "authors": "",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009315647.005"
    },
    {
        "id": 4307,
        "title": "Adversarial Examples for Captcha Generation Adversarial Machine Learning for Social Good",
        "authors": "Chen Hajaj, Meir Litman",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4608639"
    },
    {
        "id": 4308,
        "title": "Adversarial training",
        "authors": "Pin-Yu Chen, Cho-Jui Hsieh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00023-5"
    },
    {
        "id": 4309,
        "title": "Adversarial Machine Learning",
        "authors": "Aneesh Sreevallabh Chivukula, Xinghao Yang, Bo Liu, Wei Liu, Wanlei Zhou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-99772-4_1"
    },
    {
        "id": 4310,
        "title": "Physical adversarial attacks",
        "authors": "Pin-Yu Chen, Cho-Jui Hsieh",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00013-2"
    },
    {
        "id": 4311,
        "title": "Adversarial Deep Learning",
        "authors": "Aneesh Sreevallabh Chivukula, Xinghao Yang, Bo Liu, Wei Liu, Wanlei Zhou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-99772-4_2"
    },
    {
        "id": 4312,
        "title": "Adversarial Robustness for Machine Learning",
        "authors": "",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/c2020-0-01078-9"
    },
    {
        "id": 4313,
        "title": "Adversarial Machine Learning",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4135/9781529602241"
    },
    {
        "id": 4314,
        "title": "Black-box adversarial attacks",
        "authors": "Pin-Yu Chen, Cho-Jui Hsieh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00012-0"
    },
    {
        "id": 4315,
        "title": "Overview of adversarial defense",
        "authors": "Pin-Yu Chen, Cho-Jui Hsieh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00022-3"
    },
    {
        "id": 4316,
        "title": "Adversarial Attacks",
        "authors": "",
        "published": "2022-12-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009218276.023"
    },
    {
        "id": 4317,
        "title": "Game Theoretical Adversarial Deep Learning",
        "authors": "Aneesh Sreevallabh Chivukula, Xinghao Yang, Bo Liu, Wei Liu, Wanlei Zhou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-99772-4_4"
    },
    {
        "id": 4318,
        "title": "A Framework for Secure Learning",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.003"
    },
    {
        "id": 4319,
        "title": "Adversarial Machine Learning and Cybersecurity",
        "authors": "Micah Musser",
        "published": "2023-4",
        "citations": 2,
        "abstract": "Artificial intelligence systems are rapidly being deployed in all sectors of the economy, yet significant research has demonstrated that these systems can be vulnerable to a wide array of attacks. How different are these problems from more common cybersecurity vulnerabilities? What legal ambiguities do they create, and how can organizations ameliorate them? This report, produced in collaboration with the Program on Geopolitics, Technology, and Governance at the Stanford Cyber Policy Center, presents the recommendations of a July 2022 workshop of experts to help answer these questions.",
        "link": "http://dx.doi.org/10.51593/2022ca003"
    },
    {
        "id": 4320,
        "title": "Training-time adversarial attacks",
        "authors": "Pin-Yu Chen, Cho-Jui Hsieh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00014-4"
    },
    {
        "id": 4321,
        "title": "White-box adversarial attacks",
        "authors": "Pin-Yu Chen, Cho-Jui Hsieh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00011-9"
    },
    {
        "id": 4322,
        "title": "Deep Learning Background",
        "authors": "",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009315647.003"
    },
    {
        "id": 4323,
        "title": "Adversarial Defense Mechanisms for Supervised Learning",
        "authors": "Aneesh Sreevallabh Chivukula, Xinghao Yang, Bo Liu, Wei Liu, Wanlei Zhou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-99772-4_5"
    },
    {
        "id": 4324,
        "title": "Adversarial attacks beyond image classification",
        "authors": "Pin-Yu Chen, Cho-Jui Hsieh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00015-6"
    },
    {
        "id": 4325,
        "title": "Index",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.016"
    },
    {
        "id": 4326,
        "title": "Privacy-Preserving Mechanisms for SVM Learning",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.007"
    },
    {
        "id": 4327,
        "title": "References",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.015"
    },
    {
        "id": 4328,
        "title": "Dedication",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00004-1"
    },
    {
        "id": 4329,
        "title": "Copyright",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00003-x"
    },
    {
        "id": 4330,
        "title": "Adversarial Examples Against Machine Learning Models",
        "authors": "",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4135/9781529602258"
    },
    {
        "id": 4331,
        "title": "Glossary",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.014"
    },
    {
        "id": 4332,
        "title": "Introduction",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.001"
    },
    {
        "id": 4333,
        "title": "Adversarial Machine Learning",
        "authors": "Fabio Roli",
        "published": "No Date",
        "citations": 0,
        "abstract": "Machine-learning algorithms are widely used for cybersecurity applications, including spam, malware detection, biometric recognition. In these applications, the learning algorithm must face intelligent and adaptive attackers who can carefully manipulate data to purposely subvert the learning process. As machine learning algorithms have not been originally designed under such premises, they have been shown to be vulnerable towell-crafted attacks, including test-time evasion and training-time poisoning attacks (also known as adversarial examples).This talk aims to introduce the fundamentals of adversarial machine learning and some techniques to assess the vulnerability of machine-learning algorithms to adversarial attacks. We report application examples including object recognition in images, biometric identity recognition, spam, and malware detection.",
        "link": "http://dx.doi.org/10.52843/cassyni.bcgygr"
    },
    {
        "id": 4334,
        "title": "Adversarial robustness of beyond neural network models",
        "authors": "Pin-Yu Chen, Cho-Jui Hsieh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00027-2"
    },
    {
        "id": 4335,
        "title": "Adversarial Attack Surfaces",
        "authors": "Aneesh Sreevallabh Chivukula, Xinghao Yang, Bo Liu, Wei Liu, Wanlei Zhou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-99772-4_3"
    },
    {
        "id": 4336,
        "title": "Biography",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00006-5"
    },
    {
        "id": 4337,
        "title": "Index",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00035-1"
    },
    {
        "id": 4338,
        "title": "Generative Adversarial Networks-aided Intrusion Detection System",
        "authors": "V. Kumar",
        "published": "2023-3-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003203964-6"
    },
    {
        "id": 4339,
        "title": "Correction to: Adversarial Machine Learning Attack Surfaces, Defence Mechanisms, Learning Theories in Artificial Intelligence",
        "authors": "Aneesh Sreevallabh Chivukula, Xinghao Yang, Bo Liu, Wei Liu, Wanlei Zhou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-99772-4_8"
    },
    {
        "id": 4340,
        "title": "References",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00034-x"
    },
    {
        "id": 4341,
        "title": "Contents",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00005-3"
    },
    {
        "id": 4342,
        "title": "On the Adversarial Robustness of Subspace Learning",
        "authors": "Fuwei Li, Lifeng Lai, Shuguang Cui",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-16375-3_4"
    },
    {
        "id": 4343,
        "title": "Robust Deep Regression and Active Learning",
        "authors": "",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009315647.013"
    },
    {
        "id": 4344,
        "title": "Emotion Detection Using Generative Adversarial Network",
        "authors": "Sima Das, Ahona Ghosh",
        "published": "2023-3-8",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003203964-11"
    },
    {
        "id": 4345,
        "title": "Appendix A: Background for Learning and Hyper-Geometry",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.010"
    },
    {
        "id": 4346,
        "title": "Adversarial robustness in federated learning",
        "authors": "Chulin Xie, Xiaoyang Wang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-44-319037-7.00013-2"
    },
    {
        "id": 4347,
        "title": "Transcend Adversarial Examples: Diversified Adversarial Attacks to Test Deep Learning Model",
        "authors": "Wei Kong",
        "published": "2023-11-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccd58817.2023.00013"
    },
    {
        "id": 4348,
        "title": "Generative Adversarial Networks",
        "authors": "",
        "published": "2022-8-18",
        "citations": 112,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108891530.013"
    },
    {
        "id": 4349,
        "title": "References",
        "authors": "",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009315647.017"
    },
    {
        "id": 4350,
        "title": "Preface",
        "authors": "",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009315647.001"
    },
    {
        "id": 4351,
        "title": "Background and Notation",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.002"
    },
    {
        "id": 4352,
        "title": "Improving Learning in a Mobile Robot using Adversarial Training",
        "authors": "Todd Flyr, Simon Parsons",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010107100820089"
    },
    {
        "id": 4353,
        "title": "Adversarial Perturbation for Privacy Preservation",
        "authors": "Aneesh Sreevallabh Chivukula, Xinghao Yang, Bo Liu, Wei Liu, Wanlei Zhou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-99772-4_7"
    },
    {
        "id": 4354,
        "title": "Front Matter",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00002-8"
    },
    {
        "id": 4355,
        "title": "Index",
        "authors": "",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009315647.018"
    },
    {
        "id": 4356,
        "title": "Generative Adversarial Networks for Video-to-Video Translation",
        "authors": "Yogini Borole, Roshani Raut",
        "published": "2023-3-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003203964-4"
    },
    {
        "id": 4357,
        "title": "Analyzing Adversarial Attacks against Deep Learning for Robot Navigation",
        "authors": "Mohamed Ibn Khedher, Mehdi Rezzoug",
        "published": "2021",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010323611141121"
    },
    {
        "id": 4358,
        "title": "Attacking a Hypersphere Learner",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.004"
    },
    {
        "id": 4359,
        "title": "Delving Deep into Adversarial Attack for Multi-label Learning",
        "authors": "Fengguang Su",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>This research mainly focuses on adversarial attacks in multi-label learning. We analyze the shortcomings of existing research in optimization objectives and solution methods. Then, we constructed a new measure for the optimization objects based on the Jaccrd index. Furthermore, we propose a novel approach to solving the optimization problem.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22714999"
    },
    {
        "id": 4360,
        "title": "Delving Deep into Adversarial Attack for Multi-label Learning",
        "authors": "Fengguang Su",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>This research mainly focuses on adversarial attacks in multi-label learning. We analyze the shortcomings of existing research in optimization objectives and solution methods. Then, we constructed a new measure for the optimization objects based on the Jaccrd index. Furthermore, we propose a novel approach to solving the optimization problem.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22714999.v2"
    },
    {
        "id": 4361,
        "title": "Delving Deep into Adversarial Attack for Multi-label Learning",
        "authors": "Fengguang Su",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>This research mainly focuses on adversarial attacks in multi-label learning. We analyze the shortcomings of existing research in optimization objectives and solution methods. Then, we constructed a new measure for the optimization objects based on the Jaccrd index. Furthermore, we propose a novel approach to solving the optimization problem.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22714999.v1"
    },
    {
        "id": 4362,
        "title": "When Explainability Meets Adversarial Learning: Detecting Adversarial Examples using SHAP Signatures",
        "authors": "Gil Fidel, Ron Bitton, Asaf Shabtai",
        "published": "2020-7",
        "citations": 47,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn48605.2020.9207637"
    },
    {
        "id": 4363,
        "title": "Learning Ordered Top-k Adversarial Attacks via Adversarial Distillation",
        "authors": "Zekun Zhang, Tianfu Wu",
        "published": "2020-6",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvprw50498.2020.00396"
    },
    {
        "id": 4364,
        "title": "Analysing Adversarial Examples for Deep Learning",
        "authors": "Jason Jung, Naveed Akhtar, Ghulam Hassan",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010313705850592"
    },
    {
        "id": 4365,
        "title": "Evaluating Deep Learning-based NIDS in Adversarial Settings",
        "authors": "Hesamodin Mohammadian, Arash Habibi Lashkari, Ali A. Ghorbani",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010867900003120"
    },
    {
        "id": 4366,
        "title": "Collaborative Learning of Generative Adversarial Networks",
        "authors": "Takuya Tsukahara, Tsubasa Hirakawa, Takayoshi Yamashita, Hironobu Fujiyoshi",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010251804920499"
    },
    {
        "id": 4367,
        "title": "Incremental Data Augmentation and Classification Learning Based on Interactive-Learning Generative Adversarial Network",
        "authors": "Sukhan Lee, Seunghwan Kim",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4641401"
    },
    {
        "id": 4368,
        "title": "Leveraging Dual-Generative Adversarial Networks for Adversarial Malware Detection via Ensemble Learning",
        "authors": "Lucas Gordon",
        "published": "2023-8-29",
        "citations": 0,
        "abstract": "\r\n\r\n\r\n\r\nIn the expanding realm of cybersecurity, machine learning-based malware detection has emerged as a vital line of defense. However, the growing sophistication of malware attacks poses formidable challenges to conventional detection systems. To address this, this paper uses a Generative Adversarial Network that utilizes dual generators for adversarial learning on malware, designed to enhance the detection of harmful Portable Executable (PE) files. Our model employs a two-tiered generator system within the GAN architecture, where the secondary generator intervenes when the primary generator yields a malware PE executable dismissed by the detector.\r\nThe detection unit leverages ensemble learning techniques to analyze the PE software feature vector, capitalizing on the synergy of multiple learning models for improved performance and generalization. This setup empowers the system to generate a broader range of adversarial examples and respond to them effectively, enhancing the robustness of the detector against previously unseen or variable malware types.\r\n\r\n\r\n\r\n",
        "link": "http://dx.doi.org/10.24908/iqurcp16688"
    },
    {
        "id": 4369,
        "title": "Physical World Adversarial Attacks on Images and Texts",
        "authors": "Aneesh Sreevallabh Chivukula, Xinghao Yang, Bo Liu, Wei Liu, Wanlei Zhou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-99772-4_6"
    },
    {
        "id": 4370,
        "title": "Appendix C: Analysis of SpamBayes",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.012"
    },
    {
        "id": 4371,
        "title": "An Introduction to Generative Adversarial Learning: Architectures and Applications",
        "authors": "Roozbeh Razavi-Far, Ariel Ruiz-Garcia, Vasile Palade",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-91390-8_1"
    },
    {
        "id": 4372,
        "title": "Adversarial-Playground: A visualization suite showing how adversarial examples fool deep learning",
        "authors": "Andrew P. Norton, Yanjun Qi",
        "published": "2017-10",
        "citations": 24,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/vizsec.2017.8062202"
    },
    {
        "id": 4373,
        "title": "Using Conditional Generative Adversarial Networks to Boost the Performance of Machine Learning in Microbiome Datasets",
        "authors": "Derek Reiman, Yang Dai",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009892601030110"
    },
    {
        "id": 4374,
        "title": "Availability Attack Case Study: SpamBayes",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.005"
    },
    {
        "id": 4375,
        "title": "Near-Optimal Evasion of Classifiers",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.008"
    },
    {
        "id": 4376,
        "title": "Fair Data Generation and Machine Learning Through Generative Adversarial Networks",
        "authors": "Xintao Wu, Depeng Xu, Shuhan Yuan, Lu Zhang",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-91390-8_3"
    },
    {
        "id": 4377,
        "title": "Mobile Robot Navigation Strategies Through Behavioral Cloning and Generative Adversarial Imitation Learning",
        "authors": "Kevin Silva, Rodrigo Calvo",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011856700003467"
    },
    {
        "id": 4378,
        "title": "Adversarial Machine Learning: A Comparative Study on Contemporary Intrusion Detection Datasets",
        "authors": "Yulexis Pacheco, Weiqing Sun",
        "published": "2021",
        "citations": 23,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010253501600171"
    },
    {
        "id": 4379,
        "title": "Targeted Adversarial Learning Optimized Sampling",
        "authors": "Jun Zhang, Yi Isaac Yang, Frank Noé",
        "published": "No Date",
        "citations": 1,
        "abstract": "<div>Abstract Boosting transitions of rare events is critical to modern-day simulations of complex dynamic systems. We present a novel approach to modify the potential energy surface in order to drive the system to a user-defined target distribution where the free energy barrier is lowered. The new approach, called targeted adversarial learning optimized sampling (TALOS) combines the strengths of statistical mechanics and deep learning. By casting the enhanced sampling problem as a competing game between a real sampling engine and a virtual discriminator, TALOS enables unsupervised construction of bias potential on an arbitrary dimensional space and seeks for an optimal transport plan that transforms the system into target. Through multiple experiments we show that on-the-fly training of TALOS benefits from the state-of-art optimization techniques in deep learning, thus is efficient, robust and interpretable. Additionally, TALOS is closely connected to actor-critic reinforcement learning, giving rise to a new approach to manipulating the Hamiltonian systems via deep learning.</div>",
        "link": "http://dx.doi.org/10.26434/chemrxiv.7932371"
    },
    {
        "id": 4380,
        "title": "Support Vector Machines (SVMs)",
        "authors": "",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781009315647.016"
    },
    {
        "id": 4381,
        "title": "Enhancing the Adversarial Robustness in Medical Image Classification: Exploring Adversarial Machine Learning with Vision Transformers-Based Models",
        "authors": "Elif Kanca, Selen Ayas, Elif Baykal Kablan, Murat Ekinci",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4605358"
    },
    {
        "id": 4382,
        "title": "Learning Attention for Object Tracking with Adversarial Learning Network",
        "authors": "Xu Cheng, Chen Song, Yongxiang Gu, Beijing Chen",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nArtificial intelligence has been widely studied on solving intelligent surveillance analysis and security problems in recent years. Although many multimedia security approaches have been proposed by using deep learning network model, there are still some challenges on their performances which deserve in-depth research. On one hand, high computational complexity of current deep learning methods makes it hard to be applied to real-time scenario. On the other hand, it is difficult to obtain the specific features of a video by fine-tuning the network online with the object state of the first frame, which fails to capture rich appearance variations of the object. To solve above two issues, in this paper, an effective object tracking method with learning attention is proposed to achieve the object localization and reduce the training time in adversarial learning framework. First, a prediction network is designed to track the object in video sequences. The object positions of the first ten frames are employed to fine-tune prediction network, which can fully mine a specific features of an object. Second, the prediction network is integrated into the generative adversarial network framework, which randomly generates masks to capture object appearance variations via adaptively dropout input features. Third, we present a spatial attention mechanism to improve the tracking performance. The proposed network can identify the mask that maintains the most robust features of the objects over a long temporal span. Extensive experiments on two large-scale benchmarks demonstrate that the proposed algorithm performs favorably against state-of-the-art methods.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-15512/v1"
    },
    {
        "id": 4383,
        "title": "Learning Attention for Object Tracking with Adversarial Learning Network",
        "authors": "Xu Cheng, Chen Song, Yongxiang Gu, Beijing Chen",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nArtificial intelligence has been widely studied on solving intelligent surveillance analysis and security problems in recent years. Although many multimedia security approaches have been proposed by using deep learning network model, there are still some challenges on their performances which deserve in-depth research. On one hand, high computational complexity of current deep learning methods makes it hard to be applied to real-time scenario. On the other hand, it is difficult to obtain the specific features of a video by fine-tuning the network online with the object state of the first frame, which fails to capture rich appearance variations of the object. To solve above two issues, in this paper, an effective object tracking method with learning attention is proposed to achieve the object localization and reduce the training time in adversarial learning framework. First, a prediction network is designed to track the object in video sequences. The object positions of the first ten frames are employed to fine-tune prediction network, which can fully mine a specific features of an object. Second, the prediction network is integrated into the generative adversarial network framework, which randomly generates masks to capture object appearance variations via adaptively dropout input features. Third, we present a spatial attention mechanism to improve the tracking performance. The proposed network can identify the mask that maintains the most robust features of the objects over a long temporal span. Extensive experiments on two large-scale benchmarks demonstrate that the proposed algorithm performs favorably against state-of-the-art methods.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-15512/v2"
    },
    {
        "id": 4384,
        "title": "Adversarial Latent Representation Learning for Speech Enhancement",
        "authors": "Yuanhang Qiu, Ruili Wang",
        "published": "2020-10-25",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2020-1593"
    },
    {
        "id": 4385,
        "title": "Targeted Adversarial Learning Optimized Sampling",
        "authors": "Jun Zhang, Yi Isaac Yang, Frank Noé",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract Boosting transitions of rare events is critical to modern-day simulations of complex dynamic systems. We present a novel approach to modify the potential energy surface in order to drive the system to a user-defined target distribution where the free energy barrier is lowered. The new approach, called targeted adversarial learning optimized sampling (TALOS) combines the strengths of statistical mechanics and deep learning. By casting the enhanced sampling problem as a competing game between a real sampling engine and a virtual discriminator, TALOS enables unsupervised construction of bias potential on an arbitrary dimensional space and seeks for an optimal transport plan that transforms the system into target. Through multiple experiments we show that on-the-fly training of TALOS benefits from the state-of-art optimization techniques in deep learning, thus is efficient, robust and interpretable. Additionally, TALOS is closely connected to actor-critic reinforcement learning, giving rise to a new approach to manipulating the Hamiltonian systems via deep learning.",
        "link": "http://dx.doi.org/10.26434/chemrxiv.7932371.v2"
    },
    {
        "id": 4386,
        "title": "Adversarial Learning in Accelerometer Based Transportation and Locomotion Mode Recognition",
        "authors": "Lukas Günthermann, Lin Wang, Ivor Simpson, Andrew Philippides, Daniel Roggen",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-91390-8_10"
    },
    {
        "id": 4387,
        "title": "CoachGAN: Fast Adversarial Transfer Learning between Differently Shaped Entities",
        "authors": "Mehdi Mounsif, Sébastien Lengagne, Benoit Thuilot, Lounis Adouane",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009972200890096"
    },
    {
        "id": 4388,
        "title": "Generative Adversarial Phonology: Modeling unsupervised allophonic learning with neural networks",
        "authors": "Gasper Begus",
        "published": "No Date",
        "citations": 0,
        "abstract": "Training deep neural networks on well-understood dependencies in speech data can provide new insights into how they learn internal representations. This paper argues that acquisition of speech can be modeled as a dependency between random space and generated speech data in the Generative Adversarial Network architecture and proposes a methodology to uncover the network's internal representations that correspond to phonetic and phonological properties. The Generative Adversarial architecture is uniquely appropriate for modeling phonetic and phonological learning because the network is trained on unannotated raw acoustic data and learning is unsupervised without any language-specific assumptions or pre-assumed levels of abstraction. A Generative Adversarial Network was trained on an allophonic distribution in English, in which voiceless stops surface as aspirated word-initially before stressed vowels, except if preceded by a sibilant [s]. The network successfully learns the allophonic alternation: the network's generated speech signal contains the conditional distribution of aspiration duration. The paper proposes a technique for establishing the network's internal representations that identifies latent variables that correspond to, for example, presence of [s] and its spectral properties. By manipulating these variables, we actively control the presence of [s] and its frication amplitude in the generated outputs. This suggests that the network learns to use latent variables as an approximation of phonetic and phonological representations. Crucially, we observe that the dependencies learned in training extend beyond the training interval, which allows for additional exploration of learning representations. The paper also discusses how the network's architecture and innovative outputs resemble and differ from linguistic behavior in language acquisition, speech disorders, and speech errors, and how well-understood dependencies in speech data can help us interpret how neural networks learn their representations.",
        "link": "http://dx.doi.org/10.31234/osf.io/ptd3a"
    },
    {
        "id": 4389,
        "title": "Prognostics with Variational Auto-encoder by Generative Adversarial Learning",
        "authors": "Yufei Tang, Yu Huang",
        "published": "No Date",
        "citations": 0,
        "abstract": "<div>Prognostics predicts future performance progression</div><div>and remaining useful life (RUL) of in-service systems</div><div>based on historical/contemporary data. One of the challenges for prognostics is the development of methods which are capable of handling real-world uncertainties that typically lead to inaccurate predictions. To alleviate the impacts of uncertainties and to achieve accurate degradation trajectory and RUL predictions, a novel sequence-to-sequence predictive model is proposed based on a variational auto-encoder (VAE) that is trained with Generative Adversarial Networks (GAN). A Long Short-Term Memory (LSTM) network and Gaussian mixture model are utilized as building blocks so that the model is capable of providing probabilistic predictions. Correlative and monotonic metrics are applied to identify sensitive features in the degradation progress, in order to reduce the uncertainty induced by raw data. Then, the extracted features are concatenated with one-hot health</div><div>state indicators as training data for the model to learn the end-of-life (EoL) without the need for prior knowledge of failure thresholds. The performance of the proposed model is validated by health monitoring data collected from real-world aero-engines, wind turbines, and lithium-ion batteries. The results demonstrate that significant performance improvement can be achieved in long-term degradation progress and RUL prediction tasks.</div>",
        "link": "http://dx.doi.org/10.36227/techrxiv.12751172"
    },
    {
        "id": 4390,
        "title": "Prognostics with Variational Auto-encoder by Generative Adversarial Learning",
        "authors": "Yufei Tang, Yu Huang",
        "published": "No Date",
        "citations": 0,
        "abstract": "<div>Prognostics predicts future performance progression</div><div>and remaining useful life (RUL) of in-service systems</div><div>based on historical/contemporary data. One of the challenges for prognostics is the development of methods which are capable of handling real-world uncertainties that typically lead to inaccurate predictions. To alleviate the impacts of uncertainties and to achieve accurate degradation trajectory and RUL predictions, a novel sequence-to-sequence predictive model is proposed based on a variational auto-encoder (VAE) that is trained with Generative Adversarial Networks (GAN). A Long Short-Term Memory (LSTM) network and Gaussian mixture model are utilized as building blocks so that the model is capable of providing probabilistic predictions. Correlative and monotonic metrics are applied to identify sensitive features in the degradation progress, in order to reduce the uncertainty induced by raw data. Then, the extracted features are concatenated with one-hot health</div><div>state indicators as training data for the model to learn the end-of-life (EoL) without the need for prior knowledge of failure thresholds. The performance of the proposed model is validated by health monitoring data collected from real-world aero-engines, wind turbines, and lithium-ion batteries. The results demonstrate that significant performance improvement can be achieved in long-term degradation progress and RUL prediction tasks.</div>",
        "link": "http://dx.doi.org/10.36227/techrxiv.12751172.v1"
    },
    {
        "id": 4391,
        "title": "Targeted Adversarial Learning Optimized Sampling",
        "authors": "Jun Zhang, Yi Isaac Yang, Frank Noé",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract Boosting transitions of rare events is critical to modern-day simulations of complex dynamic systems. We present a novel approach to modify the potential energy surface in order to drive the system to a user-defined target distribution where the free energy barrier is lowered. The new approach, called targeted adversarial learning optimized sampling (TALOS) combines the strengths of statistical mechanics and deep learning. By casting the enhanced sampling problem as a competing game between a real sampling engine and a virtual discriminator, TALOS enables unsupervised construction of bias potential on an arbitrary dimensional space and seeks for an optimal transport plan that transforms the system into target. Through multiple experiments we show that on-the-fly training of TALOS benefits from the state-of-art optimization techniques in deep learning, thus is efficient, robust and interpretable. Additionally, TALOS is closely connected to actor-critic reinforcement learning, giving rise to a new approach to manipulating the Hamiltonian systems via deep learning.",
        "link": "http://dx.doi.org/10.26434/chemrxiv.7932371.v3"
    },
    {
        "id": 4392,
        "title": "Review for \"Preserving node similarity adversarial learning graph representation with graph neural network\"",
        "authors": "",
        "published": "2023-11-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/eng2.12854/v2/review1"
    },
    {
        "id": 4393,
        "title": "A Taxonomy and Terminology of Adversarial Machine Learning",
        "authors": "Elham Tabassi",
        "published": "2023",
        "citations": 12,
        "abstract": "",
        "link": "http://dx.doi.org/10.6028/nist.ai.100-2"
    },
    {
        "id": 4394,
        "title": "Robustness Against Adversarial Attacks Via Learning Confined Adversarial Polytopes",
        "authors": "Shayan Mohajer Hamidi, Linfeng Ye",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446776"
    },
    {
        "id": 4395,
        "title": "Data augmentation for unsupervised machine learning",
        "authors": "Pin-Yu Chen, Cho-Jui Hsieh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-824020-5.00033-8"
    },
    {
        "id": 4396,
        "title": "Underwater Image Enhancement Using Generative Adversarial Network",
        "authors": "Nisha Singh Gaur, Mukesh D. Patil, Gajanan K. Birajdar",
        "published": "2023-3-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003203964-12"
    },
    {
        "id": 4397,
        "title": "Adversarial learning games with deep learning models",
        "authors": "Aneesh Sreevallabh Chivukula, Wei Liu",
        "published": "2017-5",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2017.7966196"
    },
    {
        "id": 4398,
        "title": "Feedback Adversarial Learning: Spatial Feedback for Improving Generative Adversarial Networks",
        "authors": "Minyoung Huh, Shao-Hua Sun, Ning Zhang",
        "published": "2019-6",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr.2019.00157"
    },
    {
        "id": 4399,
        "title": "Targeted Adversarial Learning Optimized Sampling",
        "authors": "Jun Zhang, Yi Isaac Yang, Frank Noé",
        "published": "No Date",
        "citations": 0,
        "abstract": "Boosting transitions of rare events is critical to modern-day simulations of complex dynamic systems. We present a novel approach to modify the potential energy surface in order to drive the system to a user-defined target distribution where the free energy barrier is lowered. The new approach, called targeted adversarial learning optimized sampling (TALOS), cross-fertilizes statistical mechanics and deep learning. By casting the enhanced sampling problem as a competing game between a real sampling engine and a virtual discriminator, TALOS enables unsupervised construction of bias potential on an arbitrary dimensional space and seeks for an optimal transport plan that transforms the system into target. Through multiple experiments we show that on-the-fly training of TALOS benefits from the state-of-art optimization techniques in deep learning, thus is efficient, robust and interpretable. TALOS can also simultaneously learn to extract good reaction coordinate from a high-dimensional space where bias potential is being constructed. Additionally, TALOS is shown to be closely related to reinforcement learning, giving rise to a new framework of manipulating Hamiltonian in order to fulfill user-specified tasks via deep learning.",
        "link": "http://dx.doi.org/10.26434/chemrxiv.7932371.v1"
    },
    {
        "id": 4400,
        "title": "Integrity Attack Case Study: PCA Detector",
        "authors": "",
        "published": "2019-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781107338548.006"
    }
]