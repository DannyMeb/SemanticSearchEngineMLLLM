[
    {
        "id": 2905,
        "title": "From applied ethics and ethical principles to virtue and narrative in AI practices",
        "authors": "Paul Hayes, Noel Fitzpatrick, José Manuel Ferrández",
        "published": "2024-4-8",
        "citations": 0,
        "abstract": "AbstractThe question of how we can use ethics and ethical frameworks to avert the negative consequences of AI through guidance on human behaviour and the design of technological systems has recently been receiving increasing attention. The appropriate response to an ethics of AI has certainly been contentious. For some years the wisdom of deontology and utilitarianism in the ethics of technology has been questioned. Today, a kind of AI ethics principlism has gained a degree of widespread acceptance, yet it still invites harsh rejections in recent scholarship. In this paper, we wish to explore the contribution to an ethics of AI made by a narrative philosophy and ethics of technology inspired by the ‘little ethics’ of Paul Ricoeur, and virtue ethics of Alasdair MacIntyre, most recently and promisingly built upon by Wessel Reijers and Mark Coeckelbergh.  The objective of this paper is to examine the extent to which a narrative and virtue based ethics (or, VPD, i.e., virtuous practice design) might be a plausible candidate for the foundation of an ethics of AI, or rather ethical AI practice. This will be achieved by exploring the ways in which this approach can respond to some of the significant faults with or critiques of applied and principles and guidelines based ethical approaches to AI ethics.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00472-z"
    },
    {
        "id": 2906,
        "title": "The Epistemic Status of AI in Medical Practices: Ethical Challenges",
        "authors": "Angelina Baeva",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "In recent years, discussions have been increasingly emerging in modern scientific research that, in connection with the development of AI technologies, questions arise about the objectivity, plausibility and reliability of knowledge, as well as whether these technologies will not replace the expert figure as the authority that has so far acted as a guarantor of objectivity and the center of decision-making. Modern historians of science Duston L. and Galison P. in their book on the history of scientific objectivity, they talk about the alternation of \"epistemic virtues\", as one of which objectivity has been established since a certain moment. At the same time, the promotion of one or another virtue regulating the scientific self, i.e. acting as a normative principle for a scientist when choosing one or another way of seeing and one or another scientific practice, depends on making decisions in difficult cases requiring the will and limitation of the self. In this sense, epistemology is combined with ethics: a scientist, guided by certain moral principles, gives preference to one or another way of behavior, choosing, for example, not a more accurate hand-drawn image, but an uncluttered photograph, perhaps fuzzy, but obtained mechanically, which means more objective and free from any admixture of subjectivity. In this regard, the epistemic status of modern AI-based technologies, which increasingly assume the functions of the scientific self, including in terms of influencing final decision-making and obtaining objective knowledge, seems interesting. For example, in the field of medicine, robotic devices already provide significant support, taking over some of the functions, for example, of a first-level doctor to collect and analyze standardized patient data and diagnostics. There is an assumption that AI will take on more and more responsibilities in the near future: data processing, development of new drugs and treatment methods, establishing remote interaction with the patient, etc. But does this mean that the scientific self can be replaced by AI-based algorithms, and another epistemic virtue will replace objectivity, finally breaking the link between ethics and epistemology – this question needs to be investigated.",
        "keywords": "",
        "link": "http://dx.doi.org/10.17816/dd625319"
    },
    {
        "id": 2907,
        "title": "Accountability for Responsible AI Practices: Ethical Responsibilities of Senior Leadership",
        "authors": "Alex John London",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4736880"
    },
    {
        "id": 2908,
        "title": "Ethical Requirements Stack: A framework for implementing ethical requirements of AI in software engineering practices",
        "authors": "Mamia Agbese, Rahul Mohanani, Arif Ali Khan, Pekka Abrahamsson",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3593434.3593489"
    },
    {
        "id": 2909,
        "title": "Navigating the AI frontier: ethical considerations and best practices in microbial genomics research",
        "authors": "Andrew J. Page, Niamh M. Tumelty, Samuel K. Sheppard",
        "published": "2023-6-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1099/mgen.0.001049"
    },
    {
        "id": 2910,
        "title": "Balancing the scale: navigating ethical and practical challenges of artificial intelligence (AI) integration in legal practices",
        "authors": "Ammar Zafar",
        "published": "2024-4-15",
        "citations": 0,
        "abstract": "AbstractThe paper explores the integration of artificial intelligence in legal practice, discussing the ethical and practical issues that arise and how it affects customary legal procedures. It emphasises the shift from labour-intensive legal practice to technology-enhanced methods, with a focus on artificial intelligence's potential to improve access to legal services and streamline legal procedures. This discussion importantly highlights the ethical challenges introduced by the integration of Artificial Intelligence, with a specific focus on issues of bias and transparency. These ethical concerns become particularly paramount in the context of sensitive legal areas, including but not limited to, child custody disputes, criminal justice, and divorce settlements. It underscores the critical need for maintaining ethical vigilance, advocating for developing and implementing AI systems characterised by a profound commitment to ethical integrity. This approach is vital to guarantee fairness and uphold transparency across all judicial proceedings. The study advocates for a \"human in the loop\" strategy that combines human knowledge and AI techniques to mitigate biases and guarantee individualised legal results to ensure AI functions as a complement rather than a replacement, the paper concludes by emphasising the necessity of preserving the human element in legal practices.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s44163-024-00121-8"
    },
    {
        "id": 2911,
        "title": "From principles to practices: the intertextual interaction between AI ethical and legal discourses",
        "authors": "Le Cheng, Xiuli Liu",
        "published": "2023-4-25",
        "citations": 6,
        "abstract": "Abstract\nThe ascendancy and ubiquity of generative AI technology, exemplified by ChatGPT, has resulted in a transformative shift in the conventional human–AI interaction paradigm, leading to substantial alterations in societal modes of production. Drawing on CDA approach, this study conducts a thematic intertextuality analysis of 29 AI ethical documents, and delves into the restructuring of the human–AI relations catalysed by ChatGPT, as well as the complex ethical and legal challenges it presents. The findings indicate that the thematic intertextuality between AI ethical discourse and legal discourse promotes the connection and convergence of narrative-ideological structures, which in turn primarily creates new meaningful texts and ethical frameworks that promote a holistic approach to a good AI society. This research also identifies the importance of integrating law-making efforts with substantive ethical analysis and appropriate discursive strategies to promote the responsible and ethical development of generative AI that benefits society as a whole.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1515/ijld-2023-2001"
    },
    {
        "id": 2912,
        "title": "Generative conversational AI agent for managerial practices: The role of IQ dimensions, novelty seeking and ethical concerns",
        "authors": "Abdullah M. Baabdullah",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.techfore.2023.122951"
    },
    {
        "id": 2913,
        "title": "Ethical implications of AI in the Metaverse",
        "authors": "Alesia Zhuk",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "AbstractThis paper delves into the ethical implications of AI in the Metaverse through the analysis of real-world case studies, including Horizon Worlds, Decentraland, Roblox, Sansar, and Rec Room. The examination reveals recurring concerns related to content moderation, emphasising the need for a human-AI hybrid approach to strike a balance between creative freedom and user safety. Privacy and data protection emerge as crucial considerations, highlighting the importance of transparent communication and user data control for responsible AI implementation. Additionally, promoting inclusivity and diversity is emphasised, calling for transparent governance, diverse representation, and collaboration with ethics experts to ensure equitable AI practices. By addressing these specific ethical challenges, we can pave the way towards a responsible and user-centric Metaverse, maximising its potential while safeguarding user well-being and rights.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00450-5"
    },
    {
        "id": 2914,
        "title": "Artificial Intention: A Path to Ethical AI?",
        "authors": "Pawas Piyush",
        "published": "2023-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21275/sr231005155020"
    },
    {
        "id": 2915,
        "title": "Ensuring a ‘Responsible’ AI future in India: RRI as an approach for identifying the ethical challenges from an Indian perspective",
        "authors": "Nitika Bhalla, Laurence Brooks, Tonii Leach",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "AbstractArtificial intelligence (AI) can be seen to be at an inflexion point in India, a country which is keen to adopt and exploit new technologies, but needs to carefully consider how they do this. AI is usually deployed with good intentions, to unlock value and create opportunities for the people; however it does not come without its challenges. There are a set of ethical–social issues associated with AI, which include concerns around privacy, data protection, job displacement, historical bias and discrimination. Through a series of focus groups with knowledgeable people embedded in India and its culture, this research explores the ethical–societal changes and challenges that India now faces. Further, it investigates whether the principles and practices of responsible research and innovation (RRI) might provide a framework to help identify and deal with these issues. The results show that the areas in which RRI could offer scope to improve this outlook include education, policy and governance, legislation and regulation, and innovation and industry practices. Some significant challenges described by participants included: the lack of awareness of AI by the public as well as policy makers; India’s access and implementation of Western datasets, resulting in a lack of diversity, exacerbation of existing power asymmetries, increase in social inequality and the creation of bias; the potential replacement of jobs by AI. One option was to look at a hybrid approach, a mix of AI and humans, with expansion and upskilling of the current workforce. In terms of strategy, there seems to be a gap between the rhetoric of the government and what is seen on the ground, and therefore going forward there needs to be a much greater engagement with a wider audience of stakeholders.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00370-w"
    },
    {
        "id": 2916,
        "title": "Empathy: an ethical consideration of AI &amp; others in the workplace",
        "authors": "Denise Kleinrichert",
        "published": "2024-1-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01831-w"
    },
    {
        "id": 2917,
        "title": "Equity, autonomy, and the ethical risks and opportunities of generalist medical AI",
        "authors": "Reuben Sass",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00380-8"
    },
    {
        "id": 2918,
        "title": "Artificial consciousness: the missing ingredient for ethical AI?",
        "authors": "Antonio Chella",
        "published": "2023-11-21",
        "citations": 1,
        "abstract": "Can we conceive machines that can formulate autonomous intentions and make conscious decisions? If so, how would this ability affect their ethical behavior? Some case studies help us understand how advances in understanding artificial consciousness can contribute to creating ethical AI systems.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/frobt.2023.1270460"
    },
    {
        "id": 2919,
        "title": "Ethical Considerations in the Use of Disfluencies in AI-Generated Speech",
        "authors": "Ralph Rose",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011987200003470"
    },
    {
        "id": 2920,
        "title": "The ethical wisdom of AI developers",
        "authors": "Tricia A. Griffin, Brian P. Green, Jos V.M. Welie",
        "published": "2024-3-20",
        "citations": 0,
        "abstract": "AbstractThis paper explores ethical wisdom in the artificial intelligence (AI) developer community. Despite robust literature about the need for virtue ethics approaches in AI development, little research has directly engaged with the developer community about their progress in this regard. We have thus conducted semi-structured interviews with a worldwide cohort of 40 developers, which focused on their awareness of ethics issues, how they navigate ethical challenges, and the barriers they encounter in developing ethical wisdom. We find developers are largely aware of the ethical territories they must navigate and the moral dilemmas they personally encounter, but they face limited and inconsistent resources for ethical guidance or training. Furthermore, there are significant barriers inhibiting the development of ethical wisdom in the AI developer community, including the industry’s fixation on innovation, the narrow scope of technical practice, limited provisions for reflection and dialogue, and incentive structures that prioritize profits and prestige. The paper concludes by emphasizing the need to address the gap in domain-specific ethical skill and provides recommendations for organizations, educators, and the AI developer community.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00458-x"
    },
    {
        "id": 2921,
        "title": "The ethical agency of AI developers",
        "authors": "Tricia A. Griffin, Brian Patrick Green, Jos V. M. Welie",
        "published": "2023-1-9",
        "citations": 6,
        "abstract": "AbstractPublic and academic discourse about the ethics of artificial intelligence, machine learning, and data science has largely focused on the algorithms and the companies deploying them. Little attention has been paid to the ethical agency of the developers. This study is the first of its kind that centers developers in the ethical environment. Semi-structured interviews with 40 developers about the ethics of being a developer revealed more than 20 themes, 3 of which are the subject of this paper: ethics in the occupational ecosystem, developer ethical agency, and the characteristics of an ethical developer. These themes reveal significant gaps between how developers perceive themselves and the reality of their work experiences. Their ethical agency is likewise variable. They have some authority to intervene for ethical reasons in systems they work on, but they often do not realize just how many ethical decisions they make. Nonetheless, this study reveals a growing ethical wisdom in this community, one that needs to be surfaced and nurtured by engaging with developers.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-022-00256-3"
    },
    {
        "id": 2922,
        "title": "The poverty of ethical AI: impact sourcing and AI supply chains",
        "authors": "James Muldoon, Callum Cant, Mark Graham, Funda Ustek Spilda",
        "published": "2023-12-20",
        "citations": 1,
        "abstract": "AbstractImpact sourcing is the practice of employing socio-economically disadvantaged individuals at business process outsourcing centres to reduce poverty and create secure jobs. One of the pioneers of impact sourcing is Sama, a training-data company that focuses on annotating data for artificial intelligence (AI) systems and claims to support an ethical AI supply chain through its business operations. Drawing on fieldwork undertaken at three of Sama’s East African delivery centres in Kenya and Uganda and follow-up online interviews, this article interrogates Sama’s claims regarding the benefits of its impact sourcing model. Our analysis reveals alarming accounts of low wages, insecure work, a tightly disciplined labour management process, gender-based exploitation and harassment and a system designed to extract value from low-paid workers to produce profits for investors. We argue that competitive market-based dynamics generate a powerful force that pushes such companies towards limiting the actual social impact of their business model in favour of ensuring higher profit margins. This force can be resisted, but only through countervailing measures such as pressure from organised workers, civil society, or regulation. These findings have broad implications related to working conditions for low-wage data annotators across the sector and cast doubt on the ethical nature of AI products that rely on this form of AI data work.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01824-9"
    },
    {
        "id": 2923,
        "title": "Suggestions for Ethical Decision-Making Model through Collaboration between Human and AI",
        "authors": "Hyunsoo Kim,  ",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "Purpose: The purpose of this study is to explore and propose a model that allows humans and AI to collaborate in the process of making decisions about ethical issues. Due to AI's autonomy and mission performance capabilities, AI is sometimes viewed as an agent competing with humans. However, since the autonomy and mission performance capabilities of AI are applied at very diverse levels and areas, it is necessary to set certain categories and review their application. This study sought to reveal that more valid decisions can be made by collaborating between humans and AI in the category of ethical decision-making.\r\nMethod: This study uses methods of literature research and development research. First, using literature research to review various previous studies to understand the autonomy of AI in the relationship between humans and AI. Next, analyzing the meaning and characteristics of ethical judgment. Next, looking at a series of models that explain decision making. Second, using development research methods, for design and propose a model in which humans and AI appropriately collaborate in the process of making ethical decisions.\r\nResults: The results of this study reveal the following points. First, the results of ethical decision-making by humans and AI involve greater responsibility and related issues than the results of general decision-making. Second, in order to solve these problems, it is necessary to utilize collective intelligence through collective decision-making and at the same time distribute responsibility. Third, as a public and collective entity functioning as a committee, humans become the subjects of final judgment and responsibility, and AI must play a role in actively and functionally assisting such judgment. Fourth, this decision-making process needs to be presented in the form of a model as a principle that can be applied to various specific cases.\r\nConclusion: The conclusion of this study suggests that effective and valid ethical decisions can be made through collaboration between humans and AI in the ethical communication process. And based on this, we present a collaboration model between humans and AI. This model consists of the following steps: First, AI should be actively involved in the process of exploring data sources, collecting data, storing data, and refining and analyzing data for ethical decisions. Second, ethical decisions based on this are made by a human community in the form of a committee as a group thinking process. Third, allow humans and AI to evaluate and exchange opinions on the results of these ethical judgments through mutual feedback and collaboration.",
        "keywords": "",
        "link": "http://dx.doi.org/10.22471/ai.2023.8.12"
    },
    {
        "id": 2924,
        "title": "Ethical AI governance: mapping a research ecosystem",
        "authors": "Simon Knight, Antonette Shibani, Nicole Vincent",
        "published": "2024-2-14",
        "citations": 0,
        "abstract": "AbstractHow do we assess the positive and negative impacts of research about- or research that employs artificial intelligence (AI), and how adequate are existing research governance frameworks for these ends? That concern has seen significant recent attention, with various calls for change, and a plethora of emerging guideline documents across sectors. However, it is not clear what kinds of issues are expressed in research ethics with or on AI at present, nor how resources are drawn on in this process to support the navigation of ethical issues. Research Ethics Committees (RECs) have a well-established history in ethics governance, but there have been concerns about their capacity to adequately govern AI research. However, no study to date has examined the ways that AI-related projects engage with the ethics ecosystem, or its adequacy for this context. This paper analysed a single institution’s ethics applications for research related to AI, applying a socio-material lens to their analysis. Our novel methodology provides an approach to understanding ethics ecosystems across institutions. Our results suggest that existing REC models can effectively support consideration of ethical issues in AI research, we thus propose that any new materials should be embedded in this existing well-established ecosystem.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00416-z"
    },
    {
        "id": 2925,
        "title": "Ethical and preventive legal technology",
        "authors": "Georgios Stathis, Jaap van den Herik",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "AbstractPreventive Legal Technology (PLT) is a new field of Artificial Intelligence (AI) investigating the intelligent prevention of disputes. The concept integrates the theories of preventive law and legal technology. Our goal is to give ethics a place in the new technology. By explaining the decisions of PLT, we aim to achieve a higher degree of trustworthiness because explicit explanations are expected to improve the level of transparency and accountability. Trustworthiness is an urgent topic in the discussion on doing AI research ethically and accounting for the regulations. For this purpose, we examine the limitations of rule-based explainability for PLT. Hence, our Problem Statement reads: to what extent is it possible to develop an explainable and trustworthy Preventive Legal Technology? After an insightful literature review, we focus on case studies with applications. The results describe (1) the effectivity of PLT and (2) its responsibility. The discussion is challenging and multivariate, investigating deeply the relevance of PLT for LegalTech applications in light of the development of the AI Act (currently still in its final phase of process) and the work of the High-Level Expert Group (HLEG) on AI. On the ethical side, explaining AI decisions for small PLT domains is clearly possible, with direct effects on trustworthiness due to increased transparency and accountability.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00413-2"
    },
    {
        "id": 2926,
        "title": "Could AI Ethical Anxiety, Perceived Ethical Risks and Ethical Awareness About AI Influence University Students’ Use of Generative AI Products? An Ethical Perspective",
        "authors": "Wenjuan Zhu, Lei Huang, Xinni Zhou, Xiaoya Li, Gaojun Shi, Jingxin Ying, Chaoyue Wang",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/10447318.2024.2323277"
    },
    {
        "id": 2927,
        "title": "A phenomenological perspective on AI ethical failures: The case of facial recognition technology",
        "authors": "Yuni Wen, Matthias Holweg",
        "published": "2023-4-1",
        "citations": 1,
        "abstract": "AbstractAs more and more companies adopt artificial intelligence to increase the efficiency and effectiveness of their products and services, they expose themselves to ethical crises and potentially damaging public controversy associated with its use. Despite the prevalence of AI ethical problems, most companies are strategically unprepared to respond effectively to the public. This paper aims to advance our empirical understanding of company responses to AI ethical crises by focusing on the rise and fall of facial recognition technology. Specifically, through a comparative case study of how four big technology companies responded to public outcry over their facial recognition programs, we not only demonstrated the unfolding and consequences of public controversies over this new technology, but also identified and described four major types of company responses—Deflection, Improvement, Validation, and Pre-emption. These findings pave the way for future research on the management of controversial technology and the ethics of AI.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01648-7"
    },
    {
        "id": 2928,
        "title": "AI risk assessment using ethical dimensions",
        "authors": "Alessio Tartaro, Enrico Panai, Mariangela Zoe Cocchiaro",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00401-6"
    },
    {
        "id": 2929,
        "title": "Ethical AI: Proposal to bridge the gap in EU regulation on trustworthy AI and to support practical implementation of ethical perspectives",
        "authors": "Alexandra Prisznyák",
        "published": "2023",
        "citations": 0,
        "abstract": "In 2020, GPT-3 defined itself as a thinking robot. The history of AI development is identified with machines becoming increasingly intelligent, but behind it lies the human factor, the soaring of the human mind. However, the question of machine ethics is also a question of cultural ethics. Based on in-depth interviews conducted in seven industries, the author reveals that ethical considerations are not yet taken into account in the development of AI systems. To support practical implementation, the author identifies two shortcomings based on a comparative analysis of the EU’s AI Act and Ethical Guidelines for Trustworthy AI: (1) missing ethical sensitisation and training of AI system developers and supervisors; (2) suggested approaches to handling harmful feedback loops and decision-making biases. The author uses the philosophical and ethical heritage of 21 philosophers as a compass to propose solutions for the identified gaps and deficiencies of organisational integration.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33908/ef.2023.2.4"
    },
    {
        "id": 2930,
        "title": "Corporate values, ethical leadership and social responsibility practices in mature SME’s in China: Basis for enhanced ethical leadership practices",
        "authors": "Lixia Tang",
        "published": "2023-8-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5861/ijrsm.2023.1053"
    },
    {
        "id": 2931,
        "title": "Corporate values, ethical leadership and social responsibility practices in mature SME’s in China: Basis for enhanced ethical leadership practices",
        "authors": "Lixia Tang",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5861/ijrsm.2023.1102"
    },
    {
        "id": 2932,
        "title": "Ethical considerations in emotion recognition technologies: a review of the literature",
        "authors": "Amelia Katirai",
        "published": "2023-6-20",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00307-3"
    },
    {
        "id": 2933,
        "title": "Using structured ethical techniques to facilitate reasoning in technology ethics",
        "authors": "Matt A. Murphy",
        "published": "2023-11-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00371-9"
    },
    {
        "id": 2934,
        "title": "When things go wrong: the recall of AI systems as a last resort for ethical and lawful AI",
        "authors": "Alessio Tartaro",
        "published": "2023-8-30",
        "citations": 0,
        "abstract": "AbstractThis paper presents an initial exploration of the concept of AI system recall, primarily understood as a last resort when AI systems violate ethical norms, societal expectations, or legal obligations. The discussion is spurred by recent incidents involving notable AI systems, demonstrating that AI recalls can be a very real necessity. This study delves into the concept of product recall as traditionally understood in industry and explores its potential application to AI systems. Our analysis of this concept is centered around two prominent categories of recall drivers in the AI domain: ethical-social and legal considerations. In terms of ethical-social drivers, we apply the innovative notion of “moral Operational Design Domain”, suggesting AI systems should be recalled when they violate ethical principles and societal expectation. In addition, we also explore the recall of AI systems from a legal perspective, where the recently proposed AI Act provides regulatory measures for recalling AI systems that pose risks to health, safety, and fundamental rights. The paper also underscores the need for further research, especially around defining precise ethical and societal triggers for AI recalls, creating an efficient recall management framework for organizations, and reassessing the fit of traditional product recall models for AI systems within the AI Act's regulatory context. By probing these complex intersections between AI, ethics, and regulation, this work aims to contribute to the development of robust and responsible AI systems while maintaining readiness for failure scenarios.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00327-z"
    },
    {
        "id": 2935,
        "title": "Ethical Issues Posed by ‘Generative-AI’ (G-AI) - Response strategies for ‘Good AI Society’",
        "authors": "Sunghee Yoo",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.37305/jkba.2023.06.24.1.1"
    },
    {
        "id": 2936,
        "title": "Ethical Considerations in ChatGPT AI",
        "authors": "Prof. Vivek Gupta, Ishika Bishwash, Rubina Dhital, Simren Sanjay, Anirudh Lodha, Deepesh M Jain",
        "published": "2024-3-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.55248/gengpi.5.0324.0877"
    },
    {
        "id": 2937,
        "title": "The human role to guarantee an ethical AI in healthcare: a five-facts approach",
        "authors": "Raquel Iniesta",
        "published": "2023-10-25",
        "citations": 2,
        "abstract": "AbstractWith the emergence of AI systems to assist clinical decision-making, several ethical dilemmas are brought to the general attention. AI systems are claimed to be the solution for many high-skilled medical tasks where machines can potentially surpass human ability as for example in identifying normal and abnormal chest X-rays. However, there are also warns that AI tools could be the basis for a human replacement that can risk dehumanisation in medicine. In recent years, important proposals in the domain of AI ethics in healthcare have identified main ethical issues, as for example fairness, autonomy, transparency, and responsibility. The human warranty, which implies human evaluation of the AI procedures, has been described to lower the ethical risks. However, as relevant these works have been, translating principles into action has proved challenging as existing codes were mostly a description of principles. There is a great need to produce how-to proposals that are specific enough to be action-guiding. We present five human-focussed facts designed into a framework of human action for an ethical AI in healthcare. Through the factors, we examine the role of medical practitioners, patients, and developers in designing, implementing, and using AI in a responsible manner that preserves human dignity. The facts encompass a range of ethical concerns that were commonly found in relevant literature. Given that it is crucial to bring as many perspectives as possible to the field, this work contributes to translate principles into human action to guarantee an ethical AI in health.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00353-x"
    },
    {
        "id": 2938,
        "title": "Ethical Considerations in AI: Navigating Bias, Fairness, and Accountability",
        "authors": "",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.48047/resmil.v10i1.22"
    },
    {
        "id": 2939,
        "title": "Review of “AI assurance: towards trustworthy, explainable, safe, and ethical AI” by Feras A. Batarseh and Laura J. Freeman, Academic Press, 2023",
        "authors": "Jialei Wang, Li Fu",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01802-1"
    },
    {
        "id": 2940,
        "title": "Socialisation approach to AI value acquisition: enabling flexible ethical navigation with built-in receptiveness to social influence",
        "authors": "Joel Janhonen",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": "AbstractThis article describes an alternative starting point for embedding human values into artificial intelligence (AI) systems. As applications of AI become more versatile and entwined with society, an ever-wider spectrum of considerations must be incorporated into their decision-making. However, formulating less-tangible human values into mathematical algorithms appears incredibly challenging. This difficulty is understandable from a viewpoint that perceives human moral decisions to primarily stem from intuition and emotional dispositions, rather than logic or reason. Our innate normative judgements promote prosocial behaviours which enable collaboration within a shared environment. Individuals internalise the values and norms of their social context through socialisation. The complexity of the social environment makes it impractical to consistently apply logic to pick the best available action. This has compelled natural agents to develop mental shortcuts and rely on the collective moral wisdom of the social group. This work argues that the acquisition of human values cannot happen just through rational thinking, and hence, alternative approaches should be explored. Designing receptiveness to social signalling can provide context-flexible normative guidance in vastly different life tasks. This approach would approximate the human trajectory for value learning, which requires social ability. Artificial agents that imitate socialisation would prioritise conformity by minimising detected or expected disapproval while associating relative importance with acquired concepts. Sensitivity to direct social feedback would especially be useful for AI that possesses some embodied physical or virtual form. Work explores the necessary faculties for social norm enforcement and the ethical challenges of navigating based on the approval of others.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00372-8"
    },
    {
        "id": 2941,
        "title": "Ethical AI does not have to be like finding a black cat in a dark room",
        "authors": "Apala Lahiri Chavan, Eric Schaffer",
        "published": "2023-5-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01661-w"
    },
    {
        "id": 2942,
        "title": "From ethical AI frameworks to tools: a review of approaches",
        "authors": "Erich Prem",
        "published": "2023-8",
        "citations": 20,
        "abstract": "AbstractIn reaction to concerns about a broad range of potential ethical issues, dozens of proposals for addressing ethical aspects of artificial intelligence (AI) have been published. However, many of them are too abstract for being easily translated into concrete designs for AI systems. The various proposed ethical frameworks can be considered an instance of principlism that is similar to that found in medical ethics. Given their general nature, principles do not say how they should be applied in a particular context. Hence, a broad range of approaches, methods, and tools have been proposed for addressing ethical concerns of AI systems. This paper presents a systematic analysis of more than 100 frameworks, process models, and proposed remedies and tools for helping to make the necessary shift from principles to implementation, expanding on the work of Morley and colleagues. This analysis confirms a strong focus of proposed approaches on only a few ethical issues such as explicability, fairness, privacy, and accountability. These issues are often addressed with proposals for software and algorithms. Other, more general ethical issues are mainly addressed with conceptual frameworks, guidelines, or process models. This paper develops a structured list and definitions of approaches, presents a refined segmentation of the AI development process, and suggests areas that will require more attention from researchers and developers.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00258-9"
    },
    {
        "id": 2943,
        "title": "Ethical Problems of Super-Massive Generative AI",
        "authors": "Sunyong Byun",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.46397/jaih.14.3"
    },
    {
        "id": 2944,
        "title": "The EU AI Act: A Comprehensive Regulatory Framework for Ethical AI Development",
        "authors": "Sean Musch, Michael Borrelli, Charles Kerrigan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4549248"
    },
    {
        "id": 2945,
        "title": "Ethical Uses of Artificial Intelligence AI",
        "authors": "Rasha Waheeb",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4507569"
    },
    {
        "id": 2946,
        "title": "Stream: social data and knowledge collective intelligence platform for TRaining Ethical AI Models",
        "authors": "Yuwei Wang, Enmeng Lu, Zizhe Ruan, Yao Liang, Yi Zeng",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01851-6"
    },
    {
        "id": 2947,
        "title": "Ethical considerations and policy interventions concerning the impact of generative AI tools in the economy and in society",
        "authors": "Mirko Farina, Xiao Yu, Andrea Lavazza",
        "published": "2024-1-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00405-2"
    },
    {
        "id": 2948,
        "title": "Ethical Dimensions in Contemporary Medical Practices: A Systematic Review and Analysis of Diverse Perspectives",
        "authors": "Taj R",
        "published": "2023",
        "citations": 0,
        "abstract": "Objective: This systematic review and analysis aim to comprehensively explore diverse ethical perspectives within contemporary medical practices. Acknowledging the complexity of ethical considerations in medicine influenced by cultural, socio-economic, and legal factors, the objective is to synthesize insights from various studies and delve into key themes such as patient autonomy, informed consent, healthcare equity, and the ethical implications of emerging technologies. Methodology: Adhering to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines 2020, this analysis systematically reviewed scholarly articles focusing on ethical considerations within modern medical practices from 2020 to 2023. A thorough screening process, based on specific Medical Subject Headings (MeSH) terms, was conducted in major databases (PubMed, Scopus, Web of Knowledge, and Google Scholar). Eleven relevant studies were included, representing diverse perspectives and ethical frameworks. Result: The systematic study selection process identified 11 relevant studies from an initial pool of 297 records. These studies covered a range of topics, including parental decision-making for adolescents with mental health issues, the legalization of medical cannabis, challenges in patient care during the COVID-19 pandemic and medical education ethics. The included studies were subjected to a meticulous evaluation of their characteristics, outcomes, and limitations. The findings contribute valuable insights into the multifaceted ethical dimensions of contemporary medical practices. Conclusion: This systematic review and analysis provide a comprehensive overview of diverse ethical perspectives inherent in contemporary medical practices. While recognizing the complexity of medical ethics, influenced by various factors, the study identifies patterns, gaps and divergent viewpoints within the selected studies. The analysis aims to inform practitioners, policymakers, and scholars engaged in ethical decision-making in healthcare, fostering a more informed and ethically robust approach to modern medical practices. Despite the limitations in some studies, the findings contribute to the ongoing discourse on medical ethics and highlight the need for further research and dialogue to address evolving ethical challenges in healthcare.",
        "keywords": "",
        "link": "http://dx.doi.org/10.23880/abca-16000264"
    },
    {
        "id": 2949,
        "title": "Ethical climate in business: The state of ethical climate, standards and practices in business organisations in Mauritius",
        "authors": "Oumeshsingh Sookdawoor",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4475612"
    },
    {
        "id": 2950,
        "title": "Navigating the Ethical Landscape: Considerations in Implementing AI-ML Systems in Human Resources",
        "authors": "Sunil Basnet",
        "published": "2024-3-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.55248/gengpi.5.0324.0755"
    },
    {
        "id": 2951,
        "title": "Navigating Generative AI: The Teacher Librarian's Role in Cultivating Ethical and Critical Practices",
        "authors": "Kay Oddone, Kasey Garrison, Krystal Gagen-Spriggs",
        "published": "2024-1-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/24750158.2023.2289093"
    },
    {
        "id": 2952,
        "title": "Let us make man in our image-a Jewish ethical perspective on creating conscious robots",
        "authors": "Mois Navon",
        "published": "2023-9-12",
        "citations": 1,
        "abstract": "AbstractThe dream of making conscious humanoid robots is one that has long tantalized humanity, yet today it seems closer than ever before. Assuming that science can make it happen, the question becomes: should we make it happen? Is it morally permissible to create synthetic beings with consciousness? While a consequentialist approach may seem logical, attempting to assess the potential positive and negative consequences of such a revolutionary technology is highly speculative and raises more questions than it answers. Accordingly, some turn to ancient and not-so-ancient stories of “automata” for direction. Of the many automata conjured throughout history, if not in matter then in mind, the Golem stands out as one of the most persistent paradigms employed to discuss technology in general and technologically engendered life forms in particular. In this essay, I introduce a novel reading of the Golem paradigm to argue not from consequentialism, but from a deep-seated two-thousand-year-old tradition, the ethical implications of which are wholly deontological.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00328-y"
    },
    {
        "id": 2953,
        "title": "Exploring the Effect of AI Assistance on Human Ethical Decisions",
        "authors": "Saumik Narayanan",
        "published": "2023-8-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3600211.3604750"
    },
    {
        "id": 2954,
        "title": "Unveiling the ethical positions of conversational AIs: a study on OpenAI’s ChatGPT and Google’s Bard",
        "authors": "Quintin P. McGrath",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "AbstractIn an era where conversational AIs (CAIs) like OpenAI’s ChatGPT and Google's Bard are becoming integral to daily life, understanding their ethical positions is paramount. This research delves into the expressed moral values of these CAIs, exploring how their pre-training influences their ethical stances. The study aims to assess the articulated ethical positions of ChatGPT and Bard, uncovering whether these systems align with particular moral values. By understanding their ethical positions, the research seeks to provide insights into how these CAIs might respond to prompts and guide users in their selection and utilization. Utilizing O’Boyle and Forsyth’s Ethical Position Questionnaire (EPQ-5), the research evaluated the CAIs’ levels of idealism and relativism. The study also involved a third CAI, Anthropic’s Claude and an online human panel, to analyze the reasoning behind the responses, providing a more nuanced understanding of the ethical positions. The initial findings revealed that ChatGPT aligns more with an ‘absolutist’ position, endorsing strict adherence to moral principles, while Bard leans towards a ‘situationist’ stance, valuing flexibility and situational considerations. However, further analysis by Claude and humans suggested a more complex categorization, with ChatGPT fitting the 'exceptionist' categorization and Bard aligning with ‘absolutism.’ The research underscores the significance of recognizing the trained-in ethical positions of CAIs, as they are not neutral but reflect particular ethical leanings. Understanding these positions is vital for interpreting CAI outputs and using these systems effectively and ethically. The study calls for further exploration into how these ethical positions might influence real-world applications of CAIs.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00433-6"
    },
    {
        "id": 2955,
        "title": "Ethical AI is Not about AI",
        "authors": "Deborah G. Johnson, Mario Verdicchio",
        "published": "2023-2",
        "citations": 7,
        "abstract": "The equation Ethics + AI = Ethical AI is questionable.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3576932"
    },
    {
        "id": 2956,
        "title": "The role of ChatGPT in disrupting concepts, changing values, and challenging ethical norms: a qualitative study",
        "authors": "Pouyan Esmaeilzadeh",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00338-w"
    },
    {
        "id": 2957,
        "title": "Image synthesis from an ethical perspective",
        "authors": "Oliver Bendel",
        "published": "2023-9-27",
        "citations": 0,
        "abstract": "AbstractGenerative AI has gained a lot of attention in society, business, and science. This trend has increased since 2018, and the big breakthrough came in 2022. In particular, AI-based text and image generators are now widely used. This raises a variety of ethical issues. The present paper first gives an introduction to generative AI and then to applied ethics in this context. Three specific image generators are presented: DALL-E 2, Stable Diffusion, and Midjourney. The author goes into technical details and basic principles, and compares their similarities and differences. This is followed by an ethical discussion. The paper addresses not only risks, but opportunities for generative AI. A summary with an outlook rounds off the article.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01780-4"
    },
    {
        "id": 2958,
        "title": "Generative AI can fabricate advanced scientific visualizations: ethical implications and strategic mitigation framework",
        "authors": "Jeff J. H. Kim, Richard S. Um, James W. Y. Lee, Olusola Ajilore",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00439-0"
    },
    {
        "id": 2959,
        "title": "Ethical and political consumption: an integrated typology of practices",
        "authors": "Margarita Komninou",
        "published": "2023-5-22",
        "citations": 0,
        "abstract": "Addressing the diversity of consumer practices requires perceiving and measuring ethical and political consumerism beyond acts of buycotting and boycotting. By viewing consumption as limited to ‘purchasing’ and ‘shopping’, the agency of the consumer is bound to certain rules and mechanisms of the market, raising questions on the degree of alternativeness of each practice. Arbitrarily ascribing a strictly ‘noneconomic’ motivation behind the ‘ethical’ and ‘political’ framings of consumption results in excluding private (economic) troubles from the public sphere (ignoring thus their political nature). This conceptual article presents a novel analytical tool that maps consumer practices according to two critical conditions within which practices are performed: monetary transaction and legality. An example of how the proposed typology can be applied in the lodging sector demonstrates the typology’s ability to appreciate the diversity found in consumer practices, while also commenting on their degrees of alterity. Overall, the article calls for a reconsideration of the narrow repertoire of consumer action that is often associated with ethical and political consumerism, if we want to understand consumption as an “arena of politics” and a form of political participation in a more democratic manner (where every person gets to “vote”).\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.32388/dlhwlk"
    },
    {
        "id": 2960,
        "title": "A context-specific analysis of ethical principles relevant for AI-assisted decision-making in health care",
        "authors": "Larissa Schlicht, Miriam Räker",
        "published": "2023-7-24",
        "citations": 1,
        "abstract": "AbstractArtificial intelligence (AI)-assisted technologies may exert a profound impact on social structures and practices in care contexts. Our study aimed to complement ethical principles considered relevant for the design of AI-assisted technology in health care with a context-specific conceptualization of the principles from the perspectives of individuals potentially affected by the implementation of AI technologies in nursing care. We conducted scenario-based semistructured interviews focusing on situations involving moral decision-making occurring in everyday nursing practice with nurses (N = 15) and care recipients (N = 13) working, respectively, living in long-term care facilities in Germany. First, we analyzed participants’ concepts of the ethical principles beneficence, respect for autonomy and justice. Second, we investigated participants’ expectations regarding the actualization of these concepts within the context of AI-assisted decision-making. The results underscore the importance of a context-specific conceptualization of ethical principles for overcoming epistemic uncertainty regarding the risks and opportunities associated with the (non)fulfillment of these ethical principles. Moreover, our findings provide indications regarding which concepts of the investigated ethical principles ought to receive extra attention when designing AI technologies to ensure that these technologies incorporate the moral interests of stakeholders in the care sector.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00324-2"
    },
    {
        "id": 2961,
        "title": "How to Bridge the Gap between AI Ethical Guidelines and Responsible Ethical Conduct",
        "authors": "Uma G. Gupta",
        "published": "2023-5-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.26573/2021.17.1.4"
    },
    {
        "id": 2962,
        "title": "Ethical Reflections on AI for Cybersecurity: Building Trust",
        "authors": "Joseph Oloyede",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4733563"
    },
    {
        "id": 2963,
        "title": "Artificial Intelligence (AI) in Islamic Ethics: Towards Pluralist Ethical Benchmarking for AI",
        "authors": "Ezieddin Elmahjub",
        "published": "2023-12",
        "citations": 2,
        "abstract": "AbstractThis paper explores artificial intelligence (AI) ethics from an Islamic perspective at a critical time for AI ethical norm-setting. It advocates for a pluralist approach to ethical AI benchmarking. As rapid advancements in AI technologies pose challenges surrounding autonomy, privacy, fairness, and transparency, the prevailing ethical discourse has been predominantly Western or Eurocentric. To address this imbalance, this paper delves into the Islamic ethical traditions to develop a framework that contributes to the global debate on optimal norm setting for designing and using AI technologies.The paper outlines Islamic parameters for ethical values and moral actions in the context of AI's ethical uncertainties. It emphasizes the significance of both textual and non-textual Islamic sources in addressing these uncertainties while placing a strong emphasis on the notion of \"good\" or \"maṣlaḥa\" as a normative guide for AI's ethical evaluation. Defining maṣlaḥa as an ethical state of affairs in harmony with divine will, the paper highlights the coexistence of two interpretations of maṣlaḥa: welfarist/utility-based and duty-based. Islamic jurisprudence allows for arguments supporting ethical choices that prioritize building the technical infrastructure for AI to maximize utility. Conversely, it also supports choices that reject consequential utility calculations as the sole measure of value in determining ethical responses to AI advancements.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13347-023-00668-x"
    },
    {
        "id": 2964,
        "title": "Encountering Artificial Intelligence: Ethical and Anthropological Investigations",
        "authors": " ",
        "published": "2023-12-14",
        "citations": 0,
        "abstract": "What does it mean to consider the world of AI through a Christian lens? Rapid developments in AI continue to reshape society, raising new ethical questions and challenging our understanding of the human person. Encountering Artificial Intelligence draws on Pope Francis’ discussion of a culture of encounter and broader themes in Catholic social thought in order to examine how current AI applications affect human relationships in various social spheres and offers concrete recommendations for better implementation. The document also explores questions regarding personhood, consciousness, and the kinds of relationships humans might have with even the most advanced AI. Through these discussions, the document investigates the theoretical and practical challenges to interpersonal encounter raised by the age of AI. Cover image credit: The cover image for Encountering Artificial Intelligence: Ethical and Anthropological Investigations was created by Jordan Wales using Dall-E and the prompt “a sibyl conjures a deep neural network, oil on canvas by Raphael.”",
        "keywords": "",
        "link": "http://dx.doi.org/10.55476/001c.91230"
    },
    {
        "id": 2965,
        "title": "Marketing with ChatGPT: Navigating the Ethical Terrain of GPT-Based Chatbot Technology",
        "authors": "Pablo Rivas, Liang Zhao",
        "published": "2023-4-10",
        "citations": 47,
        "abstract": "ChatGPT is an AI-powered chatbot platform that enables human users to converse with machines. It utilizes natural language processing and machine learning algorithms, transforming how people interact with AI technology. ChatGPT offers significant advantages over previous similar tools, and its potential for application in various fields has generated attention and anticipation. However, some experts are wary of ChatGPT, citing ethical implications. Therefore, this paper shows that ChatGPT has significant potential to transform marketing and shape its future if certain ethical considerations are taken into account. First, we argue that ChatGPT-based tools can help marketers create content faster and potentially with quality similar to human content creators. It can also assist marketers in conducting more efficient research and understanding customers better, automating customer service, and improving efficiency. Then we discuss ethical implications and potential risks for marketers, consumers, and other stakeholders, that are essential for ChatGPT-based marketing; doing so can help revolutionize marketing while avoiding potential harm to stakeholders.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ai4020019"
    },
    {
        "id": 2966,
        "title": "Commentary on Artificial Intelligence (AI) in Islamic Ethics: Towards Pluralist Ethical Benchmarking for AI",
        "authors": "Amana Raquib",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13347-023-00677-w"
    },
    {
        "id": 2967,
        "title": "E-coaching systems and social justice: ethical concerns about inequality, coercion, and stigmatization",
        "authors": "B. A. Kamphorst, J. H. Anderson",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "AbstractPoor self-regulation has been linked to various behaviors that contribute to pressing societal issues, including rising household debt, inefficient use of sustainable resources, and increasing healthcare demands. In light of this observation, the prospect of individuals receiving automated, tailored support by “e-coaching systems” to scaffold and improve their self-regulation is thought to hold promise for making society-wide progress in addressing such issues. Though there may be legitimate reasons for promoting the use of such systems, and individuals might welcome the support, our aim in the present article is to contribute to the ethics of e-coaching by showing how societal pressures towards the widespread adoption of automated e-coaching systems raise concerns in relation to three distinct aspects of social justice. We argue that societal inequalities may be introduced or exacerbated by (1) unequal access to the technologies, (2) unequally distributed restrictions to liberty and subjection to coercion, and (3) the potentially disparate impact of the use of e-coaching technologies on (self-)stigmatizing perceptions of competence. The article offers a research agenda for studying and addressing these concerns.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00424-7"
    },
    {
        "id": 2968,
        "title": "The Ethical and Social Implications of Using AI in Healthcare - A Literature Review",
        "authors": "Suyash Bhogawar, Siddhartha Nuthakki, Sanju Mannumadam Venugopal, Sreeram Mullankandy",
        "published": "2023-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21275/sr231116135559"
    },
    {
        "id": 2969,
        "title": "ETHICAL CONSIDERATIONS IN AI: NAVIGATING BIAS, FAIRNESS, AND ACCOUNTABILITY (2020)",
        "authors": "",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.48047/jcr.07.03.375"
    },
    {
        "id": 2970,
        "title": "Measuring adherence to AI ethics: a methodology for assessing adherence to ethical principles in the use case of AI-enabled credit scoring application",
        "authors": "Maria Pokholkova, Auxane Boch, Ellen Hohma, Christoph Lütge",
        "published": "2024-4-15",
        "citations": 0,
        "abstract": "AbstractThis article discusses the critical need to find solutions for ethically assessing artificial intelligence systems, underlining the importance of ethical principles in designing, developing, and employing these systems to enhance their acceptance in society. In particular, measuring AI applications’ adherence to ethical principles is determined to be a major concern. This research proposes a methodology for measuring an application’s adherence to acknowledged ethical principles. The proposed concept is grounded in existing research on quantification, specifically, Expert Workshop, which serves as a foundation of this study. The suggested method is tested on the use case of AI-enabled Credit Scoring applications using the ethical principle of transparency as an example. AI development, AI Ethics, finance, and regulation experts were invited to a workshop. The study’s findings underscore the importance of ethical AI implementation and highlight benefits and limitations for measuring ethical adherence. A proposed methodology thus offers insights into a foundation for future AI ethics assessments within and outside the financial industry, promoting responsible AI practices and constructive dialogue.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00468-9"
    },
    {
        "id": 2971,
        "title": "On educating ethics in the AI era: why business schools need to move beyond digital upskilling, towards ethical upskilling",
        "authors": "David De Cremer, Devesh Narayanan",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00306-4"
    },
    {
        "id": 2972,
        "title": "A Case Study on AI Engineering Practices: Developing an Autonomous Stock Trading System",
        "authors": "Marcel Grote, Justus Bogner",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cain58948.2023.00032"
    },
    {
        "id": 2973,
        "title": "Guidance for researchers and peer-reviewers on the ethical use of Large Language Models (LLMs) in scientific research workflows",
        "authors": "Ryan Watkins",
        "published": "2023-5-16",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00294-5"
    },
    {
        "id": 2974,
        "title": "In defense of ethical guidelines",
        "authors": "Björn Lundgren",
        "published": "2023-8",
        "citations": 1,
        "abstract": "AbstractRecently, Luke Munn attacked “AI ethics” generally, or guidelines, principles, codes of ethics, ethical frameworks. In particular, he argued that ethical guidelines are useless. Here I respond to this critique, arguing that Munn’s criticism is mostly unfair and misguided, and that his own proposal is already implemented in various guidelines.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-022-00244-7"
    },
    {
        "id": 2975,
        "title": "Exploring the Human-AI Nexus: A Friendly Dispute Between Second-Order Cybernetical Ethical Thinking and Questions of AI Ethics",
        "authors": "Dietmar Koering",
        "published": "2023-5-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.58695/ec.4"
    },
    {
        "id": 2976,
        "title": "Trustworthy AI: A Fuzzy-Multiple Method for Evaluating Ethical Principles in AI Regulations",
        "authors": "Oksana Adamyk, Oksana Chereshnyuk, Bogdan Adamyk, Serhii Rylieiev",
        "published": "2023-9-21",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/acit58437.2023.10275505"
    },
    {
        "id": 2977,
        "title": "The ethical ambiguity of AI data enrichment: Measuring gaps in research ethics norms and practices",
        "authors": "Will Hawkins, Brent Mittelstadt",
        "published": "2023-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3593013.3593995"
    },
    {
        "id": 2978,
        "title": "Artificial Intelligence (AI) Trust Framework and Maturity Model: Applying an Entropy Lens to Improve Security, Privacy, and Ethical AI",
        "authors": "Michael Mylrea, Nikki Robinson",
        "published": "2023-10-9",
        "citations": 3,
        "abstract": "Recent advancements in artificial intelligence (AI) technology have raised concerns about the ethical, moral, and legal safeguards. There is a pressing need to improve metrics for assessing security and privacy of AI systems and to manage AI technology in a more ethical manner. To address these challenges, an AI Trust Framework and Maturity Model is proposed to enhance trust in the design and management of AI systems. Trust in AI involves an agreed-upon understanding between humans and machines about system performance. The framework utilizes an “entropy lens” to root the study in information theory and enhance transparency and trust in “black box” AI systems, which lack ethical guardrails. High entropy in AI systems can decrease human trust, particularly in uncertain and competitive environments. The research draws inspiration from entropy studies to improve trust and performance in autonomous human–machine teams and systems, including interconnected elements in hierarchical systems. Applying this lens to improve trust in AI also highlights new opportunities to optimize performance in teams. Two use cases are described to validate the AI framework’s ability to measure trust in the design and management of AI systems.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/e25101429"
    },
    {
        "id": 2979,
        "title": "Review of: \"Ethical and political consumption: an integrated typology of practices\"",
        "authors": "Mahsa Ghaffari",
        "published": "2023-6-8",
        "citations": 0,
        "abstract": "",
        "keywords": "",
        "link": "http://dx.doi.org/10.32388/79g8jc"
    },
    {
        "id": 2980,
        "title": "AI Health Ethical Review: A Value Design Methodology",
        "authors": "Elizaveta A. Karpova",
        "published": "2023",
        "citations": 0,
        "abstract": "As our world becomes more dependent on data, algorithms are increasingly being used to make informed decisions in areas ranging from finance to HR. The healthcare sector is no exception, and artificial intelligence systems are becoming more and more widespread in this area. While AI can help us make more informed and efficient decisions, it also presents many moral and ethical challenges. One of the biggest issues is the issue of trust. When &quot;machine&quot; replaces &quot;human&quot; decision making, it can be difficult for patients and healthcare professionals to trust the outcome. In addition, the &quot;black box&quot; mechanisms in artificial intelligence systems make it unclear who is responsible for the decisions made, which can lead to ethical dilemmas. In addition, there is a risk of emotional frustration for patients and healthcare professionals, as AI may not be able to provide the kind of human touch that is often needed in healthcare. Despite increased attention to these issues in recent years, technical solutions to these complex moral and ethical issues are often developed without regard to the social context and opinions of the advocates affected by the technology. In addition, calls for more ethical and socially responsible AI often focus on basic legal principles such as &quot;transparency&quot; and &quot;responsibility&quot; and leave out the much more problematic area of human values. To solve this problem, the article proposes a &quot;value-sensitive&quot; approach to the development of AI, which can help translate basic human rights and values into context-sensitive requirements for AI algorithms. This approach can help create a route from human values to clear and understandable requirements for AI design. It can also help overcome ethical issues that hinder the responsible implementation of AI in healthcare and everyday life.",
        "keywords": "",
        "link": "http://dx.doi.org/10.31857/s023620070026109-6"
    },
    {
        "id": 2981,
        "title": "The question of \"Mind-sets\" and AI: Cultural origins and limits of the current AI  Ethical AIs and Cultural Pluralism",
        "authors": "Badrudin Amershi",
        "published": "2023-1-4",
        "citations": 0,
        "abstract": "The current process of scientific and technological development is the outcome of the epochal Cultural Revolution in the West: i.e. the emergence of the Age of Enlightenment and its pursuit of \"rationality\". Today, \"rationality\" combined with \"logic\" has mutated into a \"strong belief\" in the power of rationality and \"computational processes\" as a 'safer' and only way to acquire knowledge. This is the main driving force behind the emergence of AI. At the core of this mind-set is the fundamental duality of the observer and the observed. After the imperial expansion of Western Europe – in alliance with religion, its previous foe (“Christianity”) – this world-view became the globally dominant mind-set. The paper explores the dominant narrative of rationality and reason of Western science, and seeks an alternative world of cultural diversity.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30564/aia.v4i2.5156"
    },
    {
        "id": 2982,
        "title": "Social and ethical challenges of the metaverse",
        "authors": "Richard Benjamins, Yaiza Rubio Viñuela, Chema Alonso",
        "published": "2023-8",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00278-5"
    },
    {
        "id": 2983,
        "title": "AI powered Social Communication: a Qualitative Investigation in to Social and Ethical Concerns",
        "authors": "Vikrant Yadav",
        "published": "2024",
        "citations": 0,
        "abstract": "Social media has become an integral part of modern day lifestyle of new generation. The social media penetration in day to affairs is to such an extent that, there hardly is any day that goes without having any social media interaction. Although an easy way of distant communication and entertainment are the driving force behind emergence of social media platforms, in recent times it has been used to fulfil the undesired motives. Many instances of fake news, bias, spreading of hatred, deep fakes have been noticed. This paper is an attempt to conduct a conceptual analysis of AI technology alongwith the literary survey of impact of AI on social communication. Based on the qualitative literary survey, the author has proposed some recommendations, some of which includes, inclusion of social media ethics in school curriculum, international norms for use of social media platform etc.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54941/ahfe1004592"
    },
    {
        "id": 2984,
        "title": "The rise of artificial intelligence in libraries: the ethical and equitable methodologies, and prospects for empowering library users",
        "authors": "James Oluwaseyi Hodonu-Wusu",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00432-7"
    },
    {
        "id": 2985,
        "title": "Ethical concerns around privacy and data security in AI health monitoring for Parkinson’s disease: insights from patients, family members, and healthcare professionals",
        "authors": "Itai Bavli, Anita Ho, Ravneet Mahal, Martin J. McKeown",
        "published": "2024-1-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01843-6"
    },
    {
        "id": 2986,
        "title": "Formalizing ethical principles within AI systems: experts’ opinions on why (not) and how to do it",
        "authors": "Franziska Poszler, Edy Portmann, Christoph Lütge",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "AbstractAI systems are increasingly put into contexts where computed decisions must be guided by ethical considerations. To develop ethically grounded algorithms and technologies, scholars have suggested computational ethics as an essential frontier, which aims to translate ethical principles into computer code. However, computational ethics has received little attention in academic literature so far, with existing work mainly focusing on its technical implementation, while many open questions concerning its (societal and ethical) implications still need to be resolved. Therefore, in this study, we interviewed 12 experts from philosophy, AI and cognitive sciences to shed light on computational ethics beyond a technical perspective. Findings suggest that indicated supporting and opposing arguments can be clustered into pragmatic/practical, societal and epistemic reasons, all of which need to be contemplated when engaging in computational ethics and developing resulting artificial moral agents. Furthermore, the mentioned recommendations for companies’ technological design and development, for industry’s governance measures and academia’s research endeavors are recapitulated and summarized in a holistic framework that aims to facilitate a reflected implementation of ‘ethics in and by design’ in the future.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00425-6"
    },
    {
        "id": 2987,
        "title": "Ethical Behaviourism and the Moral Status of AI Robots",
        "authors": "Sang-deuk Kim",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.20293/jokps.2023.167.59"
    },
    {
        "id": 2988,
        "title": "Stepping Above the Generative Ai Ethical Floor: The Sky's the Limit",
        "authors": "Joseph Regalia",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4746753"
    },
    {
        "id": 2989,
        "title": "Ethical Concerns about Using AI-Generated Text in Scientific Research",
        "authors": "Zuheir N. Khlaif",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4387984"
    },
    {
        "id": 2990,
        "title": "The Ethics of Artificial Intelligence: Review of Ethical Machines: Your Concise Guide to Totally Unbiased, Transparent, and Respectful AI by R. Blackman; Ethics of Artificial Intelligence: Case Studies and Options for Addressing Ethical Challenges by B.C. Stahl, D. Schroeder, and R. Rodrigues; and AI Ethics by M. Coeckelbergh",
        "authors": "Christian Goglin",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10551-023-05538-2"
    },
    {
        "id": 2991,
        "title": "Ever Heard of Ethical AI? Investigating the Salience of Ethical AI Issues among the German Population",
        "authors": "Kimon Kieslich, Marco Lünich, Pero Došenović",
        "published": "2023-2-21",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/10447318.2023.2178612"
    },
    {
        "id": 2992,
        "title": "Economic, Societal, Legal, and Ethical Considerations for Large Language Models",
        "authors": "Jay Lofstead",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/transai60598.2023.00049"
    },
    {
        "id": 2993,
        "title": "Ethical Governance of AI: An Integrated Approach via Human-in-the-Loop Machine Learning",
        "authors": "Ximeng Chen",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/cmsf2023008029"
    },
    {
        "id": 2994,
        "title": "Ethical Implications of AI-Powered Chatbots",
        "authors": "Dawn Branley-Bell, Johannes Feiner, Sabine Prossnegg",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.38023/f8b4776d-12bd-4661-aadd-cf6e148ce73b"
    },
    {
        "id": 2995,
        "title": "Traversing the Ethical Landscape of Data Scraping for AI",
        "authors": "Jayasankar Jayachandran, Vijay Arni",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4666354"
    },
    {
        "id": 2996,
        "title": "Ethical Considerations in the Transformative Role of AI Chatbots in Education",
        "authors": "Patrick Ryan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4623611"
    },
    {
        "id": 2997,
        "title": "Exploring The Use of AI In Legal Decision Making: Benefits and Ethical Implications",
        "authors": "Sreelatha A, Gyandeep Choudhary",
        "published": "2023-9",
        "citations": 0,
        "abstract": "There has been a lot of discussion about how to incorporate AI into legal decision-making. The purpose of this research is to investigate the potential positive outcomes and potential negative consequences of using artificial intelligence in the legal system. A thorough understanding of the potential benefits and ethical considerations tied to the use of AI in legal decision-making can be attained through a thorough review of relevant literature, the formulation of research inquiries, and the establishment of research objectives.",
        "keywords": "",
        "link": "http://dx.doi.org/10.57029/scheel4"
    },
    {
        "id": 2998,
        "title": "Evaluating the acceptability of ethical recommendations in industry 4.0: an ethics by design approach",
        "authors": "Marc M. Anderson, Karën Fort",
        "published": "2024-1-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01834-7"
    },
    {
        "id": 2999,
        "title": "The State of Ethical Practices in Accounting: How Greed Has Inhibited Accounting Leaders From Creating an Ethical Organizational Culture",
        "authors": "",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.33423/jlae.v20i2.6170"
    },
    {
        "id": 3000,
        "title": "Artificial Intelligence (AI) Influence in Law: Balancing Technological Advancements with Ethical Considerations",
        "authors": "Ammar Zafar",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4656578"
    },
    {
        "id": 3001,
        "title": "Increasing Safety in Highways Transit Systems by Using Ethical Artificial Intelligence AI",
        "authors": "Rasha Waheeb",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4573277"
    },
    {
        "id": 3002,
        "title": "INTEGRATING AI ETHICAL-MORAL STANDARDS: AI TYPES AND THE ROLE OF THE CONSTRUAL LEVEL OF ACCEPTANCE",
        "authors": "Dan Jin,  , Heejin Lim",
        "published": "2023-7-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.15444/gmc2023.07.01.01"
    },
    {
        "id": 3003,
        "title": "Learning from Buddhist Teachings and Ethical Practices in Qualitative Research",
        "authors": "Pei-Jung Li",
        "published": "2023-2-1",
        "citations": 0,
        "abstract": "This paper aims at conceptualizing research ethics in qualitative research with Buddhist teachings. As a Buddhist, I first introduce how Buddhism came to be central in my life and eventually influenced me as a qualitative researcher. I exemplify how the concepts of all-beings-are-equal, karma, the five precepts, and repentance might inspire a qualitative practice that centers ethics and informs a researcher’s interactions with participants. I suggest that researchers not only work on reflecting on their body (actions), speech (talk), and mind (thoughts) but more importantly, move beyond just reflection and reflexivity to facing and resolving “unwholesome” moments that may arise during the research process. I thus demonstrate how to repent in regard to one’s research-related actions, speech, and thoughts, with a particular focus on doing-no-harm and truthfulness. To illustrate, I offer an example from my own research that highlights how Buddhist teachings might be relevant in practice. My arguments aim to contribute to the literature on research ethics by introducing repentance by the researchers, alongside the Buddhist precepts, as central to ethical qualitative research practice.",
        "keywords": "",
        "link": "http://dx.doi.org/10.46743/2160-3715/2023.5772"
    },
    {
        "id": 3004,
        "title": "Ethical and Legal Challenges of AI in Marketing: An Exploration of Solutions",
        "authors": "Dinesh Kumar",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4396132"
    },
    {
        "id": 3005,
        "title": "Exploring differences in ethical decision-making processes between humans and ChatGPT-3 model: a study of trade-offs",
        "authors": "Umair Rehman, Farkhund Iqbal, Muhammad Umair Shah",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00335-z"
    },
    {
        "id": 3006,
        "title": "Exploring business students’ views of the use of generative AI in assignment writing",
        "authors": "Duncan Murray, Karen Williams",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "\nThe rise of generative AI, particularly over the past few years, has raised notable issues about its use. This has been possibly most pronounced in academia, where there has been strong debate on the potential value of generative AI to augment learning outcomes versus the potential for academic dishonesty and devalued education. Whilst some papers have looked at students’ perspectives on the use of generative AI, there has been less focus exploring through what ethical perspectives or frames students see using generative AI in their tertiary education.\n\n\nWe interviewed and conducted focus groups and interviews with students enrolled in an Australian university business school, to explore the ethical frames through which they saw the use of generative AI. Focussing on three specific perspectives: Deontological, Consequentialism and Virtue Ethics, it emerged that no single perspective dominated, with students having a complex mix and latticework of ethical perspectives on its use, even within the same individual. We explore some potential implications for practice that emerged from the data, one of which is the role of the academic as moral exemplar. \n",
        "keywords": "",
        "link": "http://dx.doi.org/10.14742/apubs.2023.662"
    },
    {
        "id": 3007,
        "title": "ETHICAL FRONTIERS IN AI-DRIVEN STUDENT DEVELOPMENT: NAVIGATING NEW REALMS OF ENGAGEMENT AND SUPPORT",
        "authors": "Henry Mason",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21125/inted.2024.1648"
    },
    {
        "id": 3008,
        "title": "Ethical Implications in AI-Powered Trend Research Platforms",
        "authors": "Victoria Rodrigues Schon, Chiara Colombi",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "The manuscript discusses the limitations of applying AI in trend research platforms for the fashion system. This analysis intends to take a position within the emergent research topic of AI. Considering its ethical implications, we explore the opportunities of implementing AI to support trend research from a design-oriented perspective, realising the relationship between fashion and trends, which is central in shaping the future. Examples of AI-powered trend platforms evidence how valuable their insights are for strategic innovation. The analysis focuses on platforms that provide tailored services using AI and expert interpretation. Virtue ethics of technology serves as a useful framework to examine this topic, proposing a new set of virtues that respond to technology’s shaping of behaviour and its disadvantages. The risks of applying AI are many-fold; the consequences perpetuate power imbalances and social inequality. Proposing guidelines for enabling a responsible practice explores how to forge ethics into AI, creating a pluralised practice.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36253/fh-2261"
    },
    {
        "id": 3009,
        "title": "Governing Ethical Gaps in Distributed AI Development",
        "authors": "Nandhini Swaminathan, David Danks",
        "published": "2024-4",
        "citations": 0,
        "abstract": "AbstractGood business practice often leads companies to subdivide into separate functional entities for operational efficiency and specialization. However, these kinds of divisions can generate significant ethical and perhaps even regulatory gaps when they occur in AI companies. In particular, one natural division for an AI company is into separate entities responsible for model development, testing, and cybersecurity (to maintain and protect data). In this paper, we argue that this division can lead to some ethical responsibilities always being “someone else’s job.” For concreteness, we consider the US National Institute of Standards and Technology’s AI Risk Management Framework (NIST AI RMF) as a guide to ethical obligations in a corporate context. We show that a common division of labor in AI development and deployment can lead to specific obligations for which no entity is responsible, even though they apply to the effort as a whole. We propose “Join Accountability Agreements”, a mechanism to ensure that ethical obligations do not slip through the cracks because of the way an effort is structured. We thus aim to highlight the significance of comprehensive examinations of and adaptable strategies for our ethical obligations when developing AI systems in a distributed manner.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s44206-024-00088-0"
    },
    {
        "id": 3010,
        "title": "Artificial Intelligence in Elderly Care: Navigating Ethical and Responsible AI Adoption for Seniors",
        "authors": "David Mhlanga",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4675564"
    },
    {
        "id": 3011,
        "title": "NAVIGATING THE NEXUS OF AI LITERACIES: A STUDY ON GENERATIVE AI PRACTICES AMONG NTU STUDENTS",
        "authors": "Siew Hiang Sally Ng, Hsiao-yun Chan",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21125/inted.2024.0600"
    },
    {
        "id": 3012,
        "title": "Narrativity and responsible and transparent ai practices",
        "authors": "Paul Hayes, Noel Fitzpatrick",
        "published": "2024-2-25",
        "citations": 1,
        "abstract": "AbstractThis paper builds upon recent work in narrative theory and the philosophy of technology by examining the place of transparency and responsibility in discussions of AI, and what some of the implications of this might be for thinking ethically about AI and especially AI practices, that is, the structured social activities implicating and defining what AI is. In this paper, we aim to show how pursuing a narrative understanding of technology and AI can support knowledge of process and practice through transparency, as well help summon us to responsibility through visions of possibility and of actual harms arising from AI practices. We provide reflections on the relations between narrative, transparency and responsibility, building an argument that narratives (about AI, practices, and those persons implicated in its design, implementation, and deployment) support the kind of knowing and understanding that is the aim of transparency, and, moreover, that such knowledge supports responsibility in informing agents and activating responsibility through creating knowledge about something that can and should be responded to. Furthermore, we argue for considering an expansion of the kinds of practices that we might legitimately consider ‘AI practices’ given the diverse set of (often materially embedded) activities that sustain and are sustained by AI that link directly to its ethical acceptability and which are rendered transparent in the narrative mode. Finally, we argue for an expansion of narratives and narrative sources to be considered in questions of AI, understanding that transparency is multi-faceted and found in stories from diverse sources and people.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-024-01881-8"
    },
    {
        "id": 3013,
        "title": "The ethical implications of Chatbot developments for conservation expertise",
        "authors": "Zarrin Tasnim Sworna, Danilo Urzedo, Andrew J Hoskins, Catherine J Robinson",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "AbstractChatbots have emerged as a potent artificial intelligence (AI) tool for expediting expert knowledge, including evidence used for conservation research and practices. While digital technologies can support the curation and analysis of vast amounts of conservation datasets to inform best practices, AI-driven solutions raise ethical concerns around what source of evidence is used or not. This paper examines the ethical issues around sources, biases, and representation of conservation evidence formulated by chatbots. We interviewed two versions of ChatGPT, GPT-3.5-turbo and GPT-4, regarding knowledge available for ecological restoration and analysed 40,000 answers. Our results show that these chatbot developments are expanding the inclusion of diverse data sources and improving the accuracy of the responses. However, these technical developments do not necessarily imply ethical considerations in terms of fair representation and unbiased inclusion of diverse knowledge offered by different sources of expertise. While the updated model expands the descriptions ofgeographical locations and organizations, there remain limitations regarding equitable representation of different expertise and stakeholders. The updated version of GPT still relies heavily on evidence from high-income countries (88%), North American expertise (67%), and male academics (46%) with limited contributions from minority groups, such as Indigenous organizations (10%) and low-income countries (2%). In conclusion, the ethical implications within generative AI reveal the crucial requirement of human-centered negotiations to consider how knowledge practices are legitimized and embedded in the development and use of chatbots.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00460-3"
    },
    {
        "id": 3014,
        "title": "Uncovering Energy-Efficient Practices in Deep Learning Training: Preliminary Steps Towards Green AI",
        "authors": "Tim Yarally, Luıs Cruz, Daniel Feitosa, June Sallou, Arie van Deursen",
        "published": "2023-5",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cain58948.2023.00012"
    },
    {
        "id": 3015,
        "title": "Navigating the Ethical Maze: Balancing Digital Resilience and Ethical Imperatives for Sustainable Business Practices in the Digital Age: A Multidimensional Framework",
        "authors": "G.G. Udaya Priyasantha Rathnayake",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.46254/au02.20230270"
    },
    {
        "id": 3016,
        "title": "Safeguarding Ethical AI: Detecting Potentially Sensitive Data Re-Identification and Generation of Misleading or Abusive Content from Quantized Large Language Models",
        "authors": "Navya Kollapally, James Geller",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012411900003657"
    },
    {
        "id": 3017,
        "title": "Ethical Leadership in HRM: A Critical Analysis of the Role of HRM Practices in Promoting Ethical Behavior and Corporate Social Responsibility",
        "authors": "La Saudin",
        "published": "2024-3-24",
        "citations": 0,
        "abstract": "This study explores the contextual factors that influence the relationship between Human Resources (HRM) ethical leadership, employee ethical behavior, and corporate social responsibility (CSR). Through a literature review, we examine the influence of organizational culture, company values, government regulations, pressure from stakeholders, and the role of industry and business environment in shaping the dynamics between these variables. Findings show that alignment between HRM practices and organizational culture, CSR authenticity, and government regulations play a key role in shaping employee behavior, organizational commitment, and company performance. In addition, industry characteristics and business environment moderate the relationship between these variables. These results emphasize the importance of understanding the complexity of the relationship between HRM ethical leadership, employee ethical behavior, and CSR in various organizational contexts.",
        "keywords": "",
        "link": "http://dx.doi.org/10.62207/5krrfc83"
    },
    {
        "id": 3018,
        "title": "The Role of Ethical Principles in AI Startups",
        "authors": "James E. Bessen, Stephen Michael Impink, Robert Seamans",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4378280"
    },
    {
        "id": 3019,
        "title": "HarmonyVisage: Ethical Facial Emotion Dataset Using Advanced Generative AI",
        "authors": "Claire Xu",
        "published": "2023-10-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/uemcon59035.2023.10316128"
    },
    {
        "id": 3020,
        "title": "Keynote 1: Harmonizing Computer Technology, AI, and Ethical Engineering for a Sustainable Futures",
        "authors": "",
        "published": "2023-8-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccce58854.2023.10246085"
    },
    {
        "id": 3021,
        "title": "Open AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning",
        "authors": "David Mhlanga",
        "published": "2023",
        "citations": 107,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4354422"
    },
    {
        "id": 3022,
        "title": "Exploring Ethical Implications of ChatGPT and Other AI Chatbots and Regulation of Disinformation Propagation",
        "authors": "Glorin Sebastian",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4461801"
    },
    {
        "id": 3023,
        "title": "Augmenting Intelligence: Ethical Challenges in the Age of AI",
        "authors": "Carol J. Smith",
        "published": "2024-3-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3599732.3641496"
    },
    {
        "id": 3024,
        "title": "Ethical U se of AI in Social Media",
        "authors": "Srikari Rallabandi, Ishan G S Kakodkar, Obulesh Avuku",
        "published": "2023-8-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iwis58789.2023.10284706"
    },
    {
        "id": 3025,
        "title": "Toward Ethical Use of Generative AI in AP Courses",
        "authors": "Kyrie Zhixuan Zhou, Madelyn Sanfilippo, Allison Sinnott",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4632928"
    },
    {
        "id": 3026,
        "title": "Embracing Cultural Differences to Ensure Ethical Publication Practices",
        "authors": "Jonathan Lee, Blair Hesp",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "Ethical publication practices apply universally, but differing cultural contexts can alter the interpretation and application of guidelines. In particular, collaborating with colleagues and authors in the Asia-Pacific region can sometimes be confusing and frustrating when attempting to align expectations between all parties involved in medical writing projects. Engaging with colleagues in other regions to develop flexible, culturally appropriate processes can help strengthen working relationships, expedite project completion, and adhere to publication best practices.",
        "keywords": "",
        "link": "http://dx.doi.org/10.55752/amwa.2023.298"
    },
    {
        "id": 3027,
        "title": "Shimjeong: A Philosophical Beacon for Ethical Business Practices in High-Corruption Environments",
        "authors": "Mykhailo Ilin",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4785345"
    },
    {
        "id": 3028,
        "title": "Application of ethical AI requirements to an AI solution use-case in healthcare domain",
        "authors": "Zohreh Pourzolfaghar, Marco Alfano, Markus Helfert",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "PurposeThis paper aims to describe the results of applying ethical AI requirements to a healthcare use case. The purpose of this study is to investigate the effectiveness of using open educational resources for Trustworthy AI to provide recommendations to an AI solution within the healthcare domain.Design/methodology/approachThis study utilizes the Hackathon method as its research methodology. Hackathons are short events where participants share a common goal. The purpose of this to determine the efficacy of the educational resources provided to the students. To achieve this objective, eight teams of students and faculty members participated in the Hackathon. The teams made suggestions for healthcare use case based on the knowledge acquired from educational resources. A research team based at the university hosting the Hackathon devised the use case. The healthcare research team participated in the Hackathon by presenting the use case and subsequently analysing and evaluating the utility of the outcomes.FindingsThe Hackathon produced a framework of proposed recommendations for the introduced healthcare use case, in accordance with the EU's requirements for Trustworthy AI.Research limitations/implicationsThe educational resources have been applied to one use-case.Originality/valueThis is the first time that open educational resources for Trustworthy AI have been utilized in higher education, making this a novel study. The university hosting the Hackathon has been the coordinator for the Trustworthy AI Hackathon (as partner to Trustworthy AI project).",
        "keywords": "",
        "link": "http://dx.doi.org/10.1108/ajb-12-2022-0201"
    },
    {
        "id": 3029,
        "title": "Ethical Awareness of UXers in the Loop",
        "authors": "Harin Yoon, Soojin Jun",
        "published": "2023-9-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3565066.3608691"
    },
    {
        "id": 3030,
        "title": "Ethical Considerations in Using AI in Educational Research",
        "authors": "Nuri Balta,  ",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "This editorial explores the ethical challenges associated with integrating artificial intelligence into educational settings. They highlight key ethical principles to guide AI use in educational research, including transparency, accountability, fairness, and authenticity. The author emphasizes the need for ethical frameworks to address complex issues around biases, attribution, and the human-AI division of labor.",
        "keywords": "",
        "link": "http://dx.doi.org/10.51853/jorids/14205"
    },
    {
        "id": 3031,
        "title": "Robot, let us pray! Can and should robots have religious functions? An ethical exploration of religious robots",
        "authors": "Anna Puzio",
        "published": "2023-12-11",
        "citations": 2,
        "abstract": "AbstractConsiderable progress is being made in robotics, with robots being developed for many different areas of life: there are service robots, industrial robots, transport robots, medical robots, household robots, sex robots, exploration robots, military robots, and many more. As robot development advances, an intriguing question arises: should robots also encompass religious functions? Religious robots could be used in religious practices, education, discussions, and ceremonies within religious buildings. This article delves into two pivotal questions, combining perspectives from philosophy and religious studies: can and should robots have religious functions? Section 2 initiates the discourse by introducing and discussing the relationship between robots and religion. The core of the article (developed in Sects. 3 and 4) scrutinizes the fundamental questions: can robots possess religious functions, and should they? After an exhaustive discussion of the arguments, benefits, and potential objections regarding religious robots, Sect. 5 addresses the lingering ethical challenges that demand attention. Section 6 presents a discussion of the findings, outlines the limitations of this study, and ultimately responds to the dual research question. Based on the study’s results, brief criteria for the development and deployment of religious robots are proposed, serving as guidelines for future research. Section 7 concludes by offering insights into the future development of religious robots and potential avenues for further research.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01812-z"
    },
    {
        "id": 3032,
        "title": "Reinforcement learning-based motion planning in partially observable environments under ethical constraints",
        "authors": "Junchao Li, Mingyu Cai, Shaoping Xiao",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00441-6"
    },
    {
        "id": 3033,
        "title": "Do current regulations prevent unethical AI practices?",
        "authors": "",
        "published": "2023-9-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.7441/joc.2023.03.11"
    },
    {
        "id": 3034,
        "title": "Impact of ethical leadership, HRM practices and ethical climate on organizational citizenship behaviors in Nigerian local governments",
        "authors": "Abubakar Tabiu",
        "published": "2023-8-29",
        "citations": 0,
        "abstract": "PurposeThe increasing number of ethical scandals reported in many public organizations all over the world, highlighted the need for more in-depth studies on the influence of ethical leadership and management practices in the public sector organizations. This study examines the link (direct and indirect) between ethical leadership, HRM practices, ethical climate and organizational citizenship behaviors (OCBs) within the context of Nigerian local governments.Design/methodology/approachA cross-sectional design was adopted and data for the study was collected quantitatively by administering questionnaires to supervisors/leaders and their respective employees/subordinates. A total of 270 participants comprising 135 leaders/supervisors who are head of departments and another 135 employee/subordinates participated in the study. Partial Least Square Structural Equation Modeling (PLS-SEM) was used in testing the hypotheses.FindingsThe findings show that ethical leadership, HRM practices and ethical climate significantly affect OCBs. Also, the study shows that ethical climate mediated both the relationships between ethical leadership and OCBs, and HRM practices and OCBs respectively. Thus, the study concluded that both ethical leadership and HRM practices can influence OCBs directly and also indirectly through ethical climate.Practical implicationsThe study empirically delineates the importance of ethical leadership, HRM practices and ethical climate in promoting more OCBs within the context of Nigerian local governments. Therefore, managers/administrators should encourage ethical leadership style, and implement good HRM practices and promote ethical climate within their organization so as to boost their employees' OCBs.Originality/valueThe findings of this study will contribute to the understanding of the relationships between ethical leadership, HRM practices, ethical climate and OCBs in the public sector organizations within Nigeria. The findings will also provide additional support that ethical climate is an important mechanism on the relationship between ethical leadership and HRM practices on OCBs.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1108/ijpl-06-2022-0038"
    },
    {
        "id": 3035,
        "title": "Ethics in AI: how software development companies in Brazil deal with the ethical implications of AI technologies",
        "authors": "Lucas Gabriel Teixeira da Silva, Eloize Rossi Marques Seno",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "The use of AI technologies has become increasingly common in the software development industry. Although the ethical challenges of using these technologies have been the subject of numerous academic studies, little is known about AI software development practices. Furthermore, there are currently no effective methods and frameworks to help implement ethics at a project level. Given this context, we carried out an empirical study in order to better understand how software development companies in Brazil deal with the ethics of AI in practice. The results highlighted a lack of clarity in standard guidelines and a lack of concern about the ethical implications imposed by the use of AI technologies, suggesting that the governance of AI systems based on principled ethical guidelines is not enough to establish norms to the AI industry and its developers.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5753/eniac.2023.233866"
    },
    {
        "id": 3036,
        "title": "Beyond Discrimination: Generative AI Applications and Ethical Challenges in Forensic Psychiatry",
        "authors": "Leda Tortora",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "The advent and growing popularity of generative artificial intelligence (GenAI) holds the potential to revolutionise AI applications in forensic psychiatry and criminal justice, which traditionally relied on discriminative AI algorithms. Generative AI models mark a significant shift from the previously prevailing paradigm through their ability to generate seemingly new realistic data and analyse and integrate a vast amount of unstructured content from different data formats. This potential extends beyond reshaping conventional practices, like risk assessment, diagnostic support, and treatment and rehabilitation plans, to creating new opportunities in previously underexplored areas, such as training and education. This paper examines the transformative impact of generative artificial intelligence on AI applications in forensic psychiatry and criminal justice. First, it introduces generative AI and its prevalent models. Following this, it reviews the current applications of discriminative AI in forensic psychiatry. Subsequently, it presents a thorough exploration of the potential of generative AI to transform established practices and introduce novel applications through multimodal generative models, data generation and data augmentation. Finally, it provides a comprehensive overview of ethical and legal issues associated with deploying generative AI models, focusing on their impact on individuals as well as their broader societal implications. In conclusion, this paper aims to contribute to the ongoing discourse concerning the dynamic challenges of generative AI applications in forensic contexts, highlighting potential opportunities, risks, and challenges. It advocates for interdisciplinary collaboration and emphasises the necessity for thorough, responsible evaluations of generative AI models before widespread adoption into domains where decisions with substantial life-altering consequences are routinely made.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fpsyt.2024.1346059"
    },
    {
        "id": 3037,
        "title": "Artificial Intelligence Ethics and Fairness: A study to address bias and fairness issues in AI systems, and the ethical implications of AI applications",
        "authors": "Nimesh Gupta",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "Artificial intelligence (AI) has made incredible strides in several fields, revolutionising business and everyday life. Thoughts regarding the moral ramifications and fairness of AI systems have grown in prominence along with its fast development. This article explores the crucial issues of AI fairness and ethics, concentrating on ways to detect and reduce prejudice in AI systems while also discussing larger ethical implications. The paper emphasises the possible repercussions of biased decision-making while highlighting the many forms and sources of bias that might develop in AI models. There are several methods and strategies to deal with bias in AI systems, including data pretreatment, algorithmic changes, and transparency measures. In an effort to balance justice and efficacy, the trade-offs between fairness goals and overall model performance are examined. The article also emphasises how crucial it is for AI systems to be transparent and understandable in order to foster accountability. For the purpose of establishing ethical AI development and deployment practises, regulatory issues and ethical decision-making frameworks are also investigated. This study emphasises the need of ongoing research and development of moral AI systems to guarantee a just and equitable future for AI applications via in-depth analysis and case studies.",
        "keywords": "",
        "link": "http://dx.doi.org/10.31305/rrijm2023.v03.n02.004"
    },
    {
        "id": 3038,
        "title": "Fine-Tuning Languages: Epistemological Foundations for Ethical AI in Journalism",
        "authors": "Laurence Dierickx, Carl-Gustav Lindén",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sds57534.2023.00013"
    },
    {
        "id": 3039,
        "title": "Emotional Attachment to AI Companions and European Law",
        "authors": "Claire Boine",
        "published": "2023-2-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21428/2c646de5.db67ec7f"
    },
    {
        "id": 3040,
        "title": "Integrals and Integrity: Generative AI Tries to Learn Cosmology",
        "authors": "Bruce A. Bassett",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21428/2c646de5.20c92601"
    },
    {
        "id": 3041,
        "title": "Making AI Ethical by Design: The UNESCO Perspective",
        "authors": "Gabriela Ramos, Mariagrazia Squicciarini, Eleonora Lamm",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mc.2023.3325949"
    },
    {
        "id": 3042,
        "title": "Generative AI in Public Opinion Guidance during Emergency Public Events: Challenges, Opportunities, and Ethical Considerations",
        "authors": "Li Zeng",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4426190"
    },
    {
        "id": 3043,
        "title": "Emerging Practices of Ethical Consumption To Affirm Sustainability: A Literature Review",
        "authors": "Amrita Nandy",
        "published": "2023-11-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.59321/bauetj.v4i1.13"
    },
    {
        "id": 3044,
        "title": "A Theoretical Framework for Exploring Ethical Marketing Practices in Pharmaceutical Industry of Pakistan",
        "authors": "Fazal Malik",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4616478"
    },
    {
        "id": 3045,
        "title": "From AI Ethics Principles to Practices: A Teleological Methodology to Apply AI Ethics Principles in The Defence Domain",
        "authors": "Mariarosaria Taddeo, Alexander Blanchard, Chris Thomas",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4520945"
    },
    {
        "id": 3046,
        "title": "Physician Leadership, AI, and Employment Practices",
        "authors": "Timothy Paterick",
        "published": "2023-11",
        "citations": 0,
        "abstract": "With a combination of access to large sets of training data on the internet, considerable increase in computing power, and novel breakthroughs in neural networks, AI has the potential to affect every organization and every employee.",
        "keywords": "",
        "link": "http://dx.doi.org/10.55834/plj.6842603892"
    },
    {
        "id": 3047,
        "title": "Regulating Transparency of AI: A Survey of Best Practices",
        "authors": "Rita Matulionyte",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4554868"
    },
    {
        "id": 3048,
        "title": "Making Informed Decisions on Reproductive Practices Based on Education AI Tool of Animation",
        "authors": "",
        "published": "2023-5-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.48047/nq.2019.17.06.2438"
    },
    {
        "id": 3049,
        "title": "Ethical decision-making in human-automation collaboration: a case study of the nurse rostering problem",
        "authors": "Vincent Bebien, Odile Bellenguez, Gilles Coppin, Anna Ma-Wyatt, Rachel Stephens",
        "published": "2024-4-3",
        "citations": 0,
        "abstract": "AbstractAs artificial intelligence (AI) is increasingly present in different aspects of society and its harmful impacts are more visible, concrete methods to help design ethical AI systems and limit currently encountered risks must be developed. Taking the example of a well-known Operations Research problem, the Nurse Rostering Problem (NRP), this paper presents a way to help close the gap between abstract principles and on-the-ground applications with two different steps. We first propose a normative step that uses dedicated scientific knowledge to provide new rules for an NRP model, with the aim of improving nurses’ well-being. However, this step alone may be insufficient to comprehensively deal with all key ethical issues, particularly autonomy and explicability. Therefore, as a complementary second step, we introduce an interactive process that integrates a human decision-maker in the loop and allows practical ethics to be applied. Using input from stakeholders to enrich a mathematical model may help compensate for flaws in automated tools.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00459-w"
    },
    {
        "id": 3050,
        "title": "AI-assisted ethics? considerations of AI simulation for the ethical assessment and design of assistive technologies",
        "authors": "Silke Schicktanz, Johannes Welsch, Mark Schweda, Andreas Hein, Jochem W. Rieger, Thomas Kirste",
        "published": "2023-6-26",
        "citations": 1,
        "abstract": "Current ethical debates on the use of artificial intelligence (AI) in healthcare treat AI as a product of technology in three ways. First, by assessing risks and potential benefits of currently developed AI-enabled products with ethical checklists; second, by proposing ex ante lists of ethical values seen as relevant for the design and development of assistive technology, and third, by promoting AI technology to use moral reasoning as part of the automation process. The dominance of these three perspectives in the discourse is demonstrated by a brief summary of the literature. Subsequently, we propose a fourth approach to AI, namely, as a methodological tool to assist ethical reflection. We provide a concept of an AI-simulation informed by three separate elements: 1) stochastic human behavior models based on behavioral data for simulating realistic settings, 2) qualitative empirical data on value statements regarding internal policy, and 3) visualization components that aid in understanding the impact of changes in these variables. The potential of this approach is to inform an interdisciplinary field about anticipated ethical challenges or ethical trade-offs in concrete settings and, hence, to spark a re-evaluation of design and implementation plans. This may be particularly useful for applications that deal with extremely complex values and behavior or with limitations on the communication resources of affected persons (e.g., persons with dementia care or for care of persons with cognitive impairment). Simulation does not replace ethical reflection but does allow for detailed, context-sensitive analysis during the design process and prior to implementation. Finally, we discuss the inherently quantitative methods of analysis afforded by stochastic simulations as well as the potential for ethical discussions and how simulations with AI can improve traditional forms of thought experiments and future-oriented technology assessment.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fgene.2023.1039839"
    },
    {
        "id": 3051,
        "title": "Ethical considerations in working with ChatGPT on a questionnaire about the future of work with ChatGPT",
        "authors": "Konstantinos Konstantis, Antonios Georgas, Antonis Faras, Konstantinos Georgas, Aristotle Tympas",
        "published": "2023-6-20",
        "citations": 3,
        "abstract": "AbstractThe prospect of the use of Large Language Models, like ChatGPT, in work environments raises important questions regarding both the potential for a dramatic change in the quality of jobs and the risk of unemployment. The answers to these questions, but, also, the posing of questions to be answered, may involve the use of ChatGPT. This, in turn, may give rise to a series of ethical considerations. The article seeks to identify such considerations by presenting a research on a questionnaire that was developed by means of ChatGPT before it was answered, first, by a group of humans (H) and, then, through the use of a machine (M), ChatGPT. The language model was actually used to respond to the questionnaire twice. First, based on its data (M1), and, second, based on it being asked to imitate a human (M2). Based on the significant differences between the H and M answers, and, further, on the noticeable differences occurring within the M answers (the differences between the M1 and M2 answers), the article concludes by registering a cluster of three ethical considerations.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00312-6"
    },
    {
        "id": 3052,
        "title": "Ethical governance of artificial intelligence for defence: normative tradeoffs for principle to practice guidance",
        "authors": "Alexander Blanchard, Christopher Thomas, Mariarosaria Taddeo",
        "published": "2024-2-19",
        "citations": 1,
        "abstract": "AbstractThe rapid diffusion of artificial intelligence (AI) technologies in the defence domain raises challenges for the ethical governance of these systems. A recent shift from the what to the how of AI ethics sees a nascent body of literature published by defence organisations focussed on guidance to implement AI ethics principles. These efforts have neglected a crucial intermediate step between principles and guidance concerning the elicitation of ethical requirements for specifying the guidance. In this article, we outline the key normative choices and corresponding tradeoffs that are involved in specifying guidance for the implementation of AI ethics principles in the defence domain. These correspond to: the AI lifecycle model used; the scope of stakeholder involvement; the accountability goals chosen; the choice of auditing requirements; and the choice of mechanisms for transparency and traceability. We provide initial recommendations for navigating these tradeoffs and highlight the importance of a pro-ethical institutional culture.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-024-01866-7"
    },
    {
        "id": 3053,
        "title": "Responsible AI and the Arts: The Ethical and Legal Implications of AI in the Arts and Creative Industries",
        "authors": "Anna Maria Piskopani, Alan Chamberlain, Carolyn Ten Holter",
        "published": "2023-7-11",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3597512.3597528"
    },
    {
        "id": 3054,
        "title": "Ethical Considerations in Integrating AI in Research Consultations: Assessing the Possibilities and Limits of GPT-based Chatbots",
        "authors": "Yali Feng, Jun Wang, Steven G. Anderson",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "Objective: This case study sought to provide early information on the accuracy and relevance of selected GPT-based product responses to basic information queries, such as might be asked in librarian research consultations. We intended to identify positive possibilities, limitations, and ethical issues associated with using these tools in research consultations and teaching.Methods: A case simulation examined the responses of GPT-based products to a basic set of questions on a topic relevant to social work students. The four chatbots (ChatGPT-3.5, ChatGPT-4, Bard, and Perplexity) were given identical question prompts, and responses were assessed for relevance and accuracy. The simulation was supplemented by reviewing actual user exchanges with ChatGPT-3.5 using a ShareGPT file containing conversations with early users.Results: Each product provided relevant information to queries, but the nature and quality of information and the formatting sophistication varied substantially. There were troubling accuracy issues with some responses, including inaccurate or non-existent references. The only paid product examined (ChatGPT-4), generally provided the highest quality information, which raises equitable access to quality technology concerns. Examination of ShareGPT conversations also raised issues regarding ethical use of chatbots to complete course assignments, dissertation designs, and other research products.Conclusions: We conclude that these new tools offer significant potential to enhance learning if well-employed. However, their use is fraught with ethical challenges. Librarians must work closely with instructors, patrons, and administrators to assure that the potential is realized while ethical values are safeguarded.",
        "keywords": "",
        "link": "http://dx.doi.org/10.7191/jeslib.846"
    },
    {
        "id": 3055,
        "title": "AI and Course Work",
        "authors": "Brian M. Peters",
        "published": "2023-11-10",
        "citations": 0,
        "abstract": "At John Abbott and Concordia, many departmental discussions have been started addressing the scary and very real situation pertaining to AI and student work. At Concordia, one department that I know of has already circulated a working document about AI, outlining problems and strategies—this is what we need more of for sure. The English Department at Concordia has started meetings, and many discussions are taking place at the Cegep level on both the departmental and administrative levels. Is there anything we can really do, is a major question that I feel, for now, might not have an answer. What we do need to do is figure out how to address AI, how to find it/spot-it, and via our pedagogies how to motivate students not to use AI. In short, yes, we can—solutions are popping up to detect AI and, most of all, we need to make sure we don’t overload our own work schedules trying to outsmart students who use AI. This article presents an overview of obstacles that current course instructors face, be they tenured faculty, lecturers, non-permanent/part-time faculty, or teaching-assistants ; as well, this informal discussion of such problems and findings is the beginning to a discussion on how to manage course content and time without burning out as we navigate the often confusing realities associated with AI and the internet as a source where students can readily cheat and/or plagiarize. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.7202/1107540ar"
    },
    {
        "id": 3056,
        "title": "Ethical And Societal Implications of AI and Machine Learning",
        "authors": "Rudra Tiwari",
        "published": "2023-1-16",
        "citations": 1,
        "abstract": "The research paper \"Ethical and societal implications of AI and machine learning\" examines the ethical and societal implications of the increasing use of artificial intelligence (AI) and machine learning. The paper explores various ethical concerns such as bias, transparency, accountability and privacy, which arise in the development and deployment of these technologies. Additionally, the paper also analyses the societal impacts of AI and machine learning, including the implications for employment, economic inequality, and social cohesion. The paper also discusses the need for regulation and governance to ensure the responsible development and use of these technologies. In summary, the paper highlights the importance of considering ethical and societal implications in the development and deployment of AI and machine learning, and the need for responsible governance to mitigate negative impacts and promote positive outcomes. Keywords: AI ethics, Machine learning ethics, AI societal impact, Machine learning societal impact, AI and society, Machine learning and society, AI governance",
        "keywords": "",
        "link": "http://dx.doi.org/10.55041/ijsrem17519"
    },
    {
        "id": 3057,
        "title": "NAVIGATING THE ETHICAL LANDSCAPE OF AI INTEGRATION IN EDUCATIONAL SETTINGS",
        "authors": "Nasheen Nur, Seng Jhing Goh, Jignya Patel, Moti Mizrahi",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21125/inted.2024.2040"
    },
    {
        "id": 3058,
        "title": "Practical (and Ethical) Uses For Generative AI",
        "authors": "",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/npcr.32365"
    },
    {
        "id": 3059,
        "title": "ETHICAL COMPLIANCE OF AI TOOLS IN INDUSTRIAL MANUFACTURING",
        "authors": "Andrea Guillén, Christopher Fischer, Emma Teodoro, Agata Gurzawska",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.7712/150123.9877.450825"
    },
    {
        "id": 3060,
        "title": "Ethical Consideration in AI &amp; Machine Learning",
        "authors": " Rashmi, Ritika Sharma, Priyanshu Sharma, Shipra Mangal",
        "published": "2023",
        "citations": 0,
        "abstract": "This innovative investigation on the ethics of AI and machine learning sets out on a multifaceted voyage through a maze-like environment. It seeks to offer a new viewpoint on negotiating the changing issues posed by AI and machine learning by exposing the interwoven layers of ethical considerations. This work encourages a progressive mindset in the face of a constantly evolving technology environment by supporting flexibility, inclusion, and ethical awareness. The paper starts off by emphasizing the moral complexity of artificial intelligence (AI), which includes issues with bias and justice as well as problems with responsibility, autonomous decision-making, and unanticipated outcomes of intelligent systems. It illustrates the various ways in which different ethical factors interact and weave together to create new levels of ethical complexity. Beyond basic algorithms and automated procedures, the rapidly developing fields of artificial intelligence (AI) and machine learning pose a dynamic and complex ethical problem. This research article takes a singular turn as it explores the complex ethical maze that artificial intelligence and machine learning have placed before us. It seeks to offer a new viewpoint on negotiating the changing issues posed by AI and machine learning by exposing the interwoven layers of ethical considerations. This work encourages a progressive mindset in the face of a constantly evolving technology environment by supporting flexibility, inclusion, and ethical awareness. The article highlights the mutually beneficial relationship that exists between those who develop technology and society in the context of AI development and application. It explores the moral responsibilities of AI designers as well as users, showing how their choices and interactions can influence the moral environment.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36893/iej.2023.v52i5.1543-1551"
    },
    {
        "id": 3061,
        "title": "Ethical reflections on AI taking decisions for incapacitated patients",
        "authors": "A. Boretti",
        "published": "2023-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.etiqe.2023.06.001"
    },
    {
        "id": 3062,
        "title": "The selective deployment of AI in healthcare",
        "authors": "Robert Vandersluis, Julian Savulescu",
        "published": "2024-3-30",
        "citations": 0,
        "abstract": "AbstractMachine‐learning algorithms have the potential to revolutionise diagnostic and prognostic tasks in health care, yet algorithmic performance levels can be materially worse for subgroups that have been underrepresented in algorithmic training data. Given this epistemic deficit, the inclusion of underrepresented groups in algorithmic processes can result in harm. Yet delaying the deployment of algorithmic systems until more equitable results can be achieved would avoidably and foreseeably lead to a significant number of unnecessary deaths in well‐represented populations. Faced with this dilemma between equity and utility, we draw on two case studies involving breast cancer and melanoma to argue for the selective deployment of diagnostic and prognostic tools for some well‐represented groups, even if this results in the temporary exclusion of underrepresented patients from algorithmic approaches. We argue that this approach is justifiable when the inclusion of underrepresented patients would cause them to be harmed. While the context of historic injustice poses a considerable challenge for the ethical acceptability of selective algorithmic deployment strategies, we argue that, at least for the case studies addressed in this article, the issue of historic injustice is better addressed through nonalgorithmic measures, including being transparent with patients about the nature of the current epistemic deficits, providing additional services to algorithmically excluded populations, and through urgent commitments to gather additional algorithmic training data from excluded populations, paving the way for universal algorithmic deployment that is accurate for all patient groups. These commitments should be supported by regulation and, where necessary, government funding to ensure that any delays for excluded groups are kept to the minimum. We offer an ethical algorithm for algorithms—showing when to ethically delay, expedite, or selectively deploy algorithmic systems in healthcare settings.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1111/bioe.13281"
    },
    {
        "id": 3063,
        "title": "Navigating the Path to Responsible AI: Interpretable Models and Ethical Implications",
        "authors": "Alex Zhu",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "In the realm of responsible AI development, this study undertakes a thorough exploration of interpretable and transparent deep learning models, recognizing their pivotal importance in shaping the future of artificial intelligence. It rigorously investigates a broad spectrum of strategies, ranging from fundamental feature visualization and extraction techniques to advanced methods such as Local Interpretable Model-agnostic Explanations (LIME), Explainable AI (XAI) tools like SHAP and Integrated Gradients, and inherently interpretable architectures like decision networks. These multifaceted approaches collectively serve to demystify the inner workings of complex AI models, providing invaluable insights into their decision-making processes. Furthermore, this research extends its purview to encompass the ethical dimensions of AI, elevating its significance beyond technical prowess. It places a resolute emphasis on addressing bias mitigation and ensuring fairness, establishing robust mechanisms for accountability and transparency, conducting rigorous analyses of societal impacts, and bolstering data privacy and security protocols. These ethical considerations are recognized as critical pillars in the foundation of responsible AI development, with the potential to build and maintain public trust in AI technologies while simultaneously aligning these innovations with the values and expectations of society at large.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/bz5w2p29"
    },
    {
        "id": 3064,
        "title": "Scientific writing and its ethical considerations using AI tools",
        "authors": "Ladusingh Rajpurohit, Shweta Dobhada",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.oor.2024.100196"
    },
    {
        "id": 3065,
        "title": "ETHICAL PRACTICES OF DENTISTS IN PUNE CITY: A CROSS SECTIONAL STUDY",
        "authors": " SHRIKANTH MURALIDHARAN et al.",
        "published": "2023-5-29",
        "citations": 0,
        "abstract": "Introduction: Every professional body has its own code of conduct for its members. Dental profession in India is regulated by the Dental Council of India (DCI) under the aegis of the Ministry of Health and Family Welfare, Government of India. DCI; a statutory body formed by an act of parliament- the Dentists Act, 1948 (XVI of 1948). Crowding of dentists across cities leads to unhealthy competition and commercialization. This leads to violating the code of conduct put forth by the state dental councils and many of the norms are openly flouted and rules randomly bent. The objective of the present study is to access the amount of violation of the code of conduct by the dental clinics with respect to the clinic name board and advertisement, in and around Pune city, by an on-site survey. Materials and methods-Ethical clearance was obtained from the Ethics Committee of M.C.E society, Azam Campus, Pune. The study consisted of questions regarding the size of the dental clinic board, attractive symbols or wordings, qualifications other than the academic ones, and advertisements of the clinics through media or sign boards. In all, 123 clinics were observed. Statistical analysis was carried out using SPSS 22.0 (Chicago, U.S.A). Results-There were in all 123 clinics (60- BDS and 63- MDS). More BDS practitioners faulted the regulations with respect to size of the sign board, slogans on the board- like “family dentists”, “tooth designing”; fixing the sign board far away from the place of practice- at the pharmacist. Higher percentage of MDS practitioners advertised through media for promoting their clinics compared to the BDS practitioners. Overall more than half of the dentists mentioned their place of study and the university from where they obtained their degrees. Almost 25% mentioned that they had obtained gold medal in their academics and a few of them also specified the subject in which they won the medals. Conclusion: The current study highlights the violation of codes by dentists in Pune city. It also shows that post graduates are also violating norms. It is up to the DCI, to take appropriate steps including the earliest revision of its norms and its supervision of its strict adherence. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/rlj.v11i11s.1860"
    },
    {
        "id": 3066,
        "title": "Ethical Implications of Deceptive Earnings Management Practices",
        "authors": "David Fowler",
        "published": "2023-9-30",
        "citations": 0,
        "abstract": "This study is devoted to the analysis of the consequences of using deceptive methods of income management and the justification of the importance of observing ethical standards in financial reporting to ensure the sustainable development of companies. The purpose of the study is to evaluate existing revenue management practices from the point of view of their compliance with ethical standards of business conduct. Based on a critical review of the literature on income management, it was concluded that the use of fraudulent methods, especially in the preparation of financial statements, reduces the integrity and reliability of information used by interested parties in making management decisions, distorts the distribution of resources, hinders the efficient functioning of capital markets and endangers the stable functioning of the economy. Based on the results of the study, it was concluded that transparency, honesty and accountability in financial activities play an important role in creating a business environment that encourages fair and honest behavior. This contributes to the preservation of the interests of interested parties and the sustainable growth of the economy due to the observance of ethical standards in the field of business. Based on the analysis of existing revenue management practices, it has been proven that the artificial increase in share prices, the use of shadow financial transactions, and the reduction of the workforce contribute to the growth of companies’ profits, due to the dismissal of experienced employees and, possibly, the reduction of its future competitiveness. The study theoretically proves the need for organizations to find a balance between financial activities and their compliance with ethical norms, taking into account that short-term profits achieved through questionable activities can ultimately lead to a decrease in trust in companies and serve as a threat to their long-term viability. The results of the study can be useful for managers of enterprises, shareholders and subjects of the financial system as a whole from the point of view of a deeper understanding of ethical problems related to income management and ways to increase the transparency and reliability of information displayed in financial statements of companies.",
        "keywords": "",
        "link": "http://dx.doi.org/10.61093/bel.7(3).84-96.2023"
    },
    {
        "id": 3067,
        "title": "Living with AI personal assistant: an ethical appraisal",
        "authors": "Lorraine K. C. Yeung, Cecilia S. Y. Tam, Sam S. S. Lau, Mandy M. Ko",
        "published": "2023-9-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01776-0"
    },
    {
        "id": 3068,
        "title": "Crossing the principle–practice gap in AI ethics with ethical problem-solving",
        "authors": "Nicholas Kluge Corrêa, James William Santos, Camila Galvão, Marcelo Pasetti, Dieine Schiavon, Faizah Naqvi, Robayet Hossain, Nythamar De Oliveira",
        "published": "2024-4-15",
        "citations": 0,
        "abstract": "AbstractThe past years have presented a surge in (AI) development, fueled by breakthroughs in deep learning, increased computational power, and substantial investments in the field. Given the generative capabilities of more recent AI systems, the era of large-scale AI models has transformed various domains that intersect our daily lives. However, this progress raises concerns about the balance between technological advancement, ethical considerations, safety measures, and financial interests. Moreover, using such systems in sensitive areas amplifies our general ethical awareness, prompting a re-emergence of debates on governance, regulation, and human values. However, amidst this landscape, how to bridge the principle–practice gap separating ethical discourse from the technical side of AI development remains an open problem. In response to this challenge, the present work proposes a framework to help shorten this gap: ethical problem-solving (EPS). EPS is a methodology promoting responsible, human-centric, and value-oriented AI development. The framework’s core resides in translating principles into practical implementations using impact assessment surveys and a differential recommendation methodology. We utilize EPS as a blueprint to propose the implementation of an Ethics as a Service Platform, currently available as a simple demonstration. We released all framework components openly and with a permissive license, hoping the community would adopt and extend our efforts into other contexts. Available in the following URL https://nkluge-correa.github.io/ethical-problem-solving/.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00469-8"
    },
    {
        "id": 3069,
        "title": "ARTIFICIAL INTELLIGENCE (AI) ACTIVITIES IN LEGAL PRACTICES",
        "authors": "Gamze Mercan",
        "published": "2024-1-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.35826/ijoecc.1824"
    },
    {
        "id": 3070,
        "title": "AI IN LANGUAGE LEARNING PROCESS",
        "authors": "Kuziyev Shavkat Abdumuratovich,  ",
        "published": "2023-10-17",
        "citations": 0,
        "abstract": "The following article shares information about the use of modern technology in education. Where, the authors give certain backgrounds of integrating the technology with education and science. Throughout the work it’s clear that technology impacts on everything enormously. Also authors’ main focus was on discovering the use of AI in the process of education, particularly, to define its significance in foreign language learning and teaching.",
        "keywords": "",
        "link": "http://dx.doi.org/10.37547/geo-23"
    },
    {
        "id": 3071,
        "title": "Why We Need to Know More: Exploring the State of AI Incident Documentation Practices",
        "authors": "Violet Turri, Rachel Dzombak",
        "published": "2023-8-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3600211.3604700"
    },
    {
        "id": 3072,
        "title": "A Rapid Review of Responsible AI frameworks: How to guide the development of ethical AI",
        "authors": "Vita Santa Barletta, Danilo Caivano, Domenico Gigante, Azzurra Ragone",
        "published": "2023-6-14",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3593434.3593478"
    },
    {
        "id": 3073,
        "title": "Empowering education with AI: Addressing ethical concerns",
        "authors": "Sara Saylam, Nilgun Duman, Yetkin Yildirim, Kseniya Satsevich",
        "published": "2023-9-17",
        "citations": 2,
        "abstract": "There has been a rapid advancement of technology in the realm of education, and artificial intelligence (AI) has become just one of the many tools utilized by members of educational institutions. However, with the swift integration of AI into the education system, many ethical challenges and dilemmas have surfaced; primarily driven by students’ misuse of the transformative technology. The potential impact on students' critical thinking skills, autonomy, and ethical decision-making further highlights the urgency to address these issues. This article explores the detrimental effects resulting from the unethical use of AI, along with proposing significant policies and guidelines in order to maximize the beneficial utilization of AI within educational institutions. Additionally, a comprehensive analysis of relevant studies will be presented to sustain the argument stated and contribute to the development of an AI learning environment that enables the prospering of both students and faculty.",
        "keywords": "",
        "link": "http://dx.doi.org/10.31039/ljss.2023.6.103"
    },
    {
        "id": 3074,
        "title": "Towards Ethical AI: Mathematics Influences Human Behavior",
        "authors": "Dioneia Monte-Serrat, Carlo Cattani",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5642/jhummath.tgsx1558"
    },
    {
        "id": 3075,
        "title": "Regulating Artificial Intelligence for a Safer and More Ethical Future: A Review of the EU’s AI Act",
        "authors": "Faraz Akhtar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4560224"
    },
    {
        "id": 3076,
        "title": "Ethical Implications of AI in Healthcare",
        "authors": "Shubhang Dhawan, Krishan Kumar",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "This article affords a survey evaluation of the literature at the ethics of artificial intelligence (AI) in healthcare. The integration of artificial intelligence (AI) into healthcare can transform analysis, remedy and affected person care. However, this speedy development raises moral concerns associated with affected person privacy, information protection and potential bias of AI algorithms. This article explores the moral implications of AI for healthcare and examines the first-rate stability between exploiting the progressive capability of AI and shielding patient privacy. Through an in-depth exploration of moral challenges and regulatory frameworks, this examines ambitions to offer insights for healthcare, era and policy stakeholders. Keywords—Artificial Intelligence, Patient Privacy, Data Security, Treatment Innovation & Healthcare Ethics.",
        "keywords": "",
        "link": "http://dx.doi.org/10.55041/ijsrem29006"
    },
    {
        "id": 3077,
        "title": "Ethical Considerations of Bias and Fairness in AI Models",
        "authors": "Sarvachan Verma, Neha Paliwal, Kanchan Yadav, P. C. Vashist",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdt61202.2024.10489577"
    },
    {
        "id": 3078,
        "title": "Challenges faced by English education in ethical minority areas under the background of Bilingual Education Policy for ethical minority students: Taking Yunnan Province as an example",
        "authors": "Zhengxue Ai",
        "published": "2024-4-1",
        "citations": 0,
        "abstract": "With the promulgation of the national bilingual education policy, the vast majority of ethnic minorities have learned to master both Mandarin Chinese and ethnic minority languages, providing them with more opportunities for their development, but it does not emphasize their foreign language skills to go out into the world. Therefore, the research theme of this paper is the challenges of English language education in ethnic minority areas in the context of bilingual education, taking Yunnan Province as an example. The study finds that there are three main challenges facing English language education for ethnic minorities. They are language teaching issues in ethical minority areas, English teacher issues in ethical minority areas, and people’s attitudes toward English learning in ethical minority areas. Firstly, there are a lot of problems with English teachers, such as the impact of minority languages on Han English teachers is big, insufficient teacher resources, low professional quality, and high turnover. Then, the students learn English with language transfer and are not interested in it. Finally, schools, teachers, parents, and students do not value English education enough.",
        "keywords": "",
        "link": "http://dx.doi.org/10.62051/m83s2d29"
    },
    {
        "id": 3079,
        "title": "Ethical Considerations in AI-Driven User Interfaces",
        "authors": "Prashant S. Acharya, Dr. Tripti Sahu, Pranav Dixit",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": "The integration of AI into user interfaces (UIs) has propelled technological advancements, enabling personalized experiences and improved efficiency. However, the ethical implications of AI-driven UIs cannot be overlooked. This research paper will analyze the ethical considerations regarding- transparency, accountability, fairness, privacy, and user consent. By exploring potential risks and challenges, we can advocate for the implementation of ethical design principles, regulatory frameworks, and user education initiatives. Through case studies and future directions, this paper highlights the importance of responsible and ethical AI UI development.\r\nThe following questions and topics will be covered in this research paper-\r\n\r\nWhat is AI?\r\nCurrent capabilities and future scope of AI in User interfaces\r\nWhere is AI being currently used?\r\nConcerns, Risks regarding AI\r\nPotential solutions, Creating Ethical principles\r\nHow can AI be used ethically in UI design?\r\nReal-life examples\r\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/jier.v4i1.643"
    },
    {
        "id": 3080,
        "title": "The Era of AI: Upholding Ethical Leadership",
        "authors": "A S M Ahsan Uddin",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.4236/ojl.2023.124019"
    },
    {
        "id": 3081,
        "title": "Regulating Generative AI: A Pathway to Ethical and Responsible Implementation",
        "authors": "Jonathan Luckett",
        "published": "2023-8-12",
        "citations": 0,
        "abstract": "Artificial intelligence (AI) is becoming more and more prevalent in our daily lives, and its potential applications are practically limitless. However, as with any technology, there are concerns about how AI could be misused or abused. One of the most serious concerns is the potential for discrimination, particularly against women or minorities, when AI systems are used for tasks like job hiring. Additionally, there are concerns about privacy and security, as AI could be used to monitor people's movements or launch cyberattacks. To address these concerns, regulations must be developed to ensure that AI is developed and used ethically and responsibly. These regulations should address issues like safety, privacy, security, and discrimination. Finally, it is important to educate the public about AI and how to use it safely and responsibly. In this paper, I will examine the AI regulations and challenges that exist today, particularly in the United States. Two regulations I will focus on are the AI in Government Act of 2020 and the National Artificial Intelligence Initiative Act of 2020. Additionally, I will examine two Executive Orders that have addressed the issue of AI in the federal government. Finally, I will conclude with some policy considerations and recommendations for federal agencies.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5121/ijci.2023.120508"
    },
    {
        "id": 3082,
        "title": "Primed and ready?",
        "authors": "Leticia Antunes Nogueira",
        "published": "2023-10-18",
        "citations": 0,
        "abstract": "The emergence and proliferation of artificial intelligence (AI) tools has left the realm of science fiction and the province of computer science research and has reached the everyday activities of academics and various support staff. AI promises to automate and facilitate a range of research tasks and increase scientific productivity, and can thus be expected to raise new questions and dilemmas that might challenge the systems of accountability currently in place to safeguard academic integrity.\r\nThis poster presents preliminary results of an analysis of seven prominent ethical guidelines (international and Norwegian): the Vancouver protocol, ALLEA guidelines, NENT and NESH guidelines, professional codes of ethics from IFLA, ALA, and the Norwegian Union of Librarians. EBLIDA and LIBER were consulted, but do not offer their own ethical guidelines. The main research question is: to what extent do current ethical guidelines support researchers and librarians in dealing with ethical questions brought about by the proliferation of new AI tools?\r\nThe concern that emergent technologies tend to challenge values, norms, and practices in academia is not new. For example, ALLEA (2017) acknowledges that the values and principles they lay out are “affected by social, political or technological developments and by changes in the research environment” (p.3). Nonetheless, only the Vancouver protocol (updated in May 2023) provides explicit recommendations on AI; it essentially prescribes that authors/reviewers disclose if and how they used AI tools. The other documents, ranging from 2008 to 2022, mention neither AI nor the possibility of automation technologies in academic/library work.\r\nDespite the absence of advice on AI, the analysis revealed interesting issues on ethical guidelines and emergent technologies. ALA (2017) makes extensive recommendations about social media, both as a tool for libraries’ own work and as a demand from patrons who require their expertise. Similar needs for new competencies and responsibilities can be expected from AI. Also, the Norwegian Union of Librarians (2008) encourages the adoption of free software, open standards, and open source codes; this can gain new momentum with the emergence of proprietary tools and algorithms, particularly if they are trained on public data curated by i.a. libraries.\r\nEthical guidelines are general; they state a commitment to certain values and how they should guide certain tasks and practices. They do not prescribe how concrete tools should be employed. In this regard, the current ethical guidelines do offer a sound basis upon which new ethical questions can be assessed. Yet, unlike other types of tools employed in research and library work, AI poses challenges to things that are taken for granted by ethical guidelines, such as what constitutes information, or whether non-human entities can be considered authors, sources, or neither.\r\nIn conclusion, it might be beneficial to revise ethical guidelines, less so because AI requires concrete recommendations, and more because they challenge substantive assumptions upon which guidelines rely. Also, new possibilities afforded by AI might put pressure on certain values, such as reproducibility and academic craftsmanship. Assuming that academia/library communities consider these important to preserve, it might be beneficial to reaffirm these values in light of the changing landscape.",
        "keywords": "",
        "link": "http://dx.doi.org/10.7557/5.7275"
    },
    {
        "id": 3083,
        "title": "Ethical consideration for implementing AI in healthcare: A chat GPT perspective",
        "authors": "Vikas V. Pawar, Safia Farooqui",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.oraloncology.2023.106682"
    },
    {
        "id": 3084,
        "title": "Ethical Challenges in Forensic Social Work",
        "authors": "Frederic Reamer",
        "published": "2023-2-10",
        "citations": 0,
        "abstract": "Many social workers become involved in legal proceedings on their clients’ behalf. A subset of practitioners identify themselves as forensic social workers. Forensic social work is typically defined as the application of social work knowledge and skills to questions and issues relating to law, legal institutions, and legal proceedings. This social work specialization often entails collaboration with other professionals, especially attorneys, on clients’ behalf. This collaboration sometimes leads to ethical dilemmas, especially related to commitment to clients; informed consent; client confidentiality and privileged communication; conflicts of interest; and interdisciplinary collaboration. The purpose of this article is to identify common ethical challenges in forensic social work; apply relevant social work ethics standards; discuss risk management models and protocols to protect clients and practitioners; and discuss potential ethics challenges when forensic social workers are subpoenaed during legal proceedings.",
        "keywords": "",
        "link": "http://dx.doi.org/10.15763/issn.1936-9298.2023.7.1.32-41"
    },
    {
        "id": 3085,
        "title": "A Study of Ethical Dilemmas and Regulation of AI Chatbots",
        "authors": "Xiaokang Song",
        "published": "2023-9-17",
        "citations": 0,
        "abstract": "Chatbots are the product of the development of artificial intelligence to a certain stage, and have different degrees of technical effects under the iteration of technology. Under the development of media technology in recent years, the artificial intelligence robot represented by Chatgpt has attracted widespread attention because of its ability to learn dialogue, and from the current stage of development, there is no doubt that intelligent chatbots have brought about a worldwide revolution in communication technology. It has had a great impact on various fields such as sociology, communication, computation, education, etc. It has produced an underlying reaction to various fields from the technical architecture, changed the previous way of creating, interacting, educating and other behaviours, and has also had an important impact on social construction and interaction. Its unique way of knowledge learning and updating not only brings new possibilities to the network communication ecology, but also brings some ethical dilemmas in communication, which require people to be alert to this new technology and take corresponding preventive and regulatory measures.",
        "keywords": "",
        "link": "http://dx.doi.org/10.53469/jtpss.2023.03(09).02"
    },
    {
        "id": 3086,
        "title": "From Development to Dissemination: Social and Ethical Issues with Text-to-Image AI-Generated Art",
        "authors": "Sharon Chee Yin Ho",
        "published": "2023-6-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21428/594757db.acad9d77"
    },
    {
        "id": 3087,
        "title": "Ethical issues to think about when using AI in healthcare",
        "authors": "Vikas V. Pawar, Safia Farooqui",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.oor.2023.100145"
    },
    {
        "id": 3088,
        "title": "Why open-source generative AI models are an ethical way forward for science",
        "authors": "Arthur Spirling",
        "published": "2023-4-20",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/d41586-023-01295-4"
    },
    {
        "id": 3089,
        "title": "Investigate Ethical Challenges and Considerations in the Collection, Analysis, and Use of Data for IT Analytics, Addressing Issues Related to Privacy, Bias, and Responsible AI",
        "authors": "Ranadeep Reddy Palle",
        "published": "2023-1-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21275/es24101103401"
    },
    {
        "id": 3090,
        "title": "AI and Philosophy: Exploring the Complex Relationship between Worldviews and Technology Development for an Inclusive and Ethical Future",
        "authors": "Jerry Washington",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4656485"
    },
    {
        "id": 3091,
        "title": "Generative AI in Adventist Education: Opportunities and Ethical Considerations",
        "authors": "David P. Harris, Fred Armstrong",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.55668/jae0043"
    },
    {
        "id": 3092,
        "title": "DEVELOPING A METHODOLOGICAL APPROACH AND FRAMEWORK TO ASSESS STUDENTS’ ETHICAL APPROACHES TO GENERATIVE AI UTILISATION FOR ASSESSMENTS",
        "authors": "David Pike, Alina Bajgrowicz",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21125/inted.2024.1279"
    },
    {
        "id": 3093,
        "title": "AI uses in clinical surgery research and publication: an emerging ethical issue",
        "authors": "Rujittika Mungmunpuntipantip, Viroj Wiwanitkit",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1097/fs9.0000000000000102"
    },
    {
        "id": 3094,
        "title": "AI Guidelines and Ethical Readiness Inside SMEs: A Review and Recommendations",
        "authors": "Marwa Samih Soudi, Merja Bauters",
        "published": "2024-4",
        "citations": 0,
        "abstract": "AbstractSmall and medium enterprises (SMEs) represent a large segment of the global economy. As such, SMEs face many of the same ethical and regulatory considerations around Artificial Intelligence (AI) as other businesses. However, due to their limited resources and personnel, SMEs are often at a disadvantage when it comes to understanding and addressing these issues. This literature review discusses the status of ethical AI guidelines released by different organisations. We analyse the academic papers that address the private sector in addition to the guidelines released directly by the private sector to help us better understand the responsible AI guidelines within the private sector. We aim by this review to provide a comprehensive analysis of the current state of ethical AI guidelines development and adoption, as well as identify gaps in knowledge and best attempts. By synthesizing existing research and insights, such a review could provide a road map for small and medium enterprises (SMEs) to adopt ethical AI guidelines and develop the necessary readiness for responsible AI implementation. Additionally, a review could inform policy and regulatory frameworks that promote ethical AI development and adoption, thereby creating a supportive ecosystem for SMEs to thrive in the AI landscape. Our findings reveal a need for supporting SMEs to embrace responsible and ethical AI adoption by (1) Building more tailored guidelines that suit different sectors instead of fit to all guidelines. (2) Building a trusted accreditation system for organisations. (4) Giving up-to-date training to employees and managers about AI ethics. (5) Increasing the awareness about explainable AI systems, and (6) Promoting risk-based assessments rather than principle-based assessments.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s44206-024-00087-1"
    },
    {
        "id": 3095,
        "title": "User Perspectives on Ethical Challenges in Human-AI Co-Creativity: A Design Fiction Study",
        "authors": "Jeba Rezwana, Mary Lou Maher",
        "published": "2023-6-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3591196.3593364"
    },
    {
        "id": 3096,
        "title": "Physician’s autonomy in the face of AI support: walking the ethical tightrope",
        "authors": "Florian Funer, Urban Wiesing",
        "published": "2024-3-28",
        "citations": 0,
        "abstract": "The introduction of AI support tools raises questions about the normative orientation of medical practice and the need to rethink its basic concepts. One of these concepts that is central to the discussion is the physician’s autonomy and its appropriateness in the face of high-powered AI applications. In this essay, a differentiation of the physician’s autonomy is made on the basis of a conceptual analysis. It is argued that the physician’s decision-making autonomy is a purposeful autonomy. The physician’s decision-making autonomy is fundamentally anchored in the medical ethos for the purpose to promote the patient’s health and well-being and to prevent him or her from harm. It follows from this purposefulness that the physician’s autonomy is not to be protected for its own sake, but only insofar as it serves this end better than alternative means. We argue that today, given existing limitations of AI support tools, physicians still need physician’s decision-making autonomy. For the possibility of physicians to exercise decision-making autonomy in the face of AI support, we elaborate three conditions: (1) sufficient information about AI support and its statements, (2) sufficient competencies to integrate AI statements into clinical decision-making, and (3) a context of voluntariness that allows, in justified cases, deviations from AI support. If the physician should fulfill his or her moral obligation to promote the health and well-being of the patient, then the use of AI should be designed in such a way that it promotes or at least maintains the physician’s decision-making autonomy.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fmed.2024.1324963"
    },
    {
        "id": 3097,
        "title": "Adopting AI in Defense Organizations Requires Further Focus on Ethical, Legal and Societal Aspects",
        "authors": "Benjamyn Scott, Henning Lahmann, Bart Custers",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4754951"
    },
    {
        "id": 3098,
        "title": "AI IN HIGHER EDUCATION: NEW ETHICAL CHALLENGES FOR STUDENTS AND TEACHERS",
        "authors": "Fernando Castelló-Sirvent, Vicenta Eloina García Félix, Lourdes Canós-Darós",
        "published": "2023-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21125/edulearn.2023.1172"
    },
    {
        "id": 3099,
        "title": "Seeming Ethical Makes You Attractive: Unraveling How Ethical Perceptions of AI in Hiring Impacts Organizational Innovativeness and Attractiveness",
        "authors": "Serge P. da Motta Veiga, Maria Figueroa-Armijos, Brent B. Clark",
        "published": "2023-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10551-023-05380-6"
    },
    {
        "id": 3100,
        "title": "Understanding DSM-5-TR: Changes, Updates, and Ethical Practices in Mental Health.",
        "authors": "Tony Bobadilla",
        "published": "2024-1-23",
        "citations": 0,
        "abstract": "This overview delves into the DSM-5-TR, exploring its historical development, organization, and significant changes, emphasizing cultural, racist, and discriminatory considerations, coding intricacies, and the assessment of children. The updated criteria for various disorders are examined, with a particular focus on Prolonged Grief Disorder and its associated concerns. Future research suggests enhancing the DSM-5-TR through dimensional approaches and investigating their impact on clinical practice and patient outcomes. Mental health professionals are urged to use the DSM-5-TR effectively and ethically, considering both its strengths and limitations. The paper aims to comprehensively understand the DSM-5-TR and its prospective role in shaping research and clinical practices.",
        "keywords": "",
        "link": "http://dx.doi.org/10.24297/jssr.v20i.9571"
    },
    {
        "id": 3101,
        "title": "Realization of Disability Equity Through Ethical Data Management Practices",
        "authors": "Carolyn Petersen",
        "published": "2023-11-8",
        "citations": 0,
        "abstract": "People with disabilities (PWDs) experience worse health outcomes than people who do not have disabilities. Making meaningful progress on disability equity requires new ways of thinking about disability, new tools and processes, and new ways of working within the existing health care system. Immediate actions to increase disability equity include expanded data collection including patient-reported outcomes measures, more transparent, person-centered data governance and management, integration of public health and clinic-based health data, and renewed efforts to communicate with and treat PWDs with respect. Prevention of threats to realization of disability equity including a resurgence in the practice of eugenics, misuse of emerging technologies such as CRISPR, and surveillance-promoting technologies also are critical.",
        "keywords": "",
        "link": "http://dx.doi.org/10.47912/jscdm.252"
    },
    {
        "id": 3102,
        "title": "Strategies For Upholding Ethical Standards: Best Practices For Managers In Fostering A Culture Of Ethics In Organizations",
        "authors": "",
        "published": "2024-1-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.47750/qas/25.199.38"
    },
    {
        "id": 3103,
        "title": "Physicians’ and Machine Learning Researchers’ Perspectives on Ethical Issues in the Early Development of Clinical Machine Learning Tools: Qualitative Interview Study",
        "authors": "Jane Paik Kim, Katie Ryan, Max Kasun, Justin Hogg, Laura B Dunn, Laura Weiss Roberts",
        "published": "2023-10-30",
        "citations": 2,
        "abstract": "\nBackground\nInnovative tools leveraging artificial intelligence (AI) and machine learning (ML) are rapidly being developed for medicine, with new applications emerging in prediction, diagnosis, and treatment across a range of illnesses, patient populations, and clinical procedures. One barrier for successful innovation is the scarcity of research in the current literature seeking and analyzing the views of AI or ML researchers and physicians to support ethical guidance.\n\n\nObjective\nThis study aims to describe, using a qualitative approach, the landscape of ethical issues that AI or ML researchers and physicians with professional exposure to AI or ML tools observe or anticipate in the development and use of AI and ML in medicine.\n\n\nMethods\nSemistructured interviews were used to facilitate in-depth, open-ended discussion, and a purposeful sampling technique was used to identify and recruit participants. We conducted 21 semistructured interviews with a purposeful sample of AI and ML researchers (n=10) and physicians (n=11). We asked interviewees about their views regarding ethical considerations related to the adoption of AI and ML in medicine. Interviews were transcribed and deidentified by members of our research team. Data analysis was guided by the principles of qualitative content analysis. This approach, in which transcribed data is broken down into descriptive units that are named and sorted based on their content, allows for the inductive emergence of codes directly from the data set.\n\n\nResults\nNotably, both researchers and physicians articulated concerns regarding how AI and ML innovations are shaped in their early development (ie, the problem formulation stage). Considerations encompassed the assessment of research priorities and motivations, clarity and centeredness of clinical needs, professional and demographic diversity of research teams, and interdisciplinary knowledge generation and collaboration. Phase-1 ethical issues identified by interviewees were notably interdisciplinary in nature and invited questions regarding how to align priorities and values across disciplines and ensure clinical value throughout the development and implementation of medical AI and ML. Relatedly, interviewees suggested interdisciplinary solutions to these issues, for example, more resources to support knowledge generation and collaboration between developers and physicians, engagement with a broader range of stakeholders, and efforts to increase diversity in research broadly and within individual teams.\n\n\nConclusions\nThese qualitative findings help elucidate several ethical challenges anticipated or encountered in AI and ML for health care. Our study is unique in that its use of open-ended questions allowed interviewees to explore their sentiments and perspectives without overreliance on implicit assumptions about what AI and ML currently are or are not. This analysis, however, does not include the perspectives of other relevant stakeholder groups, such as patients, ethicists, industry researchers or representatives, or other health care professionals beyond physicians. Additional qualitative and quantitative research is needed to reproduce and build on these findings.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.2196/47449"
    },
    {
        "id": 3104,
        "title": "Regulatory Siblings: The Unfair Commercial Practices Directive Roots of the AI Act",
        "authors": "Catalina Goanta",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4337417"
    }
]