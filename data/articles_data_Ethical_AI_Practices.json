[
    {
        "id": 801,
        "title": "From applied ethics and ethical principles to virtue and narrative in AI practices",
        "authors": "Paul Hayes, Noel Fitzpatrick, José Manuel Ferrández",
        "published": "2024-4-8",
        "citations": 0,
        "abstract": "AbstractThe question of how we can use ethics and ethical frameworks to avert the negative consequences of AI through guidance on human behaviour and the design of technological systems has recently been receiving increasing attention. The appropriate response to an ethics of AI has certainly been contentious. For some years the wisdom of deontology and utilitarianism in the ethics of technology has been questioned. Today, a kind of AI ethics principlism has gained a degree of widespread acceptance, yet it still invites harsh rejections in recent scholarship. In this paper, we wish to explore the contribution to an ethics of AI made by a narrative philosophy and ethics of technology inspired by the ‘little ethics’ of Paul Ricoeur, and virtue ethics of Alasdair MacIntyre, most recently and promisingly built upon by Wessel Reijers and Mark Coeckelbergh.  The objective of this paper is to examine the extent to which a narrative and virtue based ethics (or, VPD, i.e., virtuous practice design) might be a plausible candidate for the foundation of an ethics of AI, or rather ethical AI practice. This will be achieved by exploring the ways in which this approach can respond to some of the significant faults with or critiques of applied and principles and guidelines based ethical approaches to AI ethics.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00472-z"
    },
    {
        "id": 802,
        "title": "The Epistemic Status of AI in Medical Practices: Ethical Challenges",
        "authors": "Angelina Baeva",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "In recent years, discussions have been increasingly emerging in modern scientific research that, in connection with the development of AI technologies, questions arise about the objectivity, plausibility and reliability of knowledge, as well as whether these technologies will not replace the expert figure as the authority that has so far acted as a guarantor of objectivity and the center of decision-making. Modern historians of science Duston L. and Galison P. in their book on the history of scientific objectivity, they talk about the alternation of \"epistemic virtues\", as one of which objectivity has been established since a certain moment. At the same time, the promotion of one or another virtue regulating the scientific self, i.e. acting as a normative principle for a scientist when choosing one or another way of seeing and one or another scientific practice, depends on making decisions in difficult cases requiring the will and limitation of the self. In this sense, epistemology is combined with ethics: a scientist, guided by certain moral principles, gives preference to one or another way of behavior, choosing, for example, not a more accurate hand-drawn image, but an uncluttered photograph, perhaps fuzzy, but obtained mechanically, which means more objective and free from any admixture of subjectivity. In this regard, the epistemic status of modern AI-based technologies, which increasingly assume the functions of the scientific self, including in terms of influencing final decision-making and obtaining objective knowledge, seems interesting. For example, in the field of medicine, robotic devices already provide significant support, taking over some of the functions, for example, of a first-level doctor to collect and analyze standardized patient data and diagnostics. There is an assumption that AI will take on more and more responsibilities in the near future: data processing, development of new drugs and treatment methods, establishing remote interaction with the patient, etc. But does this mean that the scientific self can be replaced by AI-based algorithms, and another epistemic virtue will replace objectivity, finally breaking the link between ethics and epistemology – this question needs to be investigated.",
        "keywords": "",
        "link": "http://dx.doi.org/10.17816/dd625319"
    },
    {
        "id": 803,
        "title": "Accountability for Responsible AI Practices: Ethical Responsibilities of Senior Leadership",
        "authors": "Alex John London",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4736880"
    },
    {
        "id": 804,
        "title": "Ethical Requirements Stack: A framework for implementing ethical requirements of AI in software engineering practices",
        "authors": "Mamia Agbese, Rahul Mohanani, Arif Ali Khan, Pekka Abrahamsson",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3593434.3593489"
    },
    {
        "id": 805,
        "title": "Navigating the AI frontier: ethical considerations and best practices in microbial genomics research",
        "authors": "Andrew J. Page, Niamh M. Tumelty, Samuel K. Sheppard",
        "published": "2023-6-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1099/mgen.0.001049"
    },
    {
        "id": 806,
        "title": "From principles to practices: the intertextual interaction between AI ethical and legal discourses",
        "authors": "Le Cheng, Xiuli Liu",
        "published": "2023-4-25",
        "citations": 6,
        "abstract": "Abstract\nThe ascendancy and ubiquity of generative AI technology, exemplified by ChatGPT, has resulted in a transformative shift in the conventional human–AI interaction paradigm, leading to substantial alterations in societal modes of production. Drawing on CDA approach, this study conducts a thematic intertextuality analysis of 29 AI ethical documents, and delves into the restructuring of the human–AI relations catalysed by ChatGPT, as well as the complex ethical and legal challenges it presents. The findings indicate that the thematic intertextuality between AI ethical discourse and legal discourse promotes the connection and convergence of narrative-ideological structures, which in turn primarily creates new meaningful texts and ethical frameworks that promote a holistic approach to a good AI society. This research also identifies the importance of integrating law-making efforts with substantive ethical analysis and appropriate discursive strategies to promote the responsible and ethical development of generative AI that benefits society as a whole.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1515/ijld-2023-2001"
    },
    {
        "id": 807,
        "title": "Generative conversational AI agent for managerial practices: The role of IQ dimensions, novelty seeking and ethical concerns",
        "authors": "Abdullah M. Baabdullah",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.techfore.2023.122951"
    },
    {
        "id": 808,
        "title": "Ethical implications of AI in the Metaverse",
        "authors": "Alesia Zhuk",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "AbstractThis paper delves into the ethical implications of AI in the Metaverse through the analysis of real-world case studies, including Horizon Worlds, Decentraland, Roblox, Sansar, and Rec Room. The examination reveals recurring concerns related to content moderation, emphasising the need for a human-AI hybrid approach to strike a balance between creative freedom and user safety. Privacy and data protection emerge as crucial considerations, highlighting the importance of transparent communication and user data control for responsible AI implementation. Additionally, promoting inclusivity and diversity is emphasised, calling for transparent governance, diverse representation, and collaboration with ethics experts to ensure equitable AI practices. By addressing these specific ethical challenges, we can pave the way towards a responsible and user-centric Metaverse, maximising its potential while safeguarding user well-being and rights.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00450-5"
    },
    {
        "id": 809,
        "title": "Artificial Intention: A Path to Ethical AI?",
        "authors": "Pawas Piyush",
        "published": "2023-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21275/sr231005155020"
    },
    {
        "id": 810,
        "title": "AI risk assessment using ethical dimensions",
        "authors": "Alessio Tartaro, Enrico Panai, Mariangela Zoe Cocchiaro",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00401-6"
    },
    {
        "id": 811,
        "title": "Ensuring a ‘Responsible’ AI future in India: RRI as an approach for identifying the ethical challenges from an Indian perspective",
        "authors": "Nitika Bhalla, Laurence Brooks, Tonii Leach",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "AbstractArtificial intelligence (AI) can be seen to be at an inflexion point in India, a country which is keen to adopt and exploit new technologies, but needs to carefully consider how they do this. AI is usually deployed with good intentions, to unlock value and create opportunities for the people; however it does not come without its challenges. There are a set of ethical–social issues associated with AI, which include concerns around privacy, data protection, job displacement, historical bias and discrimination. Through a series of focus groups with knowledgeable people embedded in India and its culture, this research explores the ethical–societal changes and challenges that India now faces. Further, it investigates whether the principles and practices of responsible research and innovation (RRI) might provide a framework to help identify and deal with these issues. The results show that the areas in which RRI could offer scope to improve this outlook include education, policy and governance, legislation and regulation, and innovation and industry practices. Some significant challenges described by participants included: the lack of awareness of AI by the public as well as policy makers; India’s access and implementation of Western datasets, resulting in a lack of diversity, exacerbation of existing power asymmetries, increase in social inequality and the creation of bias; the potential replacement of jobs by AI. One option was to look at a hybrid approach, a mix of AI and humans, with expansion and upskilling of the current workforce. In terms of strategy, there seems to be a gap between the rhetoric of the government and what is seen on the ground, and therefore going forward there needs to be a much greater engagement with a wider audience of stakeholders.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00370-w"
    },
    {
        "id": 812,
        "title": "Empathy: an ethical consideration of AI &amp; others in the workplace",
        "authors": "Denise Kleinrichert",
        "published": "2024-1-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01831-w"
    },
    {
        "id": 813,
        "title": "Equity, autonomy, and the ethical risks and opportunities of generalist medical AI",
        "authors": "Reuben Sass",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00380-8"
    },
    {
        "id": 814,
        "title": "Artificial consciousness: the missing ingredient for ethical AI?",
        "authors": "Antonio Chella",
        "published": "2023-11-21",
        "citations": 1,
        "abstract": "Can we conceive machines that can formulate autonomous intentions and make conscious decisions? If so, how would this ability affect their ethical behavior? Some case studies help us understand how advances in understanding artificial consciousness can contribute to creating ethical AI systems.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/frobt.2023.1270460"
    },
    {
        "id": 815,
        "title": "Ethical Considerations in the Use of Disfluencies in AI-Generated Speech",
        "authors": "Ralph Rose",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011987200003470"
    },
    {
        "id": 816,
        "title": "The ethical wisdom of AI developers",
        "authors": "Tricia A. Griffin, Brian P. Green, Jos V.M. Welie",
        "published": "2024-3-20",
        "citations": 0,
        "abstract": "AbstractThis paper explores ethical wisdom in the artificial intelligence (AI) developer community. Despite robust literature about the need for virtue ethics approaches in AI development, little research has directly engaged with the developer community about their progress in this regard. We have thus conducted semi-structured interviews with a worldwide cohort of 40 developers, which focused on their awareness of ethics issues, how they navigate ethical challenges, and the barriers they encounter in developing ethical wisdom. We find developers are largely aware of the ethical territories they must navigate and the moral dilemmas they personally encounter, but they face limited and inconsistent resources for ethical guidance or training. Furthermore, there are significant barriers inhibiting the development of ethical wisdom in the AI developer community, including the industry’s fixation on innovation, the narrow scope of technical practice, limited provisions for reflection and dialogue, and incentive structures that prioritize profits and prestige. The paper concludes by emphasizing the need to address the gap in domain-specific ethical skill and provides recommendations for organizations, educators, and the AI developer community.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00458-x"
    },
    {
        "id": 817,
        "title": "The ethical agency of AI developers",
        "authors": "Tricia A. Griffin, Brian Patrick Green, Jos V. M. Welie",
        "published": "2023-1-9",
        "citations": 6,
        "abstract": "AbstractPublic and academic discourse about the ethics of artificial intelligence, machine learning, and data science has largely focused on the algorithms and the companies deploying them. Little attention has been paid to the ethical agency of the developers. This study is the first of its kind that centers developers in the ethical environment. Semi-structured interviews with 40 developers about the ethics of being a developer revealed more than 20 themes, 3 of which are the subject of this paper: ethics in the occupational ecosystem, developer ethical agency, and the characteristics of an ethical developer. These themes reveal significant gaps between how developers perceive themselves and the reality of their work experiences. Their ethical agency is likewise variable. They have some authority to intervene for ethical reasons in systems they work on, but they often do not realize just how many ethical decisions they make. Nonetheless, this study reveals a growing ethical wisdom in this community, one that needs to be surfaced and nurtured by engaging with developers.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-022-00256-3"
    },
    {
        "id": 818,
        "title": "The poverty of ethical AI: impact sourcing and AI supply chains",
        "authors": "James Muldoon, Callum Cant, Mark Graham, Funda Ustek Spilda",
        "published": "2023-12-20",
        "citations": 1,
        "abstract": "AbstractImpact sourcing is the practice of employing socio-economically disadvantaged individuals at business process outsourcing centres to reduce poverty and create secure jobs. One of the pioneers of impact sourcing is Sama, a training-data company that focuses on annotating data for artificial intelligence (AI) systems and claims to support an ethical AI supply chain through its business operations. Drawing on fieldwork undertaken at three of Sama’s East African delivery centres in Kenya and Uganda and follow-up online interviews, this article interrogates Sama’s claims regarding the benefits of its impact sourcing model. Our analysis reveals alarming accounts of low wages, insecure work, a tightly disciplined labour management process, gender-based exploitation and harassment and a system designed to extract value from low-paid workers to produce profits for investors. We argue that competitive market-based dynamics generate a powerful force that pushes such companies towards limiting the actual social impact of their business model in favour of ensuring higher profit margins. This force can be resisted, but only through countervailing measures such as pressure from organised workers, civil society, or regulation. These findings have broad implications related to working conditions for low-wage data annotators across the sector and cast doubt on the ethical nature of AI products that rely on this form of AI data work.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01824-9"
    },
    {
        "id": 819,
        "title": "Suggestions for Ethical Decision-Making Model through Collaboration between Human and AI",
        "authors": "Hyunsoo Kim,  ",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "Purpose: The purpose of this study is to explore and propose a model that allows humans and AI to collaborate in the process of making decisions about ethical issues. Due to AI's autonomy and mission performance capabilities, AI is sometimes viewed as an agent competing with humans. However, since the autonomy and mission performance capabilities of AI are applied at very diverse levels and areas, it is necessary to set certain categories and review their application. This study sought to reveal that more valid decisions can be made by collaborating between humans and AI in the category of ethical decision-making.\r\nMethod: This study uses methods of literature research and development research. First, using literature research to review various previous studies to understand the autonomy of AI in the relationship between humans and AI. Next, analyzing the meaning and characteristics of ethical judgment. Next, looking at a series of models that explain decision making. Second, using development research methods, for design and propose a model in which humans and AI appropriately collaborate in the process of making ethical decisions.\r\nResults: The results of this study reveal the following points. First, the results of ethical decision-making by humans and AI involve greater responsibility and related issues than the results of general decision-making. Second, in order to solve these problems, it is necessary to utilize collective intelligence through collective decision-making and at the same time distribute responsibility. Third, as a public and collective entity functioning as a committee, humans become the subjects of final judgment and responsibility, and AI must play a role in actively and functionally assisting such judgment. Fourth, this decision-making process needs to be presented in the form of a model as a principle that can be applied to various specific cases.\r\nConclusion: The conclusion of this study suggests that effective and valid ethical decisions can be made through collaboration between humans and AI in the ethical communication process. And based on this, we present a collaboration model between humans and AI. This model consists of the following steps: First, AI should be actively involved in the process of exploring data sources, collecting data, storing data, and refining and analyzing data for ethical decisions. Second, ethical decisions based on this are made by a human community in the form of a committee as a group thinking process. Third, allow humans and AI to evaluate and exchange opinions on the results of these ethical judgments through mutual feedback and collaboration.",
        "keywords": "",
        "link": "http://dx.doi.org/10.22471/ai.2023.8.12"
    },
    {
        "id": 820,
        "title": "Ethical AI governance: mapping a research ecosystem",
        "authors": "Simon Knight, Antonette Shibani, Nicole Vincent",
        "published": "2024-2-14",
        "citations": 0,
        "abstract": "AbstractHow do we assess the positive and negative impacts of research about- or research that employs artificial intelligence (AI), and how adequate are existing research governance frameworks for these ends? That concern has seen significant recent attention, with various calls for change, and a plethora of emerging guideline documents across sectors. However, it is not clear what kinds of issues are expressed in research ethics with or on AI at present, nor how resources are drawn on in this process to support the navigation of ethical issues. Research Ethics Committees (RECs) have a well-established history in ethics governance, but there have been concerns about their capacity to adequately govern AI research. However, no study to date has examined the ways that AI-related projects engage with the ethics ecosystem, or its adequacy for this context. This paper analysed a single institution’s ethics applications for research related to AI, applying a socio-material lens to their analysis. Our novel methodology provides an approach to understanding ethics ecosystems across institutions. Our results suggest that existing REC models can effectively support consideration of ethical issues in AI research, we thus propose that any new materials should be embedded in this existing well-established ecosystem.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00416-z"
    },
    {
        "id": 821,
        "title": "Ethical and preventive legal technology",
        "authors": "Georgios Stathis, Jaap van den Herik",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "AbstractPreventive Legal Technology (PLT) is a new field of Artificial Intelligence (AI) investigating the intelligent prevention of disputes. The concept integrates the theories of preventive law and legal technology. Our goal is to give ethics a place in the new technology. By explaining the decisions of PLT, we aim to achieve a higher degree of trustworthiness because explicit explanations are expected to improve the level of transparency and accountability. Trustworthiness is an urgent topic in the discussion on doing AI research ethically and accounting for the regulations. For this purpose, we examine the limitations of rule-based explainability for PLT. Hence, our Problem Statement reads: to what extent is it possible to develop an explainable and trustworthy Preventive Legal Technology? After an insightful literature review, we focus on case studies with applications. The results describe (1) the effectivity of PLT and (2) its responsibility. The discussion is challenging and multivariate, investigating deeply the relevance of PLT for LegalTech applications in light of the development of the AI Act (currently still in its final phase of process) and the work of the High-Level Expert Group (HLEG) on AI. On the ethical side, explaining AI decisions for small PLT domains is clearly possible, with direct effects on trustworthiness due to increased transparency and accountability.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00413-2"
    },
    {
        "id": 822,
        "title": "Could AI Ethical Anxiety, Perceived Ethical Risks and Ethical Awareness About AI Influence University Students’ Use of Generative AI Products? An Ethical Perspective",
        "authors": "Wenjuan Zhu, Lei Huang, Xinni Zhou, Xiaoya Li, Gaojun Shi, Jingxin Ying, Chaoyue Wang",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/10447318.2024.2323277"
    },
    {
        "id": 823,
        "title": "A phenomenological perspective on AI ethical failures: The case of facial recognition technology",
        "authors": "Yuni Wen, Matthias Holweg",
        "published": "2023-4-1",
        "citations": 1,
        "abstract": "AbstractAs more and more companies adopt artificial intelligence to increase the efficiency and effectiveness of their products and services, they expose themselves to ethical crises and potentially damaging public controversy associated with its use. Despite the prevalence of AI ethical problems, most companies are strategically unprepared to respond effectively to the public. This paper aims to advance our empirical understanding of company responses to AI ethical crises by focusing on the rise and fall of facial recognition technology. Specifically, through a comparative case study of how four big technology companies responded to public outcry over their facial recognition programs, we not only demonstrated the unfolding and consequences of public controversies over this new technology, but also identified and described four major types of company responses—Deflection, Improvement, Validation, and Pre-emption. These findings pave the way for future research on the management of controversial technology and the ethics of AI.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01648-7"
    },
    {
        "id": 824,
        "title": "Ethical AI: Proposal to bridge the gap in EU regulation on trustworthy AI and to support practical implementation of ethical perspectives",
        "authors": "Alexandra Prisznyák",
        "published": "2023",
        "citations": 0,
        "abstract": "In 2020, GPT-3 defined itself as a thinking robot. The history of AI development is identified with machines becoming increasingly intelligent, but behind it lies the human factor, the soaring of the human mind. However, the question of machine ethics is also a question of cultural ethics. Based on in-depth interviews conducted in seven industries, the author reveals that ethical considerations are not yet taken into account in the development of AI systems. To support practical implementation, the author identifies two shortcomings based on a comparative analysis of the EU’s AI Act and Ethical Guidelines for Trustworthy AI: (1) missing ethical sensitisation and training of AI system developers and supervisors; (2) suggested approaches to handling harmful feedback loops and decision-making biases. The author uses the philosophical and ethical heritage of 21 philosophers as a compass to propose solutions for the identified gaps and deficiencies of organisational integration.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33908/ef.2023.2.4"
    },
    {
        "id": 825,
        "title": "Corporate values, ethical leadership and social responsibility practices in mature SME’s in China: Basis for enhanced ethical leadership practices",
        "authors": "Lixia Tang",
        "published": "2023-8-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5861/ijrsm.2023.1053"
    },
    {
        "id": 826,
        "title": "Corporate values, ethical leadership and social responsibility practices in mature SME’s in China: Basis for enhanced ethical leadership practices",
        "authors": "Lixia Tang",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5861/ijrsm.2023.1102"
    },
    {
        "id": 827,
        "title": "Navigating Generative AI: The Teacher Librarian's Role in Cultivating Ethical and Critical Practices",
        "authors": "Kay Oddone, Kasey Garrison, Krystal Gagen-Spriggs",
        "published": "2023-12-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/24750158.2023.2289093"
    },
    {
        "id": 828,
        "title": "Ethical considerations in emotion recognition technologies: a review of the literature",
        "authors": "Amelia Katirai",
        "published": "2023-6-20",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00307-3"
    },
    {
        "id": 829,
        "title": "Using structured ethical techniques to facilitate reasoning in technology ethics",
        "authors": "Matt A. Murphy",
        "published": "2023-11-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00371-9"
    },
    {
        "id": 830,
        "title": "When things go wrong: the recall of AI systems as a last resort for ethical and lawful AI",
        "authors": "Alessio Tartaro",
        "published": "2023-8-30",
        "citations": 0,
        "abstract": "AbstractThis paper presents an initial exploration of the concept of AI system recall, primarily understood as a last resort when AI systems violate ethical norms, societal expectations, or legal obligations. The discussion is spurred by recent incidents involving notable AI systems, demonstrating that AI recalls can be a very real necessity. This study delves into the concept of product recall as traditionally understood in industry and explores its potential application to AI systems. Our analysis of this concept is centered around two prominent categories of recall drivers in the AI domain: ethical-social and legal considerations. In terms of ethical-social drivers, we apply the innovative notion of “moral Operational Design Domain”, suggesting AI systems should be recalled when they violate ethical principles and societal expectation. In addition, we also explore the recall of AI systems from a legal perspective, where the recently proposed AI Act provides regulatory measures for recalling AI systems that pose risks to health, safety, and fundamental rights. The paper also underscores the need for further research, especially around defining precise ethical and societal triggers for AI recalls, creating an efficient recall management framework for organizations, and reassessing the fit of traditional product recall models for AI systems within the AI Act's regulatory context. By probing these complex intersections between AI, ethics, and regulation, this work aims to contribute to the development of robust and responsible AI systems while maintaining readiness for failure scenarios.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00327-z"
    },
    {
        "id": 831,
        "title": "Ethical Issues Posed by ‘Generative-AI’ (G-AI) - Response strategies for ‘Good AI Society’",
        "authors": "Sunghee Yoo",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.37305/jkba.2023.06.24.1.1"
    },
    {
        "id": 832,
        "title": "The human role to guarantee an ethical AI in healthcare: a five-facts approach",
        "authors": "Raquel Iniesta",
        "published": "2023-10-25",
        "citations": 2,
        "abstract": "AbstractWith the emergence of AI systems to assist clinical decision-making, several ethical dilemmas are brought to the general attention. AI systems are claimed to be the solution for many high-skilled medical tasks where machines can potentially surpass human ability as for example in identifying normal and abnormal chest X-rays. However, there are also warns that AI tools could be the basis for a human replacement that can risk dehumanisation in medicine. In recent years, important proposals in the domain of AI ethics in healthcare have identified main ethical issues, as for example fairness, autonomy, transparency, and responsibility. The human warranty, which implies human evaluation of the AI procedures, has been described to lower the ethical risks. However, as relevant these works have been, translating principles into action has proved challenging as existing codes were mostly a description of principles. There is a great need to produce how-to proposals that are specific enough to be action-guiding. We present five human-focussed facts designed into a framework of human action for an ethical AI in healthcare. Through the factors, we examine the role of medical practitioners, patients, and developers in designing, implementing, and using AI in a responsible manner that preserves human dignity. The facts encompass a range of ethical concerns that were commonly found in relevant literature. Given that it is crucial to bring as many perspectives as possible to the field, this work contributes to translate principles into human action to guarantee an ethical AI in health.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00353-x"
    },
    {
        "id": 833,
        "title": "Ethical Considerations in ChatGPT AI",
        "authors": "Prof. Vivek Gupta, Ishika Bishwash, Rubina Dhital, Simren Sanjay, Anirudh Lodha, Deepesh M Jain",
        "published": "2024-3-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.55248/gengpi.5.0324.0877"
    },
    {
        "id": 834,
        "title": "Ethical Considerations in AI: Navigating Bias, Fairness, and Accountability",
        "authors": "",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.48047/resmil.v10i1.22"
    },
    {
        "id": 835,
        "title": "Review of “AI assurance: towards trustworthy, explainable, safe, and ethical AI” by Feras A. Batarseh and Laura J. Freeman, Academic Press, 2023",
        "authors": "Jialei Wang, Li Fu",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01802-1"
    },
    {
        "id": 836,
        "title": "Socialisation approach to AI value acquisition: enabling flexible ethical navigation with built-in receptiveness to social influence",
        "authors": "Joel Janhonen",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": "AbstractThis article describes an alternative starting point for embedding human values into artificial intelligence (AI) systems. As applications of AI become more versatile and entwined with society, an ever-wider spectrum of considerations must be incorporated into their decision-making. However, formulating less-tangible human values into mathematical algorithms appears incredibly challenging. This difficulty is understandable from a viewpoint that perceives human moral decisions to primarily stem from intuition and emotional dispositions, rather than logic or reason. Our innate normative judgements promote prosocial behaviours which enable collaboration within a shared environment. Individuals internalise the values and norms of their social context through socialisation. The complexity of the social environment makes it impractical to consistently apply logic to pick the best available action. This has compelled natural agents to develop mental shortcuts and rely on the collective moral wisdom of the social group. This work argues that the acquisition of human values cannot happen just through rational thinking, and hence, alternative approaches should be explored. Designing receptiveness to social signalling can provide context-flexible normative guidance in vastly different life tasks. This approach would approximate the human trajectory for value learning, which requires social ability. Artificial agents that imitate socialisation would prioritise conformity by minimising detected or expected disapproval while associating relative importance with acquired concepts. Sensitivity to direct social feedback would especially be useful for AI that possesses some embodied physical or virtual form. Work explores the necessary faculties for social norm enforcement and the ethical challenges of navigating based on the approval of others.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00372-8"
    },
    {
        "id": 837,
        "title": "Ethical AI does not have to be like finding a black cat in a dark room",
        "authors": "Apala Lahiri Chavan, Eric Schaffer",
        "published": "2023-5-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01661-w"
    },
    {
        "id": 838,
        "title": "From ethical AI frameworks to tools: a review of approaches",
        "authors": "Erich Prem",
        "published": "2023-8",
        "citations": 20,
        "abstract": "AbstractIn reaction to concerns about a broad range of potential ethical issues, dozens of proposals for addressing ethical aspects of artificial intelligence (AI) have been published. However, many of them are too abstract for being easily translated into concrete designs for AI systems. The various proposed ethical frameworks can be considered an instance of principlism that is similar to that found in medical ethics. Given their general nature, principles do not say how they should be applied in a particular context. Hence, a broad range of approaches, methods, and tools have been proposed for addressing ethical concerns of AI systems. This paper presents a systematic analysis of more than 100 frameworks, process models, and proposed remedies and tools for helping to make the necessary shift from principles to implementation, expanding on the work of Morley and colleagues. This analysis confirms a strong focus of proposed approaches on only a few ethical issues such as explicability, fairness, privacy, and accountability. These issues are often addressed with proposals for software and algorithms. Other, more general ethical issues are mainly addressed with conceptual frameworks, guidelines, or process models. This paper develops a structured list and definitions of approaches, presents a refined segmentation of the AI development process, and suggests areas that will require more attention from researchers and developers.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00258-9"
    },
    {
        "id": 839,
        "title": "Ethical Problems of Super-Massive Generative AI",
        "authors": "Sunyong Byun",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.46397/jaih.14.3"
    },
    {
        "id": 840,
        "title": "The EU AI Act: A Comprehensive Regulatory Framework for Ethical AI Development",
        "authors": "Sean Musch, Michael Borrelli, Charles Kerrigan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4549248"
    },
    {
        "id": 841,
        "title": "Ethical Uses of Artificial Intelligence AI",
        "authors": "Rasha Waheeb",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4507569"
    },
    {
        "id": 842,
        "title": "Stream: social data and knowledge collective intelligence platform for TRaining Ethical AI Models",
        "authors": "Yuwei Wang, Enmeng Lu, Zizhe Ruan, Yao Liang, Yi Zeng",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01851-6"
    },
    {
        "id": 843,
        "title": "Ethical considerations and policy interventions concerning the impact of generative AI tools in the economy and in society",
        "authors": "Mirko Farina, Xiao Yu, Andrea Lavazza",
        "published": "2024-1-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00405-2"
    },
    {
        "id": 844,
        "title": "Ethical Dimensions in Contemporary Medical Practices: A Systematic Review and Analysis of Diverse Perspectives",
        "authors": "Taj R",
        "published": "2023",
        "citations": 0,
        "abstract": "Objective: This systematic review and analysis aim to comprehensively explore diverse ethical perspectives within contemporary medical practices. Acknowledging the complexity of ethical considerations in medicine influenced by cultural, socio-economic, and legal factors, the objective is to synthesize insights from various studies and delve into key themes such as patient autonomy, informed consent, healthcare equity, and the ethical implications of emerging technologies. Methodology: Adhering to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines 2020, this analysis systematically reviewed scholarly articles focusing on ethical considerations within modern medical practices from 2020 to 2023. A thorough screening process, based on specific Medical Subject Headings (MeSH) terms, was conducted in major databases (PubMed, Scopus, Web of Knowledge, and Google Scholar). Eleven relevant studies were included, representing diverse perspectives and ethical frameworks. Result: The systematic study selection process identified 11 relevant studies from an initial pool of 297 records. These studies covered a range of topics, including parental decision-making for adolescents with mental health issues, the legalization of medical cannabis, challenges in patient care during the COVID-19 pandemic and medical education ethics. The included studies were subjected to a meticulous evaluation of their characteristics, outcomes, and limitations. The findings contribute valuable insights into the multifaceted ethical dimensions of contemporary medical practices. Conclusion: This systematic review and analysis provide a comprehensive overview of diverse ethical perspectives inherent in contemporary medical practices. While recognizing the complexity of medical ethics, influenced by various factors, the study identifies patterns, gaps and divergent viewpoints within the selected studies. The analysis aims to inform practitioners, policymakers, and scholars engaged in ethical decision-making in healthcare, fostering a more informed and ethically robust approach to modern medical practices. Despite the limitations in some studies, the findings contribute to the ongoing discourse on medical ethics and highlight the need for further research and dialogue to address evolving ethical challenges in healthcare.",
        "keywords": "",
        "link": "http://dx.doi.org/10.23880/abca-16000264"
    },
    {
        "id": 845,
        "title": "Navigating the Ethical Landscape: Considerations in Implementing AI-ML Systems in Human Resources",
        "authors": "Sunil Basnet",
        "published": "2024-3-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.55248/gengpi.5.0324.0755"
    },
    {
        "id": 846,
        "title": "Ethical climate in business: The state of ethical climate, standards and practices in business organisations in Mauritius",
        "authors": "Oumeshsingh Sookdawoor",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4475612"
    },
    {
        "id": 847,
        "title": "Let us make man in our image-a Jewish ethical perspective on creating conscious robots",
        "authors": "Mois Navon",
        "published": "2023-9-12",
        "citations": 1,
        "abstract": "AbstractThe dream of making conscious humanoid robots is one that has long tantalized humanity, yet today it seems closer than ever before. Assuming that science can make it happen, the question becomes: should we make it happen? Is it morally permissible to create synthetic beings with consciousness? While a consequentialist approach may seem logical, attempting to assess the potential positive and negative consequences of such a revolutionary technology is highly speculative and raises more questions than it answers. Accordingly, some turn to ancient and not-so-ancient stories of “automata” for direction. Of the many automata conjured throughout history, if not in matter then in mind, the Golem stands out as one of the most persistent paradigms employed to discuss technology in general and technologically engendered life forms in particular. In this essay, I introduce a novel reading of the Golem paradigm to argue not from consequentialism, but from a deep-seated two-thousand-year-old tradition, the ethical implications of which are wholly deontological.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00328-y"
    },
    {
        "id": 848,
        "title": "Exploring the Effect of AI Assistance on Human Ethical Decisions",
        "authors": "Saumik Narayanan",
        "published": "2023-8-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3600211.3604750"
    },
    {
        "id": 849,
        "title": "Unveiling the ethical positions of conversational AIs: a study on OpenAI’s ChatGPT and Google’s Bard",
        "authors": "Quintin P. McGrath",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "AbstractIn an era where conversational AIs (CAIs) like OpenAI’s ChatGPT and Google's Bard are becoming integral to daily life, understanding their ethical positions is paramount. This research delves into the expressed moral values of these CAIs, exploring how their pre-training influences their ethical stances. The study aims to assess the articulated ethical positions of ChatGPT and Bard, uncovering whether these systems align with particular moral values. By understanding their ethical positions, the research seeks to provide insights into how these CAIs might respond to prompts and guide users in their selection and utilization. Utilizing O’Boyle and Forsyth’s Ethical Position Questionnaire (EPQ-5), the research evaluated the CAIs’ levels of idealism and relativism. The study also involved a third CAI, Anthropic’s Claude and an online human panel, to analyze the reasoning behind the responses, providing a more nuanced understanding of the ethical positions. The initial findings revealed that ChatGPT aligns more with an ‘absolutist’ position, endorsing strict adherence to moral principles, while Bard leans towards a ‘situationist’ stance, valuing flexibility and situational considerations. However, further analysis by Claude and humans suggested a more complex categorization, with ChatGPT fitting the 'exceptionist' categorization and Bard aligning with ‘absolutism.’ The research underscores the significance of recognizing the trained-in ethical positions of CAIs, as they are not neutral but reflect particular ethical leanings. Understanding these positions is vital for interpreting CAI outputs and using these systems effectively and ethically. The study calls for further exploration into how these ethical positions might influence real-world applications of CAIs.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00433-6"
    },
    {
        "id": 850,
        "title": "Ethical AI is Not about AI",
        "authors": "Deborah G. Johnson, Mario Verdicchio",
        "published": "2023-2",
        "citations": 7,
        "abstract": "The equation Ethics + AI = Ethical AI is questionable.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3576932"
    },
    {
        "id": 851,
        "title": "Image synthesis from an ethical perspective",
        "authors": "Oliver Bendel",
        "published": "2023-9-27",
        "citations": 0,
        "abstract": "AbstractGenerative AI has gained a lot of attention in society, business, and science. This trend has increased since 2018, and the big breakthrough came in 2022. In particular, AI-based text and image generators are now widely used. This raises a variety of ethical issues. The present paper first gives an introduction to generative AI and then to applied ethics in this context. Three specific image generators are presented: DALL-E 2, Stable Diffusion, and Midjourney. The author goes into technical details and basic principles, and compares their similarities and differences. This is followed by an ethical discussion. The paper addresses not only risks, but opportunities for generative AI. A summary with an outlook rounds off the article.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01780-4"
    },
    {
        "id": 852,
        "title": "The role of ChatGPT in disrupting concepts, changing values, and challenging ethical norms: a qualitative study",
        "authors": "Pouyan Esmaeilzadeh",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00338-w"
    },
    {
        "id": 853,
        "title": "Generative AI can fabricate advanced scientific visualizations: ethical implications and strategic mitigation framework",
        "authors": "Jeff J. H. Kim, Richard S. Um, James W. Y. Lee, Olusola Ajilore",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00439-0"
    },
    {
        "id": 854,
        "title": "A context-specific analysis of ethical principles relevant for AI-assisted decision-making in health care",
        "authors": "Larissa Schlicht, Miriam Räker",
        "published": "2023-7-24",
        "citations": 1,
        "abstract": "AbstractArtificial intelligence (AI)-assisted technologies may exert a profound impact on social structures and practices in care contexts. Our study aimed to complement ethical principles considered relevant for the design of AI-assisted technology in health care with a context-specific conceptualization of the principles from the perspectives of individuals potentially affected by the implementation of AI technologies in nursing care. We conducted scenario-based semistructured interviews focusing on situations involving moral decision-making occurring in everyday nursing practice with nurses (N = 15) and care recipients (N = 13) working, respectively, living in long-term care facilities in Germany. First, we analyzed participants’ concepts of the ethical principles beneficence, respect for autonomy and justice. Second, we investigated participants’ expectations regarding the actualization of these concepts within the context of AI-assisted decision-making. The results underscore the importance of a context-specific conceptualization of ethical principles for overcoming epistemic uncertainty regarding the risks and opportunities associated with the (non)fulfillment of these ethical principles. Moreover, our findings provide indications regarding which concepts of the investigated ethical principles ought to receive extra attention when designing AI technologies to ensure that these technologies incorporate the moral interests of stakeholders in the care sector.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00324-2"
    },
    {
        "id": 855,
        "title": "Ethical and political consumption: an integrated typology of practices",
        "authors": "Margarita Komninou",
        "published": "2023-5-22",
        "citations": 0,
        "abstract": "Addressing the diversity of consumer practices requires perceiving and measuring ethical and political consumerism beyond acts of buycotting and boycotting. By viewing consumption as limited to ‘purchasing’ and ‘shopping’, the agency of the consumer is bound to certain rules and mechanisms of the market, raising questions on the degree of alternativeness of each practice. Arbitrarily ascribing a strictly ‘noneconomic’ motivation behind the ‘ethical’ and ‘political’ framings of consumption results in excluding private (economic) troubles from the public sphere (ignoring thus their political nature). This conceptual article presents a novel analytical tool that maps consumer practices according to two critical conditions within which practices are performed: monetary transaction and legality. An example of how the proposed typology can be applied in the lodging sector demonstrates the typology’s ability to appreciate the diversity found in consumer practices, while also commenting on their degrees of alterity. Overall, the article calls for a reconsideration of the narrow repertoire of consumer action that is often associated with ethical and political consumerism, if we want to understand consumption as an “arena of politics” and a form of political participation in a more democratic manner (where every person gets to “vote”).\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.32388/dlhwlk"
    },
    {
        "id": 856,
        "title": "Ethical Reflections on AI for Cybersecurity: Building Trust",
        "authors": "Joseph Oloyede",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4733563"
    },
    {
        "id": 857,
        "title": "How to Bridge the Gap between AI Ethical Guidelines and Responsible Ethical Conduct",
        "authors": "Uma G. Gupta",
        "published": "2023-5-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.26573/2021.17.1.4"
    },
    {
        "id": 858,
        "title": "Artificial Intelligence (AI) in Islamic Ethics: Towards Pluralist Ethical Benchmarking for AI",
        "authors": "Ezieddin Elmahjub",
        "published": "2023-12",
        "citations": 2,
        "abstract": "AbstractThis paper explores artificial intelligence (AI) ethics from an Islamic perspective at a critical time for AI ethical norm-setting. It advocates for a pluralist approach to ethical AI benchmarking. As rapid advancements in AI technologies pose challenges surrounding autonomy, privacy, fairness, and transparency, the prevailing ethical discourse has been predominantly Western or Eurocentric. To address this imbalance, this paper delves into the Islamic ethical traditions to develop a framework that contributes to the global debate on optimal norm setting for designing and using AI technologies.The paper outlines Islamic parameters for ethical values and moral actions in the context of AI's ethical uncertainties. It emphasizes the significance of both textual and non-textual Islamic sources in addressing these uncertainties while placing a strong emphasis on the notion of \"good\" or \"maṣlaḥa\" as a normative guide for AI's ethical evaluation. Defining maṣlaḥa as an ethical state of affairs in harmony with divine will, the paper highlights the coexistence of two interpretations of maṣlaḥa: welfarist/utility-based and duty-based. Islamic jurisprudence allows for arguments supporting ethical choices that prioritize building the technical infrastructure for AI to maximize utility. Conversely, it also supports choices that reject consequential utility calculations as the sole measure of value in determining ethical responses to AI advancements.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13347-023-00668-x"
    },
    {
        "id": 859,
        "title": "Encountering Artificial Intelligence: Ethical and Anthropological Investigations",
        "authors": " ",
        "published": "2023-12-14",
        "citations": 0,
        "abstract": "What does it mean to consider the world of AI through a Christian lens? Rapid developments in AI continue to reshape society, raising new ethical questions and challenging our understanding of the human person. Encountering Artificial Intelligence draws on Pope Francis’ discussion of a culture of encounter and broader themes in Catholic social thought in order to examine how current AI applications affect human relationships in various social spheres and offers concrete recommendations for better implementation. The document also explores questions regarding personhood, consciousness, and the kinds of relationships humans might have with even the most advanced AI. Through these discussions, the document investigates the theoretical and practical challenges to interpersonal encounter raised by the age of AI. Cover image credit: The cover image for Encountering Artificial Intelligence: Ethical and Anthropological Investigations was created by Jordan Wales using Dall-E and the prompt “a sibyl conjures a deep neural network, oil on canvas by Raphael.”",
        "keywords": "",
        "link": "http://dx.doi.org/10.55476/001c.91230"
    },
    {
        "id": 860,
        "title": "Marketing with ChatGPT: Navigating the Ethical Terrain of GPT-Based Chatbot Technology",
        "authors": "Pablo Rivas, Liang Zhao",
        "published": "2023-4-10",
        "citations": 45,
        "abstract": "ChatGPT is an AI-powered chatbot platform that enables human users to converse with machines. It utilizes natural language processing and machine learning algorithms, transforming how people interact with AI technology. ChatGPT offers significant advantages over previous similar tools, and its potential for application in various fields has generated attention and anticipation. However, some experts are wary of ChatGPT, citing ethical implications. Therefore, this paper shows that ChatGPT has significant potential to transform marketing and shape its future if certain ethical considerations are taken into account. First, we argue that ChatGPT-based tools can help marketers create content faster and potentially with quality similar to human content creators. It can also assist marketers in conducting more efficient research and understanding customers better, automating customer service, and improving efficiency. Then we discuss ethical implications and potential risks for marketers, consumers, and other stakeholders, that are essential for ChatGPT-based marketing; doing so can help revolutionize marketing while avoiding potential harm to stakeholders.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ai4020019"
    },
    {
        "id": 861,
        "title": "Commentary on Artificial Intelligence (AI) in Islamic Ethics: Towards Pluralist Ethical Benchmarking for AI",
        "authors": "Amana Raquib",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13347-023-00677-w"
    },
    {
        "id": 862,
        "title": "E-coaching systems and social justice: ethical concerns about inequality, coercion, and stigmatization",
        "authors": "B. A. Kamphorst, J. H. Anderson",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "AbstractPoor self-regulation has been linked to various behaviors that contribute to pressing societal issues, including rising household debt, inefficient use of sustainable resources, and increasing healthcare demands. In light of this observation, the prospect of individuals receiving automated, tailored support by “e-coaching systems” to scaffold and improve their self-regulation is thought to hold promise for making society-wide progress in addressing such issues. Though there may be legitimate reasons for promoting the use of such systems, and individuals might welcome the support, our aim in the present article is to contribute to the ethics of e-coaching by showing how societal pressures towards the widespread adoption of automated e-coaching systems raise concerns in relation to three distinct aspects of social justice. We argue that societal inequalities may be introduced or exacerbated by (1) unequal access to the technologies, (2) unequally distributed restrictions to liberty and subjection to coercion, and (3) the potentially disparate impact of the use of e-coaching technologies on (self-)stigmatizing perceptions of competence. The article offers a research agenda for studying and addressing these concerns.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00424-7"
    },
    {
        "id": 863,
        "title": "The Ethical and Social Implications of Using AI in Healthcare - A Literature Review",
        "authors": "Suyash Bhogawar, Siddhartha Nuthakki, Sanju Mannumadam Venugopal, Sreeram Mullankandy",
        "published": "2023-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21275/sr231116135559"
    },
    {
        "id": 864,
        "title": "ETHICAL CONSIDERATIONS IN AI: NAVIGATING BIAS, FAIRNESS, AND ACCOUNTABILITY (2020)",
        "authors": "",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.48047/jcr.07.03.375"
    },
    {
        "id": 865,
        "title": "On educating ethics in the AI era: why business schools need to move beyond digital upskilling, towards ethical upskilling",
        "authors": "David De Cremer, Devesh Narayanan",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00306-4"
    },
    {
        "id": 866,
        "title": "A Case Study on AI Engineering Practices: Developing an Autonomous Stock Trading System",
        "authors": "Marcel Grote, Justus Bogner",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cain58948.2023.00032"
    },
    {
        "id": 867,
        "title": "Guidance for researchers and peer-reviewers on the ethical use of Large Language Models (LLMs) in scientific research workflows",
        "authors": "Ryan Watkins",
        "published": "2023-5-16",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00294-5"
    },
    {
        "id": 868,
        "title": "The ethical ambiguity of AI data enrichment: Measuring gaps in research ethics norms and practices",
        "authors": "Will Hawkins, Brent Mittelstadt",
        "published": "2023-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3593013.3593995"
    },
    {
        "id": 869,
        "title": "Exploring the Human-AI Nexus: A Friendly Dispute Between Second-Order Cybernetical Ethical Thinking and Questions of AI Ethics",
        "authors": "Dietmar Koering",
        "published": "2023-5-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.58695/ec.4"
    },
    {
        "id": 870,
        "title": "Trustworthy AI: A Fuzzy-Multiple Method for Evaluating Ethical Principles in AI Regulations",
        "authors": "Oksana Adamyk, Oksana Chereshnyuk, Bogdan Adamyk, Serhii Rylieiev",
        "published": "2023-9-21",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/acit58437.2023.10275505"
    },
    {
        "id": 871,
        "title": "In defense of ethical guidelines",
        "authors": "Björn Lundgren",
        "published": "2023-8",
        "citations": 1,
        "abstract": "AbstractRecently, Luke Munn attacked “AI ethics” generally, or guidelines, principles, codes of ethics, ethical frameworks. In particular, he argued that ethical guidelines are useless. Here I respond to this critique, arguing that Munn’s criticism is mostly unfair and misguided, and that his own proposal is already implemented in various guidelines.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-022-00244-7"
    },
    {
        "id": 872,
        "title": "Artificial Intelligence (AI) Trust Framework and Maturity Model: Applying an Entropy Lens to Improve Security, Privacy, and Ethical AI",
        "authors": "Michael Mylrea, Nikki Robinson",
        "published": "2023-10-9",
        "citations": 2,
        "abstract": "Recent advancements in artificial intelligence (AI) technology have raised concerns about the ethical, moral, and legal safeguards. There is a pressing need to improve metrics for assessing security and privacy of AI systems and to manage AI technology in a more ethical manner. To address these challenges, an AI Trust Framework and Maturity Model is proposed to enhance trust in the design and management of AI systems. Trust in AI involves an agreed-upon understanding between humans and machines about system performance. The framework utilizes an “entropy lens” to root the study in information theory and enhance transparency and trust in “black box” AI systems, which lack ethical guardrails. High entropy in AI systems can decrease human trust, particularly in uncertain and competitive environments. The research draws inspiration from entropy studies to improve trust and performance in autonomous human–machine teams and systems, including interconnected elements in hierarchical systems. Applying this lens to improve trust in AI also highlights new opportunities to optimize performance in teams. Two use cases are described to validate the AI framework’s ability to measure trust in the design and management of AI systems.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/e25101429"
    },
    {
        "id": 873,
        "title": "Review of: \"Ethical and political consumption: an integrated typology of practices\"",
        "authors": "Mahsa Ghaffari",
        "published": "2023-6-8",
        "citations": 0,
        "abstract": "",
        "keywords": "",
        "link": "http://dx.doi.org/10.32388/79g8jc"
    },
    {
        "id": 874,
        "title": "AI Health Ethical Review: A Value Design Methodology",
        "authors": "Elizaveta A. Karpova",
        "published": "2023",
        "citations": 0,
        "abstract": "As our world becomes more dependent on data, algorithms are increasingly being used to make informed decisions in areas ranging from finance to HR. The healthcare sector is no exception, and artificial intelligence systems are becoming more and more widespread in this area. While AI can help us make more informed and efficient decisions, it also presents many moral and ethical challenges. One of the biggest issues is the issue of trust. When &quot;machine&quot; replaces &quot;human&quot; decision making, it can be difficult for patients and healthcare professionals to trust the outcome. In addition, the &quot;black box&quot; mechanisms in artificial intelligence systems make it unclear who is responsible for the decisions made, which can lead to ethical dilemmas. In addition, there is a risk of emotional frustration for patients and healthcare professionals, as AI may not be able to provide the kind of human touch that is often needed in healthcare. Despite increased attention to these issues in recent years, technical solutions to these complex moral and ethical issues are often developed without regard to the social context and opinions of the advocates affected by the technology. In addition, calls for more ethical and socially responsible AI often focus on basic legal principles such as &quot;transparency&quot; and &quot;responsibility&quot; and leave out the much more problematic area of human values. To solve this problem, the article proposes a &quot;value-sensitive&quot; approach to the development of AI, which can help translate basic human rights and values into context-sensitive requirements for AI algorithms. This approach can help create a route from human values to clear and understandable requirements for AI design. It can also help overcome ethical issues that hinder the responsible implementation of AI in healthcare and everyday life.",
        "keywords": "",
        "link": "http://dx.doi.org/10.31857/s023620070026109-6"
    },
    {
        "id": 875,
        "title": "The question of \"Mind-sets\" and AI: Cultural origins and limits of the current AI  Ethical AIs and Cultural Pluralism",
        "authors": "Badrudin Amershi",
        "published": "2023-1-4",
        "citations": 0,
        "abstract": "The current process of scientific and technological development is the outcome of the epochal Cultural Revolution in the West: i.e. the emergence of the Age of Enlightenment and its pursuit of \"rationality\". Today, \"rationality\" combined with \"logic\" has mutated into a \"strong belief\" in the power of rationality and \"computational processes\" as a 'safer' and only way to acquire knowledge. This is the main driving force behind the emergence of AI. At the core of this mind-set is the fundamental duality of the observer and the observed. After the imperial expansion of Western Europe – in alliance with religion, its previous foe (“Christianity”) – this world-view became the globally dominant mind-set. The paper explores the dominant narrative of rationality and reason of Western science, and seeks an alternative world of cultural diversity.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30564/aia.v4i2.5156"
    },
    {
        "id": 876,
        "title": "Social and ethical challenges of the metaverse",
        "authors": "Richard Benjamins, Yaiza Rubio Viñuela, Chema Alonso",
        "published": "2023-8",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00278-5"
    },
    {
        "id": 877,
        "title": "AI powered Social Communication: a Qualitative Investigation in to Social and Ethical Concerns",
        "authors": "Vikrant Yadav",
        "published": "2024",
        "citations": 0,
        "abstract": "Social media has become an integral part of modern day lifestyle of new generation. The social media penetration in day to affairs is to such an extent that, there hardly is any day that goes without having any social media interaction. Although an easy way of distant communication and entertainment are the driving force behind emergence of social media platforms, in recent times it has been used to fulfil the undesired motives. Many instances of fake news, bias, spreading of hatred, deep fakes have been noticed. This paper is an attempt to conduct a conceptual analysis of AI technology alongwith the literary survey of impact of AI on social communication. Based on the qualitative literary survey, the author has proposed some recommendations, some of which includes, inclusion of social media ethics in school curriculum, international norms for use of social media platform etc.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54941/ahfe1004592"
    },
    {
        "id": 878,
        "title": "The rise of artificial intelligence in libraries: the ethical and equitable methodologies, and prospects for empowering library users",
        "authors": "James Oluwaseyi Hodonu-Wusu",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00432-7"
    },
    {
        "id": 879,
        "title": "Formalizing ethical principles within AI systems: experts’ opinions on why (not) and how to do it",
        "authors": "Franziska Poszler, Edy Portmann, Christoph Lütge",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "AbstractAI systems are increasingly put into contexts where computed decisions must be guided by ethical considerations. To develop ethically grounded algorithms and technologies, scholars have suggested computational ethics as an essential frontier, which aims to translate ethical principles into computer code. However, computational ethics has received little attention in academic literature so far, with existing work mainly focusing on its technical implementation, while many open questions concerning its (societal and ethical) implications still need to be resolved. Therefore, in this study, we interviewed 12 experts from philosophy, AI and cognitive sciences to shed light on computational ethics beyond a technical perspective. Findings suggest that indicated supporting and opposing arguments can be clustered into pragmatic/practical, societal and epistemic reasons, all of which need to be contemplated when engaging in computational ethics and developing resulting artificial moral agents. Furthermore, the mentioned recommendations for companies’ technological design and development, for industry’s governance measures and academia’s research endeavors are recapitulated and summarized in a holistic framework that aims to facilitate a reflected implementation of ‘ethics in and by design’ in the future.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00425-6"
    },
    {
        "id": 880,
        "title": "Ethical concerns around privacy and data security in AI health monitoring for Parkinson’s disease: insights from patients, family members, and healthcare professionals",
        "authors": "Itai Bavli, Anita Ho, Ravneet Mahal, Martin J. McKeown",
        "published": "2024-1-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01843-6"
    },
    {
        "id": 881,
        "title": "Ethical Behaviourism and the Moral Status of AI Robots",
        "authors": "Sang-deuk Kim",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.20293/jokps.2023.167.59"
    },
    {
        "id": 882,
        "title": "Stepping Above the Generative Ai Ethical Floor: The Sky's the Limit",
        "authors": "Joseph Regalia",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4746753"
    },
    {
        "id": 883,
        "title": "The Ethics of Artificial Intelligence: Review of Ethical Machines: Your Concise Guide to Totally Unbiased, Transparent, and Respectful AI by R. Blackman; Ethics of Artificial Intelligence: Case Studies and Options for Addressing Ethical Challenges by B.C. Stahl, D. Schroeder, and R. Rodrigues; and AI Ethics by M. Coeckelbergh",
        "authors": "Christian Goglin",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10551-023-05538-2"
    },
    {
        "id": 884,
        "title": "Ever Heard of Ethical AI? Investigating the Salience of Ethical AI Issues among the German Population",
        "authors": "Kimon Kieslich, Marco Lünich, Pero Došenović",
        "published": "2023-2-21",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/10447318.2023.2178612"
    },
    {
        "id": 885,
        "title": "Traversing the Ethical Landscape of Data Scraping for AI",
        "authors": "Jayasankar Jayachandran, Vijay Arni",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4666354"
    },
    {
        "id": 886,
        "title": "Ethical Concerns about Using AI-Generated Text in Scientific Research",
        "authors": "Zuheir N. Khlaif",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4387984"
    },
    {
        "id": 887,
        "title": "Ethical Governance of AI: An Integrated Approach via Human-in-the-Loop Machine Learning",
        "authors": "Ximeng Chen",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/cmsf2023008029"
    },
    {
        "id": 888,
        "title": "Economic, Societal, Legal, and Ethical Considerations for Large Language Models",
        "authors": "Jay Lofstead",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/transai60598.2023.00049"
    },
    {
        "id": 889,
        "title": "Ethical Considerations in the Transformative Role of AI Chatbots in Education",
        "authors": "Patrick Ryan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4623611"
    },
    {
        "id": 890,
        "title": "Exploring The Use of AI In Legal Decision Making: Benefits and Ethical Implications",
        "authors": "Sreelatha A, Gyandeep Choudhary",
        "published": "2023-9",
        "citations": 0,
        "abstract": "There has been a lot of discussion about how to incorporate AI into legal decision-making. The purpose of this research is to investigate the potential positive outcomes and potential negative consequences of using artificial intelligence in the legal system. A thorough understanding of the potential benefits and ethical considerations tied to the use of AI in legal decision-making can be attained through a thorough review of relevant literature, the formulation of research inquiries, and the establishment of research objectives.",
        "keywords": "",
        "link": "http://dx.doi.org/10.57029/scheel4"
    },
    {
        "id": 891,
        "title": "Evaluating the acceptability of ethical recommendations in industry 4.0: an ethics by design approach",
        "authors": "Marc M. Anderson, Karën Fort",
        "published": "2024-1-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01834-7"
    },
    {
        "id": 892,
        "title": "The State of Ethical Practices in Accounting: How Greed Has Inhibited Accounting Leaders From Creating an Ethical Organizational Culture",
        "authors": "",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.33423/jlae.v20i2.6170"
    },
    {
        "id": 893,
        "title": "Learning from Buddhist Teachings and Ethical Practices in Qualitative Research",
        "authors": "Pei-Jung Li",
        "published": "2023-2-1",
        "citations": 0,
        "abstract": "This paper aims at conceptualizing research ethics in qualitative research with Buddhist teachings. As a Buddhist, I first introduce how Buddhism came to be central in my life and eventually influenced me as a qualitative researcher. I exemplify how the concepts of all-beings-are-equal, karma, the five precepts, and repentance might inspire a qualitative practice that centers ethics and informs a researcher’s interactions with participants. I suggest that researchers not only work on reflecting on their body (actions), speech (talk), and mind (thoughts) but more importantly, move beyond just reflection and reflexivity to facing and resolving “unwholesome” moments that may arise during the research process. I thus demonstrate how to repent in regard to one’s research-related actions, speech, and thoughts, with a particular focus on doing-no-harm and truthfulness. To illustrate, I offer an example from my own research that highlights how Buddhist teachings might be relevant in practice. My arguments aim to contribute to the literature on research ethics by introducing repentance by the researchers, alongside the Buddhist precepts, as central to ethical qualitative research practice.",
        "keywords": "",
        "link": "http://dx.doi.org/10.46743/2160-3715/2023.5772"
    },
    {
        "id": 894,
        "title": "Artificial Intelligence (AI) Influence in Law: Balancing Technological Advancements with Ethical Considerations",
        "authors": "Ammar Zafar",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4656578"
    },
    {
        "id": 895,
        "title": "INTEGRATING AI ETHICAL-MORAL STANDARDS: AI TYPES AND THE ROLE OF THE CONSTRUAL LEVEL OF ACCEPTANCE",
        "authors": "Dan Jin,  , Heejin Lim",
        "published": "2023-7-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.15444/gmc2023.07.01.01"
    },
    {
        "id": 896,
        "title": "Increasing Safety in Highways Transit Systems by Using Ethical Artificial Intelligence AI",
        "authors": "Rasha Waheeb",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4573277"
    },
    {
        "id": 897,
        "title": "Ethical and Legal Challenges of AI in Marketing: An Exploration of Solutions",
        "authors": "Dinesh Kumar",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4396132"
    },
    {
        "id": 898,
        "title": "Exploring business students’ views of the use of generative AI in assignment writing",
        "authors": "Duncan Murray, Karen Williams",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "\nThe rise of generative AI, particularly over the past few years, has raised notable issues about its use. This has been possibly most pronounced in academia, where there has been strong debate on the potential value of generative AI to augment learning outcomes versus the potential for academic dishonesty and devalued education. Whilst some papers have looked at students’ perspectives on the use of generative AI, there has been less focus exploring through what ethical perspectives or frames students see using generative AI in their tertiary education.\n\n\nWe interviewed and conducted focus groups and interviews with students enrolled in an Australian university business school, to explore the ethical frames through which they saw the use of generative AI. Focussing on three specific perspectives: Deontological, Consequentialism and Virtue Ethics, it emerged that no single perspective dominated, with students having a complex mix and latticework of ethical perspectives on its use, even within the same individual. We explore some potential implications for practice that emerged from the data, one of which is the role of the academic as moral exemplar. \n",
        "keywords": "",
        "link": "http://dx.doi.org/10.14742/apubs.2023.662"
    },
    {
        "id": 899,
        "title": "Exploring differences in ethical decision-making processes between humans and ChatGPT-3 model: a study of trade-offs",
        "authors": "Umair Rehman, Farkhund Iqbal, Muhammad Umair Shah",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00335-z"
    },
    {
        "id": 900,
        "title": "ETHICAL FRONTIERS IN AI-DRIVEN STUDENT DEVELOPMENT: NAVIGATING NEW REALMS OF ENGAGEMENT AND SUPPORT",
        "authors": "Henry Mason",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21125/inted.2024.1648"
    }
]