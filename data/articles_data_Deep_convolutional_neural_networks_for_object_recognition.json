[
    {
        "id": 10505,
        "title": "Deep convolutional neural networks are not mechanistic explanations of object recognition",
        "authors": "Bojana Grujičić",
        "published": "2024-1-12",
        "citations": 0,
        "abstract": "AbstractGiven the extent of using deep convolutional neural networks to model the mechanism of object recognition, it becomes important to analyse the evidence of their similarity and the explanatory potential of these models. I focus on one frequent method of their comparison—representational similarity analysis, and I argue, first, that it underdetermines these models as how-actually mechanistic explanations. This happens because different similarity measures in this framework pick out different mechanisms across DCNNs and the brain in order to correspond them, and there is no arbitration between them in terms of relevance for object recognition. Second, the reason similarity measures are underdetermining to a large degree stems from the highly idealised nature of these models, which undermines their status as how-possibly mechanistic explanatory models of object recognition as well. Thus, building models with more theoretical consideration and choosing relevant similarity measures may bring us closer to the goal of mechanistic explanation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11229-023-04461-3"
    },
    {
        "id": 10506,
        "title": "Utilizing Convolutional Neural Networks for Object Recognition with Image Filtering and Edge Detection in Deep Learning",
        "authors": "J. Shajeena, Vinay Kumar Jarugula, A. Bindhu, S. Kayalvizhi",
        "published": "2023-12-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icrtac59277.2023.10480796"
    },
    {
        "id": 10507,
        "title": "Automated labeling of training data for improved object detection in traffic videos by fine-tuned deep convolutional neural networks",
        "authors": "Iván García-Aguilar, Jorge García-González, Rafael Marcos Luque-Baena, Ezequiel López-Rubio",
        "published": "2023-3",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patrec.2023.01.015"
    },
    {
        "id": 10508,
        "title": "Evaluating Compact Convolutional Neural Networks for Object Recognition Using Sensor Data on Resource-Constrained Devices",
        "authors": "Icaro Camelo, Ana-Maria Cretu",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ecsa-10-16202"
    },
    {
        "id": 10509,
        "title": "Image quality and object detection performance of convolutional neural networks",
        "authors": "Austin C. Bergstrom, David W. Messinger",
        "published": "2023-6-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2663779"
    },
    {
        "id": 10510,
        "title": "An Efficient Traffic Sign Classification and Recognition with Deep Convolutional Neural Networks",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.55487/p9zr8384"
    },
    {
        "id": 10511,
        "title": "Advances in Convolutional Neural Networks for Object Detection and Recognition",
        "authors": "Dhananjay Kumar Yadav, Neeraj Kumari, Syed Harron",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470695"
    },
    {
        "id": 10512,
        "title": "Implementation of an Object Detection System using Convolutional Neural Networks",
        "authors": "P. Divakar, V. Pavani",
        "published": "2024-3-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.55248/gengpi.5.0324.0769"
    },
    {
        "id": 10513,
        "title": "Deep Convolutional Neural Network Recognition of Hand Gestures",
        "authors": "Neeraj Kumar,  A.Rajitha,  G.Lohitha",
        "published": "2023",
        "citations": 0,
        "abstract": "Hand gestures are becoming more common in HCI. No matter the project, the majority of the task will involve interaction with other parts of the body, the environment, etc. We demonstrate how to locate a user’s hand and movements, apply this information in a home situation, and interact with the system in this work. Using this information is also discussed. Sign language communicates visually using hand motions. Hand gestures may help hearing-impaired people communicate. Processing hand gestures lets people use their hands to communicate. Words can be made by combining signs and digits on the palms of one’s hands. Sightbased and glove-based hand motions are used nowadays. In this paper, we introduce deep convolutional neural networks for image classification and demonstrate their utility in hand gesture classification. In particular, we examine how these networks can recognise hand motions. Deep convolutional hand gesture can uncover many hand motions. Hand gestures can express many emotions. Time is needed to comprehend the hand motions Using a convolutional neural network to separate items or photographs saves time and effort. Hand actions demand more time to assess. In this case, the deep convolutional neural network speeds up the procedure. The system’s precision, sensitivity, and accuracy will improve with deep CNN. CNN, which divides the dataset into chunks, can be utilised to get high accuracy, specificity, and sensitivity from the dataset. Once the camera transmits the hand gesture image, the system will stop.",
        "keywords": "",
        "link": "http://dx.doi.org/10.58599/ijsmien.2023.1302"
    },
    {
        "id": 10514,
        "title": "Application of Deep Convolutional Neural Networks in Image Recognition and Classification in Library Management",
        "authors": "Songyun Wang",
        "published": "2023-6-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11277-023-10571-5"
    },
    {
        "id": 10515,
        "title": "Speech to Text Recognition for Videogame Controlling with Convolutional Neural Networks",
        "authors": "Joaquin Aguirre-Peralta, Marek Rivas-Zavala, Willy Ugarte",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011782900003411"
    },
    {
        "id": 10516,
        "title": "Convolutional Neural Networks for Object Detection and Recognition",
        "authors": "Ms. Archana Karne, Mr. RadhaKrishna Karne, Mr. V. Karthik Kumar, Dr. A. Arunkumar",
        "published": "2023-2-4",
        "citations": 0,
        "abstract": "One of the essential technologies in the fields of target extraction, pattern recognition, and motion measurement is moving object detection. Finding moving objects or a number of moving objects across a series of frames is called object tracking. Basically, object tracking is a difficult task. Unexpected changes in the surroundings, an item's mobility, noise, etc., might make it difficult to follow an object. Different tracking methods have been developed to solve these issues. This paper discusses a number of object tracking and detection approaches. The major methods for identifying objects in images will be discussed in this paper. Recent years have seen impressive advancements in fields like pattern recognition and machine learning, both of which use convolutional neural networks (CNNs). It is mostly caused by graphics processing units'(GPUs) enhanced parallel processing capacity. This article describes many kinds of object classification, object racking, and object detection techniques. Our results showed that the suggested algorithm can detect moving objects reliably and efficiently in a variety of situations.",
        "keywords": "",
        "link": "http://dx.doi.org/10.55529/jaimlnn.32.1.13"
    },
    {
        "id": 10517,
        "title": "Automatic Food Recognition Using Deep Convolutional Neural Networks with Self-attention Mechanism",
        "authors": "Rahib Abiyev, Joseph Adepoju",
        "published": "2024-1-9",
        "citations": 0,
        "abstract": "AbstractThe significance of food in human health and well-being cannot be overemphasized. Nowadays, in our dynamic life, people are increasingly concerned about their health due to increased nutritional ailments. For this reason, mobile food-tracking applications that require a reliable and robust food classification system are gaining popularity. To address this, we propose a robust food recognition model using deep convolutional neural networks with a self-attention mechanism (FRCNNSAM). By training multiple FRCNNSAM structures with varying parameters, we combine their predictions through averaging. To prevent over-fitting and under-fitting data augmentation to generate extra training data, regularization to avoid excessive model complexity was used. The FRCNNSAM model is tested on two novel datasets: Food-101 and MA Food-121. The model achieved an impressive accuracy of 96.40% on the Food-101 dataset and 95.11% on MA Food-121. Compared to baseline transfer learning models, the FRCNNSAM model surpasses performance by 8.12%. Furthermore, the evaluation on random internet images demonstrates the model's strong generalization ability, rendering it suitable for food image recognition and classification tasks.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s44230-023-00057-9"
    },
    {
        "id": 10518,
        "title": "Deep Convolutional Neural Networks for Automated Butterfly Species Recognition and Classification",
        "authors": "Thatte Surabhi, Bhoite Sachin, Chaudhari Advait",
        "published": "2023-8-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icirca57980.2023.10220696"
    },
    {
        "id": 10519,
        "title": "Enhancing Sign Language Recognition Using Deep Convolutional Neural Networks",
        "authors": "Athanasios Kanavos, Orestis Papadimitriou, Phivos Mylonas, Manolis Maragoudakis",
        "published": "2023-7-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iisa59645.2023.10345865"
    },
    {
        "id": 10520,
        "title": "Deep Wavelet Convolutional Neural Networks for Multimodal Human Activity Recognition Using Wearable Inertial Sensors",
        "authors": "Thi Hong Vuong, Tung Doan, Atsuhiro Takasu",
        "published": "2023-12-9",
        "citations": 1,
        "abstract": "Recent advances in wearable systems have made inertial sensors, such as accelerometers and gyroscopes, compact, lightweight, multimodal, low-cost, and highly accurate. Wearable inertial sensor-based multimodal human activity recognition (HAR) methods utilize the rich sensing data from embedded multimodal sensors to infer human activities. However, existing HAR approaches either rely on domain knowledge or fail to address the time-frequency dependencies of multimodal sensor signals. In this paper, we propose a novel method called deep wavelet convolutional neural networks (DWCNN) designed to learn features from the time-frequency domain and improve accuracy for multimodal HAR. DWCNN introduces a framework that combines continuous wavelet transforms (CWT) with enhanced deep convolutional neural networks (DCNN) to capture the dependencies of sensing signals in the time-frequency domain, thereby enhancing the feature representation ability for multiple wearable inertial sensor-based HAR tasks. Within the CWT, we further propose an algorithm to estimate the wavelet scale parameter. This helps enhance the performance of CWT when computing the time-frequency representation of the input signals. The output of the CWT then serves as input for the proposed DCNN, which consists of residual blocks for extracting features from different modalities and attention blocks for fusing these features of multimodal signals. We conducted extensive experiments on five benchmark HAR datasets: WISDM, UCI-HAR, Heterogeneous, PAMAP2, and UniMiB SHAR. The experimental results demonstrate the superior performance of the proposed model over existing competitors.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23249721"
    },
    {
        "id": 10521,
        "title": "Creating Deep Convolutional Neural Networks for Image Classification",
        "authors": "Nabeel Siddiqui",
        "published": "2023-3-23",
        "citations": 0,
        "abstract": "\n            This lesson provides a beginner-friendly introduction to convolutional neural networks (CNNs) for image classification. The tutorial provides a conceptual understanding of how neural networks work by using Google's Teachable Machine to train a model on paintings from the ArtUK database. This lesson also demonstrates how to use Javascript to embed the model in a live website.\n          ",
        "keywords": "",
        "link": "http://dx.doi.org/10.46430/phen0108"
    },
    {
        "id": 10522,
        "title": "Skin Cancer Recognition Using Unified Deep Convolutional Neural Networks",
        "authors": "Nasser A. AlSadhan, Shatha Ali Alamri, Mohamed Maher Ben Ismail, Ouiem Bchir",
        "published": "2024-3-22",
        "citations": 1,
        "abstract": "The incidence of skin cancer is rising globally, posing a significant public health threat. An early and accurate diagnosis is crucial for patient prognoses. However, discriminating between malignant melanoma and benign lesions, such as nevi and keratoses, remains a challenging task due to their visual similarities. Image-based recognition systems offer a promising solution to aid dermatologists and potentially reduce unnecessary biopsies. This research investigated the performance of four unified convolutional neural networks, namely, YOLOv3, YOLOv4, YOLOv5, and YOLOv7, in classifying skin lesions. Each model was trained on a benchmark dataset, and the obtained performances were compared based on lesion localization, classification accuracy, and inference time. In particular, YOLOv7 achieved superior performance with an Intersection over Union (IoU) of 86.3%, a mean Average Precision (mAP) of 75.4%, an F1-measure of 80%, and an inference time of 0.32 s per image. These findings demonstrated the potential of YOLOv7 as a valuable tool for aiding dermatologists in early skin cancer diagnosis and potentially reducing unnecessary biopsies.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/cancers16071246"
    },
    {
        "id": 10523,
        "title": "Foreign Object Debris (FOD) Classification Through Material Recognition Using Deep Convolutional Neural Network With Focus on Metal",
        "authors": "Syeda Mahrukh Zainab, Khurram Khan, Adnan Fazil, Muhammad Zakwan",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3239424"
    },
    {
        "id": 10524,
        "title": "Handwritten Character Recognition Using Deep Learning (Convolutional Neural Network)",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.7176/ceis/14-1-05"
    },
    {
        "id": 10525,
        "title": "Real-Time Face Recognition System with Fine-tune Convolutional Neural Networks",
        "authors": "",
        "published": "2023-6-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.48047/nq.2022.20.8.nq221055"
    },
    {
        "id": 10526,
        "title": "Analysis of Fingerprint Image Recognition using Deep Residual Convolutional Neural Network",
        "authors": "Rosa Andrie Asmara, Cahya Rahmad, Juanda Rahimatullah, Anik Nur Handayani",
        "published": "2023-11-23",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/comnetsat59769.2023.10420689"
    },
    {
        "id": 10527,
        "title": "Color object classification using multi-channel Zernike moments-based rotation invariant bag-of-visual-words and deep convolutional neural networks",
        "authors": "Jaspreet Singh, Chandan Singh",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.inffus.2023.101823"
    },
    {
        "id": 10528,
        "title": "Speech Emotion Recognition and Deep Learning: An Extensive Validation Using Convolutional Neural Networks",
        "authors": "Francesco Ardan Dal Rí, Fabio Cifariello Ciardi, Nicola Conci",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3326071"
    },
    {
        "id": 10529,
        "title": "CAPTCHA Recognition Using Deep Convolutional Neural Networks (DCNN)",
        "authors": "Canavoy Narahari Sujatha, Chilukoti Pranathi, N. Hari Kumar Reddy, Gandu Sushma, Abhishek Gudipalli",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/i-pact58649.2023.10434845"
    },
    {
        "id": 10530,
        "title": "The role of scene context in object recognition by humans and convolutional neural networks",
        "authors": "Haley G. Frey, Hojin Jang, Hui-Yuan Miao, Frank Tong",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.5698"
    },
    {
        "id": 10531,
        "title": "Application of Deep Convolutional Neural Networks to Telugu Scriptsfor Optical Character Recognition",
        "authors": "Gnaneswari M, Chaitanya Kumar T",
        "published": "2023-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14445/22312803/ijctt-v71i1p108"
    },
    {
        "id": 10532,
        "title": "Deep Learning Convolutional Neural Networks (CNNs) on Recognition and Classification of White Blood Cells (WBCs)",
        "authors": "Salila Ongtrakul, Anyarin Thitirattanapong, Anoma Eamkong, Chuchart Pintavirooj, Supan Tungjitkusolmun",
        "published": "2023-10-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bmeicon60347.2023.10322084"
    },
    {
        "id": 10533,
        "title": "Cardiac Arrhythmia Classification in Electrocardiogram Signals with Convolutional Neural Networks",
        "authors": "Igor Souza, Daniel Dantas",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011682800003411"
    },
    {
        "id": 10534,
        "title": "Real-time recognition and localization method for deep-sea underwater object",
        "authors": "Yuanyang Tang, Yuman Nie, Yong Chen, Yaoxiong Wang",
        "published": "2023-2-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nnice58320.2023.10105685"
    },
    {
        "id": 10535,
        "title": "Image-based time series forecasting: A deep convolutional neural network approach",
        "authors": "Artemios-Anargyros Semenoglou, Evangelos Spiliotis, Vassilios Assimakopoulos",
        "published": "2023-1",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2022.10.006"
    },
    {
        "id": 10536,
        "title": "SCTN: Event-based object tracking with energy-efficient deep convolutional spiking neural networks",
        "authors": "Mingcheng Ji, Ziling Wang, Rui Yan, Qingjie Liu, Shu Xu, Huajin Tang",
        "published": "2023-2-16",
        "citations": 0,
        "abstract": "Event cameras are asynchronous and neuromorphically inspired visual sensors, which have shown great potential in object tracking because they can easily detect moving objects. Since event cameras output discrete events, they are inherently suitable to coordinate with Spiking Neural Network (SNN), which has a unique event-driven computation characteristic and energy-efficient computing. In this paper, we tackle the problem of event-based object tracking by a novel architecture with a discriminatively trained SNN, called the Spiking Convolutional Tracking Network (SCTN). Taking a segment of events as input, SCTN not only better exploits implicit associations among events rather than event-wise processing, but also fully utilizes precise temporal information and maintains the sparse representation in segments instead of frames. To make SCTN more suitable for object tracking, we propose a new loss function that introduces an exponential Intersection over Union (IoU) in the voltage domain. To the best of our knowledge, this is the first tracking network directly trained with SNN. Besides, we present a new event-based tracking dataset, dubbed DVSOT21. In contrast to other competing trackers, experimental results on DVSOT21 demonstrate that our method achieves competitive performance with very low energy consumption compared to ANN based trackers with very low energy consumption compared to ANN based trackers. With lower energy consumption, tracking on neuromorphic hardware will reveal its advantage.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fnins.2023.1123698"
    },
    {
        "id": 10537,
        "title": "Object recognition system of sports equipment based on convolutional neural network",
        "authors": " Ying-Chen",
        "published": "2023-6-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icise60366.2023.00115"
    },
    {
        "id": 10538,
        "title": "Modi Script Recognition Using Convolutional Neural Networks and VGG16: A Deep Learning Approach for Historical Script Analysis",
        "authors": "Prathmesh Sainath Chidrawar, Vidhya Dhamdhere",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccubea58933.2023.10391961"
    },
    {
        "id": 10539,
        "title": "Hand Gesture Recognition with Deep Convolutional Neural Networks: A Comparative Study",
        "authors": "You Li Chong, Chin Poo Lee, Kian Ming Lim, Jit Yan Lim",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icspc59664.2023.10419918"
    },
    {
        "id": 10540,
        "title": "Malayalam Handwritten Character Recognition using Transfer Learning and Fine Tuning of Deep Convolutional Neural Networks",
        "authors": "Pearlsy P V, Deepa Sankar",
        "published": "2023-5-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access57397.2023.10200336"
    },
    {
        "id": 10541,
        "title": "Corrigendum: SCTN: event-based object tracking with energy-efficient deep convolutional spiking neural networks",
        "authors": "Mingcheng Ji, Ziling Wang, Rui Yan, Qingjie Liu, Shu Xu, Huajin Tang",
        "published": "2023-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fnins.2023.1204334"
    },
    {
        "id": 10542,
        "title": "Melanoma Cancer Classification using Deep Convolutional Neural Networks",
        "authors": "José M. Cadena, Noel Peréz, Diego Benítez, Felipe Grijalva, Ricardo Flores, Oscar Camacho, Yovani Marrero-Ponce",
        "published": "2023-7-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icprs58416.2023.10179049"
    },
    {
        "id": 10543,
        "title": "Handwritten Vedic Sanskrit Text Recognition Using Deep Learning and Convolutional Neural Networks",
        "authors": "Et al. Ashi Maheshwari",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "Recognizing Vedic Sanskrit text is essential for accessing classical Indo-Aryan language, predominantly utilized in the Vedas. Currently, there is limited awareness about the Vedas, making this field a highly demanding and challenging area in pattern recognition. To accelerate progress in optical character recognition (OCR), deep learning methods are indispensable. This article presents a novel approach to Vedic Sanskrit text recognition, incorporating deep convolutional architectures with their respective interpretations. We introduce three modified 4-fold CNN architectures and the AlexNet model. Our system comprises a handwritten dataset containing 140 distinct Vedic Sanskrit words, with approximately 500 images per word, totaling around 70,000 images. The dataset is partitioned for training and testing in an 80:20 ratio. Training is conducted using 20% of the samples, and the resulting model is applied to the deep convolutional network with varied sets of neurons in their hidden layers. Our proposed method demonstrates robust support for accurate Vedic Sanskrit word classification. The recognition rate achieved in our research is 97.42%, with an average recognition time of 0.3640 milliseconds, surpassing existing CNN-based approaches.",
        "keywords": "",
        "link": "http://dx.doi.org/10.17762/ijritcc.v11i11.10071"
    },
    {
        "id": 10544,
        "title": "Visual Object Tracking Based on Improved Convolutional Neural Network",
        "authors": "Siming Tang",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10166632"
    },
    {
        "id": 10545,
        "title": "Modeling Biological Face Recognition with Deep Convolutional Neural Networks",
        "authors": "Leonard Elia van Dyck, Walter Roland Gruber",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "Abstract\nDeep convolutional neural networks (DCNNs) have become the state-of-the-art computational models of biological object recognition. Their remarkable success has helped vision science break new ground, and recent efforts have started to transfer this achievement to research on biological face recognition. In this regard, face detection can be investigated by comparing face-selective biological neurons and brain areas to artificial neurons and model layers. Similarly, face identification can be examined by comparing in vivo and in silico multidimensional “face spaces.” In this review, we summarize the first studies that use DCNNs to model biological face recognition. On the basis of a broad spectrum of behavioral and computational evidence, we conclude that DCNNs are useful models that closely resemble the general hierarchical organization of face recognition in the ventral visual pathway and the core face network. In two exemplary spotlights, we emphasize the unique scientific contributions of these models. First, studies on face detection in DCNNs indicate that elementary face selectivity emerges automatically through feedforward processing even in the absence of visual experience. Second, studies on face identification in DCNNs suggest that identity-specific experience and generative mechanisms facilitate this particular challenge. Taken together, as this novel modeling approach enables close control of predisposition (i.e., architecture) and experience (i.e., training data), it may be suited to inform long-standing debates on the substrates of biological face recognition.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1162/jocn_a_02040"
    },
    {
        "id": 10546,
        "title": "Object detection and classification of butterflies using efficient CNN and pre-trained deep convolutional neural networks",
        "authors": "R. Faerie Mattins, M. Vergin Raja Sarobin, Azrina Abd Aziz, S. Srivarshan",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-17563-4"
    },
    {
        "id": 10547,
        "title": "A Performance Study: Convolutional Deep Belief Networks and Convolutional Neural Networks for Audio Classification",
        "authors": "Maharshi Patel, Aaditya Darakh",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/csitss60515.2023.10334214"
    },
    {
        "id": 10548,
        "title": "Siamese Neural Networks for Kinship Prediction: A Deep Convolutional Neural Network Approach",
        "authors": "Tukaram Navghare,  , Aniket Muley, Vinayak Jadhav",
        "published": "2024-1-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17485/ijst/v17i4.3018"
    },
    {
        "id": 10549,
        "title": "Few-shot human–object interaction video recognition with transformers",
        "authors": "Qiyue Li, Xuemei Xie, Jin Zhang, Guangming Shi",
        "published": "2023-6",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.01.019"
    },
    {
        "id": 10550,
        "title": "Convolutional Neural Networks for Object Detection",
        "authors": "Bruno Romão, Eric Fagotto",
        "published": "2024-1-8",
        "citations": 0,
        "abstract": "<div class=\"section abstract\"><div class=\"htmlview paragraph\">Autonomous cars (ACs) and advanced driver-assistance systems (ADAS) have relied on convolutional neural networks (CNNs) for object detection. However, image degradation caused by adverse weather conditions like rain, snow, and fog can decrease the performance of a CNN. So, this paper presents the development of an image-processing technique aimed to mitigate such a problem. First, after an extensive evaluation of models for object detection, YOLOv3 was chosen because of its compromise between precision and inference time. Afterwards, the training and test of a YOLOv3 CNN was investigated for cars, traffic signals, traffic lights, pedestrians, and riders. Performance was evaluated by estimating the average and mean average precision (mAP) for every one of the mentioned object classes. An OpenCV based pre-processing technique to mitigate the degradation imposed by adverse weather conditions was implemented. Specifically, the OpenCV filters of erosion, dilation and joint bilateral filter were applied during training and tests of the datasets Berkeley DeepDrive (BDD100K) and Detection in Adverse Weather Nature (DAWN). The developed work discusses the benefits of OpenCV filters for data augmentation in training and testing CNNs. Our results show a mAP improvement around 3% in the tests with DAWN.</div></div>",
        "keywords": "",
        "link": "http://dx.doi.org/10.4271/2023-36-0097"
    },
    {
        "id": 10551,
        "title": "Application of Advanced Deep Convolutional Neural Networks for the Recognition of Road Surface Anomalies",
        "authors": "Dong Doan Van",
        "published": "2023-6-2",
        "citations": 4,
        "abstract": "The detection of road surface anomalies is a crucial task for modern traffic monitoring systems. In this paper, we used the YOLOv8 network,- a state-of-the-art convolutional neural network architecture, for real-time object recognition and to automatically identify potholes, cracks, and patches on the road surface. We created a custom dataset of 1044 road surface images in Vietnam, each of which was annotated with pavement anomalies, and the YOLOv8 network was trained with this dataset. The results show that the model achieved an accuracy of 0.56 mAP at a threshold of 0.5, indicating its potential for practical application.",
        "keywords": "",
        "link": "http://dx.doi.org/10.48084/etasr.5890"
    },
    {
        "id": 10552,
        "title": "Video Classification-Based Action Recognition with Enhanced Convolutional Neural Networks",
        "authors": "Bo Mei",
        "published": "2023-8-26",
        "citations": 0,
        "abstract": "The classification of videos has become increasingly important in the field of data science research, as it has numerous practical applications in modern society. Compared to image classification, video classification poses a significantly greater challenge. One of the most obvious difficulties is that video classification tasks require more powerful computers due to the large number of features that need to be computed. Additionally, conventional 2D Convolutional Neural Networks (2D CNNs) are not effective in handling such tasks. This paper proposes a novel 2-layer Convolutional Neural Network (CNN) architecture for action recognition that addresses these challenges. The proposed architecture achieved a high test accuracy of 79.66% for classifying large video clips. The results indicate the effectiveness of the proposed approach for video classification tasks.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5121/csit.2023.131506"
    },
    {
        "id": 10553,
        "title": "Design and Implementation of Land Area Calculation for Maps Using Mask Region Based Convolutional Neural Networks Deep Neural Network",
        "authors": "Akram A. Pathan, Nagaraj V. Dharwadkar",
        "published": "2023-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1134/s1054661822040095"
    },
    {
        "id": 10554,
        "title": "Deep Convolutional Generative Adversarial Networks for Crime Scene Object Detection",
        "authors": "Uma N",
        "published": "2023-8-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaiss58487.2023.10250517"
    },
    {
        "id": 10555,
        "title": "Adaptive filters in Graph Convolutional Neural Networks",
        "authors": "Andrea Apicella, Francesco Isgrò, Andrea Pollastro, Roberto Prevete",
        "published": "2023-12",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2023.109867"
    },
    {
        "id": 10556,
        "title": "Fine-grained image analysis for facial expression recognition using deep convolutional neural networks with bilinear pooling",
        "authors": "Sanoar Hossain, Saiyed Umer, Ranjeet Kr. Rout, M. Tanveer",
        "published": "2023-2",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.asoc.2023.109997"
    },
    {
        "id": 10557,
        "title": "A Neurocomputational Model of Decision and Confidence in Object Recognition Task",
        "authors": "Setareh Sadat Roshan, Naser Sadeghnejad, Fatemeh Sharifiadeh, Reza Ebrahimpour",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2024.106318"
    },
    {
        "id": 10558,
        "title": "Image Classification of Stroke Blood Clot Origin Using Deep Convolutional Neural Networks and Visual Transformers: A Kaggle Competition",
        "authors": "",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": "Stroke is one of two main causes of death worldwide. Many individuals suffer from ischemic stroke every year. Only in US, more over 700,000 individuals meet ischemic stroke due to blood clot blocking an artery to the brain every year. «Stroke symptoms typically start suddenly, over seconds to minutes, and in most cases do not progress further. The symptoms depend on the area of the brain affected. The more extensive the area of the brain affected, the more functions that are likely to be lost. »  «Ischemic stroke occurs because of a loss of blood supply to part of the brain, initiating the ischemic cascade. » In the case of subsequent strokes, it is possible to mitigate consequences if physicians can determine stroke etiology. The paper describes particular approach how to apply Artificial Intelligence for purposes of separating two major acute ischemic stroke (AIS) etiology subtypes: cardiac and large artery atherosclerosis. Four deep neural network architectures and simple ensemble method are used in the approach.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33140/jeee.02.04.14"
    },
    {
        "id": 10559,
        "title": "Deep Convolutional Neural Networks for Predominant Instrument Recognition in Polyphonic Music Using Discrete Wavelet Transform",
        "authors": "Sukanta Kumar Dash, S. S. Solanki, Soubhik Chakraborty",
        "published": "2024-3-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00034-024-02641-1"
    },
    {
        "id": 10560,
        "title": "A Flexible Iontronic Capacitive Sensing Array for Hand Gesture Recognition Using Deep Convolutional Neural Networks",
        "authors": "Tiantong Wang, Yunbiao Zhao, Qining Wang",
        "published": "2023-6-1",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1089/soro.2021.0209"
    },
    {
        "id": 10561,
        "title": "Handwritten Recognition Based on Convolutional Neural Networks",
        "authors": "Mohan Wang",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceace60673.2023.10442130"
    },
    {
        "id": 10562,
        "title": "Tactile Transfer Learning and Object Recognition With a Multifingered Hand Using Morphology Specific Convolutional Neural Networks",
        "authors": "Satoshi Funabashi, Gang Yan, Fei Hongyi, Alexander Schmitz, Lorenzo Jamone, Tetsuya Ogata, Shigeki Sugano",
        "published": "2024",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2022.3215723"
    },
    {
        "id": 10563,
        "title": "Implementation of Field-Programmable Gate Array Platform for Object Classification Tasks Using Spike-Based Backpropagated Deep Convolutional Spiking Neural Networks",
        "authors": "Vijay Kakani, Xingyou Li, Xuenan Cui, Heetak Kim, Byung-Soo Kim, Hakil Kim",
        "published": "2023-6-30",
        "citations": 2,
        "abstract": "This paper investigates the performance of deep convolutional spiking neural networks (DCSNNs) trained using spike-based backpropagation techniques. Specifically, the study examined temporal spike sequence learning via backpropagation (TSSL-BP) and surrogate gradient descent via backpropagation (SGD-BP) as effective techniques for training DCSNNs on the field programmable gate array (FPGA) platform for object classification tasks. The primary objective of this experimental study was twofold: (i) to determine the most effective backpropagation technique, TSSL-BP or SGD-BP, for deeper spiking neural networks (SNNs) with convolution filters across various datasets; and (ii) to assess the feasibility of deploying DCSNNs trained using backpropagation techniques on low-power FPGA for inference, considering potential configuration adjustments and power requirements. The aforementioned objectives will assist in informing researchers and companies in this field regarding the limitations and unique perspectives of deploying DCSNNs on low-power FPGA devices. The study contributions have three main aspects: (i) the design of a low-power FPGA board featuring a deployable DCSNN chip suitable for object classification tasks; (ii) the inference of TSSL-BP and SGD-BP models with novel network architectures on the FPGA board for object classification tasks; and (iii) a comparative evaluation of the selected spike-based backpropagation techniques and the object classification performance of DCSNNs across multiple metrics using both public (MNIST, CIFAR10, KITTI) and private (INHA_ADAS, INHA_KLP) datasets.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/mi14071353"
    },
    {
        "id": 10564,
        "title": "Object Detection Algorithms Based on Convolutional Neural Networks",
        "authors": "Zihan Deng, Ang Li",
        "published": "2024-1-26",
        "citations": 0,
        "abstract": "Object detection is a fundamental and challenging task in computer vision, and it has attracted much attention from researchers worldwide. In recent years, deep learning technology has made remarkable progress and enabled new possibilities for object detection. Convolutional neural networks (CNNs), which are powerful tools for feature extraction and representation learning, have become the dominant approach for object detection, surpassing the traditional methods. This article reviews the development history of CNNs and their applications to object detection. It also introduces and compares two main branches of CNN-based object detection algorithms: region-based methods, which use a two-stage pipeline to first generate candidate regions and then classify them, and regression-based methods, which directly predict the bounding boxes and labels of objects in a single stage. Finally, it summarizes the current state-of-the-art and discusses the future directions of object detection research.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/vyfg4e34"
    },
    {
        "id": 10565,
        "title": "A study on the recognition of monkeypox infection based on deep convolutional neural networks",
        "authors": "Junkang Chen, Junying Han",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "IntroductionThe World Health Organization (WHO) has assessed the global public risk of monkeypox as moderate, and 71 WHO member countries have reported more than 14,000 cases of monkeypox infection. At present, the identification of clinical symptoms of monkeypox mainly depends on traditional medical means, which has the problems of low detection efficiency and high detection cost. The deep learning algorithm is excellent in image recognition and can extract and recognize image features quickly and reliably.MethodsTherefore, this paper proposes a residual convolutional neural network based on the λ function and contextual transformer (LaCTResNet) for the image recognition of monkeypox cases.ResultsThe average recognition accuracy of the neural network model is 91.85%, which is 15.82% higher than that of the baseline model ResNet50 and better than the classical convolutional neural networks models such as AlexNet, VGG16, Inception-V3, and EfficientNet-B5.DiscussionThis method realizes high-precision identification of skin symptoms of the monkeypox virus to provide a fast and reliable auxiliary diagnosis method for monkeypox cases for front-line medical staff.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fimmu.2023.1225557"
    },
    {
        "id": 10566,
        "title": "Palmprint Recognition Using Pre-Trained Convolutional Neural Networks",
        "authors": "Nader Ebrahimpour, Faruk Baturalp Günay",
        "published": "2023-10-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.36287/setsci.6.1.018"
    },
    {
        "id": 10567,
        "title": "Object Detection and Recognition in Remote Sensing Images by Employing a Hybrid Generative Adversarial Networks and Convolutional Neural Networks",
        "authors": "Araddhana Arvind Deshmukh, Mamta Kumari, V.V. Jaya Rama Krishnaiah, Shweta Bandhekar, R. Dharani",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14569/ijacsa.2023.0140965"
    },
    {
        "id": 10568,
        "title": "Deep Convolutional Neural Networks with Transfer Learning for Bone Fracture Recognition using Small Exemplar Image Datasets",
        "authors": "Kethu Nikhil Kumar Reddy, Vassilis Cutsuridis",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icasspw59220.2023.10193015"
    },
    {
        "id": 10569,
        "title": "An Deep Convolutional Neural Networks are used to Detect Cyberbullying on Social Networks.",
        "authors": "B.S. Rawat",
        "published": "2023-10-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/gcat59970.2023.10353375"
    },
    {
        "id": 10570,
        "title": "Exploring Convolutional Neural Networks for Facial Expression Recognition: A Comprehensive Survey",
        "authors": "",
        "published": "2024-3-20",
        "citations": 0,
        "abstract": "Facial emotion recognition is a very sought-after field in recent times as it has many important applications such as effective calculations, video game testing and motion capture in video games, human-computer interaction through machine vision, computer research etc. Facial expression is considered a nonverbal form of communication, as it reveals an individual's internal sentiments and emotional states through changes in multiple facial landmark points. Facial identification provides a more comprehensive insight into the person's thoughts and these expressions are analyzed using deep learning methods, such as CNN. The accuracy rates achieved are compared to other methods. In this paper, a concise exploration of diverse applications within Facial Expression Recognition (FER) fields and the publicly accessible data sets employed in FER studies is outlined. FER using multiple different CNN algorithms is also presented. Finally, through comparing multiple different studies of various CNN algorithms, a table and a chart are provided for a better understanding of the rate of accuracy achieved throughout the use of different datasets.",
        "keywords": "",
        "link": "http://dx.doi.org/10.62304/jieet.v3i02.87"
    },
    {
        "id": 10571,
        "title": "A Review of Deep Convolutional Neural Networks in Mobile Face Recognition",
        "authors": "Jing Chi, Chin Kim On, Haopeng Zhang, Soo See Chai",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "With the emergence of deep learning, Convolutional Neural Network (CNN) models have been proposed to advance the progress of various applications, including face recognition, object detection, pattern recognition, and number plate recognition. The utilization of CNNs in these areas has considerably improved security and surveillance capabilities by providing automated recognition solutions, such as traffic surveillance, access control devices, biometric security systems, and attendance systems. However, there is still room for improvement in this field. This paper discusses several classic CNN models, such as LeNet-5, AlexNet, VGGNet, GoogLeNet, and ResNet, as well as lightweight models for mobile-based applications, such as MobileNet, ShuffleNet, and EfficientNet. Additionally, deep CNN-based face recognition models, such as DeepFace, DeepID, FaceNet, and SphereFace, are explored, along with their architectural characteristics, advantages, disadvantages, and recognition accuracy. The results indicate that many scholars are researching lightweight face recognition, but applying it to mobile devices is impractical due to high computational costs. Furthermore, noise label learning is not robust in actual scenarios, and unlabeled face learning is expensive in manual labeling. Finally, this paper concludes with a discussion of the current problems faced by face recognition technology and its potential future directions for development. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.3991/ijim.v17i23.40867"
    },
    {
        "id": 10572,
        "title": "Ensemble of Deep Convolutional Neural Networks for Multi-Class Skin Lesion Recognition Using Soft Attention",
        "authors": "S. M. Mahedy Hasan, Md. Al Mamun, Md. Farukuzzaman Faruk, Azmain Yakin Srizon",
        "published": "2023-9-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icict4sd59951.2023.10303518"
    },
    {
        "id": 10573,
        "title": "Thai Handwritten Character Recognition Using Deep Convolutional Neural Network",
        "authors": "Suwanee Kulkarineetham, Vipa Thananant",
        "published": "2023-4-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccs57501.2023.10151078"
    },
    {
        "id": 10574,
        "title": "Dance movement recognition method based on convolutional neural network",
        "authors": "Zhiqun Lin",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10166919"
    },
    {
        "id": 10575,
        "title": "Recognition of Bangladeshi Sign Language (BdSL) Words using Deep Convolutional Neural Networks (DCNNs)",
        "authors": "Aminul Haque, Rishad Amin Pulok, Md Mizanur Rahman, Sanzida Akter, Nusrat Khan, Shamsul Haque",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "In a world where effective communication is fundamental, individuals who are Deaf and Dumb (D&D) often face unique challenges due to their primary mode of communication—sign language. Despite the interpreters' invaluable roles, their lack of availability causes communication difficulties for the D&D individuals. This study explores whether the field of Human-Computer Interaction (HCI) could be a potential solution. The primary objective is to assist D&D individuals with computer applications that could act as mediators to bridge the communication gap between them and the wider hearing population. To ensure their independent communication, we propose an automated system that could detect specific Bangla Sign Language (BdSL) words, addressing a critical gap in the sign language detection and recognition literature. Our approach leverages deep learning and transfer learning principles to convert webcam-captured hand gestures into textual representations in real-time. The model's development and assessment rest upon 992 images created by the authors, categorized into ten distinct classes representing various BdSL words. Our findings show the DenseNet201 and ResNet50-V2 models achieve promising training and testing accuracies of 99% and 93%, respectively. Doi: 10.28991/ESJ-2023-07-06-019 Full Text: PDF",
        "keywords": "",
        "link": "http://dx.doi.org/10.28991/esj-2023-07-06-019"
    },
    {
        "id": 10576,
        "title": "Deep Convolutional Tables: Deep Learning Without Convolutions",
        "authors": "Shay Dekel, Yosi Keller, Aharon Bar-Hillel",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2023.3270402"
    },
    {
        "id": 10577,
        "title": "Deep Learning for Early Diagnosis of Diabetic Retinopathy: a Study Using Convolutional Neural Network",
        "authors": "Ali Sultan Mayya",
        "published": "2023-6-16",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/neuront58640.2023.10175853"
    },
    {
        "id": 10578,
        "title": "Using a Genetic Algorithm to Update Convolutional Neural Networks for Abnormality Classification in Mammography",
        "authors": "Steven Wessels, Dustin van der Haar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011648500003411"
    },
    {
        "id": 10579,
        "title": "Deep convolutional neural networks-based features for Indonesian large vocabulary speech recognition",
        "authors": "Hilman F. Pardede, Purwoko Adhi, Vicky Zilvan, Ade Ramdan, Dikdik Krisnandi",
        "published": "2023-6-1",
        "citations": 0,
        "abstract": "There are great interests in developing speech recognition using deep learning technologies due to their capability to model the complexity of pronunciations, syntax, and language rules of speech data better than the traditional hidden Markov model (HMM) do. But, the availability of large amount of data is necessary for deep learning-based speech recognition to be effective. While this is not a problem for mainstream languages such as English or Chinese, this is not the case for non-mainstream languages such as Indonesian. To overcome this limitation, we present deep features based on convolutional neural networks (CNN) for Indonesian large vocabulary continuous speech recognition in this paper. The CNN is trained discriminatively which is different from usual deep learning implementations where the networks are trained generatively. Our evaluations show that the proposed method on Indonesian speech data achieves 7.26% and 9.01% error reduction rates over the state-of-the-art deep belief networks-deep neural networks (DBN-DNN) for large vocabulary continuous speech recognition (LVCSR), with Mel frequency cepstral coefficients (MFCC) and filterbank (FBANK) used as features, respectively. An error reduction rate of 6.13% is achieved compared to CNN-DNN with generative training.",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijai.v12.i2.pp610-617"
    },
    {
        "id": 10580,
        "title": "Handwritten Character and Digit Recognition with Deep Convolutional Neural Networks: A Comparative Study",
        "authors": "Chui En Mook, Chin Poo Lee, Kian Ming Lim, Jit Yan Lim",
        "published": "2023-8-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icoict58202.2023.10262721"
    },
    {
        "id": 10581,
        "title": "Numerosity representation across changes in object and scene content in convolutional neural networks",
        "authors": "Thomas Chapalain, Bertrand Thirion, Evelyn Eger",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32470/ccn.2023.1312-0"
    },
    {
        "id": 10582,
        "title": "Human activity recognition based on deep convolutional neural network",
        "authors": "Vimal Anand, Meenakshi Sundaram",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0183672"
    },
    {
        "id": 10583,
        "title": "DEEP CONVOLUTIONAL NEURAL NETWORKS FOR MALARIA CELL CLASSIFICATION",
        "authors": "",
        "published": "2023-7-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets43669"
    },
    {
        "id": 10584,
        "title": "Automated Human Emotion Recognition from Speech Using Convolutional Neural Networks",
        "authors": "Sachin Mittal",
        "published": "2023-10-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icssas57918.2023.10331772"
    },
    {
        "id": 10585,
        "title": "Language recognition by convolutional neural networks",
        "authors": "l. Khosravani Pour, A. Farrokhi",
        "published": "2023-2-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.24200/sci.2022.59110.6064"
    },
    {
        "id": 10586,
        "title": "Impacts of ResNet Skip Connection levels on Inception Convolutional Neural Network using Different Resized Images in Object Recognition",
        "authors": "Tatpon Kongkertsuk, Siriporn Supratid",
        "published": "2023-3-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ieecon56657.2023.10126626"
    },
    {
        "id": 10587,
        "title": "The developmental trajectory of object recognition robustness: Children are like small adults but unlike big deep neural networks",
        "authors": "Lukas S. Huber, Robert Geirhos, Felix A. Wichmann",
        "published": "2023-7-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.7.4"
    },
    {
        "id": 10588,
        "title": "Application of Graph Convolutional Neural Networks Combined with Single-Model Decision-Making Fusion Neural Networks in Structural Damage Recognition",
        "authors": "Xiaofei Li, Langxing Xu, Hainan Guo, Lu Yang",
        "published": "2023-11-22",
        "citations": 1,
        "abstract": "In cases with a large number of sensors and complex spatial distribution, correctly learning the spatial characteristics of the sensors is vital for structural damage identification. Graph convolutional neural networks (GCNs), unlike other methods, have the ability to learn the spatial characteristics of the sensors, which is targeted at the above problems in structural damage identification. However, under the influence of environmental interference, sensor instability, and other factors, part of the vibration signal can easily change its fundamental characteristics, and there is a possibility of misjudging structural damage. Therefore, on the basis of building a high-performance graphical convolutional deep learning model, this paper considers the integration of data fusion technology in the model decision-making layer and proposes a single-model decision-making fusion neural network (S_DFNN) model. Through experiments involving the frame model and the self-designed cable-stayed bridge model, it is concluded that this method has a better performance of damage recognition for different structures, and the accuracy is improved based on a single model and has good damage recognition performance. The method has better damage identification performance in different structures, and the accuracy rate is improved based on the single model, which has a very good damage identification effect. It proves that the structural damage diagnosis method proposed in this paper with data fusion technology combined with deep learning has a strong generalization ability and has great potential in structural damage diagnosis.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23239327"
    },
    {
        "id": 10589,
        "title": "Automated Liar Recognition from Facial Expression Using Hybrid Feedforward Deep Neural Network And Convolutional Neural Network",
        "authors": "Hema Malini, Om Prakash Sharma",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cset58993.2023.10346781"
    },
    {
        "id": 10590,
        "title": "Object Detection Algorithm Based on Multi-Scaled Convolutional Neural Networks",
        "authors": "T J Nandhini, K Thinakaran",
        "published": "2023-3-18",
        "citations": 27,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aisp57993.2023.10134980"
    },
    {
        "id": 10591,
        "title": "Exploring the role of texture features in deep convolutional neural networks: Insights from Portilla-Simoncelli statistics",
        "authors": "Yusuke Hamano, Shoko Nagasaka, Hayaru Shouno",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.09.028"
    },
    {
        "id": 10592,
        "title": "Recognition of cat ras of face and body using convolutional neural networks",
        "authors": "Akhmad Wahyu Aji, Esmeralda Contessa Djamal, Ridwan Ilyas",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0129043"
    },
    {
        "id": 10593,
        "title": "Analysis of convolutional neural networks and its application in object detection",
        "authors": "Yiming Gao",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "With the development of times and technology, artificial intelligence-based neural network algorithms have been widely used in scientific research and life. Among them, Convolutional neural network (CNN) is the most classic and the most representative. CNN have been widely used in images classification in recent years. This article focuses on the basic information of the convolutional neural networks and its applications especially in object detection. Also, the advantages of the CNN and the possible future improvements will be told in this article. In the end of this article some research of experiments will be shown in order to prove the accuracy of convolutional neural networks in detecting objects and visualizing results. This article gathers basic knowledge of convolutional neural networks. As a result, it may help new starters to get to know the CNN and then make contributions to the development of deep learning especially the CNN according to the advantages and future improvements mentioned in the article.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/14/20230759"
    },
    {
        "id": 10594,
        "title": "Utilizing Convolutional Neural Networks for Real-Time Object Tracking",
        "authors": "Dhananjay Kumar Yadav, Neeraj Sharma, Febin Prakash",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470866"
    },
    {
        "id": 10595,
        "title": "Speaker age and gender recognition using 1D and 2D convolutional neural networks",
        "authors": "Ergün Yücesoy",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00521-023-09153-0"
    },
    {
        "id": 10596,
        "title": "Prediction of Optical Scattering from Plasmonic Nanostructures using Deep Convolutional Neural Networks",
        "authors": "E.G. Norris, J. Baxter, J. Desaultels, L. Ramunno",
        "published": "2023",
        "citations": 0,
        "abstract": "Deep Learning is used for predicting scattered fields from arbitrarily-shaped individual plasmonic nanoparticles using the multipole expansion",
        "keywords": "",
        "link": "http://dx.doi.org/10.1364/cleo_fs.2023.fw3c.3"
    },
    {
        "id": 10597,
        "title": "Bipolar Population Threshold Encoding for Audio Recognition with Deep Spiking Neural Networks",
        "authors": "Xiaocui Lin, Jiangrong Shen, Jun Wen, Huajin Tang",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191235"
    },
    {
        "id": 10598,
        "title": "Livestock Recognition and Identification with Deep Convolutional Neural Networks: A Case Study of Pigs",
        "authors": "Feiyang Zhao, Maohong Tian, Sheng Hu, Jian Liang, Longfu Zhou, Hualin Li",
        "published": "2023-3-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3594315.3594642"
    },
    {
        "id": 10599,
        "title": "Does training with blurred images bring convolutional neural networks closer to humans with respect to robust object recognition and internal representations?",
        "authors": "Sou Yoshihara, Taiki Fukiage, Shin'ya Nishida",
        "published": "2023-2-15",
        "citations": 2,
        "abstract": "It has been suggested that perceiving blurry images in addition to sharp images contributes to the development of robust human visual processing. To computationally investigate the effect of exposure to blurry images, we trained convolutional neural networks (CNNs) on ImageNet object recognition with a variety of combinations of sharp and blurred images. In agreement with recent reports, mixed training on blurred and sharp images (B+S training) brings CNNs closer to humans with respect to robust object recognition against a change in image blur. B+S training also slightly reduces the texture bias of CNNs in recognition of shape-texture cue conflict images, but the effect is not strong enough to achieve human-level shape bias. Other tests also suggest that B+S training cannot produce robust human-like object recognition based on global configuration features. Using representational similarity analysis and zero-shot transfer learning, we also show that B+S-Net does not facilitate blur-robust object recognition through separate specialized sub-networks, one network for sharp images and another for blurry images, but through a single network analyzing image features common across sharp and blurry images. However, blur training alone does not automatically create a mechanism like the human brain in which sub-band information is integrated into a common representation. Our analysis suggests that experience with blurred images may help the human brain recognize objects in blurred images, but that alone does not lead to robust, human-like object recognition.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fpsyg.2023.1047694"
    },
    {
        "id": 10600,
        "title": "MODI Lipi Handwritten Character Recognition Using Convolutional Neural Networks (CNN)",
        "authors": "",
        "published": "2023-5-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets40141"
    },
    {
        "id": 10601,
        "title": "Identification of the spatiotemporal activity patterns of cultured neuronal networks using deep convolutional neural networks (CNNs)",
        "authors": "Kaito Ogomori, Suguru N. Kudoh",
        "published": "2023-10-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bmeicon60347.2023.10321992"
    },
    {
        "id": 10602,
        "title": "Comparison of models of deep convolutional neural networks",
        "authors": "Zihan Wang",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "Recently, deep learning has gained considerable success and acceptance in a variety of fields, attracting an increasing number of researchers who are delving deeper and gaining a broader perspective on the subject. It provides more sustainability and opportunities to advance the development of society and transform the lives of individuals. Consequently, it is crucial for individuals to understand the neural network development path. This paper provides a concise overview of the structure and components of Convolutional Neural Network, as well as some of the most well-known and influential learning models in the history of its development. Through an analysis of various models of convolutional neural network, the workings of convolutional neural networks were investigated. The paper discovered that the structure of neural networks is becoming deeper and more complex in order to achieve greater efficacy and avoid the overfitting issue. For researchers to enhance and advance neural network performance, there are still numerous parameters and perspectives to improve and advance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/16/20230857"
    },
    {
        "id": 10603,
        "title": "Deepfake Detection with Deep Learning: Convolutional Neural Networks versus Transformers",
        "authors": "Vrizlynn L.L. Thing",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/csr57506.2023.10225004"
    },
    {
        "id": 10604,
        "title": "Sensor-based gesture recognition with convolutional neural networks",
        "authors": "Ran Bi",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "Sensor-based gesture recognition is an active research field of great significance with a wide range of applications in control systems for virtual reality, medical monitoring, and abnormal behavior determination. This problem has drawn the attention from both the academia and industry and many methods are proposed in the literature. Recently, deep learning has been widely applied in sensor-based gesture recognition and achieved good effects. In this paper, we proposed a classifier model based on Convolutional Neural Network (CNN) and applied it to EMG-based and smartphone-based datasets, respectively. For these two datasets, our model both achieved better classification accuracies than traditional machine learning models, with the results of approximately 97% and 72% accuracies, respectively. We also analyzed the effects of different parameters on the results of the proposed CNN model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/4/2023305"
    },
    {
        "id": 10605,
        "title": "Facial emotion recognition using sparrow search optimization tuned deep convolutional neural network",
        "authors": "J. Seetha",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0179056"
    },
    {
        "id": 10606,
        "title": "Enhanced Deep Convolutional Neural Networks for Facial Mask Recognition using MobileNetV2 Transfer Learning Techniques",
        "authors": "Avulamanda Sai Sindhuri, Althi Sushma Parvathi, Anvesh Kodali, Gayam Venkateswar Reddy, S. Madhavi, Venkata Ramana Gupta Nallagattla",
        "published": "2023-7-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icecaa58104.2023.10212366"
    },
    {
        "id": 10607,
        "title": "Recent Deep Neural Networks for Object Detection",
        "authors": "Jun Pan",
        "published": "2023-2-10",
        "citations": 1,
        "abstract": "Object recognition is a basic and difficult task in computer vision. Its purpose is to identify the object and give its exact position in the picture. In recent years, it has attracted extensive attention and gradually become a research hotspot. With the continuous development of object detection, some investigators have been solving existing problems and started to apply deep neural networks to the task. Despite the great progress in the research work surrounding the mission, there are few reviews of the mission, lacking a comprehensive review of its development in recent years. Given this period of rapid development, I will give an overview of object detection and present what methods have been used in object detection in recent years to improve task performance. This paper's goal is to give an exhaustive overview of the most latest developments in the area brought about by deep learning technology. At the same time, the possible problems in the task are analyzed, and the potential problems in the task are analyzed.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v31i.5153"
    },
    {
        "id": 10608,
        "title": "EEG evoked automated emotion recognition using deep convolutional neural network",
        "authors": "Abgeena Abgeena, Shruti Garg",
        "published": "2023-2-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icecct56650.2023.10179711"
    },
    {
        "id": 10609,
        "title": "Efficient Wafer Defect Patterns Recognition Using Deep Convolutional Neural Network",
        "authors": "M. M. Manjurul Islam, Cormac McAteer, Girijesh Prasad",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cai54212.2023.00102"
    },
    {
        "id": 10610,
        "title": "Speech Emotion Recognition Based on Multiple Acoustic Features and Deep Convolutional Neural Network",
        "authors": "Kishor Bhangale, Mohanaprasad Kothandaraman",
        "published": "2023-2-7",
        "citations": 20,
        "abstract": "Speech emotion recognition (SER) plays a vital role in human–machine interaction. A large number of SER schemes have been anticipated over the last decade. However, the performance of the SER systems is challenging due to the high complexity of the systems, poor feature distinctiveness, and noise. This paper presents the acoustic feature set based on Mel frequency cepstral coefficients (MFCC), linear prediction cepstral coefficients (LPCC), wavelet packet transform (WPT), zero crossing rate (ZCR), spectrum centroid, spectral roll-off, spectral kurtosis, root mean square (RMS), pitch, jitter, and shimmer to improve the feature distinctiveness. Further, a lightweight compact one-dimensional deep convolutional neural network (1-D DCNN) is used to minimize the computational complexity and to represent the long-term dependencies of the speech emotion signal. The overall effectiveness of the proposed SER systems’ performance is evaluated on the Berlin Database of Emotional Speech (EMODB) and the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) datasets. The proposed system gives an overall accuracy of 93.31% and 94.18% for the EMODB and RAVDESS datasets, respectively. The proposed MFCC and 1-D DCNN provide greater accuracy and outpace the traditional SER techniques.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12040839"
    },
    {
        "id": 10611,
        "title": "Multiple SOTA Convolutional Neural Networks for Facial Expression Recognition",
        "authors": "Yuming Huang",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "Facial Expression Recognition (FER) has been a popular topic in the field of computer vision. Various and plentiful facial expression datasets emerged every year for people to train their models and compete. ImageNet, as a massive database for image classification, became a standard benchmark for new computer vision models. Many excellent models such as VGG, ResNet, and EfficientNet managed to excel and were regarded as state-of-the-art models (SOTAs). This study aims to investigate whether SOTA models trained on ImageNet can perform exceptionally well in FER tasks. The models are categorized into three groups based on different weight initialization strategies and then trained and evaluated on the FER-2013 dataset. The results indicate that models with weights trained on ImageNet can be fine-tuned and perform well in FER-2013, particularly when compared to other groups. Finally, simpler models with less computational costs are promoted considering the need for real-time application of facial expression recognition.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/8/20230135"
    },
    {
        "id": 10612,
        "title": "FSConv: Flexible and separable convolution for convolutional neural networks compression",
        "authors": "Yangyang Zhu, Luofeng Xie, Zhengfeng Xie, Ming Yin, Guofu Yin",
        "published": "2023-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2023.109589"
    },
    {
        "id": 10613,
        "title": "Implementation of Convolutional Neural Networks on FPGA for Object Detection",
        "authors": "N. Sujith Kumar, G. L Madhumati",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10307606"
    },
    {
        "id": 10614,
        "title": "Prostate Cancer Detection, Segmentation, and Classification using Deep Neural Networks",
        "authors": "Yahia Bouslimi, Takwa Gader, Afef Echi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011795100003411"
    },
    {
        "id": 10615,
        "title": "Deep Hand Gesture Recognition: A Wavelet Scattering Alternative to Convolutional Networks",
        "authors": "Adel Al-Jumaily, Rami N. Khushaba",
        "published": "2023-7-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ssp53291.2023.10208011"
    },
    {
        "id": 10616,
        "title": "ENHANCED DDOS ATTACK DETECTION USING IMPROVED DEEP CONVOLUTIONAL NEURAL NETWORKS",
        "authors": "",
        "published": "2024-4-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.58257/ijprems32996"
    },
    {
        "id": 10617,
        "title": "An IoT Device Recognition Method based on Convolutional Neural Network",
        "authors": "Minghao Lu, Linghui Li, Yali Gao, Xiaoyong Li",
        "published": "2023-2-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nnice58320.2023.10105697"
    },
    {
        "id": 10618,
        "title": "SIGN LANGUAGE RECOGNITION: A DEEP CONVOLUTIONAL NEURAL NETWORK APPROACH FOR ACCURATE ALPHABET IDENTIFICATION",
        "authors": "",
        "published": "2023-5-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets39571"
    },
    {
        "id": 10619,
        "title": "A novel deep convolutional encoder–decoder network: application to moving object detection in videos",
        "authors": "Avatharam Ganivada, Srinivas Yara",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00521-023-08956-5"
    },
    {
        "id": 10620,
        "title": "Characterising representation dynamics in recurrent neural networks for object recognition",
        "authors": "Sushrut Thorat, Adrien Doerig, Tim Kietzmann",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32470/ccn.2023.1088-0"
    },
    {
        "id": 10621,
        "title": "Intelligent IDS in wireless sensor networks using deep fuzzy convolutional neural network",
        "authors": "Shalini Subramani, M. Selvi",
        "published": "2023-7",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00521-023-08511-2"
    },
    {
        "id": 10622,
        "title": "Automatic recognition of lung tumor using convolutional neural networks",
        "authors": "H.D. Praveena, Kumar Ch.V.M.S.N. Pavan, A. Rajani, P. Bharathi",
        "published": "2023-3-1",
        "citations": 0,
        "abstract": "The unchecked proliferation of abnormal cells in the lung is known as lung cancer, and it is one of the major causes of death globally. The most accurate way for finding malignant lung nodules is a thorax Computed Tomography (CT) scan. A spherical lesion called a lung nodule can either be malignant or not. Lung cancer appears as rounded, white shadow nodules on the CT scan. The candidate ROIs are calculated using existing method and some blood vessels are removed using rule-based methods based on the candidate ROIs' shape features. Next, the candidate ROIs' remaining grey and texture features are calculated, and are given to the classifier to categorize the candidates. The rule-based technique has no omissions, according to experimental results, however the misclassification probability is too high. Therefore, in the proposed method, by computing the texture features from the Grey Level Co-occurrence Matrix (GLCM) in the wavelet domain, the nodules were identified and CT images were categorized using Convolutional Neural Networks (CNN) into two groups: those with and those without malignant lung nodules. In this work, two classifiers Support Vector Machine (SVM) and CNN are used for the recognized lung cancer image to determine the severity of the condition. Comparisons between SVM and CNN classifiers are done with regard to quality parameters including accuracy and sensitivity.",
        "keywords": "",
        "link": "http://dx.doi.org/10.18137/cardiometry.2023.26.302308"
    },
    {
        "id": 10623,
        "title": "Sensor-based gesture recognition with convolutional neural networks",
        "authors": "Andrew Guo Wang",
        "published": "2023-8-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2685659"
    },
    {
        "id": 10624,
        "title": "Speech Emotion Recognition Using Convolutional Neural Networks with Attention Mechanism",
        "authors": "Konstantinos Mountzouris, Isidoros Perikos, Ioannis Hatzilygeroudis",
        "published": "2023-10-23",
        "citations": 1,
        "abstract": "Speech emotion recognition (SER) is an interesting and difficult problem to handle. In this paper, we deal with it through the implementation of deep learning networks. We have designed and implemented six different deep learning networks, a deep belief network (DBN), a simple deep neural network (SDNN), an LSTM network (LSTM), an LSTM network with the addition of an attention mechanism (LSTM-ATN), a convolutional neural network (CNN), and a convolutional neural network with the addition of an attention mechanism (CNN-ATN), having in mind, apart from solving the SER problem, to test the impact of the attention mechanism on the results. Dropout and batch normalization techniques are also used to improve the generalization ability (prevention of overfitting) of the models as well as to speed up the training process. The Surrey Audio–Visual Expressed Emotion (SAVEE) database and the Ryerson Audio–Visual Database (RAVDESS) were used for the training and evaluation of our models. The results showed that the networks with the addition of the attention mechanism did better than the others. Furthermore, they showed that the CNN-ATN was the best among the tested networks, achieving an accuracy of 74% for the SAVEE database and 77% for the RAVDESS, and exceeding existing state-of-the-art systems for the same datasets.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12204376"
    },
    {
        "id": 10625,
        "title": "Moving scene object tracking method based on deep convolutional neural network",
        "authors": "Long Liu, Bing Lin, Yong Yang",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.aej.2023.11.077"
    },
    {
        "id": 10626,
        "title": "Facial Expression Recognition Using combined Feature and Convolutional Neural Networks",
        "authors": "Priyadarsini Samal, Mohammad Farukh Hashmi",
        "published": "2023-12-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/acit58888.2023.10453862"
    },
    {
        "id": 10627,
        "title": "Convolutional Recurrent Neural Networks for Medical Image Recognition",
        "authors": "Pankaj Saraswat, Rohaila Naaz, Kavitha R",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470932"
    },
    {
        "id": 10628,
        "title": "Recognition of Mentally Pronounced Russian Phonemes Using Convolutional Neural Networks and Electroencephalography Data",
        "authors": "L. E. Seleznyev, A. A. Chupakhin, V. A. Kostenko, A. O. Shevchenko, A. V. Vartanov",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3103/s1060992x23020066"
    },
    {
        "id": 10629,
        "title": "Gait speed based individual recognition model using deep 2-D convolutional neural network",
        "authors": "Abhay Lal, P Nithyakani",
        "published": "2023-1-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccci56745.2023.10128342"
    },
    {
        "id": 10630,
        "title": "Automatic flood detection by leveraging deep convolutional neural networks",
        "authors": "Delwende Pierre Wilfried, Nikita Rai, Kanika Singla",
        "published": "2023-2-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iemecon56962.2023.10092315"
    },
    {
        "id": 10631,
        "title": "Deep Convolutional Neural Networks Transfer Learning Comparison on Arabic Handwriting Recognition System",
        "authors": "Siti Ummi Masruroh, Muhammad Fikri Syahid, Firman Munthaha, Asep Taufik Muharram, Rizka Amalia Putri",
        "published": "2023-5-12",
        "citations": 2,
        "abstract": "Around 27 languages and more than 420 million people worldwide use Arabic letters. That makes the Arabic language one of the most used languages. However, the Arabic language has a challenge, namely the difference in letters based on their position. Arabic handwriting recognition is important for various applications, such as education and communication. One example is during a pandemic when most education has turned digital, making recognizing students' Arabic handwriting difficult. This paper aims to create a model that can recognize Arabic handwriting by comparing several CNN architectures using transfer learning to classify Arabic, Hijja, and AHCD handwriting datasets. Transfer learning is a model that has been trained by previous datasets to other datasets and is suitable for use in models with small datasets because it can improve model accuracy even with small datasets. The datasets were split into 60%, 20%, and 20% for training, validation, and testing. Each model uses data augmentation and 50% dropout on a fully connected layer to reduce overfitting. Some of the CNN architectures used in this study to create Arabic writing recognition models are ResNet, DenseNet, VGG16, VGG19, InceptionV3, and MobileNet. The models were compiled and trained with various parameters. The best model achieved to classify AHCD and Hijja dataset is VGG16 with Adam optimizer and 0.0001 learning rate. Based on this research, it is expected to know the performance of the best model for classifying Arabic handwriting.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30630/joiv.7.2.1605"
    },
    {
        "id": 10632,
        "title": "A novel interactive deep cascade spectral graph convolutional network with multi-relational graphs for disease prediction",
        "authors": "Sihui Li, Rui Zhang",
        "published": "2024-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2024.106285"
    },
    {
        "id": 10633,
        "title": "Mathematical expression recognition using a new deep neural model",
        "authors": "Abolfazl Mirkazemy, Peyman Adibi, Seyed Mohhamad Saied Ehsani, Alireza Darvishy, Hans-Peter Hutter",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.08.045"
    },
    {
        "id": 10634,
        "title": "Virtual Multiphase Flowmeter Using Deep Convolutional Neural Networks",
        "authors": "Renata Mercante, Theodoro Antoun Netto",
        "published": "2023-10-11",
        "citations": 1,
        "abstract": "Summary\nPetroleum wells produce a combination of oil, gas, and water in what is called a multiphase flow. This mixture is transported through flowlines to a tank separator that isolates and quantifies the volume of each fluid. However, this mechanical gravity separation process takes a long time, and the tank is often shared between many other wells in a field, making it difficult to allow an individual online measurement of the extracted fluids. Without this information, operators cannot effectively control production or estimate each well’s depletion rate, leading to losses or reduced profits. This paper aims to propose a low-cost, instantaneous model to perform this measure using artificial intelligence, commonly known as a virtual flowmeter (VFM). The idea behind it is to use data from pressure and temperature sensors already available on every well in addition to the state of the opening control valve to train a deep neural network with a convolutional layer to output each fluid’s volume rate. The proposed method is computationally simpler than recurrent neural networks and provides similar results. However, it still requires data to train the neural network. Adequate free databases of well production with telemetry are hard to find, so this paper proposes using the Schlumberger OLGA multiphase flow simulator software to provide the data, adjusting the simulator with fluid and operational information from actual wells. Tests have shown that the approximation with the proposed methods achieves up to 99.6% accuracy, making it possible to replace an expensive multiphase meter or use it as a redundant digital sensor for fault alerts of possible inaccurate readings.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2118/214681-pa"
    },
    {
        "id": 10635,
        "title": "Predicting Alzheimer's Disease from Brain MRI Images using Deep Convolutional Neural Networks",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56452/6-3-668"
    },
    {
        "id": 10636,
        "title": "Real-time mask-wearing detection in video streams using deep convolutional neural networks for face recognition",
        "authors": "Suhirman Suhirman, Shoffan Saifullah, Ahmad Tri Hidayat, M. Apriandi Kusuma, Rafał Drezewski",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "This research aims to develop a real-time mask-wearing detection system using deep convolutional neural networks (CNNs). This is crucial in the coronavirus disease 2019 (COVID-19) pandemic to alert individuals who are not wearing masks early on, thereby reducing the spread of the virus. Since COVID-19 primarily spreads through respiratory droplets and mask-wearing is recommended, our proposed study utilizes computer vision techniques, specifically image processing, to detect masked and unmasked faces. We employ a customized CNN architecture consisting of five convolutional layers, followed by max-pooling layers and fully connected (FC) layers. The final output layer utilizes softmax activation for classification. The model is updated with optimized layer configurations and parameter values. We are developing an application that uses a digital camera as an input device. The application utilizes a dataset comprising 11,792 image samples, which are used for training and testing purposes with the 80:20 ratio. Real-time testing is conducted using human subjects captured by the camera. The experimental results demonstrate that the CNN method achieves a classification accuracy of 99% on the training data and 98.83% during real-time video testing. These findings suggest that the real-time mask detection system using CNN performs effectively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijece.v14i1.pp1005-1014"
    },
    {
        "id": 10637,
        "title": "Recognition of Static American Sign Language Hand Gestures Using Convolutional Neural Networks",
        "authors": "Sonu Mittal, Aashika jain, Shubham Jain",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4473983"
    },
    {
        "id": 10638,
        "title": "Alzheimer's MRI Recognition Based on Convolutional Neural Networks",
        "authors": "Mingjun Wang",
        "published": "2024-3-24",
        "citations": 0,
        "abstract": "Alzheimer's disease (AD) is a progressively worsening neurodegenerative disorder, where early diagnosis is crucial for implementing effective disease management strategies. In multimodal diagnostic pathways, Magnetic Resonance Imaging (MRI) plays a pivotal role as a non-invasive imaging technique in disease identification and progression monitoring. Deep learning, particularly Convolutional Neural Networks (CNN), can extract key biomarkers from complex imaging data. By training CNN models to automatically interpret MRI scans, radiology experts can utilize these advanced analytical tools for more efficient and consistent pathological assessments, thereby enhancing clinical decision support systems. This study develops a deep learning-based method for the automatic classification of Alzheimer's brain MRI images, using convolutional neural networks to categorize MRI images into four stages: no dementia, very mild dementia, mild dementia, and moderate dementia. A CNN model is constructed, learning distinctive features of the images through multi-level feature extraction and performing feature map visualization. Early stopping is employed to prevent overfitting. The model is trained on a training set and evaluated on a test set, with performance metrics including confusion matrix, accuracy, precision, recall, F1 score, Kappa coefficient, Matthew’s coefficient, ROC curve with AUC value, and PQ curve with AP value. The results show that the proposed model effectively differentiates between various categories of MRI images, providing valuable tools for early diagnosis and condition monitoring.",
        "keywords": "",
        "link": "http://dx.doi.org/10.62051/0xherm33"
    },
    {
        "id": 10639,
        "title": "On the Use of Deep Convolutional Neural Networks in Microwave Imaging",
        "authors": "Mohammed Farook Maricar, Amer Zakaria, Nasser Qaddoumi",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/apmc57107.2023.10439686"
    },
    {
        "id": 10640,
        "title": "Multi-Tracker Object Localizer: An Optimal Object Detector Based on Convolutional Neural Networks and Multi-Tracker Optimization Algorithm",
        "authors": "Ehsan Zakeri, Wen-Fang Xie, Ibrahim Babiker",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/m2vip58386.2023.10413372"
    },
    {
        "id": 10641,
        "title": "Adaptive Fault Diagnosis Model for High-Speed Railway Turnout Using Deep Convolutional Neural Networks",
        "authors": "Xiaoyu Jiang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijsn.2023.10058289"
    },
    {
        "id": 10642,
        "title": "Innovative Integration of Convolutional Neural Networks for Enhanced Face Recognition",
        "authors": "Kavita, Rajender Singh Chhillar",
        "published": "2024-3-31",
        "citations": 0,
        "abstract": "The face Recognition technique is important in Computer Vision nowadays. The research study focuses on a Face Recognition system that uses deep learning to identify face photos. Face detection and categorization are carried out using various Convolutional neural network (CNN) models using deep learning methods. Prior research has mostly focused on either the ResNet or DenseNet-based CNN models. The current study combines ResNet and DenseNet to create a hybrid model. The suggested work aims to improve efficiency and accuracy. During the simulation's training and testing phases, categories are taken into account. The present study is centered on the Labeled Faces in the Wild (LFW) dataset. The photos go through an initial noise reduction procedure. Picture quality assessment involves considering measures like MSE, PSNR, and SSIM. Once the suggested model has completed training, it produces high-quality images. The suggested system includes the Innovative CNN approach framework, which combines DenseNet with a noise reduction approach, a segmentation mechanism, and a ResNet model based on CNN. Comparative research was performed to assess the precision of several filtered image collections using different convolutional neural network models. The simulation results show that the proposed model had higher performance and accuracy than traditional ResNet and DenseNet models.\r\n ",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/jes.1740"
    },
    {
        "id": 10643,
        "title": "Speech Command Recognition Based on Convolutional Spiking Neural Networks",
        "authors": "Erik Sadovsky, Maros Jakubec, Roman Jarina",
        "published": "2023-4-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/radioelektronika57919.2023.10109082"
    },
    {
        "id": 10644,
        "title": "Deep Image Clustering by Spiking Neural Networks",
        "authors": "Arash Mahyari, Hadi AliAkbarpour",
        "published": "2023-9-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aipr60534.2023.10440717"
    },
    {
        "id": 10645,
        "title": "Large Kernel Convolutional Neural Networks for Action Recognition Based on RepLKNet",
        "authors": "Runlin Wang",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icicml60161.2023.10424920"
    },
    {
        "id": 10646,
        "title": "Convolutional Neural Networks Using Scalograms for Stress Recognition in Drivers",
        "authors": "Pamela Zontone, Antonio Affanni, Alessandro Piras, Roberto Rinaldo",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/eusipco58844.2023.10290079"
    },
    {
        "id": 10647,
        "title": "Recognition of Static American Sign Language Hand Gestures Using Convolutional Neural Networks",
        "authors": "Sonu Mittal, Aashika jain, Shubham Jain",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4605153"
    },
    {
        "id": 10648,
        "title": "DeepQ Feature Selection and Recognition of Handwritten Prediction Using Convolutional Neural Networks",
        "authors": "A. Sasi Kumar, P. S. Aithal",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4541239"
    },
    {
        "id": 10649,
        "title": "Identification of Covid-19 Using Speech Recognition and Convolutional Neural Networks",
        "authors": "Tharanga Ranaweera, Kasun Karunanayaka",
        "published": "2023-2-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icarc57651.2023.10145735"
    },
    {
        "id": 10650,
        "title": "Occluded Face Recognition Using Deep Convolutional Neural Network with Sparse Representation",
        "authors": "S. Anusha, K. Nimala",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/accai58221.2023.10200930"
    },
    {
        "id": 10651,
        "title": "Foreign object detection system in catenary networks based on novel cascade convolutional neural networks",
        "authors": "Lixiao Wang, Rong Wu, Yonghuan He",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3021339"
    },
    {
        "id": 10652,
        "title": "A novel physical activity recognition approach using deep ensemble optimized transformers and reinforcement learning",
        "authors": "Sajad Ahmadian, Mehrdad Rostami, Vahid Farrahi, Mourad Oussalah",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2024.106159"
    },
    {
        "id": 10653,
        "title": "Convolutional neural network compression for traffic sign recognition",
        "authors": "Yuchen Zhang, Xuefang Zhang",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2678883"
    },
    {
        "id": 10654,
        "title": "IIOT fault detection using multi deep convolutional neural networks",
        "authors": "K. Nithya, R. Kousalya",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/icp.2023.2884"
    },
    {
        "id": 10655,
        "title": "Deep Learning with Convolutional Neural Networks: from Theory to Practice",
        "authors": "Kritika Pandey, Sanskruti Patel",
        "published": "2023-4-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icoei56765.2023.10125854"
    },
    {
        "id": 10656,
        "title": "Review on Real-Time Object Detection Models using Deep Neural Networks",
        "authors": "Lenard Byenkya Nkalubo, Rose Nakibuule",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4331602"
    },
    {
        "id": 10657,
        "title": "Deep Learning-based Rice Leaf Disease Diagnosis using Convolutional Neural Networks",
        "authors": "Gursewak Singh, Ranjit Singh",
        "published": "2023-6-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icscss57650.2023.10169402"
    },
    {
        "id": 10658,
        "title": "Reduced Skeleton Representation for Action Recognition on Graph Convolutional Neural Networks",
        "authors": "Ida Germann, Raphael Memmesheimer, Dietrich Paulus",
        "published": "2023-1-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sii55687.2023.10039092"
    },
    {
        "id": 10659,
        "title": "Evaluation of Deep Convolutional Neural Networks for Detecting Nonpalpable Breast Abnormalities in Mammography",
        "authors": "Imad Zyout",
        "published": "2023-2-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aset56582.2023.10180771"
    },
    {
        "id": 10660,
        "title": "Lung Cancer Detection Using Deep Learning-Based Convolutional Neural Networks",
        "authors": "Somya Srivastav, Kalpna Guleria, Shagun Sharma",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/asiancon58793.2023.10269839"
    },
    {
        "id": 10661,
        "title": "Retracted: Hypertuned Deep Convolutional Neural Network for Sign Language Recognition",
        "authors": "",
        "published": "2023-9-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9793147"
    },
    {
        "id": 10662,
        "title": "FACIAL EXPRESSION RECOGNITION USING CONVOLUTIONAL NEURAL NETWORKS [CNN]",
        "authors": "Akash Raghav, Nitin Tewari,  ",
        "published": "2023-7-1",
        "citations": 0,
        "abstract": "While humans have traditionally excelled at discerning emotions through facial expressions, achieving the same capability with a computer program has proven challenging. However, recent advancements in computer vision and machine learning have made it feasible to recognize emotions accurately. This paper introduces a novel facial emotion identification technique known as Convolutional Neural Networks for Facial Emotion Recognition (FERC). FERC utilizes a twopart convolutional neural network (CNN) architecture: The paper consists of two main sections. The first section is dedicated to removing the background from the image, while the second section focuses on extracting the facial feature vector. The FERC model utilizes an expressional vector (EV) to identify five different regular facial expressions. With its single-level CNN approach, FERC offers improved accuracy compared to commonly used techniques. Moreover, prior to constructing the EV, a novel background removal strategy is implemented to address various potential challenges, such as distance from the camera. The application of FERC in emotion detection holds promise for a wide range of applications, including student predictive learning and lie detection.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33564/ijeast.2023.v08i03.012"
    },
    {
        "id": 10663,
        "title": "Convolutional Neural Networks Model for Medical Radiographic Image Recognition COVID-19 Cases of Madagascar",
        "authors": "",
        "published": "2023-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14738/tecs.115.15678"
    },
    {
        "id": 10664,
        "title": "Content-Adaptive Downsampling in Convolutional Neural Networks",
        "authors": "Robin Hesse, Simone Schaub-Meyer, Stefan Roth",
        "published": "2023-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00478"
    },
    {
        "id": 10665,
        "title": "Guidance and Fault Recognition of Physical Experimental Operations Based on Convolutional Neural Networks",
        "authors": "Yangyang Zhao",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icise-ie60962.2023.10456390"
    },
    {
        "id": 10666,
        "title": "KurdSet Handwritten Digits Recognition Based on Different Convolutional Neural Networks Models",
        "authors": "Sardar Hasen Ali, Maiwan Bahjat Abdulrazzaq",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "Recognition of handwritten digits has garnered significant interest among researchers in the domain of recognizing pattern. This interest stems from the recognition's relevance in various real-life applications, including reading financial checks and official documents, which has remained a persistent obstacle. To address this challenge, researchers have developed numerous algorithms focusing on recognizing handwritten digits across different human languages. This paper presents a new Kurdish Handwritten dataset, consisting of Kurdish characters, digits, texts, and symbols. The dataset consists of 1560 participants, encompassing a broad and varied group. It serves as the primary dataset for training and evaluating algorithms in Kurdish digit recognition. We used Kurdish dataset named (KurdSet) and Arabic dataset for handwritten recognition, which holds 70,000 images of Arabic digits that were written by 700 various participants. Additionally, various models are utilized in the study, including ResNet50, DenseNet121, MobileNet, and a custom CNN (convolutional neural network). Additionally, the models' effectiveness was assessed through the examination of test accuracy, which measures the percentage of correctly classified digits in the evaluation phase. ResNet50 also performs exceptionally well that achieved test accuracy 99.67%, indicating its All models exhibit good performance, DenseNet121 and the Custom CNN Model demonstrate the highest test accuracy of 99.73%, highlighting their superior performance. capabilities in capturing relevant features. Despite its accuracy, MobileNet still exhibits good recognition capability with a test accuracy 99.54%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.18421/tem131-23"
    },
    {
        "id": 10667,
        "title": "HierNet: Image Recognition with Hierarchical Convolutional Networks",
        "authors": "Levente Tempfli, Csanád Sándor",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012321100003636"
    },
    {
        "id": 10668,
        "title": "Theia: Bleed-Through Estimation with Convolutional Neural Networks",
        "authors": "Najib Ishaq, Nathan Hotaling, Nicholas Schaub",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00447"
    },
    {
        "id": 10669,
        "title": "Double-branch deep convolutional neural network-based rice leaf diseases recognition and classification",
        "authors": "Xiong Bi, Hongchun Wang",
        "published": "2023-10-30",
        "citations": 0,
        "abstract": "Deep convolutional neural network (DCNN) has recently made significant strides in classification and recognition of rice leaf disease. The majority of classification models perform disease image recognitions using a collocation patterns including pooling layers, convolutional layers, and fully connected layers, followed by repeating this structure to complete depth increase. However, the key information of the lesion area is locally limited. That is to say, in the case of only performing feature extraction according to the above-mentioned model, redundant and low-correlation image feature information with the lesion area will be received, resulting in low accuracy of the model. For improvement of the network structure and accuracy promotion, here we proposed a double-branch DCNN (DBDCNN) model with a convolutional block attention module (CBAM). The results show that the accuracy of the classic models VGG-16, ResNet-50, ResNet50+CBAM, MobileNet-V2, GoogLeNet, EfficientNet-B1 and Inception-V2 is lower than the accuracy of the model in this paper (98.73%). Collectively, the DBDCNN model here we proposed might be a better choice for classification and identification of rice leaf diseases in the future, based on its novel identification strategy for crop disease diagnosis.",
        "keywords": "",
        "link": "http://dx.doi.org/10.4081/jae.2023.1544"
    },
    {
        "id": 10670,
        "title": "Evaluation of Emotion Recognition in Facial Image Using Attentive Deep Convolutional Neural Network",
        "authors": "Nur Aini, Hilman Ferdinandus Pardede",
        "published": "2023-8-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icitri59340.2023.10249341"
    },
    {
        "id": 10671,
        "title": "Research on MNIST Handwritten Number Recognition Based on Convolutional Neural Networks",
        "authors": "Yanling Yang, Tao Wang",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aibt57480.2023.00012"
    },
    {
        "id": 10672,
        "title": "Enhancing Convolutional Neural Networks via separately trained kernels for digit recognition",
        "authors": "Zhaochen Yang",
        "published": "2024-3-29",
        "citations": 0,
        "abstract": "This paper introduces a novel methodology for pre-training neural networks. Instead of the traditional approach of running a single classifier for all objects, the method used in the research constructs individual classifiers for each object to extract unique features. These classifiers, in essence, act as a series of binary classifiers, each pre-training a distinct set of convolutional kernels. These individually trained kernels are then combined and processed by a comprehensive classifier. The methodology leverages the power of individual feature extraction and collaborative processing to enhance the overall performance of the classifier. The results demonstrate that this innovative pre-training approach leads to a significant improvement in classification performance, yielding higher accuracy compared to conventional methods. It underscores the benefits of incorporating individual object feature extraction and combined processing in the pre-training phase of neural network-based classification tasks. The study opens new paths for improving pre-training methods in neural networks, with potential applications in various fields that require high-accuracy object recognition. Future work will delve deeper into the potential challenges associated with model complexity and overfitting, and will also include a more comprehensive evaluation using extensive training, cross-validation, and independent test sets. This will further validate the effectiveness of our proposed pre-training methodology.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/54/20241659"
    },
    {
        "id": 10673,
        "title": "Artificial intelligence-based Medicine Recognition System using faster Recurrent Convolutional Neural Networks",
        "authors": "P.Ranjith Kumar, Tarun Jaiswal, Satyabrata Jena",
        "published": "2023",
        "citations": 0,
        "abstract": "Recently, chronic patients are taking multiple medications incorrectly and taking the wrong medications due to similarity of drugs.It is possible that taking the improper medication can result in hazardous interactions with other medications or they will counteract the intended benefits of the medications, resulting in extra severe repercussions such as acute complications. The conventional methods are failed to provide the maximum efficiency. Therefore, this article is focused on implementation of faster recurrent convolutional neural networks (FR-CNN), which is capable of extracting the features from images. FR-CNN mainly used to analyze the patterns of the medicines and extracts the deep features. Further, classification of medicines is carried out by comparing with ground truth labels. The simulation results shows that the proposed system resulted in superior performance as compared to state of art approaches.",
        "keywords": "",
        "link": "http://dx.doi.org/10.58599/ijsmien.2023.1105"
    },
    {
        "id": 10674,
        "title": "VC dimensions of group convolutional neural networks",
        "authors": "Philipp Christian Petersen, Anna Sepliarskaia",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.10.012"
    },
    {
        "id": 10675,
        "title": "Deep Convolutional Neural Networks Based on Knowledge Distillation for Offline Handwritten Chinese Character Recognition",
        "authors": "Hongli He, Zongnan Zhu, Zhuo Li, Yongping Dan",
        "published": "2024-3-20",
        "citations": 0,
        "abstract": "Deep convolutional neural networks (DNNs) have achieved outstanding performance in this field. Meanwhile, handwritten Chinese character recognition (HCCR) is a challenging area of research in the field of computer vision. DNNs require a large number of parameters and high memory consumption. To address these issues, this paper proposes an approach based on an attention mechanism and knowledge distillation. The attention mechanism improves the feature extraction and the knowledge distillation reduces the number of parameters. The experimental results show that ResNet18 achieves a recognition accuracy of 97.63% on the HCCR dataset with 11.25 million parameters. Compared with other methods, this study improves the performance for HCCR.",
        "keywords": "",
        "link": "http://dx.doi.org/10.20965/jaciii.2024.p0231"
    },
    {
        "id": 10676,
        "title": "Optimizing Convolutional Neural Networks Utilizing Tensor Decomposition Techniques for Large-Scale Image Recognition Tasks",
        "authors": "Tiancheng Hu",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "Convolutional Neural Networks (CNNs) are integral to numerous applications in today's digital landscape. However, their computational demands often result in slow operation, especially when resources are constrained. This study introduces two tensor decomposition methods aimed at optimizing the performance of CNNs by minimizing the total number of operations and weights, while maintaining accuracy. The first method employs Canonical Polyadic (CP) decomposition to divide the convolutional layer into multiple rank 1 tensors. The second method uses Tucker decomposition to break down the convolutional layer into a compact core tensor and several matrices. The effectiveness of these methods was evaluated on widely-used convolutional architectures, VGG16 and LeNet, by substituting their convolutional layers with a series of decomposed layers, implemented using PyTorch and TensorLy. The CP decomposition method achieved a computational speed-up of 43% with a minimal accuracy reduction of less than 0.12%. Similarly, Tucker decomposition resulted in a 37% speed-up with an accuracy decrease of less than 0.16%. These findings suggest that the proposed tensor decomposition methods can significantly enhance the efficiency of CNNs without significantly impacting their performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.47611/jsrhs.v12i3.4916"
    },
    {
        "id": 10677,
        "title": "Imperceptible Image Watermark Embedding using Multi-resolution Wavelet Decomposition and Deep Convolutional Neural Networks",
        "authors": "Amal Khalifa",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icist59754.2023.10367058"
    },
    {
        "id": 10678,
        "title": "Adaptive fault diagnosis model for high-speed railway turnout using deep convolutional neural networks",
        "authors": "Xiaoyu Jiang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijsn.2023.134134"
    },
    {
        "id": 10679,
        "title": "A Comparative Study of Deep Convolutional Neural Networks for Musculoskeletal X-Ray Images",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18178/wcse.2023.06.015"
    },
    {
        "id": 10680,
        "title": "An Overview and Application of Deep Convolutional Neural Networks for Medical Image Segmentation",
        "authors": "Sanskruti Patel",
        "published": "2023-2-2",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icais56108.2023.10073857"
    },
    {
        "id": 10681,
        "title": "Expand Object Detection Dataset Automatically via Deep Learning Neural Networks",
        "authors": "Bing Liu, Subramaniam Ganesan",
        "published": "2023-9-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccit58132.2023.10273981"
    },
    {
        "id": 10682,
        "title": "Image recognition based on convolutional deep confidence networks",
        "authors": "Baifang Niu, Hu Li, Wenxin Chen, Hongjun Han",
        "published": "2023-4-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsp58490.2023.10248879"
    },
    {
        "id": 10683,
        "title": "Classification of Some Barley Cultivars with Deep Convolutional Neural Networks",
        "authors": "Fatih BAYRAM, Mustafa YILDIZ",
        "published": "2023-1-31",
        "citations": 2,
        "abstract": "The homogeneity of the seeds is an important factor in terms of processing, transportation, storage, and product quality of agricultural products. It is possible to classify the grain polymorphism of barley cultivars, which are economically important among cereal crops, in a short time with computer vision methods with high accuracy rate and almost zero cost. In this research, a novel image database consisting of 2800 images were created to classify 14 barley cultivars. Six different deep convolutional neural network models were designed based on a transfer learning method with pretrained DenseNet-121, DenseNet-169, DenseNet-201, InceptionResNetV2, MobileNetV2 and Xception networks. The models were trained and evaluated with test-time augmentation method, the best performance was obtained from DenseNet-169 model with average 96.07% recall, 96.29% precision, 96.07% F1-score, and 96.07% accuracy on a test set independent of the training set. The results showed that the transfer learning method performed using additional layers such as dropout and data augmentation with sufficient data samples in these images with high similarities prevented overfitting by increasing the model performance. As a result, it can be suggested that the provided web tool based on the transfer model has an encouraging performance in identifying seedswith a high number of cultivars such as barley. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.15832/ankutbd.815230"
    },
    {
        "id": 10684,
        "title": "Convolutional Neural Networks for Deep Spoken Keyword Spotting",
        "authors": "Nayyer Aafaq, Mehran Saleem, Jahanzeb Tariq Khan, Imran Hafeez Abbasi",
        "published": "2023-2-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icai58407.2023.10136648"
    },
    {
        "id": 10685,
        "title": "Enhancing Breast Cancer Classification in Mammography Images Using Multi-View Deep Convolutional Neural Networks",
        "authors": "Swathi Baswaraju",
        "published": "2023-9-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icosec58147.2023.10276164"
    },
    {
        "id": 10686,
        "title": "Retracted: Application of Convolutional Neural Network Algorithm under Deep Learning in Digital Clothing Design",
        "authors": "",
        "published": "2023-6-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9862189"
    },
    {
        "id": 10687,
        "title": "Convolutional Neural Networks for Determining the Ion Beam Impact on a Space Debris Object",
        "authors": "M. REDKA, C. KHOROSHYLOV",
        "published": "2023-12-22",
        "citations": 0,
        "abstract": "Introduction. Space debris is a serious problem that significantly complicates space activity. This problem can be mitigated by active space debris removal. The ion beam shepherd (IBS) concept assumes the contactless removal of a space debris object (SDO) by the plume of an ion thruster (IT). Techniques for determining the force impact from the IT to the SDO are of crucial importance for implementing the IBS concept.Problem Statement. A launcher’s upper stage, approximated by a cylinder, is considered an SDO deorbited by the plume of the IT. The SDO can change its orientation and position relative to the shepherd satellite. The shepherd satellite shall be able to determine the force transmitted to the SDO by the IT, using only SDO’s images as the input information.Purpose. The study aims to develop a neural net model that can map an SDO image to the force transmitted by an IT plume to this object and estimate the accuracy of such models.Material and Methods. Plasma physics methods are used to obtain ground truth values of the ion beam force. The deep learning methodology is applied to create neural net models.Results. Three different approaches for end-to-end ion force determination have been investigated. The first model uses a single convolutional neural net (CNN). The second model is an ensemble network consisting of four sub-models, and a classifier is used to pick the correct sub-model. The last model is similar to the first one but is trained on all images used for the second model. After training, all three models’ accuracy and computational complexity are estimated. These estimates demonstrate the acceptable performance of CNN-based models.Conclusions. This paper demonstrates that CNNs can be used to determine the force impact without knowledge about the SDO position and orientation and significantly faster than the previous methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.15407/scine19.06.019"
    },
    {
        "id": 10688,
        "title": "Learning Point Processes and Convolutional Neural Networks for Object Detection in Satellite Images",
        "authors": "Jules Mabon, Mathias Ortner, Josiane Zerubia",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "Convolutional neural networks (CNN) have shown great results for object-detection tasks by learning texture and pattern-extraction filters. However, object-level interactions are harder to grasp without increasing the complexity of the architectures. On the other hand, Point Process models propose to solve the detection of the configuration of objects as a whole, allowing the factoring in of the image data and the objects’ prior interactions. In this paper, we propose combining the information extracted by a CNN with priors on objects within a Markov Marked Point Process framework. We also propose a method to learn the parameters of this Energy-Based Model. We apply this model to the detection of small vehicles in optical satellite imagery, where the image information needs to be complemented with object interaction priors because of noise and small object sizes.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/rs16061019"
    },
    {
        "id": 10689,
        "title": "Vehicle detection systems for intelligent driving using deep convolutional neural networks",
        "authors": "Rahib Abiyev, Murat Arslan",
        "published": "2023-5-2",
        "citations": 3,
        "abstract": "AbstractIn the paper, a vision-based vehicle identification system is proposed for autonomous intelligent car driving. The accurate detection of obstacles (vehicles) during intelligent car driving allows avoiding crashes, preventing accidents, saving people’s lives and reducing harm. The vehicle detection system, which uses low-quality images captured by a monocular video camera mounted at the front of the car, is based on convolutional neural networks (CNN). The CNN can extract global features of the images using convolutional layers and achieves more accurate, and faithful contours of vehicles. The CNN structure proposed in the paper provides high-accuracy detection of vehicle images. The experiments that have been performed using GTI dataset demonstrate that the CNN-based vehicle detection system achieves very accurate results and is more robust to different variations of images.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s44163-023-00062-8"
    },
    {
        "id": 10690,
        "title": "Joint matrix decomposition for deep convolutional neural networks compression",
        "authors": "Shaowu Chen, Jiahao Zhou, Weize Sun, Lei Huang",
        "published": "2023-1",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neucom.2022.10.021"
    },
    {
        "id": 10691,
        "title": "A Novel Deep Convolutional Neural Network Approach using Jacobi Polynomial and Laplacian Function (JPLF) in Recognition of Plant Leaf Disease",
        "authors": "Pushparani S Janes,  , P L Chithra",
        "published": "2024-4-3",
        "citations": 0,
        "abstract": "Background/Objectives: Enhancing agricultural productivity is crucial for fostering economic growth. Plant diseases significantly threaten crops, necessitating timely detection to mitigate adverse impacts on quality, quantity, and overall productivity. This research addresses the importance of early disease detection in agriculture and proposes an innovative method utilizing Jacobian Polynomial and Laplacian Function for precise identification. Methods: Efficient monitoring of large-scale crop farms with minimal workforce is essential. To achieve this, an automatic method for plant disease detection is proposed. The method leverages Jacobian polynomials to expand input features, mitigating correlation issues among input vectors. The expanded Jacobi polynomial is the input vector for a backpropagation algorithm with a novel activation function based on the Laplacian function. Findings: The efficacy of the proposed JPLF model is demonstrated through the accurate identification of leaf diseases, achieving a high testing accuracy of 92.07%. Comparative analysis with existing models, such as CNN with MobileNet V2 (85.38%) and the IoU model (83.75%), highlights the superiority of the JPLF model in plant disease detection. Novelty: To overcome the limitations of existing approaches, the incorporation of Jacobian polynomials plays a pivotal role in expanding input features. This expansion aids in eliminating correlations among input vectors, enhancing the efficacy of disease detection. The proposed model, Jacobi Polynomial and Laplacian Function (JPLF) introduces a unique activation function based on the Laplacian function, improving accuracy.  Keywords: Plant Disease Detection, Jacobi Polynomial, Laplacian Transform, Deep Learning Model, Feature Expansion",
        "keywords": "",
        "link": "http://dx.doi.org/10.17485/ijst/v17i14.2651"
    },
    {
        "id": 10692,
        "title": "A Kinship Authentication Algorithm Based on Deep Convolutional Neural Networks",
        "authors": "Yichen Hu, Hujun Geng",
        "published": "2023-8-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ccpqt60491.2023.00014"
    },
    {
        "id": 10693,
        "title": "Hybrid Deep Convolutional Neural Network based Speaker Recognition for Noisy Speech Environments",
        "authors": "Venkata Subba Reddy Gade, M. Sumathi",
        "published": "2023-5-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaaic56838.2023.10141080"
    },
    {
        "id": 10694,
        "title": "Driving Behaviors Recognition Using Deep Neural Networks",
        "authors": "Karam Darwish, Majd Ali",
        "published": "2023-7-10",
        "citations": 0,
        "abstract": "Road accidents are skyrocketing, and traffic safety is a severe problem around the world. Many road traffic deaths are related to drivers’ unsafe behaviors. In this paper, we propose two different deep-learning models which classify the driver’s actions in a 60-second time frame into two main categories: Normal and Aggressive driving based on GPS data collected at 1 Hz, which is later preprocessed and passed to the proposed models to identify dominant driving behavior in each time frame. The models achieved an accuracy of 93.75 percent in real-world tests, which proves the efficiency of this method in driving behavior recognition.",
        "keywords": "",
        "link": "http://dx.doi.org/10.14464/ess.v10i5.592"
    },
    {
        "id": 10695,
        "title": "Feature filtering module of convolutional neural networks for image recognition system",
        "authors": "Shining Chen, Xianghua Ma",
        "published": "2023-4-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2673212"
    },
    {
        "id": 10696,
        "title": "Motion recognition of football players based on deformable convolutional neural networks",
        "authors": "Lingqiang Xuan, Di Zhang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijbm.2024.10063378"
    },
    {
        "id": 10697,
        "title": "Revolutionizing image recognition: The dominance and future potential of convolutional neural networks",
        "authors": "Xingyu Ye",
        "published": "2024-3-19",
        "citations": 0,
        "abstract": "As AI technology advances swiftly and diverse industries increasingly require image processing, traditional image recognition methods are displaying their limitations. This paper explores the evolving landscape of AI technology in the context of image processing and highlights the limitations of traditional image recognition methods. With the proliferation of big data and the evolution of deep learning, convolutional neural networks (CNNs) have emerged as a dominant solution for image recognition across diverse industries. The paper begins by elucidating the architecture of CNNs and introduces commonly employed traditional CNN models. Furthermore, it offers practical insights into the application of CNNs within various industries, illuminating the path for future CNN development. The transformative potential of CNNs is underscored, as they possess the ability to extract intricate patterns from images, reshaping numerous domains. The paper's primary focus is on CNNs in the realm of image recognition, encompassing efforts to enhance precision and efficiency in CNN-based image recognition, as well as addressing real-world challenges in this domain using CNNs.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/48/20241257"
    },
    {
        "id": 10698,
        "title": "Retracted: Long Jump Action Recognition Based on Deep Convolutional Neural Network",
        "authors": "",
        "published": "2023-10-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9835615"
    },
    {
        "id": 10699,
        "title": "Percolation detection using convolutional deep neural networks",
        "authors": "Esteban Iriarte, Joaquín Peralta, Claudia Loyola, Sergio Davis",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0133188"
    },
    {
        "id": 10700,
        "title": "MRI brain tumor detection and classification using parallel deep convolutional neural networks",
        "authors": "Takowa Rahman, Md Saiful Islam",
        "published": "2023-4",
        "citations": 24,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.measen.2023.100694"
    },
    {
        "id": 10701,
        "title": "Deep Learning-based Automated Detection of Retinal Diseases with Convolutional Neural Networks",
        "authors": " Manivasagam, Shweta Singh, Shri Bhagwan",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470689"
    },
    {
        "id": 10702,
        "title": "Time Series Recognition with Convolutional and Recursive Neural Networks in BSPM",
        "authors": "Dariusz Wójcik, Tomasz Rymarczyk, Łukasz Maciura, Michał Oleszek, Przemysław Adamkiewicz",
        "published": "2023-5-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iiphdw54739.2023.10124427"
    },
    {
        "id": 10703,
        "title": "Cross-data recognition on sign language letters based on convolutional neural networks",
        "authors": "Zhixi Zhu",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "With an estimated 1.5 billion hearing-impaired people globally, sign language is a vital means of communication among them. Meanwhile, the complexity and diversity of sign languages across different regions bring challenges to researchers. As existing studies in this field usually lack the implementation of recognition models with multiple datasets, which limits their practical value in real-life scenarios, this study intends to get around this constraint. This work constructs a baseline American Sign Language Letter Recognition model using Convolutional Neural Network (CNN) and then optimizes it to enhance its ability. Finally, cross-data recognition is carried out. In order to train and evaluate the model, this study gathers data from several sources, including the MNIST sign language set and real-life photos. It also investigates how data augmentation affects recognition ability. Consequently, the CNN model is able to recognize hand gestures for different alphabetic letters in solid backgrounds. Its accurate rate of it reaches about 99.83%. For the extra real-life dataset, which contains 96 images, the model could still detect the majority of the images with sign language equivalents, despite some accuracy loss in more crowded backgrounds. This work, in general, concentrates on the potential of CNNs for sign language identification and highlights the significance of cross-data recognition in creating useful recognition models.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/15/20230847"
    },
    {
        "id": 10704,
        "title": "Fruits Recognition using Deep Convolutional Neural Network for Low Computing Device",
        "authors": "Irene Anindaputri Iswanto",
        "published": "2023-5-31",
        "citations": 0,
        "abstract": "Artificial intelligence is one of the most developed fields in Computer Science where a lot of researches had been done to make the computer smarter to perform human-like task. One of the most common human-life task research that had been done is object recognition. Convolutional Neural Network is one of the most popular deep learning model to perform a good object recognition. While improving CNN model can be done by simply increasing the depth of its architecture, some researchers prove that as the CNN architecture go deeper, the accuracy will get worse. ResNet, with their residual layer, successfully lift the limitation, but ResNet by itself is too heavy for a mobile or low computing device. This paper proposes a new model which could reach the accuracy of ResNet while having faster prediction time. The proposed model and other state-of-the-art models had been trained on our own fruits and vegetables dataset. The result shows that the proposed model can reach the same accuracy as Resnet110 and overcome the accuracy of DenseNet121 while being faster than those models.",
        "keywords": "",
        "link": "http://dx.doi.org/10.21512/emacsjournal.v5i2.9986"
    }
]