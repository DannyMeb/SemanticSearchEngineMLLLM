[
    {
        "id": 24671,
        "title": "Medical Image Detection and Recognition Using Machine Learning and Deep Learning",
        "authors": "M. Arun Anoop, P. Karthikeyan, S. Poonkuntran",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003366249-1"
    },
    {
        "id": 24672,
        "title": "Machine Learning and Deep Learning Techniques for Medical Image Recognition",
        "authors": "Ben Othman Soufiene, Chinmay Chakraborty",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003366249"
    },
    {
        "id": 24673,
        "title": "Review for \"Deep learning‐based recognition method of red bed soft rock image\"",
        "authors": "",
        "published": "2022-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/gj.4752/v2/review1"
    },
    {
        "id": 24674,
        "title": "Review for \"Deep learning‐based recognition method of red bed soft rock image\"",
        "authors": "",
        "published": "2023-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/gj.4752/v2/review2"
    },
    {
        "id": 24675,
        "title": "Review for \"Deep learning‐based recognition method of red bed soft rock image\"",
        "authors": "",
        "published": "2023-3-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/gj.4752/v3/review1"
    },
    {
        "id": 24676,
        "title": "Review for \"Deep learning‐based recognition method of red bed soft rock image\"",
        "authors": "",
        "published": "2022-10-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/gj.4752/v1/review1"
    },
    {
        "id": 24677,
        "title": "Multi-Instance Multi-Stage Deep Learning for Medical Image Recognition",
        "authors": "Zhennan Yan, Yiqiang Zhan, Shaoting Zhang, Dimitris Metaxas, Xiang Sean Zhou",
        "published": "2017",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-810408-8.00006-7"
    },
    {
        "id": 24678,
        "title": "Document Image Dewarping using Deep Learning",
        "authors": "Vijaya Ramanna, Saqib Bukhari, Andreas Dengel",
        "published": "2019",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007368405240531"
    },
    {
        "id": 24679,
        "title": "Review for \"BesNet: binocular ferrographic image recognition model based on deep learning technology\"",
        "authors": "",
        "published": "2023-6-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1108/ilt-05-2023-0150/v2/review1"
    },
    {
        "id": 24680,
        "title": "Review for \"Deep learning‐based recognition method of red bed soft rock image\"",
        "authors": "",
        "published": "2022-11-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/gj.4752/v1/review2"
    },
    {
        "id": 24681,
        "title": "Review for \"BesNet: binocular ferrographic image recognition model based on deep learning technology\"",
        "authors": "",
        "published": "2023-6-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1108/ilt-05-2023-0150/v1/review1"
    },
    {
        "id": 24682,
        "title": "DECIMER - Towards Deep Learning for Chemical Image Recognition",
        "authors": "Kohulan Rajan, Achim Zielesny, Christoph Steinbeck",
        "published": "No Date",
        "citations": 0,
        "abstract": "The automatic recognition of chemical structure diagrams from the literature is an indispensable component of workflows to re-discover information about chemicals and to make it available in open-access databases. Here we report preliminary findings in our development of DECIMER (Deep lEarning for Chemical ImagE Recognition), a deep learning method based on existing show-and-tell deep neural networks which makes very few assumptions about the structure of the underlying problem. The training state reported here does not yet rival the performance of existing traditional approaches, but we present evidence that our method will reach a comparable detection power with sufficient training time. Training success of DECIMER depends on the input data representation: DeepSMILES are clearly superior over SMILES and we have preliminary indication that the recently reported SELFIES outperform DeepSMILES. An extrapolation of our results towards larger training data sizes suggest that we might be able to achieve >90% accuracy with about 60 to 100 million training  structures, so that training can be completed within several months on a single GPU. This work is completely based on open-source software and open data and is available to the general public for any purpose.",
        "link": "http://dx.doi.org/10.26434/chemrxiv.12464420"
    },
    {
        "id": 24683,
        "title": "Research on Image Recognition based on Reinforcement Learning",
        "authors": "Jiabin Luo, Rongzhen Luo",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10166036"
    },
    {
        "id": 24684,
        "title": "DECIMER - Towards Deep Learning for Chemical Image Recognition",
        "authors": "Kohulan Rajan, Achim Zielesny, Christoph Steinbeck",
        "published": "No Date",
        "citations": 0,
        "abstract": "The automatic recognition of chemical structure diagrams from the literature is an indispensable component of workflows to re-discover information about chemicals and to make it available in open-access databases. Here we report preliminary findings in our development of DECIMER (Deep lEarning for Chemical ImagE Recognition), a deep learning method based on existing show-and-tell deep neural networks which makes very few assumptions about the structure of the underlying problem. The training state reported here does not yet rival the performance of existing traditional approaches, but we present evidence that our method will reach a comparable detection power with sufficient training time. Training success of DECIMER depends on the input data representation: DeepSMILES are clearly superior over SMILES and we have preliminary indication that the recently reported SELFIES outperform DeepSMILES. An extrapolation of our results towards larger training data sizes suggest that we might be able to achieve >90% accuracy with about 60 to 100 million training structures, so that training can be completed within several months on a single GPU. This work is completely based on open-source software and open data and is available to the general public for any purpose.",
        "link": "http://dx.doi.org/10.26434/chemrxiv.12464420.v1"
    },
    {
        "id": 24685,
        "title": "The Study of Traditional Pest Image Recognition and Deep Learning Pest Image Recognition",
        "authors": "Chengrui You",
        "published": "2023-10-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdacai59742.2023.00120"
    },
    {
        "id": 24686,
        "title": "DECIMER - Towards Deep Learning for Chemical Image Recognition",
        "authors": "Kohulan Rajan, Achim Zielesny, Christoph Steinbeck",
        "published": "No Date",
        "citations": 0,
        "abstract": "The automatic recognition of chemical structure diagrams from the literature is an indispensable component of workflows to re-discover information about chemicals and to make it available in open-access databases. Here we report preliminary findings in our development of DECIMER (Deep lEarning for Chemical ImagE Recognition), a deep learning method based on existing show-and-tell deep neural networks which makes very few assumptions about the structure of the underlying problem. The training state reported here does not yet rival the performance of existing traditional approaches, but we present evidence that our method will reach a comparable detection power with sufficient training time. Training success of DECIMER depends on the input data representation: DeepSMILES are clearly superior over SMILES and we have preliminary indication that the recently reported SELFIES outperform DeepSMILES. An extrapolation of our results towards larger training data sizes suggest that we might be able to achieve >90% accuracy with about 60 to 100 million training structures, so that training can be completed within several months on a single GPU. This work is completely based on open-source software and open data and is available to the general public for any purpose.",
        "link": "http://dx.doi.org/10.26434/chemrxiv.12464420.v2"
    },
    {
        "id": 24687,
        "title": "Research and Design of Smart Home Speech Recognition System Based on Deep Learning",
        "authors": "Pengyu Wang",
        "published": "2020-7",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvidl51233.2020.00-98"
    },
    {
        "id": 24688,
        "title": "A Novel Architecture based on Deep Learning for Scene Image Recognition",
        "authors": "Bhavesh Shri Kumar, Naren J, Vithya G, Prahathish K",
        "published": "2019-2-20",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.37200/ijpr/v23i1/pr190251"
    },
    {
        "id": 24689,
        "title": "Image Denoising to enhance Character Recognition using Deep Learning",
        "authors": "Vanlal ruata, J. Hussain",
        "published": "No Date",
        "citations": 2,
        "abstract": "Abstract\nIn this paper, we proposed implementing a Deep Convolutional Neural Network. A relationship between a noisy character image to its clean counter-part are mapped using Deep Convolutional Neural Network.The overall process is divided into two stages: noise type classification and image denoising. Firstly, the noise type classification identifies the types of noise, and based on this noise type, a particular denoising model is selected, which increases the image denoising performance. The denoising network inputs a noisy image and a target of its clean corresponding image during the training. After the mapping function is trained, the generated model performs character image denoising. Then, on each band, a trained mapping function perform image denoising irrespective of the other band. Finally, each block is assembled to generate a clean image. In this paper, the MNIST and Char74K dataset of handwritten digits diluted with artificial noise divided into ten types are used for experimentation.. Our experimental results show that the proposed techniques perform better image denoising ascompared to the existing methods, both in terms of image noise type classification and image denoising. The overall Character recognition accuracy increased by 66% after performing the proposed denoising technique.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-571989/v1"
    },
    {
        "id": 24690,
        "title": "Deep Learning Methods for Brain Tumor Segmentation",
        "authors": "Marwen Sakli, Chaker Essid, Bassem Ben Salah, Hedi Sakli",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003366249-11"
    },
    {
        "id": 24691,
        "title": "Decision letter for \"BesNet: binocular ferrographic image recognition model based on deep learning technology\"",
        "authors": "",
        "published": "2023-6-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1108/ilt-05-2023-0150/v1/decision1"
    },
    {
        "id": 24692,
        "title": "Decision letter for \"Deep learning‐based recognition method of red bed soft rock image\"",
        "authors": "",
        "published": "2023-1-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/gj.4752/v2/decision1"
    },
    {
        "id": 24693,
        "title": "Application of Unsupervised Deep Learning in Road Image Recognition",
        "authors": "",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.38007/proceedings.0000409"
    },
    {
        "id": 24694,
        "title": "DECIMER 1.0: Deep Learning for Chemical Image Recognition using Transformers",
        "authors": "Kohulan Rajan, Achim Zielesny, Christoph Steinbeck",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The amount of data available on chemical structures and their properties has increased exponentially over the past decades. In particular, articles published before the mid-1990 are available only in printed or scanned form. The extraction and storage of data from those articles in a publicly accessible database are desirable, but doing this manually is a slow and error-prone process. In order to extract chemical structure depictions and convert them into a computer-readable format, optical chemical structure recognition (OCSR) tools were developed where the best performing OCSR tools are mostly rule-based.</p><p> </p><p>The DECIMER (Deep lEarning for Chemical ImagE Recognition) project was launched to address the OCSR problem with the latest computational intelligence methods to provide an automated open-source software solution. Various current deep learning approaches were explored to seek a best-fitting solution to the problem. In a preliminary communication, we outlined the prospect of being able to predict SMILES encodings of chemical structure depictions with about 90% accuracy using a dataset of 50-100 million molecules. In this article, the new DECIMER model is presented, a transformer-based network, which can predict SMILES with above 96% accuracy from depictions of chemical structures without stereochemical information and above 89% accuracy for depictions with stereochemical information.</p><p><br></p>",
        "link": "http://dx.doi.org/10.26434/chemrxiv.14479287"
    },
    {
        "id": 24695,
        "title": "Research on image recognition based on neural network model learning algorithm",
        "authors": "Shuxuan Feng, Jun Lu",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10164845"
    },
    {
        "id": 24696,
        "title": "Decision letter for \"BesNet: binocular ferrographic image recognition model based on deep learning technology\"",
        "authors": "",
        "published": "2023-6-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1108/ilt-05-2023-0150/v2/decision1"
    },
    {
        "id": 24697,
        "title": "Image Recognition using Deep Learning Techniques",
        "authors": "",
        "published": "2021-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.37896/jxu15.6/005"
    },
    {
        "id": 24698,
        "title": "Decision letter for \"Deep learning‐based recognition method of red bed soft rock image\"",
        "authors": "",
        "published": "2023-3-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/gj.4752/v3/decision1"
    },
    {
        "id": 24699,
        "title": "Decision letter for \"Deep learning‐based recognition method of red bed soft rock image\"",
        "authors": "",
        "published": "2022-11-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/gj.4752/v1/decision1"
    },
    {
        "id": 24700,
        "title": "Computer Vision Approaches in Radiograph Image Analysis",
        "authors": "Abdelbaki Souid, Ben Othman Soufiene, Hedi Sakli",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003366249-10"
    },
    {
        "id": 24701,
        "title": "Gesture Recognition for UAV-based Rescue Operation based on Deep Learning",
        "authors": "Chang Liu, Tamás Szirányi",
        "published": "2021",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010522001800187"
    },
    {
        "id": 24702,
        "title": "DECIMER 1.0: Deep Learning for Chemical Image Recognition using Transformers",
        "authors": "Kohulan Rajan, Achim Zielesny, Christoph Steinbeck",
        "published": "No Date",
        "citations": 0,
        "abstract": "The amount of data available on chemical structures and their properties has increased steadily over the past decades. In particular, articles published before the mid-1990 are available only in printed or scanned form. The extraction and storage of data from those articles in a publicly accessible database are desirable, but doing this manually is a slow and error-prone process. In order to extract chemical structure depictions and convert them into a computer-readable format, optical chemical structure recognition (OCSR) tools were developed where the best performing OCSR tools are mostly rule-based. The DECIMER (Deep lEarning for Chemical ImagE Recognition) project was launched to address the OCSR problem with the latest computational intelligence methods to provide an automated open-source software solution. Various current deep learning approaches were explored to seek a best-fitting solution to the problem. In a preliminary communication, we outlined the prospect of being able to predict SMILES encodings of chemical structure depictions with about 90% accuracy using a dataset of 50-100 million molecules. In this article, the new DECIMER model is presented, a transformer-based network, which can predict SMILES with above 96% accuracy from depictions of chemical structures without stereochemical information and above 89% accuracy for depictions with stereochemical information.",
        "link": "http://dx.doi.org/10.33774/chemrxiv-2021-9j7wg-v2"
    },
    {
        "id": 24703,
        "title": "DECIMER 1.0: Deep Learning for Chemical Image Recognition using Transformers",
        "authors": "Kohulan Rajan, Achim Zielesny, Christoph Steinbeck",
        "published": "No Date",
        "citations": 0,
        "abstract": "The amount of data available on chemical structures and their properties has increased steadily over the past decades. In particular, articles published before the mid-1990 are available only in printed or scanned form. The extraction and storage of data from those articles in a publicly accessible database are desirable, but doing this manually is a slow and error-prone process. In order to extract chemical structure depictions and convert them into a computer-readable format, optical chemical structure recognition (OCSR) tools were developed where the best performing OCSR tools are mostly rule-based. The DECIMER (Deep lEarning for Chemical ImagE Recognition) project was launched to address the OCSR problem with the latest computational intelligence methods to provide an automated open-source software solution. Various current deep learning approaches were explored to seek a best-fitting solution to the problem. In a preliminary communication, we outlined the prospect of being able to predict SMILES encodings of chemical structure depictions with about 90% accuracy using a dataset of 50-100 million molecules. In this article, the new DECIMER model is presented, a transformer-based network, which can predict SMILES with above 96% accuracy from depictions of chemical structures without stereochemical information and above 89% accuracy for depictions with stereochemical information.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2021-9j7wg-v2"
    },
    {
        "id": 24704,
        "title": "Investigation of the theory and applications of deep learning-based image recognition",
        "authors": "Likai Cai",
        "published": "2023-6-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2681279"
    },
    {
        "id": 24705,
        "title": "Deep Learning-Based Emotion Recognition through Facial Expressions",
        "authors": "Sarunya Kanjanawattana, Piyapong Kittichaiwatthana, Komsan Srivisut, Panchalee Praneetpholkrang",
        "published": "2023-6",
        "citations": 0,
        "abstract": "Nowadays, humans can communicate easily with others by recognizing speech and text characters, particularly facial expressions. In human communication, it is critical to comprehend their emotion or implicit expression. Indeed, facial expression recognition is vital for analyzing the emotions of conversation partners, which can contribute to a series of matters, including mental health consulting. This technique enables psychiatrists to select appropriate questions based on their patients’ current emotional state. The purpose of this study was to develop a deep learningbased model for detecting and recognizing emotions on human faces. We divided the experiment into two parts: Faster R-CNN and mini-Xception architecture. We concentrated on four distinct emotional states: angry, sad, happy, and neutral. Both models implemented using the Faster R-CNN and the mini-Xception architectures were compared during the evaluation process. The findings indicate that the mini-Xception architecture model produced a better result than the Faster R-CNN. This study will be expanded in the future to include the detection of complex emotions such as sadness.",
        "link": "http://dx.doi.org/10.18178/joig.11.2.140-145"
    },
    {
        "id": 24706,
        "title": "Efficient deep learning of image denoising using patch complexity local divide and deep conquer",
        "authors": "Inpyo Hong, Youngbae Hwang, Daeyoung Kim",
        "published": "2019-12",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patcog.2019.06.011"
    },
    {
        "id": 24707,
        "title": "DECIMER 1.0: Deep Learning for Chemical Image Recognition using Transformers",
        "authors": "Kohulan Rajan, Achim Zielesny, Christoph Steinbeck",
        "published": "No Date",
        "citations": 0,
        "abstract": "The amount of data available on chemical structures and their properties has increased exponentially over the past decades. In particular, articles published before the mid-1990 are available only in printed or scanned form. The extraction and storage of data from those articles in a publicly accessible database are desirable, but doing this manually is a slow and error-prone process. In order to extract chemical structure depictions and convert them into a computer-readable format, optical chemical structure recognition (OCSR) tools were developed where the best performing OCSR tools are mostly rule-based. The DECIMER (Deep lEarning for Chemical ImagE Recognition) project was launched to address the OCSR problem with the latest computational intelligence methods to provide an automated open-source software solution. Various current deep learning approaches were explored to seek a best-fitting solution to the problem. In a preliminary communication, we outlined the prospect of being able to predict SMILES encodings of chemical structure depictions with about 90% accuracy using a dataset of 50-100 million molecules. In this article, the new DECIMER model is presented, a transformer-based network, which can predict SMILES with above 96% accuracy from depictions of chemical structures without stereochemical information and above 89% accuracy for depictions with stereochemical information.",
        "link": "http://dx.doi.org/10.26434/chemrxiv.14479287.v1"
    },
    {
        "id": 24708,
        "title": "Image recognition method based on deep learning",
        "authors": "Xin Jia",
        "published": "2017-5",
        "citations": 29,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ccdc.2017.7979332"
    },
    {
        "id": 24709,
        "title": "3D Image Annotation using Deep Learning and View-based Image Features",
        "authors": "Mohammadiman Hosseinnia, Alireza Behrad",
        "published": "2023-2-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ipria59240.2023.10147190"
    },
    {
        "id": 24710,
        "title": "Target detection and recognition of radar spectrum image based on deep learning",
        "authors": "HanYu Zou, Xin Chen, Chenxi Wang, Song He, xiao Tang",
        "published": "2021-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2604729"
    },
    {
        "id": 24711,
        "title": "Author response for \"BesNet: binocular ferrographic image recognition model based on deep learning technology\"",
        "authors": " Fei Xie,  Haijun Wei",
        "published": "2023-6-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1108/ilt-05-2023-0150/v2/response1"
    },
    {
        "id": 24712,
        "title": "Satellite Image Classification with Deep Learning",
        "authors": "Mark Pritt, Gary Chern",
        "published": "2017-10",
        "citations": 76,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aipr.2017.8457969"
    },
    {
        "id": 24713,
        "title": "Research on image recognition mechanism based on deep learning",
        "authors": "Qiang Han, Yueru Wang, Wenye Sun",
        "published": "2022-4-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2636974"
    },
    {
        "id": 24714,
        "title": "Fall Behavior Recognition Based on Deep Learning and Image Processing",
        "authors": "He Xu, Leixian Shen, Qingyun Zhang, Guoxu Cao",
        "published": "2020",
        "citations": 0,
        "abstract": "Accidental fall detection for the elderly who live alone can minimize the risk of death and injuries. In this article, we present a new fall detection method based on \"deep learning and image, where a human body recognition model-DeeperCut is used. First, a camera is used to get the detection source data, and then the video is split into images which can be input into DeeperCut model. The human key point data in the output map and the label of the pictures are used as training data to input into the fall detection neural network. The output model then judges the fall of the subsequent pictures. In addition, the fall detection system is designed and implemented with using Raspberry Pi hardware in a local network environment. The presented method obtains a 100% fall detection rate in the experimental environment. The false positive rate on the test set is around 1.95% which is very low and can be ignored because this will be checked by using SMS, WeChat and other SNS tools to confirm falls. Experimental results show that the proposed fall behavior recognition is effective and feasible to be deployed in home environment. ",
        "link": "http://dx.doi.org/10.4018/978-1-7998-0414-7.ch078"
    },
    {
        "id": 24715,
        "title": "Understanding deep learning decision for satellite image classification",
        "authors": "Asif Mehmood",
        "published": "2021-4-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2591974"
    },
    {
        "id": 24716,
        "title": "Timed-image based deep learning for action recognition in video sequences",
        "authors": "Abdourrahmane Mahamane Atto, Alexandre Benoit, Patrick Lambert",
        "published": "2020-8",
        "citations": 20,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patcog.2020.107353"
    },
    {
        "id": 24717,
        "title": "Deep Learning Based Image Recognition for 5G Smart IoT Applications",
        "authors": "Jing Li, Xinfang li, Yuwen Ning",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nWith the advent of the 5G era，the development of massive data learning algorithms and in-depth research on neural networks, deep learning methods are widely used in image recognition tasks. However, there is currently a lack of methods for identifying and classifying efficiently Internet of Things (IoT) images. This paper develops an IoT image recognition system based on deep learning, i.e., uses convolutional neural networks (CNN) to construct image recognition algorithms, and uses principal component analysis (PCA) and linear discriminant analysis (LDA) to extract image features, respectively. The effectiveness of the two PCA and LDA image recognition methods is verified through experiments. And when the image feature dimension is 25, the best image recognition effect can be obtained. The main classifier used for image recognition in the IoT is the support vector machine (SVM), and the SVM and CNN are trained by using the database of this paper. At the same time, the effectiveness of the two for image recognition is checked, and then the trained classifier is used for image recognition. It is found that a CNN and SVM-based secondary classification IoT image recognition method improves the accuracy of image recognition. The secondary classification method combines the characteristics of the SVM and CNN image recognition methods, and the accuracy of the image recognition method is verified to provide an effective improvement through experimental verification.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-108738/v1"
    },
    {
        "id": 24718,
        "title": "Deep Learning in Digital Medical Image Recognition",
        "authors": "",
        "published": "2022-6-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.38007/nn.2022.030206"
    },
    {
        "id": 24719,
        "title": "Deep learning for underwater image recognition in small sample size situations",
        "authors": "Leilei Jin, Hong Liang",
        "published": "2017-6",
        "citations": 38,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/oceanse.2017.8084645"
    },
    {
        "id": 24720,
        "title": "Survey of Deep Learning Methods in Image Recognition and Analysis of Intrauterine Residues",
        "authors": "Bhawna Swarnkar, Nilay Khare, Manasi Gyanchandani",
        "published": "2022-1-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003226147-8"
    },
    {
        "id": 24721,
        "title": "Handling Segmentation and Classification Problems in Deep Learning for Identification of Interstitial Lung Disease",
        "authors": "Tapas Pal, Biswadev Goswami, Rajesh P. Barnwal",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003366249-9"
    },
    {
        "id": 24722,
        "title": "An efficient transformer algorithm for image recognition based on ensemble learning methodology",
        "authors": "Yihong Tang",
        "published": "2021-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2604565"
    },
    {
        "id": 24723,
        "title": "Analysis of Commodity image recognition based on deep learning",
        "authors": "Li Xie",
        "published": "2021-1-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3449388.3449389"
    },
    {
        "id": 24724,
        "title": "Research on Automatic Dish Recognition Algorithm Based on Deep Learning",
        "authors": "Hongmin Shao, Jiong Mu, Rong Tang, Xiao Chen, Mingxin Liu",
        "published": "2020-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvidl51233.2020.00-26"
    },
    {
        "id": 24725,
        "title": "Deep Active Transfer Learning for Image Recognition",
        "authors": "Ankita Singh, Shayok Chakraborty",
        "published": "2020-7",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn48605.2020.9207391"
    },
    {
        "id": 24726,
        "title": "A deep learning image recognition framework accelerator based parallel computing",
        "authors": "Da Li, Rui Li, Shuo Zhang",
        "published": "2018-6-27",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3234804.3234812"
    },
    {
        "id": 24727,
        "title": "Deep Learning and Computer-Aided Diagnosis for Medical Image Processing: A Personal Perspective",
        "authors": "Ronald M. Summers",
        "published": "2017",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-42999-1_1"
    },
    {
        "id": 24728,
        "title": "Yoga Posture Recognition by Learning Spatial-Temporal Feature with Deep Learning Techniques",
        "authors": "J. Palanimeera, K. Ponmozhi",
        "published": "2023-7-21",
        "citations": 1,
        "abstract": " Yoga posture recognition remains a difficult issue because of crowded backgrounds, varied settings, occlusions, viewpoint alterations, and camera motions, despite recent promising advances in deep learning. In this paper, the method for accurately detecting various yoga poses using DL (Deep Learning) algorithms is provided. Using a standard RGB camera, six yoga poses — Sukhasana, Kakasana, Naukasana, Dhanurasana, Tadasana, and Vrikshasana — were captured on ten people, five men and five women. In this study, a brand-new DL model is presented for representing the spatio-temporal (ST) variation of skeleton-based yoga poses in movies. It is advised to use a variety of representation learners to pry video-level temporal recordings, which combine spatio-temporal sampling with long-range time mastering to produce a successful and effective training approach. A novel feature extraction method using Open Pose is described, together with a DenceBi-directional LSTM network to represent spatial-temporal links in both the forward and backward directions. This will increase the efficacy and consistency of modeling long-range action detection. To improve temporal pattern modeling capability, they are stacked and combined with dense skip connections. To improve performance, two modalities from look and motion are fused with a fusion module and compared to other deep learning models are LSTMs including LSTM, Bi-LSTM, Res-LSTM, and Res-BiLSTM. Studies on real-time datasets of yoga poses show that the suggested DenseBi-LSTM model performs better and yields better results than state-of-the-art techniques for yoga pose detection. ",
        "link": "http://dx.doi.org/10.1142/s0219467824500554"
    },
    {
        "id": 24729,
        "title": "A Novel Deep-learning Pipeline for Light Field Image Based Material Recognition",
        "authors": "Yunlong Wang, Kunbo Zhang, Zhenan Sun",
        "published": "2021-1-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icpr48806.2021.9412007"
    },
    {
        "id": 24730,
        "title": "From machine generated to handwritten character recognition; a deep learning approach",
        "authors": "Kian Peymani, Mohsen Soryani",
        "published": "2017-4",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/pria.2017.7983055"
    },
    {
        "id": 24731,
        "title": "Development and application of computer image recognition technology",
        "authors": "Quan Zhang",
        "published": "2021-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2604790"
    },
    {
        "id": 24732,
        "title": "Deep SLRT: The Development of Deep Learning based Multilingual and Multimodal Sign Language Recognition and Translation Framework",
        "authors": "Natarajan Balasubramanian, Elakkiya Rajasekar",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "Developing deep neural models for continuous recognition of sign gestures\nand generation of sign videos from spoken sentences is still challenging and requires\nmuch investigation in earlier studies. Although the recent approaches provide plausible\nsolutions for these tasks, they still fail to perform well in handling continuous sentences\nand visual quality aspects. The recent advancements in deep learning techniques\nenvisioned new milestones in handling such complex tasks and producing impressive\nresults. This paper proposes novel approaches to develop a deep neural framework for\nrecognizing multilingual sign datasets and multimodal sign gestures. In addition to that,\nthe proposed model generates sign gesture videos from spoken sentences. In the first\nfold, it deals with the sign gesture recognition tasks using a hybrid CNN-LSTM\nalgorithm. The second fold uses the hybrid NMT-GAN techniques to produce high quality sign gesture videos. The proposed model has been evaluated using different\nquality metrics. We also compared the proposed model performance qualitatively using\ndifferent benchmark sign language datasets. The proposed model achieves 98%\nclassification accuracy and improved video quality in sign language recognition and\nvideo generation tasks.",
        "link": "http://dx.doi.org/10.2174/9789815079210123010011"
    },
    {
        "id": 24733,
        "title": "Fine-Grained Image Recognition Method Based on Input Perception Joint Probability Prediction",
        "authors": "Xiaoxi Yuan",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10165818"
    },
    {
        "id": 24734,
        "title": "Analysis of Machine Learning and Deep Learning in Health Informatics, and Their Application",
        "authors": "Tharuni Gelli, Challa Sri Gouri, D. Ajitha, Nagarjuna Telagam, Ben Othman Soufiene",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003366249-3"
    },
    {
        "id": 24735,
        "title": "Deep neural networks-based relevant latent representation learning for hyperspectral image classification",
        "authors": "Akrem Sellami, Salvatore Tabbone",
        "published": "2022-1",
        "citations": 95,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patcog.2021.108224"
    },
    {
        "id": 24736,
        "title": "Deep Learning in Medical Image Classification and Object Detection: a Survey",
        "authors": "Priyanka Gupta, Shikha Gupta",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.37628/ijippr.v8i2.846"
    },
    {
        "id": 24737,
        "title": "Offline and online deep learning for image recognition",
        "authors": "Nguyen Huu Phong, Bernardete Ribeiro",
        "published": "2017-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/expat.2017.7984421"
    },
    {
        "id": 24738,
        "title": "Deep Learning in Image Recognition",
        "authors": "Yanxiang Huang",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "With the rapid development of high-tech in China, the field of artificial intelligence has also been promoted. Image recognition is an important topic in the field of artificial intelligence, which mainly includes two modules: classification recognition and feature extraction; At the same time, as an important research direction of AI, deep learning has made rapid progress in recent years. It has been widely used in image recognition, speech recognition and other fields and has achieved great success. This paper analyzes the application of deep learning in image recognition, mainly from the aspects of face recognition, remote sensing image classification, etc. Its purpose is to provide help for relevant practitioners, so as to promote the development of image recognition in the tide of AI development.",
        "link": "http://dx.doi.org/10.54254/2755-2721/8/20230082"
    },
    {
        "id": 24739,
        "title": "TICNN: A Hierarchical Deep Learning Framework for Still Image Action Recognition Using Temporal Image Prediction",
        "authors": "Marjaneh Safaei, Pooyan Balouchian, Hassan Foroosh",
        "published": "2018-10",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icip.2018.8451193"
    },
    {
        "id": 24740,
        "title": "Post-mortem iris recognition with deep-learning-based image segmentation",
        "authors": "Mateusz Trokielewicz, Adam Czajka, Piotr Maciejewicz",
        "published": "2020-2",
        "citations": 45,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.imavis.2019.103866"
    },
    {
        "id": 24741,
        "title": "Experiments using deep learning for dermoscopy image analysis",
        "authors": "Cristina Nader Vasconcelos, Bárbara Nader Vasconcelos",
        "published": "2020-11",
        "citations": 46,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patrec.2017.11.005"
    },
    {
        "id": 24742,
        "title": "An Efficient Human Activity Recognition Technique Based on Deep Learning",
        "authors": "A. Khelalef, F. Ababsa, N. Benoudjit",
        "published": "2019-10",
        "citations": 20,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1134/s1054661819040084"
    },
    {
        "id": 24743,
        "title": "Comparative analysis of image classification algorithms based on traditional machine learning and deep learning",
        "authors": "Pin Wang, En Fan, Peng Wang",
        "published": "2021-1",
        "citations": 303,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patrec.2020.07.042"
    },
    {
        "id": 24744,
        "title": "Indian Sign Language Gesture Recognition using Image Processing and Deep Learning",
        "authors": "Neel Kamal Bhagat, Y. Vishnusai, G. N. Rathna",
        "published": "2019-12",
        "citations": 48,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dicta47822.2019.8945850"
    },
    {
        "id": 24745,
        "title": "Hand-Crafted Feature Extraction and Deep Learning Models for Leaf Image Recognition",
        "authors": "Angelin Gladston, Sucithra B.",
        "published": "2022-10-21",
        "citations": 1,
        "abstract": "Plant leaf recognition has been carried out widely using low-level features. Scale invariant feature transform technique has been used to extract the low-level features. Leaves that match based on low-level features but do not do so in semantic perspective cannot be recognized. To address this, global features are extracted and used. Similarly, convolutional neural networks, deep learning networks, and transfer learning-based neural networks have been used for leaf image recognition. Even then there are issues like leaf images in various illuminations, rotations, taken in different angle, and so on. To address such issues, the closeness among low-level features and global features are computed using multiple distance measures, and a leaf recognition framework has been proposed. Two deep network models, namely Densenet and Xception, are used in the experiments. The matched patches are evaluated both quantitatively and qualitatively. Experimental results obtained are promising for the closeness-based leaf recognition framework as well as the Densenet-based leaf recognition.",
        "link": "http://dx.doi.org/10.4018/978-1-7998-8892-5.ch010"
    },
    {
        "id": 24746,
        "title": "Research on embroidery image recognition based on deep learning",
        "authors": "Yinglu Wu",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.3005861"
    },
    {
        "id": 24747,
        "title": "Correlation Net: Spatiotemporal multimodal deep learning for action recognition",
        "authors": "Novanto Yudistira, Takio Kurita",
        "published": "2020-3",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.image.2019.115731"
    },
    {
        "id": 24748,
        "title": "Automated Acute Lymphoblastic Leukemia Detection Using Blood Smear Image Analysis",
        "authors": "Chandan Kumar Jha, Arvind Choubey, Maheshkumar H. Kolekar, Chinmay Chakraborty",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003366249-4"
    },
    {
        "id": 24749,
        "title": "Research on image recognition of three fritillaria cirrhosa species based on deep learning",
        "authors": "Yuxiu Chen, Yuyan Li, Sheng Zhang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBased on the deep learning method, a network model that can quickly and accurately identify the species of fritillaria cirrhosa species was constructed. Taking three kinds of fritillaria cirrhosa images, the learning method based on deep residual convolutional neural network was used to input the unprocessed original image directly as input, and the features of the image were extracted through convolution and pooling operations. On this basis, the ResNet34 model was improved, and the additional fully connected layer was added in front of the Softmax classifier to improve the learning ability of the network model. Visual analysis of the training process was carried out to determine the optimal number of iterations for model training and ensure the recognition accuracy. Total of 3915 images of three kinds of fritillaria cirrhosae were used as data sources for the experiments, among which 160 images of each type were randomly selected to form the validation set, and 60 Songbei, 54 Qingbei, and 58 Lubei images were selected to form the test set. The final training set recognition accuracy rate was 95.8%, the validation set accuracy rate reached 92.3%, and the test set accuracy rate was 88.7%. The image recognition method of fritillaria cirrhosa based on deep learning proposed in this paper is effective and feasible, which can quickly and accurately identify the species of fritillaria cirrhosa species, and provides a new idea for the intelligent recognition of Chinese medicinal materials.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2862886/v1"
    },
    {
        "id": 24750,
        "title": "Deep Learning Models for Facial Expression Recognition",
        "authors": "Atul Sajjanhar, ZhaoQi Wu, Quan Wen",
        "published": "2018-12",
        "citations": 28,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dicta.2018.8615843"
    },
    {
        "id": 24751,
        "title": "Image Recognition Algorithm Based on Deep Learning",
        "authors": "Jiashan Zhu",
        "published": "2022-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdiime56946.2022.00011"
    },
    {
        "id": 24752,
        "title": "Evaluation on Vision Intelligent Control and Image Target Location and Recognition Based on Deep Learning",
        "authors": "Wenhong Zhao, Wei Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nVision is the most important way for human beings to obtain information. Under the constant evolution of electronic imaging technology, visual images are extensively applied to the production and life of people. The analysis of visual image information can achieve intelligent control and complete specific tasks in industrial production. For example, in the logistics parcel sorting, the traditional manual parcel sorting is slow, inefficient and costly. For the logistics parcel sorting system, the machine vision was used to obtain the parcel image information, and the depth learning algorithm was used to locate and recognize the parcel image. In this paper, the depth confidence network algorithm and the convolution neural network algorithm were compared in image positioning and recognition experiments. After several groups of iterative experiments, the results showed that in large package images, the average image recognition accuracy of the depth confidence network algorithm and the convolution neural network algorithm was 94.42% and 96.09% respectively. In the small package image, the average image recognition accuracy of the depth confidence network algorithm and the convolution neural network algorithm were 96.53% and 97.64%, respectively. Therefore, applying convolution neural network to the object recognition of logistics package image can effectively improve the accuracy of image recognition and improve the efficiency of logistics package sorting.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3118475/v1"
    },
    {
        "id": 24753,
        "title": "Learning deep and compact models for gesture recognition",
        "authors": "Koustav Mullick, Anoop M. Namboodiri",
        "published": "2017-9",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icip.2017.8297033"
    },
    {
        "id": 24754,
        "title": "Weld Defect Detection and Image Defect Recognition Using Deep Learning Technology",
        "authors": "Yu Cheng, HongGui Deng, YuXin Feng, JunJiang Xiang",
        "published": "No Date",
        "citations": 6,
        "abstract": "Abstract\nWelding defects not only bring several economic losses to enterprises and individuals but also threatens peoples lives. We propose a deep learning model, where the data-trained deep learning algorithm is employed to detect the weld defects, and the Convolutional Neural Networks (CNNs) are utilized to recognize the image features. The Transfer Learning (TL) is adopted to reduce the training time via simple adjustments and hyperparameter regulations. The designed deep learning-based model is compared with other classic models to prove its effectiveness in weld defect detection and image recognition further. The results show this model can accurately identify weld defects and eliminates the complexity of manually extracting features, reaching a recognition accuracy of 92.54%. Hence, the reliability and automation of detection and recognition is improved signifificantly. Actual application also verififies the effectiveness of TL in weld defect detection and image defect recognition. Therefore, our research results can provide theoretical and practical references for effificient automatic detection of steel plates, cost reduction, and the high-quality development of iron and steel enterprises.Index Terms - convolutional neural network, deep learning, image detect recognition, transfer learning, weld defect detection",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-149365/v1"
    },
    {
        "id": 24755,
        "title": "Application Analysis of Image Enhancement Method in Deep Learning Image Recognition Scene",
        "authors": "Shangzheng Liu, Bin Liu",
        "published": "2021-8-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icesc51422.2021.9532597"
    },
    {
        "id": 24756,
        "title": "Application Analysis of Image Enhancement Method in Deep Learning Image Recognition Scene",
        "authors": "Lian Ding, Wei Du",
        "published": "2021-9-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icirca51532.2021.9544905"
    },
    {
        "id": 24757,
        "title": "Deep Transfer Learning Based Human Activity Recognition By Transforming IMU Data To Image Domain Using Novel Activity Image Creation Method",
        "authors": "Mohammed hashim B.A, Amutha R",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nHuman Activity Recognition is the most popular research area in the pervasive computing field in recent years. Sensor data plays a vital role in identifying several human actions. Convolutional Neural Networks (CNNs) have now become the most recent technique in the computer vision phenomenon, but still it is premature to use CNN for sensor data, particularly in ubiquitous and wearable computing. In this paper, we have proposed the idea of transforming the raw accelerometer and gyroscope sensor data to the visual domain by using our novel activity image creation method (NAICM). Pre-trained CNN (AlexNet) has been used on the converted image domain information. The proposed method is evaluated on several online available human activity recognition dataset. The results show that the proposed novel activity image creation method (NAICM) has successfully created the activity images with a classification accuracy of 98.36% using pre trained CNN.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-766724/v1"
    },
    {
        "id": 24758,
        "title": "Deep Transfer Learning Based Human Activity Recognition By Transforming IMU Data To Image Domain Using Novel Activity Image Creation Method",
        "authors": "Mohammed hashim B.A, Amutha R",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nHuman Activity Recognition is the most popular research area in the pervasive computing field in recent years. Sensor data plays a vital role in identifying several human actions. Convolutional Neural Networks (CNNs) have now become the most recent technique in the computer vision phenomenon, but still it is premature to use CNN for sensor data, particularly in ubiquitous and wearable computing. In this paper, we have proposed the idea of transforming the raw accelerometer and gyroscope sensor data to the visual domain by using our novel activity image creation method (NAICM). Pre-trained CNN (AlexNet) has been used on the converted image domain information. The proposed method is evaluated on several online available human activity recognition dataset. The results show that the proposed novel activity image creation method (NAICM) has successfully created the activity images with a classification accuracy of 98.36% using pre trained CNN.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-766724/v2"
    },
    {
        "id": 24759,
        "title": "Microorganism Image Recognition based on Deep Learning Application",
        "authors": "Treesukon Treebupachatsakul, Suvit Poomrittigul",
        "published": "2020-1",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iceic49074.2020.9051009"
    },
    {
        "id": 24760,
        "title": "Image approach to English digits recognition using deep learning",
        "authors": "F. N. Zainol, M. Z. Ibrahim",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1049/icp.2022.2484"
    },
    {
        "id": 24761,
        "title": "Curvature Augmented Deep Learning for 3D Object Recognition",
        "authors": "Sarah Braeger, Hassan Foroosh",
        "published": "2018-10",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icip.2018.8451487"
    },
    {
        "id": 24762,
        "title": "Image Based Facial Micro-Expression Recognition Using Deep Learning on Small Datasets",
        "authors": "Madhumita A. Takalkar, Min Xu",
        "published": "2017-11",
        "citations": 55,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dicta.2017.8227443"
    },
    {
        "id": 24763,
        "title": "Deep learning concepts and datasets for image recognition: overview 2019",
        "authors": "Karel Horak, Robert Sablatnig",
        "published": "2019-8-14",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2539806"
    },
    {
        "id": 24764,
        "title": "Emotional image color transfer via deep learning",
        "authors": "Da Liu, Yaxi Jiang, Min Pei, Shiguang Liu",
        "published": "2018-7",
        "citations": 30,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patrec.2018.03.015"
    },
    {
        "id": 24765,
        "title": "Face Mask Detection and Temperature Scanning for the COVID-19 Surveillance System Based on Deep Learning Models",
        "authors": "Nagarjuna Telagam, D. Ajitha, Nehru Kandasamy, Ben Othman Soufiene",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003366249-12"
    },
    {
        "id": 24766,
        "title": "Advances in deep learning-based image recognition of product packaging",
        "authors": "Siyuan Chen, Danfei Liu, Yumei Pu, Yunfei Zhong",
        "published": "2022-12",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.imavis.2022.104571"
    },
    {
        "id": 24767,
        "title": "A survey on deep learning based face recognition",
        "authors": "Guodong Guo, Na Zhang",
        "published": "2019-12",
        "citations": 303,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.cviu.2019.102805"
    },
    {
        "id": 24768,
        "title": "Review of Deep Learning Methods in Mammography, Cardiovascular, and Microscopy Image Analysis",
        "authors": "Gustavo Carneiro, Yefeng Zheng, Fuyong Xing, Lin Yang",
        "published": "2017",
        "citations": 26,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-42999-1_2"
    },
    {
        "id": 24769,
        "title": "Large-Scale Image Action Recognition Depends on Deep Learning",
        "authors": "Wei Wu, Jiale Yu",
        "published": "2019-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cisp-bmei48845.2019.8965888"
    },
    {
        "id": 24770,
        "title": "Pornographic Image Recognition Based on Multi-Instance Deep Learning",
        "authors": "Daxiang LI, Zhan Ji, ying Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4049626"
    }
]