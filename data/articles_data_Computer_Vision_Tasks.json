[
    {
        "id": 13071,
        "title": "Learning to Resize Images for Computer Vision Tasks",
        "authors": "Hossein Talebi, Peyman Milanfar",
        "published": "2021-10",
        "citations": 54,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv48922.2021.00055"
    },
    {
        "id": 13072,
        "title": "Uni-NLX: Unifying Textual Explanations for Vision and Vision-Language Tasks",
        "authors": "Fawaz Sammani, Nikos Deligiannis",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00498"
    },
    {
        "id": 13073,
        "title": "A Comprehensive Study of Vision Transformers on Dense Prediction Tasks",
        "authors": "Kishaan Jeeveswaran, Senthilkumar Kathiresan, Arnav Varma, Omar Magdy, Bahram Zonooz, Elahe Arani",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010917800003124"
    },
    {
        "id": 13074,
        "title": "Surrogate Contrastive Network for Supervised Band Selection in Multispectral Computer Vision Tasks",
        "authors": "Edgar A. Bernal",
        "published": "2019-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvprw.2019.00131"
    },
    {
        "id": 13075,
        "title": "Difficulty Estimation with Action Scores for Computer Vision Tasks",
        "authors": "Octavio Arriaga, Sebastian Palacio, Matias Valdenegro-Toro",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00030"
    },
    {
        "id": 13076,
        "title": "Deep learning-based object detection for computer vision tasks",
        "authors": "Priyanka Dhanasekaran, E. Uma, A. V. Geetha, T. Mala",
        "published": "2023-9-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003453406-4"
    },
    {
        "id": 13077,
        "title": "Guest Editorial: Learning from limited annotations for computer vision tasks",
        "authors": "Yazhou Yao, Wenguan Wang, Qiang Wu, Dongfang Liu, Jin Zheng",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1049/cvi2.12229"
    },
    {
        "id": 13078,
        "title": "Co-segmentation inspired attention module for video-based computer vision tasks",
        "authors": "Arulkumar Subramaniam, Jayesh Vaidya, Muhammed Abdul Majeed Ameen, Athira Nambiar, Anurag Mittal",
        "published": "2022-10",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.cviu.2022.103532"
    },
    {
        "id": 13079,
        "title": "Fully synthetic training for image restoration tasks",
        "authors": "Raphaël Achddou, Yann Gousseau, Saïd Ladjal",
        "published": "2023-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103723"
    },
    {
        "id": 13080,
        "title": "Computer Vision: EO Imaging &amp; Video Tasks, Metrics, and Datasets [Slides]",
        "authors": "Alexei Skurikhin, Natalie Klein",
        "published": "2023-3-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2172/1963611"
    },
    {
        "id": 13081,
        "title": "Patch-based Privacy Preserving Neural Network for Vision Tasks",
        "authors": "Mitsuhiro Mabuchi, Tetsuya Ishikawa",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00160"
    },
    {
        "id": 13082,
        "title": "Causal Attention for Vision-Language Tasks",
        "authors": "Xu Yang, Hanwang Zhang, Guojun Qi, Jianfei Cai",
        "published": "2021-6",
        "citations": 57,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr46437.2021.00972"
    },
    {
        "id": 13083,
        "title": "Comparison of Large Language And Vision Models on Representative Downstream Tasks",
        "authors": "Huitong Chen",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icicml60161.2023.10424913"
    },
    {
        "id": 13084,
        "title": "Semantic Bottleneck for Computer Vision Tasks",
        "authors": "Maxime Bucher, Stéphane Herbin, Frédéric Jurie",
        "published": "2019",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-20890-5_44"
    },
    {
        "id": 13085,
        "title": "Application of Graph Structures in Computer Vision Tasks",
        "authors": "Nikita Andriyanov",
        "published": "2022-10-29",
        "citations": 3,
        "abstract": "On the one hand, the solution of computer vision tasks is associated with the development of various kinds of images or random fields mathematical models, i.e., algorithms, that are called traditional image processing. On the other hand, nowadays, deep learning methods play an important role in image recognition tasks. Such methods are based on convolutional neural networks that perform many matrix multiplication operations with model parameters and local convolutions and pooling operations. However, the modern artificial neural network architectures, such as transformers, came to the field of machine vision from natural language processing. Image transformers operate with embeddings, in the form of mosaic blocks of picture and the links between them. However, the use of graph methods in the design of neural networks can also increase efficiency. In this case, the search for hyperparameters will also include an architectural solution, such as the number of hidden layers and the number of neurons for each layer. The article proposes to use graph structures to develop simple recognition networks on different datasets, including small unbalanced X-ray image datasets, widely known the CIFAR-10 dataset and the Kaggle competition Dogs vs Cats dataset. Graph methods are compared with various known architectures and with networks trained from scratch. In addition, an algorithm for representing an image in the form of graph lattice segments is implemented, for which an appropriate description is created, based on graph data structures. This description provides quite good accuracy and performance of recognition. The effectiveness of this approach based, on the descriptors of the resulting segments, is shown, as well as the graph methods for the architecture search.",
        "link": "http://dx.doi.org/10.3390/math10214021"
    },
    {
        "id": 13086,
        "title": "NLX-GPT: A Model for Natural Language Explanations in Vision and Vision-Language Tasks",
        "authors": "Fawaz Sammani, Tanmoy Mukherjee, Nikos Deligiannis",
        "published": "2022-6",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52688.2022.00814"
    },
    {
        "id": 13087,
        "title": "Aligned Image-Word Representations Improve Inductive Transfer Across Vision-Language Tasks",
        "authors": "Tanmay Gupta, Kevin Shih, Saurabh Singh, Derek Hoiem",
        "published": "2017-10",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv.2017.452"
    },
    {
        "id": 13088,
        "title": "Vision-Language Navigation With Self-Supervised Auxiliary Reasoning Tasks",
        "authors": "Fengda Zhu, Yi Zhu, Xiaojun Chang, Xiaodan Liang",
        "published": "2020-6",
        "citations": 90,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr42600.2020.01003"
    },
    {
        "id": 13089,
        "title": "Mirroring Sankey Diagrams for Visual Comparison Tasks",
        "authors": "Zana Vosough, Dietrich Kammer, Mandy Keck, Rainer Groh",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006651203490355"
    },
    {
        "id": 13090,
        "title": "ETL: Efficient Transfer Learning for Face Tasks",
        "authors": "Thrupthi John, Isha Dua, Vineeth Balasubramanian, C. Jawahar",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010907700003124"
    },
    {
        "id": 13091,
        "title": "Language Features Matter: Effective Language Representations for Vision-Language Tasks",
        "authors": "Andrea Burns, Reuben Tan, Kate Saenko, Stan Sclaroff, Bryan Plummer",
        "published": "2019-10",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv.2019.00757"
    },
    {
        "id": 13092,
        "title": "Generating of synthetic datasets using diffusion models for solving computer vision tasks in urban applications",
        "authors": "Ilya Reutov",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.procs.2023.12.036"
    },
    {
        "id": 13093,
        "title": "Simultaneous Deep Transfer Across Domains and Tasks",
        "authors": "Judy Hoffman, Eric Tzeng, Trevor Darrell, Kate Saenko",
        "published": "2017",
        "citations": 33,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-58347-1_9"
    },
    {
        "id": 13094,
        "title": "ZiCo-BC: A Bias Corrected Zero-Shot NAS for Vision Tasks",
        "authors": "Kartikeya Bhardwaj, Hsin-Pai Cheng, Sweta Priyadarshi, Zhuojin Li",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00145"
    },
    {
        "id": 13095,
        "title": "Exploring complementary information of self‐supervised pretext tasks for unsupervised video pre‐training",
        "authors": "Wei Zhou, Yi Hou, Kewei Ouyang, Shilin Zhou",
        "published": "2022-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1049/cvi2.12084"
    },
    {
        "id": 13096,
        "title": "Synthetic Driver Image Generation for Human Pose-Related Tasks",
        "authors": "Romain Guesdon, Carlos Crispim-Junior, Laure Rodet",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011780800003417"
    },
    {
        "id": 13097,
        "title": "What Matters For Meta-Learning Vision Regression Tasks?",
        "authors": "Ning Gao, Hanna Ziesche, Ngo Anh Vien, Michael Volpp, Gerhard Neumann",
        "published": "2022-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52688.2022.01436"
    },
    {
        "id": 13098,
        "title": "DONNAv2 - Lightweight Neural Architecture Search for Vision tasks",
        "authors": "Sweta Priyadarshi, Tianyu Jiang, Hsin-Pai Cheng, Sendil Krishna, Viswanath Ganapathy, Chirag Patel",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00149"
    },
    {
        "id": 13099,
        "title": "Transferability and Hardness of Supervised Classification Tasks",
        "authors": "Anh Tran, Cuong Nguyen, Tal Hassner",
        "published": "2019-10",
        "citations": 39,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv.2019.00148"
    },
    {
        "id": 13100,
        "title": "AuxNet: Auxiliary Tasks Enhanced Semantic Segmentation for Automated Driving",
        "authors": "Sumanth Chennupati, Ganesh Sistu, Senthil Yogamani, Samir Rawashdeh",
        "published": "2019",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007684106450652"
    },
    {
        "id": 13101,
        "title": "AuxNet: Auxiliary Tasks Enhanced Semantic Segmentation for Automated Driving",
        "authors": "Sumanth Chennupati, Ganesh Sistu, Senthil Yogamani, Samir Rawashdeh",
        "published": "2019",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007684100002108"
    },
    {
        "id": 13102,
        "title": "Vision-Language Models Performing Zero-Shot Tasks Exhibit Disparities Between Gender Groups",
        "authors": "Melissa Hall, Laura Gustafson, Aaron Adcock, Ishan Misra, Candace Ross",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00294"
    },
    {
        "id": 13103,
        "title": "Cloud Transformers: A Universal Approach To Point Cloud Processing Tasks",
        "authors": "Kirill Mazur, Victor Lempitsky",
        "published": "2021-10",
        "citations": 23,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv48922.2021.01054"
    },
    {
        "id": 13104,
        "title": "Does Robustness on ImageNet Transfer to Downstream Tasks?",
        "authors": "Yutaro Yamada, Mayu Otani",
        "published": "2022-6",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52688.2022.00900"
    },
    {
        "id": 13105,
        "title": "Recurrent Assistance: Cross-Dataset Training of LSTMs on Kitchen Tasks",
        "authors": "Toby Perrett, Dima Damen",
        "published": "2017-10",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccvw.2017.161"
    },
    {
        "id": 13106,
        "title": "Jointly Recognizing Object Fluents and Tasks in Egocentric Videos",
        "authors": "Yang Liu, Ping Wei, Song-Chun Zhu",
        "published": "2017-10",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv.2017.318"
    },
    {
        "id": 13107,
        "title": "Auxiliary Tasks for Efficient Learning of Point-Goal Navigation",
        "authors": "Saurabh Satish Desai, Stefan Lee",
        "published": "2021-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wacv48630.2021.00076"
    },
    {
        "id": 13108,
        "title": "How Useful Is Self-Supervised Pretraining for Visual Tasks?",
        "authors": "Alejandro Newell, Jia Deng",
        "published": "2020-6",
        "citations": 52,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr42600.2020.00737"
    },
    {
        "id": 13109,
        "title": "Learning Across Tasks and Domains",
        "authors": "Pierluigi Zama Ramirez, Alessio Tonioni, Samuele Salti, Luigi Di Stefano",
        "published": "2019-10",
        "citations": 24,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv.2019.00820"
    },
    {
        "id": 13110,
        "title": "VL-ADAPTER: Parameter-Efficient Transfer Learning for Vision-and-Language Tasks",
        "authors": "Yi-Lin Sung, Jaemin Cho, Mohit Bansal",
        "published": "2022-6",
        "citations": 51,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52688.2022.00516"
    },
    {
        "id": 13111,
        "title": "Densely connected multidilated convolutional networks for dense prediction tasks",
        "authors": "Naoya Takahashi, Yuki Mitsufuji",
        "published": "2021-6",
        "citations": 22,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr46437.2021.00105"
    },
    {
        "id": 13112,
        "title": "Attentive Single-Tasking of Multiple Tasks",
        "authors": "Kevis-Kokitsi Maninis, Ilija Radosavovic, Iasonas Kokkinos",
        "published": "2019-6",
        "citations": 84,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr.2019.00195"
    },
    {
        "id": 13113,
        "title": "Auxiliary Tasks and Exploration Enable ObjectGoal Navigation",
        "authors": "Joel Ye, Dhruv Batra, Abhishek Das, Erik Wijmans",
        "published": "2021-10",
        "citations": 40,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv48922.2021.01581"
    },
    {
        "id": 13114,
        "title": "Structure-Encoding Auxiliary Tasks for Improved Visual Representation in Vision-and-Language Navigation",
        "authors": "Chia-Wen Kuo, Chih-Yao Ma, Judy Hoffman, Zsolt Kira",
        "published": "2023-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00116"
    },
    {
        "id": 13115,
        "title": "DATNet: Dense Auxiliary Tasks for Object Detection",
        "authors": "Alex Levinshtein, Alborz Rezazadeh Sereshkeh, Konstantinos G. Derpanis",
        "published": "2020-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wacv45572.2020.9093325"
    },
    {
        "id": 13116,
        "title": "Correlation Coordinate Plots: Efficient Layouts for Correlation Tasks",
        "authors": "Hoa Nguyen, Paul Rosen",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-64870-5_13"
    },
    {
        "id": 13117,
        "title": "4-DoF Tracking for Robot Fine Manipulation Tasks",
        "authors": "Mennatullah Siam, Abhineet Singh, Camilo Perez, Martin Jagersand",
        "published": "2017-5",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/crv.2017.41"
    },
    {
        "id": 13118,
        "title": "A Survey on Generative Adversarial Networks for imbalance problems in computer vision tasks",
        "authors": "Vignesh Sampath, Iñaki Maurtua, Juan José Aguilar Martín, Aitor Gutierrez",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nAny computer vision application development starts off by acquiring images and data, then preprocessing and pattern recognition steps to perform a task. When the acquired images are highly imbalanced and not adequate, the desired task may not be achievable. Unfortunately, the occurrence of imbalance problems in acquired image datasets in certain complex real-world problems such as anomaly detection, emotion recognition, medical image analysis, fraud detection, metallic surface defect detection, disaster prediction, etc., are inevitable. The performance of computer vision algorithms can significantly deteriorate when the training dataset is imbalanced. In recent years, Generative Adversarial Networks (GANs) have gained immense attention by researchers across a variety of application domains due to their capability to model complex real-world image data. It is particularly important that GANs can not only be used to generate synthetic images, but also its fascinating adversarial learning idea showed good potential in restoring balance in imbalanced datasets. In this paper, we examine the most recent developments of GANs based techniques for addressing imbalance problems in image data. The real-world challenges and implementations of synthetic image generation based on GANs are extensively covered in this survey. Our survey first introduces various imbalance problems in computer vision tasks and its existing solutions, and then examine key concepts such as deep generative image models and GANs. After that, we propose a taxonomy to summarize GANs based techniques for addressing imbalance problems in computer vision tasks into three major categories: 1. Image level imbalances in classification, 2. object level imbalances in object detection and 3. pixel level imbalances in segmentation tasks. We elaborate the imbalance problems of each group, and further provide GANs based solutions in each group. Readers will understand how GANs based techniques can handle the problem of imbalances and boost performance of the computer vision algorithms.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-45616/v2"
    },
    {
        "id": 13119,
        "title": "A Survey on Generative Adversarial Networks for imbalance problems in computer vision tasks",
        "authors": "Vignesh Sampath, Iñaki Maurtua, Juan José Aguilar Martín, Aitor Gutierrez",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nAny computer vision application development starts off by acquiring images and data, then preprocessing and pattern recognition steps to perform a task. When the acquired images are highly imbalanced and not adequate, the desired task may not be achievable. Unfortunately, the occurrence of imbalance problems in acquired image datasets in certain complex real-world problems such as anomaly detection, emotion recognition, medical image analysis, fraud detection, metallic surface defect detection, disaster prediction, etc., are inevitable. The performance of computer vision algorithms can significantly deteriorate when the training dataset is imbalanced. In recent years, Generative Adversarial Neural Networks (GANs) have gained immense attention by researchers across a variety of application domains due to their capability to model complex real-world image data. It is particularly important that GANs can not only be used to generate synthetic images, but also its fascinating adversarial learning idea showed good potential in restoring balance in imbalanced datasets.In this paper, we examine the most recent developments of GANs based techniques for addressing imbalance problems in image data. The real-world challenges and implementations of synthetic image generation based on GANs are extensively covered in this survey. Our survey first introduces various imbalance problems in computer vision tasks and its existing solutions, and then examines key concepts such as deep generative image models and GANs. After that, we propose a taxonomy to summarize GANs based techniques for addressing imbalance problems in computer vision tasks into three major categories: 1. Image level imbalances in classification, 2. object level imbalances in object detection and 3. pixel level imbalances in segmentation tasks. We elaborate the imbalance problems of each group, and provide GANs based solutions in each group. Readers will understand how GANs based techniques can handle the problem of imbalances and boost performance of the computer vision algorithms.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-45616/v4"
    },
    {
        "id": 13120,
        "title": "Learning to Look Around: Intelligently Exploring Unseen Environments for Unknown Tasks",
        "authors": "Dinesh Jayaraman, Kristen Grauman",
        "published": "2018-6",
        "citations": 47,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr.2018.00135"
    },
    {
        "id": 13121,
        "title": "Can We Characterize Tasks Without Labels or Features?",
        "authors": "Bram Wallace, Ziyang Wu, Bharath Hariharan",
        "published": "2021-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr46437.2021.00130"
    },
    {
        "id": 13122,
        "title": "Box-based Refinement for Weakly Supervised and Unsupervised Localization Tasks",
        "authors": "Eyal Gomel, Tal Shaharbany, Lior Wolf",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01470"
    },
    {
        "id": 13123,
        "title": "A Survey on Generative Adversarial Networks for Imbalance Problems in Computer Vision Tasks",
        "authors": "Vignesh Sampath, Iñaki Maurtua, Juan José Aguilar Martín, Aitor Gutierrez",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nAny computer vision application development starts off by acquiring images and data, then preprocessingand pattern recognition steps to perform a task. When the acquired image is highly imbalanced and notadequate, the desired task may not be achievable. Unfortunately, the occurrence of imbalance problems inacquired image datasets in certain complex real-world problems such as anomaly detection, emotionrecognition, medical image analysis, fraud detection, metallic surface defect detection, disaster prediction,etc., are inevitable. The performance of computer vision algorithms can significantly deteriorate when thetraining dataset is imbalanced. In recent years, Generative Adversarial Networks (GANs) have gainedimmense attention by researchers across a variety of application domains due to their capability to modelcomplex real-world image data. It is particularly important that GANs can not only be used to generatesynthetic images, but also its fascinating adversarial learning idea showed good potential in restoringbalance in imbalanced datasets.In this paper, we examine the most recent developments of GANs based techniques for addressingimbalance problems in image data. The real-world challenges and implementations of synthetic imagegeneration based on GANs are extensively covered in this survey. Our survey first introduces variousimbalance problems in computer vision tasks and its existing solutions, and then examine key conceptssuch as deep generative image models and GANs. After that, we propose taxonomy to summarize GANsbased techniques for addressing imbalance problems in computer vision tasks into three major categories:Image level imbalances in classification, object level imbalances in object detection and pixel levelimbalances in segmentation tasks. We elaborate the imbalance problems of each group, and furtherprovide GANs based solutions in each group. Readers will understand how GANs based techniques canhandle the problem of imbalances and boost performance of the computer vision algorithms.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-45616/v1"
    },
    {
        "id": 13124,
        "title": "Searching for Robustness: Loss Learning for Noisy Classification Tasks",
        "authors": "Boyan Gao, Henry Gouk, Timothy M. Hospedales",
        "published": "2021-10",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv48922.2021.00660"
    },
    {
        "id": 13125,
        "title": "A Survey on Generative Adversarial Networks for imbalance problems in computer vision tasks",
        "authors": "Vignesh Sampath, Iñaki Maurtua, Juan José Aguilar Martín, Aitor Gutierrez",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nAny computer vision application development starts off by acquiring images and data, then preprocessing and pattern recognition steps to perform a task. When the acquired images are highly imbalanced and not adequate, the desired task may not be achievable. Unfortunately, the occurrence of imbalance problems in acquired image datasets in certain complex real-world problems such as anomaly detection, emotion recognition, medical image analysis, fraud detection, metallic surface defect detection, disaster prediction, etc., are inevitable. The performance of computer vision algorithms can significantly deteriorate when the training dataset is imbalanced. In recent years, Generative Adversarial Networks (GANs) have gained immense attention by researchers across a variety of application domains due to their capability to model complex real-world image data. It is particularly important that GANs can not only be used to generate synthetic images, but also its fascinating adversarial learning idea showed good potential in restoring balance in imbalanced datasets.In this paper, we examine the most recent developments of GANs based techniques for addressing imbalance problems in image data. The real-world challenges and implementations of synthetic image generation based on GANs are extensively covered in this survey. Our survey first introduces various imbalance problems in computer vision tasks and its existing solutions, and then examines key concepts such as deep generative image models and GANs. After that, we propose a taxonomy to summarize GANs based techniques for addressing imbalance problems in computer vision tasks into three major categories: 1. Image level imbalances in classification, 2. object level imbalances in object detection and 3. pixel level imbalances in segmentation tasks. We elaborate the imbalance problems of each group, and provide GANs based solutions in each group. Readers will understand how GANs based techniques can handle the problem of imbalances and boost performance of the computer vision algorithms.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-45616/v3"
    },
    {
        "id": 13126,
        "title": "PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning",
        "authors": "Arun Mallya, Svetlana Lazebnik",
        "published": "2018-6",
        "citations": 455,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr.2018.00810"
    },
    {
        "id": 13127,
        "title": "Unsupervised Image Style Embeddings for Retrieval and Recognition Tasks",
        "authors": "Siddhartha Gairola, Rajvi Shah, P.J. Narayanan",
        "published": "2020-3",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wacv45572.2020.9093421"
    },
    {
        "id": 13128,
        "title": "How Close Are Other Computer Vision Tasks to Deepfake Detection?",
        "authors": "Huy H. Nguyen, Junichi Yamagishi, Isao Echizen",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcb57857.2023.10448744"
    },
    {
        "id": 13129,
        "title": "The MIS Check-Dam Dataset for Object Detection and Instance Segmentation Tasks",
        "authors": "Chintan Tundia, Rajiv Kumar, Om Damani, G. Sivakumar",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010799600003124"
    },
    {
        "id": 13130,
        "title": "Finding and Navigating to Humans in Complex Environments for Assistive Tasks",
        "authors": "Asfand Yaar, Antonino Furnari, Marco Rosano, Aki Härmä, Giovanni Farinella",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012271700003660"
    },
    {
        "id": 13131,
        "title": "FAME-ViL: Multi-Tasking Vision-Language Model for Heterogeneous Fashion Tasks",
        "authors": "Xiao Han, Xiatian Zhu, Licheng Yu, Li Zhang, Yi-Zhe Song, Tao Xiang",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00262"
    },
    {
        "id": 13132,
        "title": "Robotic Finger Design Workflow for Adaptable Industrial Assembly Tasks",
        "authors": "Adam Wolniakowski, Anders Lindvig, Nicolai Iversen, Norbert Krüger, Aljaž Kramberger",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010020100690076"
    },
    {
        "id": 13133,
        "title": "Efficiency study of VGG networks in autonomous driving tasks",
        "authors": "Junhua Qi",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.3021397"
    },
    {
        "id": 13134,
        "title": "Video Anomaly Detection via Sequentially Learning Multiple Pretext Tasks",
        "authors": "Chenrui Shi, Che Sun, Yuwei Wu, Yunde Jia",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00948"
    },
    {
        "id": 13135,
        "title": "Diversified Dynamic Routing for Vision Tasks",
        "authors": "Botos Csaba, Adel Bibi, Yanwei Li, Philip Torr, Ser-Nam Lim",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-25069-9_48"
    },
    {
        "id": 13136,
        "title": "Leveraging Deep Reinforcement Learning for Reaching Robotic Tasks",
        "authors": "Kapil Katyal, I-Jeng Wang, Philippe Burlina",
        "published": "2017-7",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvprw.2017.71"
    },
    {
        "id": 13137,
        "title": "Filter Distribution Templates in Convolutional Networks for Image Classification Tasks",
        "authors": "Ramon Izquierdo, Walterio Mayol-Cuevas",
        "published": "2021-6-25",
        "citations": 0,
        "abstract": "Neural network designers have reached progressive accuracy by increasing models depth, introducing new layer types and discovering new combinations of layers. A common element in many architectures is the distribution of the number of filters in each layer. Neural network models keep a pattern design of increasing filters in deeper layers such as those in LeNet, VGG, ResNet, MobileNet and even in automatic discovered architectures such as NASNet. It remains unknown if this pyramidal distribution of filters is the best for different tasks and constrains. In this work we present a series of modifications in the distribution of filters in three popular neural network models and their effects in accuracy and resource consumption. Results show that by applying this approach, some models improve up to 8.9% in accuracy showing reductions in parameters up to 54%.",
        "link": "http://dx.doi.org/10.52591/lxai202106253"
    },
    {
        "id": 13138,
        "title": "Distilling from Similar Tasks for Transfer Learning on a Budget",
        "authors": "Kenneth Borup, Cheng Perng Phoo, Bharath Hariharan",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01050"
    },
    {
        "id": 13139,
        "title": "SIMBAR: Single Image-Based Scene Relighting For Effective Data Augmentation For Automated Driving Vision Tasks",
        "authors": "Xianling Zhang, Nathan Tseng, Ameerah Syed, Rohan Bhasin, Nikita Jaipuria",
        "published": "2022-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52688.2022.00370"
    },
    {
        "id": 13140,
        "title": "An efficient multi-agent computationnal model for massively distribution of independent and heterogeneous tasks",
        "authors": "Abdelaziz Daaif, Omar Bouattane, Mohamed Youssfi",
        "published": "2017-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isacv.2017.8054914"
    },
    {
        "id": 13141,
        "title": "Adapting JPEG XS gains and priorities to tasks and contents",
        "authors": "Benoit Brummer, Christophe de Vleeschouwer",
        "published": "2020-6",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvprw50498.2020.00090"
    },
    {
        "id": 13142,
        "title": "Video Object Segmentation",
        "authors": "Ning Xu, Weiyao Lin, Xiankai Lu, Yunchao Wei",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-44656-6"
    },
    {
        "id": 13143,
        "title": "Dynamic-Net: Tuning the Objective Without Re-Training for Synthesis Tasks",
        "authors": "Alon Shoshan, Roey Mechrez, Lihi Zelnik-Manor",
        "published": "2019-10",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv.2019.00331"
    },
    {
        "id": 13144,
        "title": "Video Object Tracking",
        "authors": "Ning Xu, Weiyao Lin, Xiankai Lu, Yunchao Wei",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-44660-3"
    },
    {
        "id": 13145,
        "title": "Leveraging Heterogeneous Auxiliary Tasks to Assist Crowd Counting",
        "authors": "Muming Zhao, Jian Zhang, Chongyang Zhang, Wenjun Zhang",
        "published": "2019-6",
        "citations": 86,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr.2019.01302"
    },
    {
        "id": 13146,
        "title": "Pose-Robust Face Verification by Exploiting Competing Tasks",
        "authors": "Boyu Lu, Jingxiao Zheng, Jun-Cheng Chen, Rama Chellappa",
        "published": "2017-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wacv.2017.130"
    },
    {
        "id": 13147,
        "title": "Computer vision models application in the current system on object detection tasks",
        "authors": "Feilian Huang",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "The implementation of object detection algorithms would be helpful to the various fields of the current time. When object detection is applied to the surveillance camera system, it will be more efficient to locate crimes or find lost kids. This paper will investigate the performance of different object detection algorithms in a real-world scenario. With experimentation, CenterNet++ outperforms YOLO and MaskRCNN, two traditional and classic object detection algorithms, on the MS COCO dataset, which concludes that CenterNet++ can ensure both accuracy and speed.",
        "link": "http://dx.doi.org/10.54254/2755-2721/4/20230335"
    },
    {
        "id": 13148,
        "title": "Learning Multiple Dense Prediction Tasks from Partially Annotated Data",
        "authors": "Wei-Hong Li, Xialei Liu, Hakan Bilen",
        "published": "2022-6",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52688.2022.01831"
    },
    {
        "id": 13149,
        "title": "The Spatially-Correlative Loss for Various Image Translation Tasks",
        "authors": "Chuanxia Zheng, Tat-Jen Cham, Jianfei Cai",
        "published": "2021-6",
        "citations": 61,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr46437.2021.01614"
    },
    {
        "id": 13150,
        "title": "The Dance of Logic and Unpredictability: Examining the Predictability of User Behavior on Visual Analytics Tasks",
        "authors": "Alvitta Ottley",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012671100003660"
    },
    {
        "id": 13151,
        "title": "A new framework with multiple tasks for detecting and locating pain events in video",
        "authors": "Junkai Chen, Zheru Chi, Hong Fu",
        "published": "2017-2",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.cviu.2016.11.003"
    },
    {
        "id": 13152,
        "title": "Performance of Texture Compression Algorithms in Low-Latency Computer Vision Tasks",
        "authors": "Jakub Zadnik, Markku Makitalo, Jussi Iho, Pekka Jaaskelainen",
        "published": "2021-6-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/euvip50544.2021.9484015"
    },
    {
        "id": 13153,
        "title": "Deep Learning Algorithm for Computer Vision with a New Technique and Concept: PIDC-NN for Binary Classification Tasks in a Coal Preparation Plant (MinerNet)",
        "authors": "Refat Mohammed Abdullah Eshaq",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p><strong>To Whom It May Concern</strong></p>\n<p>Members of Scientific Community</p>\n<p>Dear colleagues:</p>\n<p>I hope my letter finds you well. My name is REFAT MOHAMMED ABDULLAH ESHAQ ( <a href=\"https://orcid.org/0000-0002-6448-4054\" target=\"_blank\">https://orcid.org/0000-0002-6448-4054</a> ). I have created a new algorithm, namely Proportional–Integral–Derivative–Cumulative (PIDC), also called MinerNet. This algorithm work based on the PID controller that was created by the inventor Elmer Sperry in 1910. </p>\n<p>Although convolutional neural networks (CNNs) have achieved great successes in computer vision and pattern recognition, they have some shortcomings. In this article, a novel deep learning algorithm for binary classification is proposed to distinguish between coal and gangue infrared images. First, a Proportional–Integral–Derivative–Cumulative (PIDC) algorithm is created, which works based on the concept of a PID controller, in order to quickly extract features from infrared images and also to control the performance of Artificial Neural Networks (ANNs). Second, an ANN is designed for binary classification tasks (coal/gangue). Third, the PIDC algorithm and the ANN algorithm are connected to create a new learning system, namely, the Proportional–Integral–Derivative–Cumulative Neural Network (PIDC-NN), also called MinerNet. The proposed PIDC-NN architecture works without any traditional layers of deep CNNs such as convolutional layers, nonlinear activation functions layers, batch normalization layers, polling layers, or dropout layers. The results of the training and test processes demonstrate that the proposed PIDC-NN architecture alleviates the oscillation and overfitting problems of existing CNNs. Moreover, it solves the problem of dead neurons and big data that are required to train CNNs. Additionally, it provides robust and resilient control by tuning the gain coefficients <em>KP</em>, <em>KI</em>, and <em>KD</em>; the sampling time (<em>dt</em>); and <em>arbitrary value </em>(<em>AV</em>). A comparison between the proposed PIDC-NN architecture and state-of-the-art CNNs proves the effectiveness of the proposed method in accelerating both the training and test processes with competitive loss and accuracy. </p>\n<p><strong>I emphasize that this algorithm (PIDC) that I created through my own effort, can provide optimal control to any system (not only ANN) whether linear or nonlinear with multiple inputs. Furthermore, this algorithm (PIDC) can control multiple complicated random inputs and make the system linear even with inputs, their amounts, and values are huge numbers (goes to infinity).</strong> </p>\n<p><u><strong>The code is licensed under GNU Affero General Public License Version 3 (GNU AGPLv3); for more information, see </strong></u><a href=\"https://www.gnu.org/licenses/agpl-3.0.en.html\" target=\"_blank\"><strong>https://www.gnu.org/licenses/agpl-3.0.en.html</strong></a><u><strong>. The dataset (Coal and Gangue Infrared Images in BMP file format (Data.rar)) is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0); for more information, see </strong></u><a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" target=\"_blank\"><strong>https://creativecommons.org/licenses/by-nc-sa/4.0/</strong></a><u><strong>. </strong></u></p>\n<p>· The code has been released on GitHub, see <a href=\"https://github.com/REFATESHAQ\" target=\"_blank\">https://github.com/REFATESHAQ</a> </p>\n<p>· The data (Coal and Gangue Infrared Images in BMP file format (Data.rar)) has been released on IEEE Dataport. <a href=\"https://dx.doi.org/10.21227/v3m7-dk11\" target=\"_blank\">https://dx.doi.org/10.21227/v3m7-dk11</a> </p>\n<p>This work has been supported by my livelihood and my family's aid. The code and data is connected to article, entitled “<strong>Deep Learning Algorithm for Computer Vision with a New Technique and Concept: PIDC-NN for Binary Classification Tasks in a Coal Preparation Plant (MinerNet)</strong>” TechRxiv (10.36227/techrxiv.23266301). Note that, the article is under review. </p>\n<p>Yours faithfully</p>\n<p>ESHAQ</p>\n<p><br></p>\n<p>Web of Science ResearcherID: AAJ-8724-2020</p>\n<p>ResearchGate: <a href=\"https://www.researchgate.net/profile/Refat-Eshaq\" target=\"_blank\">https://www.researchgate.net/profile/Refat-Eshaq</a></p>\n<p>Google Scholar: <a href=\"https://scholar.google.com/citations?user=_mmSzykAAAAJ&hl=en\" target=\"_blank\">https://scholar.google.com/citations?user=_mmSzykAAAAJ&hl=en</a></p>\n<p>Author's Email: <a href=\"mailto:refateshaq1993@gmail.com\" target=\"_blank\">refateshaq1993@gmail.com</a>;  <a href=\"mailto:refateshaq@hotmail.com\" target=\"_blank\">refateshaq@hotmail.com</a>;  <a href=\"mailto:fs18050005@cumt.edu.cn\" target=\"_blank\">fs18050005@cumt.edu.cn</a>; </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23266301.v1"
    },
    {
        "id": 13154,
        "title": "Review of deep learning methods for medical segmentation tasks in brain tumors",
        "authors": "Jiaqi Li, Yuxin Hou",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1049/pbhe049e_ch2"
    },
    {
        "id": 13155,
        "title": "I can’t believe there’s no images! : Learning Visual Tasks Using Only Language Supervision",
        "authors": "Sophia Gu, Christopher Clark, Aniruddha Kembhavi",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00252"
    },
    {
        "id": 13156,
        "title": "Computer Vision Tasks for Ambient Intelligence in Children’s Health",
        "authors": "Danila Germanese, Sara Colantonio, Marco Del Coco, Pierluigi Carcagnì, Marco Leo",
        "published": "2023-10-6",
        "citations": 0,
        "abstract": "Computer vision is a powerful tool for healthcare applications since it can provide objective diagnosis and assessment of pathologies, not depending on clinicians’ skills and experiences. It can also help speed-up population screening, reducing health care costs and improving the quality of service. Several works summarise applications and systems in medical imaging, whereas less work is devoted to surveying approaches for healthcare goals using ambient intelligence, i.e., observing individuals in natural settings. Even more, there is a lack of papers providing a survey of works exhaustively covering computer vision applications for children’s health, which is a particularly challenging research area considering that most existing computer vision technologies have been trained and tested only on adults. The aim of this paper is then to survey, for the first time in the literature, the papers covering children’s health-related issues by ambient intelligence methods and systems relying on computer vision.",
        "link": "http://dx.doi.org/10.3390/info14100548"
    },
    {
        "id": 13157,
        "title": "Exploiting Proximity-Aware Tasks for Embodied Social Navigation",
        "authors": "Enrico Cancelli, Tommaso Campari, Luciano Serafini, Angel X. Chang, Lamberto Ballan",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01006"
    },
    {
        "id": 13158,
        "title": "Deep Learning Algorithm for Computer Vision with a New Technique and Concept: PIDC-NN for Binary Classification Tasks in a Coal Preparation Plant (MinerNet)",
        "authors": "Refat Mohammed Abdullah Eshaq",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p><strong>To Whom It May Concern</strong></p>\n<p>Members of The Scientific Community</p>\n<p>Dear colleagues:</p>\n<p>I hope my letter finds you well. My name is REFAT MOHAMMED ABDULLAH ESHAQ (<a href=\"https://orcid.org/0000-0002-6448-4054\" target=\"_blank\">https://orcid.org/0000-0002-6448-4054</a>). I have created a new algorithm, namely Proportional–Integral–Derivative–Cumulative Neural Networks (PIDC-NN), also called MinerNet. This algorithm work based on the PID controller that was created by the inventor Elmer Sperry in 1910. The code has been released on GitHub, see https://github.com/REFATESHAQ/PIDC-NN_MinerNet, and https://github.com/REFATESHAQ/PIDC-NN_MinerNet-Pro. The data (Coal and Gangue Infrared Images in BMP file format) has been released on IEEE Dataport. <a href=\"https://dx.doi.org/10.21227/v3m7-dk11\" target=\"_blank\">https://dx.doi.org/10.21227/v3m7-dk11</a></p>\n<p>Although convolutional neural networks (CNNs) have achieved great successes in computer vision and pattern recognition, they have some shortcomings. In this article, a novel deep learning algorithm for binary classification is proposed to distinguish between coal and gangue infrared images. First, a Proportional–Integral–Derivative–Cumulative (PIDC) algorithm is created, which works based on the concept of a PID controller, in order to quickly extract features from infrared images and also to control the performance of Artificial Neural Networks (ANNs). Second, an ANN is designed for binary classification tasks (coal/gangue). Third, the PIDC algorithm and the ANN algorithm are connected to create a new learning system, namely, the Proportional–Integral–Derivative–Cumulative Neural Network (PIDC-NN), also called MinerNet. The proposed PIDC-NN architecture works without any traditional layers of deep CNNs such as convolutional layers, nonlinear activation functions layers, batch normalization layers, polling layers, or dropout layers. The results of the training and test processes demonstrate that the proposed PIDC-NN architecture alleviates the oscillation and overfitting problems of existing CNNs. Moreover, it solves the problem of dead neurons and big data that are required to train CNNs. Additionally, it provides robust and resilient control by tuning the gain coefficients <em>KP</em>, <em>KI</em>, and <em>KD</em>; the sampling time (<em>dt</em>); and <em>arbitrary value </em>(<em>AV</em>). A comparison between the proposed PIDC-NN architecture and state-of-the-art CNNs proves the effectiveness of the proposed method in accelerating both the training and test processes with competitive loss and accuracy. </p>\n<p><strong>I emphasize that this algorithm (PIDC) that I created through my own effort, can provide optimal control to any system (not only ANN) whether linear or nonlinear with multiple inputs. Furthermore, this algorithm (PIDC) can control multiple complicated random inputs and make the system linear even with inputs, their amounts, and values are huge numbers (goes to infinity).</strong> </p>\n<p><u><strong>The code is licensed under GNU Affero General Public License Version 3 (GNU AGPLv3); for more information, see </strong></u><a href=\"https://www.gnu.org/licenses/agpl-3.0.en.html\" target=\"_blank\"><strong>https://www.gnu.org/licenses/agpl-3.0.en.html</strong></a><u><strong>. The dataset (Coal and Gangue Infrared Images in BMP file format (Data.rar)) is licensed under a </strong></u> <strong>Creative Commons Attribution 4.0 International (CC BY 4.0) License. For more information, see </strong><a href=\"https://creativecommons.org/licenses/by/4.0/\" target=\"_blank\"><strong>https://creativecommons.org/licenses/by/4.0/</strong></a><strong>.</strong> </p>\n<p>This work has been supported by my livelihood and my family's aid. The code and data is connected to article, entitled “<strong>Deep Learning Algorithm for Computer Vision with a New Technique and Concept: PIDC-NN for Binary Classification Tasks in a Coal Preparation Plant (MinerNet)</strong>” TechRxiv (10.36227/techrxiv.23266301). Note that, the article is under review. </p>\n<p><u><strong>The question is, why do I make contact with you? </strong></u></p>\n<p>As the average review time in top journals for the first round of submission may exceed one year, they encourage the authors to submit their papers to TechRxiv, IEEE's preprint server, and publish the code in GitHub platform in order to quickly disseminate their work to a wide audience and gain community feedback. Therefore: </p>\n<p>· If you are a researcher in medicine, you can use and develop this code to detect the cancers Benign and Malignant Tumors by using the dataset of breast mammography images as inputs to the PIDC-NN algorithm.</p>\n<p>· If you are a researcher in Ecological and Environmental Engineering, you can use and develop this code to study geological and climate changes by using Remote Sensing Images as inputs to the PIDC-NN algorithm.</p>\n<p>· If you are a researcher in Mining Engineering, you can use and develop this code to detect and explore the resources by using images you collected as inputs to the PIDC-NN algorithm.</p>\n<p>· If you are a researcher in Mechanical or Industrial Engineering, you can use and develop this code to remove unwanted material from production lines of factories or to detect defects in equipment. Also who work in Fluid Mechanics and Gas Dynamics, you can use this code in order to study the behavior of fluid by using infrared images of the movement of the fluid through the pipes and heat exchangers.</p>\n<p>· If you are a researcher in Mechatronics Engineering, you can use and develop this code and insert it in Robots as visual sense algorithm such as Robotic Arms (Manipulators), Mobile Robots, and Drones and so on. </p>\n<p>Finally, there are a lot of benefits from this algorithm (PIDC) to control thermal, electrical, and mechanical processes as long as you understand how the PIDC algorithm deal with multiple random complicated inputs to produce one or multiple stable outputs. To clarify, the PIDC algorithm can not only apply to control ANN but also to any system needs to be stable.</p>\n<p>Yours faithfully</p>\n<p>ESHAQ</p>\n<p>ResearchGate: <a href=\"https://www.researchgate.net/profile/Refat-Eshaq\" target=\"_blank\">https://www.researchgate.net/profile/Refat-Eshaq</a></p>\n<p>Google Scholar: <a href=\"https://scholar.google.com/citations?user=_mmSzykAAAAJ&hl=en\" target=\"_blank\">https://scholar.google.com/citations?user=_mmSzykAAAAJ&hl=en</a></p>\n<p>Author's Email: <a href=\"mailto:refateshaq1993@gmail.com\" target=\"_blank\">refateshaq1993@gmail.com</a>;  <a href=\"mailto:refateshaq@hotmail.com\" target=\"_blank\">refateshaq@hotmail.com</a>;  <a href=\"mailto:fs18050005@cumt.edu.cn\" target=\"_blank\">fs18050005@cumt.edu.cn</a>; </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23266301.v3"
    },
    {
        "id": 13159,
        "title": "3D visualization of HPC Tasks Scheduling Algorithm",
        "authors": "Pavel Alexandrovich Vasev",
        "published": "2023",
        "citations": 0,
        "abstract": "The paper is devoted to the issue of visualization of the algorithm for scheduling parallel tasks. Task planning is a key part of the online visualization and parallel programming environment developed by the author. When programming a parallel version of one application task, a suspicion arose that the scheduling algorithm does not optimally distribute the load between the performers. In this connection, it was decided to visualize its work in order to see the overall picture and possible problem areas of the algorithm. The display view works in three-dimensional space and visualizes the assignment of tasks with dots. The coordinates of the points are determined by the logical time, the sequence number of the core (performer), and the sequence number of the data block from the decomposition of the task. The color of the dots is set by the task type. Dependencies between data tasks are shown in segments. The constructed view of the display successfully coped with the task, and the planning algorithm was improved.",
        "link": "http://dx.doi.org/10.20948/graphicon-2023-341-353"
    },
    {
        "id": 13160,
        "title": "Filter Distribution Templates in Convolutional Networks for Image Classification Tasks",
        "authors": "Ramon Izquierdo-Cordova, Walterio Mayol-Cuevas",
        "published": "2021-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvprw53098.2021.00136"
    },
    {
        "id": 13161,
        "title": "Deep Learning Algorithm for Computer Vision with a New Technique and Concept: PIDC-NN for Binary Classification Tasks in a Coal Preparation Plant (MinerNet)",
        "authors": "Refat Mohammed Abdullah Eshaq",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p><strong>To Whom It May Concern</strong></p>\n<p>Members of The Scientific Community</p>\n<p>Dear colleagues:</p>\n<p>I hope my letter finds you well. My name is REFAT MOHAMMED ABDULLAH ESHAQ (<a href=\"https://orcid.org/0000-0002-6448-4054\" target=\"_blank\">https://orcid.org/0000-0002-6448-4054</a>). I have created a new algorithm, namely Proportional–Integral–Derivative–Cumulative Neural Networks (PIDC-NN), also called MinerNet. This algorithm work based on the PID controller that was created by the inventor Elmer Sperry in 1910. The code has been released on GitHub, see https://github.com/REFATESHAQ/PIDC-NN_MinerNet, and https://github.com/REFATESHAQ/PIDC-NN_MinerNet-Pro. The data (Coal and Gangue Infrared Images in BMP file format) has been released on IEEE Dataport. <a href=\"https://dx.doi.org/10.21227/v3m7-dk11\" target=\"_blank\">https://dx.doi.org/10.21227/v3m7-dk11</a></p>\n<p>Although convolutional neural networks (CNNs) have achieved great successes in computer vision and pattern recognition, they have some shortcomings. In this article, a novel deep learning algorithm for binary classification is proposed to distinguish between coal and gangue infrared images. First, a Proportional–Integral–Derivative–Cumulative (PIDC) algorithm is created, which works based on the concept of a PID controller, in order to quickly extract features from infrared images and also to control the performance of Artificial Neural Networks (ANNs). Second, an ANN is designed for binary classification tasks (coal/gangue). Third, the PIDC algorithm and the ANN algorithm are connected to create a new learning system, namely, the Proportional–Integral–Derivative–Cumulative Neural Network (PIDC-NN), also called MinerNet. The proposed PIDC-NN architecture works without any traditional layers of deep CNNs such as convolutional layers, nonlinear activation functions layers, batch normalization layers, polling layers, or dropout layers. The results of the training and test processes demonstrate that the proposed PIDC-NN architecture alleviates the oscillation and overfitting problems of existing CNNs. Moreover, it solves the problem of dead neurons and big data that are required to train CNNs. Additionally, it provides robust and resilient control by tuning the gain coefficients <em>KP</em>, <em>KI</em>, and <em>KD</em>; the sampling time (<em>dt</em>); and <em>arbitrary value </em>(<em>AV</em>). A comparison between the proposed PIDC-NN architecture and state-of-the-art CNNs proves the effectiveness of the proposed method in accelerating both the training and test processes with competitive loss and accuracy. </p>\n<p><strong>I emphasize that this algorithm (PIDC) that I created through my own effort, can provide optimal control to any system (not only ANN) whether linear or nonlinear with multiple inputs. Furthermore, this algorithm (PIDC) can control multiple complicated random inputs and make the system linear even with inputs, their amounts, and values are huge numbers (goes to infinity).</strong> </p>\n<p><u><strong>The code is licensed under GNU Affero General Public License Version 3 (GNU AGPLv3); for more information, see </strong></u><a href=\"https://www.gnu.org/licenses/agpl-3.0.en.html\" target=\"_blank\"><strong>https://www.gnu.org/licenses/agpl-3.0.en.html</strong></a><u><strong>. The dataset (Coal and Gangue Infrared Images in BMP file format (Data.rar)) is licensed under a </strong></u> <strong>Creative Commons Attribution 4.0 International (CC BY 4.0) License. For more information, see </strong><a href=\"https://creativecommons.org/licenses/by/4.0/\" target=\"_blank\"><strong>https://creativecommons.org/licenses/by/4.0/</strong></a><strong>.</strong> </p>\n<p>This work has been supported by my livelihood and my family's aid. The code and data is connected to article, entitled “<strong>Deep Learning Algorithm for Computer Vision with a New Technique and Concept: PIDC-NN for Binary Classification Tasks in a Coal Preparation Plant (MinerNet)</strong>” TechRxiv (10.36227/techrxiv.23266301). Note that, the article is under review. </p>\n<p><u><strong>The question is, why do I make contact with you? </strong></u></p>\n<p>As the average review time in top journals for the first round of submission may exceed one year, they encourage the authors to submit their papers to TechRxiv, IEEE's preprint server, and publish the code in GitHub platform in order to quickly disseminate their work to a wide audience and gain community feedback. Therefore: </p>\n<p>· If you are a researcher in medicine, you can use and develop this code to detect the cancers Benign and Malignant Tumors by using the dataset of breast mammography images as inputs to the PIDC-NN algorithm.</p>\n<p>· If you are a researcher in Ecological and Environmental Engineering, you can use and develop this code to study geological and climate changes by using Remote Sensing Images as inputs to the PIDC-NN algorithm.</p>\n<p>· If you are a researcher in Mining Engineering, you can use and develop this code to detect and explore the resources by using images you collected as inputs to the PIDC-NN algorithm.</p>\n<p>· If you are a researcher in Mechanical or Industrial Engineering, you can use and develop this code to remove unwanted material from production lines of factories or to detect defects in equipment. Also who work in Fluid Mechanics and Gas Dynamics, you can use this code in order to study the behavior of fluid by using infrared images of the movement of the fluid through the pipes and heat exchangers.</p>\n<p>· If you are a researcher in Mechatronics Engineering, you can use and develop this code and insert it in Robots as visual sense algorithm such as Robotic Arms (Manipulators), Mobile Robots, and Drones and so on. </p>\n<p>Finally, there are a lot of benefits from this algorithm (PIDC) to control thermal, electrical, and mechanical processes as long as you understand how the PIDC algorithm deal with multiple random complicated inputs to produce one or multiple stable outputs. To clarify, the PIDC algorithm can not only apply to control ANN but also to any system needs to be stable.</p>\n<p>Yours faithfully</p>\n<p>ESHAQ</p>\n<p>ResearchGate: <a href=\"https://www.researchgate.net/profile/Refat-Eshaq\" target=\"_blank\">https://www.researchgate.net/profile/Refat-Eshaq</a></p>\n<p>Google Scholar: <a href=\"https://scholar.google.com/citations?user=_mmSzykAAAAJ&hl=en\" target=\"_blank\">https://scholar.google.com/citations?user=_mmSzykAAAAJ&hl=en</a></p>\n<p>Author's Email: <a href=\"mailto:refateshaq1993@gmail.com\" target=\"_blank\">refateshaq1993@gmail.com</a>;  <a href=\"mailto:refateshaq@hotmail.com\" target=\"_blank\">refateshaq@hotmail.com</a>;  <a href=\"mailto:fs18050005@cumt.edu.cn\" target=\"_blank\">fs18050005@cumt.edu.cn</a>; </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23266301"
    },
    {
        "id": 13162,
        "title": "Exploration of privacy preserving deep learning framework for computer vision tasks",
        "authors": "Amala Wilson, Mashhour Solh, Melody Moh",
        "published": "2022-4-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3476883.3524048"
    },
    {
        "id": 13163,
        "title": "Deep Learning Algorithm for Computer Vision with a New Technique and Concept: PIDC-NN for Binary Classification Tasks in a Coal Preparation Plant (MinerNet)",
        "authors": "Refat Mohammed Abdullah Eshaq",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p><strong>To Whom It May Concern</strong></p>\n<p>Members of Scientific Community</p>\n<p>Dear colleagues:</p>\n<p>I hope my letter finds you well. My name is REFAT MOHAMMED ABDULLAH ESHAQ ( <a href=\"https://orcid.org/0000-0002-6448-4054\" target=\"_blank\">https://orcid.org/0000-0002-6448-4054</a> ). I have created a new algorithm, namely Proportional–Integral–Derivative–Cumulative (PIDC), also called MinerNet. This algorithm work based on the PID controller that was created by the inventor Elmer Sperry in 1910. The code has been released on GitHub, see · The code has been released on GitHub, see <a href=\"https://github.com/REFATESHAQ/PIDC-NN_MinerNet\" target=\"_blank\">https://github.com/REFATESHAQ</a> . The data (Coal and Gangue Infrared Images in BMP file format (Data.rar)) has been released on IEEE Dataport. <a href=\"https://dx.doi.org/10.21227/v3m7-dk11\" target=\"_blank\">https://dx.doi.org/10.21227/v3m7-dk11   </a></p>\n<p>Although convolutional neural networks (CNNs) have achieved great successes in computer vision and pattern recognition, they have some shortcomings. In this article, a novel deep learning algorithm for binary classification is proposed to distinguish between coal and gangue infrared images. First, a Proportional–Integral–Derivative–Cumulative (PIDC) algorithm is created, which works based on the concept of a PID controller, in order to quickly extract features from infrared images and also to control the performance of Artificial Neural Networks (ANNs). Second, an ANN is designed for binary classification tasks (coal/gangue). Third, the PIDC algorithm and the ANN algorithm are connected to create a new learning system, namely, the Proportional–Integral–Derivative–Cumulative Neural Network (PIDC-NN), also called MinerNet. The proposed PIDC-NN architecture works without any traditional layers of deep CNNs such as convolutional layers, nonlinear activation functions layers, batch normalization layers, polling layers, or dropout layers. The results of the training and test processes demonstrate that the proposed PIDC-NN architecture alleviates the oscillation and overfitting problems of existing CNNs. Moreover, it solves the problem of dead neurons and big data that are required to train CNNs. Additionally, it provides robust and resilient control by tuning the gain coefficients <em>KP</em>, <em>KI</em>, and <em>KD</em>; the sampling time (<em>dt</em>); and <em>arbitrary value </em>(<em>AV</em>). A comparison between the proposed PIDC-NN architecture and state-of-the-art CNNs proves the effectiveness of the proposed method in accelerating both the training and test processes with competitive loss and accuracy. </p>\n<p><strong>I emphasize that this algorithm (PIDC) that I created through my own effort, can provide optimal control to any system (not only ANN) whether linear or nonlinear with multiple inputs. Furthermore, this algorithm (PIDC) can control multiple complicated random inputs and make the system linear even with inputs, their amounts, and values are huge numbers (goes to infinity).</strong> </p>\n<p><u><strong>The code is licensed under GNU Affero General Public License Version 3 (GNU AGPLv3); for more information, see </strong></u><a href=\"https://www.gnu.org/licenses/agpl-3.0.en.html\" target=\"_blank\"><strong>https://www.gnu.org/licenses/agpl-3.0.en.html</strong></a><u><strong>. The dataset (Coal and Gangue Infrared Images in BMP file format (Data.rar)) is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0); for more information, see </strong></u><a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" target=\"_blank\"><strong>https://creativecommons.org/licenses/by-nc-sa/4.0/</strong></a><u><strong>. </strong></u></p>\n<p>This work has been supported by my livelihood and my family's aid. The code and data is connected to article, entitled “<strong>Deep Learning Algorithm for Computer Vision with a New Technique and Concept: PIDC-NN for Binary Classification Tasks in a Coal Preparation Plant (MinerNet)</strong>” TechRxiv (10.36227/techrxiv.23266301). Note that, the article is under review. </p>\n<p><u><strong>The question is, why do I make contact with you? </strong></u></p>\n<p>As the average review time in top journals for the first round of submission may exceed one year, they encourage the authors to submit their papers to TechRxiv, IEEE's preprint server, and publish the code in GitHub platform in order to quickly disseminate their work to a wide audience and gain community feedback. Therefore: </p>\n<p>· If you are a researcher in medicine, you can use and develop this code to detect the cancers Benign and Malignant Tumors by using the dataset of breast mammography images as inputs to the PIDC-NN algorithm.</p>\n<p>· If you are a researcher in Ecological and Environmental Engineering, you can use and develop this code to study geological and climate changes by using Remote Sensing Images as inputs to the PIDC-NN algorithm.</p>\n<p>· If you are a researcher in Mining Engineering, you can use and develop this code to detect and explore the resources by using images you collected as inputs to the PIDC-NN algorithm.</p>\n<p>· If you are a researcher in Mechanical or Industrial Engineering, you can use and develop this code to remove unwanted material from production lines of factories or to detect defects in equipment. Also who work in Fluid Mechanics and Gas Dynamics, you can use this code in order to study the behavior of fluid by using infrared images of the movement of the fluid through the pipes and heat exchangers.</p>\n<p>· If you are a researcher in Mechatronics Engineering, you can use and develop this code and insert it in Robots as visual sense algorithm such as Robotic Arms (Manipulators), Mobile Robots, and Drones and so on. </p>\n<p>Finally, there are a lot of benefits from this algorithm (PIDC) to control thermal, electrical, and mechanical processes as long as you understand how the PIDC algorithm deal with multiple random complicated inputs to produce one or multiple stable outputs. To clarify, the PIDC algorithm can not only apply to control ANN but also to any system need to be stable.</p>\n<p>Yours faithfully</p>\n<p>ESHAQ</p>\n<p>Web of Science ResearcherID: AAJ-8724-2020</p>\n<p>ResearchGate: <a href=\"https://www.researchgate.net/profile/Refat-Eshaq\" target=\"_blank\">https://www.researchgate.net/profile/Refat-Eshaq</a></p>\n<p>Google Scholar: <a href=\"https://scholar.google.com/citations?user=_mmSzykAAAAJ&hl=en\" target=\"_blank\">https://scholar.google.com/citations?user=_mmSzykAAAAJ&hl=en</a></p>\n<p>Author's Email: <a href=\"mailto:refateshaq1993@gmail.com\" target=\"_blank\">refateshaq1993@gmail.com</a>;  <a href=\"mailto:refateshaq@hotmail.com\" target=\"_blank\">refateshaq@hotmail.com</a>;  <a href=\"mailto:fs18050005@cumt.edu.cn\" target=\"_blank\">fs18050005@cumt.edu.cn</a>; </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.23266301.v2"
    },
    {
        "id": 13164,
        "title": "Identifying Modular Construction Worker Tasks Using Computer Vision",
        "authors": "Roshan Panahi, Joseph Louis, Nicholas Aziere, Ankur Podder, Colby Swanson",
        "published": "2022-5-24",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1061/9780784483893.118"
    },
    {
        "id": 13165,
        "title": "IDEA: Index of Difficulty for Eye Tracking Applications - An Analysis Model for Target Selection Tasks",
        "authors": "Mohsen Parisay, Charalambos Poullis, Marta Kersten-Oertel",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010195701350144"
    },
    {
        "id": 13166,
        "title": "SINC: Self-Supervised In-Context Learning for Vision-Language Tasks",
        "authors": "Yi-Syuan Chen, Yun-Zhu Song, Cheng Yu Yeo, Bei Liu, Jianlong Fu, Hong-Han Shuai",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01415"
    },
    {
        "id": 13167,
        "title": "Peripheral Vision: A Critical Component of Many Visual Tasks",
        "authors": "Ruth Rosenholtz",
        "published": "2023-3-22",
        "citations": 0,
        "abstract": "In understanding human visual perception, an important component consists of what people can perceive at a glance. If that glance provides the observer with sufficient task-relevant information, this affords efficient processing. If not, one must move one’s eyes and integrate information across glances and over time, which is necessarily slower and limited by both working memory and the ability to integrate that information. Vision at a glance has to do in large part with the strengths and limitations of peripheral vision, and in particular with visual crowding. Understanding peripheral vision has helped unify a number of aspects of vision.",
        "link": "http://dx.doi.org/10.1093/acrefore/9780190236557.013.878"
    },
    {
        "id": 13168,
        "title": "Image as a Foreign Language: BEIT Pretraining for Vision and Vision-Language Tasks",
        "authors": "Wenhui Wang, Hangbo Bao, Li Dong, Johan Bjorck, Zhiliang Peng, Qiang Liu, Kriti Aggarwal, Owais Khan Mohammed, Saksham Singhal, Subhojit Som, Furu Wei",
        "published": "2023-6",
        "citations": 82,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01838"
    },
    {
        "id": 13169,
        "title": "Learning Multiple Pixelwise Tasks Based on Loss Scale Balancing",
        "authors": "Jae-Han Lee, Chul Lee, Chang-Su Kim",
        "published": "2021-10",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv48922.2021.00506"
    },
    {
        "id": 13170,
        "title": "Perspectives and Prospects on Transformer Architecture for Cross-Modal Tasks with Language and Vision",
        "authors": "Andrew Shin, Masato Ishii, Takuya Narihira",
        "published": "2022-2",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11263-021-01547-8"
    }
]