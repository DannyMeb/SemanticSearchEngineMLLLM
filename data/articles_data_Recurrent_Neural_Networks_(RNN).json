[
    {
        "id": 1401,
        "title": "Recurrent Neural Networks (RNN)",
        "authors": "Fathi M. Salem",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-89929-5_3"
    },
    {
        "id": 1402,
        "title": "Gated RNN: The Gated Recurrent Unit (GRU) RNN",
        "authors": "Fathi M. Salem",
        "published": "2022",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-89929-5_5"
    },
    {
        "id": 1403,
        "title": "Recurrent Neural Networks (RNN)",
        "authors": "Arash Gharehbaghi",
        "published": "2023-5-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780429321252-14"
    },
    {
        "id": 1404,
        "title": "Gated RNN: The Minimal Gated Unit (MGU) RNN",
        "authors": "Fathi M. Salem",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-89929-5_6"
    },
    {
        "id": 1405,
        "title": "Gated RNN: The Long Short-Term Memory (LSTM) RNN",
        "authors": "Fathi M. Salem",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-89929-5_4"
    },
    {
        "id": 1406,
        "title": "Recurrent Neural Networks (RNN) or Sequence Models",
        "authors": "Abhijit Ghatak",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-13-5850-0_8"
    },
    {
        "id": 1407,
        "title": "Recurrent neural network from adder’s perspective: Carry-lookahead RNN",
        "authors": "Haowei Jiang, Feiwei Qin, Jin Cao, Yong Peng, Yanli Shao",
        "published": "2021-12",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neunet.2021.08.032"
    },
    {
        "id": 1408,
        "title": "Recurrent Neural Networks (RNN)",
        "authors": "Cao Xiao, Jimeng Sun",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-82184-5_7"
    },
    {
        "id": 1409,
        "title": "DA-RNN: Semantic Mapping with Data Associated Recurrent Neural Networks",
        "authors": "Yu Xiang, Dieter Fox",
        "published": "2017-7-12",
        "citations": 66,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15607/rss.2017.xiii.013"
    },
    {
        "id": 1410,
        "title": "Improved Recurrent Neural Networks (RNN) Based Intelligent Fund Transaction Model",
        "authors": "Gang Hu, Yi Ye, Yin Zhang, M. Shamim Hossain",
        "published": "2019-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/gcwkshps45667.2019.9024476"
    },
    {
        "id": 1411,
        "title": "Recurrent Neural Networks",
        "authors": "Samit Ahlawat",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-8835-1_4"
    },
    {
        "id": 1412,
        "title": "CS-RNN: efficient training of recurrent neural networks with continuous skips",
        "authors": "Tianyu Chen, Sheng Li, Jun Yan",
        "published": "2022-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s00521-022-07227-z"
    },
    {
        "id": 1413,
        "title": "Gender Classification Based on The Non-Lexical Cues Of Emergency Calls With Recurrent Neural Networks (RNN)",
        "authors": " SON,  KWON,  PARK",
        "published": "2019-4-11",
        "citations": 11,
        "abstract": "Automatic gender classification in speech is a challenging research field with a wide range of applications in HCI (humancomputer interaction). A couple of decades of research have shown promising results, but there is still a need for improvement. Until now, gender classification has been made using differences in the spectral characteristics of males and females. We assumed that a neutral margin exists between the male and female spectral range. This margin causes misclassification of gender. To address this limitation, we studied three non-lexical speech features (fillers, overlapping, and lengthening). From the statistical analysis, we found that overlapping and lengthening are effective in gender classification. Next, we performed gender classification using overlapping, lengthening, and the baseline acoustic feature, Mel Frequency Cepstral Coefficient (MFCC). We have tried to achieve the best results by using various combinations of features at the same time or sequentially. We used two types of machine-learning methods, support vector machine (SVM) and recurrent neural networks (RNN), to classify the gender. We achieved 89.61% with RNN using a feature set including MFCC, overlapping, and lengthening at the same time. Also, we have reclassified using non-lexical features with only data belonging to the neutral margin which was empirically selected based on the result of gender classification with only MFCC. As a result, we determined that the accuracy of classification with RNN using lengthening was 1.83% better than when MFCC alone was used. We concluded that new speech features could be effective in improving gender classification through a behavioral approach, notably including emergency calls.",
        "link": "http://dx.doi.org/10.3390/sym11040525"
    },
    {
        "id": 1414,
        "title": "EMI-RNN – Enhanced Multilayer Independently Recurrent Neural Networks for Handover Optimization in 5G Ultra Dense Networks",
        "authors": "Dr K Madhavi -",
        "published": "2019-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32622/ijrat.72201988"
    },
    {
        "id": 1415,
        "title": "GR-RNN: Global-context residual recurrent neural networks for writer identification",
        "authors": "Sheng He, Lambert Schomaker",
        "published": "2021-9",
        "citations": 30,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.patcog.2021.107975"
    },
    {
        "id": 1416,
        "title": "RNN-BOF: A Multivariate Global Recurrent Neural Network for Binary Outcome Forecasting of Inpatient Aggression",
        "authors": "Aidan Quinn, Melanie Simmons, Benjamin Spivak, Christoph Bergmeir",
        "published": "2022-7-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn55064.2022.9892527"
    },
    {
        "id": 1417,
        "title": "Aspect Based Sentiment Analysis Using Recurrent Neural Networks (RNN) on Social Media Twitter",
        "authors": "Muhammad Afryan Saputra, Erwin Budi Setiawan",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icodsa58501.2023.10276768"
    },
    {
        "id": 1418,
        "title": "Predicting Earnings Directional Movement Utilizing Recurrent Neural Networks (RNN)",
        "authors": "Amos Baranes, Rimona Palas, Arthur Yosef",
        "published": "2022-9-1",
        "citations": 1,
        "abstract": "ABSTRACTThe study has two objectives. The first, to develop an earnings movement prediction model to help investors in their decision process, the second, to explore the potential of Recurrent Neural Networks (RNN) in financial statement analysis and present a detailed model for its application. RNN's two major advantages are: they do not make assumptions regarding the data and allow users to search whatever functional form best describes the underlying relationship between financial data and changes in earnings; they dynamically account for time-series behavior, earnings of a certain time period are not independent of earnings in previous time periods. The paper utilizes the newly mandated XBRL data, whose benefits are that it is freely available, easily accessible and is more timely than traditional databases. The use of RNN is validated in the results by providing a higher accuracy prediction than neural networks and logistic regression.",
        "link": "http://dx.doi.org/10.2308/jeta-2021-001"
    },
    {
        "id": 1419,
        "title": "Abd-Rnn: Attention Based Bi-Directional Deep Learning Recurrent Neural Networks for Aquaculture Water Quality Prediction",
        "authors": "Rasheed Abdul Haq K. P., Harigovindan V. P., Manoj P. Samuel",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4242752"
    },
    {
        "id": 1420,
        "title": "Ransomware Protection Tool based on Recurrent Neural Network (RNN)",
        "authors": "",
        "published": "2021-6-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.37896/jxu15.6/002"
    },
    {
        "id": 1421,
        "title": "CA-RNN: Using Context-Aligned Recurrent Neural Networks for Modeling Sentence Similarity",
        "authors": "Qin Chen, Qinmin Hu, Jimmy Xiangji Huang, Liang He",
        "published": "2018-4-25",
        "citations": 22,
        "abstract": "\n      \n        The recurrent neural networks (RNNs) have shown good performance for sentence similarity modeling in recent years. Most RNNs focus on modeling the hidden states based on the current sentence, while the context information from the other sentence is not well investigated during the hidden state generation. In this paper, we propose a context-aligned RNN (CA-RNN) model, which incorporates the contextual information of the aligned words in a sentence pair for the inner hidden state generation. Specifically, we first perform word alignment detection to identify the aligned words in the two sentences. Then, we present a context alignment gating mechanism and embed it into our model to automatically absorb the aligned words' context for the hidden state update. Experiments on three benchmark datasets, namely TREC-QA and WikiQA for answer selection and MSRP for paraphrase identification, show the great advantages of our proposed model. In particular, we achieve the new state-of-the-art performance on TREC-QA and WikiQA. Furthermore, our model is comparable to if not better than the recent neural network based approaches on MSRP.\n      \n    ",
        "link": "http://dx.doi.org/10.1609/aaai.v32i1.11273"
    },
    {
        "id": 1422,
        "title": "The RNN-ELM classifier",
        "authors": "Athanasios Vlontzos",
        "published": "2017-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2017.7966188"
    },
    {
        "id": 1423,
        "title": "FiC-RNN: A Multi-FPGA Acceleration Framework for Deep Recurrent Neural Networks",
        "authors": "Yuxi SUN, Hideharu AMANO",
        "published": "2020-12-1",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1587/transinf.2020pap0003"
    },
    {
        "id": 1424,
        "title": "Predicting Date Production in Iraq Using Recurrent Neural Networks RNN",
        "authors": "Hassan Muayad Ibrahim, Weam Saadi Hamza, Mohammed Saad Abed",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "Artificial intelligence methods play an important role in predicting future values of time series and thus help in setting economic and social development plans. The study aimed to predict the production of dates in Iraq using recurrent neural networks, based on the production of dates in Iraq for the period from 2002-2021. The appropriate prediction model was chosen based on the MSE, MAPE, and MAE error measures. Recurrent neural networks that used the TRAINBR training function and the Purlin function were adopted to predict the production of dates in Iraq, which gives the lowest error value for the MSE, MAPE, and MAE error measures.",
        "link": "http://dx.doi.org/10.55529/ijrise.41.22.30"
    },
    {
        "id": 1425,
        "title": "The Point Of Interest (POI) Recommendation for Mobile Digital Culture Heritage (M-DCH) Based on the Behavior Analysis using the Recurrent Neural Networks (RNN) and User-Collaborative Filtering",
        "authors": "Chung-Ming Huang Chung-Ming Huang, Chen-Yi Wu Chung-Ming Huang",
        "published": "2021-7",
        "citations": 4,
        "abstract": "",
        "link": "http://dx.doi.org/10.53106/160792642021072204010"
    },
    {
        "id": 1426,
        "title": "AI‐Based Weather Forecasting System for Smart Agriculture System Using a Recurrent Neural Networks (RNN) Algorithm",
        "authors": "T. Devi, N. Deepa, N. Gayathri, S. Rakesh Kumar",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781394166923.ch5"
    },
    {
        "id": 1427,
        "title": "Seismic Velocity Inversion via Physical Embedding Recurrent Neural Networks (RNN)",
        "authors": "Cai Lu, Chunlong Zhang",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "Seismic velocity inversion is one of the most critical issues in the field of seismic exploration and has long been the focus of numerous experts and scholars. In recent years, the advancement of machine learning technologies has infused new vitality into the research of seismic velocity inversion and yielded a wealth of research outcomes. Typically, seismic velocity inversion based on machine learning lacks control over physical processes and interpretability. Starting from wave theory and the physical processes of seismic data acquisition, this paper proposes a method for seismic velocity model inversion based on Physical Embedding Recurrent Neural Networks. Firstly, the wave equation is a mathematical representation of the physical process of acoustic waves propagating through a medium, and the finite difference method is an effective approach to solving the wave equation. With this in mind, we introduce the architecture of recurrent neural networks to describe the finite difference solution of the wave equation, realizing the embedding of physical processes into machine learning. Secondly, in seismic data acquisition, the propagation of acoustic waves from multiple sources through the medium represents a high-dimensional causal time series (wavefield snapshots), where the influential variable is the velocity model, and the received signals are the observations of the wavefield. This forms a forward modeling process as the forward simulation of the wavefield equation, and the use of error back-propagation between observations and calculations as the velocity inversion process. Through time-lapse inversion and by incorporating the causal information of wavefield propagation, the non-uniqueness issue in velocity inversion is mitigated. Through mathematical derivations and theoretical model analyses, the effectiveness and rationality of the method are demonstrated. In conjunction with simulation results for complex models, the method proposed in this paper can achieve velocity inversion in complex geological structures.",
        "link": "http://dx.doi.org/10.3390/app132413312"
    },
    {
        "id": 1428,
        "title": "MST-RNN: A Multi-Dimension Spatiotemporal Recurrent Neural Networks for Recommending the Next Point of Interest",
        "authors": "Chunshan Li, Dongmei Li, Zhongya Zhang, Dianhui Chu",
        "published": "2022-5-27",
        "citations": 5,
        "abstract": "With the increasing popularity of location-aware Internet-of-Vehicle services, the next-Point-of-Interest (POI) recommendation has gained significant research interest, predicting where drivers will go next from their sequential movements. Many researchers have focused on this problem and proposed solutions. Machine learning-based methods (matrix factorization, Markov chain, and factorizing personalized Markov chain) focus on a POI sequential transition. However, they do not recommend the user’s position for the next few hours. Neural network-based methods can model user mobility behavior by learning the representations of the sequence data in the high-dimensional space. However, they just consider the influence from the spatiotemporal dimension and ignore many important influences, such as duration time at a POI (Point of Interest) and the semantic tags of the POIs. In this paper, we propose a novel method called multi-dimension spatial–temporal recurrent neural networks (MST-RNN), which extends the ST-RNN and exploits the duration time dimension and semantic tag dimension of POIs in each layer of neural networks. Experiments on real-world vehicle movement data show that the proposed MST-RNN is effective and clearly outperforms the state-of-the-art methods.",
        "link": "http://dx.doi.org/10.3390/math10111838"
    },
    {
        "id": 1429,
        "title": "RNN-SURV: A Deep Recurrent Model for Survival Analysis",
        "authors": "Eleonora Giunchiglia, Anton Nemchenko, Mihaela van der Schaar",
        "published": "2018",
        "citations": 31,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-01424-7_3"
    },
    {
        "id": 1430,
        "title": "RECURRENT NEURAL NETWORK (RNN) ANALYSIS FOR BRAIN TUMOR CLASSIFICATION USING DECISION TREE CLASSIFIERS",
        "authors": "",
        "published": "2020-9-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31838/jcr.07.06.344"
    },
    {
        "id": 1431,
        "title": "Photovoltaic power prediction using a recurrent neural network RNN",
        "authors": "Mohamed Hamza Kermia, Dhaker Abbes, Jerome Bosche",
        "published": "2020-9-28",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/energycon48941.2020.9236461"
    },
    {
        "id": 1432,
        "title": "sRAKI-RNN: accelerated MRI with scan-specific recurrent neural networks using densely connected blocks",
        "authors": "Seyed Amir Hossein Hosseini, Chi Zhang, Kamil Ugurbil, Steen Moeller, Mehmet Akcakaya",
        "published": "2019-9-9",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2527949"
    },
    {
        "id": 1433,
        "title": "RECURRENT NEURAL NETWORK (RNN) ANALYSIS FOR BRAIN TUMOR CLASSIFICATION USING DECISION TREE CLASSIFIERS",
        "authors": "",
        "published": "2020-9-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31838/jcr.07.6.344"
    },
    {
        "id": 1434,
        "title": "Prediction of energy consumption using recurrent neural networks (RNN) and nonlinear autoregressive neural network with external input (NARX)",
        "authors": "Wan Muhammad Zafri Wan Yahaya, Fadhlan Hafizhelmi Kamaru Zaman, Mohd Fuad Abdul Latip",
        "published": "2020-3-1",
        "citations": 0,
        "abstract": "Recurrent Neural Networks (RNN) and Nonlinear Autoregressive Neural Network with External Input (NARX) are recently applied in predicting energy consumption. Energy consumption prediction for depth analysis of how electrical energy consumption is managed on Tower 2 Engineering Building is critical in order to reduce the energy usage and the operational cost. Prediction of energy consumption in this building will bring great benefits to the Faculty of Electrical Engineering UiTM Shah Alam. In this work, we present the comparative study on the performance of prediction of energy consumption in Tower 2 Engineering Building using RNN and NARX method. The model of RNN and NARX are trained using data collected using smart meters installed inside the building. The results after training and testing using RNN and NARX show that by using the recorded data we can accurately predict the energy consumption in the building. We also show that RNN model trained with normalized data performs better than NARX model.",
        "link": "http://dx.doi.org/10.11591/ijeecs.v17.i3.pp1215-1223"
    },
    {
        "id": 1435,
        "title": "ProxySense: A novel approach for gas concentration estimation using Long Short-Term Memory Recurrent Neural Network (LSTM-RNN)",
        "authors": "Nwamaka Okafor, Declan Delaney, Ugochukwu Mathew",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>When equipped with a reliable calibration model, Low-Cost Sensor (LCS) can be relied upon as an effective option for gas concentration estimation, providing robust and high spatio-temporal resolution data to replace large-scale analytical instruments. In this paper, we present ProxySense, a rapid and efficient approach for gas concentration estimation. The ProxySense pipeline consists of gas sensing unit made up of array of metal oxide LCS, data pre-processing including an effective approach based on Variatioanl Autoencoders (VAE) for handling missing sensor data and Long Short Term Memory Reccurrent Neural Network (LSTM-RNN) prediction model. We investigate the capability of ProxySense in exploiting the deep characteristics that exist in multi-sensors’ responses to predict the concentration of a gas for which no specific sensor is included in a multi-sensor device. We evaluated ProxySense for benzene (C6H6) and carbon monoxide (CO) concentration predictions and compared the performances to multiple baselines by means of prediction error characterization. We further studied the relationship between model performance and training length and showed ProxySense to be highly accurate for gas concentration prediction even for small number of training period.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.20306418"
    },
    {
        "id": 1436,
        "title": "Recurrent Neural Network (RNN) and Sequence Feature Models",
        "authors": "",
        "published": "2022-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811254185_0016"
    },
    {
        "id": 1437,
        "title": "PSB-RNN: A Processing-in-Memory Systolic Array Architecture using Block Circulant Matrices for Recurrent Neural Networks",
        "authors": "Nagadastagiri Challapalle, Sahithi Rampalli, Makesh Chandran, Gurpreet Kalsi, Sreenivas Subramoney, John Sampson, Vijaykrishnan Narayanan",
        "published": "2020-3",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/date48585.2020.9116469"
    },
    {
        "id": 1438,
        "title": "Vehicle Seismic Signal Recognition based on Recurrent Neural Network (RNN)",
        "authors": "Xiong Li, Nan Wang, Yuhang Ding",
        "published": "2020-11-27",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icus50048.2020.9274828"
    },
    {
        "id": 1439,
        "title": "ProxySense: A novel approach for gas concentration estimation using Long Short-Term Memory Recurrent Neural Network (LSTM-RNN)",
        "authors": "Nwamaka Okafor, Declan Delaney, Ugochukwu Mathew",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>When equipped with a reliable calibration model, Low-Cost Sensor (LCS) can be relied upon as an effective option for gas concentration estimation, providing robust and high spatio-temporal resolution data to replace large-scale analytical instruments. In this paper, we present ProxySense, a rapid and efficient approach for gas concentration estimation. The ProxySense pipeline consists of gas sensing unit made up of array of metal oxide LCS, data pre-processing including an effective approach based on Variatioanl Autoencoders (VAE) for handling missing sensor data and Long Short Term Memory Reccurrent Neural Network (LSTM-RNN) prediction model. We investigate the capability of ProxySense in exploiting the deep characteristics that exist in multi-sensors’ responses to predict the concentration of a gas for which no specific sensor is included in a multi-sensor device. We evaluated ProxySense for benzene (C6H6) and carbon monoxide (CO) concentration predictions and compared the performances to multiple baselines by means of prediction error characterization. We further studied the relationship between model performance and training length and showed ProxySense to be highly accurate for gas concentration prediction even for small number of training period.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.20306418.v1"
    },
    {
        "id": 1440,
        "title": "Hybrid Convolutional Recurrent Neural Networks Outperform CNN and RNN in Task-state EEG Detection for Parkinson's Disease",
        "authors": "Xinjie Shi, Tianqi Wang, Lan Wang, Hanjun Liu, Nan Yan",
        "published": "2019-11",
        "citations": 31,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/apsipaasc47483.2019.9023190"
    },
    {
        "id": 1441,
        "title": "PG-RNN: using position-gated recurrent neural networks for aspect-based sentiment classification",
        "authors": "Qingchun Bai, Jie Zhou, Liang He",
        "published": "2022-2",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11227-021-04019-5"
    },
    {
        "id": 1442,
        "title": "Deepfake Video Detection by Combining Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN)",
        "authors": "Yunes Al-Dhabi, Shuang Zhang",
        "published": "2021-8-20",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/csaiee54046.2021.9543264"
    },
    {
        "id": 1443,
        "title": "iR6mA-RNN: Identifying N6-Methyladenosine Sites in Eukaryotic Transcriptomes using Recurrent Neural Networks and Sequence-embedded Features",
        "authors": "Binh P. Nguyen, Thanh-Hoang Nguyen-Vo, Loc Nguyen, Quang H. Trinh, Chalinor Baliuag, Trang T. T. Do, Susanto Rahardja",
        "published": "2023-7-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ssp53291.2023.10207989"
    },
    {
        "id": 1444,
        "title": "E-RNN: Design Optimization for Efficient Recurrent Neural Networks in FPGAs",
        "authors": "Zhe Li, Caiwen Ding, Siyue Wang, Wujie Wen, Youwei Zhuo, Chang Liu, Qinru Qiu, Wenyao Xu, Xue Lin, Xuehai Qian, Yanzhi Wang",
        "published": "2019-2",
        "citations": 45,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/hpca.2019.00028"
    },
    {
        "id": 1445,
        "title": "RNN-DBSVM: Optimal Recurrent Neural Network Density Based Support Vector Machine",
        "authors": "Karim El Moutaouakil, Abdellatif Elouissari, Adrian Olaru, Vasile Palade, Mihaela Ciorei",
        "published": "No Date",
        "citations": 0,
        "abstract": "When implementing SVMs, two major problems are encountered: (a) the number of local minima increases exponentially with the number of samples and (b) the quantity of required computer storage, required for a regular quadratic programming solver, increases by an exponential mag-nitude as the problem size expands.  The Kernel-Adatron family of algorithms gaining attention lately which has allowed it to handle very large classification and regression problems. Howev-er, these methods treat different types of samples (Noise, border, and core) in the same manner, which causes searches in unpromising areas and increases the number of iterations. In this work, we introduce a hybrid method to overcome these shortcomings, namely Optimal Recurrent Neu-ral Network Density Based Support Vector Machine (Opt-RNN-DBSVM). This method consists of four steps: (a) characterization of different samples, (b) elimination of samples with a low probability of being a support vector, (c) construction of an appropriate recurrent neural network based on an original energy function, and (d) solution of the system of differential equations, managing the dynamics of the RNN, using the Euler-Cauchy method involving an optimal time step. The RNN remembers the regions explored during the search process thanks to its recurrent architecture. We demonstrated that RNN-SVM converges to feasible support vectors and Opt-RNN-DBSVM has a very low time complexity compared to RNN-SVM with constant time step, and KAs-SVM. Several experiments were performed on academic data sets. We used several classification performances measures to compare Opt-RNN-DBSVM to different classification methods and the results obtained show the good performance of the proposed method.",
        "link": "http://dx.doi.org/10.20944/preprints202307.1306.v1"
    },
    {
        "id": 1446,
        "title": "Quaternionic Recurrent Correlation Neural Networks",
        "authors": "Marcos Eduardo Valle",
        "published": "2018-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2018.8489714"
    },
    {
        "id": 1447,
        "title": "Cyclic models and recurrent neural networks",
        "authors": "Thomas P. Trappenberg",
        "published": "2019-11-28",
        "citations": 0,
        "abstract": "This chapter discusses models with cyclic dependencies. There are two principle architectures that are discussed. The first principle architecture of cyclic graphs comprises directed graphs similar to the Bayesian networks except that they include loops. Formally, such networks represent dynamical systems in the wider context and therefore represent some form of temporal modeling. The second type of models have connections between neurons that are bi-directional. These types of networks will be discussed in the context of stochastic units in the second half of this chapter.",
        "link": "http://dx.doi.org/10.1093/oso/9780198828044.003.0009"
    },
    {
        "id": 1448,
        "title": "A Recurrent Neural Network (RNN) based approach for reliably classifying land usage from satellite imagery",
        "authors": "I. Kastanis",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18174/fairdata2018.16279"
    },
    {
        "id": 1449,
        "title": "A MEMS IMU De-Noising Method Using Long Short Term Memory Recurrent Neural Networks (LSTM-RNN)",
        "authors": "Changhui Jiang, Shuai Chen, Yuwei Chen, Boya Zhang, Ziyi Feng, Hui Zhou, Yuming Bo",
        "published": "2018-10-15",
        "citations": 77,
        "abstract": "Microelectromechanical Systems (MEMS) Inertial Measurement Unit (IMU) containing a three-orthogonal gyroscope and three-orthogonal accelerometer has been widely utilized in position and navigation, due to gradually improved accuracy and its small size and low cost. However, the errors of a MEMS IMU based standalone Inertial Navigation System (INS) will diverge over time dramatically, since there are various and nonlinear errors contained in the MEMS IMU measurements. Therefore, MEMS INS is usually integrated with a Global Positioning System (GPS) for providing reliable navigation solutions. The GPS receiver is able to generate stable and precise position and time information in open sky environment. However, under signal challenging conditions, for instance dense forests, city canyons, or mountain valleys, if the GPS signal is weak and even is blocked, the GPS receiver will fail to output reliable positioning information, and the integration system will fade to an INS standalone system. A number of effects have been devoted to improving the accuracy of INS, and de-nosing or modelling the random errors contained in the MEMS IMU have been demonstrated to be an effective way of improving MEMS INS performance. In this paper, an Artificial Intelligence (AI) method was proposed to de-noise the MEMS IMU output signals, specifically, a popular variant of Recurrent Neural Network (RNN) Long Short Term Memory (LSTM) RNN was employed to filter the MEMS gyroscope outputs, in which the signals were treated as time series. A MEMS IMU (MSI3200, manufactured by MT Microsystems Company, Hebei, China) was employed to test the proposed method, a 2 min raw gyroscope data with 400 Hz sampling rate was collected and employed in this testing. The results show that the standard deviation (STD) of the gyroscope data decreased by 60.3%, 37%, and 44.6% respectively compared with raw signals, and on the other way, the three-axis attitude errors decreased by 15.8%, 18.3% and 51.3% individually. Further, compared with an Auto Regressive and Moving Average (ARMA) model with fixed parameters, the STD of the three-axis gyroscope outputs decreased by 42.4%, 21.4% and 21.4%, and the attitude errors decreased by 47.6%, 42.3% and 52.0%. The results indicated that the de-noising scheme was effective for improving MEMS INS accuracy, and the proposed LSTM-RNN method was more preferable in this application.",
        "link": "http://dx.doi.org/10.3390/s18103470"
    },
    {
        "id": 1450,
        "title": "FE-RNN: A fuzzy embedded recurrent neural network for improving interpretability of underlying neural network",
        "authors": "James Chee Min Tan, Qi Cao, Chai Quek",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ins.2024.120276"
    },
    {
        "id": 1451,
        "title": "Retinal OCT Image Classification Based on CNN-RNN Unified Neural Networks",
        "authors": "Xue-Feng Jiang Xue-Feng Jiang, Ken-Cheng Xue-Feng Jiang, Zhi-De Li Ken-Cheng",
        "published": "2024-2",
        "citations": 0,
        "abstract": "\n                        <p>Computer-aided diagnosis of retinopathy is a hot research topic in the field of medical image classification, where optical coherence tomography (OCT) is an important basis for the diagnosis of ophthalmic diseases. Traditional approaches to multi-label image classification learn independent classifiers for each category and employ ranking or thresholding on the classification results. These techniques, although working well, fail to explicitly exploit the label dependencies in an image. In this paper, two publicly available retinal OCT image datasets are integrated and screened. Then, an end-to-end deep learning algorithmic framework based on CNN-RNN Unified Neural Networks was proposed to automatically and reliably classify six categories of retinal OCT images. Numerical results suggest that the proposed algorithm works well in terms of accuracy, precision, sensitivity and specificity, approaching or even partially surpassing the performance of clinical experts. It is valuable in promoting computer-aided diagnosis towards practical clinical applications and improving the efficiency of clinical diagnosis of retinal diseases.</p>\n<p>&nbsp;</p>\n                    ",
        "link": "http://dx.doi.org/10.53106/199115992024023501021"
    },
    {
        "id": 1452,
        "title": "Intents Categorization for Chatbot Development Using Recurrent Neural Network (RNN) Learning",
        "authors": "Adi Prasetyo, Heru Agus Santoso",
        "published": "2021-3-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icaccs51430.2021.9441947"
    },
    {
        "id": 1453,
        "title": "Learning Device Models with Recurrent Neural Networks",
        "authors": "John Clemens",
        "published": "2018-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2018.8489466"
    },
    {
        "id": 1454,
        "title": "Recurrent Neural Networks",
        "authors": "Charu Aggarwal",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-29642-0_8"
    },
    {
        "id": 1455,
        "title": "Prediction of Wastewater Treatment Plant Effluent Water Quality Using Recurrent Neural Network (RNN) Models",
        "authors": "Praewa Wongburi, Jae K. Park",
        "published": "2023-9-22",
        "citations": 3,
        "abstract": "Artificial Intelligence (AI) has recently emerged as a powerful tool with versatile applications spanning various domains. AI replicates human intelligence processes through machinery and computer systems, finding utility in expert systems, image and speech recognition, machine vision, and natural language processing (NLP). One notable area with limited exploration pertains to using deep learning models, specifically Recurrent Neural Networks (RNNs), for predicting water quality in wastewater treatment plants (WWTPs). RNNs are purpose-built for handling sequential data, featuring a feedback mechanism. However, standard RNNs may exhibit limitations in accommodating both short-term and long-term dependencies when addressing intricate time series problems. The solution to this challenge lies in adopting Long Short-Term Memory (LSTM) cells, known for their inherent memory management through a ‘forget gate’ mechanism. In general, LSTM architecture demonstrates superior performance. WWTP data represent a historical series influenced by fluctuating environmental conditions. This study employs simple RNNs and LSTM architecture to construct prediction models for effluent parameters, systematically assessing their performance through various training data scenarios and model architectures. The primary objective was to determine the most suitable WWTP dataset model. The study revealed that an epoch setting of 50 and a batch size of 100 yielded the lowest training time and root mean square error (RMSE) values for both RNN and LSTM models. Furthermore, when these models are applied to predict effluent parameters, they exhibit precise RMSE values for all parameters. The study results can be applied to detect potential upsets in WWTP operations.",
        "link": "http://dx.doi.org/10.3390/w15193325"
    },
    {
        "id": 1456,
        "title": "Deep Learning in Python: Different Types of Deep Learning Network",
        "authors": "",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4135/9781526493439"
    },
    {
        "id": 1457,
        "title": "Fake News (Hoax) Detection on Social Media Using Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) Methods",
        "authors": "Reyhan Septri Asta, Erwin Budi Setiawan",
        "published": "2023-8-23",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icoict58202.2023.10262617"
    },
    {
        "id": 1458,
        "title": "Recurrent Neural Network (\n            <scp>RNN</scp>\n            )",
        "authors": "",
        "published": "2023-10-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781394209118.ch9"
    },
    {
        "id": 1459,
        "title": "Recurrent Neural Network (RNN), Long short-term memory (LSTM) for Aerosol Optical Depth (AOD) using NASA’s MERRA-2 Reanalysis",
        "authors": "Mohammed Magooda, Mohamed Eltahan, Karim Moharm",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/essoar.10503933.1"
    },
    {
        "id": 1460,
        "title": "Image to Text Processing Using Convolution Neural Networks",
        "authors": "V. Pattabiraman, R. Maheswari",
        "published": "2022-5-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003307822-4"
    },
    {
        "id": 1461,
        "title": "Recurrent Neural Networks",
        "authors": "Charu C. Aggarwal",
        "published": "2018",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-94463-0_7"
    },
    {
        "id": 1462,
        "title": "Question–Answer System on Episodic Data Using Recurrent Neural Networks (RNN)",
        "authors": "Vineet Yadav, Vishnu Bharadwaj, Alok Bhatt, Ayush Rawal",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-32-9949-8_39"
    },
    {
        "id": 1463,
        "title": "Ransomware Protection Tool based on Recurrent Neural Network (RNN)",
        "authors": "Nandhini S",
        "published": "2020-5-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22214/ijraset.2020.5325"
    },
    {
        "id": 1464,
        "title": "Music Generation for Novices Using Recurrent Neural Network (RNN)",
        "authors": "Sahreen Sajad, S Dharshika, Merin Meleet",
        "published": "2021-9-24",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icses52305.2021.9633906"
    },
    {
        "id": 1465,
        "title": "End-to-End Speech Recognition Using Recurrent Neural Network (RNN)",
        "authors": "Rene Avalloni de Morais, Baidya Nath Saha",
        "published": "2021-6-28",
        "citations": 0,
        "abstract": "Deep learning algorithms have received dramatic progress in the area of natural language processing and automatic human speech recognition. However, the accuracy of the deep learning algorithms depends on the amount and quality of the data and training deep models requires high-performance computing resources. In this backdrop, this paper adresses an end-to-end speech recognition system where we finetune Mozilla DeepSpeech architecture using two different datasets: LibriSpeech clean dataset and Harvard speech dataset. We train Long Short Term Memory (LSTM) based deep Recurrent Neural Netowrk (RNN) models in Google Colab platform and use their GPU resources. Extensive experimental results demonstrate that Mozilla DeepSpeech model could be fine-tuned for different audio datasets to recognize speeches successfully.",
        "link": "http://dx.doi.org/10.21467/proceedings.115.20"
    },
    {
        "id": 1466,
        "title": "Removal of Motion Artifacts from ECG signals by Combination of Recurrent Neural Networks and Deep Neural Networks",
        "authors": "Muhammad Zubair",
        "published": "No Date",
        "citations": 0,
        "abstract": "<div><div><div><p>Electrocardiogram (ECG) is the graphical portrayal of heart usefulness. The ECG signals holds its significance in the discovery of heart irregularities. These ECG signals are frequently tainted by antiques from various sources. It is basic to diminish these curios and improve the exactness just as dependability to show signs of improvement results identified with heart usefulness. The most commonly disturbed artifact in ECG signals is Motion Artifacts (MA). In this paper, we have proposed a new concept on how machine learning algorithms can be used for de-noising the ECG signals. Towards the goal, a unique combination of Recurrent Neural Network (RNN) and Deep Neural Network (DNN) is used to efficiently remove MA. The proposed algorithm is validated using ECG records obtained from the MIT-BIH Arrhythmia Database. To eliminate MA using the proposed method, we have used Adam optimization algorithm to train and fit the contaminated ECG data in RNN and DNN models. Performance evaluation results in terms of SNR and RRMSE show that the proposed algorithm outperforms other existing MA removal methods without significantly distorting the morphologies of ECG signals.</p></div></div></div>",
        "link": "http://dx.doi.org/10.36227/techrxiv.14526828.v1"
    },
    {
        "id": 1467,
        "title": "Removal of Motion Artifacts from ECG signals by Combination of Recurrent Neural Networks and Deep Neural Networks",
        "authors": "Muhammad Zubair",
        "published": "No Date",
        "citations": 0,
        "abstract": "<div><div><div><p>Electrocardiogram (ECG) is the graphical portrayal of heart usefulness. The ECG signals holds its significance in the discovery of heart irregularities. These ECG signals are frequently tainted by antiques from various sources. It is basic to diminish these curios and improve the exactness just as dependability to show signs of improvement results identified with heart usefulness. The most commonly disturbed artifact in ECG signals is Motion Artifacts (MA). In this paper, we have proposed a new concept on how machine learning algorithms can be used for de-noising the ECG signals. Towards the goal, a unique combination of Recurrent Neural Network (RNN) and Deep Neural Network (DNN) is used to efficiently remove MA. The proposed algorithm is validated using ECG records obtained from the MIT-BIH Arrhythmia Database. To eliminate MA using the proposed method, we have used Adam optimization algorithm to train and fit the contaminated ECG data in RNN and DNN models. Performance evaluation results in terms of SNR and RRMSE show that the proposed algorithm outperforms other existing MA removal methods without significantly distorting the morphologies of ECG signals.</p></div></div></div>",
        "link": "http://dx.doi.org/10.36227/techrxiv.14526828"
    },
    {
        "id": 1468,
        "title": "Chaos Theory of Random Recurrent Neural Networks",
        "authors": "Haiping Huang",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-7570-6_16"
    },
    {
        "id": 1469,
        "title": "Effect of dilution in asymmetric recurrent neural networks",
        "authors": "Viola Folli, Giorgio Gosti, Marco Leonetti, Giancarlo Ruocco",
        "published": "2018-8",
        "citations": 25,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neunet.2018.04.003"
    },
    {
        "id": 1470,
        "title": "Retracted: RNN Neural Network Model for Chinese-Korean Translation Learning",
        "authors": "",
        "published": "2022-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1155/2022/9816219"
    },
    {
        "id": 1471,
        "title": "Deep-Sentiment: An Effective Deep Sentiment Analysis Using a Decision-Based Recurrent Neural Network (D-RNN)",
        "authors": "Putta Durga, Deepthi Godavarthi",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2023.3320738"
    },
    {
        "id": 1472,
        "title": "An Effective Recurrent Neural Network (RNN) based Intrusion Detection via Bi-directional Long Short-Term Memory",
        "authors": "S. Sivamohan, S.S. Sridhar, S. Krishnaveni",
        "published": "2021-6-25",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/conit51480.2021.9498552"
    },
    {
        "id": 1473,
        "title": "Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network",
        "authors": "Alex Sherstinsky",
        "published": "2020-3",
        "citations": 1897,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.physd.2019.132306"
    },
    {
        "id": 1474,
        "title": "M049 Classification of pancreatic cancer stadium using recurrent neural network (RNN) model algorithm",
        "authors": "R. Fajar, N.I. Kurniastuti",
        "published": "2022-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.cca.2022.04.361"
    },
    {
        "id": 1475,
        "title": "Fading memory as inductive bias in residual recurrent networks",
        "authors": "Igor Dubinin, Felix Effenberger",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neunet.2024.106179"
    },
    {
        "id": 1476,
        "title": "Machine Learning for Proxy Modeling of Dynamic Reservoir Systems: Deep Neural Network DNN and Recurrent Neural Network RNN Applications",
        "authors": "Soumi Chaki, Yevgeniy Zagayevskiy, Xuebei Shi, Terry Wong, Zainub Noor",
        "published": "2020-1-13",
        "citations": 13,
        "abstract": "\nA methodology to construct deep neural network- (DNN) and recurrent neural network- (RNN) based proxy flow models is presented; these can reduce computational time of the flow simulation runs in the routine reservoir engineering workflows, such as history matching or optimization. A comparison of these two techniques shows that the DNN model generates predictions more quickly, but the RNN model provides better quality. In addition, RNN-based proxy flow models can make predictions for times after those included in the training data set. Both approaches can reduce computational time by a factor of up to 100 in comparison to the full-physics flow simulator. An example of the proxy flow model application is successfully demonstrated in an exhaustive search history matching exercise. All developments are shown on a synthesized Brugge petroleum reservoir.",
        "link": "http://dx.doi.org/10.2523/iptc-20118-ms"
    },
    {
        "id": 1477,
        "title": "MUSE-RNN: A Multilayer Self-Evolving Recurrent Neural Network for Data Stream Classification",
        "authors": "Monidipa Das, Mahardhika Pratama, Septiviana Savitri, Jie Zhang",
        "published": "2019-11",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdm.2019.00021"
    },
    {
        "id": 1478,
        "title": "An Approach to Predict a Student’s Academic Performance using Recurrent Neural Network (RNN)",
        "authors": "Arindam Mondal, Joydeep Mukherjee",
        "published": "2018-7-16",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5120/ijca2018917352"
    },
    {
        "id": 1479,
        "title": "Recurrent Neural Networks Analysis for Embedded Systems",
        "authors": "Gonçalo Neves, Jean-Baptiste Chaudron, Arnaud Dion",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010715700003063"
    },
    {
        "id": 1480,
        "title": "Recurrent Neural Networks",
        "authors": "Amit Kumar Tyagi, Ajith Abraham",
        "published": "2022-5-26",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003307822"
    },
    {
        "id": 1481,
        "title": "SS-RNN: A Strengthened Skip Algorithm for Data Classification Based on Recurrent Neural Networks",
        "authors": "Wenjie Cao, Ya-Zhou Shi, Huahai Qiu, Bengong Zhang",
        "published": "2021-10-13",
        "citations": 0,
        "abstract": "Recurrent neural networks are widely used in time series prediction and classification. However, they have problems such as insufficient memory ability and difficulty in gradient back propagation. To solve these problems, this paper proposes a new algorithm called SS-RNN, which directly uses multiple historical information to predict the current time information. It can enhance the long-term memory ability. At the same time, for the time direction, it can improve the correlation of states at different moments. To include the historical information, we design two different processing methods for the SS-RNN in continuous and discontinuous ways, respectively. For each method, there are two ways for historical information addition: 1) direct addition and 2) adding weight weighting and function mapping to activation function. It provides six pathways so as to fully and deeply explore the effect and influence of historical information on the RNNs. By comparing the average accuracy of real datasets with long short-term memory, Bi-LSTM, gated recurrent units, and MCNN and calculating the main indexes (Accuracy, Precision, Recall, and F1-score), it can be observed that our method can improve the average accuracy and optimize the structure of the recurrent neural network and effectively solve the problems of exploding and vanishing gradients.",
        "link": "http://dx.doi.org/10.3389/fgene.2021.746181"
    },
    {
        "id": 1482,
        "title": "Two-timescale recurrent neural networks for distributed minimax optimization",
        "authors": "Zicong Xia, Yang Liu, Jiasen Wang, Jun Wang",
        "published": "2023-8",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.06.003"
    },
    {
        "id": 1483,
        "title": "Considerations in using recurrent neural networks to probe neural dynamics",
        "authors": "Jonathan C Kao",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractRecurrent neural networks (RNNs) are increasingly being used to model complex cognitive and motor tasks performed by behaving animals. Here, RNNs are trained to reproduce animal behavior while also recapitulating key statistics of empirically recorded neural activity. In this manner, the RNN can be viewed as an in silico circuit whose computational elements share similar motifs with the cortical area it is modeling. Further, as the RNN’s governing equations and parameters are fully known, they can be analyzed to propose hypotheses for how neural populations compute. In this context, we present important considerations when using RNNs to model motor behavior in a delayed reach task. First, by varying the network’s nonlinear activation and rate regularization, we show that RNNs reproducing single neuron firing rate motifs may not adequately capture important population motifs. Second, by visualizing the RNN’s dynamics in low-dimensional projections, we demonstrate that even when RNNs recapitulate key neurophysiological features on both the single neuron and population levels, it can do so through distinctly different dynamical mechanisms. To militate between these mechanisms, we show that an RNN consistent with a previously proposed dynamical mechanism is more robust to noise. Finally, we show that these dynamics are sufficient for the RNN to generalize to a target switch task it was not trained on. Together, these results emphasize important considerations when using RNN models to probe neural dynamics.",
        "link": "http://dx.doi.org/10.1101/364489"
    },
    {
        "id": 1484,
        "title": "Recurrent Neural Networks",
        "authors": "Ke-Lin Du, M. N. S. Swamy",
        "published": "2019",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4471-7452-3_12"
    },
    {
        "id": 1485,
        "title": "Composing Multi-Instrumental Music with Recurrent Neural Networks",
        "authors": "David Samuel, Martin Pilat",
        "published": "2019-7",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2019.8852430"
    },
    {
        "id": 1486,
        "title": "Music Artist Classification with Convolutional Recurrent Neural Networks",
        "authors": "Zain Nasrullah, Yue Zhao",
        "published": "2019-7",
        "citations": 24,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2019.8851988"
    },
    {
        "id": 1487,
        "title": "Applications of Recurrent Neural Network",
        "authors": "Kusumika Krori Dutta, S. Poornima, Ramit Sharma, Deebul Nair, Paul G. Ploeger",
        "published": "2022-5-26",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003307822-3"
    },
    {
        "id": 1488,
        "title": "MPA-RNN: A Novel Attention-Based Recurrent Neural Networks for Total Nitrogen Prediction",
        "authors": "Jingxuan Geng, Chunhua Yang, Yonggang Li, Lijuan Lan, Qiwu Luo",
        "published": "2022-10",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tii.2022.3161990"
    },
    {
        "id": 1489,
        "title": "ECT-LSTM-RNN: An Electrical Capacitance Tomography Model-Based Long Short-Term Memory Recurrent Neural Networks for Conductive Materials",
        "authors": "Wael Deabes, Alaa Sheta, Malik Braik",
        "published": "2021",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2021.3079447"
    },
    {
        "id": 1490,
        "title": "Neural identification using recurrent high-order neural networks for discrete nonlinear systems with unknown time delays",
        "authors": "",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-817078-6.00011-8"
    },
    {
        "id": 1491,
        "title": "GENDER CLASSIFICATION BASED ON VOICE USING RECURRENT NEURAL NETWORK (RNN)",
        "authors": "Diva Tifanny Adherda, Missi Hikmatyar,  Ruuhwan",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "The information technology field continues to progress rapidly. Technological progress is kept in check with such factors as touch, sight, and sound. Each man with another man has a characteristic difference, one that can be seen is by his voice. The processing of sound is an essential concept to all kinds of systems that require human interaction in its daily activities. One of the techniques used in processing speech is classification, which has a direct effect on speech recognition systems. SimpleRNN and LSTM are models of deep learning that can be used to classify sentiment. It can process data in such a sequence as sound, video, and text. These results provide accuracy 90% of the test data and 95% accuracy to the training data.",
        "link": "http://dx.doi.org/10.35457/antivirus.v17i1.3049"
    },
    {
        "id": 1492,
        "title": "Recurrent networks with soft-thresholding nonlinearities for lightweight coding",
        "authors": "MohammadMehdi Kafashan, ShiNung Ching",
        "published": "2017-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neunet.2017.07.008"
    },
    {
        "id": 1493,
        "title": "Recognition of handwritten text using long short term memory (LSTM) recurrent neural network (RNN)",
        "authors": "I. Joe Louis Paul, S. Sasirekha, D. Raghul Vishnu, K. Surya",
        "published": "2019",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/1.5097522"
    },
    {
        "id": 1494,
        "title": "Feature Expansion Using GloVe for Hate Speech Detection using Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) Method in Twitter",
        "authors": "Vincent Williams Jonathan, Erwin Budi Setiawan",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icodsa58501.2023.10277204"
    },
    {
        "id": 1495,
        "title": "Meteorological Data Forecast using RNN",
        "authors": "Stefan Balluff, Jörg Bendfeld, Stefan Krauter",
        "published": "2020",
        "citations": 2,
        "abstract": "Gathering knowledge not only of the current but also the upcoming wind speed is getting more and more important as the experience of operating and maintaining wind turbines is increasing. Not only with regards to operation and maintenance tasks such as gearbox and generator checks but moreover due to the fact that energy providers have to sell the right amount of their converted energy at the European energy markets, the knowledge of the wind and hence electrical power of the next day is of key importance. Selling more energy as has been offered is penalized as well as offering less energy as contractually promised. In addition to that the price per offered kWh decreases in case of a surplus of energy. Achieving a forecast there are various methods in computer science: fuzzy logic, linear prediction or neural networks. This paper presents current results of wind speed forecasts using recurrent neural networks (RNN) and the gradient descent method plus a backpropagation learning algorithm. Data used has been extracted from NASA's Modern Era-Retrospective analysis for Research and Applications (MERRA) which is calculated by a GEOS-5 Earth System Modeling and Data Assimilation system. The presented results show that wind speed data can be forecasted using historical data for training the RNN. Nevertheless, the current set up system lacks robustness and can be improved further with regards to accuracy.",
        "link": "http://dx.doi.org/10.4018/978-1-7998-0414-7.ch050"
    },
    {
        "id": 1496,
        "title": "Automated Human Activity Recognition by Colliding Bodies Optimization-based Optimal Feature Selection with Recurrent Neural Network (RNN)",
        "authors": "Pankaj Khatiwada, Matrika Subedi, Ayan Chatterjee, Martin Wulf Gerdes",
        "published": "No Date",
        "citations": 7,
        "abstract": "— In a smart healthcare system,&quot; Human Activity Recognition (HAR)&quot; is considered as an efficient approach in pervasive computing from activity sensor readings. The &quot;Ambient Assisted Living (AAL)&quot; in the home or community helps the people to provide independent care and enhanced living quality. However, many AAL models are restricted to multiple factors that include both the computational cost and system complexity. Moreover, the HAR concept has more relevance because of its applications, such as content-based video search, sports play analysis, crowd behavior prediction systems, patient monitoring systems, and surveillance systems. This paper attempts to implement the HAR system using a popular deep learning algorithm, namely &quot;Recurrent Neural Network (RNN)&quot; with the activity data collected from smart activity sensors over time, and it is publicly available in the &quot;UC Irvine Machine Learning Repository (UCI)&quot;. The proposed model involves three processes: (1) data collection, (b) optimal feature learning, and (c) activity recognition. The data gathered from the benchmark repository was initially subjected to optimal feature selection that helped to select the most significant features. The proposed optimal feature selection method is based on a new meta-heuristic algorithm called &quot;Colliding Bodies Optimization (CBO)&quot;. An objective function derived from the recognition accuracy has been used for accomplishing the optimal feature selection. The proposed model on the concerned benchmark dataset outperformed the conventional models with enhanced performance.",
        "link": "http://dx.doi.org/10.20944/preprints202010.0367.v1"
    },
    {
        "id": 1497,
        "title": "Few-shot transfer learning of a recurrent neural network (RNN) for holographic image reconstruction",
        "authors": "Luzhe Huang, Xilin Yang, Tairan Liu, Aydogan Ozcan",
        "published": "2022",
        "citations": 0,
        "abstract": "We demonstrate few-shot generalization of an RNN-based holographic image reconstruction network to small datasets of new sample/tissue types never seen in training, which achieved faster convergence and improved reconstruction quality with less trainable parameters.",
        "link": "http://dx.doi.org/10.1364/fio.2022.fth3b.3"
    },
    {
        "id": 1498,
        "title": "Implementation of Recurrent Neural Network (RNN) for Question Similarity Identification in Indonesian Language",
        "authors": "Muhammad Iqbal,  Hasmawati, Ade Romadhony",
        "published": "2023-12-28",
        "citations": 0,
        "abstract": "In a question-and-answer forum, the identification of question similarity is used to determine how similar two questions are. This procedure makes sure that user-submitted questions are compared to the questions in a database for matches to improve system performance on the online Q&A platform. Currently, question similarity is mostly done in foreign languages. The purpose of this research is to identify question similarities and evaluate the effectiveness of the methods used in Indonesian language questions. The data used is a public dataset with labeled pairs of questions as 0 and 1 where label 0 for different pairs of questions and label 1 for the same pairs of questions. The method used is a Recurrent Neural Network (RNN) with the Manhattan Distance approach to calculate the similarity distance between two questions. The question pairs are taken as two inputs with a reference label to identify the similarity distance between the two question inputs. We evaluated the model using three different optimizers namely RMSprop, Adam, and Adagrad. The best results were obtained using the Adam optimizer with 80:20 ratio split-data and overall accuracy is 76%, precision is 74%, recall is 98.8%, and F1-score is 85.1%.",
        "link": "http://dx.doi.org/10.15575/join.v8i2.1138"
    },
    {
        "id": 1499,
        "title": "Multi-Decoder RNN Autoencoder Based on Variational Bayes Method",
        "authors": "Daisuke Kaji, Kazuho Watanabe, Masahiro Kobayashi",
        "published": "2020-7",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn48605.2020.9206686"
    },
    {
        "id": 1500,
        "title": "Why Layering in Recurrent Neural Networks? A DeepESN Survey",
        "authors": "Claudio Gallicchio, Alessio Micheli",
        "published": "2018-7",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2018.8489368"
    }
]