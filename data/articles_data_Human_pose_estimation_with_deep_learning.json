[
    {
        "id": 27905,
        "title": "Human Pose Estimation Using Deep Learning Models",
        "authors": "Fırgat MURADLI, Serap ÇAKAR, Feyza ÇEREZCİ, Gülüzar ÇİT",
        "published": "2023-3-3",
        "citations": 0,
        "abstract": "In the last decade, there has been a lot of research into recovering 3D human poses from images. The current datasets need to address frequent exposure estimation problems adequately. However, these are shared resources to assess, inform, and contrast various models. Deep learning models are widely utilized and perform at high levels in many branches of research and engineering. So these models are used in this study with the help of the OpenCV and Keras libraries, which are open-source programs. Providing significant improvements in diversity and difficulty, the MPII Human Pose dataset is used to train and test the ResNet50 and VGG16 models. The validation rate of the dataset is shown to evaluate the model's performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.16984/saufenbilder.977793"
    },
    {
        "id": 27906,
        "title": "HUMAN POSE ESTIMATION SYSTEM USING DEEP LEARNING ALGORITHMS",
        "authors": "Daniil Vyshnivskyi, Oleksii Liashenko, Nataliia Yeromina",
        "published": "2023-6-9",
        "citations": 0,
        "abstract": "The purpose of this work is the software implementation of neural network that can solve problem of Human Pose Estimation. With rapid improvements of neural network models and computing resources over last 10 years it’s become possible to automate a lot of processes, carry out research and improve quality of life. One of the directions is Computer Vision: it allows to recognize objects, track motions, image segmentation, facial recognition etc. Human pose estimation is the part of Computer Vision area of research. It allows to capture human pose from a video or an image and have many uses in medicine, sport, augmented reality, video games etc. Therefore, the goal of this work is to find and optimize algorithm, that is relatively accurate, for identifying and classifying the joints in the human body. To achieve the goal, the following tasks were solved: current methods and technologies that is commonly used to solve problem of human pose estimation were reviewed and analyzed, artificial neural networks were used as a mathematical apparatus for the model, software implementation for human pose estimation was developed and tested, outputs from model were analyzed and evaluated, results and conclusion were formulated.",
        "keywords": "",
        "link": "http://dx.doi.org/10.26906/sunz.2023.2.075"
    },
    {
        "id": 27907,
        "title": "Research advanced in human pose estimation based on deep learning",
        "authors": "YE XIA, Xinxue Jiang, Liaowenjin Yan",
        "published": "2023-3-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2667904"
    },
    {
        "id": 27908,
        "title": "Study on Deep Learning Models for Human Pose Estimation and its Real Time Application",
        "authors": "Jyoti Jangade, Kanojia Sindhuben Babulal",
        "published": "2023-3-3",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iscon57294.2023.10112004"
    },
    {
        "id": 27909,
        "title": "Deep learning-based human pose estimation towards artworks classification",
        "authors": "Marcin Kutrzyński, Dariusz Król",
        "published": "2024-3-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/24751839.2024.2331866"
    },
    {
        "id": 27910,
        "title": "Yoga Pose Estimation along with Human Posture Detection using Deep Learning Approach",
        "authors": "D. Deepa, R. Velumani, S. Selvaraj",
        "published": "2023-3-22",
        "citations": 0,
        "abstract": "The yoga is the ancient art for keeping the human body healthy and fit and acquiring mental peace. This position in yoga almost matches with human posture for comfortable physical activity. The different sequence of body joint action leads to a specific yoga asana that has its own benefit for health. If asana are done in improper way, it would create a bad impact not only in health but also in mental peace. The advancement in computer vision technology help the yoga practitioner identify if they are doing right asana by applying various machine learning and deep learning algorithms for pose estimation. This article has done the concise literature survey on different machine and deep learning algorithm available in computer vision technology. The survey portraits the different classification for human posture estimation and yoga pose estimation along with their contributions and specific difference in between them. Especially the CNN, RNN and LSTM algorithm evolution is briefly narrated in this concise survey for yoga pose estimation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/2/20220625"
    },
    {
        "id": 27911,
        "title": "3D Human Pose Estimation and Posture Correction Using Deep Learning and Optimization Methods",
        "authors": "Jin-Young Choi, Eun-Ju Ha, Jong-Wook Kim",
        "published": "2023-11-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.15625/vap.2023.0116"
    },
    {
        "id": 27912,
        "title": "Human Pose Estimation Using Commodity WiFi and Deep Learning Approach",
        "authors": "Zhengjie Wang, Wenchao Wang, Jianhang Li, Qingwei Zhang, Zhaolei Dong, Yinjing Guo",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icftic59930.2023.10456071"
    },
    {
        "id": 27913,
        "title": "Computer Vision &amp; Deep Learning based Realtime and Pre-Recorded Human Pose Estimation",
        "authors": "Milind Shah, Kinjal Gandhi, Bhagyesha M Pandhi, Priyanka Padhiyar, Sheshang Degadwala",
        "published": "2023-5-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaaic56838.2023.10141279"
    },
    {
        "id": 27914,
        "title": "6-DoF Pose Estimation from Stereo LiDAR of Actual Machine using Deep Learning",
        "authors": "Shintaro Hashimoto, Yu Nakajima, Naoki Ishihama",
        "published": "2023-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aero55745.2023.10115618"
    },
    {
        "id": 27915,
        "title": "Real-Time Human Pose Estimation on Embedded Devices Based on Deep Learning",
        "authors": "HE Caishi, WU Sijia, Lu Yan, Dou Zihao, Yang Feng",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccwamtip60502.2023.10387117"
    },
    {
        "id": 27916,
        "title": "Deep Learning-Based Standardized Evaluation and Human Pose Estimation: A Novel Approach to Motion Perception",
        "authors": "Yuzhong Liu, Tianfan Zhang, Zhe Li, Lequan Deng",
        "published": "2023-10-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18280/ts.400549"
    },
    {
        "id": 27917,
        "title": "Deep Learning-based Head Pose Estimation for Enhancing Nonverbal Communication in Human-Robot Interaction",
        "authors": "Chan Young Yoon, Yoongu Lim, DongWook Lee, KwangEun Ko",
        "published": "2023-8-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ro-man57019.2023.10309461"
    },
    {
        "id": 27918,
        "title": "Traffic Surveillance: Vehicle Detection and Pose Estimation Based on Deep Learning",
        "authors": "FAjer Fadhil",
        "published": "2023-2-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.15199/48.2023.02.22"
    },
    {
        "id": 27919,
        "title": "gAIt: Deep Learning Based Evaluation of Injurious Running Biomechanics Using Pose Estimation",
        "authors": "Adarsh Iyer",
        "published": "2023-7-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icprs58416.2023.10179061"
    },
    {
        "id": 27920,
        "title": "Human Pose Estimation Using Deep Learning: A Systematic Literature Review",
        "authors": "Esraa Samkari, Muhammad Arif, Manal Alghamdi, Mohammed A. Al Ghamdi",
        "published": "2023-11-13",
        "citations": 4,
        "abstract": "Human Pose Estimation (HPE) is the task that aims to predict the location of human joints from images and videos. This task is used in many applications, such as sports analysis and surveillance systems. Recently, several studies have embraced deep learning to enhance the performance of HPE tasks. However, building an efficient HPE model is difficult; many challenges, like crowded scenes and occlusion, must be handled. This paper followed a systematic procedure to review different HPE models comprehensively. About 100 articles published since 2014 on HPE using deep learning were selected using several selection criteria. Both image and video data types of methods were investigated. Furthermore, both single and multiple HPE methods were reviewed. In addition, the available datasets, different loss functions used in HPE, and pretrained feature extraction models were all covered. Our analysis revealed that Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) are the most used in HPE. Moreover, occlusion and crowd scenes remain the main problems affecting models’ performance. Therefore, the paper presented various solutions to address these issues. Finally, this paper highlighted the potential opportunities for future work in this task.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/make5040081"
    },
    {
        "id": 27921,
        "title": "Performance benchmark of deep learning human pose estimation for UAVs",
        "authors": "Theofanis Kalampokas, Stelios Krinidis, Vassilios Chatzis, George A. Papakostas",
        "published": "2023-11",
        "citations": 1,
        "abstract": "AbstractHuman pose estimation (HPE) is a computer vision application that estimates human body joints from images. It gives machines the capability to better understand the interaction between humans and the environment. For this accomplishment, many HPE methods have been deployed in robots, vehicles, and unmanned aerial vehicles (UAVs). This effort raised the challenge of balance between algorithm performance and efficiency, especially in UAVs, where computational resources are limited for saving battery power. Despite the considerable progress in the HPE problem, there are very few methods that are proposed to face this challenge. To highlight the severity of this fact, the proposed paper presents a brief review and an HPE benchmark from the aspect of algorithms performance and efficiency under UAV operation. More specifically, the contribution of HPE methods in the last 22 years is covered, along with the variety of methods that exist. The benchmark consists of 36 pose estimation models in 3 known datasets with metrics that fulfill the paper aspect. From the results, MobileNet-based models achieved competitive performance and the lowest computational cost, in comparison with ResNet-based models. Finally, benchmark results are projected in edge devices hardware specifications to analyze the appropriateness of these algorithms for UAV deployment.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00138-023-01448-5"
    },
    {
        "id": 27922,
        "title": "Deep learning-based real-time 3D human pose estimation",
        "authors": "Xiaoyan Zhang, Zhengchun Zhou, Ying Han, Hua Meng, Meng Yang, Sutharshan Rajasegarar",
        "published": "2023-3",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.engappai.2022.105813"
    },
    {
        "id": 27923,
        "title": "A Survey on Deep Learning-Based 2D Human Pose Estimation Models",
        "authors": "Sani Salisu, A. S. A. Mohamed, M. H. Jaafar, Ainun S. B. Pauzi, Hussain A. Younis",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/cmc.2023.035904"
    },
    {
        "id": 27924,
        "title": "PoseGU: 3D human pose estimation with novel human pose generator and unbiased learning",
        "authors": "Shannan Guan, Haiyan Lu, Linchao Zhu, Gengfa Fang",
        "published": "2023-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103715"
    },
    {
        "id": 27925,
        "title": "Evaluation System of Student's Concentration Using Deep Learning-Based Head-Pose Estimation",
        "authors": "Truong Quang Vinh, Nguyen Bang",
        "published": "2023-11-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/acompa61072.2023.00029"
    },
    {
        "id": 27926,
        "title": "Computerized Framework for Yoga Pose Estimation Using Deep Learning Algorithm",
        "authors": "Tushar Singh Bist, Indrajeet Kumar, Rahul Chauhan",
        "published": "2023-9-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cisct57197.2023.10351398"
    },
    {
        "id": 27927,
        "title": "BowlingDL: A Deep Learning-Based Bowling Players Pose Estimation and Classification",
        "authors": "Nourah Fahad Janbi, Nada Almuaythir",
        "published": "2023-1-23",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaisc56366.2023.10085434"
    },
    {
        "id": 27928,
        "title": "Deep Learning-based Human Pose Estimation: A Survey",
        "authors": "Ce Zheng, Wenhan Wu, Chen Chen, Taojiannan Yang, Sijie Zhu, Ju Shen, Nasser Kehtarnavaz, Mubarak Shah",
        "published": "2024-1-31",
        "citations": 46,
        "abstract": "\n            Human pose estimation aims to locate the human body parts and build human body representation (e.g., body skeleton) from input data such as images and videos. It has drawn increasing attention during the past decade and has been utilized in a wide range of applications including human-computer interaction, motion analysis, augmented reality, and virtual reality. Although the recently developed deep learning-based solutions have achieved high performance in human pose estimation, there still remain challenges due to insufficient training data, depth ambiguities, and occlusion. The goal of this survey article is to provide a comprehensive review of recent deep learning-based solutions for both 2D and 3D pose estimation via a systematic analysis and comparison of these solutions based on their input data and inference procedures. More than 260 research papers since 2014 are covered in this survey. Furthermore, 2D and 3D human pose estimation datasets and evaluation metrics are included. Quantitative performance comparisons of the reviewed methods on popular datasets are summarized and discussed. Finally, the challenges involved, applications, and future research directions are concluded. A regularly updated project page is provided:\n            https://github.com/zczcwh/DL-HPE\n            .\n          ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3603618"
    },
    {
        "id": 27929,
        "title": "Forward dynamics computational modelling of a cyclist fall with the inclusion of protective response using deep learning-based human pose estimation",
        "authors": "Kevin Gildea, Daniel Hall, Christopher R. Cherry, Ciaran Simms",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jbiomech.2024.111959"
    },
    {
        "id": 27930,
        "title": "Direct face pose estimation using multiple camera views and deep learning",
        "authors": "Hyuno Kim, Seohyun Lee, Yuji Yamakawa",
        "published": "2023-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2651041"
    },
    {
        "id": 27931,
        "title": "Reaper: Articulated Object 6d Pose Estimation with Deep Reinforcement Learning",
        "authors": "Liu Liu, Qi Wu, Zhendong Xue, Sucheng Qian, Rui Li",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10223108"
    },
    {
        "id": 27932,
        "title": "Depth-aware pose estimation using deep learning for exoskeleton gait analysis",
        "authors": "Yachun Wang, Zhongcai Pei, Chen Wang, Zhiyong Tang",
        "published": "2023-12-19",
        "citations": 0,
        "abstract": "AbstractIn rehabilitation medicine, real-time analysis of the gait for human wearing lower-limb exoskeleton rehabilitation robot during walking can effectively prevent patients from experiencing excessive and asymmetric gait during rehabilitation training, thereby avoiding falls or even secondary injuries. To address the above situation, we propose a gait detection method based on computer vision for the real-time monitoring of gait during human–machine integrated walking. Specifically, we design a neural network model called GaitPoseNet, which is used for posture recognition in human–machine integrated walking. Using RGB images as input and depth features as output, regression of joint coordinates through depth estimation of implicit supervised networks. In addition, joint guidance strategy (JGS) is designed in the network framework. The degree of correlation between the various joints of the human body is used as a detection target to effectively overcome prediction difficulties due to partial joint occlusion during walking. Finally, a post processing algorithm is designed to describe patients’ walking motion by combining the pixel coordinates of each joint point and leg length. Our advantage is that we provide a non-contact measurement method with strong universality, and use depth estimation and JGS to improve measurement accuracy. Conducting experiments on the Walking Pose with Exoskeleton (WPE) Dataset shows that our method can reach 95.77% PCKs@0.1, 93.14% PCKs@0.08 and 3.55 ms runtime. Therefore our method achieves advanced performance considering both speed and accuracy.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-023-50207-z"
    },
    {
        "id": 27933,
        "title": "Deep Learning for Head Pose Estimation: A Survey",
        "authors": "Andrea Asperti, Daniele Filippini",
        "published": "2023-4-26",
        "citations": 6,
        "abstract": "AbstractHead pose estimation (HPE) is an active and popular area of research. Over the years, many approaches have constantly been developed, leading to a progressive improvement in accuracy; nevertheless, head pose estimation remains an open research topic, especially in unconstrained environments. In this paper, we will review the increasing amount of available datasets and the modern methodologies used to estimate orientation, with a special attention to deep learning techniques. We will discuss the evolution of the field by proposing a classification of head pose estimation methods, explaining their advantages and disadvantages, and highlighting the different ways deep learning techniques have been used in the context of HPE. An in-depth performance comparison and discussion is presented at the end of the work. We also highlight the most promising research directions for future investigations on the topic.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42979-023-01796-z"
    },
    {
        "id": 27934,
        "title": "Squirrel Search Optimization with Deep Convolutional Neural Network for Human Pose Estimation",
        "authors": "K. Ishwarya, A. Alice Nithya",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/cmc.2023.034654"
    },
    {
        "id": 27935,
        "title": "A Systematic Review of Recent Deep Learning Approaches for 3D Human Pose Estimation",
        "authors": "Amal El Kaid, Karim Baïna",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "Three-dimensional human pose estimation has made significant advancements through the integration of deep learning techniques. This survey provides a comprehensive review of recent 3D human pose estimation methods, with a focus on monocular images, videos, and multi-view cameras. Our approach stands out through a systematic literature review methodology, ensuring an up-to-date and meticulous overview. Unlike many existing surveys that categorize approaches based on learning paradigms, our survey offers a fresh perspective, delving deeper into the subject. For image-based approaches, we not only follow existing categorizations but also introduce and compare significant 2D models. Additionally, we provide a comparative analysis of these methods, enhancing the understanding of image-based pose estimation techniques. In the realm of video-based approaches, we categorize them based on the types of models used to capture inter-frame information. Furthermore, in the context of multi-person pose estimation, our survey uniquely differentiates between approaches focusing on relative poses and those addressing absolute poses. Our survey aims to serve as a pivotal resource for researchers, highlighting state-of-the-art deep learning strategies and identifying promising directions for future exploration in 3D human pose estimation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/jimaging9120275"
    },
    {
        "id": 27936,
        "title": "Reducing the device complexity for 3D human pose estimation: A deep learning approach using monocular camera and IMUs",
        "authors": "Changyu Zhao, Hirotaka Uchitomi, Taiki Ogata, Xianwen Ming, Yoshihiro Miyake",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.engappai.2023.106639"
    },
    {
        "id": 27937,
        "title": "Body Pose Estimation using Deep Learning",
        "authors": "Priyanshu Mahajan, Shambhavi Gupta, Divya Kheraj Bhanushali",
        "published": "2023-3-31",
        "citations": 0,
        "abstract": "Abstract: Healthcare, sports analysis, gaming, and entertain- ment are just some of the many fields that could benefit from solving the challenging issue of real-time human pose detection and recognition in computer vision. Capturing human motion, analysing physical exercise, and giving feedback on performance can all benefit from reliable detection and recognition of body poses. The recent progress in deep learning has made it possible to create real-time systems that can accurately and quickly recognise and identify human poses.",
        "keywords": "",
        "link": "http://dx.doi.org/10.22214/ijraset.2023.49688"
    },
    {
        "id": 27938,
        "title": "Active Transfer Learning for Efficient Video-Specific Human Pose Estimation",
        "authors": "Hiromu Taketsugu, Norimichi Ukita",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00189"
    },
    {
        "id": 27939,
        "title": "Automatic Dance Pose Estimation from the Hand Signs using Deep Learning",
        "authors": "Mrs. Rashmi H",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "Abstract: Human activity is the sequential change of the human body. The collection and assessment of multimedia content connected to dance will be beneficial for the preservation of cultural heritage, the creation of video recommendation systems, and the assistance of students through tutoring systems. Indian classical dance (ICD) classification is still a fascinating subject of research because of its intricate hand gestures. Changes in learning habits make automated teaching solutions unavoidable in many fields, from traditional to internet forums. ICD also becomes an essential part of a vibrant legacy and culture that needs to be updated and maintained at all costs. Complex poses including full-body rotation and self-hands-occlusion are part of the dance. The primary goal of this research is to create a framework for Bharatanatyam dancing.",
        "keywords": "",
        "link": "http://dx.doi.org/10.22214/ijraset.2023.56708"
    },
    {
        "id": 27940,
        "title": "OmniTrax: A deep learning-driven multi-animal tracking\nand pose-estimation add-on for Blender",
        "authors": "Fabian Plum",
        "published": "2024-3-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21105/joss.05549"
    },
    {
        "id": 27941,
        "title": "Vision-Based Human Pose Estimation via Deep Learning: A Survey",
        "authors": "Gongjin Lan, Yu Wu, Fei Hu, Qi Hao",
        "published": "2023-2",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/thms.2022.3219242"
    },
    {
        "id": 27942,
        "title": "SDFPoseGraphNet: Spatial Deep Feature Pose Graph Network for 2D Hand Pose Estimation",
        "authors": "Sartaj Ahmed Salman, Ali Zakir, Hiroki Takahashi",
        "published": "2023-11-10",
        "citations": 1,
        "abstract": "In the field of computer vision, hand pose estimation (HPE) has attracted significant attention from researchers, especially in the fields of human–computer interaction (HCI) and virtual reality (VR). Despite advancements in 2D HPE, challenges persist due to hand dynamics and occlusions. Accurate extraction of hand features, such as edges, textures, and unique patterns, is crucial for enhancing HPE. To address these challenges, we propose SDFPoseGraphNet, a novel framework that combines the strengths of the VGG-19 architecture with spatial attention (SA), enabling a more refined extraction of deep feature maps from hand images. By incorporating the Pose Graph Model (PGM), the network adaptively processes these feature maps to provide tailored pose estimations. First Inference Module (FIM) potentials, alongside adaptively learned parameters, contribute to the PGM’s final pose estimation. The SDFPoseGraphNet, with its end-to-end trainable design, optimizes across all components, ensuring enhanced precision in hand pose estimation. Our proposed model outperforms existing state-of-the-art methods, achieving an average precision of 7.49% against the Convolution Pose Machine (CPM) and 3.84% in comparison to the Adaptive Graphical Model Network (AGMN).",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23229088"
    },
    {
        "id": 27943,
        "title": "Towards Retail Stores Automation: 6-DOF Pose Estimation Combining Deep Learning Object Detection and Dense Depth Alignment",
        "authors": "Virgile Foussereau, Iori Kumagai, Guillaume Caron",
        "published": "2024-1-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sii58957.2024.10417145"
    },
    {
        "id": 27944,
        "title": "Uncertainty Criteria in Active Transfer Learning for Efficient Video-Specific Human Pose Estimation",
        "authors": "Hiromu Taketsugu, Norimichi Ukita",
        "published": "2023-7-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/mva57639.2023.10215565"
    },
    {
        "id": 27945,
        "title": "3D Articulated Human Pose Recognition via Learning Deep Gaussian Mixture Models for Virtual Exercise",
        "authors": "Jong-Sung Kim",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icce-asia59966.2023.10326393"
    },
    {
        "id": 27946,
        "title": "Automated Evaluation of Karate Practitioners’ Style during the First Kata Performance using Deep Learning and Pose Estimation",
        "authors": "Khaled Mostafa, Mohamed Hany, Ayman Atia",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/niles59815.2023.10296663"
    },
    {
        "id": 27947,
        "title": "AiShifu: AI Karate Pose Trainer Using Human Pose Estimation",
        "authors": "Frederick Lu",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "One application of the artificial intelligence (AI) technology is self-guided physical activities where a computing device acts as a trainer. One key challenge for these applications is how to measure the performance of such an AI trainer, especially when the AI trainer is run on a generic PC or a mobile device. In the spirit of the Turing test, an AI trainer should mimic the behavior of a human trainer. A good human trainer generally considers the training history and the level of the trainee when providing feedback, which requires more than body position analysis. In this work, we built a Martial Art trainer application called AIShifu that helps users practice martial art poses using Human Pose Estimation (HPE). We chose an open-source neural network called HRNET trained with MS-COCO dataset as the core of the HPE. The joint coordinates and angles were used to identify the pose being practiced by the trainee, whether the active side is left or right, and how close is the key joint angle to that from a “golden” image. We collected data from both a black belt martial artist and a novice trainee and on three Karate poses. Based on the data, it is clear that the blackbelt performed the poses more consistently. A much larger sample size was required to test how well an AI trainer can discern the difference between trainees with different levels of proficiency. This understanding forms the foundation to customize AI trainer softwares for different users.",
        "keywords": "",
        "link": "http://dx.doi.org/10.47611/jsrhs.v12i3.5063"
    },
    {
        "id": 27948,
        "title": "Deep learning approach to vehicle pose estimation from polarimetric image data",
        "authors": "Matthew D. Siefring, Bradley M. Ratliff, Brett S. Ballard",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2677123"
    },
    {
        "id": 27949,
        "title": "Stacked hourglass deep learning networks based on attention mechanism in multi-person pose estimation",
        "authors": "jiazhi Di, ben wang, hua hu",
        "published": "2023-3-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2668319"
    },
    {
        "id": 27950,
        "title": "RGB Image-Based Hand Pose Estimation: A Survey on Deep Learning Perspective",
        "authors": "Seyed Amirhossein Farjadi, M.-R. Akbarzadeh-T, Kamaledin Ghiasi-Shirazi",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aisp61396.2024.10475217"
    },
    {
        "id": 27951,
        "title": "Excavator 3D pose estimation using deep learning and hybrid datasets",
        "authors": "Amin Assadzadeh, Mehrdad Arashpour, Heng Li, Reza Hosseini, Faris Elghaish, Shanaka Baduge",
        "published": "2023-1",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.aei.2023.101875"
    },
    {
        "id": 27952,
        "title": "A Comparative Analysis of Traditional Deep Learning Framework for 3D Object Pose Estimation",
        "authors": "Davesh Singh Som, Pawan Kumar Goel, Deepak Singh Rana, Anurag Aeron, Raman Kumar",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdt61202.2024.10489605"
    },
    {
        "id": 27953,
        "title": "Deep Learning-based Mobile Robot Target Object Localization and Pose Estimation Research",
        "authors": "Caixia He, Laiyun He",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14569/ijacsa.2023.01406140"
    },
    {
        "id": 27954,
        "title": "Soft Body Pose-Invariant Evasion Attacks against Deep Learning Human Detection",
        "authors": "Chen Li, Weisi Guo",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bigdataservice58306.2023.00032"
    },
    {
        "id": 27955,
        "title": "Estimation on Human Motion Posture using Improved Deep Reinforcement Learning",
        "authors": "Wenjing Ma Wenjing Ma, Jianguang Zhao Wenjing Ma, Guangquan Zhu Jianguang Zhao",
        "published": "2023-8",
        "citations": 0,
        "abstract": "\n                        <p>Estimating human motion posture can provide important data for intelligent monitoring systems, human-computer interaction, motion capture, and other fields. However, the traditional human motion posture estimation algorithm is difficult to achieve the goal of fast estimation of human motion posture. To address the problems of traditional algorithms, in the paper, we propose an estimation algorithm for human motion posture using improved deep reinforcement learning. First, the double deep Q network is constructed to improve the deep reinforcement learning algorithm. The improved deep reinforcement learning algorithm is used to locate the human motion posture coordinates and improve the effectiveness of bone point calibration. Second, the human motion posture analysis generative adversarial networks are constructed to realize the automatic recognition and analysis of human motion posture. Finally, using the preset human motion posture label, combined with the undirected graph model of the human, the human motion posture estimation is completed, and the precise estimation algorithm of the human motion posture is realized. Experiments are performed based on MPII Human Pose data set and HiEve data set. The results show that the proposed algorithm has higher positioning accuracy of joint nodes. The recognition effect of bone joint points is better, and the average is about 1.45%. The average posture accuracy is up to 98.2%, and the average joint point similarity is high. Therefore, it is proved that the proposed method has high application value in human-computer interaction, human motion capture and other fields.</p>\n<p>&nbsp;</p>\n                    ",
        "keywords": "",
        "link": "http://dx.doi.org/10.53106/199115992023083404008"
    },
    {
        "id": 27956,
        "title": "Optimal Deep Convolutional Neural Network with Pose Estimation for Human Activity Recognition",
        "authors": "S. Nandagopal, G. Karthy, A. Sheryl Oliver, M. Subha",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/csse.2023.028003"
    },
    {
        "id": 27957,
        "title": "Deep learning pose estimation for multi-cattle lameness detection",
        "authors": "Shaun Barney, Satnam Dlay, Andrew Crowe, Ilias Kyriazakis, Matthew Leach",
        "published": "2023-3-18",
        "citations": 6,
        "abstract": "AbstractThe objective of this study was to develop a fully automated multiple-cow real-time lameness detection system using a deep learning approach for cattle detection and pose estimation that could be deployed across dairy farms. Utilising computer vision and deep learning, the system can analyse simultaneously both the posture and gait of each cow within a camera field of view to a very high degree of accuracy (94–100%). Twenty-five video sequences containing 250 cows in varying degrees of lameness were recorded and independently scored by three accredited Agriculture and Horticulture Development Board (AHDB) mobility scorers using the AHDB dairy mobility scoring system to provide ground truth lameness data. These observers showed significant inter-observer reliability. Video sequences were broken down into their constituent frames and with a further 500 images downloaded from google, annotated with 15 anatomical points for each animal. A modified Mask-RCNN estimated the pose of each cow to output 5 key-points to determine back arching and 2 key-points to determine head position. Using the SORT (simple, online, and real-time tracking) algorithm, cows were tracked as they move through frames of the video sequence (i.e., in moving animals). All the features were combined using the CatBoost gradient boosting algorithm with accuracy being determined using threefold cross-validation including recursive feature elimination. Precision was assessed using Cohen’s kappa coefficient and assessments of precision and recall. This methodology was applied to cows with varying degrees of lameness (according to accredited scoring, n = 3) and demonstrated that some characteristics directly associated with lameness could be monitored simultaneously. By combining the algorithm results over time, more robust evaluation of individual cow lameness was obtained. The model showed high performance for predicting and matching the ground truth lameness data with the outputs of the algorithm. Overall, threefold lameness detection accuracy of 100% and a lameness severity classification accuracy of 94% respectively was achieved with a high degree of precision (Cohen’s kappa = 0.8782, precision = 0.8650 and recall = 0.9209).",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-023-31297-1"
    },
    {
        "id": 27958,
        "title": "Deep Learning-Based GYM Monitoring System using YOLOv5 and Pose Estimation Algorithm",
        "authors": "R Renugadevi, P. Arul, V Subashree, G Sathi, M Dharmateja, G Indhumathi",
        "published": "2023-11-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceca58529.2023.10394921"
    },
    {
        "id": 27959,
        "title": "Lightweight human pose estimation based on high-resolution network",
        "authors": "Zhiwen Yang, Ruan Yang, Yunong Yang",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2675120"
    },
    {
        "id": 27960,
        "title": "Three-dimensional structural displacement measurement using monocular vision and deep learning based pose estimation",
        "authors": "Chujin Sun, Donglian Gu, Xinzheng Lu",
        "published": "2023-5",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ymssp.2023.110141"
    },
    {
        "id": 27961,
        "title": "Accurate and Scalable Contour-based Camera Pose Estimation Using Deep Learning with Synthetic Data",
        "authors": "Ilyar Asl Sabbaghian Hokmabadi, Mengchi Ai, Chrysostomos Minaretzis, Michael Sideris, Naser El-Sheimy",
        "published": "2023-4-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/plans53410.2023.10139984"
    },
    {
        "id": 27962,
        "title": "Dishpolish: Exploring the Recovery of Geometric Invariants in Deep Learning Models via Pose Estimation of Microwave Dish Antennae",
        "authors": "Christopher Liberatore, Logan Boyd, John Bielas, Richard Borth, Rachel Kinard",
        "published": "2023-8-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/naecon58068.2023.10365772"
    },
    {
        "id": 27963,
        "title": "Deep Learning Aided Magnetostatic Fields Based Real-Time Pose Estimation of AUV for Homing Applications",
        "authors": "Bala Naga Jyothi Vandavasi, Ananda Ramadass Gidugu, Hrishikesh Venkataraman",
        "published": "2023-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/lsens.2023.3248955"
    },
    {
        "id": 27964,
        "title": "Deep Learning-Based 6-DoF Object Pose Estimation Considering Synthetic Dataset",
        "authors": "Tianyu Zheng, Chunyan Zhang, Shengwen Zhang, Yanyan Wang",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "Due to the difficulty in generating a 6-Degree-of-Freedom (6-DoF) object pose estimation dataset, and the existence of domain gaps between synthetic and real data, existing pose estimation methods face challenges in improving accuracy and generalization. This paper proposes a methodology that employs higher quality datasets and deep learning-based methods to reduce the problem of domain gaps between synthetic and real data and enhance the accuracy of pose estimation. The high-quality dataset is obtained from Blenderproc and it is innovatively processed using bilateral filtering to reduce the gap. A novel attention-based mask region-based convolutional neural network (R-CNN) is proposed to reduce the computation cost and improve the model detection accuracy. Meanwhile, an improved feature pyramidal network (iFPN) is achieved by adding a layer of bottom-up paths to extract the internalization of features of the underlying layer. Consequently, a novel convolutional block attention module–convolutional denoising autoencoder (CBAM–CDAE) network is proposed by presenting channel attention and spatial attention mechanisms to improve the ability of AE to extract images’ features. Finally, an accurate 6-DoF object pose is obtained through pose refinement. The proposed approach is compared to other models using the T-LESS and LineMOD datasets. Comparison results demonstrate the proposed approach outperforms the other estimation models.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23249854"
    },
    {
        "id": 27965,
        "title": "Enhancing 3D Human Pose Estimation through Adversarial Learning and Graph Convolutional Networks",
        "authors": "Aman Sharma, Shivani Kumari, Abhipsha Priyadarshini, Pulkit Dwivedi",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10307858"
    },
    {
        "id": 27966,
        "title": "Uncertainty prediction in human pose estimation based on Gaussian heatmap",
        "authors": "XiaoNan Wu, ZengZhao Chen, Hai Liu",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2675293"
    },
    {
        "id": 27967,
        "title": "Multiscale Models for Real-Time Human Pose Estimation",
        "authors": "Zongyou Liu, Wenbai Li, Hongtao Wang",
        "published": "2023-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3616901.3616957"
    },
    {
        "id": 27968,
        "title": "Deep learning for material synthesis and pose estimation material systems: A review",
        "authors": "Jayaraj Ramasamy, Sandhya Pundhir, Sreekumar Narayanan, Sudhir Ramadass, S. Aswin, Arjun Suresh",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.matpr.2021.04.234"
    },
    {
        "id": 27969,
        "title": "Deep Learning Based Pose Estimation and Action Prediction for Construction Machines",
        "authors": "Thanh-Dat T. Nguyen, Minh-Hoang Nguyen, Tan-Hoa Nguyen, Viet-Cuong Pham",
        "published": "2023-11-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/atigb59969.2023.10364538"
    },
    {
        "id": 27970,
        "title": "3D human pose detection using nano sensor and multi-agent deep reinforcement learning",
        "authors": "Yangjie Sun, Xiaoxi Che, Nan Zhang",
        "published": "2023",
        "citations": 3,
        "abstract": "<abstract>\n<p>Due to the complexity of three-dimensional (3D) human pose, it is difficult for ordinary sensors to capture subtle changes in pose, resulting in a decrease in the accuracy of 3D human pose detection. A novel 3D human motion pose detection method is designed by combining Nano sensors and multi-agent deep reinforcement learning technology. First, Nano sensors are placed in key parts of the human to collect human electromyogram (EMG) signals. Second, after de-noising the EMG signal by blind source separation technology, the time-domain and frequency-domain features of the surface EMG signal are extracted. Finally, in the multi-agent environment, the deep reinforcement learning network is introduced to build the multi-agent deep reinforcement learning pose detection model, and the 3D local pose of the human is output according to the features of the EMG signal. The fusion and pose calculation of the multi-sensor pose detection results are performed to obtain the 3D human pose detection results. The results show that the proposed method has high accuracy for detecting various human poses, and the accuracy, precision, recall and specificity of 3D human pose detection results are 0.97, 0.98, 0.95 and 0.98, respectively. Compared with other methods, the detection results in this paper are more accurate, and can be widely used in medicine, film, sports and other fields.</p>\n</abstract>",
        "keywords": "",
        "link": "http://dx.doi.org/10.3934/mbe.2023230"
    },
    {
        "id": 27971,
        "title": "Depalletisation humanoid torso: Real-time cardboard package detection based on deep learning and pose estimation algorithm",
        "authors": "Santheep Yesudasu, Wafae Sebbata, Jean-François Brethé, Patrick Bonnin",
        "published": "2023-8-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mmar58394.2023.10242581"
    },
    {
        "id": 27972,
        "title": "UNPOSED: an Ultra-wideband Network for Pose Estimation with Deep Learning",
        "authors": "Giulia Martinelli, Luca Santoro, Matteo Nardello, Davide Brunelli, Daniele Fontanelli, Nicola Conci",
        "published": "2023-6-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/metroind4.0iot57462.2023.10180019"
    },
    {
        "id": 27973,
        "title": "Deep Learning-based 6D pose estimation of texture less objects for Industrial Cobots",
        "authors": "Charan Vikram, Kishore P, Aswin R, Karthik R, Menaka Radhakrishnan, Thillaivasan Veeranathan",
        "published": "2023-7-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3610419.3610506"
    },
    {
        "id": 27974,
        "title": "Deep learning for 6D pose estimation of objects — A case study for autonomous driving",
        "authors": "Sabera Hoque, Shuxiang Xu, Ananda Maiti, Yuchen Wei, Md. Yasir Arafat",
        "published": "2023-8",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.119838"
    },
    {
        "id": 27975,
        "title": "基于深度学习序列方法的多人姿态估计用来检测人体与关键点位置",
        "authors": "Rizwan Tahir, Yunze Cai",
        "published": "2023-10-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s12204-023-2658-z"
    },
    {
        "id": 27976,
        "title": "Improving Learning-based Camera Pose Estimation for Image-based Augmented Reality Applications",
        "authors": "Enyu Cai, Ryan Rossi, Chang Xiao",
        "published": "2023-4-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3544549.3585756"
    },
    {
        "id": 27977,
        "title": "Evaluation of Camera Pose Estimation Using Human Head Pose Estimation",
        "authors": "Robert Fischer, Michael Hödlmoser, Margrit Gelautz",
        "published": "2023-3-30",
        "citations": 2,
        "abstract": "AbstractWe introduce and evaluate a novel camera pose estimation framework that uses the human head as a calibration object. The proposed method facilitates extrinsic calibration from 2D input images (NIR and/or RGB), while merely relying on the detected human head, without the need for depth information. The approach is applicable to single cameras or multi-camera networks. Our implementation uses a fine-tuned deep learning-based 2D human facial landmark detector to estimate the 3D human head pose by fitting a 3D head model to the detected 2D facial landmarks. Our work focuses on an evaluation of the proposed approach on real multi-camera recordings and synthetic renderings to determine the accuracy of the pose estimation results and their applicability. We assess the robustness of our method against different input parameters, such as varying relative camera positions, variations of head models, face occlusions (by masks, sun glasses, etc.), potential biases and variance among humans. Based on the experimental results, we expect our approach to be effective for numerous use cases including automotive attention monitoring, robotics, VR/AR and other scenarios where ease of handling outweighs accuracy.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42979-023-01709-0"
    },
    {
        "id": 27978,
        "title": "Gated Region-Refine pose transformer for human pose estimation",
        "authors": "Tianfeng Wang, Xiaoxu Zhang",
        "published": "2023-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neucom.2023.01.090"
    },
    {
        "id": 27979,
        "title": "Retracted: Research on Human Pose Capture Based on the Deep Learning Algorithm",
        "authors": "",
        "published": "2023-8-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9794159"
    },
    {
        "id": 27980,
        "title": "Deep Semantic Graph Transformer for Multi-View 3D Human Pose Estimation",
        "authors": "Lijun Zhang, Kangkang Zhou, Feng Lu, Xiang-Dong Zhou, Yu Shi",
        "published": "2024-3-24",
        "citations": 0,
        "abstract": "Most Graph Convolutional Networks based 3D human pose estimation (HPE) methods were involved in single-view 3D HPE and utilized certain spatial graphs, existing key problems such as depth ambiguity, insufficient feature representation, or limited receptive fields. To address these issues, we propose a multi-view 3D HPE framework based on deep semantic graph transformer, which adaptively learns and fuses multi-view significant semantic features of human nodes to improve 3D HPE performance. First, we propose a deep semantic graph transformer encoder to enrich spatial feature information. It deeply mines the position, spatial structure, and skeletal edge knowledge of joints and dynamically learns their correlations. Then, we build a progressive multi-view spatial-temporal feature fusion framework to mitigate joint depth uncertainty. To enhance the pose spatial representation, deep spatial semantic feature are interacted and fused across different viewpoints during monocular feature extraction. Furthermore, long-time relevant temporal dependencies are modeled and spatial-temporal information from all viewpoints is fused to intermediately supervise the depth. Extensive experiments on three 3D HPE benchmarks show that our method achieves state-of-the-art results. It can effectively enhance pose features, mitigate depth ambiguity in single-view 3D HPE, and improve 3D HPE performance without providing camera parameters. Codes and models are available at https://github.com/z0911k/SGraFormer.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1609/aaai.v38i7.28549"
    },
    {
        "id": 27981,
        "title": "Pose estimation of sow and piglets during free farrowing using deep learning",
        "authors": "Fahimeh Farahnakian, Farshad Farahnakian, Stefan Björkman, Victor Bloch, Matti Pastell, Jukka Heikkonen",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jafr.2024.101067"
    },
    {
        "id": 27982,
        "title": "Spatial Structure-oriented and Angle-based Human Pose Estimation for Pose Classification",
        "authors": "P Charith -, Prajwal Kumar B R -, Anitha M -",
        "published": "2023-11-29",
        "citations": 0,
        "abstract": "This study provides a detailed analysis of the performance of different pose classification models trained using data from the human pose classification model. The approach involves considering both spatial structure-oriented techniques, which incorporate body part coordinates and their relative positions, and angle-based methods that calculate the angles between joints. This combined spatial and angular data play a crucial role in enhancing the precision of pose classification. It is worth noting that while our primary investigation is based on a yoga pose dataset, the versatility and applicability of our approach extend to other pose datasets, showcasing the broad potential of our spatial and angle-based methodology.\n\nIn summary, this research embarks on the integration of Human Pose Estimation with machine learning for yoga pose classification. The outcomes promise not only to advance the field of pose classification but also to yield practical applications in exercise, fitness, and beyond. This research has practical implications, aiming to integrate the developed model into a project we developed titled “AI-Based Human Pose Detection Tool. “The tool uses real-time video analysis to track users' movements during workouts, with the Blazepose model detecting key landmarks and assessing metrics. This enhances posture and form assessment, making the tool valuable for fitness enthusiasts.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36948/ijfmr.2023.v05i06.9614"
    },
    {
        "id": 27983,
        "title": "Postural Ergonomic Assessment of Construction Workers Based on Human 3D Pose Estimation and Machine Learning",
        "authors": "Y. Tao, H. Hu, F. Xu, Z. Zhang, Z. Hu",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ieem58616.2023.10406391"
    },
    {
        "id": 27984,
        "title": "Learning 3D Human Pose Estimation from Dozens of Datasets using a Geometry-Aware Autoencoder to Bridge Between Skeleton Formats",
        "authors": "Istvan Sarandi, Alexander Hermans, Bastian Leibe",
        "published": "2023-1",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00297"
    },
    {
        "id": 27985,
        "title": "Deep Monocular Relative 6D Pose Estimation for Ship-Based Autonomous UAV",
        "authors": "Maneesha Wickramasuriya, Taeyoung Lee, Murray Snyder",
        "published": "2024-1-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2514/6.2024-2877"
    },
    {
        "id": 27986,
        "title": "HUMAN POSE ESTIMATION",
        "authors": "Jayasri R",
        "published": "2024-3-23",
        "citations": 0,
        "abstract": "In \"Human Pose Estimation\" with integrated feedback mechanisms to assess and guide users in achieving correct poses. Utilizing advanced deep learning techniques in computer vision, the system swiftly detects key points on the human body and provides instant feedback on pose accuracy. Built on convolutional neural networks trained on extensive pose datasets, the system includes pose detection, classification, and feedback stages. By comparing detected poses with predefined correct poses, the system delivers positive feedback for accurate poses and corrective guidance for deviations.  Key Words: Human Pose Estimation, Pose Detection, Pose Classification, Correct Pose Assessment, Fitness Training, Key Points Detection, Correct Pose Thresholds",
        "keywords": "",
        "link": "http://dx.doi.org/10.55041/isjem01426"
    },
    {
        "id": 27987,
        "title": "Analyzing Some Efficient Deep Learners for Face Pose Estimation",
        "authors": "Mayank Kumar Rusia, Dushyant Kumar Singh",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/r10-htc57504.2023.10461889"
    },
    {
        "id": 27988,
        "title": "Recognition Method with Deep Contrastive Learning and Improved Transformer for 3D Human Motion Pose",
        "authors": "Datian Liu, Haitao Yang, Zhang Lei",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "AbstractThree-dimensional (3D) human pose recognition techniques based on spatial data have gained attention. However, existing models and algorithms fail to achieve desired precision. We propose a 3D human motion pose recognition method using deep contrastive learning and an improved Transformer. The improved Transformer removes noise between human motion RGB and depth images, addressing orientation correlation in 3D models. Two-dimensional (2D) pose features are extracted from de-noised RGB images using a kernel generation module in a graph convolutional network (GCN). Depth features are extracted from de-noised depth images. The 2D pose features and depth features are fused using a regression module in the GCN to obtain 3D pose recognition results. The results demonstrate that the proposed method captures RGB and depth images, achieving high recognition accuracy and fast speed. The proposed method demonstrates good accuracy in 3D human motion pose recognition.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s44196-023-00351-1"
    },
    {
        "id": 27989,
        "title": "Rethinking Visibility in Human Pose Estimation: Occluded Pose Reasoning via Transformers",
        "authors": "Pengzhan Sun, Kerui Gu, Yunsong Wang, Linlin Yang, Angela Yao",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00580"
    },
    {
        "id": 27990,
        "title": "PoseMatcher: One-shot 6D Object Pose Estimation by Deep Feature Matching",
        "authors": "Pedro Castro, Tae-Kyun Kim",
        "published": "2023-10-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00229"
    },
    {
        "id": 27991,
        "title": "Enhancing 3D human pose estimation with NIR single-pixel imaging and time-of-flight technology: a deep learning approach",
        "authors": "Carlos Osorio Quero, Daniel Durini, Jose Rangel-Magdaleno, Jose Martinez-Carranza, Ruben Ramos-Garcia",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "The extraction of 3D human pose and body shape details from a single monocular image is a significant challenge in computer vision. Traditional methods use RGB images, but these are constrained by varying lighting and occlusions. However, cutting-edge developments in imaging technologies have introduced new techniques such as single-pixel imaging (SPI) that can surmount these hurdles. In the near-infrared spectrum, SPI demonstrates impressive capabilities in capturing a 3D human pose. This wavelength can penetrate clothing and is less influenced by lighting variations than visible light, thus providing a reliable means to accurately capture body shape and pose data, even in difficult settings. In this work, we explore the use of an SPI camera operating in the NIR with time-of-flight (TOF) at bands 850–1550 nm as a solution to detect humans in nighttime environments. The proposed system uses the vision transformers (ViT) model to detect and extract the characteristic features of humans for integration over a 3D body model SMPL-X through 3D body shape regression using deep learning. To evaluate the efficacy of NIR-SPI 3D image reconstruction, we constructed a laboratory scenario that simulates nighttime conditions, enabling us to test the feasibility of employing NIR-SPI as a vision sensor in outdoor environments. By assessing the results obtained from this setup, we aim to demonstrate the potential of NIR-SPI as an effective tool to detect humans in nighttime scenarios and capture their accurate 3D body pose and shape.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1364/josaa.499933"
    },
    {
        "id": 27992,
        "title": "Robust Human Pose Estimation under Gaussian Noise",
        "authors": "Patrick Schlosser, Christoph Ledermann",
        "published": "2023-5-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icra48891.2023.10160453"
    },
    {
        "id": 27993,
        "title": "Lightweight Human Pose Estimation Algorithm Based on Improved FastPose",
        "authors": "Zhu Shiran, Wan Qing, Jia Shijie",
        "published": "2023-4-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.57237/j.cst.2023.02.003"
    },
    {
        "id": 27994,
        "title": "Efficient Low-Resolution Human Pose Estimation with Knowledge Bridge",
        "authors": "Ze Li, Feng Zhang, Lei Chen",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cac59555.2023.10451190"
    },
    {
        "id": 27995,
        "title": "Spatial-temporal Multi-scale Constrained Learning for mmWave-based Human Pose Estimation",
        "authors": "Lin Chen, Xuemei Guo, Guoli Wang, Hongyi Li",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tcds.2023.3334302"
    },
    {
        "id": 27996,
        "title": "LInKs \"Lifting Independent Keypoints\" - Partial Pose Lifting for Occlusion Handling with Improved Accuracy in 2D-3D Human Pose Estimation",
        "authors": "Peter Hardy, Hansung Kim",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00339"
    },
    {
        "id": 27997,
        "title": "Human pose estimation model based on DiracNets and integral pose regression",
        "authors": "Xinzheng Xu, Yanyan Guo, Xin Wang",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-15057-x"
    },
    {
        "id": 27998,
        "title": "Pose Relation Transformer Refine Occlusions for Human Pose Estimation",
        "authors": "Hyung-gun Chi, Seunggeun Chi, Stanley Chan, Karthik Ramani",
        "published": "2023-5-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icra48891.2023.10161259"
    },
    {
        "id": 27999,
        "title": "EBA-PRNetCC: An Efficient Bridge Attention-Integration PoseResNet for Coordinate Classification in 2D Human Pose Estimation",
        "authors": "Ali Zakir, Sartaj Salman, Gibran Benitez-Garcia, Hiroki Takahashi",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012366300003660"
    },
    {
        "id": 28000,
        "title": "3D Human Pose Estimation: A Survey",
        "authors": "Shan Jia",
        "published": "2023-9-1",
        "citations": 0,
        "abstract": "This comprehensive review article explores the latest research advancements in the realm of estimating 3D human pose. Traditional methods such as PSM, SVM are discussed. Besides, this review also talks about deep learning-based approaches, including direct approaches, 2D-to-3D lifting and volumetric model approach for single person, top-down approaches and bottom-up approaches for multi-person pose estimation. The analysis covers the strengths and challenges of various methods, encompassing issues such as model generalization, occlusion robustness, and computational efficiency. Current research issues are identified, and future directions are proposed. By summarizing and evaluating existing methods, this paper aims to provide valuable insights for researchers in both academia and industry, driving the evolution of 3D human pose estimation for better practical applications.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/fcis.v5i2.13139"
    },
    {
        "id": 28001,
        "title": "The Latest Progress in Human Pose Estimation",
        "authors": "Shuyan Zhang, Xufei Hu",
        "published": "2023-1-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccrd56364.2023.10080205"
    },
    {
        "id": 28002,
        "title": "Learning 3D Human Pose and Shape Estimation Using Uncertainty-Aware Body Part Segmentation",
        "authors": "Ziming Wang, Han Yu, Xiaoguang Zhu, Zengwen Li, Changxue Chen, Liang Song",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10095635"
    },
    {
        "id": 28003,
        "title": "TAEKWONDO POSE ESTIMATION WITH DEEP LEARNING ARCHITECTURES ON ONE-DIMENSIONAL AND TWO-DIMENSIONAL DATA",
        "authors": "Dat Tien Nguyen, Chau Ngoc Ha, Ha Thanh Thi Hoang, Truong Nhat Nguyen, Tuyet Ngoc Huynh, Hai Thanh Nguyen",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": "Practicing sports is an activity that helps people maintain and improve their health, enhance memory and concentration, reduce anxiety and stress, and train teamwork and leadership ability. With the development of science and technology, artificial intelligence in sports has become increasingly popular with the public and brings many benefits. In particular, many applications help people track and evaluate athletes' achievements in competitions. This study extracts images from Taekwondo videos and generates skeleton data from frames using the Fast Forward Moving Picture Experts Group (FFMPEG) technique using MoveNet. After that, we use deep learning architectures such as Long Short-Term Memory Networks, Convolutional Long Short-Term Memory, and Long-term Recurrent Convolutional Networks to perform the poses classification tasks in Taegeuk in Jang lessons. This work presents two approaches. The first approach uses a sequence skeleton extracted from the image by Movenet. Second, we use sequence images to train using video classification architecture. Finally, we recognize poses in sports lessons using skeleton data to remove noise in the image, such as background and extraneous objects behind the exerciser. As a result, our proposed method has achieved promising performance in pose classification tasks in an introductory Taekwondo lesson.",
        "keywords": "",
        "link": "http://dx.doi.org/10.15625/1813-9663/18043"
    },
    {
        "id": 28004,
        "title": "HOLOTumor: 6 DoF Phantom Head Pose Estimation-Based Deep Learning and Brain Tumor Segmentation for AR Visualization and Interaction",
        "authors": "Kahina Amara, Mohamed Amine Guerroudji, Oussama Kerdjidj, Nadia Zenati, Naeem Ramzan",
        "published": "2023-10-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/jsen.2023.3305596"
    },
    {
        "id": 28005,
        "title": "Calibrated deep attention model for 3D pose estimation in the wild",
        "authors": "Longkui Jiang, Yuru Wang, Xinhe Ji",
        "published": "2023",
        "citations": 0,
        "abstract": "<abstract>\n <p>Three-dimensional human pose estimation is a key technology in many computer vision tasks. Regressing a 3D pose from 2D images is a challenging task, especially for applications in natural scenes. Recovering the 3D pose from a monocular image is an ill-posed problem itself; moreover, most of the existing datasets have been captured in a laboratory environment, which means that the model trained by them cannot generalize well to in-the-wild data. In this work, we improve the 3D pose estimation performance by introducing the attention mechanism and a calibration network. The attention model will capture the channel-wise dependence, so as to enhance the depth analysis ability of the model. The multi-scale pose calibration network adaptively learns body structure and motion characteristics, and will therefore rectify the estimation results. We tested our model on the Human 3.6M dataset for quantitive evaluation, and the experimental results show the proposed methods with higher accuracy. In order to test the generalization capability for in-the-wild applications, we also report the qualitative results on the natural scene Leeds Sports Pose dataset; the visualization results show that the estimated results are more reasonable than the baseline model.</p>\n </abstract>",
        "keywords": "",
        "link": "http://dx.doi.org/10.3934/era.2023079"
    },
    {
        "id": 28006,
        "title": "Source-free Domain Adaptive Human Pose Estimation",
        "authors": "Qucheng Peng, Ce Zheng, Chen Chen",
        "published": "2023-10-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00445"
    },
    {
        "id": 28007,
        "title": "Monocular 2D and 3D human pose estimation review",
        "authors": "Yumeng Wang",
        "published": "2023-4-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2673629"
    },
    {
        "id": 28008,
        "title": "DiffPose: Multi-hypothesis Human Pose Estimation using Diffusion Models",
        "authors": "Karl Holmquist, Bastian Wandt",
        "published": "2023-10-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01464"
    },
    {
        "id": 28009,
        "title": "Learning Better Keypoints for Multi-Object 6DoF Pose Estimation",
        "authors": "Yangzheng Wu, Michael Greenspan",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00062"
    },
    {
        "id": 28010,
        "title": "A Multi-Task Learning and Data Augmentation-Based Pose Estimation Algorithm",
        "authors": "Hui Li, Jiangyuan Qi",
        "published": "2023-6-23",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icise60366.2023.00082"
    },
    {
        "id": 28011,
        "title": "Pose ResNet: A 3D human pose estimation network model",
        "authors": "Wenxia Bao, Zhongyu Ma, Dong Liang, Xianjun Yang, Tao Niu",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bdicn58493.2023.00061"
    },
    {
        "id": 28012,
        "title": "Convolutional Cross-View Pose Estimation",
        "authors": "Zimin Xia, Olaf Booij, Julian F. P. Kooij",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tpami.2023.3346924"
    },
    {
        "id": 28013,
        "title": "Grasp Pose Estimation for Pick and Place of Frozen Blood Bags Based on Point Cloud Processing and Deep Learning Strategies Using Vacuum Grippers",
        "authors": "Muhammad Zain Bashir, Jaeseok Kim, Olivia Nocentini, Filippo Cavallo",
        "published": "2023-6-7",
        "citations": 0,
        "abstract": "AbstractWe describe different strategies to compute grasp poses for vacuum grippers for pick and place of frozen blood bags. Our methods process RGB-D data to search for local flat patches on the bags’ surface which act as grasp points when using vacuum grippers. We develop three strategies which analyze point cloud data to propose gripper poses and one method that trains a real-time object detector to propose the grasp point and processes point cloud data to compute the bag’s orientation. All the strategies are based on the computation of a normal vector at each 3D point to account for the surface orientation. They differ from each other based on how each method searches for these flat patches. We validate and compare the effectiveness of our methods by conducting real-world pick and place experiments, achieving an average success rate of above 80%. In conclusion, four different strategies, both analytical and a hybrid of analytic and deep learning approaches to infer optimal grasp poses for vacuum grippers to automatise pick and place operations of blood bags were presented.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42979-023-01927-6"
    },
    {
        "id": 28014,
        "title": "Optimized Deep Learning for Human age Estimation",
        "authors": "Kirti A. Patil, R. P. Bhavsar, B. V. Pawar",
        "published": "2024-4-4",
        "citations": 0,
        "abstract": "Background/ Introduction: Human age assessment plays a crucial part in diagnosing genetic problems, and development abnormalities in children. They are also used in several applications, like forensic investigation and criminal scenes. Generally, human age is estimated from X-ray images of bones, and the manual estimation of human age is highly subjective, as they depend on the medical experience of the professionals. Further, they are prone to error and are laborious, thereby requiring automated Bone Age Assessment (BAA) for determining human age with high accurateness.\r\nMaterials and methods: This work presents a novel approach using Deep Learning (DL) and optimization considering the X-ray images of hand. Here, human age is estimated using the Deep Residual Network (DRN), whose parameters are trained using the proposed Beluga whale lion optimization (BWLO) algorithm. Further, several processes, like pre-processing, Region of Interest (RoI) extraction, Image augmentation, and feature extraction are used to enhance the accuracy of the estimation model.\r\nResults and conclusion: The BWLO_DRN is examined for its superiority considering metrics, like accuracy, Sensitivity, Specificity, Positive Predictive Value (PPV) and Negative Predictive Value (NPV).",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/jes.1525"
    },
    {
        "id": 28015,
        "title": "Deep Learning Based Target Pose Estimation Using LiDAR Measurements in Active Debris Removal Operations",
        "authors": "Enrique Aldao Pensado, Luis Miguel González de Santos, Manuel Sanjurjo-Rivo, Higinio González Jorge",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/taes.2023.3262505"
    },
    {
        "id": 28016,
        "title": "Deep-learning-based head pose estimation from a single RGB image and its application to medical CROM measurement",
        "authors": "Panrasee Ritthipravat, Kittisak Chotikkakamthorn, Wen-Nung Lie, Worapan Kusakunniran, Pimchanok Tuakta, Paitoon Benjapornlert",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "AbstractFor human beings, neck movement will be degraded due to aging, trauma, musculoskeletal disorders, or degenerative diseases. Cervical range of motion (CROM) measurement is one of the popular quantitative neck examinations. Despite radiography is considered as the gold standard, it suffers from invasiveness, radiation exposure, and expensiveness. Recently, vision-based methods have been applied for CROM measurement but achieve large errors and require depth camera. On the other hand, deep neural networks provide good performances on head pose estimation (HPE) from a single image, thus promising for medical CROM measurement. We propose to use CNN networks to extract pyramidal or multi-level image features, which are passed to cross-level attention modules for feature fusion and then to a modified ASPP module and a multi-bin classification/regression module for spatial-channel attention and Euler angle conversion/prediction, respectively. The proposed technique was evaluated on public datasets, such as 300W_LP, AFLW2000, and BIWI, to verify its superior performances (with mean MAE = 3.50°, 3.40°, and 2.31° for different experimental protocols) than state-of-the-art methods. Our pre-trained model was also evaluated with our own collected dataset from hospital for CROM measurement. It also achieved the lowest MAE of 4.58° among other methods and conformed with a medical standard of 5 degrees except the pitch angle (which has a MAE of 5.70°, larger than the standard and the yaw (MAE = 3.60°) and roll angles (MAE = 4.44°)). In general, HPE technique is feasible for CROM measurement and shows its advantages of speed, non-invasiveness, free of anatomical landmark and low cost of operation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-024-18612-2"
    },
    {
        "id": 28017,
        "title": "DS-HPE: Deep Set for Head Pose Estimation",
        "authors": "Velayuthan Menan, Asiri Gawesha, Pradeepa Samarasinghe, Dharshana Kasthurirathna",
        "published": "2023-3-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ccwc57344.2023.10099159"
    },
    {
        "id": 28018,
        "title": "Deep Learning-Based Real-Time Smartphone Pose Detection for Ultra-Wideband Tagless Gate",
        "authors": "Junyoung Choi, Sagnik Bhattacharya",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/globecom54140.2023.10436971"
    },
    {
        "id": 28019,
        "title": "Human Pose Estimation Using Parallel Architecture",
        "authors": "Shuhena Salam Aonty, Kaushik Deb, Dhrubajyoti Das, Kang-Hyun Jo",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iwis58789.2023.10284672"
    },
    {
        "id": 28020,
        "title": "3D Hand Pose Estimation and Shape Reconstruction based on Multi-task Learning",
        "authors": "Jiye Wang, Xiaoming Luan",
        "published": "2023-8-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icma57826.2023.10215729"
    },
    {
        "id": 28021,
        "title": "3D human pose and shape estimation via de-occlusion multi-task learning",
        "authors": "Hang Ran, Xin Ning, Weijun Li, Meilan Hao, Prayag Tiwari",
        "published": "2023-9",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neucom.2023.126284"
    },
    {
        "id": 28022,
        "title": "Lightweight Human Pose Estimation with Attention Mechanism",
        "authors": "Fangrui Han, Meng Dai, XiaoWei Chen",
        "published": "2023-7-27",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icivc58118.2023.10270337"
    },
    {
        "id": 28023,
        "title": "B-Pose: Bayesian Deep Network for Camera 6-DoF Pose Estimation From RGB Images",
        "authors": "Aref Miri Rekavandi, Farid Boussaid, Abd-Krim Seghouane, Mohammed Bennamoun",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/lra.2023.3313062"
    },
    {
        "id": 28024,
        "title": "Multi-modal AI Systems for Human and Animal Pose Estimation in Challenging Conditions",
        "authors": "Qianyi Deng",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smartcomp58114.2023.00060"
    },
    {
        "id": 28025,
        "title": "Towards infrared human pose estimation via Transformer",
        "authors": "Zhilei Zhu, Wanli Dong, Xiaoming Gao, Anjie Peng",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191173"
    },
    {
        "id": 28026,
        "title": "Lightweight Human Pose Estimation Based on Self-Attention Mechanism",
        "authors": "Youtao Luo, Xiaoming Gao",
        "published": "2023-3-21",
        "citations": 0,
        "abstract": "To tackle the issues of numerous parameters, high computational complexity, and extended detection time prevalent in current human pose estimation network models, we have incorporated an hourglass structure to create a lightweight single-path network model, which has fewer parameters and a shorter computation time. To ensure model accuracy, we have implemented a window self-attention mechanism with a reduced parameter count. Additionally, we have redesigned this self-attention module to effectively extract local and global information, thereby enriching the feature information learned by the model. This module merges with the inverted residual network architecture, creating a separate module of WGNet. Finally, WGNet can be flexibly embedded into different stages of the model. Training and validation on COCO and MPII datasets demonstrate that this model reduces the number of parameters by 25%, computational complexity by 41%, and inference time by nearly two times, compared to Hrformer, which also utilizes the windowed self-attention mechanism, at the cost of only 3.5% accuracy.",
        "keywords": "",
        "link": "http://dx.doi.org/10.56028/aetr.4.1.253.2023"
    },
    {
        "id": 28027,
        "title": "Knowledge Distillation for Human Pose Estimation Using Channel Dropout Strategy",
        "authors": "Guangyao Zhou, Xiluo Teng, Kang-Hyun Jo",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iwis58789.2023.10284595"
    },
    {
        "id": 28028,
        "title": "Deep Learning for Real-Time Satellite Pose Estimation on Tensor Processing Units",
        "authors": "Alessandro Lotti, Dario Modenini, Paolo Tortora, Massimiliano Saponara, Maria A. Perino",
        "published": "2023-5",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2514/1.a35496"
    },
    {
        "id": 28029,
        "title": "Evaluation of mouse behavioral responses to nutritive versus nonnutritive sugar using a deep learning-based 3D real-time pose estimation system",
        "authors": "Jineun Kim, Dae-gun Kim, Wongyo Jung, Greg S. B. Suh",
        "published": "2023-4-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/01677063.2023.2174982"
    },
    {
        "id": 28030,
        "title": "Human Pose Estimation Based on Improved HRNet Model",
        "authors": "Wei Luo, Jinyu Xue",
        "published": "2023-5-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ccai57533.2023.10201272"
    },
    {
        "id": 28031,
        "title": "Study on human pose estimation based on channel and spatial attention",
        "authors": "Yilong Liu",
        "published": "2023-1-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccece58074.2023.10135500"
    },
    {
        "id": 28032,
        "title": "Deep Learning-based Human Height Estimation from a Stereo Vision System",
        "authors": "Henry O. Velesaca, Jorge Vulgarin, Boris X. Vintimilla",
        "published": "2023-7-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icprs58416.2023.10179079"
    },
    {
        "id": 28033,
        "title": "YH-Pose: Human pose estimation in complex coal mine scenarios",
        "authors": "XiangQing Dong, XiChao Wang, BaoJiang Li, HaiYan Wang, GuoChu Chen, Meng Cai",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.engappai.2023.107338"
    },
    {
        "id": 28034,
        "title": "Upper Body Pose Estimation Using Deep Learning for a Virtual Reality Avatar",
        "authors": "Taravat Anvari, Kyoungju Park, Ganghyun Kim",
        "published": "2023-2-14",
        "citations": 1,
        "abstract": "With the popularity of virtual reality (VR) games and devices, demand is increasing for estimating and displaying user motion in VR applications. Most pose estimation methods for VR avatars exploit inverse kinematics (IK) and online motion capture methods. In contrast to existing approaches, we aim for a stable process with less computation, usable in a small space. Therefore, our strategy has minimum latency for VR device users, from high-performance to low-performance, in multi-user applications over the network. In this study, we estimate the upper body pose of a VR user in real time using a deep learning method. We propose a novel method inspired by a classical regression model and trained with 3D motion capture data. Thus, our design uses a convolutional neural network (CNN)-based architecture from the joint information of motion capture data and modifies the network input and output to obtain input from a head and both hands. After feeding the model with properly normalized inputs, a head-mounted display (HMD), and two controllers, we render the user’s corresponding avatar in VR applications. We used our proposed pose estimation method to build single-user and multi-user applications, measure their performance, conduct a user study, and compare the results with previous methods for VR avatars.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app13042460"
    },
    {
        "id": 28035,
        "title": "Efficient, Self-Supervised Human Pose Estimation with Inductive Prior Tuning",
        "authors": "Nobline Yoo, Olga Russakovsky",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00351"
    },
    {
        "id": 28036,
        "title": "A Review on Human Pose Estimation Using Mediapipe",
        "authors": "Rahul Chauhan, Ikshit Dhyani, Himadri Vaidya",
        "published": "2023-9-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cisct57197.2023.10351240"
    },
    {
        "id": 28037,
        "title": "An Improved Lightweight Human Pose Estimation Method in Video",
        "authors": "Xiaoshuai Chu, Ruirui Ji, Wei Gao, Mengfei Yan, Zichen Zhou",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cac59555.2023.10451146"
    },
    {
        "id": 28038,
        "title": "Double Discrete Representation for 3D Human Pose Estimation from Head-mounted Camera",
        "authors": "Juheon Hwang, Jiwoo Kang",
        "published": "2024-1-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icce59016.2024.10444241"
    },
    {
        "id": 28039,
        "title": "Ego-Body Pose Estimation via Ego-Head Pose Estimation",
        "authors": "Jiaman Li, C. Karen Liu, Jiajun Wu",
        "published": "2023-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01644"
    },
    {
        "id": 28040,
        "title": "A New 3D Human Pose Estimation Network for Knee Posture Estimation",
        "authors": "Shangqi Cui, Fan Peng, Zhi Yang",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3644116.3644239"
    },
    {
        "id": 28041,
        "title": "RepEPnP: Weakly Supervised 3D Human Pose Estimation with EPnP Algorithm",
        "authors": "Huaijing Lai, Zhenhua Tang, Xiaoyan Zhang",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191300"
    },
    {
        "id": 28042,
        "title": "Leveraging body pose estimation for gesture recognition in human-robot interaction using synthetic data",
        "authors": "Xiaoyu Zhu, Celso de Melo, Alexander G. Hauptmann",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2664030"
    },
    {
        "id": 28043,
        "title": "Selective Learning of Human Pose Estimation Based on Multi-Scale Convergence Network",
        "authors": "Wenkai LIU, Cuizhu QIN, Menglong WU, Wenle BAI, Hongxia DONG",
        "published": "2023-5-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1587/transinf.2022edl8093"
    },
    {
        "id": 28044,
        "title": "Correction to: Learning Enriched Hop-Aware Correlation for Robust 3D Human Pose Estimation",
        "authors": "Shengping Zhang, Chenyang Wang, Liqiang Nie, Hongxun Yao, Qingming Huang, Qi Tian",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11263-023-01786-x"
    },
    {
        "id": 28045,
        "title": "Learnable Human Mesh Triangulation for 3D Human Pose and Shape Estimation",
        "authors": "Sungho Chun, Sungbum Park, Ju Yong Chang",
        "published": "2023-1",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00287"
    },
    {
        "id": 28046,
        "title": "Surya namaskar pose estimation and correction using machine learning",
        "authors": "Medha Wyawahare, Kasturi Joshi, Riya Joshi, Rohan Joshi, Shubhankar Kalekar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0181557"
    },
    {
        "id": 28047,
        "title": "Spacecraft Homography Pose Estimation with Single-Stage Deep Convolutional Neural Network",
        "authors": "Shengpeng Chen, Wenyi Yang, Wei Wang, Jianting Mai, Jian Liang, Xiaohu Zhang",
        "published": "2024-3-12",
        "citations": 0,
        "abstract": "Spacecraft pose estimation using computer vision has garnered increasing attention in research areas such as automation system theory, control theory, sensors and instruments, robot technology, and automation software. Confronted with the extreme environment of space, existing spacecraft pose estimation methods are predominantly multi-stage networks with complex operations. In this study, we propose an approach for spacecraft homography pose estimation with a single-stage deep convolutional neural network for the first time. We formulated a homomorphic geometric constraint equation for spacecraft with planar features. Additionally, we employed a single-stage 2D keypoint regression network to obtain homography 2D keypoint coordinates for spacecraft. After decomposition to obtain the rough spacecraft pose based on the homography matrix constructed according to the geometric constraint equation, a loss function based on pixel errors was employed to refine the spacecraft pose. We conducted extensive experiments using widely used spacecraft pose estimation datasets and compared our method with state-of-the-art techniques in the field to demonstrate its effectiveness.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s24061828"
    },
    {
        "id": 28048,
        "title": "Ego-Body Pose Estimation via Ego-Head Pose Estimation",
        "authors": "Jiaman Li, C. Karen Liu, Jiajun Wu",
        "published": "2023-6",
        "citations": 0,
        "abstract": "\n            Estimating 3D human motion from an ego-centric video, which records the environment viewed from the first-person perspective with a front-facing monocular camera, is critical to applications in VR/AR. However, naively learning a mapping between egocentric videos and full-body human motions is challenging for two reasons. First, modeling this complex relationship is difficult; unlike reconstruction motion from third-person videos, the human body is often out of view of an egocentric video. Second, learning this mapping requires a large-scale, diverse dataset containing paired egocentric videos and the corresponding 3D human poses. Creating such a dataset requires meticulous instrumentation for data acquisition, and unfortunately, such a dataset does not currently exist. As such, existing works have only worked on small-scale datasets with limited motion and scene diversity\n            (yuan20183d; yuan2019ego; luo2021dynamics).\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3609468.3609473"
    },
    {
        "id": 28049,
        "title": "MSTPose: Learning-Enriched Visual Information with Multi-Scale Transformers for Human Pose Estimation",
        "authors": "Chengyu Wu, Xin Wei, Shaohua Li, Ao Zhan",
        "published": "2023-7-27",
        "citations": 0,
        "abstract": "Human pose estimation is a complex detection task in which the network needs to capture the rich information contained in the images. In this paper, we propose MSTPose (Multi-Scale Transformer for human Pose estimation). Specifically, MSTPose leverages a high-resolution convolution neural network (CNN) to extract texture information from images. For the feature maps from three different scales produced by the backbone network, each branch performs the coordinate attention operations. The feature maps are then spatially and channel-wise flattened, combined with keypoint tokens generated through random initialization, and fed into a parallel Transformer structure to learn spatial dependencies between features. As the Transformer outputs one-dimensional sequential features, the mainstream two-dimensional heatmap method is abandoned in favor of one-dimensional coordinate vector regression. The experiments show that MSTPose outperforms other CNN-based pose estimation models and demonstrates clear advantages over CNN + Transformer networks of similar types.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12153244"
    },
    {
        "id": 28050,
        "title": "Yoga Guide: Yoga Pose Estimation Using Machine Learning",
        "authors": "Aniket Jagtap",
        "published": "2024-2-29",
        "citations": 0,
        "abstract": "Abstract: A deep learning model is proposed which uses convolutional neural networks/LR algorithm for yoga pose identification along with a human joints localization model followed by a process for identification of errors in the pose for developing the system. After obtaining all the information about the pose of the user the system gives feedback to improve or correct the posture of the user. we propose an improved algorithm to calculate scores that can be applied to all poses. Our application is evaluated on different Yoga poses under different scenes, and its robustness is guaranteed.",
        "keywords": "",
        "link": "http://dx.doi.org/10.22214/ijraset.2024.58272"
    },
    {
        "id": 28051,
        "title": "A Lightweight Context-Aware Feature Transformer Network for Human Pose Estimation",
        "authors": "Yanli Ma, Qingxuan Shi, Fan Zhang",
        "published": "2024-2-9",
        "citations": 0,
        "abstract": "We propose a Context-aware Feature Transformer Network (CaFTNet), a novel network for human pose estimation. To address the issue of limited modeling of global dependencies in convolutional neural networks, we design the Transformerneck to strengthen the expressive power of features. Transformerneck directly substitutes 3×3 convolution in the bottleneck of HRNet with a Contextual Transformer (CoT) block while reducing the complexity of the network. Specifically, the CoT first produces keys with static contextual information through 3×3 convolution. Then, relying on query and contextualization keys, dynamic contexts are generated through two concatenated 1×1 convolutions. Static and dynamic contexts are eventually fused as an output. Additionally, for multi-scale networks, in order to further refine the features of the fusion output, we propose an Attention Feature Aggregation Module (AFAM). Technically, given an intermediate input, the AFAM successively deduces attention maps along the channel and spatial dimensions. Then, an adaptive refinement module (ARM) is exploited to activate the obtained attention maps. Finally, the input undergoes adaptive feature refinement through multiplication with the activated attention maps. Through the above procedures, our lightweight network provides powerful clues for the detection of keypoints. Experiments are performed on the COCO and MPII datasets. The model achieves a 76.2 AP on the COCO val2017 dataset. Compared to other methods with a CNN as the backbone, CaFTNet has a 72.9% reduced number of parameters. On the MPII dataset, our method uses only 60.7% of the number of parameters, acquiring similar results to other methods with a CNN as the backbone.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics13040716"
    },
    {
        "id": 28052,
        "title": "DaViTPose: An Enhanced Vision Transforme- Based Architecture for Accurate Human Pose Estimation",
        "authors": "Varun Gupta, Vaibhav Srivastava, Vishu Tomar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4459900"
    },
    {
        "id": 28053,
        "title": "Human Action Classification Based on Pose Estimation and Artificial Neural Network",
        "authors": "Trairat Sabaichai, Datchakorn Tancharoen, Pawit Limpasuthum",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/incit60207.2023.10413056"
    },
    {
        "id": 28054,
        "title": "Retracted: 3D Human Pose Estimation Based on Transformer Algorithm",
        "authors": "",
        "published": "2023-7-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9813246"
    },
    {
        "id": 28055,
        "title": "Efficient and Lightweight Human Pose Estimation Algorithm",
        "authors": "Jie Zhang, Mai Yan, Haiyong Zheng",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceict57916.2023.10244793"
    },
    {
        "id": 28056,
        "title": "Graphrpe: Relative Position Encoding Graph Transformer for 3d Human Pose Estimation",
        "authors": "Junjie Zou, Ming Shao, Siyu Xia",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10222124"
    },
    {
        "id": 28057,
        "title": "Karate Kata Style Classification Using Pose Landmarks and Deep Learning",
        "authors": "Mahmoud Daker, Farida Elsayaad, Ayman Atia",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/niles59815.2023.10296806"
    },
    {
        "id": 28058,
        "title": "Transfer Learning for Driver Pose Estimation from Synthetic Data",
        "authors": "Daniel Sagmeister, Dominik Schörkhuber, Matej Nezveda, Fabian Stiedl, Maria Schimkowitsch, Margrit Gelautz",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iv55152.2023.10186532"
    },
    {
        "id": 28059,
        "title": "Towards a Markerless 3D Pose Estimation Tool",
        "authors": "Amaan Rahman",
        "published": "2023-4-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3544549.3583950"
    },
    {
        "id": 28060,
        "title": "Deformable Pose Network: A Multi-Stage Deformable Convolutional Network for 2D Hand Pose Estimation",
        "authors": "Sartaj Salman, Ali Zakir, Hiroki Takahashi",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012569000003660"
    },
    {
        "id": 28061,
        "title": "Deep Neural Pose Estimation for a Flapping Wing Unmanned Aerial Vehicle with Visual-Inertial Sensor Fusion",
        "authors": "Tejaswi K C, Taeyoung Lee, Chang-Kwon Kang",
        "published": "2024-1-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2514/6.2024-0948"
    },
    {
        "id": 28062,
        "title": "Smoothness-based consistency learning for macaque pose estimation",
        "authors": "Ping Xue, ShiXiong Deng",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11760-023-02665-1"
    },
    {
        "id": 28063,
        "title": "A multimodal discrimination method for the response to name behavior of autistic children based on human pose tracking and head pose estimation",
        "authors": "Chunyi Song, Shigang Wang, Meimei Chen, Honghua Li, Feiyong Jia, Yunxiu Zhao",
        "published": "2023-1",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.displa.2022.102360"
    },
    {
        "id": 28064,
        "title": "Exploration of deep learning architectures for real-time yoga pose recognition",
        "authors": "Sumeet Saurav, Prashant Gidde, Sanjay Singh",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-024-18694-y"
    },
    {
        "id": 28065,
        "title": "Thermal image identification against pose and expression variations using deep learning",
        "authors": "Naser Zaeri, Rusul Qasim",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jer.2023.10.043"
    },
    {
        "id": 28066,
        "title": "Learning scale-aware relationships via Laplacian decomposition-based transformer for 3D human pose estimation",
        "authors": "Jeonghwan Kim, Hyukmin Kwon, Seong Yong Lim, Wonjun Kim",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00530-023-01216-5"
    },
    {
        "id": 28067,
        "title": "L-HRNet: A Lightweight High-Resolution Network for Human Pose Estimation",
        "authors": "Yunxiang Liu, Jiajie Hua",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciibms60103.2023.10347785"
    },
    {
        "id": 28068,
        "title": "Privacy-Preserved Video Monitoring Method with 3D Human Pose Estimation",
        "authors": "Jifan Shen, Yuling Sun",
        "published": "2023-5-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cscwd57460.2023.10152735"
    },
    {
        "id": 28069,
        "title": "Dense-connected Stacked Hourglass Networks for Human Pose Estimation",
        "authors": "H. Liu, C. Ding",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": "The main idea of this project is to try to improve the accuracy of human pose estimation in previous models. The new model proposed is based on the Stacked Hourglass Network with new structures added. The new structures ensured that the preservation of features of the original data by adding connections across the network, which we refer to as a Dense-connected Stacked Hourglass network, and we expected the new structure and the feature preserved could be helpful in the later stages because the Stacked Hourglass network pools down to very low resolution, during which important information may be lost. The data sets used in the project are MPII Human Pose and FLIC (Frames Labelled in Cinema). The final results show that the proposed architecture is able to improve the estimation accuracy to certain extend in identifying head, wrist and hip, while further studies on the architecture and improvements are still required.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/38/20230534"
    },
    {
        "id": 28070,
        "title": "Lightweight Cross-Fusion Network on Human Pose Estimation for Edge Device",
        "authors": "Xian Zhu, Xiaoqin Zeng, Wei Ma",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2021.3065574"
    },
    {
        "id": 28071,
        "title": "Monocular Vision and Machine Learning for Pose Estimation",
        "authors": "Quang Tran, Jeffrey Choate, Clark N. Taylor, Scott Nykl, David Curtis",
        "published": "2023-4-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/plans53410.2023.10140128"
    },
    {
        "id": 28072,
        "title": "DB-HRNet: Dual Branch High-Resolution Network for Human Pose Estimation",
        "authors": "Yanxia Wang, Renjie Wang, Hu Shi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3328221"
    },
    {
        "id": 28073,
        "title": "Multi-hypothesis representation learning for transformer-based 3D human pose estimation",
        "authors": "Wenhao Li, Hong Liu, Hao Tang, Pichao Wang",
        "published": "2023-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2023.109631"
    },
    {
        "id": 28074,
        "title": "Self-supervised 3D Human Pose Estimation from a Single Image",
        "authors": "Jose Sosa, David Hogg",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00507"
    },
    {
        "id": 28075,
        "title": "A Comparative Study of Recent 2D Human Pose Estimation Methods",
        "authors": "Nada E. Elshami, Ahmad Salah, Heba Mohsen",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icci61671.2024.10485088"
    },
    {
        "id": 28076,
        "title": "ElliPose: Stereoscopic 3D Human Pose Estimation by Fitting Ellipsoids",
        "authors": "Christian Grund, Julian Tanke, Juergen Gall",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00289"
    },
    {
        "id": 28077,
        "title": "Multi-scale Feature Injection for Occluded 3D Human Pose and Shape Estimation",
        "authors": "Yunhui Shi, Yangyang Ge, Jin Wang",
        "published": "2023-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ccdc58219.2023.10327150"
    },
    {
        "id": 28078,
        "title": "An enhanced real-time human pose estimation method based on modified YOLOv8 framework",
        "authors": "Chengang Dong, Guodong Du",
        "published": "2024-4-5",
        "citations": 0,
        "abstract": "AbstractThe objective of human pose estimation (HPE) derived from deep learning aims to accurately estimate and predict the human body posture in images or videos via the utilization of deep neural networks. However, the accuracy of real-time HPE tasks is still to be improved due to factors such as partial occlusion of body parts and limited receptive field of the model. To alleviate the accuracy loss caused by these issues, this paper proposes a real-time HPE model called $${\\textbf {CCAM-Person}}$$\n\nCCAM\n-\nPerson\n\n based on the YOLOv8 framework. Specifically, we have improved the backbone and neck of the YOLOv8x-pose real-time HPE model to alleviate the feature loss and receptive field constraints. Secondly, we introduce the context coordinate attention module (CCAM) to augment the model’s focus on salient features, reduce background noise interference, alleviate key point regression failure caused by limb occlusion, and improve the accuracy of pose estimation. Our approach attains competitive results on multiple metrics of two open-source datasets, MS COCO 2017 and CrowdPose. Compared with the baseline model YOLOv8x-pose, CCAM-Person improves the average precision by 2.8% and 3.5% on the two datasets, respectively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-024-58146-z"
    },
    {
        "id": 28079,
        "title": "Learning the Deep and the Shallow: Deep-Learning-Based Depth Phase Picking and Earthquake Depth Estimation",
        "authors": "Jannes Münchmeyer, Joachim Saul, Frederik Tilmann",
        "published": "2023-10-17",
        "citations": 2,
        "abstract": "Abstract\nAutomated teleseismic earthquake monitoring is an essential part of global seismicity analysis. Although constraining epicenters in an automated fashion is an established technique, constraining event depths is substantially more difficult. One solution to this challenge is teleseismic depth phases, but these can currently not be identified precisely by automatic detection methods. Here, we propose two deep-learning models, DepthPhaseTEAM and DepthPhaseNet, to detect and pick depth phases. For training the models, we create a dataset based on the ISC-EHB bulletin—a high-quality catalog with detailed phase annotations. We show how backprojecting the predicted phase arrival probability curves onto the depth axis yields accurate estimates of earthquake depth. Furthermore, we show how a multistation model, DepthPhaseTEAM, leads to better and more consistent predictions than the single-station model, DepthPhaseNet. To allow direct application of our models, we integrate them within the SeisBench library.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1785/0220230187"
    },
    {
        "id": 28080,
        "title": "Human Age Estimation from Images in Real-Time Application Using Machine Learning and Deep Learning Models",
        "authors": "Rohith S V, Lavani Amaan Khan, Archana V, Jayanthi M. G, Prashanth Kannadaguli",
        "published": "2023-9-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nmitcon58196.2023.10275901"
    },
    {
        "id": 28081,
        "title": "Novel deep learning models for yoga pose estimator",
        "authors": "Amira Samy Talaat",
        "published": "2023-12",
        "citations": 1,
        "abstract": "AbstractYoga pose recognition and correction are artificial intelligent techniques to provide standardized and appropriate yoga poses. Incorrect yoga poses can cause serious injuries and long-term complications. Analyzing human posture can identify and rectify abnormal positions, improving well-being at home. A posture estimator extracts yoga asana attributes from properly represented images. These extracted features are then utilized directly as inputs for various neural networks and machine learning models. These models serve the purpose of evaluating and predicting the accuracy of specific yoga poses. The objective of this research is to explore multiple methods for classifying yoga poses. The LGDeep model is introduced, which combines a novel residual convolutional neural network with three deep learning approaches: Xception, VGGNet, and SqueezeNet. Additionally, the LGDeep model incorporates feature extraction methods such as LDA and GDA. Experimental results demonstrate that the LGDeep classifier outperforms other approaches and achieves the highest classification accuracy ratio.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42452-023-05581-8"
    },
    {
        "id": 28082,
        "title": "Research on Bolt Pose Detection Technology Based on Deep Learning",
        "authors": "Lin Shang, Xuewei Cao, En Li",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cac59555.2023.10451097"
    },
    {
        "id": 28083,
        "title": "Evaluation of hybrid deep learning and optimization method for 3D human pose and shape reconstruction in simulated depth images",
        "authors": "Xiaofang Wang, Stéphanie Prévost, Adnane Boukhayma, Eric Desjardin, Céline Loscos, Benoit Morisset, Franck Multon",
        "published": "2023-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cag.2023.07.005"
    },
    {
        "id": 28084,
        "title": "Listening Human Behavior: 3D Human Pose Estimation with Acoustic Signals",
        "authors": "Yuto Shibata, Yutaka Kawashima, Mariko Isogawa, Go Irie, Akisato Kimura, Yoshimitsu Aoki",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01280"
    },
    {
        "id": 28085,
        "title": "A survey on deep learning-based monocular spacecraft pose estimation: Current state, limitations and prospects",
        "authors": "Leo Pauly, Wassim Rharbaoui, Carl Shneider, Arunkumar Rathinam, Vincent Gaudillière, Djamila Aouada",
        "published": "2023-11",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.actaastro.2023.08.001"
    },
    {
        "id": 28086,
        "title": "A survey of deep learning methods and datasets for hand pose estimation from hand-object interaction images",
        "authors": "Taeyun Woo, Wonjung Park, Woohyun Jeong, Jinah Park",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cag.2023.09.013"
    },
    {
        "id": 28087,
        "title": "Pose Estimation and Virtual Gym Assistant Using MediaPipe and Machine Learning",
        "authors": "Urmi Dedhia, Pratham Bhoir, Prateek Ranka, Pratik Kanani",
        "published": "2023-9-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nmitcon58196.2023.10275938"
    },
    {
        "id": 28088,
        "title": "Human Pose Estimation based on HRNet and Feature Pyramids",
        "authors": "Fangjie Dong, Miaowei Yang, Pengshen Yang",
        "published": "2023-4-1",
        "citations": 0,
        "abstract": "A popular area of research in the realm of computer vision is human pose estimation, which is the process of recovering human joint points from the given images or videos. Convolutional neural networks, which have great feature representation capabilities, have become a fundamental component of human pose estimation algorithms as a result of the deep learning field's quick development. To enhance feature quality and raise the precision of human pose estimate, in this paper, we propose a new model based on HRNet neural network and feature pyramid to more accurately capture each main part of the human body. The model uses HRNet as the backbone network, taking advantage of its ability to combine low resolution with high resolution, and afterwards adds characteristic pyramids to the HRNetnetwork in order to enhance the capability of detecting small objects by utilizing its ability to solve multi-scale problems. The model can estimate a human's pose accurately, according to experimental results, and on the MPII Human Pose dataset, the addition of the feature pyramid enhances the model's detection performance by 0.05. in order to achieve smoothing after adding feature mapping with different resolutions, the detection performance improves by 0.17 after further improvement by adding  convolution. For the elbow, it improves by almost 0.5. The model's ability to increase the precision of human pose estimate is supported by all of the outcomes.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v39i.6734"
    },
    {
        "id": 28089,
        "title": "CapsulePose: A variational CapsNet for real-time end-to-end 3D human pose estimation",
        "authors": "Nicola Garau, Nicola Conci",
        "published": "2023-2",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neucom.2022.11.097"
    },
    {
        "id": 28090,
        "title": "Upper Bounds for Localization Errors in 2D Human Pose Estimation",
        "authors": "Patrick Schlosser, Christoph Ledermann, Tamim Asfour",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iros55552.2023.10341572"
    },
    {
        "id": 28091,
        "title": "FALNet: flow-based attention lightweight network for human pose estimation",
        "authors": "Degui Xiao, Jiahui Liu, Jiazhi Li",
        "published": "2023-9-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/1.jei.32.5.053008"
    },
    {
        "id": 28092,
        "title": "Integrated Driver Pose Estimation for Autonomous Driving",
        "authors": "Xiao Cao, Wei Hu, Hui Liu",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012639400003657"
    },
    {
        "id": 28093,
        "title": "Recurrent Transformer for 3D Human Pose Estimation",
        "authors": "Guang Cheng, Yan Huang, Bing Yu",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icbase59196.2023.10303115"
    },
    {
        "id": 28094,
        "title": "Human Pose Estimation using Artificial Intelligence with Virtual Gym Tracker",
        "authors": "Neetu Faujdar, Shipra Saraswat, Sachin Sharma",
        "published": "2023-3-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iscon57294.2023.10112064"
    },
    {
        "id": 28095,
        "title": "Human Pose Estimation Using MediaPipe Pose and Optimization Method Based on a Humanoid Model",
        "authors": "Jong-Wook Kim, Jin-Young Choi, Eun-Ju Ha, Jae-Ho Choi",
        "published": "2023-2-20",
        "citations": 27,
        "abstract": "Seniors who live alone at home are at risk of falling and injuring themselves and, thus, may need a mobile robot that monitors and recognizes their poses automatically. Even though deep learning methods are actively evolving in this area, they have limitations in estimating poses that are absent or rare in training datasets. For a lightweight approach, an off-the-shelf 2D pose estimation method, a more sophisticated humanoid model, and a fast optimization method are combined to estimate joint angles for 3D pose estimation. As a novel idea, the depth ambiguity problem of 3D pose estimation is solved by adding a loss function deviation of the center of mass from the center of the supporting feet and penalty functions concerning appropriate joint angle rotation range. To verify the proposed pose estimation method, six daily poses were estimated with a mean joint coordinate difference of 0.097 m and an average angle difference per joint of 10.017 degrees. In addition, to confirm practicality, videos of exercise activities and a scene of a person falling were filmed, and the joint angle trajectories were produced as the 3D estimation results. The optimized execution time per frame was measured at 0.033 s on a single-board computer (SBC) without GPU, showing the feasibility of the proposed method as a real-time system.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app13042700"
    },
    {
        "id": 28096,
        "title": "Action Recognition and Sports Evaluation of Running Pose Based on Pose Estimation",
        "authors": "Yongchang Yang, Yang Zeng, Li Yang, Yifan Lu, Xinwei Lee, Yasushi Enomoto",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.13189/saj.2024.120118"
    },
    {
        "id": 28097,
        "title": "3D Human Pose Estimation with Dilated Sampled Frames",
        "authors": "Ge Cao, Qing Tang, Tran Tien Dat, Ashraf Uddin Russo, Kanghyun Jo",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iwis58789.2023.10284636"
    },
    {
        "id": 28098,
        "title": "BalanceHRNet: An effective network for bottom-up human pose estimation",
        "authors": "Yaoping Li, Shuangcheng Jia, Qian Li",
        "published": "2023-4",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.01.036"
    },
    {
        "id": 28099,
        "title": "Contextual learning in Video Analytics for Human pose Detection using Bayesian Learning and LSTM",
        "authors": "S. Jeevidha, S. Saraswathi, D Vishnuprasad.",
        "published": "2023-4-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icnwc57852.2023.10127440"
    },
    {
        "id": 28100,
        "title": "Ensemble of 6 DoF Pose estimation from state-of-the-art deep methods.",
        "authors": "Ibon Merino, Jon Azpiazu, Anthony Remazeilles, Basilio Sierra",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neucom.2023.126270"
    },
    {
        "id": 28101,
        "title": "Enhancing Cricket Performance Analysis with Human Pose Estimation and Machine Learning",
        "authors": "Hafeez Ur Rehman Siddiqui, Faizan Younas, Furqan Rustam, Emmanuel Soriano Flores, Julién Brito Ballester, Isabel de la Torre Diez, Sandra Dudley, Imran Ashraf",
        "published": "2023-8-1",
        "citations": 1,
        "abstract": "Cricket has a massive global following and is ranked as the second most popular sport globally, with an estimated 2.5 billion fans. Batting requires quick decisions based on ball speed, trajectory, fielder positions, etc. Recently, computer vision and machine learning techniques have gained attention as potential tools to predict cricket strokes played by batters. This study presents a cutting-edge approach to predicting batsman strokes using computer vision and machine learning. The study analyzes eight strokes: pull, cut, cover drive, straight drive, backfoot punch, on drive, flick, and sweep. The study uses the MediaPipe library to extract features from videos and several machine learning and deep learning algorithms, including random forest (RF), support vector machine, k-nearest neighbors, decision tree, linear regression, and long short-term memory to predict the strokes. The study achieves an outstanding accuracy of 99.77% using the RF algorithm, outperforming the other algorithms used in the study. The k-fold validation of the RF model is 95.0% with a standard deviation of 0.07, highlighting the potential of computer vision and machine learning techniques for predicting batsman strokes in cricket. The study’s results could help improve coaching techniques and enhance batsmen’s performance in cricket, ultimately improving the game’s overall quality.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23156839"
    },
    {
        "id": 28102,
        "title": "ActionPrompt: Action-Guided 3D Human Pose Estimation With Text and Pose Prompting",
        "authors": "Hongwei Zheng, Han Li, Bowen Shi, Wenrui Dai, Botao Wang, Yu Sun, Min Guo, Hongkai Xiong",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icme55011.2023.00452"
    },
    {
        "id": 28103,
        "title": "Deep metric learning for visual servoing: when pose and image meet in latent space",
        "authors": "Samuel Felton, Elisa Fromont, Eric Marchand",
        "published": "2023-5-29",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icra48891.2023.10160963"
    },
    {
        "id": 28104,
        "title": "Real‐time ergonomic risk assessment in construction using a co‐learning‐powered 3D human pose estimation model",
        "authors": "Wang Chen, Donglian Gu, Jintao Ke",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "AbstractWork‐related musculoskeletal disorders pose significant health risks to construction workers, making it essential to monitor their postures and identify physical exposure to mitigate these risks. This study presents a novel framework for real‐time ergonomic risk assessment of workers in construction environments. Specifically, this study develops a lightweight human pose estimation (HPE) model with a residual log‐likelihood estimation head and adopts pose‐tracking technology to enable real‐time recognition of workers’ three‐dimensional (3D) postures. In particular, this study proposes a novel co‐learning method that enables the HPE model to learn two‐dimensional (2D) and 3D features from multi‐dimension datasets simultaneously, substantially enhancing the model's ability to capture 3D postures from 2D images. The proposed framework facilitates real‐time ergonomic risk assessment, reducing potential risks to construction workers and offering promising practical applications.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1111/mice.13139"
    }
]