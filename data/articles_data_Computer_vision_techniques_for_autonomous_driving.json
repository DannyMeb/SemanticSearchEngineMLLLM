[
    {
        "id": 13905,
        "title": "Lens Flare-Aware Detector in Autonomous Driving",
        "authors": "Shanxing Ma, Jan Aelterman",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012309900003660"
    },
    {
        "id": 13906,
        "title": "Improving Lane Annotation in Autonomous Driving Data Sets with Classical Computer Vision Techniques",
        "authors": "Dimitrije Stojanović, Nenad Četić, Jelena Kocić, Bogdan Pavković",
        "published": "2023-5-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/zinc58345.2023.10174073"
    },
    {
        "id": 13907,
        "title": "Surround-View Vision-based 3D Detection for Autonomous Driving: A Survey",
        "authors": "Apoorv Singh",
        "published": "2023-10-2",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00348"
    },
    {
        "id": 13908,
        "title": "Transformer-Based Sensor Fusion for Autonomous Driving: A Survey",
        "authors": "Apoorv Singh",
        "published": "2023-10-2",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00355"
    },
    {
        "id": 13909,
        "title": "MVAD: monocular vision-based autonomous driving distance perception system",
        "authors": "Xiaoyun Wei, Chaosui Xiao",
        "published": "2023-2-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2660058"
    },
    {
        "id": 13910,
        "title": "SMART-RD: Towards a Risk Assessment Framework for Autonomous Railway Driving",
        "authors": "Justin Bescop, Nicolas Goeman, Amel Aissaoui, Benjamin Allaert, Jean-Philippe Vandeborre",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012474300003660"
    },
    {
        "id": 13911,
        "title": "Comprehensive Evaluation of End-to-End Driving Model Explanations for Autonomous Vehicles",
        "authors": "Chenkai Zhang, Daisuke Deguchi, Jialei Chen, Hiroshi Murase",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012365900003660"
    },
    {
        "id": 13912,
        "title": "Domain generalization of 3D semantic segmentation in autonomous driving",
        "authors": "Jules Sanchez, Jean-Emmanuel Deschaud, François Goulette",
        "published": "2023-10-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01657"
    },
    {
        "id": 13913,
        "title": "WEDGE: A multi-weather autonomous driving dataset built from generative vision-language models",
        "authors": "Aboli Marathe, Deva Ramanan, Rahee Walambe, Ketan Kotecha",
        "published": "2023-6",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00334"
    },
    {
        "id": 13914,
        "title": "Efficiency study of VGG networks in autonomous driving tasks",
        "authors": "Junhua Qi",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3021397"
    },
    {
        "id": 13915,
        "title": "Unsupervised 3D Perception with 2D Vision-Language Distillation for Autonomous Driving",
        "authors": "Mahyar Najibi, Jingwei Ji, Yin Zhou, Charles R. Qi, Xinchen Yan, Scott Ettinger, Dragomir Anguelov",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00790"
    },
    {
        "id": 13916,
        "title": "Can Visual Information Reduce Anxiety During Autonomous Driving? Analysis and Reduction of Anxiety Based on Eye Movements in Passengers of Autonomous Personal Mobility Vehicles",
        "authors": "Ryunosuke Harada, Hiroshi Yoshitake, Motoki Shino",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011802800003417"
    },
    {
        "id": 13917,
        "title": "On Offline Evaluation of 3D Object Detection for Autonomous Driving",
        "authors": "Tim Schreier, Katrin Renz, Andreas Geiger, Kashyap Chitta",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00441"
    },
    {
        "id": 13918,
        "title": "VLAAD: Vision and Language Assistant for Autonomous Driving",
        "authors": "SungYeon Park, MinJae Lee, JiHyuk Kang, Hahyeon Choi, Yoonah Park, Juhwan Cho, Adam Lee, DongKyu Kim",
        "published": "2024-1-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacvw60836.2024.00107"
    },
    {
        "id": 13919,
        "title": "Neural Map Prior for Autonomous Driving",
        "authors": "Xuan Xiong, Yicheng Liu, Tianyuan Yuan, Yue Wang, Yilun Wang, Hang Zhao",
        "published": "2023-6",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01682"
    },
    {
        "id": 13920,
        "title": "Potential cyber threats of adversarial attacks on autonomous driving models",
        "authors": "Eldar Boltachev",
        "published": "2023-6-5",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11416-023-00486-x"
    },
    {
        "id": 13921,
        "title": "Localized Semantic Feature Mixers for Efficient Pedestrian Detection in Autonomous Driving",
        "authors": "Abdul Hannan Khan, Mohammed Shariq Nawaz, Andreas Dengel",
        "published": "2023-6",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00530"
    },
    {
        "id": 13922,
        "title": "Physics-inspired computer vision algorithms for autonomous driving, security, and medical applications",
        "authors": "Bahram Jalali",
        "published": "2023-9-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2678189"
    },
    {
        "id": 13923,
        "title": "Weakly Supervised Class-agnostic Motion Prediction for Autonomous Driving",
        "authors": "Ruibo Li, Hanyu Shi, Ziang Fu, Zhe Wang, Guosheng Lin",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01688"
    },
    {
        "id": 13924,
        "title": "Video Task Decathlon: Unifying Image and Video Tasks in Autonomous Driving",
        "authors": "Thomas E. Huang, Yifan Liu, Luc Van Gool, Fisher Yu",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00794"
    },
    {
        "id": 13925,
        "title": "Exploring the Road Graph in Trajectory Forecasting for Autonomous Driving",
        "authors": "Rémy Sun, Diane Lingrand, Frédéric Precioso",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00014"
    },
    {
        "id": 13926,
        "title": "Correction to: Potential cyber threats of adversarial attacks on autonomous driving models",
        "authors": "Eldar Boltachev",
        "published": "2023-8-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11416-023-00497-8"
    },
    {
        "id": 13927,
        "title": "Azimuth Super-Resolution for FMCW Radar in Autonomous Driving",
        "authors": "Yu-Jhe Li, Shawn Hunt, Jinhyung Park, Matthew O'Toole, Kris Kitani",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01679"
    },
    {
        "id": 13928,
        "title": "GameFormer: Game-theoretic Modeling and Learning of Transformer-based Interactive Prediction and Planning for Autonomous Driving",
        "authors": "Zhiyu Huang, Haochen Liu, Chen Lv",
        "published": "2023-10-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00361"
    },
    {
        "id": 13929,
        "title": "SemARFlow: Injecting Semantics into Unsupervised Optical Flow Estimation for Autonomous Driving",
        "authors": "Shuai Yuan, Shuzhi Yu, Hannah Kim, Carlo Tomasi",
        "published": "2023-10-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00877"
    },
    {
        "id": 13930,
        "title": "Learning Human Dynamics in Autonomous Driving Scenarios",
        "authors": "Jingbo Wang, Ye Yuan, Zhengyi Luo, Kevin Xie, Dahua Lin, Umar Iqbal, Sanja Fidler, Sameh Khamis",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01901"
    },
    {
        "id": 13931,
        "title": "Domain Adaptive Object Detection for Autonomous Driving under Foggy Weather",
        "authors": "Jinlong Li, Runsheng Xu, Jin Ma, Qin Zou, Jiaqi Ma, Hongkai Yu",
        "published": "2023-1",
        "citations": 20,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00068"
    },
    {
        "id": 13932,
        "title": "InfraParis: A multi-modal and multi-task autonomous driving dataset",
        "authors": "Gianni Franchi, Marwane Hariat, Xuanlong Yu, Nacim Belkhir, Antoine Manzanera, David Filliat",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00295"
    },
    {
        "id": 13933,
        "title": "Sensitivity analysis of AI-based algorithms for autonomous driving on optical wavefront aberrations induced by the windshield",
        "authors": "Dominik Werner Wolf, Markus Ulrich, Nikhil Kapoor",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00443"
    },
    {
        "id": 13934,
        "title": "Visual Exemplar Driven Task-Prompting for Unified Perception in Autonomous Driving",
        "authors": "Xiwen Liang, Minzhe Niu, Jianhua Han, Hang Xu, Chunjing Xu, Xiaodan Liang",
        "published": "2023-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00927"
    },
    {
        "id": 13935,
        "title": "PP4AV: A benchmarking Dataset for Privacy-preserving Autonomous Driving",
        "authors": "Linh Trinh, Phuong Pham, Hoang Trinh, Nguyen Bach, Dung Nguyen, Giang Nguyen, Huy Nguyen",
        "published": "2023-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00126"
    },
    {
        "id": 13936,
        "title": "Temporal Consistent 3D LiDAR Representation Learning for Semantic Perception in Autonomous Driving",
        "authors": "Lucas Nunes, Louis Wiesmann, Rodrigo Marcuzzi, Xieyuanli Chen, Jens Behley, Cyrill Stachniss",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00505"
    },
    {
        "id": 13937,
        "title": "NuScenes-MQA: Integrated Evaluation of Captions and QA for Autonomous Driving Datasets using Markup Annotations",
        "authors": "Yuichi Inoue, Yuki Yada, Kotaro Tanahashi, Yu Yamaguchi",
        "published": "2024-1-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacvw60836.2024.00104"
    },
    {
        "id": 13938,
        "title": "Augmenting Vision Queries with RADAR for BEV Detection in Autonomous Driving",
        "authors": "Apoorv Singh",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cai54212.2023.00031"
    },
    {
        "id": 13939,
        "title": "RangeViT: Towards Vision Transformers for 3D Semantic Segmentation in Autonomous Driving",
        "authors": "Angelika Ando, Spyros Gidaris, Andrei Bursuc, Gilles Puy, Alexandre Boulch, Renaud Marlet",
        "published": "2023-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00507"
    },
    {
        "id": 13940,
        "title": "DriveAdapter: Breaking the Coupling Barrier of Perception and Planning in End-to-End Autonomous Driving",
        "authors": "Xiaosong Jia, Yulu Gao, Li Chen, Junchi Yan, Patrick Langechuan Liu, Hongyang Li",
        "published": "2023-10-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00731"
    },
    {
        "id": 13941,
        "title": "MSeg3D: Multi-Modal 3D Semantic Segmentation for Autonomous Driving",
        "authors": "Jiale Li, Hang Dai, Hao Han, Yong Ding",
        "published": "2023-6",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.02078"
    },
    {
        "id": 13942,
        "title": "Does Physical Adversarial Example Really Matter to Autonomous Driving? Towards System-Level Effect of Adversarial Object Evasion Attack",
        "authors": "Ningfei Wang, Yunpeng Luo, Takami Sato, Kaidi Xu, Qi Alfred Chen",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00407"
    },
    {
        "id": 13943,
        "title": "MV-DeepSDF: Implicit Modeling with Multi-Sweep Point Clouds for 3D Vehicle Reconstruction in Autonomous Driving",
        "authors": "Yibo Liu, Kelly Zhu, Guile Wu, Yuan Ren, Bingbing Liu, Yang Liu, Jinjun Shan",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00763"
    },
    {
        "id": 13944,
        "title": "Vision-Based DRL Autonomous Driving Agent with Sim2Real Transfer",
        "authors": "Dianzhao Li, Ostap Okhrin",
        "published": "2023-9-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/itsc57777.2023.10422677"
    },
    {
        "id": 13945,
        "title": "Think Twice before Driving: Towards Scalable Decoders for End-to-End Autonomous Driving",
        "authors": "Xiaosong Jia, Penghao Wu, Li Chen, Jiangwei Xie, Conghui He, Junchi Yan, Hongyang Li",
        "published": "2023-6",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.02105"
    },
    {
        "id": 13946,
        "title": "Learnable fusion mechanisms for multimodal object detection in autonomous vehicles",
        "authors": "Yahya Massoud, Robert Laganiere",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "AbstractPerception systems in autonomous vehicles need to accurately detect and classify objects within their surrounding environments. Numerous types of sensors are deployed on these vehicles, and the combination of such multimodal data streams can significantly boost performance. The authors introduce a novel sensor fusion framework using deep convolutional neural networks. The framework employs both camera and LiDAR sensors in a multimodal, multiview configuration. The authors leverage both data types by introducing two new innovative fusion mechanisms: element‐wise multiplication and multimodal factorised bilinear pooling. The methods improve the bird's eye view moderate average precision score by +4.97% and +8.35% on the KITTI dataset when compared to traditional fusion operators like element‐wise addition and feature map concatenation. An in‐depth analysis of key design choices impacting performance, such as data augmentation, multi‐task learning, and convolutional architecture design is offered. The study aims to pave the way for the development of more robust multimodal machine vision systems. The authors conclude the paper with qualitative results, discussing both successful and problematic cases, along with potential ways to mitigate the latter.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12259"
    },
    {
        "id": 13947,
        "title": "Toward resilient autonomous driving—An experience report on integrating resilience mechanisms into the Apollo autonomous driving software stack",
        "authors": "Federico Lucchetti, Rafal Graczyk, Marcus Völp",
        "published": "2023-4-11",
        "citations": 0,
        "abstract": "Autonomous driver assistance systems (ADAS) have been progressively pushed to extremes. Today, increasingly sophisticated algorithms, such as deep neural networks, assume responsibility for critical driving functionality, including operating the vehicle at various levels of autonomy. Elaborate obstacle detection, classification, and prediction algorithms, mostly vision-based, trajectory planning, and smooth control algorithms, take over what humans learn until they are permitted to control vehicles and beyond. And even if humans remain in the loop (e.g., to intervene in case of error, as required by autonomy levels 3 and 4), it remains questionable whether distracted human drivers will react appropriately, given the high speed at which vehicles drive and the complex traffic situations they have to cope with. A further pitfall is trusting the whole autonomous driving stack not to fail due to accidental causes and to be robust against cyberattacks of increasing sophistication. In this experience report, we share our findings in retrofitting application-agnostic resilience mechanisms into an existing hardware-/software-stack for autonomous driving—Apollo—as well as where application knowledge helps improve existing resilience algorithms. Our goal is to ultimately decrease the vulnerability of autonomously driving vehicles to accidental faults and attacks, allowing them to absorb and tolerate both, as well as to come out of them at least as secure as before the attack has happened. We demonstrate replication and rejuvenation on the driving stack's Control module and indicate how this resilience can be extended both downwards to the hardware level, as well as upwards to the prediction and planning modules.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fcomp.2023.1125055"
    },
    {
        "id": 13948,
        "title": "Lane Detection and Traffic Sign Detection using Deep Learning and Computer Vision for Autonomous Driving Research Using CARLA Simulator",
        "authors": "Et al. Hithaishi Surendra",
        "published": "2023-11-7",
        "citations": 0,
        "abstract": "Lane identification and traffic sign detection is the most challenging and promising problem for self-driving or autonomous vehicles with unintentional lane departure and ignorance of traffic signs being major contributing factors to motor vehicle collisions around the world. To tackle this problem the proposed work aims to detect both lane and traffic signs for autonomous vehicles. This article proposes semantic segmentation and object detection model for implementing Advanced Driver Assistance System (ADAS) applications. The applications are implemented using a variant of Convolutional Neural Networks (CNN) deep learning model such as SegNet and You Only Look Once (YOLO) algorithm. Due to dynamic and adverse environment conditions, devising and testing a system which yields effective performance in all urban driving scenarios is challenging. Hence the environment is set up virtually with the help of the Car Learning to Act (CARLA) simulator. With aid of developed models, lane and traffic signs were successfully detected and tested under various constraints. Obtained results are evaluated with various performance metrics.  Models are deployed for separate created datasets. The semantic segmentation model developed for lane detection using SegNet gives a mean average precision (mAP) of 93.33%, an overall accuracy of 94.80%, F-score of 93.42% and a minimal error rate of 5.20%. Model developed for Traffic sign detection, a mean average precision of 93.67%, an accuracy of 95.56%, recall of 92.67%, F-score of 93.16% and error rate of 4.44% have been achieved.",
        "keywords": "",
        "link": "http://dx.doi.org/10.17762/ijritcc.v11i10.8891"
    },
    {
        "id": 13949,
        "title": "Zenseact Open Dataset: A large-scale and diverse multimodal dataset for autonomous driving",
        "authors": "Mina Alibeigi, William Ljungbergh, Adam Tonderski, Georg Hess, Adam Lilja, Carl Lindström, Daria Motorniuk, Junsheng Fu, Jenny Widahl, Christoffer Petersson",
        "published": "2023-10-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01846"
    },
    {
        "id": 13950,
        "title": "TBP-Former: Learning Temporal Bird's-Eye-View Pyramid for Joint Perception and Prediction in Vision-Centric Autonomous Driving",
        "authors": "Shaoheng Fang, Zi Wang, Yiqi Zhong, Junhao Ge, Siheng Chen",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00138"
    },
    {
        "id": 13951,
        "title": "IS GESTURE-BASED INTERACTION EQUALLY VIABLE IN MANUAL AND AUTONOMOUS DRIVING?",
        "authors": "",
        "published": "2023-7-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.33965/mccsis2023_202304c001"
    },
    {
        "id": 13952,
        "title": "SurroundOcc: Multi-Camera 3D Occupancy Prediction for Autonomous Driving",
        "authors": "Yi Wei, Linqing Zhao, Wenzhao Zheng, Zheng Zhu, Jie Zhou, Jiwen Lu",
        "published": "2023-10-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01986"
    },
    {
        "id": 13953,
        "title": "VAD: Vectorized Scene Representation for Efficient Autonomous Driving",
        "authors": "Bo Jiang, Shaoyu Chen, Qing Xu, Bencheng Liao, Jiajie Chen, Helong Zhou, Qian Zhang, Wenyu Liu, Chang Huang, Xinggang Wang",
        "published": "2023-10-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00766"
    },
    {
        "id": 13954,
        "title": "Developing a Car Object Detection Module for an Autonomous-driving System",
        "authors": "Yi Shi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.procs.2023.11.035"
    },
    {
        "id": 13955,
        "title": "GRI: General Reinforced Imitation and Its Application to Vision-Based Autonomous Driving",
        "authors": "Raphael Chekroun, Marin Toromanoff, Sascha Hornauer, Fabien Moutarde",
        "published": "2023-9-6",
        "citations": 9,
        "abstract": "Deep reinforcement learning (DRL) has been demonstrated to be effective for several complex decision-making applications, such as autonomous driving and robotics. However, DRL is notoriously limited by its high sample complexity and its lack of stability. Prior knowledge, e.g., as expert demonstrations, is often available but challenging to leverage to mitigate these issues. In this paper, we propose General Reinforced Imitation (GRI), a novel method which combines benefits from exploration and expert data and is straightforward to implement over any off-policy RL algorithm. We make one simplifying hypothesis: expert demonstrations can be seen as perfect data whose underlying policy gets a constant high reward. Based on this assumption, GRI introduces the notion of offline demonstration agent. This agent sends expert data which are processed both concurrently and indistinguishably with the experiences coming from the online RL exploration agent. We show that our approach enables major improvements on camera-based autonomous driving in urban environments. We further validate the GRI method on Mujoco continuous control tasks with different off-policy RL algorithms. Our method ranked first on the CARLA Leaderboard and outperforms World on Rails, the previous state-of-the-art method, by 17%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/robotics12050127"
    },
    {
        "id": 13956,
        "title": "Building a Vision-Based Mixed-Reality Framework for Autonomous Driving Navigation",
        "authors": "Imane Argui, Maxime Gueriau, Samia Ainouz",
        "published": "2023-7-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/codit58514.2023.10284251"
    },
    {
        "id": 13957,
        "title": "Applications of visual perception techniques using neural  networks in autonomous driving",
        "authors": "Kangye Hu",
        "published": "2023-12-6",
        "citations": 0,
        "abstract": "The perception system and the decision system are important components of a complete autonomous driving vehicle. The perception system can help the decision system to obtain the necessary information of external environment and vehicle status. The traditional perception system mainly relies on the on-board radar. But in recent years, vision-based perception techniques have become a hot research topic. Meanwhile, thanks to the excellent performance of neural networks in processing image data, the processing algorithms for visual perception images have also made great progress. Visual perception techniques can not only acquire more information, but also is more cost effective and easier to install. This paper provides an overview of the more mature and promising visual perception techniques, including their principles and data processing algorithms, in terms of acquiring 2D image data and 3D depth information. For acquiring 2D image data, this paper introduces the principle of event camera and reviews the current progress on the event camera. Regarding the acquisition of 3D depth information, three techniques are introduced, namely binocular stereo-vision, time of flight (TOF), and structured light. Their performance when combined with neural networks for autonomous driving applications is also reviewed. Finally, this paper lists the current dilemmas faced by the above 2D and 3D imaging techniques and the possible solutions.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/28/20230140"
    },
    {
        "id": 13958,
        "title": "Fusion of LiDAR and Computer Vision for Autonomous Navigation in Gazebo",
        "authors": "Conor Riordan, Charles O’Donnell",
        "published": "2023-4-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/southeastcon51012.2023.10115172"
    },
    {
        "id": 13959,
        "title": "Ranging Model and Algorithm Based on Monocular Vision for Autonomous Driving",
        "authors": "Rongtian Zheng, Yichao Li, An Wang",
        "published": "2023-2-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/itnec56291.2023.10082072"
    },
    {
        "id": 13960,
        "title": "Autonomous Driving Peripheral And Central Vision Region Selection For Semantic Segmentation",
        "authors": "Ahmed Abdelkader, Mohamed Abdelwahab, Fady Ibrahim, Mohamed Abdelaziz",
        "published": "2023-2-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmre56789.2023.10106575"
    },
    {
        "id": 13961,
        "title": "Planning-oriented Autonomous Driving",
        "authors": "Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima, Xizhou Zhu, Siqi Chai, Senyao Du, Tianwei Lin, Wenhai Wang, Lewei Lu, Xiaosong Jia, Qiang Liu, Jifeng Dai, Yu Qiao, Hongyang Li",
        "published": "2023-6",
        "citations": 51,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01712"
    },
    {
        "id": 13962,
        "title": "ANEC: Adaptive Neural Ensemble Controller for Mitigating Latency Problems in Vision-Based Autonomous Driving",
        "authors": "Aws Khalil, Jaerock Kwon",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iros55552.2023.10342520"
    },
    {
        "id": 13963,
        "title": "Autonomous driving based on deep neural network",
        "authors": "Zhuojun Cheng",
        "published": "2023-3-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2668350"
    },
    {
        "id": 13964,
        "title": "Doppler Principle Based Situational Awareness Method for Autonomous Driving",
        "authors": "Yitong Hu",
        "published": "2023-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cisce58541.2023.10142843"
    },
    {
        "id": 13965,
        "title": "AN IN-DEPTH STUDY OF LANE DETECTION FOR AUTONOMOUS CARS USING COMPUTER VISION TECHNIQUES",
        "authors": "Henil Gajjar,  , Stavan Sanyal,  ",
        "published": "2023-6-1",
        "citations": 0,
        "abstract": "The article discusses the importance of selfdriving cars to improve road safety and reduce the number of accidents caused by human error. Self-driving cars not only reduce human error but also help reduce driver fatigue. We further explore the use of computer vision in autonomous cars, with previous research relying on deep learning algorithms with LiDAR sensors which can be expensive. The authors propose a more cost-effective approach using simple computer vision algorithms such as color space transformation, Canny edge detection, and Hough line transformation to detect lane lines and steer the car accordingly. This approach requires less operational hardware and can be implemented using affordable boards like Raspberry Pi and Nvidia Jetson Nano. The article also highlights the reconstruction of a remote-controlled car that had a 95% accuracy using a certain set of parameters was a tool for understanding autonomous cars better.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33564/ijeast.2023.v08i02.035"
    },
    {
        "id": 13966,
        "title": "Visualization and Visual Analytics in Autonomous Driving",
        "authors": "Sudhir K.Routray",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mcg.2024.3381450"
    },
    {
        "id": 13967,
        "title": "COMPUTER VISION-BASED ROAD VEHICLE TRACKING FOR SELF-DRIVING CAR SYSTEMS",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.35741/issn.0258-2724.58.3.66"
    },
    {
        "id": 13968,
        "title": "3D Object Detection for Autonomous Driving: A Comprehensive Survey",
        "authors": "Jiageng Mao, Shaoshuai Shi, Xiaogang Wang, Hongsheng Li",
        "published": "2023-8",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11263-023-01790-1"
    },
    {
        "id": 13969,
        "title": "Equivariant Map and Agent Geometry for Autonomous Driving Motion Prediction",
        "authors": "Yuping Wang, Jier Chen",
        "published": "2023-11-16",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icecet58911.2023.10389246"
    },
    {
        "id": 13970,
        "title": "Autonomous Driving and Improved Pure Pursuit Algorithm",
        "authors": "Lingrui Yu, Yang Xue, Qiuhong Lu",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icemce60359.2023.10490560"
    },
    {
        "id": 13971,
        "title": "L-shape fitting algorithm for 3D object detection in bird’s-eye-view in an autonomous driving system",
        "authors": "Mikhail Chekanov, Oleg Shipitko",
        "published": "2024-4-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3023477"
    },
    {
        "id": 13972,
        "title": "CAD-based Autonomous Vision Inspection Systems",
        "authors": "Francesco Lupi, Antonio Maffei, Michele Lanzetta",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.procs.2024.02.033"
    },
    {
        "id": 13973,
        "title": "Advances and Future Directions in Road Lane Line Detection Techniques for Autonomous Driving Systems",
        "authors": "Suman Mandava -, Joseph Savio P -",
        "published": "2023-9-24",
        "citations": 0,
        "abstract": "This paper explores various road lane line detection techniques essential to autonomous driving and driver assistance systems.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36948/ijfmr.2023.v05i05.6684"
    },
    {
        "id": 13974,
        "title": "A Unified Approach to Autonomous Driving in a High-Fidelity Simulator Using Vision-Based Reinforcement Learning",
        "authors": "Shawan Mohammed, Alp Argun, Gerd Ascheid",
        "published": "2024-1-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sii58957.2024.10417385"
    },
    {
        "id": 13975,
        "title": "Analyzing lower half facial gestures for lip reading applications: Survey on vision techniques",
        "authors": "Preethi S.J., Niranjana Krupa B.",
        "published": "2023-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103738"
    },
    {
        "id": 13976,
        "title": "Enhancing Autonomous Driving with Grounded-Segment Anything Model: Limitations and Mitigations",
        "authors": "Zihao Zhao",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdsca59871.2023.10393594"
    },
    {
        "id": 13977,
        "title": "Road friction estimation based on vision for safe autonomous driving",
        "authors": "Tong Zhao, Peilin Guo, Yintao Wei",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ymssp.2023.111019"
    },
    {
        "id": 13978,
        "title": "Trajectory Prediction in Autonomous Driving with Vision-based Deep Neural Networks",
        "authors": "Vinay Singh, Simran Jot Kaur, Shyam Shanckin",
        "published": "2023-11-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sitis61268.2023.00032"
    },
    {
        "id": 13979,
        "title": "Position Paper: A Vision for the Dynamic Safety Assurance of ML-Enabled Autonomous Driving Systems",
        "authors": "Alvine Boaye Belle, Hadi Hemmati, Timothy C. Lethbridge",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/rew57809.2023.00056"
    },
    {
        "id": 13980,
        "title": "An Modified YOLOv5 Algorithm to Improved Image Identification for Autonomous Driving",
        "authors": "Chun-Chieh Wang, Yi-Shun Lu, Wen-Piao Lin",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/csce60160.2023.00442"
    },
    {
        "id": 13981,
        "title": "Practical research on lane recognition and driving state monitoring method based on computer vision",
        "authors": "Ziyue He",
        "published": "2023-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icpeca56706.2023.10075752"
    },
    {
        "id": 13982,
        "title": "Unsupervised 3D Point Cloud Representation Learning by Triangle Constrained Contrast for Autonomous Driving",
        "authors": "Bo Pang, Hongchi Xia, Cewu Lu",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00506"
    },
    {
        "id": 13983,
        "title": "Tower Crane Driver's Driving Behavior Detection Based on Computer Vision",
        "authors": "Hui Zhang, Yongmei Yi, Xiaocheng Yang, Yang Zhang",
        "published": "2023-4-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccea58433.2023.10135204"
    },
    {
        "id": 13984,
        "title": "Research on Multi-tasking Smart Cars Based on Autonomous Driving Systems",
        "authors": "Shukai Ding, Jian Qu",
        "published": "2023-3-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42979-023-01740-1"
    },
    {
        "id": 13985,
        "title": "Scaling Vision-Based End-to-End Autonomous Driving with Multi-View Attention Learning",
        "authors": "Yi Xiao, Felipe Codevilla, Diego Porres, Antonio M. López",
        "published": "2023-10-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iros55552.2023.10341506"
    },
    {
        "id": 13986,
        "title": "Parallelization Algorithm of Computer Vision for Autonomous Vehicles",
        "authors": "Kaniskaa MS, R. Manimegalai, Noor Mahammad SK",
        "published": "2023-5-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/vitecon58111.2023.10157031"
    },
    {
        "id": 13987,
        "title": "Driving through the Concept Gridlock: Unraveling Explainability Bottlenecks in Automated Driving",
        "authors": "Jessica Echterhoff, An Yan, Kyungtae Han, Amr Abdelraouf, Rohit Gupta, Julian McAuley",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00718"
    },
    {
        "id": 13988,
        "title": "Advancing Autonomous Navigation: Deep Learning Techniques for Self-Driving Cars",
        "authors": "Riya Kapadia, Kush Mehta",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "Abstract: The fast development of self-driving car technology has brought forth radical breakthroughs in the world of transportation and movement. This study paper looks into the paradigm shift allowed by deep learning methods in getting stable and reliable autonomous steering for self-driving cars. Leveraging the power of artificial intelligence, particularly deep learning models, this study presents a comprehensive exploration of the multifaceted aspects involved in developing a self-driving car system that can adeptly perceive its environment, make intelligent decisions, and ensure passenger and pedestrian safety. The paper first reviews the basic concepts of self-driving cars, getting into the challenges associated with real-time awareness, scene understanding, and decision-making in complex and dynamic settings. It then shows the important role that deep learning plays in handling these challenges by studying various neural network designs designed for different tasks, including picture recognition, object detection, semantic segmentation, and path planning. The study encompasses convolutional neural networks (CNNs) for picture analysis.",
        "keywords": "",
        "link": "http://dx.doi.org/10.22214/ijraset.2023.55491"
    },
    {
        "id": 13989,
        "title": "Construction of computer visual dataset for autonomous driving in sand‐dust weather",
        "authors": "Hua Zhongwei",
        "published": "2024-4",
        "citations": 0,
        "abstract": "AbstractWith the wide application of vision‐based autonomous driving and mobile robots, the impact of frequent sand‐dust weather on computer vision applications in landlocked countries during spring and autumn has also attracted more and more attention. Although there has been a lot of research on sand‐dust image enhancement, no research has been conducted on how to improve the positioning accuracy of vision‐based autonomous driving or mobile robots in sand‐dust environments, especially because there is currently a lack of dataset to evaluate visual positioning in sand‐dust weather. Therefore, a complete set of visual positioning dataset construction methods in sand‐dust weather is proposed to fill the gap in the evaluation dataset of application fields such as autonomous driving or mobile robot attitude estimation in sand‐dust weather. At the same time, this method is also suitable for the construction of visual positioning dataset under haze and other similar weather. In addition, this paper further demonstrates to readers how to use the converted dust visual positioning dataset to conduct positioning evaluation experiment of automatic driving in sand‐dust weather.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/ell2.13171"
    },
    {
        "id": 13990,
        "title": "Drive Like a Human: Rethinking Autonomous Driving with Large Language Models",
        "authors": "Daocheng Fu, Xin Li, Licheng Wen, Min Dou, Pinlong Cai, Botian Shi, Yu Qiao",
        "published": "2024-1-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacvw60836.2024.00102"
    },
    {
        "id": 13991,
        "title": "Multi-Modal 3D Object Detection in Autonomous Driving: A Survey",
        "authors": "Yingjie Wang, Qiuyu Mao, Hanqi Zhu, Jiajun Deng, Yu Zhang, Jianmin Ji, Houqiang Li, Yanyong Zhang",
        "published": "2023-8",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11263-023-01784-z"
    },
    {
        "id": 13992,
        "title": "Research on Automatic Driving Test System for On-Line Correction of Computer 3D Image Vision Vehicle Model",
        "authors": "Zhan Wei",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceace60673.2023.10442317"
    },
    {
        "id": 13993,
        "title": "Computer-Vision Based Real Time Waypoint Generation for Autonomous Vineyard Navigation with Quadruped Robots",
        "authors": "Lee Milburn, Juan Gamba, Miguel Fernandes, Claudio Semini",
        "published": "2023-4-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icarsc58346.2023.10129563"
    },
    {
        "id": 13994,
        "title": "Ethical Decision-making for Autonomous Driving based on LSTM Trajectory Prediction Network",
        "authors": "Wen Wei, Jiankun Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.procs.2023.10.647"
    },
    {
        "id": 13995,
        "title": "Survey on fast dense video segmentation techniques",
        "authors": "Quentin Monnier, Tania Pouli, Kidiyo Kpalma",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2024.103959"
    },
    {
        "id": 13996,
        "title": "UDE: A Unified Driving Engine for Human Motion Generation",
        "authors": "Zixiang Zhou, Baoyuan Wang",
        "published": "2023-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00545"
    },
    {
        "id": 13997,
        "title": "PAIR : Perception Aided Image Restoration for Natural Driving Conditions",
        "authors": "Pranjay Shyam, HyunJin Yoo",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00729"
    },
    {
        "id": 13998,
        "title": "Research Status of Acoustic Digital Twin System and Its Prospect in the Field of Autonomous Driving",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23977/acss.2023.070407"
    },
    {
        "id": 13999,
        "title": "Reconstruction-Based Adversarial Attack Detection in Vision-Based Autonomous Driving Systems",
        "authors": "Manzoor Hussain, Jang-Eui Hong",
        "published": "2023-11-7",
        "citations": 1,
        "abstract": "The perception system is a safety-critical component that directly impacts the overall safety of autonomous driving systems (ADSs). It is imperative to ensure the robustness of the deep-learning model used in the perception system. However, studies have shown that these models are highly vulnerable to the adversarial perturbation of input data. The existing works mainly focused on studying the impact of these adversarial attacks on classification rather than regression models. Therefore, this paper first introduces two generalized methods for perturbation-based attacks: (1) We used naturally occurring noises to create perturbations in the input data. (2) We introduce a modified square, HopSkipJump, and decision-based/boundary attack to attack the regression models used in ADSs. Then, we propose a deep-autoencoder-based adversarial attack detector. In addition to offline evaluation metrics (e.g., F1 score and precision, etc.), we introduce an online evaluation framework to evaluate the robustness of the model under attack. The framework considers the reconstruction loss of the deep autoencoder that validates the robustness of the models under attack in an end-to-end fashion at runtime. Our experimental results showed that the proposed adversarial attack detector could detect square, HopSkipJump, and decision-based/boundary attacks with a true positive rate (TPR) of 93%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/make5040080"
    },
    {
        "id": 14000,
        "title": "An End-to-End Optimization Framework for Autonomous Driving Software",
        "authors": "Rainer Trauth, Phillip Karle, Tobias Betz, Johannes Betz",
        "published": "2023-3-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccr56747.2023.10193889"
    },
    {
        "id": 14001,
        "title": "Identifying Occurrences of Abnormal and Drunk Driving Using Smartphones",
        "authors": "Deeksha Agrawal, Shashikala Tapaswi",
        "published": "2023-12-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvmi59935.2023.10464727"
    },
    {
        "id": 14002,
        "title": "Obstacle Detection Technology for Autonomous Driving Based on Deep Learning",
        "authors": "Chenhao Gao",
        "published": "2024-4-10",
        "citations": 0,
        "abstract": "With the rapid growth of artificial intelligence (AI) technology, traditional obstacle detection equipment faces multiple challenges such as high cost, low real-time performance, non normalization, dependence on manual operation, and time-consuming and labor-intensive. To address these shortcomings, this article proposes a deep learning (DL) based obstacle detection technology for autonomous driving on the road surface. As a complex system that integrates multiple key components such as environmental perception, positioning and navigation, path planning, and motion control, one of the core technologies of autonomous vehicles is accurate perception of the surrounding environment. In practical applications, autonomous vehicles often face complex and variable road environments, which may lead to a decrease in the quality of images captured by cameras, resulting in blurry and unclear phenomena. The DL method, especially the object detection algorithm, has shown unique advantages in visual perception and recognition in autonomous driving scenes. This paper deeply studies the obstacle detection technology of automatic driving road based on DL, aiming to achieve efficient and accurate obstacle recognition, improve the safety and reliability of auto drive system, and promote the further growth of automatic driving technology.",
        "keywords": "",
        "link": "http://dx.doi.org/10.62051/c3evm786"
    },
    {
        "id": 14003,
        "title": "Benchmarking Robustness of 3D Object Detection to Common Corruptions in Autonomous Driving",
        "authors": "Yinpeng Dong, Caixin Kang, Jinlai Zhang, Zijian Zhu, Yikai Wang, Xiao Yang, Hang Su, Xingxing Wei, Jun Zhu",
        "published": "2023-6",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00105"
    },
    {
        "id": 14004,
        "title": "Understanding the Robustness of 3D Object Detection with Bird'View Representations in Autonomous Driving",
        "authors": "Zijian Zhu, Yichi Zhang, Hai Chen, Yinpeng Dong, Shu Zhao, Wenbo Ding, Jiachen Zhong, Shibao Zheng",
        "published": "2023-6",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.02069"
    },
    {
        "id": 14005,
        "title": "Optimizing the Placement of Roadside LiDARs for Autonomous Driving",
        "authors": "Wentao Jiang, Hao Xiang, Xinyu Cai, Runsheng Xu, Jiaqi Ma, Yikang Li, Gim Hee Lee, Si Liu",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01685"
    },
    {
        "id": 14006,
        "title": "An IoT based autonomous outdoor patrol robot",
        "authors": "B. Lakshmanaprakash, P. Rajalakshmy",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/icp.2023.2865"
    },
    {
        "id": 14007,
        "title": "Guidance Lanes and Driving Algorithms Based on Computer Vision for Speed Control of Autonomous Mobile Robot",
        "authors": "Jung-Ju Kim, Jae-Hoon Choi, Dong-Jin Kim, Sang-Yule Choi",
        "published": "2024-2-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5370/kiee.2024.73.2.433"
    },
    {
        "id": 14008,
        "title": "Algorithm for automatic optimizing cross-cut saw based on computer vision techniques",
        "authors": "Hailong Ma, Mingwei Shao",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "Abstract\nThe optimization of timber classification by grades and defect detection plays an important role in the production of timbers. Traditionally, a timber is manually cut by a worker according to his experience. Defect detection and classification of a timber are with great subjectivity. Meanwhile, the action is not safe enough. In this case, an automatic optimizing cross-cut saw to finish these tasks of timber classification by grades and defect detection is built significantly. Related algorithms and detailed procedures for optimizing cross-cut saws are proposed in this paper. Additionally, a vision system is used to capture images of a timber. Captured images are analyzed and processed. First, defects in these images are detected. Then the serviceable part (defect-free) of a timber can be determined. Based on the pretrained network, the timber can be classified. As the homography matrix has been known, the physical position can be confirmed. In our proposed system, the cutting list is transmitted from the industrial control computer to a motion control system, then the timber can be cut according to the cutting list automatically. In this paper, related algorithms and detailed procedures are given. Moreover, a new optimizing cross-cut saw is built. Experiments show that the processing time for each image is about 0.026s and the minimum mean average precision is 94.15%. In this case, it can make the optimizing cross-cut saw efficient, labor-saving and safe. Furthermore, related algorithms are suitable to improve a traditional automatic optimizing cross-cut saw.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/2631-8695/acfb5b"
    },
    {
        "id": 14009,
        "title": "A Transfer-Learning-based Strategy for Autonomous Driving: Leveraging Driver Experience for Vision-Based Control",
        "authors": "AmirReza BabaAhmadi, Fatemeh Sadat Masoumi, Moosa Ayati, Mehrimah AmirPour",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aisp61396.2024.10475214"
    },
    {
        "id": 14010,
        "title": "Deep Learning Based Self Driving Cars Using Computer Vision",
        "authors": "S. Bhaggiaraj, M. Priyadharsini, K. Karuppasamy, R Snegha",
        "published": "2023-4-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icnwc57852.2023.10127448"
    },
    {
        "id": 14011,
        "title": "ENHANCING ROAD SAFETY THROUGH COMPUTER VISION-BASED DROWSINESS DETECTION FOR NIGHTTIME DRIVING",
        "authors": "",
        "published": "2023-2-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets33548"
    },
    {
        "id": 14012,
        "title": "Design and research of GPS-free autonomous driving system based on SLAM",
        "authors": "Minyao Fan, Maoyu Zhu, Jianing Bi",
        "published": "2023-6-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2670424"
    },
    {
        "id": 14013,
        "title": "Integrated Driver Pose Estimation for Autonomous Driving",
        "authors": "Xiao Cao, Wei Hu, Hui Liu",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012639400003657"
    },
    {
        "id": 14014,
        "title": "Fuel Prediction Model for Driving Patterns Using Machine Learning Techniques",
        "authors": "Manjunath TK, Ashok Kumar PS",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3844/jcssp.2024.291.302"
    },
    {
        "id": 14015,
        "title": "Learning-based 4D Millimeter Wave Automotive Radar Sensor Model Simulation for Autonomous Driving Scenarios",
        "authors": "Bin Tan, Lianqing Zheng, Zhixiong Ma, Jie Bai, Xichan Zhu, Libo Huang",
        "published": "2023-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cmvit57620.2023.00031"
    },
    {
        "id": 14016,
        "title": "Hidden Biases of End-to-End Driving Models",
        "authors": "Bernhard Jaeger, Kashyap Chitta, Andreas Geiger",
        "published": "2023-10-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00757"
    },
    {
        "id": 14017,
        "title": "Smart and Safe Driving: A Review of Threats and Security Measures for Autonomous Vehicles",
        "authors": "Suzanne Sackstein, Linda Spark, Detan Lipshitz",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icecet58911.2023.10389456"
    },
    {
        "id": 14018,
        "title": "Steering Angle Prediction Algorithm Performance Comparison in Different Simulators for Autonomous Driving",
        "authors": "David Dumančić, David Mijić, Mario Vranješ, Ratko Grbić",
        "published": "2023-9-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/softcom58365.2023.10271635"
    },
    {
        "id": 14019,
        "title": "Autonomous Network Assurance in Intent Based Networking: Vision and Challenges",
        "authors": "Aris Leivadeas, Matthias Falkner",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccn58024.2023.10230112"
    },
    {
        "id": 14020,
        "title": "An Autonomous Driving System for Image based Lane Segmentation",
        "authors": "Sheeba Joice. C, Karthi. A, Korrapati Himakumar, Dhanush Kumar. M",
        "published": "2023-2-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icecct56650.2023.10179831"
    },
    {
        "id": 14021,
        "title": "Leveraging the edge and cloud for V2X-based real-time object detection in autonomous driving",
        "authors": "Faisal Hawlader, François Robinet, Raphaël Frank",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.comcom.2023.11.025"
    },
    {
        "id": 14022,
        "title": "Transfer multi-source knowledge via scale-aware online domain adaptation in depth estimation for autonomous driving",
        "authors": "Phan Thi Huyen Thanh, Minh Quan Viet Bui, Duc Dung Nguyen, Tran Vu Pham, Truong Vinh Truong Duy, Natori Naotake",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.imavis.2023.104871"
    },
    {
        "id": 14023,
        "title": "Perception and Decision Optimization of Autonomous Driving System Driven by Internet of Things and Artificial Intelligence Algorithm",
        "authors": "Zhiwei Jin, Hongqi Xi",
        "published": "2023-11-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14733/cadaps.2024.s13.254-267"
    },
    {
        "id": 14024,
        "title": "Exploring the Effectiveness of Deep Learning Object Detectors for Multi-Class Road Target Detection in Autonomous Driving",
        "authors": "Sibongakonke Kubheka, Ritesh Ajoodha",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icecet58911.2023.10389243"
    },
    {
        "id": 14025,
        "title": "Impact and revolution on law on road traffic safety by autonomous driving technology in China",
        "authors": "Lin Xu, Bingbing He, Hanchu Zhou, Jun He",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.clsr.2023.105906"
    },
    {
        "id": 14026,
        "title": "Context‐aware trajectory prediction for autonomous driving in heterogeneous environments",
        "authors": "Zhenning Li, Zhiwei Chen, Yunjian Li, Chengzhong Xu",
        "published": "2024-1",
        "citations": 2,
        "abstract": "AbstractThe prediction of surrounding agent trajectories in heterogeneous traffic environments remains a challenging task for autonomous driving due to several critical issues, such as understanding social interactions among agents and the environment, handling multiclass traffic movements, and generating feasible trajectories in accordance with real‐world rules, all of which hinder prediction accuracy. To address these issues, a new multimodal trajectory prediction framework based on the transformer network is presented in this study. A hierarchical‐structured context‐aware module, inspired by human perceptual logic, is proposed to capture contextual information within the scene. An efficient linear global attention mechanism is also proposed to reduce the computation and memory load of the transformer framework. Additionally, this study introduces a novel auxiliary loss to penalize infeasible off‐road predictions. Empirical results on the Lyft l5kit data set demonstrate the state‐of‐the‐art performance of the proposed model, which substantially enhances the accuracy and feasibility of prediction outcomes. The proposed model also possesses a unique feature, effectively dealing with missing input observations. This study underscores the importance of comprehending social interactions among agents and the environment, handling multiclass traffic movements, and generating feasible trajectories adhering to real‐world rules in autonomous driving.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1111/mice.12989"
    },
    {
        "id": 14027,
        "title": "Quality Assessment of Image Dataset for Autonomous Driving",
        "authors": "Xingyu Li, Yuang Zhang, Yunda Shi, He Zhu, Jianming Hu, Lihui Peng",
        "published": "2023-10-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ist59124.2023.10355734"
    },
    {
        "id": 14028,
        "title": "Vision-Based Autonomous Driving: A Hierarchical Reinforcement Learning Approach",
        "authors": "Jiao Wang, Haoyi Sun, Can Zhu",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tvt.2023.3266940"
    },
    {
        "id": 14029,
        "title": "Vision-based recognition of slow signal and stop signal for autonomous driving",
        "authors": "Jyoti Madake, Tanmayee Tajne, Prachiti Talgulkar, Shripad Bhatlawande, Swati Shilaskar",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0205752"
    },
    {
        "id": 14030,
        "title": "Active Scene Flow Estimation for Autonomous Driving via Real-Time Scene Prediction and Optimal Decision",
        "authors": "Shuaijun Wang, Rui Gao, Ruihua Han, Jianjun Chen, Zirui Zhao, Zhijun Lyu, Qi Hao",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tits.2023.3332399"
    },
    {
        "id": 14031,
        "title": "A review of the application of CNN-based computer vision in auto-driving",
        "authors": "Tongwei Zhang",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "Beginning with Tesla, self-driving technology has become commercially available in recent decades. Target recognition and semantic segmentation remain significant obstacles for autonomous driving systems. Given that these two tasks are also part of the primary tasks of computer vision and that deep learning techniques based on convolutional neural networks have made advancements in the field of computer vision, a great deal of research has begun to apply convolutional neural networks to autonomous driving in the past few years. In this paper, we examine recent publications on CNN-based techniques for autonomous driving, classify them, and offer insights into future research directions.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/5/20230533"
    },
    {
        "id": 14032,
        "title": "Controlling Character Motions without Observable Driving Source",
        "authors": "Weiyuan Li, Bin Dai, Ziyi Zhou, Qi Yao, Baoyuan Wang",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00608"
    },
    {
        "id": 14033,
        "title": "Autonomous construction safety incentive mechanism using blockchain-enabled tokens and vision-based techniques",
        "authors": "Hossein Naderi, Alireza Shojaei, Reachsak Ly",
        "published": "2023-9",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.autcon.2023.104959"
    },
    {
        "id": 14034,
        "title": "Deep Reinforcement Learning for autonomous ground vehicle driving in mountainous environments with adverse environmental conditions",
        "authors": "Roger Sarango, Carlos Calderon-Cordova",
        "published": "2023-7-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceccme57830.2023.10252473"
    },
    {
        "id": 14035,
        "title": "Exploring Foveation Techniques for Virtual Reality Environments",
        "authors": "Razeen Hussain, Manuela Chessa, Fabio Solari",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012458200003660"
    },
    {
        "id": 14036,
        "title": "Are We Ready for Vision-Centric Driving Streaming Perception? The ASAP Benchmark",
        "authors": "Xiaofeng Wang, Zheng Zhu, Yunpeng Zhang, Guan Huang, Yun Ye, Wenbo Xu, Ziwei Chen, Xingang Wang",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00926"
    },
    {
        "id": 14037,
        "title": "Ultra-Sonic Sensor based Object Detection for Autonomous Vehicles",
        "authors": "Tommaso Nesti, Santhosh Boddana, Burhaneddin Yaman",
        "published": "2023-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00026"
    },
    {
        "id": 14038,
        "title": "Glume pubescence classification of wheat using computer vision techniques",
        "authors": "",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18699/plantgen2023-07"
    },
    {
        "id": 14039,
        "title": "Integrating the Inception V3 model in an end-to-end driving scenario",
        "authors": "Guanhua Ji",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3021314"
    },
    {
        "id": 14040,
        "title": "Driver anomalous driving behavior detection based on supervised contrastive learning",
        "authors": "Zhonglun Li, Jin Duan",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3021283"
    },
    {
        "id": 14041,
        "title": "In-cabin occupant monitoring system based on improved Yolo, deep reinforcement learning, and multi-task CNN for autonomous driving",
        "authors": "Chadia KHRAIEF OULED AZAIZ, Jessica DACLEU NDENGUE",
        "published": "2023-6-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2680503"
    },
    {
        "id": 14042,
        "title": "Benchmarking Perception to Streaming Inputs in Vision-Centric Autonomous Driving",
        "authors": "Tianshi Jin, Weiping Ding, Mingliang Yang, Honglin Zhu, Peisong Dai",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "In recent years, vision-centric perception has played a crucial role in autonomous driving tasks, encompassing functions such as 3D detection, map construction, and motion forecasting. However, the deployment of vision-centric approaches in practical scenarios is hindered by substantial latency, often deviating significantly from the outcomes achieved through offline training. This disparity arises from the fact that conventional benchmarks for autonomous driving perception predominantly conduct offline evaluations, thereby largely overlooking the latency concerns prevalent in real-world deployment. Although a few benchmarks have been proposed to address this limitation by introducing effective evaluation methods for online perception, they do not adequately consider the intricacies introduced by the complexity of input information streams. To address this gap, we propose the Autonomous driving Streaming I/O (ASIO) benchmark, aiming to assess the streaming input characteristics and online performance of vision-centric perception in autonomous driving. To facilitate this evaluation across diverse streaming inputs, we initially establish a dataset based on the CARLA Leaderboard. In alignment with real-world deployment considerations, we further develop evaluation metrics based on information complexity specifically tailored for streaming inputs and streaming performance. Experimental results indicate significant variations in model performance and ranking under different major camera deployments, underscoring the necessity of thoroughly accounting for the influences of model latency and streaming input characteristics during real-world deployment. To enhance streaming performance consistently across distinct streaming input features, we introduce a backbone switcher based on the identified streaming input characteristics. Experimental validation demonstrates its efficacy in perpetually improving streaming performance across varying streaming input features.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math11244976"
    },
    {
        "id": 14043,
        "title": "Implementing Mass Testing Approach with Computer Vision Techniques",
        "authors": "Josue Uwimana",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccd59681.2023.10420543"
    },
    {
        "id": 14044,
        "title": "Using Well-Known Techniques to Visualize Characteristics of Data Quality",
        "authors": "Roy Ruddle",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011664300003417"
    },
    {
        "id": 14045,
        "title": "Optimization of regional cultural modern liquor packaging design based on computer vision algorithm",
        "authors": "Jian Wang, Yanqing Chen",
        "published": "2024-1-19",
        "citations": 0,
        "abstract": "<p>In alcohol packaging, graphics, colors and text are social symbols. This article first uses the relevant principles of visual grammar to conduct a multimodal discourse analysis on the packaging pattern of Fen Liquor blue and white vases from multiple angles. Then, this paper uses human visual characteristics to improve product packaging styling effects. At the same time, a Gaussian filter is used to denoise the noisy wine packaging image, and then the image is used as an input image for grayscale transformation to obtain the guidance image. Research shows that in the multimodal discourse of Fen Liquor blue and white bottles, various forms such as images, text and colors can constitute and convey product information, mapping the history and culture of the product. This stimulates consumers’ visual senses and arouses consumers’ spiritual resonance to achieve the goal of promoting consumption.</p>",
        "keywords": "",
        "link": "http://dx.doi.org/10.32629/jai.v7i3.1452"
    },
    {
        "id": 14046,
        "title": "Autonomous Control of Shore Robotic Charging Systems Based on Computer Vision",
        "authors": "Emin Güney, Cüneyt Bayılmış, Serap Çakar, Erdeniz Erol, Özhan Atmaca",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4355597"
    },
    {
        "id": 14047,
        "title": "Benchmarking Visual Localization for Autonomous Navigation",
        "authors": "Lauri Suomela, Jussi Kalliola, Atakan Dag, Harry Edelman, Joni-Kristian Kamarainen",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00296"
    },
    {
        "id": 14048,
        "title": "Safety Education Method for Older Drivers to Correct Overestimation of Their Own Driving",
        "authors": "Akio Nishimoto, Rinki Hirabayashi, Hiroshi Yoshitake, Kenichi Yamasaki, Genta Kurita, Motoki Shino",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011804900003417"
    },
    {
        "id": 14049,
        "title": "Image Semantic Segmentation for Autonomous Driving Based on Improved U-Net",
        "authors": "Chuanlong Sun, Hong Zhao, Liang Mu, Fuliang Xu, Laiwei Lu",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/cmes.2023.025119"
    },
    {
        "id": 14050,
        "title": "COMPUTER-AIDED DESIGN OF FAULT-TOLERANT HARDWARE ARCHITECTURES FOR AUTONOMOUS DRIVING SYSTEMS",
        "authors": "Tim Maurice Julitz, Antoine Tordeux, Manuel Lower",
        "published": "2023-7",
        "citations": 0,
        "abstract": "AbstractFault-tolerant hardware architectures for autonomous vehicles can be implemented through redundancy, diversity, separation, self-diagnosis, and reconfiguration. These approaches can be coupled with majority redundancy through M-out-of-N independent system architectures. The development of fault- tolerant systems is of central importance in the launch of autonomous driving systems from level 4. The increasing complexity of electrical and electronic systems is challenging for the design of safety-critical systems. This work aims to develop a method to manage this complexity in product development and to use it to compare different types of architectures. The basis is a system consisting of sensors and microcontrollers. The reliability of all possible MooN configurations of the system is calculated automatically by numerically solving the master equation of the corresponding Markov chain. Subsequently, a software-based fault tree analysis enables more detailed modeling of the component structure. The results show that four-line architectures can provide suitable results and that the development effort for 2-ECU systems is higher than for 1-ECU systems with respect to the ISO 26262 target values.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1017/pds.2023.105"
    },
    {
        "id": 14051,
        "title": "Self-Attention blocks in UNet and FCN for accurate semantic segmentation of difficult object classes in autonomous driving",
        "authors": "Seyed-Hamid Mousavi, Kin-Choong Yow",
        "published": "2023-9-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ccece58730.2023.10288711"
    },
    {
        "id": 14052,
        "title": "Research on autonomous obstacle avoidance assistance system for surface unmanned vehicle based on intelligent vision",
        "authors": "Xiangwei Hu",
        "published": "2023-4-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccect57938.2023.10140625"
    },
    {
        "id": 14053,
        "title": "Autonomous Manipulation Learning for Similar Deformable Objects via Only One Demonstration",
        "authors": "Yu Ren, Ronghan Chen, Yang Cong",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01637"
    },
    {
        "id": 14054,
        "title": "DRAMA: Joint Risk Localization and Captioning in Driving",
        "authors": "Srikanth Malla, Chiho Choi, Isht Dwivedi, Joon Hee Choi, Jiachen Li",
        "published": "2023-1",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00110"
    },
    {
        "id": 14055,
        "title": "Preventing Drowsy Driving Accidents in the Construction Industry Using Computer Vision and Convolutional Neural Networks",
        "authors": "Jayson Francois, Mohamed Khalafalla, Doreen Kobelo, John Williams",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1061/9780784485293.044"
    },
    {
        "id": 14056,
        "title": "Balancing Privacy and Accuracy: Exploring the Impact of Data Anonymization on Deep Learning Models in Computer Vision",
        "authors": "Jun Ha Lee, Su Jeong You",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2024.3352146"
    },
    {
        "id": 14057,
        "title": "A Survey on Multimodal Large Language Models for Autonomous Driving",
        "authors": "Can Cui, Yunsheng Ma, Xu Cao, Wenqian Ye, Yang Zhou, Kaizhao Liang, Jintai Chen, Juanwu Lu, Zichong Yang, Kuei-Da Liao, Tianren Gao, Erlong Li, Kun Tang, Zhipeng Cao, Tong Zhou, Ao Liu, Xinrui Yan, Shuqi Mei, Jianguo Cao, Ziran Wang, Chao Zheng",
        "published": "2024-1-1",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacvw60836.2024.00106"
    },
    {
        "id": 14058,
        "title": "Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving",
        "authors": "Ben Agro, Quinlan Sykora, Sergio Casas, Raquel Urtasun",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00139"
    },
    {
        "id": 14059,
        "title": "Propelling autonomous driving forward",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "DELO (Windach, Germany) has developed a flexible electronics adhesive that permanently seals sensor housings airtight and thus reliably protects components such as image sensors. DELO DUALBOND BS3770 meets the stringent requirements of the semiconductor and automotive industries and helps drive innovation in autonomous driving. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.51202/2366-8040-2023-45-022"
    },
    {
        "id": 14060,
        "title": "Regulating Intermediate 3D Features for Vision-Centric Autonomous Driving",
        "authors": "Junkai Xu, Liang Peng, Haoran Cheng, Linxuan Xia, Qi Zhou, Dan Deng, Wei Qian, Wenxiao Wang, Deng Cai",
        "published": "2024-3-24",
        "citations": 0,
        "abstract": "Multi-camera perception tasks have gained significant attention in the field of autonomous driving. However, existing frameworks based on Lift-Splat-Shoot (LSS) in the multi-camera setting cannot produce suitable dense 3D features due to the projection nature and uncontrollable densification process. To resolve this problem, we propose to regulate intermediate dense 3D features with the help of volume rendering. Specifically, we employ volume rendering to process the dense 3D features to obtain corresponding 2D features (e.g., depth maps, semantic maps), which are supervised by associated labels in the training. This manner regulates the generation of dense 3D features on the feature level, providing appropriate dense and unified features for multiple perception tasks. Therefore, our approach is termed Vampire, stands for ``Volume rendering As Multi-camera Perception Intermediate feature REgulator''. Experimental results on the Occ3D and nuScenes datasets demonstrate that Vampire facilitates fine-grained and appropriate extraction of dense 3D features, and is competitive with existing SOTA methods across diverse downstream perception tasks like 3D occupancy prediction, LiDAR segmentation and 3D objection detection, while utilizing moderate GPU resources. We provide a video demonstration in the supplementary materials and Codes are available at github.com/cskkxjk/Vampire.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1609/aaai.v38i6.28449"
    },
    {
        "id": 14061,
        "title": "Computer Vision Techniques for Military Surveillance Drones",
        "authors": "Hijaz Ahmad, Muhammad Farhan, Umar Farooq",
        "published": "2023-6-30",
        "citations": 2,
        "abstract": "Commercial unmanned aerial vehicles (UAVs), also referred to as drones, have proliferated recently, raising concerns about security threats and the need for effective countermeasures. To address these concerns, various technologies have been explored, including radar, acoustics, and RF signal analysis. However, computer vision, particularly deep learning approaches, has emerged as a robust and widely used method for autonomous drone identification. The goal of this research is to create an autonomous drone identification and surveillance system that makes use of a mix of static wide-angle cameras and a lower-angle camera placed on a revolving turret. To optimize memory and processing time, we suggested a novel multi-frame DL identification model. In this approach, the frames captured by the turret's magnified camera are stacked on top of the frames from the wide-angle still camera. Utilizing this technique, we can create an efficient pipeline that conducts initial identification of small-sized aerial invaders on the primary picture plane and identification on the expanded image plane at the same time. This approach significantly reduces the computational burden associated with detection algorithms, making it more resource-efficient. Furthermore, we present the complete system architecture, which includes DL classification frameworks, tracking algorithms, and other essential components. By integrating these elements, we create a comprehensive solution for drone identification and tracking. The system leverages the power of deep learning to accurately classify and track drones in real-time, enabling prompt response and mitigating potential security threats. Overall, this research offers a novel and effective approach to autonomously identify and track drones using computer vision and deep learning techniques. By combining static and dynamic camera perspectives and employing a multi-frame detection method, we provide a resource-efficient solution for drone identification. This work contributes to the ongoing efforts in enhancing security measures against potential drone-related risks",
        "keywords": "",
        "link": "http://dx.doi.org/10.31185/wjcms.148"
    },
    {
        "id": 14062,
        "title": "Enhancement Computer Vision using Deep Learning Optimization Techniques",
        "authors": "Sonam Khattar,  Sheenam",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icacrs58579.2023.10405055"
    },
    {
        "id": 14063,
        "title": "Learning and Aggregating Lane Graphs for Urban Automated Driving",
        "authors": "Martin Büchner, Jannik Zürn, Ion-George Todoran, Abhinav Valada, Wolfram Burgard",
        "published": "2023-6",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01289"
    },
    {
        "id": 14064,
        "title": "Researching Computer Vision Techniques to Detect Safety Violations",
        "authors": "Pavel Medvedev, Vladimir Mokshin",
        "published": "2023-5-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icieam57311.2023.10139080"
    },
    {
        "id": 14065,
        "title": "GRAPHIC INTERFACE DEVELOPMENT FOR TEACHING ROBOTICS RELATED COMPUTER VISION TECHNIQUES",
        "authors": "Alberto Mendez, Alicia Mora, Ramon Barber",
        "published": "2023-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21125/inted.2023.1206"
    },
    {
        "id": 14066,
        "title": "Computer Vision for Healthy Driving Detection Using Convolution Neural Network",
        "authors": "Anigbogu Kenechukwu Sylvanus, Chukwuogo Okwuchukwu Ejike, Belonwu Tochukwu Sunday, Orji Everistus Eze, Nwankpa Joshua Makuo",
        "published": "2023-12-28",
        "citations": 0,
        "abstract": "Driving involves a rigorous act where the driver controls the operation of a motor vehicle. There have been few deployments of healthy driving applications, while some of these applications are machine learning applications some are program-driven applications. Nigeria as a developing country has little or no trained datasets for healthy driving, therefore this research will be charged with collecting local data for driving events to be trained. The datasets were collected as images. These images were extracted for driving events braking, safe driving, and speeding. The images were locally collected for Nigeria driving settings and computer vision techniques were applied to the data. The machine learning algorithm used to evaluate the model is Convolution Neural Network, the editors used for image labelling and coding the system are Jupyter notebook and VS Code. Python programming language and its libraries were also used. The classification results for model loss, accuracy, validate loss and validate accuracy and the performance of the model is 0.99 or 99%, based on this the last epoch was recorded and the loss was 0.03 or 3%.This classification result proved that the data collected from Nigeria is trainable. The trained data can be used by researchers all over the world working on safe and healthy systems in Nigeria for driving. The result also presented a convolution neural network as an algorithm suitable for healthy driving detection using computer vision. The predicted values for the three driving events were all positive. The          three driving events were all detected perfectly while running the parallel testing without being perverse.",
        "keywords": "",
        "link": "http://dx.doi.org/10.9734/ajrcos/2023/v16i4403"
    },
    {
        "id": 14067,
        "title": "Peer-to-Peer Federated Continual Learning for Naturalistic Driving Action Recognition",
        "authors": "Liangqi Yuan, Yunsheng Ma, Lu Su, Ziran Wang",
        "published": "2023-6",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00553"
    },
    {
        "id": 14068,
        "title": "LDFA: Latent Diffusion Face Anonymization for Self-driving Applications",
        "authors": "Marvin Klemp, Kevin Rösch, Royden Wagner, Jannik Quehl, Martin Lauer",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00322"
    },
    {
        "id": 14069,
        "title": "Learning to See in Nighttime Driving Scenes with Inter-frequency Priors",
        "authors": "Zhentao Fan, Xianhao Wu, Xiang Chen, Yufeng Li",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00444"
    },
    {
        "id": 14070,
        "title": "Bird’s Eye View Map for End-to-end Autonomous Driving Using Reinforcement Learning",
        "authors": "Zhiqi Mao, Zhihang Song, Lihui Peng, Jianming Hu, Danya Yao, Yi Zhang",
        "published": "2023-10-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ist59124.2023.10355730"
    },
    {
        "id": 14071,
        "title": "Shared Interest…Sometimes: Understanding the Alignment between Human Perception, Vision Architectures, and Saliency Map Techniques",
        "authors": "Katelyn Morrison, Ankita Mehra, Adam Perer",
        "published": "2023-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00391"
    },
    {
        "id": 14072,
        "title": "3D Object Detection for Autonomous Driving: A Practical Survey",
        "authors": "Álvaro Ramajo-Ballester, Arturo de la Escalera Hueso, José María Armingol Moreno",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011748400003479"
    },
    {
        "id": 14073,
        "title": "Trustworthy Artificial Intelligence Requirements in the Autonomous Driving Domain",
        "authors": "David Fernandez-Llorca, Emilia Gomez",
        "published": "2023-2",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mc.2022.3212091"
    },
    {
        "id": 14074,
        "title": "Design of an Efficient Mathematical Optimization Engine for Solving Autonomous Driving Performance for Urban Traffic Conditions",
        "authors": "Varsha Sadrani, G.V.V. Jagannadha Rao",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/upcon59197.2023.10434378"
    },
    {
        "id": 14075,
        "title": "Motorcycle Blind Spot Detection Through Computer Vision Techniques",
        "authors": "Darren Aquilina, Thomas Gatt",
        "published": "2023-9-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ispa58351.2023.10279254"
    },
    {
        "id": 14076,
        "title": "Intersection analysis using computer vision techniques with SUMO",
        "authors": "Mohammad Shokrolah Shirazi, Brendan Tran Morris, Shiqi Zhang",
        "published": "2023-5-1",
        "citations": 1,
        "abstract": "Abstract\nThis paper presents intersection analysis using computer vision techniques with Simulation of Urban MObility (SUMO). First, an efficient deep-visual tracking pipeline is proposed by using the off-the-shelf YOLO object detection architecture and cascading it with a discriminative correlation filter to produce reliable trajectories for traffic analysis of vehicles and pedestrians. While a variety of traffic measurements can be directly estimated from the extracted trajectories (e.g., speed, turning movement count), a method of incorporating turning movement count (TMC) within SUMO is proposed in order to mimic a realistic traffic flow for an observed intersection and its comprehensive analysis. Experimental evaluations on the developed tracking system implies that the YOLOv5 variant is the best for traffic cameras and, after appropriate fine-tuning using the University of Nevada, Las Vegas pedestrian data set, the YOLOv5 performance manifested a significant improvement with a recall value of 0.62. The tracking system is further employed for monitoring three other intersections in the downtown area of Las Vegas and turning movement counts were estimated for peak hours in the morning and evening of one day (7:00–9:00 and 16:00–18:00) at 15-min intervals. Finally, the intersection design, including traffic signals with estimated TMC, is used to calibrate SUMO to provide critical parameters (e.g., lane density, travel time, occupancy) for traffic signal performance evaluation and comprehensive intersection analysis. The signal design treatment demonstrates a significant improvement in travel times and simulation results indicate that the turning-left ratio is a crucial factor affecting the travel time of vehicles on each intersection leg.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1093/iti/liad003"
    },
    {
        "id": 14077,
        "title": "Severity of Catastrophic Forgetting in Object Detection for Autonomous Driving",
        "authors": "Christian Witte, René Schuster, Syed Bukhari, Patrick Trampert, Didier Stricker, Georg Schneider",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011634500003411"
    },
    {
        "id": 14078,
        "title": "Personal Protective Equipment Detection Using Computer Vision Techniques",
        "authors": "Rawabi Sultan Aldossary, Manar Nasser Almutairi, Serkan Dursun",
        "published": "2023-3-13",
        "citations": 0,
        "abstract": "AbstractThe intensive use of chemicals, machines and electrical assets introduced unsafe conditions to the workplace. An unsafe condition is a physical condition that can cause an incident, such as operating without training, defective supplies and poor housekeeping. Such conditions might cause serious injury or even death. As well as the human impact, unsafe conditions have a significant impact on operational excellence and the financial state of a company. Companies are committed to ensure a safe environment by setting safety polices, conducting safety training, fire prevention systems, safety manuals and signboards and providing safety gears. Personal protective equipment (PPE) is safety equipment that can maintain the safety of employees in hazardous conditions, such as hot surfaces and toxic chemicals that can cause serious injuries and illness. PPE is sometimes referred to as the last line of defense. Some workers might not comply with safety policies or refuse to wear the PPE. To overcome the manual safety checks and compliance of employees, in this paper we propose an AI-powered computer vision automation solution leveraging the state of the object detection model. Computer vision is the field that mimics human vision to extract purposeful information from videos and images. Computer vision brings about various functionalities to perform tasks such as object detection, object classification, object identification and object verification. The proposed solution is developed by using a computer vision technique that detects various types of PPEs in real time. The main purpose of this project is to detect a presence of eight classes (person, helmet color: Red, Yellow, Blue and White, head, vest, glasses). The best results are achieved by applying YOLOv5 on a set of construction site images with corresponding annotations in YOLO format. The proposed solution automates the process of detection and monitoring PPE and employee behavior in operation fields in real-time. Automating the detection can reflect the business value by reducing the timeframe for tracking, creating a safe environment that in turn can increase the productivity and safety of the workers and reduce the costs of operations. The proposed solution includes all the components of data ingestion, data processing, object detection model and deployment on the edge device or server to improve safety.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2118/214093-ms"
    },
    {
        "id": 14079,
        "title": "Deep Learning-based Facial Expression Recognition for Fatigue Driving",
        "authors": "Yiheng Luo, Hui Yang, Hongbin Fan, Muzi Li",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3627341.3627344"
    },
    {
        "id": 14080,
        "title": "In-vehicle fatigue driving warning device based on facial recognition fatigue detection system",
        "authors": "Yunheng Zhang, Shibo Zhu",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3021269"
    },
    {
        "id": 14081,
        "title": "Improvements to Image Reconstruction-Based Performance Prediction for Semantic Segmentation in Highly Automated Driving",
        "authors": "Andreas Bär, Daniel Kusuma, Tim Fingscheidt",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00027"
    },
    {
        "id": 14082,
        "title": "Efficient Computer Vision Inference using Modular Neural Network Techniques",
        "authors": "Ade Clinton Sitepu, Chuan-Ming Liu",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/apwcs60142.2023.10234066"
    },
    {
        "id": 14083,
        "title": "Vision-based texture and color analysis of waterbody images using computer vision and deep learning techniques",
        "authors": "Seyed Mohammad Hassan Erfani, Erfan Goharian",
        "published": "2023-5-1",
        "citations": 3,
        "abstract": "AbstractVision-based analysis of waterbodies can provide important information required for monitoring, analyzing, and managing water resource systems, such as visual flood detection, delineation, and mapping. Water, however, is an ornery object in image processing, as it can be found in different forms and colors in nature. This makes the detection, classification, and tracking of water in images and videos difficult for computer vision models. There are still visual differences resulting from water texture and its inherent optical properties associated with different waterbodies which can be recognized and extracted to support computer models to better analyze water images. This study aims to utilize a set of early, mid-level, and high-level vision techniques, including Gabor kernels, local binary patterns (LBPs), and deep learning (DL) models to extract and analyze water texture and color of different waterbodies in digital images. For this purpose, ATLANTIS TeXture (ATeX), an image dataset for waterbodies classification and texture analysis, was used. Models were trained for the task of classification on ATeX. Then, the performance of each model in extracting texture features was evaluated and compared. Results showed that the classification accuracy achieved by the Gabor magnitude tensor, LBP, and DL model (ShuffleNet V2 × 1.0) are 29, 35, and 92%, respectively, and thus the DL model outperforms traditional vision-based techniques. Moreover, the classification results on raw images represented by different color spaces (e.g., RGB, HSV, etc.) emphasized the importance of color information for digital image processing of water. Analyzing representative visual features and properties of different water types and waterbodies can facilitate designing a customized Convolutional Neural Networks (CNNs) for water scenes, as CNNs recognize objects through the analysis of both texture and shape clues and their relationship in the entire field of view.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2166/hydro.2023.146"
    },
    {
        "id": 14084,
        "title": "Autonomous 3D vision‐based bolt loosening assessment using micro aerial vehicles",
        "authors": "Xiao Pan, Sina Tavasoli, T. Y. Yang",
        "published": "2023-11",
        "citations": 4,
        "abstract": "AbstractEarlier identification of bolt loosening is crucial to maintain structural integrity and prevent system‐level collapse. In this study, a novel drone‐based 3D vision methodology has been proposed for autonomous bolt loosening assessment. First, a low‐cost micro aerial vehicle with various types of sensors is designed. Second, a drone‐based autonomous image collection method is proposed. Third, a 3D point cloud of the bolted connection is generated using the acquired images. Fourth, 3D point cloud processing methods are proposed to localize and quantify bolt loosening. The proposed method has been implemented on structural beam–column connections. The results show that the proposed drone‐based data collection method can effectively acquire images for 3D reconstruction. The 3D point cloud processing methods can reliably localize and quantify bolt loosening at high accuracy. The proposed method provides a more robust and comprehensive evaluation of bolt loosening, compared to existing 2D vision methods, which process 2D images captured at a specific camera view.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1111/mice.13023"
    },
    {
        "id": 14085,
        "title": "DEVELOPING A COMPUTER VISION BASED SYSTEM FOR AUTONOMOUS TAXIING OF AIRCRAFT",
        "authors": "Prashant Gaikwad, Abhishek Mukhopadhyay, Anujith Muraleedharan, Mukund Mitra, Pradipta Biswas",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "Authors of this paper propose a computer vision based autonomous system for the taxiing of an aircraft in the real world. The system integrates both lane detection and collision detection and avoidance models. The lane detection component employs a segmentation model consisting of two parallel architectures. An airport dataset is proposed, and the collision detection model is evaluated with it to avoid collision with any ground vehicle. The lane detection model identifies the aircraft’s path and transmits control signals to the steer-control algorithm. The steer-control algorithm, in turn, utilizes a controller to guide the aircraft along the central line with 0.013 cm resolution. To determine the most effective controller, a comparative analysis is conducted, ultimately highlighting the Linear Quadratic Regulator (LQR) as the superior choice, boasting an average deviation of 0.26 cm from the central line. In parallel, the collision detection model is also compared with other state-of-the-art models on the same dataset and proved its superiority. A detailed study is conducted in different lighting conditions to prove the efficacy of the proposed system. It is observed that lane detection and collision avoidance modules achieve true positive rates of 92.59% and 85.19%, respectively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3846/aviation.2023.20588"
    },
    {
        "id": 14086,
        "title": "A comprehensive study on lane detecting autonomous car using computer vision",
        "authors": "Henil Gajjar, Stavan Sanyal, Manan Shah",
        "published": "2023-12",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.120929"
    },
    {
        "id": 14087,
        "title": "ARIF: Autonomous Recognition in the Field Enhancing National Security with Computer Vision-Based Facial Recognition",
        "authors": "Abubakr Osman",
        "published": "2024-1-16",
        "citations": 0,
        "abstract": "Through a novel research approach that employs a mix of Convolutional Neural architectures & Siamese Neural Nets, we propose a viable mechanism that focuses on leveraging these groundbreaking advancements, through the utilization of deep learning algorithms we were able to effectively & accurately identify and authenticate individuals based on unique facial features derived from machine learnt embeddings. In The ARIF Project we implement the proposed architecture models through utilization of developer friendly modules like the python facial recognition library, the OpenCV framework & Jupiter Notebooks, performing the necessary product development, market research and product analysis throughout the development process, finally deliver a refined & minimalistic solution that not only fills market gaps but also serves as a solid foundation for rapid adoption & deployment.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54878/z68s0z54"
    },
    {
        "id": 14088,
        "title": "Autonomous mobile robot for automatic out of stock detection in a supermarket",
        "authors": "Giuseppe De Simone, Pasquale Foggia, Alessia Saggese, Mario Vento",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00197"
    },
    {
        "id": 14089,
        "title": "Integrated Perception and Planning for Autonomous Vehicle Navigation: An Optimization-based Approach",
        "authors": "Shubham Kedia, Yu Zhou, Sambhu H. Karumanchi",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00323"
    },
    {
        "id": 14090,
        "title": "RobustStateNet: Robust ego vehicle state estimation for Autonomous Driving",
        "authors": "Pragyan Dahal, Simone Mentasti, Luca Paparusso, Stefano Arrigoni, Francesco Braghin",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.robot.2023.104585"
    },
    {
        "id": 14091,
        "title": "A rational decision-making approach based on Bayesian network and BDI model for autonomous driving system",
        "authors": "Xinyuan Zhang, Dehui Du",
        "published": "2023-6-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2683203"
    },
    {
        "id": 14092,
        "title": "Path planning algorithms in the autonomous driving system: A comprehensive review",
        "authors": "Mohamed Reda, Ahmed Onsy, Amira Y. Haikal, Ali Ghanbari",
        "published": "2024-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.robot.2024.104630"
    },
    {
        "id": 14093,
        "title": "Pixel-level Contrastive Learning of Driving Videos with Optical Flow",
        "authors": "Tomoya Takahashi, Shingo Yashima, Kohta Ishikawa, Ikuro Sato, Rio Yokota",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00320"
    },
    {
        "id": 14094,
        "title": "BEV-Guided Multi-Modality Fusion for Driving Perception",
        "authors": "Yunze Man, Liang-Yan Gui, Yu-Xiong Wang",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.02103"
    },
    {
        "id": 14095,
        "title": "Improving CCTV footage in Computer Vision Using Deep Learning Techniques",
        "authors": "C Rakshitha, C Selvan",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciics59993.2023.10421193"
    },
    {
        "id": 14096,
        "title": "DeepScenario: An Open Driving Scenario Dataset for Autonomous Driving System Testing",
        "authors": "Chengjie Lu, Tao Yue, Shaukat Ali",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/msr59073.2023.00020"
    },
    {
        "id": 14097,
        "title": "Autonomous Driving Ethics: Self-driving Cars Facing Trolley Problems",
        "authors": "Yicheng Xiang",
        "published": "2023-10-26",
        "citations": 0,
        "abstract": "The trolley problem has always been one of the most famous ethical dilemmas in human history, arousing millions of arguments and discussions. When self-driving cars, as products of our new age, encounter the trolley problem, the decisions made will be different from those of human beings due to the particularity of the cars and the autopilot algorithm. This paper will first determine the definition and scope of the trolley problem, and then compare the difference between autonomous cars and traditional ones. It then proposes possible guidance for the autopilot algorithms from legal and ethical perspectives. Despite a long history, ethical methods for autonomous cars are still uncertain and hard to be accepted by everyone. Perhaps the combination of different ethical approaches could greatly ameliorate this problem. The feature of hysteresis of law makes it impossible to provide guidance for autonomous cars in time, but laws can help build abstract principles for autopilot algorithms from the perspective of reducing legal liability.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2753-7048/15/20231039"
    },
    {
        "id": 14098,
        "title": "Potential Game-Based Decision Making in Autonomous Driving (Abstract)",
        "authors": "Mushuang Liu",
        "published": "2023-5-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/acc55779.2023.10155883"
    },
    {
        "id": 14099,
        "title": "Real-time Traffic Surveillance and Detection using Deep Learning and Computer Vision Techniques",
        "authors": "Riju Tiwari, Abdul Hadi Rumaney, M. Saravanan",
        "published": "2023-5-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/vitecon58111.2023.10157694"
    },
    {
        "id": 14100,
        "title": "IDD-3D: Indian Driving Dataset for 3D Unstructured Road Scenes",
        "authors": "Shubham Dokania, A. H. Abdul Hafez, Anbumani Subramanian, Manmohan Chandraker, C.V. Jawahar",
        "published": "2023-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00446"
    },
    {
        "id": 14101,
        "title": "Using Computer Vision Techniques to Automatically Detect Abnormalities in Chest X-rays",
        "authors": "Zaid Mustafa, Heba Nsour",
        "published": "2023-9-18",
        "citations": 1,
        "abstract": "Our research focused on creating an advanced machine-learning algorithm that accurately detects anomalies in chest X-ray images to provide healthcare professionals with a reliable tool for diagnosing various lung conditions. To achieve this, we analysed a vast collection of X-ray images and utilised sophisticated visual analysis techniques; such as deep learning (DL) algorithms, object recognition, and categorisation models. To create our model, we used a large training dataset of chest X-rays, which provided valuable information for visualising and categorising abnormalities. We also utilised various data augmentation methods; such as scaling, rotation, and imitation; to increase the diversity of images used for training. We adopted the widely used You Only Look Once (YOLO) v8 algorithm, an object recognition paradigm that has demonstrated positive outcomes in computer vision applications, and modified it to classify X-ray images into distinct categories; such as respiratory infections, tuberculosis (TB), and lung nodules. It was particularly effective in identifying unique and crucial outcomes that may, otherwise, be difficult to detect using traditional diagnostic methods. Our findings demonstrate that healthcare practitioners can reliably use machine learning (ML) algorithms to diagnose various lung disorders with greater accuracy and efficiency.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/diagnostics13182979"
    },
    {
        "id": 14102,
        "title": "A Safer Vision-Based Autonomous Planning System for Quadrotor UAVs with Dynamic Obstacle Trajectory Prediction and Its Application with LLMs",
        "authors": "Jiageng Zhong, Ming Li, Yinliang Chen, Zihang Wei, Fan Yang, Haoran Shen",
        "published": "2024-1-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacvw60836.2024.00131"
    },
    {
        "id": 14103,
        "title": "Swarm Learning In Autonomous Driving: A Privacy Preserving Approach",
        "authors": "Abhishek Mishra, O. P. Joy Jefferson, Pradish Kapur, Kiran Kannur, Pooja Agarwal, Arti Arya",
        "published": "2023-6-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3608251.3608271"
    },
    {
        "id": 14104,
        "title": "Perception Enhanced Deep Deterministic Policy Gradient for Autonomous Driving in Complex Scenarios",
        "authors": "Lyuchao Liao, Hankun Xiao, Pengqi Xing, Zhenhua Gan, Youpeng He, Jiajun Wang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/cmes.2024.047452"
    }
]