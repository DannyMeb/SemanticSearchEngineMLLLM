[
    {
        "id": 23105,
        "title": "Multi frame multi-head attention learning on deep features for recognizing Indian classical dance poses",
        "authors": "Anil Kumar D., Kishore P.V.V., Chaithanya T.R., Sravani K.",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2024.104091"
    },
    {
        "id": 23106,
        "title": "Spatio-temporal representation learning enhanced speech emotion recognition with multi-head attention mechanisms",
        "authors": "Zengzhao Chen, Mengting Lin, Zhifeng Wang, Qiuyu Zheng, Chuan Liu",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2023.111077"
    },
    {
        "id": 23107,
        "title": "Dysarthria severity classification using multi-head attention and multi-task learning",
        "authors": "Amlu Anna Joshy, Rajeev Rajan",
        "published": "2023-2",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.specom.2022.12.004"
    },
    {
        "id": 23108,
        "title": "Combining Multi-Head Attention and Sparse Multi-Head Attention Networks for Session-Based Recommendation",
        "authors": "Zhiwei Zhao, Xiaoye Wang, Yingyuan Xiao",
        "published": "2023-6-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191924"
    },
    {
        "id": 23109,
        "title": "Residual Learning with Bi-LSTM and Multi-Head Attention for Multi-Modal Emotion Recognition",
        "authors": "Yifei Gao, Chi Xu",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icipca59209.2023.10257779"
    },
    {
        "id": 23110,
        "title": "Exploiting Multi-Head Attention Maps Into A Deep Riemannian Representation to Quantify Pulmonary Nodules",
        "authors": "Alejandra Moreno, Juan Olmos, Luis Guayacán, Fabio Martínez",
        "published": "2023-4-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isbi53787.2023.10230828"
    },
    {
        "id": 23111,
        "title": "Multi-agent Reinforcement Learning with Multi-head Attention",
        "authors": "Ke Ni, Jing Chen, Jian Wang, Bo Liu, Ting Lei",
        "published": "2023-2-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/itnec56291.2023.10082248"
    },
    {
        "id": 23112,
        "title": "Deep Reinforcement Learning Based Group Recommendation System with Multi-Head Attention Mechanism",
        "authors": "Saba Izadkhah, Banafsheh Reakbdar",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/transai60598.2023.00038"
    },
    {
        "id": 23113,
        "title": "Multi-Layer Attention-based State Representation for the Reinforcement Learning of Visual Servoing",
        "authors": "Hiromu Kitajima, Souksakhone Bounyong, Mototaka Yoshioka",
        "published": "2023-1-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icce56470.2023.10043381"
    },
    {
        "id": 23114,
        "title": "Enhanced Multi-Modal Knowledge Graphs Representation Learning via Self-Attention Fusion",
        "authors": "Tian Jiahong, Zhang Yongchuan, He Yong",
        "published": "2023-12-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/csecs60003.2023.10428415"
    },
    {
        "id": 23115,
        "title": "Emotion Recognition based on Physiological Signals Multi-head Attention Contrastive Learning",
        "authors": "Yunfei Guo, Tao Zhang, Wu Huang",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bibm58861.2023.10385711"
    },
    {
        "id": 23116,
        "title": "MADPL-net: Multi-layer attention dictionary pair learning network for image classification",
        "authors": "Yulin Sun, Guangming Shi, Weisheng Dong, Xuemei Xie",
        "published": "2023-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2022.103728"
    },
    {
        "id": 23117,
        "title": "Multi-Attn BLS: Multi-head attention mechanism with broad learning system for chaotic time series prediction",
        "authors": "Liyun Su, Lang Xiong, Jialing Yang",
        "published": "2023-1",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.asoc.2022.109831"
    },
    {
        "id": 23118,
        "title": "Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention",
        "authors": "Huiyin Xue, Nikolaos Aletras",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.695"
    },
    {
        "id": 23119,
        "title": "Self-Supervised Temporal Graph Learning based on Multi-Head Self-Attention Weighted Neighborhood Sequences",
        "authors": "Yulong Cao",
        "published": "2023-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bdai59165.2023.10256426"
    },
    {
        "id": 23120,
        "title": "Interpreting and Exploiting Functional Specialization in Multi-Head Attention under Multi-task Learning",
        "authors": "Chong Li, Shaonan Wang, Yunhao Zhang, Jiajun Zhang, Chengqing Zong",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.1026"
    },
    {
        "id": 23121,
        "title": "Multi-View Stereo Reconstruction Based on Self-Attention and Pyramid Feature Representation",
        "authors": "Shuxu Jing, Yixin Zhang, Zhanwen Liu, Qingling Yue",
        "published": "2023-8-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/prml59573.2023.10348350"
    },
    {
        "id": 23122,
        "title": "Dynamically Choosing the Number of Heads in Multi-Head Attention",
        "authors": "Fernando Duarte, Nuno Lau, Artur Pereira, Luís Reis",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012384500003636"
    },
    {
        "id": 23123,
        "title": "Source Acquisition Device Identification from Recorded Audio Based on Spatiotemporal Representation Learning with Multi-Attention Mechanisms",
        "authors": "Chunyan Zeng, Shixiong Feng, Dongliang Zhu, Zhifeng Wang",
        "published": "2023-4-6",
        "citations": 3,
        "abstract": "Source acquisition device identification from recorded audio aims to identify the source recording device by analyzing the intrinsic characteristics of audio, which is a challenging problem in audio forensics. In this paper, we propose a spatiotemporal representation learning framework with multi-attention mechanisms to tackle this problem. In the deep feature extraction stage of recording devices, a two-branch network based on residual dense temporal convolution networks (RD-TCNs) and convolutional neural networks (CNNs) is constructed. The spatial probability distribution features of audio signals are employed as inputs to the branch of the CNN for spatial representation learning, and the temporal spectral features of audio signals are fed into the branch of the RD-TCN network for temporal representation learning. This achieves simultaneous learning of long-term and short-term features to obtain an accurate representation of device-related information. In the spatiotemporal feature fusion stage, three attention mechanisms—temporal, spatial, and branch attention mechanisms—are designed to capture spatiotemporal weights and achieve effective deep feature fusion. The proposed framework achieves state-of-the-art performance on the benchmark CCNU_Mobile dataset, reaching an accuracy of 97.6% for the identification of 45 recording devices, with a significant reduction in training time compared to other models.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/e25040626"
    },
    {
        "id": 23124,
        "title": "A CNN and Multi-Head Attention-Based Deep Learning Network for Trajectory Prediction of Autonomous Vehicles on Multi-Lane Highways",
        "authors": "Omveer Sharma, Suryalok Dash, Manas Ranjan Sial",
        "published": "2023-10-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/gcat59970.2023.10353322"
    },
    {
        "id": 23125,
        "title": "A novel unsupervised deep learning approach for vibration-based damage diagnosis using a multi-head self-attention LSTM autoencoder",
        "authors": "Shayan Ghazimoghadam, S.A.A. Hosseinzadeh",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.measurement.2024.114410"
    },
    {
        "id": 23126,
        "title": "Meta-learning few-shot image generation algorithm combining multi-head self-attention and convolution",
        "authors": "Ze Zhang",
        "published": "2023-5-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2681078"
    },
    {
        "id": 23127,
        "title": "ConF: A Deep Learning Model Based on BiLSTM, CNN, and Cross Multi-Head Attention Mechanism for Noncoding RNA Family Prediction",
        "authors": "Shoryu Teragawa, Lei Wang",
        "published": "2023-11-13",
        "citations": 0,
        "abstract": "This paper presents ConF, a novel deep learning model designed for accurate and efficient prediction of noncoding RNA families. NcRNAs are essential functional RNA molecules involved in various cellular processes, including replication, transcription, and gene expression. Identifying ncRNA families is crucial for comprehensive RNA research, as ncRNAs within the same family often exhibit similar functionalities. Traditional experimental methods for identifying ncRNA families are time-consuming and labor-intensive. Computational approaches relying on annotated secondary structure data face limitations in handling complex structures like pseudoknots and have restricted applicability, resulting in suboptimal prediction performance. To overcome these challenges, ConF integrates mainstream techniques such as residual networks with dilated convolutions and cross multi-head attention mechanisms. By employing a combination of dual-layer convolutional networks and BiLSTM, ConF effectively captures intricate features embedded within RNA sequences. This feature extraction process leads to significantly improved prediction accuracy compared to existing methods. Experimental evaluations conducted using a single, publicly available dataset and applying ten-fold cross-validation demonstrate the superiority of ConF in terms of accuracy, sensitivity, and other performance metrics. Overall, ConF represents a promising solution for accurate and efficient ncRNA family prediction, addressing the limitations of traditional experimental and computational methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/biom13111643"
    },
    {
        "id": 23128,
        "title": "MS-YOLOv5: Improved YOLOv5 Based on Multi-Head Self-Attention for Citrus Leaf Disease Severity Estimation",
        "authors": "Hongchun Qu, Qianyi Bian",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3635638.3635651"
    },
    {
        "id": 23129,
        "title": "Structural Health Monitoring of Aircraft Engines Using Self Attention Multi-Head Machine Learning Technique",
        "authors": "Shyamaprasad V, Akshaj R, Hari Narayanan. A. G",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10306859"
    },
    {
        "id": 23130,
        "title": "A Deep Learning Model Based on Multi-Head Attention for Long-Term Forecasting of Solar Activity",
        "authors": "Adriana Marcucci, Giovanna Jerse, Valentina Alberti, Mauro Messerotti",
        "published": "2023-6-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/engproc2023039016"
    },
    {
        "id": 23131,
        "title": "Deep learning based MobileNet and multi-head attention model for facial expression recognition",
        "authors": "Aicha Nouisser, Ramzi Zouari, Monji Kherallah",
        "published": "2023",
        "citations": 0,
        "abstract": "Facial expressions is an intuitive reflection of a person’s emotional state, and it is one of the most important forms of interpersonal communication. Due to the complexity and variability of human facial expressions, traditional methods based on handcrafted feature extraction have shown insufficient performances. For this purpose, we proposed a new system of facial expression recognition based on MobileNet model with the addition of skip connections to prevent the degradation in performance in deeper architectures. Moreover, multi-head attention mechanism was applied to concentrate the processing on the most relevant parts of the image. The experiments were conducted on FER2013 database, which is imbalanced and includes ambiguities in some images containing synthetic faces. We applied a pre-processing step of face detection to eliminate wrong images, and we implemented both SMOTE and Near-Miss algorithms to get a balanced dataset and prevent the model to being biased. The experimental results showed the effectiveness of the proposed framework which achieved the recognition rate of 96.02% when applying multi-head attention mechanism",
        "keywords": "",
        "link": "http://dx.doi.org/10.34028/iajit/20/3a/6"
    },
    {
        "id": 23132,
        "title": "Relational Learning with Attribute-Based Multi-Head Attention Regulator for Few-Shot Knowledge Graph Completion",
        "authors": "Yifeng Gu, Devin Jia, Ying Lei, Bo Li",
        "published": "2023-9-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/docs60977.2023.10294941"
    },
    {
        "id": 23133,
        "title": "Target-Oriented Multimodal Sentiment Classification Based on Multi-Head Attention and Graph Neural Network",
        "authors": "Wen-Tao Chen, Fei-Peng Dai, Zheng-Xin Song, Yu-Yan Huang",
        "published": "2023-7-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmlc58545.2023.10327981"
    },
    {
        "id": 23134,
        "title": "Network traffic classification based on multi-head attention and deep metric learning",
        "authors": "Zhuo Lv, Bin Lu, Xue Li, Zan Qi",
        "published": "2023-6-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2682521"
    },
    {
        "id": 23135,
        "title": "Prediction of Household Energy Usage via Multi-Head Attention",
        "authors": "Aidan G. Kurz, Colleen P. Bailey",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/metrocon59008.2023.10339948"
    },
    {
        "id": 23136,
        "title": "Multi-Head Attention-Based Transfer Learning Approach for Potato Disease Detection",
        "authors": "Ritesh Maurya, Radim Burget, Rudra Shaurya, Martin Kiac, Malay Kishore Dutta",
        "published": "2023-10-30",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icumt61075.2023.10333272"
    },
    {
        "id": 23137,
        "title": "Deep Reinforcement Learning with Multi Head Attention Mechanism for Resource Allocation in Platoon based C-V2X Networks",
        "authors": "Irshad Khan, S H Manjula, Venugopal K R",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdds59137.2023.10434359"
    },
    {
        "id": 23138,
        "title": "Long-Term Traffic Flow Prediction Based on DiGCN-based Multi-head Spatiotemporal Attention Convolutional Network",
        "authors": "Kai Yang, Lihui Lei, Chang Lu",
        "published": "2023-2-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3587716.3587809"
    },
    {
        "id": 23139,
        "title": "Object-based video anomaly detection using multi-attention and adaptive velocity attribute representation learning",
        "authors": "Xiaopeng Ren, Huifen Xia, Yongzhao Zhan",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00530-023-01257-w"
    },
    {
        "id": 23140,
        "title": "Multi-Modal Transformer with Multi-Head Attention for Emotion Recognition",
        "authors": "Chi Xu, Yifei Gao",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsece58870.2023.10263303"
    },
    {
        "id": 23141,
        "title": "Multi-Modal Representation via Contrastive Learning with Attention Bottleneck Fusion and Attentive Statistics Features",
        "authors": "Qinglang Guo, Yong Liao, Zhe Li, Shenglin Liang",
        "published": "2023-10-7",
        "citations": 1,
        "abstract": "The integration of information from multiple modalities is a highly active area of research. Previous techniques have predominantly focused on fusing shallow features or high-level representations generated by deep unimodal networks, which only capture a subset of the hierarchical relationships across modalities. However, previous methods are often limited to exploiting the fine-grained statistical features inherent in multimodal data. This paper proposes an approach that densely integrates representations by computing image features’ means and standard deviations. The global statistics of features afford a holistic perspective, capturing the overarching distribution and trends inherent in the data, thereby facilitating enhanced comprehension and characterization of multimodal data. We also leverage a Transformer-based fusion encoder to effectively capture global variations in multimodal features. To further enhance the learning process, we incorporate a contrastive loss function that encourages the discovery of shared information across different modalities. To validate the effectiveness of our approach, we conduct experiments on three widely used multimodal sentiment analysis datasets. The results demonstrate the efficacy of our proposed method, achieving significant performance improvements compared to existing approaches.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/e25101421"
    },
    {
        "id": 23142,
        "title": "Mao-Zedong at SemEval-2023 Task 4: Label Represention Multi-Head Attention Model with Contrastive Learning-Enhanced Nearest Neighbor Mechanism for Multi-Label Text Classification",
        "authors": "Che Zhang, Ping’an Liu, Zhenyang Xiao, Haojun Fei",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.semeval-1.58"
    },
    {
        "id": 23143,
        "title": "Transformer-BLS: An efficient learning algorithm based on multi-head attention mechanism and incremental learning algorithms",
        "authors": "Rongrong Fu, Haifeng Liang, Shiwei Wang, Chengcheng Jia, Guangbin Sun, Tengfei Gao, Dan Chen, Yaodong Wang",
        "published": "2024-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.121734"
    },
    {
        "id": 23144,
        "title": "Fiber communication receiver models based on the multi-head attention mechanism",
        "authors": "Yubin Zang, Zhenming Yu, Kun Xu, Minghua Chen, Sigang Yang, Hongwei Chen",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3788/col202321.030602"
    },
    {
        "id": 23145,
        "title": "Hierarchical Multi-Instance Multi-Label Learning for Detecting Propaganda Techniques",
        "authors": "Anni Chen, Bhuwan Dhingra",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.repl4nlp-1.13"
    },
    {
        "id": 23146,
        "title": "Multi-Head Attention Machine Learning for Fault Classification in Mixed Autonomous and Human-Driven Vehicle Platoons",
        "authors": "Theodore Wu, Satvick Acharya, Abdelrahman Khalil, Ahmad F. Aljanaideh, Mohammad Al Janaideh, Deepa Kundur",
        "published": "2023-5-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icra48891.2023.10160426"
    },
    {
        "id": 23147,
        "title": "A Multi-Head Self-Attention-based on GRU Encoder-Decoder Framework for Predicting Molten Iron Silicon Content",
        "authors": "Yu Cai, Chunjie Yang, Siwei Lou, Zhenyu Zeng, Huanyu Liao, Bing Zhang",
        "published": "2023-5-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ddcls58216.2023.10167277"
    },
    {
        "id": 23148,
        "title": "DeepCAC: a deep learning approach on DNA transcription factors classification based on multi-head self-attention and concatenate convolutional neural network",
        "authors": "Jidong Zhang, Bo Liu, Jiahui Wu, Zhihan Wang, Jianqiang Li",
        "published": "2023-9-18",
        "citations": 3,
        "abstract": "AbstractUnderstanding gene expression processes necessitates the accurate classification and identification of transcription factors, which is supported by high-throughput sequencing technologies. However, these techniques suffer from inherent limitations such as time consumption and high costs. To address these challenges, the field of bioinformatics has increasingly turned to deep learning technologies for analyzing gene sequences. Nevertheless, the pursuit of improved experimental results has led to the inclusion of numerous complex analysis function modules, resulting in models with a growing number of parameters. To overcome these limitations, it is proposed a novel approach for analyzing DNA transcription factor sequences, which is named as DeepCAC. This method leverages deep convolutional neural networks with a multi-head self-attention mechanism. By employing convolutional neural networks, it can effectively capture local hidden features in the sequences. Simultaneously, the multi-head self-attention mechanism enhances the identification of hidden features with long-distant dependencies. This approach reduces the overall number of parameters in the model while harnessing the computational power of sequence data from multi-head self-attention. Through training with labeled data, experiments demonstrate that this approach significantly improves performance while requiring fewer parameters compared to existing methods. Additionally, the effectiveness of our approach  is validated in accurately predicting DNA transcription factor sequences.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s12859-023-05469-9"
    },
    {
        "id": 23149,
        "title": "Beyond Variational Models and Self-Similarity in Super-Resolution: Unfolding Models and Multi-Head Attention",
        "authors": "Ivan Pereira-Sánchez, Eloi Sans, Julia Navarro, Joan Duran",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012395400003660"
    },
    {
        "id": 23150,
        "title": "A Lightweight Multi-Head Attention Transformer for Stock Price Forecasting",
        "authors": "Anh Nguyen, Son Ha",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4729648"
    },
    {
        "id": 23151,
        "title": "Object-Centric Representation Learning with Attention Mechanism",
        "authors": "Hidemoto Nakada, Hideki Asoh",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/imcom60618.2024.10418364"
    },
    {
        "id": 23152,
        "title": "Multi-modal multi-head self-attention for medical VQA",
        "authors": "Vasudha Joshi, Pabitra Mitra, Supratik Bose",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-17162-3"
    },
    {
        "id": 23153,
        "title": "Action Recognition in Videos using 3D ConvNets with Multi-head Attention",
        "authors": "Yagmur Sahin, Mustafa Sert",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bigmm59094.2023.00017"
    },
    {
        "id": 23154,
        "title": "A recursive multi-head self-attention learning for acoustic-based gear fault diagnosis in real-industrial noise condition",
        "authors": "Yong Yao, Gui Gui, Suixian Yang, Sen Zhang",
        "published": "2024-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.engappai.2024.108240"
    },
    {
        "id": 23155,
        "title": "Recognition of Indian classical dance poses in multi head attention learning framework",
        "authors": "P. V. V. Kishore, D. Anil Kumar, SK. Khwaja Moinuddin, L. Divyasree, E. Kiran Kumar",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/rmkmate59243.2023.10369558"
    },
    {
        "id": 23156,
        "title": "A Cross-Domain Recommender System for Literary Books Using Multi-Head Self-Attention Interaction and Knowledge Transfer Learning",
        "authors": "Yuan Cui, Yuexing Duan, Yueqin Zhang, Li Pan",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "Existing book recommendation methods often overlook the rich information contained in the comment text, which can limit their effectiveness. Therefore, a cross-domain recommender system for literary books that leverages multi-head self-attention interaction and knowledge transfer learning is proposed. Firstly, the BERT model is employed to obtain word vectors, and CNN is used to extract user and project features. Then, higher-level features are captured through the fusion of multi-head self-attention and addition pooling. Finally, knowledge transfer learning is introduced to conduct joint modeling between different domains by simultaneously extracting domain-specific features and shared features between domains. On the Amazon dataset, the proposed model achieved MAE and MSE of 0.801 and 1.058 in the “movie-book” recommendation task and 0.787 and 0.805 in the “music-book” recommendation task, respectively. This performance is significantly superior to other advanced recommendation models. Moreover, the proposed model also has good universality on the Chinese dataset.",
        "keywords": "",
        "link": "http://dx.doi.org/10.4018/ijdwm.334122"
    },
    {
        "id": 23157,
        "title": "Speech Emotion Classification with Parallel Architecture of Deep Learning and Multi-Head Attention Transformer",
        "authors": "An Hoang Nguyen, Kien Trang, Nguyen Gia Minh Thao, Bao Quoc Vuong, Long Ton-That",
        "published": "2023-9-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/sice59929.2023.10354088"
    },
    {
        "id": 23158,
        "title": "Multi-Head-Self-Attention based YOLOv5X-transformer for multi-scale object detection",
        "authors": "Ponduri Vasanthi, Laavanya Mohan",
        "published": "2023-5-16",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-15773-4"
    },
    {
        "id": 23159,
        "title": "Pedestrian Inertial Navigation with Multi-Head LSTM Including Attention",
        "authors": "Muhammed Taha Köroğlu, Gökhan Çetin",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/asyu58738.2023.10296616"
    },
    {
        "id": 23160,
        "title": "Attention Balanced Multi-Dimension Multi-Task Deep Learning for Alopecia Recognition",
        "authors": "C Saraswathi,  , B Pushpa",
        "published": "2023-5-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17485/ijst/v16i18.29"
    },
    {
        "id": 23161,
        "title": "An Intention Inference Method for BiGRU Integrating Multi-head Self-Attention in Share Control",
        "authors": "Wenshan Zhao, Hua Wang",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cac59555.2023.10451784"
    },
    {
        "id": 23162,
        "title": "Tensor Multi-Task Learning for Multi-View Representation of 3D Shape",
        "authors": "Yan Zhang, Sujia Fu, Yanyun Qu",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cac59555.2023.10451409"
    },
    {
        "id": 23163,
        "title": "Multi-branch Segmentation-guided Attention Network for crowd counting",
        "authors": "Zheyi Fan, Zihao Song, Di Wu, Yixuan Zhu",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2023.103964"
    },
    {
        "id": 23164,
        "title": "Fingervein Verification using Convolutional Multi-Head Attention Network",
        "authors": "Raghavendra Ramachandra, Sushma Venkatesh",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00606"
    },
    {
        "id": 23165,
        "title": "Multi-channel EEG signals classification via CNN and multi-head self-attention on evidence theory",
        "authors": "Lang Zhang, Fuyuan Xiao, Zehong Cao",
        "published": "2023-9",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ins.2023.119107"
    },
    {
        "id": 23166,
        "title": "Stock Index Forecasting Using Combined Model of Wavelet Transform LSTM and Multi-Head Attention",
        "authors": "Heeseok Kwon, Minhyuk Lee",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.7737/kmsr.2023.40.2.097"
    },
    {
        "id": 23167,
        "title": "Grape Disease Detection Network Based On Multi Task Learning and Attention Features",
        "authors": "",
        "published": "2023-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.48047/nq.2021.19.7.nq21118"
    },
    {
        "id": 23168,
        "title": "MAPoseNet: Animal pose estimation network via multi-scale convolutional attention",
        "authors": "Sicong Liu, Qingcheng Fan, Shuqin Li, Chunjiang Zhao",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2023.103989"
    },
    {
        "id": 23169,
        "title": "A Multi-Head Convolution Network with Attention Consistency for Facial Expression Recognition",
        "authors": "Wenkang Liu, Mingyi Sun, Yang Li",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/ccc58697.2023.10240537"
    },
    {
        "id": 23170,
        "title": "Fusion of Multi-headed Self-attention for Traditional Chinese Medicine Knowledge Graph Representation Learning",
        "authors": "Yiying Lin, Feng Lin, Yu Yang, Dongsheng Shi, Qianzhong Chen, Wentao Zhu, Dongmei Li, Xiaoping Zhang",
        "published": "2023-7-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/snpd-winter57765.2023.10223765"
    },
    {
        "id": 23171,
        "title": "DAG: Dual Attention Graph Representation Learning for Node Classification",
        "authors": "Siyi Lin, Jie Hong, Bo Lang, Lin Huang",
        "published": "2023-8-28",
        "citations": 0,
        "abstract": "Transformer-based graph neural networks have accomplished notable achievements by utilizing the self-attention mechanism for message passing in various domains. However, traditional methods overlook the diverse significance of intra-node representations, focusing solely on internode interactions. To overcome this limitation, we propose a DAG (Dual Attention Graph), a novel approach that integrates both intra-node and internode dynamics for node classification tasks. By considering the information exchange process between nodes from dual branches, DAG provides a holistic understanding of information propagation within graphs, enhancing the interpretability of graph-based machine learning applications. The experimental evaluations demonstrate that DAG excels in node classification tasks, outperforming current benchmark models across ten datasets.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math11173691"
    },
    {
        "id": 23172,
        "title": "Learning to translate by learning to communicate",
        "authors": "C.m. Downey, Xuhui Zhou, Zeyu Liu, Shane Steinert-Threlkeld",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.mrl-1.17"
    },
    {
        "id": 23173,
        "title": "MA-VAE: Multi-Head Attention-Based Variational Autoencoder Approach for Anomaly Detection in Multivariate Time-Series Applied to Automotive Endurance Powertrain Testing",
        "authors": "Lucas Correia, Jan-Christoph Goos, Philipp Klein, Thomas Bäck, Anna Kononova",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012163100003595"
    },
    {
        "id": 23174,
        "title": "Research on Transportation Mode Recognition Based on Multi-Head Attention Temporal Convolutional Network",
        "authors": "Shuyu Cheng, Yingan Liu",
        "published": "2023-3-29",
        "citations": 3,
        "abstract": "Transportation mode recognition is of great importance in analyzing people’s travel patterns and planning urban roads. To make more accurate judgments on the transportation mode of the user, we propose a deep learning fusion model based on multi-head attentional temporal convolution (TCMH). First, the time-domain features of a more extensive range of sensor data are mined through a temporal convolutional network. Second, multi-head attention mechanisms are introduced to learn the significance of different features and timesteps, which can improve the identification accuracy. Finally, the deep-learned features are fed into a fully connected layer to output the classification results of the transportation mode. The experimental results demonstrate that the TCMH model achieves an accuracy of 90.25% and 89.55% on the SHL and HTC datasets, respectively, which is 4.45% and 4.70% higher than the optimal value in the baseline algorithm. The model has a better recognition effect on transportation modes.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23073585"
    },
    {
        "id": 23175,
        "title": "Nested Deformable Multi-head Attention for Facial Image Inpainting",
        "authors": "Shruti S Phutke, Subrahmanyam Murala",
        "published": "2023-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00602"
    },
    {
        "id": 23176,
        "title": "CUNI Submission to MRL 2023 Shared Task on Multi-lingual Multi-task Information Retrieval",
        "authors": "Jindřich Helcl, Jindřich Libovický",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.mrl-1.23"
    },
    {
        "id": 23177,
        "title": "Meta-learning For Vision-and-language Cross-lingual Transfer",
        "authors": "Hanxu Hu, Frank Keller",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.mrl-1.2"
    },
    {
        "id": 23178,
        "title": "Improving Efficiency and Generalisability of Motion Predictions With Deep Multi-Agent Learning and Multi-Head Attention",
        "authors": "Djamel Eddine Benrachou, Sebastien Glaser, Mohammed Elhenawy, Andry Rakotonirainy",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tits.2023.3339640"
    },
    {
        "id": 23179,
        "title": "Multi-head self-attention mechanism-based global feature learning model for ASD diagnosis",
        "authors": "Feng Zhao, Fan Feng, Shixin Ye, Yanyan Mao, Xiaobo Chen, Yuan Li, Mao Ning, MingLi Zhang",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.bspc.2024.106090"
    },
    {
        "id": 23180,
        "title": "HiCAP: Hierarchical Clustering-based Attention Pooling for Graph Representation Learning",
        "authors": "Parsa Haddadian, Rooholah Abedian, Ali Moeini",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccke60553.2023.10326268"
    },
    {
        "id": 23181,
        "title": "SegIns: A simple extension to instance discrimination task for better localization learning",
        "authors": "Melih Baydar, Emre Akbas",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2024.104122"
    },
    {
        "id": 23182,
        "title": "EfficientNet and multi-path convolution with multi-head attention network for brain tumor grade classification",
        "authors": "B. Venkateswarlu Isunuri, Jagadeesh Kakarla",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compeleceng.2023.108700"
    },
    {
        "id": 23183,
        "title": "TMH: Two-Tower Multi-Head Attention neural network for CTR prediction",
        "authors": "Zijian An, Inwhee Joe",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "Click-through rate (CTR) prediction is a term used to predict the probability of a user clicking on an ad or item and has become a popular research area in advertising. As the volume of Internet data increases, the labor costs of traditional feature engineering continue to rise. To reduce the dependence on feature interactions, this paper proposes a fusion model that combines explicit and implicit feature interactions, called the Two-Tower Multi-Head Attention Neural Network (TMH) approach. The model integrates multiple components such as multi-head attention, residual network, and deep neural networks into an end-to-end model that automatically obtains vector-level combinations of explicit and implicit features to predict click-through rates through higher-order explicit and implicit interactions. We evaluated the effectiveness of TMH in CTR prediction through numerous experiments using three real datasets. The results demonstrate that our proposed method not only outperforms existing prediction methods but also offers good interpretability.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1371/journal.pone.0295440"
    },
    {
        "id": 23184,
        "title": "Single image deraining using multi-scales context information and attention network",
        "authors": "Pengcheng Li, Shan Gai",
        "published": "2023-2",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2022.103695"
    },
    {
        "id": 23185,
        "title": "Multi-scale spatial–temporal attention graph convolutional networks for driver fatigue detection",
        "authors": "Shuxiang Fa, Xiaohui Yang, Shiyuan Han, Zhiquan Feng, Yuehui Chen",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2023.103826"
    },
    {
        "id": 23186,
        "title": "A convolutional autoencoder model with weighted multi-scale attention modules for 3D skeleton-based action recognition",
        "authors": "F. Khezerlou, A. Baradarani, M.A. Balafar",
        "published": "2023-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2023.103781"
    },
    {
        "id": 23187,
        "title": "An Efficient Audio-visual Speech Enhancement Network via Multi-head Attention",
        "authors": "Min Yang, Jianjun Hao",
        "published": "2023-5-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaibd57115.2023.10206147"
    },
    {
        "id": 23188,
        "title": "AMSFF-Net: Attention-Based Multi-Stream Feature Fusion Network for Single Image Dehazing",
        "authors": "Sanaullah Memon, Rafaqat Hussain Arain, Ghulam Ali Mallah",
        "published": "2023-2",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2022.103748"
    },
    {
        "id": 23189,
        "title": "A Novel Convolution Kernel with Multi-head Self-attention",
        "authors": "Ming Gao, Huailin Zhao, Mingfang Deng",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciibms60103.2023.10347796"
    },
    {
        "id": 23190,
        "title": "Unsupervised Multi-Head Attention Autoencoder for Multivariate Time-Series Anomaly Detection",
        "authors": "Minseok Kim, Sanghyun Park",
        "published": "2024-2-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bigcomp60711.2024.00011"
    },
    {
        "id": 23191,
        "title": "Enhancing System Inertia Estimation: Multi-Head Graph Attention Networks Leveraging PMU Measurements",
        "authors": "Faisal Albeladi, Kamal Basulaiman, Masoud Barati",
        "published": "2024-2-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tpec60005.2024.10472224"
    },
    {
        "id": 23192,
        "title": "Multi-Head Self Attention for Enhanced Object Detection in the Maritime Domain",
        "authors": "Walid Messaoud, Rim Trabelsi, Adnane Cabani, Fatma Abdelkefi",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cw58918.2023.00034"
    },
    {
        "id": 23193,
        "title": "Multi-View Multi-Task Representation Learning for Mispronunciation Detection",
        "authors": "Yassine EL Kheir, Shammur Chowdhury, Ahmed Ali",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/slate.2023-18"
    },
    {
        "id": 23194,
        "title": "Lane detection algorithm based on multi-head self-attention and multi-level feature fusion",
        "authors": "Bobo Guo, Zanxia Qiang, Xianfu Bao, Yao Xu",
        "published": "2023-4-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2671212"
    },
    {
        "id": 23195,
        "title": "Cortical Bone Thickness Assessment from Multi-frequency Ultrasound RF Data using a Convolutional Architecture with Multi-head Attention",
        "authors": "Hossam H. Sultan, Enrico Grisan, Paul Dryburgh, Laura Peralta, Sevan Harput",
        "published": "2023-9-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ius51837.2023.10307373"
    },
    {
        "id": 23196,
        "title": "Optimal Recommendation Models Based on Knowledge Representation Learning and Graph Attention Networks",
        "authors": "Qing He, Songyan Liu, Yao Liu",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3248618"
    },
    {
        "id": 23197,
        "title": "Distract Your Attention: Multi-Head Cross Attention Network for Facial Expression Recognition",
        "authors": "Zhengyao Wen, Wenzhong Lin, Tao Wang, Ge Xu",
        "published": "2023-5-11",
        "citations": 65,
        "abstract": "This paper presents a novel facial expression recognition network, called Distract your Attention Network (DAN). Our method is based on two key observations in biological visual perception. Firstly, multiple facial expression classes share inherently similar underlying facial appearance, and their differences could be subtle. Secondly, facial expressions simultaneously exhibit themselves through multiple facial regions, and for recognition, a holistic approach by encoding high-order interactions among local features is required. To address these issues, this work proposes DAN with three key components: Feature Clustering Network (FCN), Multi-head Attention Network (MAN), and Attention Fusion Network (AFN). Specifically, FCN extracts robust features by adopting a large-margin learning objective to maximize class separability. In addition, MAN instantiates a number of attention heads to simultaneously attend to multiple facial areas and build attention maps on these regions. Further, AFN distracts these attentions to multiple locations before fusing the feature maps to a comprehensive one. Extensive experiments on three public datasets (including AffectNet, RAF-DB, and SFEW 2.0) verified that the proposed method consistently achieves state-of-the-art facial expression recognition performance. The DAN code is publicly available.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/biomimetics8020199"
    },
    {
        "id": 23198,
        "title": "Auto-outlier Fusion Technique for Chest X-ray Classification with Multi-head Attention Mechanism",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23977/jipta.2022.060101"
    },
    {
        "id": 23199,
        "title": "Auto-outlier Fusion Technique for Chest X-ray Classification with Multi-head Attention Mechanism",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23977/jipta.2023.060101"
    },
    {
        "id": 23200,
        "title": "Sentiment analysis with adaptive multi-head attention in Transformer",
        "authors": "Fanfei Meng, Chen-Ao Wang",
        "published": "2024-3-25",
        "citations": 0,
        "abstract": "We propose a novel framework based on the attention mechanism to identify the sentiment of a movie review document. Previous efforts on deep neural networks with attention mechanisms focus on encoder and decoder with fixed numbers of multi-head attention. Therefore, we need a mechanism to stop the attention process automatically if no more useful information can be read from the memory.In this paper, we propose an adaptive multi-head attention architecture (AdaptAttn) which varies the number of attention heads based on length of sentences. AdaptAttn has a data preprocessing step where each document is classified into any one of the three bins small, medium or large based on length of the sentence. The document classified as small goes through two heads in each layer, the medium group passes four heads and the large group is processed by eight heads. We examine the merit of our model on the Stanford large movie review dataset. The experimental results show that the F1 score from our model is on par with the baseline model. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/50/20241326"
    },
    {
        "id": 23201,
        "title": "Automatic Front-end Code Generation from image Via Multi-Head Attention",
        "authors": "Zhihang Zhang, Ye Ding, Chenlin Huang",
        "published": "2023-4-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccea58433.2023.10135462"
    },
    {
        "id": 23202,
        "title": "Discharge Summaries Based Sentiment Detection Using Multi-Head Attention and CNN-BiGRU",
        "authors": "Samer Abdulateef Waheeb",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/csse.2023.035753"
    },
    {
        "id": 23203,
        "title": "Modeling vehicle U-turning behavior near intersections: A deep learning approach based on TCN and multi-head attention",
        "authors": "Weiliang Zeng, Qinyong Lin, Boyang Zhu, Chujun Peng, Rong Yu",
        "published": "2024-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2024.123674"
    },
    {
        "id": 23204,
        "title": "Differential attention net: Multi-directed differential attention based hybrid deep learning model for solar power forecasting",
        "authors": "Amit Rai, Ashish Shrivastava, Kartick C. Jana",
        "published": "2023-1",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.energy.2022.125746"
    },
    {
        "id": 23205,
        "title": "A hierarchical multi-modal cross-attention model for face anti-spoofing",
        "authors": "Hao Xue, Jing Ma, Xiaoyu Guo",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2023.103969"
    },
    {
        "id": 23206,
        "title": "UniBriVL: Robust Audio Representation and Generation of Audio Driven Diffusion Models",
        "authors": "Sen Fang, Bowen Gao, Yangjian Wu, TeikToe Teoh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.mrl-1.1"
    },
    {
        "id": 23207,
        "title": "Multi head self-attention gated graph convolutional network based multi‑attack intrusion detection in MANET",
        "authors": "R Reka, R Karthick, R Saravana Ram, Gurkirpal Singh",
        "published": "2024-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cose.2023.103526"
    },
    {
        "id": 23208,
        "title": "Application of Knowledge Distillation to Multi-Task Speech Representation Learning",
        "authors": "Mine Kerpicci, Van Nguyen, Shuhua Zhang, Erik Visser",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-2011"
    },
    {
        "id": 23209,
        "title": "Efficient Representation of Biochemical Structures for Supervised and Unsupervised Machine Learning Models Using Multi-Sensoric Embeddings",
        "authors": "Katrin Bohnsack, Alexander Engelsberger, Marika Kaden, Thomas Villmann",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011644000003414"
    },
    {
        "id": 23210,
        "title": "Construction safety predictions with multi-head attention graph and sparse accident networks",
        "authors": "Fatemeh Mostofi, Vedat Toğan",
        "published": "2023-12",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.autcon.2023.105102"
    },
    {
        "id": 23211,
        "title": "Dropout Multi-Head Attention for Single Image Super-Resolution",
        "authors": "Chao Yang, Yong Fan, Cheng Lu",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10448233"
    },
    {
        "id": 23212,
        "title": "Named Entity Recognition Based on Pre-training Model and Multi-head Attention Mechanism",
        "authors": "GuoHua Zhu, Jian Wang",
        "published": "2023-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icnlp58431.2023.00040"
    },
    {
        "id": 23213,
        "title": "Learning an attention-aware parallel sharing network for facial attribute recognition",
        "authors": "Si Chen, Xinyu Lai, Yan Yan, Da-Han Wang, Shunzhi Zhu",
        "published": "2023-2",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2022.103745"
    },
    {
        "id": 23214,
        "title": "Deep learning-based multi-head self-attention model for human epilepsy identification from EEG signal for biomedical traits",
        "authors": "Ashit Kumar Dutta, Mohan Raparthi, Mahmood Alsaadi, Mohammed Wasim Bhatt, Sarath Babu Dodda, Prashant G. C., Mukta Sandhu, Jagdish Chandra Patni",
        "published": "2024-3-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-024-18918-1"
    },
    {
        "id": 23215,
        "title": "Dual adaptive learning multi-task multi-view for graph network representation learning",
        "authors": "Beibei Han, Yingmei Wei, Qingyong Wang, Shanshan Wan",
        "published": "2023-5",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.02.026"
    },
    {
        "id": 23216,
        "title": "A volumetric multi-head attention strategy for lung nodule classification in CT",
        "authors": "Alejandra Moreno, Andrea Rueda, Fabio Martínez",
        "published": "2023-4-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2654256"
    },
    {
        "id": 23217,
        "title": "Parallel Multi-Head Graph Attention Network (PMGAT) Model for Human-Object Interaction Detection",
        "authors": "Jiali Zhang, Zuriahati Mohd Yunos, Habibollah Haron",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3335193"
    },
    {
        "id": 23218,
        "title": "Generating Continuations in Multilingual Idiomatic Contexts",
        "authors": "Rhitabrat Pokharel, Ameeta Agrawal",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.mrl-1.22"
    },
    {
        "id": 23219,
        "title": "Hierarchical Multi-Agent Deep Reinforcement Learning with an Attention-based Graph Matching Approach for Multi-Domain VNF-FG Embedding",
        "authors": "Lotfi Slim, Fetia Bannour",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/globecom54140.2023.10437970"
    },
    {
        "id": 23220,
        "title": "EMS2L: Enhanced Multi-Task Self-Supervised Learning for 3D Skeleton Representation Learning",
        "authors": "Lilang Lin, Jiaying Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1561/116.00000022"
    },
    {
        "id": 23221,
        "title": "Air quality index prediction model integrating multi-head self-attention mechanism",
        "authors": "Lantao Yao, Lizhi Liu",
        "published": "2023-8-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2689367"
    },
    {
        "id": 23222,
        "title": "Decision Fusion Network Based on Lightweight Multi-Head Attention Mechanism for Motor Fault Diagnosis",
        "authors": "Juan Feng, Xiaoliang Feng",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceemt59522.2023.10262927"
    },
    {
        "id": 23223,
        "title": "General fine-grained event detection based on fusion of multi-information representation and attention mechanism",
        "authors": "Xinyu He, Ge Yan, Changfu Si, Yonggong Ren",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13042-023-01900-y"
    },
    {
        "id": 23224,
        "title": "Multi Aspect Attention Online Integrated Distillation For Few-shot Learning",
        "authors": "Cailing Wang, Qingchen Wei",
        "published": "2023-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ccdc58219.2023.10326814"
    },
    {
        "id": 23225,
        "title": "Tucker Decomposition with Frequency Attention for Temporal Knowledge Graph Completion",
        "authors": "Likang Xiao, Richong Zhang, Zijie Chen, Junfan Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.repl4nlp-1.21"
    },
    {
        "id": 23226,
        "title": "A Multi-Scale LSTM with Multi-Head Self-Attention Embedding Mechanism for the Remaining Useful Life Prediction of Hot Strip Mill Rollers",
        "authors": "Ting Zhu, Zhen Chen, Di Zhou, Ershun Pan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3850/978-981-18-8071-1_p107-cd"
    },
    {
        "id": 23227,
        "title": "Traffic flow prediction model based on multi head dynamic attention and multi gate time convolution",
        "authors": "GuangBing Bao, jinyuan yang, XiaoLian Wu, zhonghao liu, jianhang zhang",
        "published": "2023-2-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2668601"
    },
    {
        "id": 23228,
        "title": "Enhancing Wind Power Forecast Precision via Multi-head Attention Transformer: An Investigation on Single-step and Multi-step Forecasting",
        "authors": "Md Rasel Sarkar, Sreenatha G. Anavatti, Tanmoy Dam, Mahardhika Pratama, Berlian Al Kindhi",
        "published": "2023-6-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191444"
    },
    {
        "id": 23229,
        "title": "PACS: Prediction and analysis of cancer subtypes from multi-omics data based on a multi-head attention mechanism model",
        "authors": "Liangrui Pan, Pengfei Rong, Dazheng Liu, Pinle Qin, Xiangxiang Zeng, Shaoliang Peng",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bibm58861.2023.10386066"
    },
    {
        "id": 23230,
        "title": "Detection of SQL Injection and Cross-Site Scripting Based on Multi-Model CNN Combined with Bidirectional GRU and Multi-Head Self-Attention",
        "authors": "Wei-Chun Hsiao, Chih-Hung Wang",
        "published": "2023-6-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccci59363.2023.10210155"
    },
    {
        "id": 23231,
        "title": "Geographic and Geopolitical Biases of Language Models",
        "authors": "Fahim Faisal, Antonios Anastasopoulos",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.mrl-1.12"
    },
    {
        "id": 23232,
        "title": "Multi-modal Physiological Signal Fusion for Emotion Classification: A Multi-Head Attention Approach",
        "authors": "Xuemei Bai, Jiaqi Tan, Hanping Hu, Chenjie Zhang, Dongbing Gu",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "Abstract\nIn this essay, a model-level fusion technique of multi-modal physiological signals using Multi-Head Attention is studied. A framework that utilizes multi-model physiological signals for the task of emotion classification is proposed. First, the GCRNN model, which combines the Graph Convolutional Network (GCN) and the Long and Short Term Memory (LSTM), captures the unique features of electroencephalogram (EEG) signals. The spatial and temporal information that makes up impulses from the EEG can be captured precisely by such a technique. The CCRNN model, which combines the Convolutional Neural Network (CNN) integrated with the Channel-wise Attention and the LSTM, is used for peripheral physiological signals. The model can extract useful features from peripheral physiological signals and automatically learn to weigh the importance of various channels. Finally, Multi-head Attention is employed to fuse the output of the GCRNN and CCRNN methods. The Multi-head Attention can automatically learn the relevance and importance of different modal signals and weigh them accordingly. Emotion classification is implemented by adding a component of Softmax to map what the model produced to discrete emotion categories. The DEAP dataset was utilized in this study for experimental verification, and the results indicate that the method using multi-modal physiological signal fusion is substantially greater in precision than the technique using simply EEG signals. Additionally, the Multi-head Attention fusion method performs better than previous fusion techniques.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1742-6596/2637/1/012047"
    },
    {
        "id": 23233,
        "title": "A Multi-Head Attention Network Integrating Knowledge Graph and Collaborative Filtering",
        "authors": "Yanfei Wei, Jing Miao, Xiaodong Cheng, Yanan Wang",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isceic59030.2023.10271153"
    },
    {
        "id": 23234,
        "title": "Mismatch Error Calibration in Time Interleaved Acquisition System Based on Multi-Head Attention Mechanism",
        "authors": "Li Chen, Kuojun Yang, Peng Ye",
        "published": "2023-8-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/autotestcon47464.2023.10296374"
    },
    {
        "id": 23235,
        "title": "Elasticity unleashed: Fine-grained cloud scaling through distributed three-way decision fusion with multi-head attention",
        "authors": "Chunmao Jiang, Ying Duan",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ins.2024.120127"
    },
    {
        "id": 23236,
        "title": "A hybrid attention mechanism for multi-target entity relation extraction using graph neural networks",
        "authors": "Arshad Javeed",
        "published": "2023-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2022.100444"
    },
    {
        "id": 23237,
        "title": "Remote sensing image registration based on multi-head self-attention mechanism",
        "authors": "Hou Jianxing, Chen Ying, Deng Xiuhan, Ni Lizheng",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciibms60103.2023.10347825"
    },
    {
        "id": 23238,
        "title": "Blind Face Restoration via Multi-head Cross-attention and Generative Priors",
        "authors": "Zhiyong Huo, Shanlin Hu",
        "published": "2023-10-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cisp-bmei60920.2023.10373317"
    },
    {
        "id": 23239,
        "title": "Ethereum Eclipse Attack Detection Based on Multi-Head Attention Mechanism with Bi-LSTM",
        "authors": "Na Cheng, Yin Liang, Shike Li, Jianbin Li",
        "published": "2023-11-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icn60549.2023.10426440"
    },
    {
        "id": 23240,
        "title": "Multi-scale Network and Ghost Attention Head for Semantic Segmentation",
        "authors": "Zetao Fei, Qinghao Guo, Yao Zhang, Yunfeng Hu, Kui Tang",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccet58756.2023.00037"
    },
    {
        "id": 23241,
        "title": "Time-Frequency Domain Speech Enhancement Framework using Audio Spectrogram Transformer with Masked Multi-head Attention",
        "authors": "Suman Samui, Soumen Garai",
        "published": "2023-12-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/codec60112.2023.10465846"
    },
    {
        "id": 23242,
        "title": "Attention induced multi-head convolutional neural network organization with MobileNetv1 transfer learning and COVID-19 diagnosis using jellyfish search optimization process on chest X-ray images",
        "authors": "M. Ramkumar, M.S. Gowtham, S. Syed Jamaesha, M. Vigenesh",
        "published": "2024-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.bspc.2024.106133"
    },
    {
        "id": 23243,
        "title": "Multi-scale features and attention guided for brain tumor segmentation",
        "authors": "Zekun Wang, Yanni Zou, Hongyu Chen, Peter X. Liu, Junyu Chen",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2024.104141"
    },
    {
        "id": 23244,
        "title": "Learning Visibility Attention Graph Representation for Time Series Forecasting",
        "authors": "Shengzhong Mao, Xiao-Jun Zeng",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3583780.3615289"
    },
    {
        "id": 23245,
        "title": "Bi-Attention enhanced representation learning for image-text matching",
        "authors": "Yumin Tian, Aqiang Ding, Di Wang, Xuemei Luo, Bo Wan, Yifeng Wang",
        "published": "2023-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2023.109548"
    },
    {
        "id": 23246,
        "title": "An Effective Model for Predicting Phage-Host Interactions Via Graph Embedding Representation Learning With Multi-Head Attention Mechanism",
        "authors": "Yue Wang, Han Sun, Haodong Wang, Dandan Li, Weizhong Zhao, Xingpeng Jiang, Xianjun Shen",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/jbhi.2023.3261319"
    },
    {
        "id": 23247,
        "title": "DE-MHAIPs: Identification of SARS-CoV-2 phosphorylation sites based on differential evolution multi-feature learning and multi-head attention mechanism",
        "authors": "Minghui Wang, Lu Yan, Jihua Jia, Jiali Lai, Hongyan Zhou, Bin Yu",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compbiomed.2023.106935"
    },
    {
        "id": 23248,
        "title": "Multi-EuP: The Multilingual European Parliament Dataset for Analysis of Bias in Information Retrieval",
        "authors": "Jinrui Yang, Timothy Baldwin, Trevor Cohn",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.mrl-1.21"
    },
    {
        "id": 23249,
        "title": "U-Net based on multi-head attention mechanism",
        "authors": "Guangyuan Zhang, Yingxiang Lu, Tingzhi Qiu, Wei Li",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3012314"
    },
    {
        "id": 23250,
        "title": "Adaptive Graph and Multi-Head Attention-Based Vehicle Trajectory Prediction",
        "authors": "Pingyi Zhang, Wen Hu, Bangji Zhang, Zhaoxuan Ma, Penghao Li",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iecon51785.2023.10311937"
    },
    {
        "id": 23251,
        "title": "Age Estimation Based on Graph Convolutional Networks and Multi-head Attention Mechanisms",
        "authors": "Miaomiao Yang, Changwei Yao, Shijin Yan",
        "published": "2023-9-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciscae59047.2023.10393185"
    },
    {
        "id": 23252,
        "title": "Improved Neural Collaborative Filtering Recommendation Method based on Multi-Head Attention and Feature Fusion",
        "authors": "Yan Tang, Xin Zhang, Xiu Zhang",
        "published": "2023-11-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ispce-asia60405.2023.10365943"
    },
    {
        "id": 23253,
        "title": "Learning Better Keypoints for Multi-Object 6DoF Pose Estimation",
        "authors": "Yangzheng Wu, Michael Greenspan",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00062"
    },
    {
        "id": 23254,
        "title": "A Point Cloud Classification Method and Its Applications Based on Multi-Head Self-Attention",
        "authors": "Xue-Jun Liu Xue-Jun Liu, Wen-Hui Wang Xue-Jun Liu, Yong Yan Wen-Hui Wang, Zhong-Ji Cui Yong Yan, Yun Sha Zhong-Ji Cui, Yi-Nan Jiang Yun Sha",
        "published": "2023-8",
        "citations": 0,
        "abstract": "\n                        <p>In the monitoring the safety status of hazardous chemical warehouses by three-dimensional re-construction of deep camera point clouds, there are classification difficulties such as large space, sparse distribution of point clouds in cargo images, and similar distribution in low dimensions. Based on the above problem, a point cloud recognition method based on multi-head attention mechanism is proposed. The algorithm first normalizes the distribution of the point cloud data set through the affine transformation algorithm to solve the problem of sparse distribution. Then, the high-dimensional feature map is obtained by fusing the data down-sampling and curve feature aggregation algorithms to solve the problem of low-dimensional distribution approximation. The feature map is then encoded using a multi-head self-attention encoder to obtain features under different heads, which are then merged into a feature map. Finally, a multi-layer fully connected neural network is used as the decoder to decode the feature map into the final object classification. Comparative experiments were performed on the ModelNet40 dataset and the self-built dataset of warehouse goods, and the results showed that the accuracy of this paper was improved by 0.5% to 7.8% compared with that of other classification algorithms.</p>\n<p>&nbsp;</p>\n                    ",
        "keywords": "",
        "link": "http://dx.doi.org/10.53106/199115992023083404014"
    },
    {
        "id": 23255,
        "title": "Spectrum Transformer: Wideband Spectrum Sensing using Multi-Head Self-Attention",
        "authors": "Weishan Zhang, Yue Wang, Xiang Chen, Zhi Tian",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/spawc53906.2023.10304551"
    },
    {
        "id": 23256,
        "title": "Lithium Battery SOC Estimation Based on Multi-Head Attention Mechanism and GRU Algorithm",
        "authors": "Xueguang Li, Menchita F. Dumlao",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": " Pure electric vehicles have been widely used due to their non-pollution, low noise, high energy conversion efficiency and other advantages. SOC (State of Charge) is a crucial indicator for lithium batteries and pure electric vehicles. SOC cannot be directly measured. This article designs a new network structure. It is the GRU-Attention network structure. The stacked GRU algorithm in GRU-Attention network extracts the temporal characteristics of lithium battery test data, and the stacked multi-head self-attention network extracts the global information. The GRU-Attention network can avoid long-term dependency and gradient disappearance problems. The proposed network utilizes Stacked FFN as the dense layer. This article will test the network designed in the public data set at the University of Maryland. Simultaneously, this article compares the effects of different BatchSize on the performance of the algorithm. The network training process converges more effectively with a smaller BatchSize. Both too large and too small BatchSize have a negative impact on the generalization performance of the network. The extraction of the time-order character, however, may be hampered if the timestamp is too small. At the same time, the paper also compares the GRU-Attention network horizontally with the GRU and Attention networks. Eventually, the GRU-Attention network proposed in this article could better meet the estimate of the lithium battery SOC.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/ajst.v7i1.10997"
    },
    {
        "id": 23257,
        "title": "End-to-end clinical temporal information extraction with multi-head attention",
        "authors": "Timothy Miller, Steven Bethard, Dmitriy Dligach, Guergana Savova",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.bionlp-1.28"
    },
    {
        "id": 23258,
        "title": "Are Attention blocks better than BiLSTM for text recognition? ",
        "authors": "Amine Mohamed Belhakimi, Guillaume Chiron, Florian Arrestier, Ahmad Montaser Awal",
        "published": "2023-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3589883.3589914"
    },
    {
        "id": 23259,
        "title": "Remaining Useful Life Prediction of Bearings Based on Multi-head Self-attention Mechanism, Multi-scale Temporal Convolutional Network and Convolutional Neural Network",
        "authors": "Hao Wei, Yu Gu, Qinghua Zhang",
        "published": "2023-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ccdc58219.2023.10327369"
    },
    {
        "id": 23260,
        "title": "Spatial-Temporal Graph Attention-Based Multi-Agent Reinforcement Learning in Cooperative Edge Caching",
        "authors": "Jiacheng Hou, Amiya Nayak",
        "published": "2023-5-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icc45041.2023.10278575"
    },
    {
        "id": 23261,
        "title": "Multi-Channel Representation Learning Enhanced Unfolding Multi-Scale Compressed Sensing Network for High Quality Image Reconstruction",
        "authors": "Chunyan Zeng, Shiyan Xia, Zhifeng Wang, Xiangkui Wan",
        "published": "2023-11-24",
        "citations": 1,
        "abstract": "Deep Unfolding Networks (DUNs) serve as a predominant approach for Compressed Sensing (CS) reconstruction algorithms by harnessing optimization. However, a notable constraint within the DUN framework is the restriction to single-channel inputs and outputs at each stage during gradient descent computations. This constraint compels the feature maps of the proximal mapping module to undergo multi-channel to single-channel dimensionality reduction, resulting in limited feature characterization capabilities. Furthermore, most prevalent reconstruction networks rely on single-scale structures, neglecting the extraction of features from different scales, thereby impeding the overall reconstruction network’s performance. To address these limitations, this paper introduces a novel CS reconstruction network termed the Multi-channel and Multi-scale Unfolding Network (MMU-Net). MMU-Net embraces a multi-channel approach, featuring the incorporation of Adap-SKConv with an attention mechanism to facilitate the exchange of information between gradient terms and enhance the feature map’s characterization capacity. Moreover, a Multi-scale Block is introduced to extract multi-scale features, bolstering the network’s ability to characterize and reconstruct the images. Our study extensively evaluates MMU-Net’s performance across multiple benchmark datasets, including Urban100, Set11, BSD68, and the UC Merced Land Use Dataset, encompassing both natural and remote sensing images. The results of our study underscore the superior performance of MMU-Net in comparison to existing state-of-the-art CS methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/e25121579"
    },
    {
        "id": 23262,
        "title": "Within- cross- consensus-view representation-based multi-view multi-label learning with incomplete data",
        "authors": "Changming Zhu, Yanchen Liu, Duoqian Miao, Yilin Dong, Witold Pedrycz",
        "published": "2023-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neucom.2023.126729"
    },
    {
        "id": 23263,
        "title": "Multi-Scale Learning with Attention-based UNet and Marginal Space Deep Ambiguity Transfer Learning for Lung Disease Prediction",
        "authors": "",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.22266/ijies2023.0831.45"
    },
    {
        "id": 23264,
        "title": "Multi-Head Attention Spatial-Temporal Graph Neural Networks for Traffic Forecasting",
        "authors": "Xiuwei Hu, Enlong Yu, Xiaoyu Zhao",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.4236/jcc.2024.123004"
    },
    {
        "id": 23265,
        "title": "Vehicle Detection in Adverse Weather: A Multi-Head Attention Approach with Multimodal Fusion",
        "authors": "Nujhat Tabassum, Mohamed El-Sharkawy",
        "published": "2024-4-13",
        "citations": 0,
        "abstract": "In the realm of autonomous vehicle technology, the multimodal vehicle detection network (MVDNet) represents a significant leap forward, particularly in the challenging context of weather conditions. This paper focuses on the enhancement of MVDNet through the integration of a multi-head attention layer, aimed at refining its performance. The integrated multi-head attention layer in the MVDNet model is a pivotal modification, advancing the network’s ability to process and fuse multimodal sensor information more efficiently. The paper validates the improved performance of MVDNet with multi-head attention through comprehensive testing, which includes a training dataset derived from the Oxford Radar RobotCar. The results clearly demonstrate that the multi-head MVDNet outperforms the other related conventional models, particularly in the average precision (AP) of estimation, under challenging environmental conditions. The proposed multi-head MVDNet not only contributes significantly to the field of autonomous vehicle detection but also underscores the potential of sophisticated sensor fusion techniques in overcoming environmental limitations.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/jlpea14020023"
    },
    {
        "id": 23266,
        "title": "Math Word Problem Solving: Operator and Template Techniques with Multi-Head Attention",
        "authors": "Sandip Sarkar, Dipankar Das, Partha Pakray, David Eduardo Pinto-Avendaño",
        "published": "2023-12-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.13053/cys-27-4-4769"
    },
    {
        "id": 23267,
        "title": "Hybrid recommendation model based on multi-head attention mechanism and cross network fusion",
        "authors": "Shaoguo Cui, Gang Zhang, Aodi Wang",
        "published": "2023-4-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2671053"
    },
    {
        "id": 23268,
        "title": "Multi Head Graph Attention for Drug Response Predicton",
        "authors": "P. Selvi Rajendran, M. Sivannarayna",
        "published": "2023-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsmdi57622.2023.00078"
    },
    {
        "id": 23269,
        "title": "An Anomaly Detection Approach Based on Bidirectional Temporal Convolutional Network and Multi-Head Attention Mechanism",
        "authors": "Rui Wang, Jiayao Li",
        "published": "2024-3-22",
        "citations": 0,
        "abstract": "Anomaly detection aims at detecting the data instances that deviate from the majority of data, and it is widely used in various fields for its ability to ensure the quality of the overall data. However, traditional anomaly detection methods face the problems such as low efficiency due to high data complexity and lack of data labels. At the same time, most methods only learn the forward features of time-series data, while lacking attention to the reverse features. For these disadvantages, this paper designs an anomaly detection approach called BiTCN-MHA based on the bidirectional temporal convolutional network (BiTCN) and multi-head attention (MHA) mechanism, which learns the features of anomalous data by capturing the forward and reverse temporal features in the time-series data, as well as solves the problems of feature information overload and neuron “death” by using MHA mechanism and ELU activation function, respectively, thereby quickly and accurately detecting anomalous data. Extensive experiments on six public datasets show that compared with eight state-of-the-arts, the proposed BiTCN-MHA method can improve the precision, recall, AUC and F1-Score by about 6.10%, 10.16%, 4.06% and 8.50%, respectively, especially having better detection performance on small time-series data.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5755/j01.itc.53.1.34254"
    },
    {
        "id": 23270,
        "title": "Speech recognition based on the transformer's multi-head attention in Arabic",
        "authors": "Omayma Mahmoudi, Mouncef Filali-Bouami, Mohamed Benchat",
        "published": "2024-3-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10772-024-10092-x"
    },
    {
        "id": 23271,
        "title": "A semi-supervised learning method with attention mechanism for pancreas segmentation",
        "authors": "Yuhao Mo, Bo Peng, Caizheng Li, Fei Teng",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1142/9789811269264_0013"
    },
    {
        "id": 23272,
        "title": "MAFD: A Federated Distillation Approach with Multi-head Attention for Recommendation Tasks",
        "authors": "Aming Wu, Young-Woo Kwon",
        "published": "2023-3-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3555776.3577849"
    },
    {
        "id": 23273,
        "title": "Multi-head attention based candidate segment selection in QA over hybrid data",
        "authors": "Qian Chen, Xiaoying Gao, Xin Guo, Suge Wang",
        "published": "2023-11-20",
        "citations": 0,
        "abstract": "Question Answering based on Tabular and Textual data is a novel task proposed in recent years in the field of QA. At present, most QA systems return answers from a single data form, such as knowledge graphs, tables, texts. However, hybrid data including structured and unstructured data is quite pervasive in real life instead of a single form. Recent research on TAT-QA mainly suffers from the higher error of extracting supporting evidences from both tabular and textual content. This paper aimed to address the problem of failure evidence extraction from more complex and realistic hybrid data. We first proposed two types of metrics to evaluate the performance of evidence extraction on hybrid data, i.e. wrong evidence ratio (WER) and missing evidence ratio (MER). Then we utilize a candidate extractor to obtain supporting evidence related to the question. Third, an origin selector is designed to determine from where the question’s answer comes. Finally, the loss of origin selector is fused to the final loss function, which can improve the evidence extraction performance. Experimental results on the TAT-QA dataset showed that our proposed model outperforms the best baseline in terms of F1, WER and MER, which proves the effectiveness of our model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/ida-227032"
    },
    {
        "id": 23274,
        "title": "NDAM-YOLOseg: a real-time instance segmentation model based on multi-head attention mechanism",
        "authors": "Chengang Dong, Yuhao Tang, Liyan Zhang",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00530-023-01212-9"
    },
    {
        "id": 23275,
        "title": "A Graph Neural Network Recommendation Method Integrating Multi Head Attention Mechanism and Improved Gated Recurrent Unit Algorithm",
        "authors": "Fang Liu, Juan Wang, Junye Yang",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3325476"
    },
    {
        "id": 23276,
        "title": "MRLBot: Multi-Dimensional Representation Learning for Social Media Bot Detection",
        "authors": "Fanrui Zeng, Yingjie Sun, Yizhou Li",
        "published": "2023-5-19",
        "citations": 0,
        "abstract": "Social media bots pose potential threats to the online environment, and the continuously evolving anti-detection technologies require bot detection methods to be more reliable and general. Current detection methods encounter challenges, including limited generalization ability, susceptibility to evasion in traditional feature engineering, and insufficient exploration of user relationships. To tackle these challenges, this paper proposes MRLBot, a social media bot detection framework based on unsupervised representation learning. We design a behavior representation learning model that utilizes Transformer and a CNN encoder–decoder to simultaneously extract global and local features from behavioral information. Furthermore, a network representation learning model is proposed that introduces intra- and outer-community-oriented random walks to learn structural features and community connections from the relationship graph. Finally, the behavioral representation and relationship representation learning models are combined to generate fused representations for bot detection. The experimental results of four publicly available social network datasets demonstrate that the proposed method has certain advantages over state-of-the-art detection methods in this field.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12102298"
    },
    {
        "id": 23277,
        "title": "Towards Efficient Multi-view Representation Learning",
        "authors": "Kai Liu, Zheng Guo, Lei Gao, Naimul Mefraz Khan, Ling Guan",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ism59092.2023.00042"
    },
    {
        "id": 23278,
        "title": "Multi-Modal Representation Learning with Text-Driven Soft Masks",
        "authors": "Jaeyoo Park, Bohyung Han",
        "published": "2023-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00274"
    },
    {
        "id": 23279,
        "title": "Generalized Zero-Shot Image Classification via Partially-Shared Multi-Task Representation Learning",
        "authors": "Gerui Wang, Sheng Tang",
        "published": "2023-5-3",
        "citations": 0,
        "abstract": "Generalized Zero-Shot Learning (GZSL) holds significant research importance as it enables the classification of samples from both seen and unseen classes. A prevailing approach for GZSL is learning transferable representations that can generalize well to both seen and unseen classes during testing. This approach encompasses two key concepts: discriminative representations and semantic-relevant representations. “Semantic-relevant” facilitates the transfer of semantic knowledge using pre-defined semantic descriptors, while “discriminative” is crucial for accurate category discrimination. However, these two concepts are arguably inherently conflicting, as semantic descriptors are not specifically designed for image classification. Existing methods often struggle with balancing these two aspects and neglect the conflict between them, leading to suboptimal representation generalization and transferability to unseen classes. To address this issue, we propose a novel partially-shared multi-task representation learning method, termed PS-GZSL, which jointly preserves complementary and sharable knowledge between these two concepts. Specifically, we first propose a novel perspective that treats the learning of discriminative and semantic-relevant representations as optimizing a discrimination task and a visual-semantic alignment task, respectively. Then, to learn more complete and generalizable representations, PS-GZSL explicitly factorizes visual features into task-shared and task-specific representations and introduces two advanced tasks: an instance-level contrastive discrimination task and a relation-based visual-semantic alignment task. Furthermore, PS-GZSL employs Mixture-of-Experts (MoE) with a dropout mechanism to prevent representation degeneration and integrates a conditional GAN (cGAN) to synthesize unseen features for estimating unseen visual features. Extensive experiments and more competitive results on five widely-used GZSL benchmark datasets validate the effectiveness of our PS-GZSL.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12092085"
    },
    {
        "id": 23280,
        "title": "Deep Multi-Object Symbol Learning with Self-Attention Based Predictors",
        "authors": "Alper Ahmetoğlu, Erhan Öztop, Emre Uğur",
        "published": "2023-7-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/siu59756.2023.10223865"
    },
    {
        "id": 23281,
        "title": "Human Action Representation Learning Using an Attention-Driven Residual 3DCNN Network",
        "authors": "Hayat Ullah, Arslan Munir",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "The recognition of human activities using vision-based techniques has become a crucial research field in video analytics. Over the last decade, there have been numerous advancements in deep learning algorithms aimed at accurately detecting complex human actions in video streams. While these algorithms have demonstrated impressive performance in activity recognition, they often exhibit a bias towards either model performance or computational efficiency. This biased trade-off between robustness and efficiency poses challenges when addressing complex human activity recognition problems. To address this issue, this paper presents a computationally efficient yet robust approach, exploiting saliency-aware spatial and temporal features for human action recognition in videos. To achieve effective representation of human actions, we propose an efficient approach called the dual-attentional Residual 3D Convolutional Neural Network (DA-R3DCNN). Our proposed method utilizes a unified channel-spatial attention mechanism, allowing it to efficiently extract significant human-centric features from video frames. By combining dual channel-spatial attention layers with residual 3D convolution layers, the network becomes more discerning in capturing spatial receptive fields containing objects within the feature maps. To assess the effectiveness and robustness of our proposed method, we have conducted extensive experiments on four well-established benchmark datasets for human action recognition. The quantitative results obtained validate the efficiency of our method, showcasing significant improvements in accuracy of up to 11% as compared to state-of-the-art human action recognition methods. Additionally, our evaluation of inference time reveals that the proposed method achieves up to a 74× improvement in frames per second (FPS) compared to existing approaches, thus showing the suitability and effectiveness of the proposed DA-R3DCNN for real-time human activity recognition.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/a16080369"
    },
    {
        "id": 23282,
        "title": "Video representation learning for temporal action detection using global-local attention",
        "authors": "Yiping Tang, Yang Zheng, Chen Wei, Kaitai Guo, Haihong Hu, Jimin Liang",
        "published": "2023-2",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2022.109135"
    },
    {
        "id": 23283,
        "title": "Cross Model Attention based Deep Learning for Multi Modal Epilepsy Detection",
        "authors": "",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.22266/ijies2023.1031.07"
    },
    {
        "id": 23284,
        "title": "Multi-Task Learning based Video Anomaly Detection with Attention",
        "authors": "Mohammad Baradaran, Robert Bergevin",
        "published": "2023-6",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00290"
    },
    {
        "id": 23285,
        "title": "Change Point Detection for Fine-Grained MFR Work Modes with Multi-Head Attention-Based Bi-LSTM Network",
        "authors": "Yiying Fang, Qihang Zhai, Ziwei Zhang, Jing Yang",
        "published": "2023-3-22",
        "citations": 1,
        "abstract": "Detection of the changes in Multi-Functional Radar (MFR) work modes is a critical situation assessment task for Electronic Support Measure (ESM) systems. There are two major challenges that must be addressed: (i) The received radar pulse stream may contain multiple work mode segments of unknown number and duration, which makes the Change Point Detection (CPD) difficult. (ii) Modern MFRs can produce a variety of parameter-level (fine-grained) work modes with complex and flexible patterns, which are challenging to detect through traditional statistical methods and basic learning models. To address the challenges, a deep learning framework is proposed for fine-grained work mode CPD in this paper. First, the fine-grained MFR work mode model is established. Then, a multi-head attention-based bi-directional long short-term memory network is introduced to abstract high-order relationships between successive pulses. Finally, temporal features are adopted to predict the probability of each pulse being a change point. The framework further improves the label configuration and the loss function of training to mitigate the label sparsity problem effectively. The simulation results showed that compared with existing methods, the proposed framework effectively improves the CPD performance at parameter-level. Moreover, the F1-score was increased by 4.15% under hybrid non-ideal conditions.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23063326"
    },
    {
        "id": 23286,
        "title": "Defect Detection of Cell Phone Screen Using a Faster Regional Convolutional Neural Network with Multi-head Attention Mechanism",
        "authors": "Dayong Yu, Shuhui Yang",
        "published": "2024-4-4",
        "citations": 0,
        "abstract": "Since the glass outer screen of a cell phone is the main sensory part of the human eye when using a cell phone, the advantages and disadvantages of the cell phone screen directly affect people's sense of use. Therefore, the defect detection requirements for cell phone screens are high and need to meet the needs of high-volume factory inspection. Most of the traditional defect detection methods use visual methods, the detection results are overly dependent on the subjectivity and experience of workers, the efficiency of this method is low, and the accuracy is poor. Currently, machine learning-based detection methods are applied in numerous industries. In this paper, a faster Regional Convolutional Neural Network (R-CNN) with multi-head attention mechanism for defect detection of cell phone screen is proposed. To enhance the network's capability in extracting feature information, a four-head attention mechanism is added to the last convolutional layer of the ResNet50 network. An improved Region of Interest (ROI) Align is proposed to replace the original ROI Pooling to reduce the localization error of cell phone screen defects. Replace the original Rectified Linear Unit (ReLU) activation function with the Copy Exponential Linear Unit (CELU) activation function to expedite the convergence capability of the network. Finally, by comparing with other classical model training, the evaluation results indicate that the proposed method achieved an average accuracy of 95.71%, which is a 5.34% improvement compared to the original faster R-CNN network.",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/jes.1618"
    },
    {
        "id": 23287,
        "title": "A study of classroom learning attention discrimination method based on head posture detection",
        "authors": "Ge Chen, Jianqiang Ji, Tianyi Wang",
        "published": "2023-4-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsp58490.2023.10248779"
    },
    {
        "id": 23288,
        "title": "Class token and knowledge distillation for multi-head self-attention speaker verification systems",
        "authors": "Victoria Mingote, Antonio Miguel, Alfonso Ortega, Eduardo Lleida",
        "published": "2023-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.dsp.2022.103859"
    },
    {
        "id": 23289,
        "title": "Click-through rate prediction model integrating user interest and multi-head attention mechanism",
        "authors": "Wei Zhang, Yahui Han, Baolin Yi, Zhaoli Zhang",
        "published": "2023-1-31",
        "citations": 1,
        "abstract": "AbstractThe purpose of click-through rate (CTR) prediction is to anticipate how likely a person is to click on an advertisement or item. It's required for a lot of internet applications, such online advertising and recommendation systems. The previous click-through rate estimation approach suffered from the following two flaws. On the one hand, input characteristics (such as user id, user age, user age, item id, item category) are usually sparse and multidimensional, making them effective. High-level combination characteristics are used for prediction. Obtaining it manually by domain experts takes a long time and is difficult to finish; also, customer interests are not all the same. The accuracy of the model findings will significantly increase if this immediately recognized component is incorporated in the prediction model. As a consequence, this study creates an IARM (interactive attention rate estimation model) that incorporates user interest as well as a multi-head self-attention mechanism. The deep learning network is used in the model to determine the user's interest expression based on user attributes. The multi-head self-attention mechanism with residual network is then employed to get feature interaction, which enhances the degree of effect of significant characteristics on the estimation result as well as its accuracy. The IARM model outperforms other recent prediction models in the assessment metrics AUC and LOSS, and it has superior accuracy, according to the results from the public experimental data set.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s40537-023-00688-6"
    },
    {
        "id": 23290,
        "title": "VATMAN : Video-Audio-Text Multimodal Abstractive Summarization with Trimodal Hierarchical Multi-head Attention",
        "authors": "Doosan Baek, Jiho Kim, Hongchul Lee",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ictc58733.2023.10392391"
    },
    {
        "id": 23291,
        "title": "PointMM: Point Cloud Semantic Segmentation CNN under Multi-Spatial Feature Encoding and Multi-Head Attention Pooling",
        "authors": "Ruixing Chen, Jun Wu, Ying Luo, Gang Xu",
        "published": "2024-3-31",
        "citations": 0,
        "abstract": "For the actual collected point cloud data, there are widespread challenges such as semantic inconsistency, density variations, and sparse spatial distribution. A network called PointMM is developed in this study to enhance the accuracy of point cloud semantic segmentation in complex scenes. The main contribution of PointMM involves two aspects: (1) Multi-spatial feature encoding. We leverage a novel feature encoding module to learn multi-spatial features from the neighborhood point set obtained by k-nearest neighbors (KNN) in the feature space. This enhances the network’s ability to learn the spatial structures of various samples more finely and completely. (2) Multi-head attention pooling. We leverage a multi-head attention pooling module to address the limitations of symmetric function-based pooling, such as maximum and average pooling, in terms of losing detailed feature information. This is achieved by aggregating multi-spatial and attribute features of point clouds, thereby enhancing the network’s ability to transmit information more comprehensively and accurately. Experiments on publicly available point cloud datasets S3DIS and ISPRS 3D Vaihingen demonstrate that PointMM effectively learns features at different levels, while improving the semantic segmentation accuracy of various objects. Compared to 12 state-of-the-art methods reported in the literature, PointMM outperforms the runner-up by 2.3% in OA on the ISPRS 3D Vaihingen dataset, and achieves the third best performance in both OA and MioU on the S3DIS dataset. Both achieve a satisfactory balance between OA, F1, and MioU.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/rs16071246"
    },
    {
        "id": 23292,
        "title": "MAGRU-IDS: A Multi-Head Attention-Based Gated Recurrent Unit for Intrusion Detection in IIoT Networks",
        "authors": "Safi Ullah, Wadii Boulila, Anis Koubâa, Jawad Ahmad",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3324657"
    },
    {
        "id": 23293,
        "title": "POI Recommendation Model Using Multi-Head Attention in Location-Based Social Network Big Data",
        "authors": "Xiaoqiang Liu",
        "published": "2023-2-17",
        "citations": 1,
        "abstract": "A point of interest (POI) recommendation model using deep learning in location-based social network big data is proposed. Firstly, the features of POI are divided into inherent features composed of attributes such as geographical location and category, and semantic features of relevance composed of spontaneous access by users. Secondly, the inherent attribute features and semantic features of POI are extracted by constraint matrix decomposition and word vector model respectively, and the two hidden vectors are spliced into the feature vectors of POI to solve the problems of data sparsity and cold start. Finally, the multi-head attention is used to obtain the key information of user preferences, and a deep learning recommendation framework is constructed to model the nonlinear interaction between features. Experiments show that when the recommendation list is 10, the precision and recall of the proposed method are 0.118 and 0.135 respectively, which are better than the comparative recommendation method.",
        "keywords": "",
        "link": "http://dx.doi.org/10.4018/ijitsa.318142"
    },
    {
        "id": 23294,
        "title": "Multi-Head Spatiotemporal Attention Graph Convolutional Network for Traffic Prediction",
        "authors": "Ariyo Oluwasanmi, Muhammad Umar Aftab, Zhiguang Qin, Muhammad Shahzad Sarfraz, Yang Yu, Hafiz Tayyab Rauf",
        "published": "2023-4-9",
        "citations": 3,
        "abstract": "Intelligent transportation systems (ITSs) have become an indispensable component of modern global technological development, as they play a massive role in the accurate statistical estimation of vehicles or individuals commuting to a particular transportation facility at a given time. This provides the perfect backdrop for designing and engineering an adequate infrastructural capacity for transportation analyses. However, traffic prediction remains a daunting task due to the non-Euclidean and complex distribution of road networks and the topological constraints of urbanized road networks. To solve this challenge, this paper presents a traffic forecasting model which combines a graph convolutional network, a gated recurrent unit, and a multi-head attention mechanism to simultaneously capture and incorporate the spatio-temporal dependence and dynamic variation in the topological sequence of traffic data effectively. By achieving 91.8% accuracy on the Los Angeles highway traffic (Los-loop) test data for 15-min traffic prediction and an R2 score of 85% on the Shenzhen City (SZ-taxi) test dataset for 15- and 30-min predictions, the proposed model demonstrated that it can learn the global spatial variation and the dynamic temporal sequence of traffic data over time. This has resulted in state-of-the-art traffic forecasting for the SZ-taxi and Los-loop datasets.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23083836"
    },
    {
        "id": 23295,
        "title": "Multi-Relational Probabilistic Event Representation Learning via Projected Gaussian Embedding",
        "authors": "Linhai Zhang, Congzhi Zhang, Deyu Zhou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.384"
    },
    {
        "id": 23296,
        "title": "Counterfactually Probing Language Identity in Multilingual Models",
        "authors": "Anirudh Srinivasan, Venkata Subrahmanyan Govindarajan, Kyle Mahowald",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.mrl-1.3"
    },
    {
        "id": 23297,
        "title": "Extracting Multi-valued Relations from Language Models",
        "authors": "Sneha Singhania, Simon Razniewski, Gerhard Weikum",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.repl4nlp-1.12"
    },
    {
        "id": 23298,
        "title": "Multi-Scale and spatial position-based channel attention network for crowd counting",
        "authors": "Lin Wang, Jie Li, Siqi Zhang, Chun Qi, Pan Wang, Fengping Wang",
        "published": "2023-2",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2022.103718"
    },
    {
        "id": 23299,
        "title": "Instance-wise multi-view representation learning",
        "authors": "Dan Li, Haibao Wang, Yufeng Wang, Shengpei Wang",
        "published": "2023-3",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.inffus.2022.11.006"
    },
    {
        "id": 23300,
        "title": "Graph features dynamic fusion learning driven by multi-head attention for large rotating machinery fault diagnosis with multi-sensor data",
        "authors": "Xin Zhang, Xi Zhang, Jie Liu, Bo Wu, Youmin Hu",
        "published": "2023-10",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.engappai.2023.106601"
    },
    {
        "id": 23301,
        "title": "A General-Purpose Multilingual Document Encoder",
        "authors": "Onur Galoğlu Robert Litschko, Robert Litschko, Goran Glavaš",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.mrl-1.4"
    },
    {
        "id": 23302,
        "title": "Multi-Modal Relational Side Information Graph Attention Networks for Recommender System",
        "authors": "Shengzhe Jiao, Yihong Zhang, Takahiro Hara",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00150"
    },
    {
        "id": 23303,
        "title": "An Efficient Honeycomb Lung Segmentation Network Combining Multi-Paradigms Representation and Cascade Attention",
        "authors": "Bingqian Yang, Xiufang Feng, Yunyun Dong",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14569/ijacsa.2023.0141256"
    },
    {
        "id": 23304,
        "title": "An effective multi-task learning framework for drug repurposing based on graph representation learning",
        "authors": "Shengwei Ye, Weizhong Zhao, Xianjun Shen, Xingpeng Jiang, Tingting He",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ymeth.2023.07.008"
    }
]