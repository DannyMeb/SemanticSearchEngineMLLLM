[
    {
        "id": 8501,
        "title": "Analysis on Noisy Boltzmann Machines and Noisy Restricted Boltzmann Machines",
        "authors": "Wenhao Lu, Chi-Sing Leung, John Sum",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2021.3102275"
    },
    {
        "id": 8502,
        "title": "Towards Multi-agent Reinforcement Learning using Quantum Boltzmann Machines",
        "authors": "Tobias Müller, Christoph Roch, Kyrill Schmid, Philipp Altmann",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010762100003116"
    },
    {
        "id": 8503,
        "title": "A Beginner's Tutorial of Restricted Boltzmann Machines",
        "authors": "Yiping Cheng",
        "published": "No Date",
        "citations": 0,
        "abstract": "Restricted Boltzmann machines (RBMs) are the building blocks of some deep learning networks. However, despite their importance, it is our perception that some very important derivations about the RBM are missing in the literature, and a beginner may feel RBM very hard to understand. We provide here these missing derivations. We cover the classic Bernoulli-Bernoulli RBM and the Gaussian-Bernoulli RBM, but leave out the ``continuous'' RBM as it is believed not as mature as the former two. This tutorial can be used as a companion or complement to the famous RBM paper ``Training restricted Boltzmann machines: An introduction'' by Fisher and Igel.",
        "link": "http://dx.doi.org/10.20944/preprints202003.0337.v1"
    },
    {
        "id": 8504,
        "title": "Boltzmann Machines as Multidimensional Item Response Theory Models",
        "authors": "Gunter Maris, Timo Bechger",
        "published": "No Date",
        "citations": 1,
        "abstract": "We show that Boltzmann machines can formally be represented as multidimensional item response theory models. This relationship inspired a new learning principle and new ways to regularize Boltzmann machines to make them more interpretable. The core results carry over to a broader class of models including Gaussian-Bernoulli restricted Boltzmann machines.",
        "link": "http://dx.doi.org/10.31234/osf.io/zjh83"
    },
    {
        "id": 8505,
        "title": "Boltzmann Machines",
        "authors": "Geoffrey Hinton",
        "published": "2017",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_31"
    },
    {
        "id": 8506,
        "title": "Complex-Valued Deep Boltzmann Machines",
        "authors": "Calin-Adrian Popa",
        "published": "2018-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2018.8489359"
    },
    {
        "id": 8507,
        "title": "Denoising Deep Boltzmann Machines: Compression for Deep Learning",
        "authors": "Qing Li, Yang Chen",
        "published": "2020-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dcc47342.2020.00038"
    },
    {
        "id": 8508,
        "title": "Restricted Boltzmann Machines",
        "authors": "Charu Aggarwal",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-29642-0_7"
    },
    {
        "id": 8509,
        "title": "GPU implementation of restricted Boltzmann machines with application to view classification in sports videos",
        "authors": "Andreas Fred Bernitzke",
        "published": "No Date",
        "citations": 0,
        "abstract": "The objective of this project is to develop a software tool which assists in comparison of a work known as \"M-GenESys: Multi Structure Genetic Algorithm based Design Space Exploration System for Integrated Scheduling, Allocation and Binding in High Level Synthesis\" with another well established GA approach known as \"A Genetic Algorithm for the Design Space Exploration of Data paths During High-Level Synthesis\".\n\nTwo sets of Software are developed based on both approaches using Microsoft visual 2005,C# language. The C# language is an object-oriented language that is aimed at enabling programmers to quickly develop a wide range of applications on the Microsoft .NET platform. The goal of C# and the .NET platform is to shorten development time by freeing the developer from worrying about several low level plumbing issues such as memory management, type safety issues, building low level libraries, array bounds checking, etc. thus allowing developers to actually spend their time and energy working on the application and business logic.",
        "link": "http://dx.doi.org/10.32920/ryerson.14644515.v1"
    },
    {
        "id": 8510,
        "title": "GPU implementation of restricted Boltzmann machines with application to view classification in sports videos",
        "authors": "Andreas Fred Bernitzke",
        "published": "No Date",
        "citations": 0,
        "abstract": "The objective of this project is to develop a software tool which assists in comparison of a work known as \"M-GenESys: Multi Structure Genetic Algorithm based Design Space Exploration System for Integrated Scheduling, Allocation and Binding in High Level Synthesis\" with another well established GA approach known as \"A Genetic Algorithm for the Design Space Exploration of Data paths During High-Level Synthesis\".\n\nTwo sets of Software are developed based on both approaches using Microsoft visual 2005,C# language. The C# language is an object-oriented language that is aimed at enabling programmers to quickly develop a wide range of applications on the Microsoft .NET platform. The goal of C# and the .NET platform is to shorten development time by freeing the developer from worrying about several low level plumbing issues such as memory management, type safety issues, building low level libraries, array bounds checking, etc. thus allowing developers to actually spend their time and energy working on the application and business logic.",
        "link": "http://dx.doi.org/10.32920/ryerson.14644515"
    },
    {
        "id": 8511,
        "title": "An approach to improve online sequential extreme learning machines using restricted Boltzmann machines",
        "authors": "Andre G. C. Pacheco, Renato A. Krohling",
        "published": "2018-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2018.8489281"
    },
    {
        "id": 8512,
        "title": "Navigation of quadruped multi-robots by gesture recognition using restricted Boltzmann machines",
        "authors": "",
        "published": "2018-9-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.13180/clawar.2018.10-12.09.30"
    },
    {
        "id": 8513,
        "title": "Restricted Boltzmann Machines: an Eigencentrality-based Approach",
        "authors": "Andrew Skabar",
        "published": "2019-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2019.8852267"
    },
    {
        "id": 8514,
        "title": "Two-Sided Markets and Restricted Boltzmann Machines",
        "authors": "Tetsuya Hoshino, Romans Pancs",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4679675"
    },
    {
        "id": 8515,
        "title": "Restricted Boltzmann Machines",
        "authors": "Charu C. Aggarwal",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-94463-0_6"
    },
    {
        "id": 8516,
        "title": "Information geometry of hyperbolic-valued Boltzmann machines",
        "authors": "Masaki Kobayashi",
        "published": "2021-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neucom.2020.12.048"
    },
    {
        "id": 8517,
        "title": "Interpreting Restricted Boltzmann Machines from Optics Theory Perspectives",
        "authors": "Ping Guo",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ssci52147.2023.10371795"
    },
    {
        "id": 8518,
        "title": "Fine-Tuning Restricted Boltzmann Machines Using No-Boundary Jellyfish",
        "authors": "Douglas Rodrigues, Gustavo Henrique de Rosa, Kelton Pontara da Costa, Danilo Jodas, João Papa",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011643400003417"
    },
    {
        "id": 8519,
        "title": "The Memristive Boltzmann Machines",
        "authors": "Mahdi Nazm Bojnordi, Engin Ipek",
        "published": "2017",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mm.2017.53"
    },
    {
        "id": 8520,
        "title": "Intelligent Human Anomaly Identification and Classification in Crowded Scenes via Multi-fused Features and Restricted Boltzmann Machines",
        "authors": "Nurkholish Halim",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>With the advancement of technology and the breakthroughs of the modern era, accessing and transforming that data into information is becoming a more complex task for the scientific community. Specifically, a wide range of wearable and vision sensors are employed to capture multimodal data from diverse sources and fields. These have been incorporated into numerous domains and applications to assess academic and remote systems, emergency personnel, and monitoring systems. This paper presents a robust human anomaly detection and classification method in crowded scenes. First, crowdsourced data is acquired as an input. A few normalizing and filtering steps for denoising are performed. Then, human silhouettes are abstracted, which significantly facilitates human detection. Then, crowd-based analysis and clustering are employed for precise and efficient predictions. Following that feature engineering process, three robust features are extracted, including deep flow, gradient patches, and dense optical flow-based descriptors. Furthermore, stochastic gradient descent (SGD) was utilized for feature selection and optimization. Finally, optimized features are further fed to the Restricted Boltzmann Machines (RBM) classifier to advance adaptive training for the classification and predictions of human behavior in crowded scenes. The experimental results revealed an 88.1% accuracy and a 12.36 % error rate for the Avenue dataset. The ADOC dataset attained an average recognition rate of 91.17 percent, and an error rate of 8.82 percent. Finally, the USCD-Ped 2 dataset achieved an improved recognition rate of 90.19% with an error rate of 9.81%.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.21215069"
    },
    {
        "id": 8521,
        "title": "Collaborative filtering based on dual conditional restricted Boltzmann machines",
        "authors": "Chunchun Li, Jun Li",
        "published": "2017-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/chicc.2017.8029090"
    },
    {
        "id": 8522,
        "title": "Improving Market Data Generation with Restricted Boltzmann Machines",
        "authors": "Alexandre Lailler, Samson Cohen",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4020037"
    },
    {
        "id": 8523,
        "title": "Boltzmann Machines",
        "authors": "Ke-Lin Du, M. N. S. Swamy",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4471-7452-3_23"
    },
    {
        "id": 8524,
        "title": "Intelligent Human Anomaly Identification and Classification in Crowded Scenes via Multi-fused Features and Restricted Boltzmann Machines",
        "authors": "Nurkholish Halim",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>With the advancement of technology and the breakthroughs of the modern era, accessing and transforming that data into information is becoming a more complex task for the scientific community. Specifically, a wide range of wearable and vision sensors are employed to capture multimodal data from diverse sources and fields. These have been incorporated into numerous domains and applications to assess academic and remote systems, emergency personnel, and monitoring systems. This paper presents a robust human anomaly detection and classification method in crowded scenes. First, crowdsourced data is acquired as an input. A few normalizing and filtering steps for denoising are performed. Then, human silhouettes are abstracted, which significantly facilitates human detection. Then, crowd-based analysis and clustering are employed for precise and efficient predictions. Following that feature engineering process, three robust features are extracted, including deep flow, gradient patches, and dense optical flow-based descriptors. Furthermore, stochastic gradient descent (SGD) was utilized for feature selection and optimization. Finally, optimized features are further fed to the Restricted Boltzmann Machines (RBM) classifier to advance adaptive training for the classification and predictions of human behavior in crowded scenes. The experimental results revealed an 88.1% accuracy and a 12.36 % error rate for the Avenue dataset. The ADOC dataset attained an average recognition rate of 91.17 percent, and an error rate of 8.82 percent. Finally, the USCD-Ped 2 dataset achieved an improved recognition rate of 90.19% with an error rate of 9.81%.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.21215069.v1"
    },
    {
        "id": 8525,
        "title": "Restricted Boltzmann Machines",
        "authors": "Timothy Masters",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-3591-1_3"
    },
    {
        "id": 8526,
        "title": "Exploring Unsupervised Anomaly Detection with Quantum Boltzmann Machines in Fraud Detection",
        "authors": "Jonas Stein, Daniëlle Schuman, Magdalena Benkard, Thomas Holger, Wanja Sajko, Michael Kölle, Jonas Nüßlein, Leo Sünkel, Olivier Salomon, Claudia Linnhoff-Popien",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012326100003636"
    },
    {
        "id": 8527,
        "title": "Rate Distortion Via Restricted Boltzmann Machines",
        "authors": "Qing Li, Yang Chen",
        "published": "2018-10",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/allerton.2018.8635888"
    },
    {
        "id": 8528,
        "title": "Pattern reconstruction with restricted Boltzmann machines",
        "authors": "Giuseppe Genovese",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4171/msl/45"
    },
    {
        "id": 8529,
        "title": "Continuous restricted Boltzmann machines",
        "authors": "Robert W. Harrison",
        "published": "2022-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11276-018-01903-6"
    },
    {
        "id": 8530,
        "title": "Unsupervised Learning with Restricted Boltzmann Machines and Auto-encoders",
        "authors": "Santanu Pattanayak",
        "published": "2017",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-3096-1_5"
    },
    {
        "id": 8531,
        "title": "Exponential Family Restricted Boltzmann Machines and Annealed Importance Sampling",
        "authors": "Yifeng Li, Xiaodan Zhu",
        "published": "2018-7",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2018.8489413"
    },
    {
        "id": 8532,
        "title": "Anomaly detection speed-up by quantum restricted Boltzmann machines",
        "authors": "Lorenzo Moro, Enrico Prati",
        "published": "2023-9-23",
        "citations": 0,
        "abstract": "AbstractQuantum machine learning promises to revolutionize traditional machine learning by efficiently addressing hard tasks for classical computation. While claims of quantum speed-up have been announced for gate-based quantum computers and photon-based boson samplers, demonstration of an advantage by adiabatic quantum annealers (AQAs) is open. Here we quantify the computational cost and the performance of restricted Boltzmann machines (RBMs), a widely investigated machine learning model, by classical and quantum annealing. Despite the lower computational complexity of the quantum RBM being lost due to physical implementation overheads, a quantum speed-up may arise as a reduction by orders of magnitude of the computational time. By employing real-world cybersecurity datasets, we observe that the negative phase on sufficiently challenging tasks is computed up to 64 times faster by AQAs during the exploitation phase. Therefore, although a quantum speed-up highly depends on the problem’s characteristics, it emerges in existing hardware on real-world data.",
        "link": "http://dx.doi.org/10.1038/s42005-023-01390-y"
    },
    {
        "id": 8533,
        "title": "Classification using Discriminative Restricted Boltzmann Machines on Spark",
        "authors": "Maria Varsamou, Theodore Antonakopoulos",
        "published": "2019-9",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/softcom.2019.8903859"
    },
    {
        "id": 8534,
        "title": "Fine-Tuning Infinity Restricted Boltzmann Machines",
        "authors": "Leandro Aparecido Passos, Joao Paulo Papa",
        "published": "2017-10",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/sibgrapi.2017.15"
    },
    {
        "id": 8535,
        "title": "Restricted Boltzmann Machines for Recommender Systems with Implicit Feedback",
        "authors": "Fan Yang, Ying Lu",
        "published": "2018-12",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata.2018.8622127"
    },
    {
        "id": 8536,
        "title": "Training Method of Causal Extensional Model of Boltzmann Machines",
        "authors": "Qingsong Peng",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isceic59030.2023.10271192"
    },
    {
        "id": 8537,
        "title": "Autoencoders, Restricted Boltzmann Machines, and Deep Belief Networks",
        "authors": "Taweh Beysolow II",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-2734-3_7"
    },
    {
        "id": 8538,
        "title": "Crime Incidents Embedding Using Restricted Boltzmann Machines",
        "authors": "Shixiang Zhu, Yao Xie",
        "published": "2018-4",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp.2018.8461621"
    },
    {
        "id": 8539,
        "title": "Voice activity detection using discriminative restricted Boltzmann machines",
        "authors": "Rogerio G. Borin, Magno T. M. Silva",
        "published": "2017-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/eusipco.2017.8081262"
    },
    {
        "id": 8540,
        "title": "Entropy, Free Energy, and Work of Restricted Boltzmann Machines",
        "authors": "Sangchul Oh, Abdelkader Baggag, Hyunchul Nha",
        "published": "2020-5-11",
        "citations": 2,
        "abstract": "A restricted Boltzmann machine is a generative probabilistic graphic network. A probability of finding the network in a certain configuration is given by the Boltzmann distribution. Given training data, its learning is done by optimizing the parameters of the energy function of the network. In this paper, we analyze the training process of the restricted Boltzmann machine in the context of statistical physics. As an illustration, for small size bar-and-stripe patterns, we calculate thermodynamic quantities such as entropy, free energy, and internal energy as a function of the training epoch. We demonstrate the growth of the correlation between the visible and hidden layers via the subadditivity of entropies as the training proceeds. Using the Monte-Carlo simulation of trajectories of the visible and hidden vectors in the configuration space, we also calculate the distribution of the work done on the restricted Boltzmann machine by switching the parameters of the energy function. We discuss the Jarzynski equality which connects the path average of the exponential function of the work and the difference in free energies before and after training.",
        "link": "http://dx.doi.org/10.3390/e22050538"
    },
    {
        "id": 8541,
        "title": "Restricted Boltzmann Machines and Their Extensions for Face Modeling",
        "authors": "Khoa Luu",
        "published": "2017-9-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26717/bjstr.2017.01.000336"
    },
    {
        "id": 8542,
        "title": "Tensor Ring Restricted Boltzmann Machines",
        "authors": "Maolin Wang, Chenbin Zhang, Yu Pan, Jing Xu, Zenglin Xu",
        "published": "2019-7",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2019.8852432"
    },
    {
        "id": 8543,
        "title": "The use of restricted Boltzmann machines for clustering collaborative filtering",
        "authors": "Soojung Lee",
        "published": "2023-9-30",
        "citations": 0,
        "abstract": "<div><p class=\"Abstract\">Collaborative filtering-based recommender systems have been successfully serviced through commercial online systems to assist people with searching the information useful to them. However, several problems inherent in such systems still exist, although a lot of research work has been devoted to finding solutions. This work focuses on clustering collaborative filtering to address the scalability problem. It proposes a novel method to determine the clustering criteria for enhancing the prediction and recommendation accuracy of the systems, which is typically degraded when the clustering algorithm is integrated into collaborative filtering. We use a restricted Boltzmann machine to find the genre preference of users, which is then inputted into the clustering algorithm to cluster users. Various experiments are conducted to evaluate the performance of the proposed method. As a result, our method showed superior performance in terms of various performance criteria compared to previous clustering collaborative filtering methods and some of the major traditional systems.</p></div>",
        "link": "http://dx.doi.org/10.32629/jai.v6i3.723"
    },
    {
        "id": 8544,
        "title": "Deep Recurrent Neural Network Based Monaural Speech Separation Using Recurrent Temporal Restricted Boltzmann Machines",
        "authors": "Suman Samui, Indrajit Chakrabarti, Soumya K. Ghosh",
        "published": "2017-8-20",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2017-57"
    },
    {
        "id": 8545,
        "title": "Matrix Product Operator Restricted Boltzmann Machines",
        "authors": "Cong Chen, Kim Batselier, Ching-Yun Ko, Ngai Wong",
        "published": "2019-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2019.8851877"
    },
    {
        "id": 8546,
        "title": "Comparing Information-Theoretic Measures of Complexity in Boltzmann Machines",
        "authors": "Maxinder Kanwal, Joshua Grochow, Nihat Ay",
        "published": "2017-7-3",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3390/e19070310"
    },
    {
        "id": 8547,
        "title": "Cross-subject Mapping of Neural Activity with Restricted Boltzmann Machines",
        "authors": "Haoming Yang, Marko Angjelichinoski, Suya Wu, Joy Putney, Simon Sponberg, Vahid Tarokh",
        "published": "No Date",
        "citations": 0,
        "abstract": "1AbstractSubject-to-subject variability is a common challenge in both generalizing models of neural data across subjects, discriminating subject-specific and inter-subject features in large neural datasets, and engineering neural interfaces with subject-specific tuning. We study the problem of the cross-subject mapping of neural activity. The objective is to obtain a task-specific representation of the target subject signal into the feature space of the source subject. We propose to use the Restricted Boltzmann Machine (RBM) with Gaussian inputs and Bernoulli hidden units; once trained over the entire set of subjects, the RBM allows the mapping of target features on source feature spaces using Gibbs sampling. We also consider a novel computationally efficient training technique for RBMs based on the minimization of the Fisher divergence, which allows the gradients of the RBM to be computed in closed form. Specifically, we test decoding performance on neuromuscular recordings of spike trains from the ten muscles that primarily control wing motion in an agile flying hawk moth,Manduca sexta. The dataset consists of this comprehensive motor program recorded from nine subjects, each driven by six discrete visual stimuli. The evaluations show that the target features can be decoded using the source classifier with an accuracy of up to 95% when mapped using an RBM trained by Fisher divergence, showcasing the promising potential of the RBMs for cross-subject mapping applications.2Author summaryIn this study, we address the variability of neural data across subjects, which is a significant obstacle in developing models that can generalize across subjects. Our objective is to create a task-specific representation of the target subject signal in the feature space of the source subject. To this end, we consider the applications of the Restricted Boltzmann Machine (RBM) with Gaussian inputs and Bernoulli hidden units, trained on the joint feature space of the target subject and source subject. The trained RBM can then be used to map target features onto the source feature spaces using Gibbs sampling. We also present a novel, score-based computationally efficient training technique for RBMs based on Fisher divergence. Using neural decoding as a downstream application, we demonstrate the effectiveness of our method on neuromuscular recordings of spike trains from the ten muscles controlling wing motion in an agile flying hawk moth,Manduca sexta, recorded from nine subjects. Numerical evaluations show that the target features can be accurately decoded using the source classifier with up to 95% accuracy when mapped using an RBM trained by Fisher divergence.",
        "link": "http://dx.doi.org/10.1101/2023.04.14.536854"
    },
    {
        "id": 8548,
        "title": "Restricted Boltzmann Machines as Models of Interacting Variables",
        "authors": "Nicola Bulso, Yasser Roudi",
        "published": "2021-9-16",
        "citations": 3,
        "abstract": "Abstract\nWe study the type of distributions that restricted Boltzmann machines (RBMs) with different activation functions can express by investigating the effect of the activation function of the hidden nodes on the marginal distribution they impose on observed binary nodes. We report an exact expression for these marginals in the form of a model of interacting binary variables with the explicit form of the interactions depending on the hidden node activation function. We study the properties of these interactions in detail and evaluate how the accuracy with which the RBM approximates distributions over binary variables depends on the hidden node activation function and the number of hidden nodes. When the inferred RBM parameters are weak, an intuitive pattern is found for the expression of the interaction terms, which reduces substantially the differences across activation functions. We show that the weak parameter approximation is a good approximation for different RBMs trained on the MNIST data set. Interestingly, in these cases, the mapping reveals that the inferred models are essentially low order interaction models.",
        "link": "http://dx.doi.org/10.1162/neco_a_01420"
    },
    {
        "id": 8549,
        "title": "The use of restricted Boltzmann machines for clustering collaborative filtering",
        "authors": "Soojung Lee",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "<div><p class=\"Abstract\">Collaborative filtering-based recommender systems have been successfully serviced through commercial online systems to assist people with searching the information useful to them. However, several problems inherent in such systems still exist, although a lot of research work has been devoted to finding solutions. This work focuses on clustering collaborative filtering to address the scalability problem. It proposes a novel method to determine the clustering criteria for enhancing the prediction and recommendation accuracy of the systems, which is typically degraded when the clustering algorithm is integrated into collaborative filtering. We use a restricted Boltzmann machine to find the genre preference of users, which is then inputted into the clustering algorithm to cluster users. Various experiments are conducted to evaluate the performance of the proposed method. As a result, our method showed superior performance in terms of various performance criteria compared to previous clustering collaborative filtering methods and some of the major traditional systems.</p></div>",
        "link": "http://dx.doi.org/10.32629/jai.v7i1.723"
    },
    {
        "id": 8550,
        "title": "Data Anonymisation, Outlier Detection and Fighting Overfitting with Restricted Boltzmann Machines",
        "authors": "Alexei Kondratyev, Christian Schwarz, Blanka Horvath",
        "published": "No Date",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3526436"
    },
    {
        "id": 8551,
        "title": "Boltzmann Machines",
        "authors": "Sridhar Alla, Suman Kalyan Adari",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-5177-5_5"
    },
    {
        "id": 8552,
        "title": "Quantum computation of Restricted Boltzmann Machines by Monte Carlo Methods",
        "authors": "Yunkai Yao",
        "published": "2022-9-30",
        "citations": 0,
        "abstract": "In recent years, the diversification of problems that require computers to solve has attracted attention to the construction of meta-heuristics that can be applied to a wide range of problems, and to specialized computers that implement these meta-heuristics in their devices. The representative meta-heuristics are Simulated Annealing (SA) and its extension to quantum computation, Quantum Annealing (QA), and its path-integral Monte Carlo method for classical simulation Crosson and Harrow showed that for certain problems where QA outperformed SA, SQA achieved performance close to that of QA, and SQA sometimes outperformed SA by an exponential time factor. On the other hand, it remains unclear whether SQA can work efficiently on a wide range of other problems. In this study, we experimentally compared SA and SQA on instances of the restricted Boltzmann machine RBM, known as a fundamental building block in deep learning, and 3SAT, a fundamental combinatorial optimization problem. The results show that SQA gives slightly better solutions than SA as the problem size increases for RBM in terms of both accuracy and computation time in our setting, but the opposite trend is observed for 3SAT, indicating that there is no significant difference between the two methods. From the viewpoint of artificial intelligence research, it is necessary to further examine whether deep learning can be made more efficient by applying QA and SQA to RBM.",
        "link": "http://dx.doi.org/10.54097/hset.v9i.1780"
    },
    {
        "id": 8553,
        "title": "Graph clustering with Boltzmann machines",
        "authors": "Pierre Miasnikof, Mohammad Bagherbeik, Ali Sheikholeslami",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.dam.2023.10.012"
    },
    {
        "id": 8554,
        "title": "Variational quantum Boltzmann machines",
        "authors": "Christa Zoufal, Aurélien Lucchi, Stefan Woerner",
        "published": "2021-6",
        "citations": 47,
        "abstract": "AbstractThis work presents a novel realization approach to quantum Boltzmann machines (QBMs). The preparation of the required Gibbs states, as well as the evaluation of the loss function’s analytic gradient, is based on variational quantum imaginary time evolution, a technique that is typically used for ground-state computation. In contrast to existing methods, this implementation facilitates near-term compatible QBM training with gradients of the actual loss function for arbitrary parameterized Hamiltonians which do not necessarily have to be fully visible but may also include hidden units. The variational Gibbs state approximation is demonstrated with numerical simulations and experiments run on real quantum hardware provided by IBM Quantum. Furthermore, we illustrate the application of this variational QBM approach to generative and discriminative learning tasks using numerical simulation.",
        "link": "http://dx.doi.org/10.1007/s42484-020-00033-7"
    },
    {
        "id": 8555,
        "title": "Tomography and generative training with quantum Boltzmann machines",
        "authors": "Mária Kieferová, Nathan Wiebe",
        "published": "2017-12-22",
        "citations": 94,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1103/physreva.96.062327"
    },
    {
        "id": 8556,
        "title": "Using a Recurrent Neural Network and Restricted Boltzmann Machines for Malicious Traffic Detection",
        "authors": "Chaopeng Li, Jinlin Wang, Xiaozhou Ye",
        "published": "2018-5-27",
        "citations": 26,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14704/nq.2018.16.5.1391"
    },
    {
        "id": 8557,
        "title": "A note on restricted Boltzmann machines and variational autoencoders",
        "authors": "Jian Zhang",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijci.2019.098344"
    },
    {
        "id": 8558,
        "title": "Point-wise gated restricted Boltzmann machines using clean data",
        "authors": "Nan Zhang",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijci.2019.10019784"
    },
    {
        "id": 8559,
        "title": "A note on restricted Boltzmann machines and variational autoencoders",
        "authors": "Jian Zhang",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijci.2019.10019781"
    },
    {
        "id": 8560,
        "title": "κ-Entropy Based Restricted Boltzmann Machines",
        "authors": "Leandro Aparecido Passos, Marcos Cleison Santana, Thierry Moreira, Joao Paulo Papa",
        "published": "2019-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2019.8851714"
    },
    {
        "id": 8561,
        "title": "Functional Connectivity States of the Brain Using Restricted Boltzmann Machines",
        "authors": "Zeynep Kahraman, Selin Aviyente",
        "published": "2018-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp.2018.8461479"
    },
    {
        "id": 8562,
        "title": "&lt;strong&gt;Online Sequential Extreme Learning Machine: A New Training Scheme for Restricted Boltzmann Machines&lt;/strong&gt;",
        "authors": "BERGHOUT Tarek",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract: The main contribution of this paper is to introduce a new iterative training algorithm for restricted Boltzmann machines. The proposed learning path is inspired from online sequential extreme learning machine one of extreme learning machine variants which deals with time accumulated sequences of data with fixed or varied sizes. Recursive least squares rules are integrated for weights adaptation to avoid learning rate tuning and local minimum issues. The proposed approach is compared to one of the well known training algorithms for Boltzmann machines named &ldquo;contrastive divergence&rdquo;, in term of time, accuracy and algorithmic complexity under the same conditions. Results strongly encourage the new given rules during data reconstruction.",
        "link": "http://dx.doi.org/10.20944/preprints202005.0444.v1"
    },
    {
        "id": 8563,
        "title": "Point-wise gated restricted Boltzmann machines using clean data",
        "authors": "Nan Zhang",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijci.2019.098345"
    },
    {
        "id": 8564,
        "title": "Spectral dynamics of learning in restricted Boltzmann machines",
        "authors": "A. Decelle, G. Fissore, C. Furtlehner",
        "published": "2017-9-1",
        "citations": 26,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1209/0295-5075/119/60001"
    },
    {
        "id": 8565,
        "title": "Optimizing Throughput and Latency of Static 5G Multicast Networks using Boltzmann Machines",
        "authors": "Madhav Vadlamani, Vivek Saraswat, Udayan Ganguly",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191207"
    },
    {
        "id": 8566,
        "title": "Correction: Gaussian-binary restricted Boltzmann machines for modeling natural image statistics",
        "authors": "Jan Melchior, Nan Wang, Laurenz Wiskott",
        "published": "2017-3-15",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1371/journal.pone.0174289"
    },
    {
        "id": 8567,
        "title": "Minimax formula for the replica symmetric free energy of deep restricted Boltzmann machines",
        "authors": "Giuseppe Genovese",
        "published": "2023-6-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1214/22-aap1868"
    },
    {
        "id": 8568,
        "title": "Gaussian-binary restricted Boltzmann machines for modeling natural image statistics",
        "authors": "Jan Melchior, Nan Wang, Laurenz Wiskott",
        "published": "2017-2-2",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1371/journal.pone.0171015"
    },
    {
        "id": 8569,
        "title": "Unsupervised Synaptic Pruning Strategies for Restricted Boltzmann Machines",
        "authors": "Surabhi Kalyan, Siddharth Joshi, Sadique Sheik, Bruno U. Pedroni, Gert Cauwcnbcrghs",
        "published": "2018-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/biocas.2018.8584839"
    },
    {
        "id": 8570,
        "title": "LTD-RBM: Robust and Fast Latent Truth Discovery Using Restricted Boltzmann Machines",
        "authors": "Klaus Broelemann, Thomas Gottron, Gjergji Kasneci",
        "published": "2017-4",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icde.2017.60"
    },
    {
        "id": 8571,
        "title": "Graph signal recovery using restricted Boltzmann machines",
        "authors": "Ankith Mohan, Aiichiro Nakano, Emilio Ferrara",
        "published": "2021-12",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.eswa.2021.115635"
    },
    {
        "id": 8572,
        "title": "Generative Semantic Hashing Enhanced via Boltzmann Machines",
        "authors": "Lin Zheng, Qinliang Su, Dinghan Shen, Changyou Chen",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.acl-main.71"
    },
    {
        "id": 8573,
        "title": "Boltzmann Machines",
        "authors": "Wei Qi Yan",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-61081-4_7"
    },
    {
        "id": 8574,
        "title": "Mean-field Boltzmann machines for high-resolution Kirchhoff migration",
        "authors": "Janaki Vamaraju, Mrinal K. Sen",
        "published": "2018-8-27",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1190/segam2018-2997793.1"
    },
    {
        "id": 8575,
        "title": "On the Training Algorithms for Restricted Boltzmann Machines",
        "authors": "Leandro Aparecido Passos, João Paulo Papa",
        "published": "2019-10-28",
        "citations": 1,
        "abstract": "Deep learning techniques have been studied extensively in the last years due to their good results related to essential tasks on a large range of applications, such as speech and face recognition, as well as object classification. Restrict Boltzmann Machines (RBMs) are among the most employed techniques, which are energy-based stochastic neural networks composed of two layers of neurons whose objective is to estimate the connection weights between them. Recently, the scientific community spent much effort on sampling methods since the effectiveness of RBMs is directly related to the success of such a process. Thereby, this work contributes to studies concerning different training algorithms for RBMs, as well as its variants Deep Belief Networks and Deep Boltzmann Machines. Further, the work covers the application of meta-heuristic methods concerning a proper fine-tune of these techniques. Moreover, the validation of the model is presented in the context of image reconstruction and unsupervised feature learning. In general, we present different approaches to training these techniques, as well as the evaluation of meta-heuristic methods for fine-tuning parameters, and its main contributions are: (i) temperature parameter introduction in DBM formulation, (ii) DBM using adaptive temperature, (iii) DBM meta-parameter optimization through meta-heuristic techniques, and (iv) infinity Restricted Boltzmann Machine (iRBM) meta-parameters optimization through meta-heuristic techniques.",
        "link": "http://dx.doi.org/10.5753/sibgrapi.est.2019.8294"
    },
    {
        "id": 8576,
        "title": "Attention in a Family of Boltzmann Machines Emerging From Modern Hopfield Networks",
        "authors": "Toshihiro Ota, Ryo Karakida",
        "published": "2023-7-12",
        "citations": 0,
        "abstract": "Abstract\nHopfield networks and Boltzmann machines (BMs) are fundamental energy-based neural network models. Recent studies on modern Hopfield networks have broadened the class of energy functions and led to a unified perspective on general Hopfield networks, including an attention module. In this letter, we consider the BM counterparts of modern Hopfield networks using the associated energy functions and study their salient properties from a trainability perspective. In particular, the energy function corresponding to the attention module naturally introduces a novel BM, which we refer to as the attentional BM (AttnBM). We verify that AttnBM has a tractable likelihood function and gradient for certain special cases and is easy to train. Moreover, we reveal the hidden connections between AttnBM and some single-layer models, namely the gaussian–Bernoulli restricted BM and the denoising autoencoder with softmax units coming from denoising score matching. We also investigate BMs introduced by other energy functions and show that the energy function of dense associative memory models gives BMs belonging to exponential family harmoniums.",
        "link": "http://dx.doi.org/10.1162/neco_a_01597"
    },
    {
        "id": 8577,
        "title": "Algorithms for estimating the partition function of restricted Boltzmann machines",
        "authors": "Oswin Krause, Asja Fischer, Christian Igel",
        "published": "2020-1",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.artint.2019.103195"
    },
    {
        "id": 8578,
        "title": "Nonlinear Dynamic Boltzmann Machines for Time-Series Prediction",
        "authors": "Sakyasingha Dasgupta, Takayuki Osogami",
        "published": "2017-2-13",
        "citations": 24,
        "abstract": "\n      \n        The dynamic Boltzmann machine (DyBM) has been proposed as a stochastic generative model of multi-dimensional time series, with an exact, learning rule that maximizes the log-likelihood of a given time series.  The DyBM, however, is defined only for binary valued data, without any nonlinear hidden units. Here, in our first contribution, we extend the DyBM to deal with real valued data.  We present a formulation called Gaussian DyBM, that can be seen as an extension of a vector autoregressive (VAR) model. This uses, in addition to standard (explanatory) variables, components that captures long term dependencies in the time series. In our second contribution, we extend the Gaussian DyBM model with a recurrent neural network (RNN) that controls the bias input to the DyBM units. We derive a stochastic gradient update rule such that, the output weights from the RNN can also be trained online along with other DyBM parameters.  Furthermore, this acts as nonlinear hidden layer extending the capacity of DyBM and allows it to model nonlinear components in a given time-series. Numerical experiments with synthetic datasets show that the RNN-Gaussian DyBM improves predictive accuracy upon standard VAR  by up to 35%.  On real multi-dimensional time-series prediction, consisting of high nonlinearity and non-stationarity, we demonstrate that this nonlinear DyBM model achieves significant improvement upon state of the art baseline methods like VAR and long short-term memory (LSTM) networks at a reduced computational cost.\n      \n    ",
        "link": "http://dx.doi.org/10.1609/aaai.v31i1.10806"
    },
    {
        "id": 8579,
        "title": "Compression by and for Deep Boltzmann Machines",
        "authors": "Qing Li, Yang Chen, Yongjune Kim",
        "published": "2020-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tcomm.2020.3020796"
    },
    {
        "id": 8580,
        "title": "Boolean matrix factorization based on collaborative neurodynamic optimization with Boltzmann machines",
        "authors": "Xinqi Li, Jun Wang, Sam Kwong",
        "published": "2022-9",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neunet.2022.06.006"
    },
    {
        "id": 8581,
        "title": "Multi disease prediction based on combined deep reinforcement Boltzmann machines",
        "authors": " Vetrithangam, Aruna Devi, Shruti Aggarwal",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/5.0108952"
    },
    {
        "id": 8582,
        "title": "Accuracy of restricted Boltzmann machines for the one-dimensional  $J_1-J_2$ Heisenberg model",
        "authors": "Luciano Loris Viteritti, Francesco Ferrari, Federico Becca",
        "published": "2022-5-19",
        "citations": 7,
        "abstract": "Neural networks have been recently proposed as variational wave functions for quantum many-body systems [G. Carleo and M. Troyer, Science \n355, 602 (2017)]. In this work, we focus on a specific architecture, known as restricted Boltzmann machine (RBM), and analyse its accuracy \nfor the spin-1/2 J_1-J_2J1−J2\nantiferromagnetic Heisenberg model in one spatial dimension. The ground\nstate of this model has a non-trivial sign structure, especially for\nJ_2/J_1>0.5J2/J1>0.5,\nforcing us to work with complex-valued RBMs. Two variational  Ansätze are\ndiscussed: one defined\nthrough a fully complex RBM, and one in which two different real-valued networks are used to approximate modulus and phase of the wave function. \nIn both cases, translational invariance is imposed by considering linear combinations of RBMs, giving access also to the lowest-energy excitations \nat fixed momentum k. We perform a systematic study on small clusters to evaluate the accuracy of these wave functions in comparison to exact \nresults, providing evidence for the supremacy of the fully complex RBM. Our calculations show that this kind of  Ansätze is very flexible \nand describes both gapless and gapped ground states, also capturing the incommensurate spin-spin correlations and low-energy spectrum for \nJ_2/J_1>0.5J2/J1>0.5. The RBM results are also compared to the ones obtained with Gutzwiller-projected fermionic states, often employed to describe \nquantum spin models [F. Ferrari, A. Parola, S. Sorella and F. Becca, Phys. Rev. B  97, 235103 (2018)]. Contrary to the latter class of \nvariational states, the fully-connected structure of RBMs hampers the transferability of the wave function from small to large clusters, implying \nan increase in the computational cost with the system size. ",
        "link": "http://dx.doi.org/10.21468/scipostphys.12.5.166"
    },
    {
        "id": 8583,
        "title": "Empirical Bayes Method for Boltzmann Machines",
        "authors": "Muneki Yasuda",
        "published": "2022",
        "citations": 0,
        "abstract": "AbstractThe framework of the empirical Bayes method allows the estimation of the values of the hyperparameters in the Boltzmann machine by maximizing a specific likelihood function referred to as the empirical Bayes likelihood function. However, the maximization is computationally difficult because the empirical Bayes likelihood function involves intractable integrations of the partition function. The method presented in this chapter avoids this computational problem by using the replica method and the Plefka expansion, which is quite simple and fast because it does not require any iterative procedures and gives reasonable estimates under certain conditions.",
        "link": "http://dx.doi.org/10.1007/978-981-16-4095-7_11"
    },
    {
        "id": 8584,
        "title": "The Smart Predictive Analysis of Stock Market Performance using Restricted Boltzmann Machines",
        "authors": "Rekha Devrani, Prerna Mahajan, Dinesh Kumar",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470921"
    },
    {
        "id": 8585,
        "title": "Probabilistic abstract argumentation: An investigation with Boltzmann machines",
        "authors": "Régis Riveret, Dimitrios Korkinof, Moez Draief, Jeremy Pitt",
        "published": "2017-5-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3233/aac-170016"
    },
    {
        "id": 8586,
        "title": "Algorithms for Estimating the Partition Function of Restricted Boltzmann Machines (Extended Abstract)",
        "authors": "Oswin Krause, Asja Fischer, Christian Igel",
        "published": "2020-7",
        "citations": 0,
        "abstract": "Estimating the normalization constants (partition functions) of energy-based probabilistic models (Markov random fields) with a high accuracy is required for measuring  performance, monitoring the training progress of adaptive models, and conducting likelihood ratio tests.   We devised a unifying theoretical framework for algorithms for estimating the partition function, including Annealed Importance Sampling (AIS) and Bennett's Acceptance Ratio method (BAR).  The unification reveals  conceptual similarities of and differences between  different approaches and suggests new algorithms. The framework is  based on a generalized form of Crooks' equality, which links the expectation over a distribution of samples generated by a transition operator to the expectation over the distribution induced by the reversed operator.  \n\nDifferent ways of sampling, such as parallel\n\ntempering and path sampling, are covered by the framework.  \n\nWe performed experiments in which we estimated the partition function of restricted Boltzmann\n\nmachines (RBMs) and Ising models. We found that BAR using parallel\n\ntempering worked well with a small number of bridging distributions,\n\nwhile path sampling based AIS performed best with many bridging\n\ndistributions.  The normalization constant is measured w.r.t.~a reference distribution, and the choice of this distribution turned out to be very important in our experiments.\n\nOverall, BAR gave the  best empirical results, outperforming AIS.",
        "link": "http://dx.doi.org/10.24963/ijcai.2020/704"
    },
    {
        "id": 8587,
        "title": "Improving the Robustness of Trading Strategy Backtesting with Boltzmann Machines and Generative Adversarial Networks",
        "authors": "Edmond Lezmi, Jules Roche, Thierry Roncalli, Jiali Xu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3645473"
    },
    {
        "id": 8588,
        "title": "Sound quality evaluation of electronic expansion valve using Gaussian restricted Boltzmann machines based DBN",
        "authors": "Bin. Zhao, Cheng J. Wu",
        "published": "2020-12",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.apacoust.2020.107493"
    },
    {
        "id": 8589,
        "title": "Thermodynamics of the Ising Model Encoded in Restricted Boltzmann Machines",
        "authors": "Jing Gu, Kai Zhang",
        "published": "2022-11-22",
        "citations": 2,
        "abstract": "The restricted Boltzmann machine (RBM) is a two-layer energy-based model that uses its hidden–visible connections to learn the underlying distribution of visible units, whose interactions are often complicated by high-order correlations. Previous studies on the Ising model of small system sizes have shown that RBMs are able to accurately learn the Boltzmann distribution and reconstruct thermal quantities at temperatures away from the critical point Tc. How the RBM encodes the Boltzmann distribution and captures the phase transition are, however, not well explained. In this work, we perform RBM learning of the 2d and 3d Ising model and carefully examine how the RBM extracts useful probabilistic and physical information from Ising configurations. We find several indicators derived from the weight matrix that could characterize the Ising phase transition. We verify that the hidden encoding of a visible state tends to have an equal number of positive and negative units, whose sequence is randomly assigned during training and can be inferred by analyzing the weight matrix. We also explore the physical meaning of the visible energy and loss function (pseudo-likelihood) of the RBM and show that they could be harnessed to predict the critical point or estimate physical quantities such as entropy.",
        "link": "http://dx.doi.org/10.3390/e24121701"
    },
    {
        "id": 8590,
        "title": "Application of Exchanging Monte Carlo Method to Sample Deep Boltzmann Machines",
        "authors": "Hiroki Shibata, Lieu-Hen Chen, Yasufumi Takama",
        "published": "2020-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/taai51410.2020.00020"
    },
    {
        "id": 8591,
        "title": "Quantum image denoising: a framework via Boltzmann machines, QUBO, and quantum annealing",
        "authors": "Phillip Kerger, Ryoji Miyazaki",
        "published": "2023-10-19",
        "citations": 0,
        "abstract": "We investigate a framework for binary image denoising via restricted Boltzmann machines (RBMs) that introduces a denoising objective in quadratic unconstrained binary optimization (QUBO) form well-suited for quantum annealing. The denoising objective is attained by balancing the distribution learned by a trained RBM with a penalty term for derivations from the noisy image. We derive the statistically optimal choice of the penalty parameter assuming the target distribution has been well-approximated, and further suggest an empirically supported modification to make the method robust to that idealistic assumption. We also show under additional assumptions that the denoised images attained by our method are, in expectation, strictly closer to the noise-free images than the noisy images are. While we frame the model as an image denoising model, it can be applied to any binary data. As the QUBO formulation is well-suited for implementation on quantum annealers, we test the model on a D-Wave Advantage machine, and also test on data too large for current quantum annealers by approximating QUBO solutions through classical heuristics.",
        "link": "http://dx.doi.org/10.3389/fcomp.2023.1281100"
    },
    {
        "id": 8592,
        "title": "Gaussian-spherical restricted Boltzmann machines",
        "authors": "Aurélien Decelle, Cyril Furtlehner",
        "published": "2020-5-11",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1088/1751-8121/ab79f3"
    },
    {
        "id": 8593,
        "title": "Information and Regularization in Restricted Boltzmann Machines",
        "authors": "Matias Vera, Leonardo Rey Vega, Pablo Piantanida",
        "published": "2021-6-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp39728.2021.9414497"
    },
    {
        "id": 8594,
        "title": "Information Perspective to Probabilistic Modeling: Boltzmann Machines versus Born Machines",
        "authors": "Song Cheng, Jing Chen, Lei Wang",
        "published": "2018-8-7",
        "citations": 61,
        "abstract": "We compare and contrast the statistical physics and quantum physics inspired approaches for unsupervised generative modeling of classical data. The two approaches represent probabilities of observed data using energy-based models and quantum states, respectively. Classical and quantum information patterns of the target datasets therefore provide principled guidelines for structural design and learning in these two approaches. Taking the Restricted Boltzmann Machines (RBM) as an example, we analyze the information theoretical bounds of the two approaches. We also estimate the classical mutual information of the standard MNIST datasets and the quantum Rényi entropy of corresponding Matrix Product States (MPS) representations. Both information measures are much smaller compared to their theoretical upper bound and exhibit similar patterns, which imply a common inductive bias of low information complexity. By comparing the performance of RBM with various architectures on the standard MNIST datasets, we found that the RBM with local sparse connection exhibit high learning efficiency, which supports the application of tensor network states in machine learning problems.",
        "link": "http://dx.doi.org/10.3390/e20080583"
    },
    {
        "id": 8595,
        "title": "Service recommendation using conditional restricted Boltzmann machines",
        "authors": "Zhongjie Wang, Tianyang Li, Ting He",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijstm.2019.10021885"
    },
    {
        "id": 8596,
        "title": "Service recommendation using conditional restricted Boltzmann machines",
        "authors": "Tianyang Li, Ting He, Zhongjie Wang",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1504/ijstm.2019.101896"
    },
    {
        "id": 8597,
        "title": "Data-driven study of mouse sleep-stages using Restricted Boltzmann Machines",
        "authors": "Vasiliki-Maria Katsageorgiou, Matteo Zanotto, Valter Tucci, Vittorio Murino, Diego Sona",
        "published": "2017-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2017.7966433"
    },
    {
        "id": 8598,
        "title": "Legendre equivalences of spherical Boltzmann machines",
        "authors": "Giuseppe Genovese, Daniele Tantari",
        "published": "2020-3-6",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1088/1751-8121/ab6b92"
    },
    {
        "id": 8599,
        "title": "Deep Learning and Limited Boltzmann Machines for Speaker Recognition",
        "authors": "Et al. P.Mathiyalagan",
        "published": "2023-1-31",
        "citations": 0,
        "abstract": "Speaker recognition has become an essential aspect of modern voice-based systems such as security and authentication applications. In this research, we propose a new method for speaker recognition based on deep learning and limited Boltzmann machines. The method comprises preemphasis and overlapping type framing, endpoint detection, feature extraction, and training of a depth belief network pattern using a limited Boltzmann machine layer. The Softmax graders are added in the top layer of the pattern, and the speaker's phonetic feature is input into the pattern for training. The likelihood probability of other speakers' phonetic features is calculated, and the speaker corresponding to the maximum probability is identified as the recognized result. The results show that the proposed method outperforms other state-of-the-art methods, achieving high accuracy and robustness to noise and signal variations.",
        "link": "http://dx.doi.org/10.17762/ijritcc.v11i1.9820"
    },
    {
        "id": 8600,
        "title": "Restricted Boltzmann machines in quantum physics",
        "authors": "Roger G. Melko, Giuseppe Carleo, Juan Carrasquilla, J. Ignacio Cirac",
        "published": "2019-9",
        "citations": 115,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1038/s41567-019-0545-1"
    }
]