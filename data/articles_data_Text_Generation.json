[
    {
        "id": 11171,
        "title": "Data-to-Text Generation with Iterative Text Editing",
        "authors": "Zdeněk Kasner, Ondřej Dušek",
        "published": "2020",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.inlg-1.9"
    },
    {
        "id": 11172,
        "title": "TUDA-Reproducibility @ ReproGen: Replicability of Human Evaluation of Text-to-Text and Concept-to-Text Generation",
        "authors": "Christian Richter, Yanran Chen, Steffen Eger",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.inlg-1.32"
    },
    {
        "id": 11173,
        "title": "TCTG:A Controllable Text Generation Method Using Text to Control Text Generation",
        "authors": "Liang Xuyuan, Tian Lihua, Li Chen",
        "published": "2021-10-22",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icsip52628.2021.9688767"
    },
    {
        "id": 11174,
        "title": "Generation of Company descriptions using concept-to-text and text-to-text deep models: dataset collection and systems evaluation",
        "authors": "Raheel Qader, Khoder Jneid, François Portet, Cyril Labbé",
        "published": "2018",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-6532"
    },
    {
        "id": 11175,
        "title": "Text-in-Context: Token-Level Error Detection for Table-to-Text Generation",
        "authors": "Zdeněk Kasner, Simon Mille, Ondřej Dušek",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.inlg-1.25"
    },
    {
        "id": 11176,
        "title": "Text-to-Text Pre-Training for Data-to-Text Tasks",
        "authors": "Mihir Kale, Abhinav Rastogi",
        "published": "2020",
        "citations": 17,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.inlg-1.14"
    },
    {
        "id": 11177,
        "title": "Personalized Persuasive Text Generation",
        "authors": "Mansoureh Motahari Nezhad, Mohammadreza Kangavari",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4453018"
    },
    {
        "id": 11178,
        "title": "Arabic Text to Image Generation Tasks",
        "authors": "Mourad BAHANI",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nCurrent AI systems have shown impressive results in the Automatic synthesis realistic images from texts descriptions tasks. In fact, Generative Adversarial Networks (GANs) are used mostly in this tasks. The Generator generates realistic images given noise and sentence vectors, and the discriminator produce a probability of how the synthetic images are reals. In this paper, in order to generate images from Arabic text, we fuse DF-GAN as a sample and efficient text-to-image generation framework and AraBERT architecture. To achieve this purpose, firstly, we re-create new datasets matching the Arabic text-to-image generation task by applying DeepL-Translator from English to Arabic on texts descriptions of original datasets. Secondly, we leverage the power of AraBERT which is trained on billions of Arabic words to produce a strong sentence embedding, and we reduce that vector's dimension to match with DF-GAN shape. Thirdly, we inject the reduced sentence embedding into the UPBlocks sections of DF-GAN and we train the proposed architecture on two challenging datasets. Following the previous works, we use CUB and Oxford-102 flowers as original datasets. Further, we measure our framework with FID and IS. Our framework is the first that achieve much success in generating high-resolution realistic and text matching images conditioned with Arabic text.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2163664/v1"
    },
    {
        "id": 11179,
        "title": "A Review of Generative Adversarial Networks in Text Generation",
        "authors": "Jaden Cohen",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.58445/rars.975"
    },
    {
        "id": 11180,
        "title": "Improving Text Generation for Product Description via Human Behaviour",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "Text generation is an important method to generate high quality and available product description from product title. For the product description generation for online E-commerce application, the main problem is how to improve the quality of generated text. In other words, how we judge the quality of text. If all texts are already positive and available, then we find it impossible to manually judge which text is the better text for a product. So if we cannot judge which is a better text manually, we cannot improve the quality of generated text. In E-commerce, product description is to attract shoppers and improve sales. So we design a method to improve the quality of generated text based on user buying behaviour. Online result shows that our approach improve the sales of products by improving the text quality.",
        "link": "http://dx.doi.org/10.36227/techrxiv.170846525.55626336/v1"
    },
    {
        "id": 11181,
        "title": "Unsupervised Code-switched Text Generation from Parallel Text",
        "authors": "Jie Chi, Brian Lu, Jason Eisner, Peter Bell, Preethi Jyothi, Ahmed M. Ali",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1050"
    },
    {
        "id": 11182,
        "title": "Domain-Specific Text Generation for Arabic Text Summarization",
        "authors": "Jezia Zakraoui, Jihad Mohamed AlJa'am, Imad Salah",
        "published": "2022-12-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icca56443.2022.10039630"
    },
    {
        "id": 11183,
        "title": "Analysing Data-To-Text Generation Benchmarks",
        "authors": "Laura Perez-Beltrachini, Claire Gardent",
        "published": "2017",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w17-3537"
    },
    {
        "id": 11184,
        "title": "Domain-independent Data-to-Text Generation for Open Data",
        "authors": "Andreas Burgdorf, Micaela Barkmann, André Pomp, Tobias Meisen",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011272900003269"
    },
    {
        "id": 11185,
        "title": "Text Generation for Imbalanced Text Classification",
        "authors": "Suphamongkol Akkaradamrongrat, Pornpimon Kachamas, Sukree Sinthupinyo",
        "published": "2019-7",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/jcsse.2019.8864181"
    },
    {
        "id": 11186,
        "title": "Revisiting Challenges in Data-to-Text Generation with Fact Grounding",
        "authors": "Hongmin Wang",
        "published": "2019",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-8639"
    },
    {
        "id": 11187,
        "title": "Exploring Structural Encoding for Data-to-Text Generation",
        "authors": "Joy Mahapatra, Utpal Garain",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.inlg-1.44"
    },
    {
        "id": 11188,
        "title": "Handling Rare Items in Data-to-Text Generation",
        "authors": "Anastasia Shimorina, Claire Gardent",
        "published": "2018",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-6543"
    },
    {
        "id": 11189,
        "title": "Text-To-Image Generation Using AI",
        "authors": "Pavithra V, Rosy S, Srinishanthini R B, Prinslin L",
        "published": "2023-4-27",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.55248/gengpi.234.4.38568"
    },
    {
        "id": 11190,
        "title": "Controlled Text Generation with Adversarial Learning",
        "authors": "Federico Betti, Giorgia Ramponi, Massimo Piccardi",
        "published": "2020",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.inlg-1.5"
    },
    {
        "id": 11191,
        "title": "Review for \"Ethical implications of text generation in the age of artificial intelligence\"",
        "authors": "",
        "published": "2022-2-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/beer.12479/v1/review1"
    },
    {
        "id": 11192,
        "title": "Review for \"Ethical implications of text generation in the age of artificial intelligence\"",
        "authors": "",
        "published": "2022-6-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/beer.12479/v2/review1"
    },
    {
        "id": 11193,
        "title": "Automatic Question Generation from Indonesian Texts Using Text-to-Text Transformers",
        "authors": "Mukhlish Fuadi, Adhi Dharma Wibawa",
        "published": "2022-9-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ieit56384.2022.9967858"
    },
    {
        "id": 11194,
        "title": "Procedural Text Generation from a Photo Sequence",
        "authors": "Taichi Nishimura, Atsushi Hashimoto, Shinsuke Mori",
        "published": "2019",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-8650"
    },
    {
        "id": 11195,
        "title": "Political Event Coding as Text-to-Text Sequence Generation",
        "authors": "Yaoyao Dai, Benjamin Radford, Andrew Halterman",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.case-1.16"
    },
    {
        "id": 11196,
        "title": "Self-Training from Self-Memory in Data-to-Text Generation",
        "authors": "Hoang Thang Ta",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4719908"
    },
    {
        "id": 11197,
        "title": "Tf-Gan: Text Feature Fusion Gan for Text-to-Image Generation",
        "authors": "Xiaoyan Jiang, Zhijun Fang, Jize Chen, Hamido Fujita",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4280052"
    },
    {
        "id": 11198,
        "title": "Generation of Fine-Grained Movie Reviews – Text Segmentation and Sentiment Analysis",
        "authors": "Sree Renjini D.",
        "published": "2020-3-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5373/jardcs/v12sp4/20201549"
    },
    {
        "id": 11199,
        "title": "Text Generation",
        "authors": "Li Zhang, Jian-Tao Sun",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4614-8265-9_416"
    },
    {
        "id": 11200,
        "title": "EGAN: Generatives Adversarial Networks for Text Generation with Sentiments",
        "authors": "Andres Pautrat-Lertora, Renzo Perez-Lozano, Willy Ugarte",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011548100003335"
    },
    {
        "id": 11201,
        "title": "The Code2Text Challenge: Text Generation in Source Libraries",
        "authors": "Kyle Richardson, Sina Zarrieß, Jonas Kuhn",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w17-3516"
    },
    {
        "id": 11202,
        "title": "Text Generation",
        "authors": "Özgür Sahin",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6421-8_4"
    },
    {
        "id": 11203,
        "title": "Controllable Sentence Simplification with a Unified Text-to-Text Transfer Transformer",
        "authors": "Kim Cheng Sheang, Horacio Saggion",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.inlg-1.38"
    },
    {
        "id": 11204,
        "title": "Automatically Ranked Russian Paraphrase Corpus for Text Generation",
        "authors": "Vadim Gudkov, Olga Mitrofanova, Elizaveta Filippskikh",
        "published": "2020",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.ngt-1.6"
    },
    {
        "id": 11205,
        "title": "Boosting Text Classification Performance on Sexist Tweets by Text Augmentation and Text Generation Using a Combination of Knowledge Graphs",
        "authors": "Sima Sharifirad, Borna Jafarpour, Stan Matwin",
        "published": "2018",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-5114"
    },
    {
        "id": 11206,
        "title": "Enhanced Transformer Model for Data-to-Text Generation",
        "authors": "Li GONG, Josep Crego, Jean Senellart",
        "published": "2019",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-5615"
    },
    {
        "id": 11207,
        "title": "Text Generation and Processing",
        "authors": "Kyle Gorman, Richard Sproat",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-02179-4_7"
    },
    {
        "id": 11208,
        "title": "Automatic FAQ Generation Using Text-to-Text Transformer Model",
        "authors": "Santosh Vasisht, Varun Tirthani, Akhil Eppa, Punit Koujalgi, Ramamoorthy Srinath",
        "published": "2022-5-27",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/incet54531.2022.9823967"
    },
    {
        "id": 11209,
        "title": "Expressive Text-to-Image Generation with Rich Text",
        "authors": "Songwei Ge, Taesung Park, Jun-Yan Zhu, Jia-Bin Huang",
        "published": "2023-10-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00694"
    },
    {
        "id": 11210,
        "title": "Language Agnostic Gesture Generation Model: A Case Study of Japanese Speakers' Gesture Generation Using English Text-to-Gesture Model",
        "authors": "Genki Sakata, Naoshi Kaneko, Dai Hasegawa, Shinichi Shirakawa",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011643600003417"
    },
    {
        "id": 11211,
        "title": "How to Imagine the World with Text? From Text-to-image Generation View",
        "authors": "Jingyi Liu",
        "published": "2023-4-1",
        "citations": 0,
        "abstract": "Words are an effective and convenient way to describe the world, but sometimes what the texts convey may be misunderstood by readers. The expression of pictures is more vivid, easy to understand and has no borders, but creating a painting often takes a long time. Text-to-image makes the two expressions complement each other: It makes every ordinary person a “painter”, so that they can feel the world, express themselves, and create more whimsy through many rich pictures. For this vision, technologists are trying their best to improve image generation models, which enables computers to generate high quality images with texts better. And they are solving some technical defects, for instance, sometimes the content of generated images is strange. In the future, text-to-image can be adapted to applications in AI such as computer-aided design, image editing, and be employed in the field of art such as movies and artworks, and then it may even make a big difference on people's life, enriching the public's spiritual world and conveying information by vivid images.",
        "link": "http://dx.doi.org/10.54097/hset.v39i.6619"
    },
    {
        "id": 11212,
        "title": "Ssd: Towards Better Text-Image Consistency Metric in Text-to-Image Generation",
        "authors": "Zhaorui Tan, Xi Yang, Zihan Ye, Qiufeng Wang, Yuyao Yan, Anh Nguyen, Kaizhu Huang",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4332128"
    },
    {
        "id": 11213,
        "title": "Towards Cross-Domain Transferability of Text Generation Models for Legal Text",
        "authors": "Vinayshekhar Bannihatti Kumar, Kasturi Bhattacharjee, Rashmi Gangadharaiah",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.nllp-1.9"
    },
    {
        "id": 11214,
        "title": "Estimating the scale of biomedical data generation using text mining",
        "authors": "Gabriel Rosenfeld, Dawei Lin",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractWhile the impact of biomedical research has traditionally been measured using bibliographic metrics such as citation or journal impact factor, the data itself is an output which can be directly measured to provide additional context about a publication’s impact. Data are a resource that can be repurposed and reused providing dividends on the original investment used to support the primary work. Moreover, it is the cornerstone upon which a tested hypothesis is rejected or accepted and specific scientific conclusions are reached. Understanding how and where it is being produced enhances the transparency and reproducibility of the biomedical research enterprise. Most biomedical data are not directly deposited in data repositories and are instead found in the publication within figures or attachments making it hard to measure. We attempted to address this challenge by using recent advances in word embedding to identify the technical and methodological features of terms used in the free text of articles’ methods sections. We created term usage signatures for five types of biomedical research data, which were used in univariate clustering to correctly identify a large fraction of positive control articles and a set of manually annotated articles where generation of data types could be validated. The approach was then used to estimate the fraction of PLOS articles generating each biomedical data type over time. Out of all PLOS articles analyzed (n = 129,918), ~7%, 19%, 12%, 18%, and 6% generated flow cytometry, immunoassay, genomic microarray, microscopy, and high-throughput sequencing data. The estimate portends a vast amount of biomedical data being produced: in 2016, if other publishers generated a similar amount of data then roughly 40,000 NIH-funded research articles would produce ~56,000 datasets consisting of the five data types we analyzed.One Sentence SummaryApplication of a word-embedding model trained on the methods sections of research articles allows for estimation of the production of diverse biomedical data types using text mining.",
        "link": "http://dx.doi.org/10.1101/182857"
    },
    {
        "id": 11215,
        "title": "Automatic Logical Forms Improve Fidelity in Table-to-Text Generation",
        "authors": "Iñigo Alonso, Eneko Agirre",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4432475"
    },
    {
        "id": 11216,
        "title": "Automatic Text Generation",
        "authors": "André Klahold, Madjid Fathi",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-27439-9_10"
    },
    {
        "id": 11217,
        "title": "Feature Generation in Text Mining",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_100165"
    },
    {
        "id": 11218,
        "title": "Text Generation for Dataset Augmentation in Security Classification Tasks",
        "authors": "Alexander  Paul Welsh, Matthew Edwards",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4616394"
    },
    {
        "id": 11219,
        "title": "Biomedical Data-to-Text Generation via Fine-Tuning Transformers",
        "authors": "Ruslan Yermakov, Nicholas Drago, Angelo Ziletti",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.inlg-1.40"
    },
    {
        "id": 11220,
        "title": "Deep Graph Convolutional Encoders for Structured Data to Text Generation",
        "authors": "Diego Marcheggiani, Laura Perez-Beltrachini",
        "published": "2018",
        "citations": 30,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-6501"
    },
    {
        "id": 11221,
        "title": "Review for \"Ethical implications of text generation in the age of artificial intelligence\"",
        "authors": "Cristina Neesham",
        "published": "2022-7-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/beer.12479/v2/review2"
    },
    {
        "id": 11222,
        "title": "Semi-Supervised Neural Text Generation by Joint Learning of Natural Language Generation and Natural Language Understanding Models",
        "authors": "Raheel Qader, François Portet, Cyril Labbé",
        "published": "2019",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-8669"
    },
    {
        "id": 11223,
        "title": "Text-to-Classic: A Diffusion Method for Classical Art Generation Based on Text",
        "authors": "Yi Li",
        "published": "2023-3-17",
        "citations": 0,
        "abstract": "Text-to-Image generation has recently become a hot research topic and diffusion models have achieved remarkable performance in this task. However, most previous researches aim at real scene generation. Few researches focus on classical art paintings. Besides, diffusion models are commonly heavy-weighted with a large number of parameters, which has a high computational cost. In this paper, we aim to solve the classical art paintings synthesis subtask. We propose a lightweight diffusion model Text-to-Classic(T2C) to synthesize classical art paintings according to text descriptions. Experiment results show that our method can achieve good performance with fewer parameters.",
        "link": "http://dx.doi.org/10.54097/fcis.v3i1.6030"
    },
    {
        "id": 11224,
        "title": "Guided Beam Search to Improve Generalization in Low-Resource Data-to-Text Generation",
        "authors": "Nicolas Garneau, Luc Lamontagne",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.inlg-main.1"
    },
    {
        "id": 11225,
        "title": "On Improving Text Generation Via Integrating Text Coherence",
        "authors": "Lisi Ai, Baoli Gao, Jianbing Zheng, Ming Gao",
        "published": "2019-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ccis48116.2019.9073682"
    },
    {
        "id": 11226,
        "title": "Evaluating Semantic Accuracy of Data-to-Text Generation with Natural Language Inference",
        "authors": "Ondřej Dušek, Zdeněk Kasner",
        "published": "2020",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.inlg-1.19"
    },
    {
        "id": 11227,
        "title": "Reducing Non-Normative Text Generation from Language Models",
        "authors": "Xiangyu Peng, Siyan Li, Spencer Frazier, Mark Riedl",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.inlg-1.43"
    },
    {
        "id": 11228,
        "title": "Multilingual Social Media Text Generation and Evaluation with Few-Shot Prompting",
        "authors": "Mack Blackburn",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gem-1.39"
    },
    {
        "id": 11229,
        "title": "Control Prefixes for Parameter-Efficient Text Generation",
        "authors": "Jordan Clive, Kris Cao, Marek Rei",
        "published": "2022",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gem-1.31"
    },
    {
        "id": 11230,
        "title": "Domain Specific Automatic Question Generation from Text",
        "authors": "Katira Soleymanzadeh",
        "published": "2017",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/p17-3014"
    },
    {
        "id": 11231,
        "title": "Decision letter for \"Ethical implications of text generation in the age of artificial intelligence\"",
        "authors": "",
        "published": "2022-7-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/beer.12479/v2/decision1"
    },
    {
        "id": 11232,
        "title": "Towards Adversarial Genetic Text Generation",
        "authors": "Deniz Kavi",
        "published": "2021-3-27",
        "citations": 0,
        "abstract": "Text generation is the task of generating natural language, and producing outputs similar to or better than human texts. Due to deep learning’s recent success in the field of natural language processing, computer generated text has come closer to becoming indistinguishable to human writing. Genetic Algorithms have not been as popular in the field of text generation. We propose a genetic algorithm combined with text classification and clustering models which automatically grade the texts generated by the genetic algorithm. The genetic algorithm is given poorly generated texts from a Markov chain, these texts are then graded by a text classifier and a text clustering model. We then apply crossover to pairs of texts, with emphasis on those that received higher grades. Changes to the grading system and further improvements to the genetic algorithm are to be the focus of future research.",
        "link": "http://dx.doi.org/10.5121/csit.2021.110407"
    },
    {
        "id": 11233,
        "title": "TWT: Table with Written Text for Controlled Data-to-Text Generation",
        "authors": "Tongliang Li, Lei Fang, Jian-Guang Lou, Zhoujun Li",
        "published": "2021",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-emnlp.107"
    },
    {
        "id": 11234,
        "title": "Cross-modal text and visual generation: A systematic review. Part 1: Image to text",
        "authors": "Maciej Żelaszczyk, Jacek Mańdziuk",
        "published": "2023-5",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.inffus.2023.01.008"
    },
    {
        "id": 11235,
        "title": "Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis",
        "authors": "Jun-Min Lee, Tae-Bin Ha",
        "published": "2023-10-24",
        "citations": 0,
        "abstract": "Generative Adversarial Networks (GAN) is a model for data synthesis, which creates plausible data through the competition of generator and discriminator. Although GAN application to image synthesis is extensively studied, it has inherent limitations to natural language generation. Because natural language is composed of discrete tokens, a generator has difficulty updating its gradient through backpropagation; therefore, most text-GAN studies generate sentences starting with a random token based on a reward system. Thus, the generators of previous studies are pre-trained in an autoregressive way before adversarial training, causing data memorization that synthesized sentences reproduce the training data. In this paper, we synthesize sentences using a framework similar to the original GAN. More specifically, we propose Text Embedding Space Generative Adversarial Networks (TESGAN) which generate continuous text embedding spaces instead of discrete tokens to solve the gradient backpropagation problem. Furthermore, TESGAN conducts unsupervised learning which does not directly refer to the text of the training data to overcome the data memorization issue. By adopting this novel method, TESGAN can synthesize new sentences, showing the potential of unsupervised learning for text synthesis. We expect to see extended research combining Large Language Models with a new perspective of viewing text as an continuous space.",
        "link": "http://dx.doi.org/10.3384/nejlt.2000-1533.2023.4855"
    },
    {
        "id": 11236,
        "title": "Decision letter for \"Ethical implications of text generation in the age of artificial intelligence\"",
        "authors": "",
        "published": "2022-2-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/beer.12479/v1/decision1"
    },
    {
        "id": 11237,
        "title": "Decision letter for \"Ethical implications of text generation in the age of artificial intelligence\"",
        "authors": "",
        "published": "2022-8-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/beer.12479/v3/decision1"
    },
    {
        "id": 11238,
        "title": "Hybridization of Intelligent Solutions Architecture for Text Understanding and Text Generation",
        "authors": "Anton Ivaschenko, Arkadiy Krivosheev, Anastasia Stolbova, Oleg Golovnin",
        "published": "2021-6-2",
        "citations": 5,
        "abstract": "This study proposes a new logical model for intelligent software architecture devoted to improving the efficiency of automated text understanding and text generation in industrial applications. The presented approach introduces a few patterns that provide a possibility to build adaptable and extensible solutions using machine learning technologies. The main idea is formalized by the concept of expounder hybridization. It summarizes an experience of document analysis and generation solutions development and social media analysis based on artificial neural networks’ practical use. The results of solving the task by the best expounder were improved using the method of aggregating multiple expounders. The quality of expounders’ combination can be further improved by introducing the pro-active competition between them on the basis of, e.g., auctioning algorithm, using several parameters including precision, solution performance and score. Analysis of the proposed approach was carried out using a dataset of legal documents including joint-stock company decision record sheets and protocols. The solution is implemented in an enterprise content management system and illustrated by an example of processing of legal documentation.",
        "link": "http://dx.doi.org/10.3390/app11115179"
    },
    {
        "id": 11239,
        "title": "Controlling keywords and their positions in text generation",
        "authors": "Yuichi Sasazawa, Terufumi Morishita, Hiroaki Ozaki, Osamu Imaichi, Yasuhiro Sogawa",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.inlg-main.29"
    },
    {
        "id": 11240,
        "title": "Classification of compressed and uncompressed text documents",
        "authors": "S.N. Bharath Bhushan, Ajit Danti",
        "published": "2018-11",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.future.2018.04.054"
    },
    {
        "id": 11241,
        "title": "A Study on Text Rank Algorithm for Automatic Text Summarization and Question Generation",
        "authors": "G. Deena",
        "published": "2021-12-31",
        "citations": 0,
        "abstract": "This paper proposes a new rule-based approach to automated question generation. The proposed approach focuses on the analysis of both sentence syntax and semantic structure. The design and implementation of the proposed approach is also described in detail. Although the primary purpose of a design system is to generate query from sentences, automated evaluation results show that it can also perform great when reading comprehension datasets that focus on question output from paragraphs. With regard to human evaluation, the designed system performs better than all other systems and generates the most natural (human-like) questions. We present a fresh approach to automatic question generation that significantly increases the percentage of acceptable questions compared to prior state-of-the-art systems. In our system, we will take data from various sources for a particular topic and summarize it for the convenience of the people, so that they don't have to go through so multiple sites for relevant data.",
        "link": "http://dx.doi.org/10.48175/ijarsct-2302"
    },
    {
        "id": 11242,
        "title": "Text Recognition on Khmer Historical Documents using Glyph Class Map Generation with Encoder-Decoder Model",
        "authors": "Dona Valy, Michel Verleysen, Sophea Chhun",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007555507490756"
    },
    {
        "id": 11243,
        "title": "Automatic generation of a text forecast along a track",
        "authors": "Einar H. Guðmundsson, Ólafur Rögnvaldsson, Karolina Stanislawska",
        "published": "No Date",
        "citations": 0,
        "abstract": "Belgingur Ltd. has created a novel weather forecasting framework,&#160;called Weather On Demand &#8211; WOD, that can be deployed in the cloud and&#160;customised for any location world-wide at a very short notice.&#160;A recent addition to the WOD system is a routing forecast option that generates a simple text forecast along a track provided by the end-user.&#160;The process is such that a user provides a list of coordinates, where each coordinate pair is accompanied by a timestamp, via an API.Points of interest are identified along the track. Most commonly these points are the locations of weather stations, as they are generally placed where weather conditions are of interest and the WOD system has additional machine learning interpolation mechanisms in development for weather stations. From this set, along with on-the-hour locations, a representative, refined, lower resolution track is assembled, for which high-resolution forecast data is pulled.From that forecast data, the information most relevant to the user is highlighted. Any difficult conditions, as well as a segmented summary is generated in simple, succinct text, programmable in any language.An ongoing extension of this feature is to develop a module that can create a simple text forecast for any user defined region.The WOD software is maintained in Git and can be installed on suitable hardware&#160;in a&#160;matter of hours, bringing the full flexibility and power of the WRF&#160;modelling system at your fingertips.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-17383"
    },
    {
        "id": 11244,
        "title": "Latent Code and Text-based Generative Adversarial Networks for Soft-text Generation",
        "authors": "Md. Akmal Haidar, Mehdi Rezagholizadeh, Alan Do Omri, Ahmad Rashid",
        "published": "2019",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/n19-1234"
    },
    {
        "id": 11245,
        "title": "Text, sound generation, and other topics",
        "authors": "Vincent Granville",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-44-321857-6.00022-9"
    },
    {
        "id": 11246,
        "title": "Notes on the Text",
        "authors": "",
        "published": "2019-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1525/9780520935884-004"
    },
    {
        "id": 11247,
        "title": "Improving Quality and Efficiency in Plan-based Neural Data-to-text Generation",
        "authors": "Amit Moryossef, Yoav Goldberg, Ido Dagan",
        "published": "2019",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-8645"
    },
    {
        "id": 11248,
        "title": "Text-to-Image Generation Using Deep Learning",
        "authors": "Sadia Ramzan, Muhammad Munwar Iqbal, Tehmina Kalsum",
        "published": "2022-7-29",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3390/engproc2022020016"
    },
    {
        "id": 11249,
        "title": "Machine Translation Pre-training for Data-to-Text Generation - A Case Study in Czech",
        "authors": "Mihir Kale, Scott Roy",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.inlg-1.13"
    },
    {
        "id": 11250,
        "title": "Text Generation: Next Word Prediction",
        "authors": "Akshay Kulkarni, Adarsha Shivananda, Anoosh Kulkarni",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-7386-9_11"
    },
    {
        "id": 11251,
        "title": "Comparative Analysis of Pretrained Text to Image Models for Accurate Radiological Image Generation for a Single Text Prompt (Preprint)",
        "authors": "Shashwat Mookherjee, Shruti Dutta, Debargha Maschatak, Sristi Chakraborty, Adrija Sinha",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nGenerative AI is a rapidly advancing field within Artificial Intelligence with wide-ranging applications. In the medical science domain, machine learning and deep learning methods have already found extensive use. This study aims to conduct a comparative analysis of seven freely available pretrained text-to-image models to generate radiological images based on a single text prompt. The primary objective is to determine which among these models produces the most accurate radiological images.\n\nThe research investigates the effectiveness of generative AI in the medical domain, particularly for generating radiological images. Several text-to-image models are tested, building on previous research that explored DALL-E 2's capabilities in understanding radiological images. By comparing the performance of different models on a single text prompt, the study provides valuable insights into their potential use in medical image generation.\n\nThrough this investigation, the study seeks to benefit medical professionals, researchers, and the wider AI community. Identifying the most accurate text-to-image model could enhance medical imaging applications, leading to improved diagnostics and treatment planning.\n\n\nOBJECTIVE\nThe objective of this article is to conduct a comparative study of seven existing pretrained text-to-image models available freely on the internet, with the specific aim of generating radiological images based on a single text prompt. The primary goal is to determine which of these text-to-image models is capable of generating the most accurate radiological images for medical applications.\n\nBy evaluating the performance of various text-to-image models, the research aims to provide insights into the effectiveness of generative AI techniques in the medical domain. Specifically, the study seeks to identify the model that demonstrates superior capabilities in accurately translating textual descriptions into radiological images.\n\nThe article seeks to contribute to the field of Generative AI, particularly in the context of medical science and radiological imaging. By comparing different models' outcomes on a single prompt, the research aims to offer valuable information for medical professionals and researchers, highlighting the potential applications and limitations of these text-to-image models in medical image generation.\n\nUltimately, the objective of the article is to facilitate advancements in medical imaging technologies, leading to improved diagnostics and medical decision-making processes. Through its comparative analysis, the article endeavors to aid the AI community in selecting the most suitable text-to-image model for generating accurate and reliable radiological images.\n\n\nMETHODS\nModel Selection: Seven existing pretrained text-to-image generative models available freely on the internet were chosen for the study. These models were specifically designed for generating images from textual descriptions.\n\nModel Descriptions: A brief description of each text-to-image model used in the study, along with their respective results, was provided to contextualize the findings.\n\nImage Generation: The prompt used for testing all models was: \"Photorealistic MRI scan of human lungs suffering from pneumonia.\"\n\nComparative Analysis: The results obtained from each model were compared and analyzed to determine which model produced the most accurate radiological image in response to the given prompt. Keeping in mind the actual imaging of the medical condition, we consulted a physiology expert to compare with the images generated by the seven different models. \n\n\nRESULTS\nThe following comparison results were obtained after the consultation and are presented as follows:\n\nDall-E 2 created the most realistic image of the lungs of a person suffering from pneumonia. It also shows the thoracic cavity with the heart in it which gives more accuracy to the image that is created. Dall-E 2 could also successfully show the difference between the left and right lung. It showed the septum which most of the models could not.\nMidjourney did a good job at showing the infection even though it failed to create the image as realistically as Dall-E 2. Midjourney did provide a clear image though. It might accurately show the spread of the infection as well. \nMin-dalle highlighted the infectious parts well, but it failed to give a more realistic image.\nCarefree Creator did well with the image of the thoracic cavity but it is not very reliable for the detection of infections.\nBig Sleep is a model which we are unsure of. If the white parts in between show the mucus congestion, then it did a nice job at showing the congestion of the lungs but did a poor job at showing the thoracic cavity.\nAphantasia used bright colours which might help the detection of infections even though it failed to show the lungs and the infection accurately.\nDeep Daze produced a very complicated image which makes identifying parts of the body and the infection very difficult.\n\n\nCONCLUSIONS\nFrom the results above, we can conclude that the existing text-to-image generation models are not capable of generating radiological images with 100% accuracy. However, it must be mentioned that some of the  models performed better than the others in specific cases. For eg, the image generated by DALL-E 2 was able to show the difference between the left and right lungs properly and also was able to show the thoracic cavity as compared to the image generated by Aphantasia which was able to showcase the detection of infections better than DALL-E 2 even though it failed to show the lungs accurately. \nThis study also indicates the importance for the need of better visualisation of medical conditions in existing radiological methods. For example the use of colours to better showcase the detection of infections as shown by the image generated by Aphantasia. Of course there are many other factors which must be considered while designing a visualisation method and we aren’t suggesting any particular method which needs to be implemented immediately. Proper  consultation with an expert is always the first step. \nThese results surely are a starting step in the domain of image generation for radiological images.It is true that in this study we used only one prompt. Further steps would include giving a better text prompt of the medial condition and giving prompts of more varied medical conditions. \n There are a variety of applications and benefits of generating radiological images. Many Machine Learning tasks like classification and segmentation require a large dataset for training respective models appropriately and an accurate radiological image generated using AI would help in making the dataset of the required size. Further developments in this field can lead to generating radiological images of specific conditions based on the particular prompt of the user.\n",
        "link": "http://dx.doi.org/10.2196/preprints.51099"
    },
    {
        "id": 11252,
        "title": "DeepText: A new approach for text proposal generation and text detection in natural images",
        "authors": "Zhuoyao Zhong, Lianwen Jin, Shuangping Huang",
        "published": "2017-3",
        "citations": 62,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp.2017.7952348"
    },
    {
        "id": 11253,
        "title": "Literal translation as text interpretation and text generation",
        "authors": "Ekaterina A. Saltykova",
        "published": "2020-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18522/2070-1403-2020-82-5-221-228"
    },
    {
        "id": 11254,
        "title": "Explaining Toxic Text via Knowledge Enhanced Text Generation",
        "authors": "Rohit Sridhar, Diyi Yang",
        "published": "2022",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.naacl-main.59"
    },
    {
        "id": 11255,
        "title": "Coherent Long Text Generation by Contrastive Soft Prompt",
        "authors": "Guandan Chen, Jiashu Pu, Yadong Xi, Rongsheng Zhang",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gem-1.42"
    },
    {
        "id": 11256,
        "title": "Assessment of EMF Model to Text Generation Strategies and Libraries in an Industrial Context",
        "authors": "Christophe Ponsard, Denis Darquennes, Valery Ramon, Jean-Christophe Deprez",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009155804330440"
    },
    {
        "id": 11257,
        "title": "Mod-D2T: A Multi-layer Dataset for Modular Data-to-Text Generation",
        "authors": "Simon Mille, Francois Lareau, Stamatia Dasiopoulou, Anya Belz",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.inlg-main.36"
    },
    {
        "id": 11258,
        "title": "Jointly Measuring Diversity and Quality in Text Generation Models",
        "authors": "Danial Alihosseini, Ehsan Montahaei, Mahdieh Soleymani Baghshah",
        "published": "2019",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-2311"
    },
    {
        "id": 11259,
        "title": "Sentence Packaging in Text Generation from Semantic Graphs as a Community Detection Problem",
        "authors": "Alexander Shvets, Simon Mille, Leo Wanner",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-6542"
    },
    {
        "id": 11260,
        "title": "Improving Chest X-ray Report Generation by Leveraging Text of Similar Images",
        "authors": "Saeed Niksaz, Fahimeh Ghasemian",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nAutomatic medical report generation is the production of reports from radiology images that are grammatically correct and coherent. Encoder-decoder is the most common architecture for report generation, which has not achieved to a satisfactory performance because of the complexity of this task. This paper presents an approach to improve the performance of report generation that can be easily added to any encoder-decoder architecture. In this approach, in addition to the features extracted from the image, the text related to the most similar image in the training data set is also provided as the input to the decoder. So, the decoder acquires additional knowledge for text production which helps to improve the performance and produce better reports. To demonstrate the efficiency of the proposed method, this technique was added to several different models for producing text from chest images. The results of evaluation demonstrated that the performance of all models improved. Also, different approaches for word embedding, including BioBert, and GloVe, were evaluated. Our result showed that BioBert, which is a language model based on the transformer, is a better approach for this task.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2760389/v1"
    },
    {
        "id": 11261,
        "title": "Enhancing Text Generation from Knowledge Graphs with Cross-Structure Attention Distillation",
        "authors": "Xiayang Shi, Zhenlin Xia, Pei Cheng",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4473671"
    },
    {
        "id": 11262,
        "title": "Table-to-Text Generation with Accurate Content Copying",
        "authors": "Yang Yang, Juan Cao, Yujun Wen, Pengzhou Zhang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nTable-to-text generation is an important task in natural language generation that aims to generate smooth, informative text based on structured data. In this paper, we propose a novel transformer-based autoregressive model that incorporates table content copying and language model based generation. At first, we propose a word transformation method to process a target text. By using target text containing fields and position information, we can help the model learn the relationship between target text and table and gain the position of where to copy. We then propose two auxiliary learning goals: table-text constraint loss and copy loss. Table-text constraint loss is introduced to effectively model table inputs, whereas copy loss is exploited to precisely copy word fragments from a table. In addition, we change the maximization-based text search strategy to reduce the probability of problems such as sentence repetition and inconsistency. On the WIKIBIO dataset, our model improves its BLUE scores from 45.47 to 46.87 and ROUGE scores from 41.54 to 42.28, outperforming state-of-the-art baseline models on automatic evaluation metrics. On the ROTOWIRE test set, compared with the best baseline model, our model gets 4.29% higher on CO metric, and 1.93 points higher on BLEU.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-753430/v1"
    },
    {
        "id": 11263,
        "title": "Adversarial Text Perturbation Generation and Analysis",
        "authors": "Jesus Guerrero, Gongbo Liang, Izzat Alsmadi",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icsc60084.2023.10349981"
    },
    {
        "id": 11264,
        "title": "Uniform Complexity for Text Generation",
        "authors": "Joseph Imperial, Harish Madabushi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.805"
    },
    {
        "id": 11265,
        "title": "TEXT TO PSEUDO CODE GENERATION",
        "authors": "",
        "published": "2023-10-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.56726/irjmets45500"
    },
    {
        "id": 11266,
        "title": "Text-to-Face Generation with StyleGAN2",
        "authors": "D. M. A. Ayanthi, Sarasi Munasinghe",
        "published": "2022-5-21",
        "citations": 3,
        "abstract": "Synthesizing images from text descriptions has become an active research area with the advent of Generative Adversarial Networks. The main goal here is to generate photo-realistic images that are aligned with the input descriptions. Text-to-Face generation(T2F) is a sub-domain of Text-to-Image generation(T2I) that is more challenging due to the complexity and variation of facial attributes. It has a number of applications mainly in the domain of public safety. Even though several models are available for T2F, there is still the need to improve the image quality and the semantic alignment. In this research, we propose a novel framework, to generate facial images that are well-aligned with the input descriptions. Our framework utilizes the highresolution face generator, StyleGAN2, and explores the possibility of using it in T2F. Here, we embed text in the input latent space of StyleGAN2 using BERT embeddings and oversee the generation of facial images using text descriptions. We trained our framework on attributebased descriptions to generate images of 1024x1024 in resolution. The images generated exhibit a 57% similarity to the ground truth images, with a face semantic distance of 0.92, outperforming state-of-the-artwork. The generated images have a FID score of 118.097 and the experimental results show that our model generates promising images.",
        "link": "http://dx.doi.org/10.5121/csit.2022.120805"
    },
    {
        "id": 11267,
        "title": "LAFT: Cross-lingual Transfer for Text Generation by Language-Agnostic Finetuning",
        "authors": "Xianze Wu, Zaixiang Zheng, Hao Zhou, Yong Yu",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.inlg-main.21"
    },
    {
        "id": 11268,
        "title": "Generation of Original Text with Text Mining and Deep Learning Methods for Turkish and Other Languages",
        "authors": "Emre DOGAN, Buket KAYA, Ahmet MUNGEN",
        "published": "2018-9",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/idap.2018.8620854"
    },
    {
        "id": 11269,
        "title": "Keyphrase Generation: A Text Summarization Struggle",
        "authors": "Erion Çano, Ondřej Bojar",
        "published": "2019",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/n19-1070"
    },
    {
        "id": 11270,
        "title": "Topic-Controlled Text Generation",
        "authors": "Cansen Caglayan, Murat Karakaya",
        "published": "2021-9-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ubmk52708.2021.9558910"
    }
]