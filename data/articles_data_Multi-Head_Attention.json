[
    {
        "id": 10460,
        "title": "Combining Multi-Head Attention and Sparse Multi-Head Attention Networks for Session-Based Recommendation",
        "authors": "Zhiwei Zhao, Xiaoye Wang, Yingyuan Xiao",
        "published": "2023-6-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191924"
    },
    {
        "id": 10461,
        "title": "Multi-Input Sequential Multi-Head Attention Based Traffic",
        "authors": "Aram Nasser, Vilmos Simon",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4581698"
    },
    {
        "id": 10462,
        "title": "Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention",
        "authors": "Huiyin Xue, Nikolaos Aletras",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.695"
    },
    {
        "id": 10463,
        "title": "Bilinear Multi-Head Attention Graph Neural Network for Traffic Prediction",
        "authors": "Haibing Hu, Kai Han, Zhizhuo Yin",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010763400003116"
    },
    {
        "id": 10464,
        "title": "Dynamically Choosing the Number of Heads in Multi-Head Attention",
        "authors": "Fernando Duarte, Nuno Lau, Artur Pereira, Luís Reis",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012384500003636"
    },
    {
        "id": 10465,
        "title": "Sentiment analysis with adaptive multi-head attention in Transformer",
        "authors": "Fanfei Meng, David Demeter",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>We propose a novel framework based on the attention mechanism to identify the sentiment of a movie review document. Previous efforts on deep neural networks with attention mechanisms focus on encoder and decoder with fixed numbers of multi-head attention. Therefore, we need a mechanism to stop the attention process automatically if no more useful information can be read from the memory.In this paper, we propose an adaptive multi-head attention architecture (AdaptAttn) which varies the number of attention heads based on length of sentences. AdaptAttn has a data preprocessing step where each document is classified into any one of the three bins small, medium or large based on length of the sentence. The document classified as small goes through two heads in each layer, the medium group passes four heads and the large group is processed by eight heads. We examine the merit of our model on the Stanford large movie review dataset. The experimental results show that the F1 score from our model is on par with the baseline model.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24638745"
    },
    {
        "id": 10466,
        "title": "Sentiment analysis with adaptive multi-head attention in Transformer",
        "authors": "Fanfei Meng, David Demeter",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>We propose a novel framework based on the attention mechanism to identify the sentiment of a movie review document. Previous efforts on deep neural networks with attention mechanisms focus on encoder and decoder with fixed numbers of multi-head attention. Therefore, we need a mechanism to stop the attention process automatically if no more useful information can be read from the memory.In this paper, we propose an adaptive multi-head attention architecture (AdaptAttn) which varies the number of attention heads based on length of sentences. AdaptAttn has a data preprocessing step where each document is classified into any one of the three bins small, medium or large based on length of the sentence. The document classified as small goes through two heads in each layer, the medium group passes four heads and the large group is processed by eight heads. We examine the merit of our model on the Stanford large movie review dataset. The experimental results show that the F1 score from our model is on par with the baseline model.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.24638745.v1"
    },
    {
        "id": 10467,
        "title": "Serialized Multi-Layer Multi-Head Attention for Neural Speaker Embedding",
        "authors": "Hongning Zhu, Kong Aik Lee, Haizhou Li",
        "published": "2021-8-30",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-2210"
    },
    {
        "id": 10468,
        "title": "Taxi Demand Prediction based on LSTM with Residuals and Multi-head Attention",
        "authors": "Chih-Jung Hsu, Hung-Hsuan Chen",
        "published": "2020",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009562000002550"
    },
    {
        "id": 10469,
        "title": "Self Multi-Head Attention for Speaker Recognition",
        "authors": "Miquel India, Pooyan Safari, Javier Hernando",
        "published": "2019-9-15",
        "citations": 38,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2019-2616"
    },
    {
        "id": 10470,
        "title": "Taxi Demand Prediction based on LSTM with Residuals and Multi-head Attention",
        "authors": "Chih-Jung Hsu, Hung-Hsuan Chen",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009562002680275"
    },
    {
        "id": 10471,
        "title": "Interpretable Multi-Head Self-Attention Architecture for Sarcasm Detection in Social Media",
        "authors": "Ramya Akula, Ivan Garibay",
        "published": "No Date",
        "citations": 5,
        "abstract": "Sarcasm is a linguistic expression often used to communicate the opposite of what is said, usually something that is very unpleasant with an intention to insult or ridicule. Inherent ambiguity in sarcastic expressions, make sarcasm detection very difficult. In this work, we focus on detecting sarcasm in textual conversations from various social networking platforms and online media. To this end, we develop an interpretable deep learning model using multi-head self-attention and gated recurrent units. Multi-head self-attention module aids in identifying crucial sarcastic cue-words from the input, and the recurrent units learn long-range dependencies between these cue-words to better classify the input text. We show the effectiveness of our approach by achieving state-of-the-art results on multiple datasets from social networking platforms and online media. Models trained using our proposed approach are easily interpretable and enable identifying sarcastic cues in the input text which contribute to the final classification score. We visualize the learned attention weights on few sample input texts to showcase the effectiveness and interpretability of our model.",
        "link": "http://dx.doi.org/10.20944/preprints202101.0302.v1"
    },
    {
        "id": 10472,
        "title": "Acoustic Scene Analysis with Multi-Head Attention Networks",
        "authors": "Weimin Wang, Weiran Wang, Ming Sun, Chao Wang",
        "published": "2020-10-25",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2020-1342"
    },
    {
        "id": 10473,
        "title": "A Detection Algorithm of Malicious Domain Based on Deep Learning and Multi-Head Attention Mechanism",
        "authors": "Siqi Huang, Bo Yan, Dongmei Zhang",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008098200840091"
    },
    {
        "id": 10474,
        "title": "Gated Multi-Head Attention Pooling for Weakly Labelled Audio Tagging",
        "authors": "Sixin Hong, Yuexian Zou, Wenwu Wang",
        "published": "2020-10-25",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2020-1197"
    },
    {
        "id": 10475,
        "title": "Prediction of Household Energy Usage via Multi-Head Attention",
        "authors": "Aidan G. Kurz, Colleen P. Bailey",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/metrocon59008.2023.10339948"
    },
    {
        "id": 10476,
        "title": "Analyzing and Controlling Inter-Head Diversity in Multi-Head Attention",
        "authors": "Hyeongu Yun, Taegwan Kang, Kyomin Jung",
        "published": "2021-2-8",
        "citations": 4,
        "abstract": "Multi-head attention, a powerful strategy for Transformer, is assumed to utilize information from diverse representation subspaces. However, measuring diversity between heads’ representations or exploiting the diversity has been rarely studied. In this paper, we quantitatively analyze inter-head diversity of multi-head attention by applying recently developed similarity measures between two deep representations: Singular Vector Canonical Correlation Analysis (SVCCA) and Centered Kernel Alignment (CKA). By doing so, we empirically show that multi-head attention does diversify representation subspaces of each head as the number of heads increases. Based on our analysis, we hypothesize that there exists an optimal inter-head diversity with which a model can achieve better performance. To examine our hypothesis, we deeply inspect three techniques to control the inter-head diversity; (1) Hilbert-Schmidt Independence Criterion regularizer among representation subspaces, (2) Orthogonality regularizer, and (3) Drophead as zero-outing each head randomly in every training step. In our experiments on various machine translation and language modeling tasks, we show that controlling inter-head diversity leads to the best performance among baselines.",
        "link": "http://dx.doi.org/10.3390/app11041548"
    },
    {
        "id": 10477,
        "title": "Multi-Modal Transformer with Multi-Head Attention for Emotion Recognition",
        "authors": "Chi Xu, Yifei Gao",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icsece58870.2023.10263303"
    },
    {
        "id": 10478,
        "title": "Enhancing Attention Models via Multi-head Collaboration",
        "authors": "Huadong Wang, Mei Tu",
        "published": "2020-12-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ialp51396.2020.9310460"
    },
    {
        "id": 10479,
        "title": "Stacked Multi-head Attention for Multi-turn Response Selection in Retrieval-based Chatbots",
        "authors": "Chongchong Yu, Weijie Jiang, Dongdong Zhu, Ruolan Li",
        "published": "2019-11",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac48633.2019.8997176"
    },
    {
        "id": 10480,
        "title": "Fiber communication receiver models based on the multi-head attention mechanism",
        "authors": "Yubin Zang, Zhenming Yu, Kun Xu, Minghua Chen, Sigang Yang, Hongwei Chen",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3788/col202321.030602"
    },
    {
        "id": 10481,
        "title": "The Application of Graph Neural Network Based on Multi-Head Attention Optimization in Information Recommendation Systems",
        "authors": "Yibing Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThis study proposes a group information recommendation (GIR) model to accurately and comprehensively explore group preferences and enhances complex groups' recommendation effect. Firstly, the group recommendation (GR) algorithm, Multi-Head Attention (MHA) mechanism, and Graph Neural Network (GNN) are summarized. Secondly, the GIR model is constructed using the MHA and GNN models. On the one hand, the model considers the importance of differences in group objects' preferences in different item recommendations. On the other hand, the impact of the interaction between objects on group preference modeling is considered. The constructed GIR model includes an embedding layer, a propagation layer, a fusion layer, and a prediction layer. Finally, experiments are conducted to verify the effectiveness of the constructed model. The verification results reveal that: (1) compared with other recommendation models, the Multi-Head Attention-Graph Neural Network (MHA-GNN) model is improved by 1.05% in the Mean Reciprocal Rank (MRR) index. (2) The recommendation precision and MRR value of the MHA-GNN model are higher than those of other fused models. (3) Compared with other recommendation models, the MHA-GNN model has the highest recommendation precision and better recommendation effect. The above conclusions show that the introduced GNN technology can effectively improve the performance of the GR model. At the same time, the established GIR system has a more accurate recommendation effect, which can realize the efficient mining of group preferences. This study aims to achieve the efficient recommendation of information and save information retrieval time.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3244223/v1"
    },
    {
        "id": 10482,
        "title": "DSCIMABNet: A Novel Multi-Head Attention Depthwise Separable CNN Model for Skin Cancer Detection",
        "authors": "Hatice Catal Reis, Veysel Turk",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4596632"
    },
    {
        "id": 10483,
        "title": "Multi‐head attention graph convolutional network model: End‐to‐end entity and relation joint extraction based on multi‐head attention graph convolutional network",
        "authors": "Zhihua Tao, Chunping Ouyang, Yongbin Liu, Tonglee Chung, Yixin Cao",
        "published": "2023-6",
        "citations": 3,
        "abstract": "AbstractAt present, the entity and relation joint extraction task has attracted more and more scholars' attention in the field of natural language processing (NLP). However, most of their methods rely on NLP tools to construct dependency trees to obtain sentence structure information. The adjacency matrix constructed by the dependency tree can convey syntactic information. Dependency trees obtained through NLP tools are too dependent on the tools and may not be very accurate in contextual semantic description. At the same time, a large amount of irrelevant information will cause redundancy. This paper presents a novel end‐to‐end entity and relation joint extraction based on the multi‐head attention graph convolutional network model (MAGCN), which does not rely on external tools. MAGCN generates an adjacency matrix through a multi‐head attention mechanism to form an attention graph convolutional network model, uses head selection to identify multiple relations, and effectively improve the prediction result of overlapping relations. The authors extensively experiment and prove the method's effectiveness on three public datasets: NYT, WebNLG, and CoNLL04. The results show that the authors’ method outperforms the state‐of‐the‐art research results for the task of entities and relation extraction.",
        "link": "http://dx.doi.org/10.1049/cit2.12086"
    },
    {
        "id": 10484,
        "title": "Relation Extraction in Biomedical texts via Multi-Head Attention Mechanism and Syntactic Dependency Feature (Preprint)",
        "authors": "Yongbin Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nBACKGROUND\nWith the rapid expansion of biomedical literature, biomedical information extraction (IE) has attracted more and more attention by researchers, especially the relation extraction (RE) between two entities is a long-term research topic.\n\n\nOBJECTIVE\nThis paper focuses on two multi-class relation extraction tasks of BioNLP 2019 Open Shared Tasks: relation extraction of Bacteria-Biotope task (BB-rel) and binary relation extraction of plant seed development task (SeeDev-binary). In essence, these two tasks are aimed to extract the relation between annotated entity pairs from biomedical texts, which is a challenging problem.\n\n\nMETHODS\nThe traditional research methods adopted feature-based or kernel-based methods, and achieved good performance. For these tasks, we propose a deep learning model based on a combination of several distributed features, such as domain-specific word embedding, part-of-speech (POS) embedding, entity type embedding, distance embedding and position embedding. The Multi-Head attention mechanism is used to extract the global semantic features of a whole sentence. Meanwhile, we introduce dependency type feature and shortest dependency path connecting two candidate entities in the syntactic dependency graph to enrich the feature representation.\n\n\nRESULTS\nExperiments show that our proposed model has excellent performance in biomedical relation extraction, achieves the F1-scores of 65.56% and 38.04% on the test sets of these two tasks, respectively. Especially in SeeDev-binary task, the F1-score of our model is superior to other existing models and achieves state-of-the-art performance.\n\n\nCONCLUSIONS\nWe demonstrated that the Multi-Head attention mechanism can learn relevant syntactic and semantic features in different representation subspaces and different positions to extract comprehensive feature representation. Moreover, syntactic dependency features can improve the performance of the model by learning dependency relation between the entities in biomedical texts.\n",
        "link": "http://dx.doi.org/10.2196/preprints.41136"
    },
    {
        "id": 10485,
        "title": "Dysarthria severity classification using multi-head attention and multi-task learning",
        "authors": "Amlu Anna Joshy, Rajeev Rajan",
        "published": "2023-2",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.specom.2022.12.004"
    },
    {
        "id": 10486,
        "title": "Multi-Head Multi-Layer Attention to Deep Language Representations for Grammatical Error Detection",
        "authors": "Masahiro Kaneko, Mamoru Komachi",
        "published": "2019-10-7",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.13053/cys-23-3-3271"
    },
    {
        "id": 10487,
        "title": "Multi-modal multi-head self-attention for medical VQA",
        "authors": "Vasudha Joshi, Pabitra Mitra, Supratik Bose",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11042-023-17162-3"
    },
    {
        "id": 10488,
        "title": "XM2A: Multi-Scale Multi-Head Attention with Cross-Talk for Multi-Variate Time Series Analysis",
        "authors": "Yash Garg, K. Selcuk Candan",
        "published": "2021-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mipr51284.2021.00030"
    },
    {
        "id": 10489,
        "title": "DeepLPC-MHANet: Multi-Head Self-Attention for Augmented Kalman Filter-based Speech Enhancement",
        "authors": "Sujan Kumar Roy, Aaron Nicolson, Kuldip K. Paliwal",
        "published": "No Date",
        "citations": 0,
        "abstract": "Current augmented Kalman filter (AKF)-based speech enhancement algorithms utilise a temporal convolutional network (TCN) to estimate the clean speech and noise linear prediction coefficient (LPC). However, the multi-head attention network (MHANet) has demonstrated the ability to more efficiently model the long-term dependencies of noisy speech than TCNs. Motivated by this, we investigate the MHANet for LPC estimation. We aim to produce clean speech and noise LPC parameters with the least bias to date. With this, we also aim to produce higher quality and more intelligible enhanced speech than any current KF or AKF-based SEA. Here, we investigate MHANet within the DeepLPC framework. DeepLPC is a deep learning framework for jointly estimating the clean speech and noise LPC power spectra. DeepLPC is selected as it exhibits significantly less bias than other frameworks, by avoiding the use of whitening filters and post-processing. DeepLPC-MHANet is evaluated on the NOIZEUS corpus using subjective AB listening tests, as well as seven different objective measures (CSIG, CBAK, COVL, PESQ, STOI, SegSNR, and SI-SDR). DeepLPC-MHANet is compared to five existing deep learning-based methods. Compared to other deep learning approaches, DeepLPC-MHANet produced clean speech LPC estimates with the least amount of bias. DeepLPC-MHANet-AKF also produced higher objective scores than any of the competing methods (with an improvement of 0.17 for CSIG, 0.15 for CBAK, 0.19 for COVL, 0.24 for PESQ, 3.70\\% for STOI, 1.03 dB for SegSNR, and 1.04 dB for SI-SDR over the next best method). The enhanced speech produced by DeepLPC-MHANet-AKF was also the most preferred amongst ten listeners. By producing LPC estimates with the least amount of bias to date, DeepLPC-MHANet enables the AKF to produce enhanced speech at a higher quality and intelligibility than any previous method.",
        "link": "http://dx.doi.org/10.36227/techrxiv.14384909.v1"
    },
    {
        "id": 10490,
        "title": "A Lightweight Multi-Head Attention Transformer for Stock Price Forecasting",
        "authors": "Anh Nguyen, Son Ha",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4729648"
    },
    {
        "id": 10491,
        "title": "Multi-Head-Self-Attention based YOLOv5X-transformer for multi-scale object detection",
        "authors": "Ponduri Vasanthi, Laavanya Mohan",
        "published": "2023-5-16",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11042-023-15773-4"
    },
    {
        "id": 10492,
        "title": "Discriminative speaker embedding with serialized multi-layer multi-head attention",
        "authors": "Hongning Zhu, Kong Aik Lee, Haizhou Li",
        "published": "2022-10",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.specom.2022.09.003"
    },
    {
        "id": 10493,
        "title": "DeepLPC-MHANet: Multi-Head Self-Attention for Augmented Kalman Filter-based Speech Enhancement",
        "authors": "Sujan Kumar Roy, Aaron Nicolson, Kuldip K. Paliwal",
        "published": "No Date",
        "citations": 0,
        "abstract": "Current augmented Kalman filter (AKF)-based speech enhancement algorithms utilise a temporal convolutional network (TCN) to estimate the clean speech and noise linear prediction coefficient (LPC). However, the multi-head attention network (MHANet) has demonstrated the ability to more efficiently model the long-term dependencies of noisy speech than TCNs. Motivated by this, we investigate the MHANet for LPC estimation. We aim to produce clean speech and noise LPC parameters with the least bias to date. With this, we also aim to produce higher quality and more intelligible enhanced speech than any current KF or AKF-based SEA. Here, we investigate MHANet within the DeepLPC framework. DeepLPC is a deep learning framework for jointly estimating the clean speech and noise LPC power spectra. DeepLPC is selected as it exhibits significantly less bias than other frameworks, by avoiding the use of whitening filters and post-processing. DeepLPC-MHANet is evaluated on the NOIZEUS corpus using subjective AB listening tests, as well as seven different objective measures (CSIG, CBAK, COVL, PESQ, STOI, SegSNR, and SI-SDR). DeepLPC-MHANet is compared to five existing deep learning-based methods. Compared to other deep learning approaches, DeepLPC-MHANet produced clean speech LPC estimates with the least amount of bias. DeepLPC-MHANet-AKF also produced higher objective scores than any of the competing methods (with an improvement of 0.17 for CSIG, 0.15 for CBAK, 0.19 for COVL, 0.24 for PESQ, 3.70\\% for STOI, 1.03 dB for SegSNR, and 1.04 dB for SI-SDR over the next best method). The enhanced speech produced by DeepLPC-MHANet-AKF was also the most preferred amongst ten listeners. By producing LPC estimates with the least amount of bias to date, DeepLPC-MHANet enables the AKF to produce enhanced speech at a higher quality and intelligibility than any previous method.",
        "link": "http://dx.doi.org/10.36227/techrxiv.14384909"
    },
    {
        "id": 10494,
        "title": "Boosting House Price Estimations with Multi-Head Gated Attention",
        "authors": "ABDELLAH  ZAKARIA SELLAM, Cosimo Distante, Pier  Luigi Mazzeo, Abdelmalik Taleb-Ahmed",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4714932"
    },
    {
        "id": 10495,
        "title": "Multi-head Attention Spatio-temporal Graph Neural Networks for traffic forecasting",
        "authors": "Xiuwei Hu, Zhiyong Wu, Yilong Sun, Yunhui Zheng",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nAccurate traffic prediction is crucial for an intelligent traffic system (ITS). However, the excessive non-linearity and complexity of the spatio-temporal correlation in traffic flow severely limit the prediction accuracy of most existing models, which simply stack temporal and spatial modules and fail to capture spatio-temporal features effectively. To improve the prediction accuracy, a multi-head attention spatio-temporal graph neural networks (MSTNet) is proposed in this paper. First, the traffic data is decomposed into unique time spans that conform to positive rules, and valuable traffic node attributes are mined through an adaptive graph structure. Second, time and spatial features are captured using a multi-head attention spatio-temporal module. Finally, a multi-step prediction module is used to achieve future traffic condition prediction. Numerical experiments were conducted on an open-source dataset, and the results demonstrate that MSTNet performs well in spatio-temporal feature extraction and achieves more positive forecasting results than the baseline methods.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3159389/v1"
    },
    {
        "id": 10496,
        "title": "Gaussian Multi-head Attention for Simultaneous Machine Translation",
        "authors": "Shaolei Zhang, Yang Feng",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.findings-acl.238"
    },
    {
        "id": 10497,
        "title": "Beyond Variational Models and Self-Similarity in Super-Resolution: Unfolding Models and Multi-Head Attention",
        "authors": "Ivan Pereira-Sánchez, Eloi Sans, Julia Navarro, Joan Duran",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012395400003660"
    },
    {
        "id": 10498,
        "title": "Social Commonsense Reasoning with Multi-Head Knowledge Attention",
        "authors": "Debjit Paul, Anette Frank",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.findings-emnlp.267"
    },
    {
        "id": 10499,
        "title": "Residual Learning with Bi-LSTM and Multi-Head Attention for Multi-Modal Emotion Recognition",
        "authors": "Yifei Gao, Chi Xu",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icipca59209.2023.10257779"
    },
    {
        "id": 10500,
        "title": "Action Recognition in Videos using 3D ConvNets with Multi-head Attention",
        "authors": "Yagmur Sahin, Mustafa Sert",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigmm59094.2023.00017"
    },
    {
        "id": 10501,
        "title": "Multi-Head Self-Attention Transformer for Dogecoin Price Prediction",
        "authors": "Sashank Sridhar, Sowmya Sanagavarapu",
        "published": "2021-7-8",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/hsi52170.2021.9538640"
    },
    {
        "id": 10502,
        "title": "Financial Volatility Forecasting: A Sparse Multi-Head Attention Neural Network",
        "authors": "Hualing Lin, Qiubi Sun",
        "published": "2021-10-14",
        "citations": 5,
        "abstract": "Accurately predicting the volatility of financial asset prices and exploring its laws of movement have profound theoretical and practical guiding significance for financial market risk early warning, asset pricing, and investment portfolio design. The traditional methods are plagued by the problem of substandard prediction performance or gradient optimization. This paper proposes a novel volatility prediction method based on sparse multi-head attention (SP-M-Attention). This model discards the two-dimensional modeling strategy of time and space of the classic deep learning model. Instead, the solution is to embed a sparse multi-head attention calculation module in the network. The main advantages are that (i) it uses the inherent advantages of the multi-head attention mechanism to achieve parallel computing, (ii) it reduces the computational complexity through sparse measurements and feature compression of volatility, and (iii) it avoids the gradient problems caused by long-range propagation and therefore, is more suitable than traditional methods for the task of analysis of long time series. In the end, the article conducts an empirical study on the effectiveness of the proposed method through real datasets of major financial markets. Experimental results show that the prediction performance of the proposed model on all real datasets surpasses all benchmark models. This discovery will aid financial risk management and the optimization of investment strategies.",
        "link": "http://dx.doi.org/10.3390/info12100419"
    },
    {
        "id": 10503,
        "title": "Bi-Level Interactive Object Detection Head Framework with Multi-Level Self-Attention Mechanism",
        "authors": "Enhui Chai, Xingxing Hao, Wei Zhou, Li Chen",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4455956"
    },
    {
        "id": 10504,
        "title": "Recurrent Network using LSTM-based Multi-head Attention for Aircraft Trajectory Prediction",
        "authors": "Myoungsoo Kim, Wonik Choi",
        "published": "2022-3-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5626/ktcp.2022.28.3.146"
    },
    {
        "id": 10505,
        "title": "Multi-agent Reinforcement Learning with Multi-head Attention",
        "authors": "Ke Ni, Jing Chen, Jian Wang, Bo Liu, Ting Lei",
        "published": "2023-2-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/itnec56291.2023.10082248"
    },
    {
        "id": 10506,
        "title": "Multi-Modality Emotion Recognition Model with GAT-Based Multi-Head Inter-Modality Attention",
        "authors": "Changzeng Fu, Chaoran Liu, Carlos Toshinori Ishi, Hiroshi Ishiguro",
        "published": "2020-8-29",
        "citations": 8,
        "abstract": "Emotion recognition has been gaining attention in recent years due to its applications on artificial agents. To achieve a good performance with this task, much research has been conducted on the multi-modality emotion recognition model for leveraging the different strengths of each modality. However, a research question remains: what exactly is the most appropriate way to fuse the information from different modalities? In this paper, we proposed audio sample augmentation and an emotion-oriented encoder-decoder to improve the performance of emotion recognition and discussed an inter-modality, decision-level fusion method based on a graph attention network (GAT). Compared to the baseline, our model improved the weighted average F1-scores from 64.18 to 68.31% and the weighted average accuracy from 65.25 to 69.88%.",
        "link": "http://dx.doi.org/10.3390/s20174894"
    },
    {
        "id": 10507,
        "title": "Multi-Resolution Multi-Head Attention in Deep Speaker Embedding",
        "authors": "Zhiming Wang, Kaisheng Yao, Xiaolong Li, Shuo Fang",
        "published": "2020-5",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp40776.2020.9053217"
    },
    {
        "id": 10508,
        "title": "St-Mgat:Spatio-Temporal Multi-Head Graph Attention Network for Traffic Flow Prediction",
        "authors": "Bowen WANG, Jingsheng Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3985422"
    },
    {
        "id": 10509,
        "title": "Double Multi-Head Attention-Based Capsule Network for Relation Classification",
        "authors": "Hongjun Heng, Renjie Li",
        "published": "2021-5-29",
        "citations": 0,
        "abstract": "Semantic relation classification is an important task in the field of nature language processing. The existing neural network relation classification models introduce attention mechanism to increase the importance of significant features, but part of these attention models only have one head which is not enough to capture more distinctive fine-grained features. Models based on RNN (Recurrent Neural Network) usually use single-layer structure and have limited feature extraction capability. Current RNN-based capsule networks have problem of improper handling of noise which increase complexity of network. Therefore, we propose a capsule network relation classification model based on double multi-head attention. In this model, we introduce an auxiliary BiGRU (Bidirectional Gated Recurrent Unit) to make up for the lack of feature extraction performance of single BiGRU, improve the bilinear attention through double multihead mechanism to enable the model to obtain more information of sentence from different representation subspace and instantiate capsules with sentence-level features to alleviate noise impact. Experiments on the SemEval-2010 Task 8 benchmark dataset show that our model outperforms most of previous state-of-the-art neural network models and achieves the comparable performance with F1 score of 85.3% in capsule network.",
        "link": "http://dx.doi.org/10.5121/csit.2021.110711"
    },
    {
        "id": 10510,
        "title": "An Intention Inference Method for BiGRU Integrating Multi-head Self-Attention in Share Control",
        "authors": "Wenshan Zhao, Hua Wang",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac59555.2023.10451784"
    },
    {
        "id": 10511,
        "title": "Pedestrian Inertial Navigation with Multi-Head LSTM Including Attention",
        "authors": "Muhammed Taha Köroğlu, Gökhan Çetin",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/asyu58738.2023.10296616"
    },
    {
        "id": 10512,
        "title": "Duplicate Question Detection based on Neural Networks and Multi-head Attention",
        "authors": "Heng Zhang, Liangyu Chen",
        "published": "2019-11",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ialp48816.2019.9037671"
    },
    {
        "id": 10513,
        "title": "Multi-channel EEG signals classification via CNN and multi-head self-attention on evidence theory",
        "authors": "Lang Zhang, Fuyuan Xiao, Zehong Cao",
        "published": "2023-9",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.ins.2023.119107"
    },
    {
        "id": 10514,
        "title": "Stock Index Forecasting Using Combined Model of Wavelet Transform LSTM and Multi-Head Attention",
        "authors": "Heeseok Kwon, Minhyuk Lee",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7737/kmsr.2023.40.2.097"
    },
    {
        "id": 10515,
        "title": "Attention as Relation: Learning Supervised Multi-head Self-Attention for Relation Extraction",
        "authors": "Jie Liu, Shaowei Chen, Bingquan Wang, Jiaxin Zhang, Na Li, Tong Xu",
        "published": "2020-7",
        "citations": 31,
        "abstract": "Joint entity and relation extraction is critical for many natural language processing (NLP) tasks, which has attracted increasing research interest. However, it is still faced with the challenges of identifying the overlapping relation triplets along with the entire entity boundary and detecting the multi-type relations. In this paper, we propose an attention-based joint model, which mainly contains an entity extraction module and a relation detection module, to address the challenges. The key of our model is devising a supervised multi-head self-attention mechanism as the relation detection module to learn the token-level correlation for each relation type separately. With the attention mechanism, our model can effectively identify overlapping relations and flexibly predict the relation type with its corresponding intensity. To verify the effectiveness of our model, we conduct comprehensive experiments on two benchmark datasets. The experimental results demonstrate that our model achieves state-of-the-art performances.",
        "link": "http://dx.doi.org/10.24963/ijcai.2020/524"
    },
    {
        "id": 10516,
        "title": "Multi-Head Attention for End-to-End Neural Machine Translation",
        "authors": "Ivan Fung, Brian Mak",
        "published": "2018-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iscslp.2018.8706667"
    },
    {
        "id": 10517,
        "title": "Deep Reinforcement Learning Based Group Recommendation System with Multi-Head Attention Mechanism",
        "authors": "Saba Izadkhah, Banafsheh Reakbdar",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/transai60598.2023.00038"
    },
    {
        "id": 10518,
        "title": "A Recommendation Model Based on Deep Feature Representation  and Multi-Head Self-Attention Mechanism",
        "authors": "Matilda Wilson, Bernd Wellington, Atticus Merrick, Imogen Huxley",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nRecommender systems analyze user attributes and historical behaviors to understand user needs and filter and select the content they want. Recommender systems have been proposed since the 1990s and have been studied to adapt to various domains. Nowadays Recommendations are now essential for the growing e-commerce, as well as for everyday entertainment such as music, movies, socializing, and networking. In recent years, deep learning technology has become a hot trend, which effectively solves the difficulty of combining features manually in traditional machine learning by automatically learning high-level feature representations. It also brings new challenges and opportunities for the development of recommendation systems. From traditional recommendation models to deep recommendation models, from manual feature engineering to automatic feature engineering, and from low-order features to high-order feature learning, recommender systems have been continuously developed and innovated. In addition, nowadays recommender systems are constantly personalized and scene-oriented, and recommender systems under various scenarios have appeared one after another, for example, social network-based recommendation, scenario-aware recommendation, geographic location-based recommendation, etc., and recommender systems are moving towards diversified and personalized development. In this paper, we explore the feature representation in current recommendation algorithms in the application scenario of video recommendation. Efficient feature representations can mine the user's hidden information and thus improve the accuracy of recommendations. An attention mechanism is introduced to propose a deep collaborative filtering recommendation model based on attention. Extensive experiments on real datasets validate the effectiveness of the model recommendations.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3222830/v1"
    },
    {
        "id": 10519,
        "title": "Hierarchical Gated Convolutional Networks with Multi-Head Attention for Text Classification",
        "authors": "Haizhou Du, Jingu Qian",
        "published": "2018-11",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icsai.2018.8599366"
    },
    {
        "id": 10520,
        "title": "Gmasegan: A Global Multi-Head Attention Speech Enhancement Generative Adversarial Network",
        "authors": "Minghang Chu, Yaoyao Ma, Zhiwei Fan, Mengtao Yang, Zhi Tao, Di Wu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4395061"
    },
    {
        "id": 10521,
        "title": "A Multi-Head Convolution Network with Attention Consistency for Facial Expression Recognition",
        "authors": "Wenkang Liu, Mingyi Sun, Yang Li",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/ccc58697.2023.10240537"
    },
    {
        "id": 10522,
        "title": "Local Multi-Head Channel Self-Attention for Facial Expression Recognition",
        "authors": "Roberto Pecoraro, Valerio Basile, Viviana Bono",
        "published": "2022-9-6",
        "citations": 29,
        "abstract": "Since the Transformer architecture was introduced in 2017, there has been many attempts to bring the self-attention paradigm in the field of computer vision. In this paper, we propose LHC: Local multi-Head Channel self-attention, a novel self-attention module that can be easily integrated into virtually every convolutional neural network, and that is specifically designed for computer vision, with a specific focus on facial expression recognition. LHC is based on two main ideas: first, we think that in computer vision, the best way to leverage the self-attention paradigm is the channel-wise application instead of the more well explored spatial attention. Secondly, a local approach has the potential to better overcome the limitations of convolution than global attention, at least in those scenarios where images have a constant general structure, as in facial expression recognition. LHC-Net achieves a new state-of-the-art in the FER2013 dataset, with a significantly lower complexity and impact on the “host” architecture in terms of computational cost when compared with the previous state-of-the-art.",
        "link": "http://dx.doi.org/10.3390/info13090419"
    },
    {
        "id": 10523,
        "title": "A multi-scale graph network with multi-head attention for histopathological diagnosis of gliomas",
        "authors": "Lei Jin, Xiaodan Xing, Yixin Ma, Tianyang Sun, Hong Chen, Feng Shi, Jinsong Wu",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14791/btrt.2022.10.f-2588"
    },
    {
        "id": 10524,
        "title": "Multi-Horizon Electricity Load and Price Forecasting Using an Interpretable Multi-Head Self-Attention and EEMD-Based Framework",
        "authors": "Muhammad Furqan Azam, Muhammad Shahzad Younis",
        "published": "2021",
        "citations": 28,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2021.3086039"
    },
    {
        "id": 10525,
        "title": "Parallel multi-head dot product attention for video summarization",
        "authors": "Bohdan Bilonoh, Sergii Mashtalir",
        "published": "2020-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dsmp47368.2020.9204059"
    },
    {
        "id": 10526,
        "title": "Multi-Head Attention for Multi-Modal Joint Vehicle Motion Forecasting",
        "authors": "Jean Mercat, Thomas Gilles, Nicole El Zoghby, Guillaume Sandou, Dominique Beauvois, Guillermo Pita Gil",
        "published": "2020-5",
        "citations": 81,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icra40945.2020.9197340"
    },
    {
        "id": 10527,
        "title": "On the diversity of multi-head attention",
        "authors": "Jian Li, Xing Wang, Zhaopeng Tu, Michael R. Lyu",
        "published": "2021-9",
        "citations": 22,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neucom.2021.04.038"
    },
    {
        "id": 10528,
        "title": "U-Former: Improving Monaural Speech Enhancement with Multi-head Self and Cross Attention",
        "authors": "Xinmeng Xu, Jianjun Hao",
        "published": "2022-8-21",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icpr56361.2022.9956638"
    },
    {
        "id": 10529,
        "title": "Emotion Recognition from Brain Connectivity Based on Multi-Head Attention Transformer and Autoencoder Network",
        "authors": "Farzad Saffari, Mikkel N Schmidt, Massimo Buscema, Luis E Bruni",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36227/techrxiv.170420879.92145482/v1"
    },
    {
        "id": 10530,
        "title": "Sequential Recommendation Using Deep Reinforcement Learning and Multi-Head Attention",
        "authors": "Raneem Sultan, Mervat Abu-Elkheir",
        "published": "2022-3-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ciss53076.2022.9751174"
    },
    {
        "id": 10531,
        "title": "Nested Deformable Multi-head Attention for Facial Image Inpainting",
        "authors": "Shruti S Phutke, Subrahmanyam Murala",
        "published": "2023-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00602"
    },
    {
        "id": 10532,
        "title": "Session-based recommendation: Learning multi-dimension interests via a multi-head attention graph neural network",
        "authors": "Yao Chen, Qi Xiong, Yina Guo",
        "published": "2022-12",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.asoc.2022.109744"
    },
    {
        "id": 10533,
        "title": "Prediction of Drug-Target Interaction Based on Multi-Head Self-Attention",
        "authors": "Xin Ma, Yujing Cheng",
        "published": "2022-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tocs56154.2022.10016085"
    },
    {
        "id": 10534,
        "title": "Bidirectional GRU with Multi-Head Attention for Chinese NER",
        "authors": "Shuo Yan, Jianping Chai, Liyun Wu",
        "published": "2020-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/itoec49072.2020.9141551"
    },
    {
        "id": 10535,
        "title": "Multi-Head Attention on Image Captioning Model with Bert Embedding",
        "authors": "Supragya Sonkar, Sriram G. Sanjeevi",
        "published": "2021-6-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccisc52257.2021.9485000"
    },
    {
        "id": 10536,
        "title": "Research on Transportation Mode Recognition Based on Multi-Head Attention Temporal Convolutional Network",
        "authors": "Shuyu Cheng, Yingan Liu",
        "published": "2023-3-29",
        "citations": 3,
        "abstract": "Transportation mode recognition is of great importance in analyzing people’s travel patterns and planning urban roads. To make more accurate judgments on the transportation mode of the user, we propose a deep learning fusion model based on multi-head attentional temporal convolution (TCMH). First, the time-domain features of a more extensive range of sensor data are mined through a temporal convolutional network. Second, multi-head attention mechanisms are introduced to learn the significance of different features and timesteps, which can improve the identification accuracy. Finally, the deep-learned features are fed into a fully connected layer to output the classification results of the transportation mode. The experimental results demonstrate that the TCMH model achieves an accuracy of 90.25% and 89.55% on the SHL and HTC datasets, respectively, which is 4.45% and 4.70% higher than the optimal value in the baseline algorithm. The model has a better recognition effect on transportation modes.",
        "link": "http://dx.doi.org/10.3390/s23073585"
    },
    {
        "id": 10537,
        "title": "Masked multi-head self-attention for causal speech enhancement",
        "authors": "Aaron Nicolson, Kuldip K. Paliwal",
        "published": "2020-12",
        "citations": 45,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.specom.2020.10.004"
    },
    {
        "id": 10538,
        "title": "MA-VAE: Multi-Head Attention-Based Variational Autoencoder Approach for Anomaly Detection in Multivariate Time-Series Applied to Automotive Endurance Powertrain Testing",
        "authors": "Lucas Correia, Jan-Christoph Goos, Philipp Klein, Thomas Bäck, Anna Kononova",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012163100003595"
    },
    {
        "id": 10539,
        "title": "EfficientNet and multi-path convolution with multi-head attention network for brain tumor grade classification",
        "authors": "B. Venkateswarlu Isunuri, Jagadeesh Kakarla",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.compeleceng.2023.108700"
    },
    {
        "id": 10540,
        "title": "Multi-Attn BLS: Multi-head attention mechanism with broad learning system for chaotic time series prediction",
        "authors": "Liyun Su, Lang Xiong, Jialing Yang",
        "published": "2023-1",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.asoc.2022.109831"
    },
    {
        "id": 10541,
        "title": "Improving Visual Speech Enhancement Network by Learning Audio-visual Affinity with Multi-head Attention",
        "authors": "Xinmeng Xu, Yang Wang, Jie Jia, Binbin Chen, Dejun Li",
        "published": "2022-9-18",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2022-10041"
    },
    {
        "id": 10542,
        "title": "TMH: Two-Tower Multi-Head Attention neural network for CTR prediction",
        "authors": "Zijian An, Inwhee Joe",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "Click-through rate (CTR) prediction is a term used to predict the probability of a user clicking on an ad or item and has become a popular research area in advertising. As the volume of Internet data increases, the labor costs of traditional feature engineering continue to rise. To reduce the dependence on feature interactions, this paper proposes a fusion model that combines explicit and implicit feature interactions, called the Two-Tower Multi-Head Attention Neural Network (TMH) approach. The model integrates multiple components such as multi-head attention, residual network, and deep neural networks into an end-to-end model that automatically obtains vector-level combinations of explicit and implicit features to predict click-through rates through higher-order explicit and implicit interactions. We evaluated the effectiveness of TMH in CTR prediction through numerous experiments using three real datasets. The results demonstrate that our proposed method not only outperforms existing prediction methods but also offers good interpretability.",
        "link": "http://dx.doi.org/10.1371/journal.pone.0295440"
    },
    {
        "id": 10543,
        "title": "Double Multi-Head Attention for Speaker Verification",
        "authors": "Miquel India, Pooyan Safari, Javier Hernando",
        "published": "2021-6-6",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp39728.2021.9414877"
    },
    {
        "id": 10544,
        "title": "An Ensemble-based Regularization Method for Multi-Head Attention",
        "authors": "J. X. Xiao, Yuexian Hou, Ke Luo",
        "published": "2021-5-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ccai50917.2021.9447483"
    },
    {
        "id": 10545,
        "title": "An Efficient Audio-visual Speech Enhancement Network via Multi-head Attention",
        "authors": "Min Yang, Jianjun Hao",
        "published": "2023-5-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icaibd57115.2023.10206147"
    },
    {
        "id": 10546,
        "title": "HeartNet: Self Multi-Head Attention Mechanism via Convolutional Network with Adversarial Data Synthesis for ECG-based Arrhythmia Classification",
        "authors": "Taki Hasan Rafi, Young Woong-Ko",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractCardiovascular disease is now one of the leading causes of morbidity and mortality in humans. Electrocardiogram (ECG) is a reliable tool for monitoring the health of the cardiovascular system. Currently, there has been a lot of focus on accurately categorizing heartbeats. There is a high demand on automatic ECG classification systems to assist medical professionals. In this paper we proposed a new deep learning method called HeartNet for developing an automatic ECG classifier. The proposed deep learning method is compressed by multi-head attention mechanism on top of CNN model. The main challenge of insufficient data label is solved by adversarial data synthesis adopting generative adversarial network (GAN) with generating additional training samples. It drastically improves the overall performance of the proposed method by 5-10% on each insufficient data label category. We evaluated our proposed method utilizing MIT-BIH dataset. Our proposed method has shown 99.67 ± 0.11 accuracy and 89.24 ± 1.71 MCC trained with adversarial data synthesized dataset. However, we have also utilized two individual datasets such as Atrial Fibrillation Detection Database and PTB Diagnostic Database to see the performance of our proposed model on ECG classification. The effectiveness and robustness of proposed method are validated by extensive experiments, comparison and analysis. Later on, we also highlighted some limitations of this work.",
        "link": "http://dx.doi.org/10.1101/2021.12.20.21268090"
    },
    {
        "id": 10547,
        "title": "Multi-Head Self Attention for Enhanced Object Detection in the Maritime Domain",
        "authors": "Walid Messaoud, Rim Trabelsi, Adnane Cabani, Fatma Abdelkefi",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cw58918.2023.00034"
    },
    {
        "id": 10548,
        "title": "Emotion Recognition based on Physiological Signals Multi-head Attention Contrastive Learning",
        "authors": "Yunfei Guo, Tao Zhang, Wu Huang",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bibm58861.2023.10385711"
    },
    {
        "id": 10549,
        "title": "Recurrent multi-head attention fusion network for combining audio and text for speech emotion recognition",
        "authors": "Chung-Soo Ahn, Chamara Kasun, Sunil Sivadas, Jagath Rajapakse",
        "published": "2022-9-18",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2022-888"
    },
    {
        "id": 10550,
        "title": "Stance Detection Using Multi-Head Attention Based Bidirectional GRU",
        "authors": "Peng Jia, Yajun Du, Binyan Lyu, Ruilin Hu",
        "published": "2021-12-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccc54389.2021.9674443"
    },
    {
        "id": 10551,
        "title": "Multi-Head Self-Attention GANs for Multiphysics Topology Optimization",
        "authors": "Corey Parrott, Diab Abueidda, Kai A. James",
        "published": "2022-6-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2514/6.2022-3726"
    },
    {
        "id": 10552,
        "title": "A Novel Convolution Kernel with Multi-head Self-attention",
        "authors": "Ming Gao, Huailin Zhao, Mingfang Deng",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iciibms60103.2023.10347796"
    },
    {
        "id": 10553,
        "title": "Vision and Language Navigation using Multi-head Attention Mechanism",
        "authors": "Sai Mao, Junmin Wu, Siqi Hong",
        "published": "2020-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdia51454.2020.00020"
    },
    {
        "id": 10554,
        "title": "Enhancing System Inertia Estimation: Multi-Head Graph Attention Networks Leveraging PMU Measurements",
        "authors": "Faisal Albeladi, Kamal Basulaiman, Masoud Barati",
        "published": "2024-2-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tpec60005.2024.10472224"
    },
    {
        "id": 10555,
        "title": "Multi-head Self-attention Recommendation Model based on Feature Interaction Enhancement",
        "authors": "Yunfei Yin, Caihao Huang, Jingqin Sun, Faliang Huang",
        "published": "2022-5-16",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icc45855.2022.9839284"
    },
    {
        "id": 10556,
        "title": "Lane Change Intention Prediction of CNN-LSTM Based on Multi-head Attention",
        "authors": "",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3901/jme.2022.22.369"
    },
    {
        "id": 10557,
        "title": "Multimodal sentiment analysis based on multi-head self-attention and convolutional block attention module",
        "authors": "Feng Geng, Hai Yang, Changde Wu, Jinqiang Li",
        "published": "2022-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aemcse55572.2022.00059"
    },
    {
        "id": 10558,
        "title": "Lane detection algorithm based on multi-head self-attention and multi-level feature fusion",
        "authors": "Bobo Guo, Zanxia Qiang, Xianfu Bao, Yao Xu",
        "published": "2023-4-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2671212"
    },
    {
        "id": 10559,
        "title": "Interpreting and Exploiting Functional Specialization in Multi-Head Attention under Multi-task Learning",
        "authors": "Chong Li, Shaonan Wang, Yunhao Zhang, Jiajun Zhang, Chengqing Zong",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.1026"
    }
]