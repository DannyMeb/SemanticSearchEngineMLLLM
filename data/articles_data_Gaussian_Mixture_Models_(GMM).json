[
    {
        "id": 1801,
        "title": "Parameter estimation of Gaussian mixture models (GMM) with expectation maximization (EM) algorithm",
        "authors": "Wardatul Jannah, Dewi R. S. Saputro",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/5.0117119"
    },
    {
        "id": 1802,
        "title": "Model Identifikasi Pemalsuan Ijazah menggunakan Gabor Wavelet dan Gaussian Mixture Models Super Vektor (GMM-SV)",
        "authors": "Alfina Alfina, Dzulgunar Muhammad Nasir",
        "published": "2020-8-29",
        "citations": 0,
        "abstract": "Various cases occur related to certificate falsification and some people and educational institutions have to deal with the law, this problem is not impossible to abuse along with advances and technological innovation with various tools that can be used by anyone. Identifying the diploma document must be of particular concern to tertiary institutions to minimize the associated fake diplomas and the diploma legalization process. In legalizing the diploma for STMIK Indonesia Banda Aceh students, checking the authenticity of the certificate is only by bringing the original certificate and photocopy of the certificate or by contacting the academic party who issued the certificate, this process is sometimes missed by officers when the queue is crowded. The specific objectives of the research include implementing a model and feature method of Gabor Wavelet and Gaussian Mixture Models Super Vector (GMM-SV) for document identification to speed up diploma identification. The flow of this research starts from the input in the form of a basic image as an image that a reference for the authenticity of the diploma. Then the test image input is an image that will be tested for authenticity. The results showed that using the Gabor Wavelet feature and the Gaussian Mixture Models Super Vector (GMM-SV) could identify fake diplomas with an accuracy rate of 92.8%.Keywords:Model, Identification, Certificate Falsification, Gabor Wavelet, Gaussian Mixture Models Super Vector (GMM-SV).",
        "link": "http://dx.doi.org/10.35870/jtik.v4i2.142"
    },
    {
        "id": 1803,
        "title": "Antenna Classification Using Gaussian Mixture Models (GMM) and Machine Learning",
        "authors": "Yihan Ma, Yang Hao",
        "published": "2020",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ojap.2020.3008130"
    },
    {
        "id": 1804,
        "title": "Segmentation of Stacked Leaf Images for Enhanced Visual Monitoring Using Gaussian Mixture Models (GMM) Algorithms",
        "authors": "Suyud Widiono, Edi Noersasongko,  Purwanto, M. Arief Soeleman",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isriti60336.2023.10467486"
    },
    {
        "id": 1805,
        "title": "Classifier Fusion Based on Gaussian Mixture Models (GMM) and Support Vector Machine (SVM) in the Function of Classification Emotional Speech, Using Spectral and Prosodic Features",
        "authors": "D. Veljković, D. Rančić",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/miel58498.2023.10315792"
    },
    {
        "id": 1806,
        "title": "Evolving Gaussian Mixture Models for Classification",
        "authors": "Simon Reichhuber, Sven Tomforde",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010984900003116"
    },
    {
        "id": 1807,
        "title": "Exoskeleton Control Based on Network of Stable Heteroclinic Channels (SHC) Combined with Gaussian Mixture Models (GMM)",
        "authors": "Tadej Petrič, Marko Jamšek, Jan Babič",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-50975-0_42"
    },
    {
        "id": 1808,
        "title": "Gaussian Mixture Model (GMM) Based Dynamic Object Detection and Tracking",
        "authors": "Vishnu Anand, Durgakant Pushp, Rishin Raj, Kaushik Das",
        "published": "2019-6",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icuas.2019.8797927"
    },
    {
        "id": 1809,
        "title": "Determination of Hidden Extrapolations via Gaussian Mixture Models",
        "authors": "ROSS PIVOVAR",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31224/2349"
    },
    {
        "id": 1810,
        "title": "Application of Gaussian Mixture Model (GMM) Cluster Analysis on Morphological Data of Archaeological Human Remains",
        "authors": "Andrea Göhring, Martin Gruber, Kai Kaniuth",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3940897"
    },
    {
        "id": 1811,
        "title": "Engine Overheating Prediction with Machine Learning Using Gaussian Mixture Model (GMM)",
        "authors": "Shrikant Deokrishna Hiwase, PRAMOD JAGTAP, Dinesh Krishna",
        "published": "2022-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4271/2022-28-0007"
    },
    {
        "id": 1812,
        "title": "Build a Model for Speech Emotion Recognition using Gaussian Mixture Model (GMM)",
        "authors": "Tirumalasetti Teja Sri, Suraki Ravi Kishan, Kakani Naga Rahul Chowdary, Pandiri Sainath",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/incoft60753.2023.10425275"
    },
    {
        "id": 1813,
        "title": "Truck Driver Safety Tendency Classification under Natural Driving Conditions Based on Gaussian Mixture Model (GMM)",
        "authors": "Xiang Zhang, Lei Zhao, Jian Wang, Changlei Wen, Ting Xu",
        "published": "2020-12-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1061/9780784483053.365"
    },
    {
        "id": 1814,
        "title": "Defect Detection Enhancement Using Gaussian Mixture Models",
        "authors": "Amir Movafeghi, Mahdi Mirzapour, Effat Yahaghi",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4522978"
    },
    {
        "id": 1815,
        "title": "Instar determination by constrained gaussian mixture models according to Dyar’s rule",
        "authors": "Sungmin Ji",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractDespite its importance in ecological studies and pest controls, the lack of knowledge of the life cycle and the ambiguity of data challenge the accurate determination of insect nymphs regarding many insect species. Finite mixture models are often utilized to classify instars without knowing the instar number. This study derives parsimonious gaussian mixture models using parameter constraints motivated by Dyar’s rule. Dyar’s rule explains the growth pattern of larvae and nymphs of insects by assuming a constant ratio of head capsule width for every two adjacent development stages. Accordingly, every mean value of log-transformed data in each instar stage is considered a linear function, where two Dyar constants are an intercept and a slope for the instar stages, respectively, to infer the instar stage of samples. The common variance for every instar stage regarding log-transformed data can be assumed in a mixture model, as well. If valid, these assumptions will allow an efficient estimation of the model by reducing free parameters. As a result, four model hypotheses are proposed for each assumption of instar counts depending on whether these two parameter constraints are applied. After model estimation, the proposed method uses the ICL criterion to choose the optimal counts of nymphal stages, and parametric bootstrap LR tests are applied to decide the most efficient model regarding parameter constraints. The proposed method could attain the correct model settings during the simulation study. This study also discusses the interpretation of the results of real insect data sets that concord with Dyar’s rule or not.",
        "link": "http://dx.doi.org/10.1101/2022.12.26.521363"
    },
    {
        "id": 1816,
        "title": "1d Split Rules for Incremental Gaussian Mixture Models Estimation",
        "authors": "Nicola Greggio, Alexandre Bernardino",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4332121"
    },
    {
        "id": 1817,
        "title": "Gaussian Mixture Model (GMM) Based Object Detection and Tracking using Dynamic Patch Estimation",
        "authors": "Vishnu Anand, Durgakant Pushp, Rishin Raj, Kaushik Das",
        "published": "2019-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iros40897.2019.8968275"
    },
    {
        "id": 1818,
        "title": "Data-Driven Remaining Useful Life Estimation Using Gaussian Mixture Models",
        "authors": "",
        "published": "2020-1-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2514/6.2021-1487.vid"
    },
    {
        "id": 1819,
        "title": "em-Test for Univariate Finite Gaussian Mixture Models",
        "authors": "Jiahua Chen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-99-6141-2_15"
    },
    {
        "id": 1820,
        "title": "Density Estimation with Gaussian Mixture Models",
        "authors": "",
        "published": "2020-2-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108679930.013"
    },
    {
        "id": 1821,
        "title": "GMM-VRD: A Gaussian Mixture Model for Dealing With Virtual and Real Concept Drifts",
        "authors": "Gustavo H. F. M. Oliveira, Leandro L. Minku, Adriano L. I. Oliveira",
        "published": "2019-7",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2019.8852097"
    },
    {
        "id": 1822,
        "title": "Feature Extraction and Classification of Speech Signal Using Hidden Markov-Gaussian Mixture Model (HM-GMM) for Driving the Rehabilitative Aids",
        "authors": "Abhishek Kushwaha, Uvanesh Kasiviswanathan, Shiru Sharma",
        "published": "2017-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/indicon.2017.8487963"
    },
    {
        "id": 1823,
        "title": "An introduction to growth mixture models (GMM)",
        "authors": "Tae Kyoung Lee, Kandauda A.S. Wickrama, Catherine Walker O'Neal",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-818630-5.10076-4"
    },
    {
        "id": 1824,
        "title": "UoR at SemEval-2020 Task 8: Gaussian Mixture Modelling (GMM) Based Sampling Approach for Multi-modal Memotion Analysis",
        "authors": "Zehao Liu, Emmanuel Osei-Brefo, Siyuan Chen, Huizhi Liang",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.semeval-1.159"
    },
    {
        "id": 1825,
        "title": "Comparison Between Classification Algorithms: Gaussian Mixture Model - GMM and Random Forest - RF, for Landsat 8 Images",
        "authors": "Daniel Assunção Pantoja, Débora Spenassato, Leonardo Ramos Emmendorfer",
        "published": "2023-3-14",
        "citations": 2,
        "abstract": "Purpose: Given the importance of monitoring and managing land cover, especially in countries with continental proportions, such as Brazil. This research aimed to compare two remote sensing image classifier algorithms.\r\n \r\nMethod/design/approach: The article compared the Gaussian Mixture Model and Random Forest classification algorithms, using Landsat 8 image, which was classified in a supervised way, in the Dezetsaka plugin of QGIS. The analysis of the performance of each model was performed using the Kappa index and Total Accuracy.\r\n \r\nResults and conclusion: The results showed that the Random Forest algorithm was more efficient than the Gaussian Mixture Model. Taking the Kappa Index (K) and Total Accuracy (po), the models obtained the following performances in the classification of classes: the Random Forest Model (K= 0.94 and po= 96.31) and the Gaussian Mixture Model obtained (K=0.85 and po=90.60).\r\n \r\nResearch implications: The results can support the choice of classification method by researchers and others interested in monitoring land cover.\r\n \r\nOriginality/value: This is a unique proposal, which compares an algorithm based on Machine Learning with another one from the category of probabilistic models. Interesting, since machine learning techniques have been gaining notoriety in several contexts.",
        "link": "http://dx.doi.org/10.24857/rgsa.v16n3-015"
    },
    {
        "id": 1826,
        "title": "PRIMAL-GMM: PaRametrIc MAnifold Learning of Gaussian Mixture Models",
        "authors": "Ziquan Liu, Lei Yu, Janet H. Hsiao, Antoni B. Chan",
        "published": "2022-6-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tpami.2020.3048727"
    },
    {
        "id": 1827,
        "title": "GAUSSIAN MIXTURE MODEL (GMM) BASED K-MEANS METHOD FOR SPEECH CLUSTERING",
        "authors": "K Rajendra Prasad,  ",
        "published": "2017-8-20",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26483/ijarcs.v8i7.4354"
    },
    {
        "id": 1828,
        "title": "Super Pixel Segmentation Using Fuzzy Genetic Filter (FGF) with Gaussian Mixture Models (GMMs)",
        "authors": "V. Kiruthika, R. Karpagam",
        "published": "2019-9-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5373/jardcs/v11i9/20192918"
    },
    {
        "id": 1829,
        "title": "Gradient-based training of Gaussian Mixture Models for High-Dimensional Streaming Data",
        "authors": "Alexander Gepperth, Benedikt Pfülb",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nWe present an approach for efficiently training Gaussian Mixture Model (GMM) by Stochastic Gradient Descent (SGD) with non-stationary, high-dimensional streaming data. Our training scheme does not require data-driven parameter initialization (e.g., k-means) and can thus be trained based on a random initialization. Furthermore, the approach allows mini-batch sizes as low as 1, which are typical for streaming-data settings. Major problems in such settings are undesirable local optima during early training phases and numerical instabilities due to high data dimensionalities. We introduce an adaptive annealing procedure to address the first problem, whereas numerical instabilities are eliminated by using an exponential-free approximation to the standard GMM log-likelihood. Experiments on a variety of visual and non-visual benchmarks show that our SGD approach can be trained completely without, for instance, k-means based centroid initialization. It also compares favorably to an online variant of Expectation-Maximization (EM) – stochastic EM (sEM), which it outperforms by a large margin for very high-dimensional data.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-369722/v1"
    },
    {
        "id": 1830,
        "title": "GAT–GMM: Generative Adversarial Training for Gaussian Mixture Models",
        "authors": "Farzan Farnia, William W. Wang, Subhro Das, Ali Jadbabaie",
        "published": "2023-3-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1137/21m1445831"
    },
    {
        "id": 1831,
        "title": "Gaussian Mixture Models with Concave Penalized Fusion",
        "authors": "Yiwei Fan, Guosheng Yin",
        "published": "2025",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5705/ss.202022.0092"
    },
    {
        "id": 1832,
        "title": "GMM-LSTM: a component driven resource utilization prediction model leveraging LSTM and gaussian mixture model",
        "authors": "Sheetal Garg, Rohit Ahuja, Raman Singh, Ivan Perl",
        "published": "2023-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s10586-022-03747-4"
    },
    {
        "id": 1833,
        "title": "Direct Fitting of Gaussian Mixture Models",
        "authors": "Leonid Keselman, Martial Hebert",
        "published": "2019-5",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/crv.2019.00012"
    },
    {
        "id": 1834,
        "title": "Model Selection for Gaussian Mixture Models",
        "authors": "Tao Huang, Heng Peng, Kun Zhang",
        "published": "2017",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5705/ss.2014.105"
    },
    {
        "id": 1835,
        "title": "A Gaussian Mixture Model-Hidden Markov Model (GMM-HMM)-based fiber optic surveillance system for pipeline integrity threat detection",
        "authors": "J. Tejedor, J. Macias-Guarasa, H. F. Martins, S. Martin-Lopez, M. Gonzalez-Herraez",
        "published": "2018",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1364/ofs.2018.wf36"
    },
    {
        "id": 1836,
        "title": "Anchored Bayesian Gaussian mixture models",
        "authors": "Deborah Kunkel, Mario Peruggia",
        "published": "2020-1-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1214/20-ejs1756"
    },
    {
        "id": 1837,
        "title": "Fast Reinforcement Learning with Incremental Gaussian Mixture Models",
        "authors": "Rafael Pinto",
        "published": "2021-7-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn52387.2021.9533632"
    },
    {
        "id": 1838,
        "title": "Meta-learning representations for clustering with infinite Gaussian mixture models",
        "authors": "Tomoharu Iwata",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neucom.2023.126423"
    },
    {
        "id": 1839,
        "title": "Spike sorting with Gaussian mixture models",
        "authors": "Bryan C. Souza, Vítor Lopes-dos-Santos, João Bacelo, Adriano B. L. Tort",
        "published": "No Date",
        "citations": 2,
        "abstract": "AbstractThe shape of extracellularly recorded action potentials is a product of several variables, such as the biophysical and anatomical properties of the neuron and the relative position of the electrode. This allows for isolating spikes of different neurons recorded in the same channel into clusters based on waveform features. However, correctly classifying spike waveforms into their underlying neuronal sources remains a main challenge. This process, called spike sorting, typically consists of two steps: (1) extracting relevant waveform features (e.g., height, width), and (2) clustering them into non-overlapping groups believed to correspond to different neurons. In this study, we explored the performance of Gaussian mixture models (GMMs) in these two steps. We extracted relevant waveform features using a combination of common techniques (e.g., principal components and wavelets) and GMM fitting parameters (e.g., standard deviations and peak distances). Then, we developed an approach to perform unsupervised clustering using GMMs, which estimates cluster properties in a data-driven way. Our results show that the proposed GMM-based framework outperforms previously established methods when using realistic simulations of extracellular spikes and actual extracellular recordings to evaluate sorting performance. We also discuss potentially better techniques for feature extraction than the widely used principal components. Finally, we provide a friendly graphical user interface in MATLAB to run our algorithm, which allows for manual adjustment of the automatic results.",
        "link": "http://dx.doi.org/10.1101/248864"
    },
    {
        "id": 1840,
        "title": "Sensor-Aided NILM with Gaussian Mixture Models",
        "authors": "Nidhal Balti, Baptiste Vrigneau, Pascal Scalart",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/eusipco58844.2023.10289785"
    },
    {
        "id": 1841,
        "title": "Image Modeling with Deep Convolutional Gaussian Mixture Models",
        "authors": "Alexander Gepperth, Benedikt Pfulb",
        "published": "2021-7-18",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn52387.2021.9533745"
    },
    {
        "id": 1842,
        "title": "A Universal Approximation Theorem for Gaussian-Gated Mixture of Experts Models",
        "authors": "Hien Nguyen",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2946964"
    },
    {
        "id": 1843,
        "title": "Detecting Extreme Temperature Events Using Gaussian Mixture Models",
        "authors": "Aytaç Paçal, Birgit Hassler, Katja Weigel, M. Levent Kurnaz, Veronika Eyring",
        "published": "No Date",
        "citations": 0,
        "abstract": "Extreme events are rare atmospheric phenomena that cause signi&#64257;cant damage to humans and natural systems, but detecting extreme events in the future in a changing climate can be challenging. Traditionally, temperature distributions were assumed to follow a normal distribution and certain thresholds were used to define extreme events. However, the mean and the variance of temperatures are expected to change in a future climate, which might limit the application of traditional methods for detecting extreme events.We found that daily maximum surface temperature data can be described accurately using a multimodal distribution. In this study, we therefore used a statistical method called Gaussian Mixture Models (GMM) to fit a multimodal distribution to daily near-surface maximum air temperature data from simulations participating in the Coupled Model Intercomparison Project Phase 6 (CMIP6) for 46 Intergovernmental Panel on Climate Change (IPCC) land regions. GMM allowed us to use the parameters from the Gaussian distribution &#64257;tted to the higher temperatures to define the thresholds for the return period of extreme events. We analysed the change in the return periods of extreme temperature events in study regions compared to the historical period (1980-2010) under future Global Warming Levels (GWL) of 1.5&#176;C, 2&#176;C, 3&#176;C and 4&#176;C for each Shared Socioeconomic Pathways (SSP) scenarios.&#160;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-13740"
    },
    {
        "id": 1844,
        "title": "Gaussian mixture models for clustering and calibration of ensemble weather forecasts",
        "authors": "Gabriel Jouan, Anne Cuzol, Valérie Monbet, Goulven Monnier",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;p&gt;Nowadays, most weather forecasting centers produce ensemble forecasts. &amp;#160;Ensemble forecasts provide information about probability distribution of the weather variables. They give a more complete description of the atmosphere than a unique run of the meteorological model. However, they may suffer from bias and under/over dispersion errors that need to be corrected. These distribution errors may depend on weather regimes. In this paper, we propose various extensions of the Gaussian mixture model and its associated inference tools for ensemble data sets. &amp;#160;The proposed models are then used to identify clusters which correspond to different types of distribution errors. Finally, a standard calibration method known as Non homogeneous Gaussian Regression (NGR) &amp;#160;is applied cluster by cluster in order to correct ensemble forecast distributions. It is shown that the proposed methodology is effective, interpretable and easy to use. &amp;#160;The clustering algorithms are illustrated on simulated and real data. The calibration method is applied to real data of temperature and wind medium range forecast for 3 stations in France.&amp;#160;&lt;/p&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu22-2311"
    },
    {
        "id": 1845,
        "title": "Gaussian Mixture Models",
        "authors": "",
        "published": "2018-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789813271234_0013"
    },
    {
        "id": 1846,
        "title": "MGMM: An R Package for fitting Gaussian Mixture Models on Incomplete Data",
        "authors": "Zachary R. McCaw, Hanna Julienne, Hugues Aschard",
        "published": "No Date",
        "citations": 2,
        "abstract": "AbstractAlthough missing data are prevalent in applications, existing implementations of Gaussian mixture models (GMMs) require complete data. Standard practice is to perform complete case analysis or imputation prior to model fitting. Both approaches have serious drawbacks, potentially resulting in biased and unstable parameter estimates. Here we present MGMM, an R package for fitting GMMs in the presence of missing data. Using three case studies on real and simulated data sets, we demonstrate that, when the underlying distribution is near-to a GMM, MGMM is more effective at recovering the true cluster assignments than state of the art imputation followed by standard GMM. Moreover, MGMM provides an accurate assessment of cluster assignment uncertainty even when the generative distribution is not a GMM. This assessment may be used to identify unassignable observations. MGMM is available as an R package on CRAN: https://CRAN.R-project.org/package=MGMM.",
        "link": "http://dx.doi.org/10.1101/2019.12.20.884551"
    },
    {
        "id": 1847,
        "title": "A Gaussian Mixture Model Approach to Classifying Response Types",
        "authors": "Owen E. Parsons",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-23876-6_1"
    },
    {
        "id": 1848,
        "title": "Multivariate Bounded Asymmetric Gaussian Mixture Model",
        "authors": "Muhammad Azam, Basim Alghabashi, Nizar Bouguila",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-23876-6_4"
    },
    {
        "id": 1849,
        "title": "Review for \"Modeling state‐transition dynamics in resting‐state brain signals by the hidden Markov and Gaussian mixture models\"",
        "authors": " Diego Vidaurre",
        "published": "2021-6-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/ejn.15386/v2/review1"
    },
    {
        "id": 1850,
        "title": "Review for \"Modeling state‐transition dynamics in resting‐state brain signals by the hidden Markov and Gaussian mixture models\"",
        "authors": "STAVROS DIMITRIADIS",
        "published": "2021-6-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/ejn.15386/v2/review2"
    },
    {
        "id": 1851,
        "title": "Peer Review #1 of \"Solution strategy based on Gaussian mixture models and dispersion reduction for the capacitated centered clustering problem (v0.1)\"",
        "authors": "",
        "published": "2021-2-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.332v0.1/reviews/1"
    },
    {
        "id": 1852,
        "title": "Peer Review #4 of \"Solution strategy based on Gaussian mixture models and dispersion reduction for the capacitated centered clustering problem (v0.1)\"",
        "authors": "",
        "published": "2021-2-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.332v0.1/reviews/4"
    },
    {
        "id": 1853,
        "title": "Hierarchical Network Exploration using Gaussian Mixture Models",
        "authors": "James Mathews, Saad Nadeem, Maryam Pouryahya, Zehor Belkhatir, Joseph O. Deasy, Allen Tannenbaum",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractWe present a framework based on optimal mass transport to construct, for a given network, a reduction hierarchy which can be used for interactive data exploration and community detection. Given a network and a set of numerical data samples for each node, we calculate a new computationally-efficient comparison metric between Gaussian Mixture Models, the Gaussian Mixture Transport distance, to determine a series of merge simplifications of the network. If only a network is given, numerical samples are synthesized from the network topology. The method has its basis in the local connection structure of the network, as well as the joint distribution of the data associated with neighboring nodes.The analysis is benchmarked on networks with known community structures. We also analyze gene regulatory networks, including the PANTHER curated database and networks inferred from the GTEx lung and breast tissue RNA profiles. Gene Ontology annotations from the EBI GOA database are ranked and superimposed to explain the salient gene modules. We find that several gene modules related to highly specific biological processes are well-coordinated in such tissues. We also find that 18 of the 50 genes of the PAM50 breast-tumor prognostic signature appear among the highly coordinated genes in a single gene module, in both the breast and lung samples. Moreover these 18 are precisely the subset of the PAM50 recently identified as the basal-like markers.",
        "link": "http://dx.doi.org/10.1101/623157"
    },
    {
        "id": 1854,
        "title": "On-line signature verification based on Gaussian mixture models",
        "authors": "Lou Yang, Mandan Liu",
        "published": "2017-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ccdc.2017.7978096"
    },
    {
        "id": 1855,
        "title": "Review for \"Modeling state‐transition dynamics in resting‐state brain signals by the hidden Markov and Gaussian mixture models\"",
        "authors": " Diego Vidaurre",
        "published": "2020-5-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/ejn.15386/v1/review2"
    },
    {
        "id": 1856,
        "title": "Peer Review #4 of \"Solution strategy based on Gaussian mixture models and dispersion reduction for the capacitated centered clustering problem (v0.2)\"",
        "authors": "",
        "published": "2021-2-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.332v0.2/reviews/4"
    },
    {
        "id": 1857,
        "title": "Peer Review #3 of \"Solution strategy based on Gaussian mixture models and dispersion reduction for the capacitated centered clustering problem (v0.1)\"",
        "authors": "",
        "published": "2021-2-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.332v0.1/reviews/3"
    },
    {
        "id": 1858,
        "title": "On the Influence of Data Imbalance on Supervised Gaussian Mixture Models",
        "authors": "Luca Scrucca",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "Imbalanced data present a pervasive challenge in many real-world applications of statistical and machine learning, where the instances of one class significantly outnumber those of the other. This paper examines the impact of class imbalance on the performance of Gaussian mixture models in classification tasks and establishes the need for a strategy to reduce the adverse effects of imbalanced data on the accuracy and reliability of classification outcomes. We explore various strategies to address this problem, including cost-sensitive learning, threshold adjustments, and sampling-based techniques. Through extensive experiments on synthetic and real-world datasets, we evaluate the effectiveness of these methods. Our findings emphasize the need for effective mitigation strategies for class imbalance in supervised Gaussian mixtures, offering valuable insights for practitioners and researchers in improving classification outcomes.",
        "link": "http://dx.doi.org/10.3390/a16120563"
    },
    {
        "id": 1859,
        "title": "Tree-Structured Gaussian Mixture Models and Their Variational Inference",
        "authors": "Yuta Nakahara",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/smc53992.2023.10394219"
    },
    {
        "id": 1860,
        "title": "Review for \"Modeling state‐transition dynamics in resting‐state brain signals by the hidden Markov and Gaussian mixture models\"",
        "authors": "STAVROS DIMITRIADIS",
        "published": "2020-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/ejn.15386/v1/review1"
    },
    {
        "id": 1861,
        "title": "Directional Gaussian Mixture Models of the gut microbiome elucidate microbial spatial structure",
        "authors": "Amey P. Pasarkar, Tyler A. Joseph, Itsik Pe’er",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractThe gut microbiome is spatially heterogeneous, with environmental niches contributing to the distribution and composition of microbial populations. A recently developed mapping technology, MaPS-seq, aims to characterize the spatial organization of the gut microbiome by providing data about local microbial populations. However, information about the global arrangement of these populations is lost by MaPS-seq. To address this, we propose a class of Gaussian Mixture Models (GMM) with spatial dependencies between mixture components in order to computationally recover the relative spatial arrangement of microbial communities. We demonstrate on synthetic data that our spatial models can identify global spatial dynamics, accurately cluster data, and improve parameter inference over a naive GMM. We applied our model to three MaPS-Seq datasets taken from varying regions of the mouse intestine. On cecal and distal colon datasets, we find our model accurately recapitulates known spatial behaviors of the gut microbiome, including compositional differences between mucus and lumen-associated populations. Our model also seem to capture the role of a pH gradient on microbial populations in the mouse ileum and proposes new behaviors as well.ImportanceThe spatial arrangement of the microbes in the gut microbiome is a defining characteristic of its behavior. Various experimental studies have attempted to provide glimpses into the mechanisms that contribute to microbial arrangements. However, many of these descriptions are qualitative. We developed a computational method that takes microbial spatial data and learns many of the experimentally validated spatial factors. We can then use our model to propose previously unknown spatial behaviors. Our results demonstrate that the gut microbiome, while exceptionally large, has predictable spatial patterns that can be used to help us understand its role in health and disease.Code availabilitygithub.com/amepas/Spatial_Mbiome",
        "link": "http://dx.doi.org/10.1101/2021.07.09.451866"
    },
    {
        "id": 1862,
        "title": "Peer Review #2 of \"Solution strategy based on Gaussian mixture models and dispersion reduction for the capacitated centered clustering problem (v0.1)\"",
        "authors": "",
        "published": "2021-2-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.332v0.1/reviews/2"
    },
    {
        "id": 1863,
        "title": "Peer Review #2 of \"Solution strategy based on Gaussian mixture models and dispersion reduction for the capacitated centered clustering problem (v0.2)\"",
        "authors": "",
        "published": "2021-2-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.332v0.2/reviews/2"
    },
    {
        "id": 1864,
        "title": "The Use of Gaussian Mixture Models with Atmospheric Lagrangian Particle Dispersion Models for Density Estimation and Feature Identification",
        "authors": "Alice Crawford",
        "published": "2020-12-17",
        "citations": 6,
        "abstract": "Atmospheric Lagrangian particle dispersion models, LPDM, simulate the dispersion of passive tracers in the atmosphere. At the most basic level, model output consists of the position of computational particles and the amount of mass they represent. In order to obtain concentration values, this information is then converted to a mass distribution via density estimation. To date, density estimation is performed with a nonparametric method so that output consists of gridded concentration data. Here we introduce the use of Gaussian mixture models, GMM, for density estimation. We compare to the histogram or bin counting method for a tracer experiment and simulation of a large volcanic ash cloud. We also demonstrate the use of the mixture model for automatic identification of features in a complex plume such as is produced by a large volcanic eruption. We conclude that use of a mixture model for density estimation and feature identification has potential to be very useful.",
        "link": "http://dx.doi.org/10.3390/atmos11121369"
    },
    {
        "id": 1865,
        "title": "Convolutional Gaussian Mixture Models with Application to Compressive Sensing",
        "authors": "Ren Wang, Xuejun Liao, Jingbo Guo",
        "published": "2018-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ssp.2018.8450817"
    },
    {
        "id": 1866,
        "title": "Approximate Query Answering in Complex Gaussian Mixture Models",
        "authors": "Mattis Hartwig, Marcel Gehrke, Ralf Moller",
        "published": "2019-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icbk.2019.00019"
    },
    {
        "id": 1867,
        "title": "Data-Driven Event Assessment in Power Systems using Gaussian Mixture Models",
        "authors": "Sirin Dutta Chowdhury, Nilanjan Senroy, Swades De",
        "published": "2019-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ptc.2019.8810637"
    },
    {
        "id": 1868,
        "title": "Decision letter for \"Modeling state‐transition dynamics in resting‐state brain signals by the hidden Markov and Gaussian mixture models\"",
        "authors": "",
        "published": "2021-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/ejn.15386/v3/decision1"
    },
    {
        "id": 1869,
        "title": "Decision letter for \"Modeling state‐transition dynamics in resting‐state brain signals by the hidden Markov and Gaussian mixture models\"",
        "authors": "",
        "published": "2021-6-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/ejn.15386/v2/decision1"
    },
    {
        "id": 1870,
        "title": "Pleiotropic Mapping and Annotation Selection in Genome-wide Association Studies with Penalized Gaussian Mixture Models",
        "authors": "Ping Zeng, Xinjie Hao, Xiang Zhou",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractMotivationGenome-wide association studies (GWASs) have identified many genetic loci associated with complex traits. A substantial fraction of these identified loci are associated with multiple traits – a phenomena known as pleiotropy. Identification of pleiotropic associations can help characterize the genetic relationship among complex traits and can facilitate our understanding of disease etiology. Effective pleiotropic association mapping requires the development of statistical methods that can jointly model multiple traits with genome-wide SNPs together.ResultsWe develop a joint modeling method, which we refer to as the integrative MApping of Pleiotropic association (iMAP). iMAP models summary statistics from GWASs, uses a multivariate Gaussian distribution to account for phenotypic correlation, simultaneously infers genome-wide SNP association pattern using mixture modeling, and has the potential to reveal causal relationship between traits. Importantly, iMAP integrates a large number of SNP functional annotations to substantially improve association mapping power, and, with a sparsity-inducing penalty, is capable of selecting informative annotations from a large, potentially noninformative set. To enable scalable inference of iMAP to association studies with hundreds of thousands of individuals and millions of SNPs, we develop an efficient expectation maximization algorithm based on an approximate penalized regression algorithm. With simulations and comparisons to existing methods, we illustrate the benefits of iMAP both in terms of high association mapping power and in terms of accurate estimation of genome-wide SNP association patterns. Finally, we apply iMAP to perform a joint analysis of 48 traits from 31 GWAS consortia together with 40 tissue-specific SNP annotations generated from the Roadmap Project. iMAP is freely available at www.xzlab.org/software.html.",
        "link": "http://dx.doi.org/10.1101/256461"
    },
    {
        "id": 1871,
        "title": "Discriminative Joint Vector And Component Reduction For Gaussian Mixture Models",
        "authors": "Yossi Bar-Yosef, Yuval Bistritz",
        "published": "2019-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/eusipco.2019.8903142"
    },
    {
        "id": 1872,
        "title": "Avoiding inferior clusterings with misspecified Gaussian mixture models",
        "authors": "Siva Rajesh Kasa, Vaibhav Rajan",
        "published": "2023-11-6",
        "citations": 0,
        "abstract": "AbstractClustering is a fundamental tool for exploratory data analysis, and is ubiquitous across scientific disciplines. Gaussian Mixture Model (GMM) is a popular probabilistic and interpretable model for clustering. In many practical settings, the true data distribution, which is unknown, may be non-Gaussian and may be contaminated by noise or outliers. In such cases, clustering may still be done with a misspecified GMM. However, this may lead to incorrect classification of the underlying subpopulations. In this paper, we identify and characterize the problem of inferior clustering solutions. Similar to well-known spurious solutions, these inferior solutions have high likelihood and poor cluster interpretation; however, they differ from spurious solutions in other characteristics, such as asymmetry in the fitted components. We theoretically analyze this asymmetry and its relation to misspecification. We propose a new penalty term that is designed to avoid both inferior and spurious solutions. Using this penalty term, we develop a new model selection criterion and a new GMM-based clustering algorithm, SIA. We empirically demonstrate that, in cases of misspecification, SIA avoids inferior solutions and outperforms previous GMM-based clustering methods.",
        "link": "http://dx.doi.org/10.1038/s41598-023-44608-3"
    },
    {
        "id": 1873,
        "title": "Decision letter for \"Modeling state‐transition dynamics in resting‐state brain signals by the hidden Markov and Gaussian mixture models\"",
        "authors": "",
        "published": "2020-6-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/ejn.15386/v1/decision1"
    },
    {
        "id": 1874,
        "title": "Speech Emotion Recognition System Using Gaussian Mixture Model and Improvement proposed via Boosted GMM",
        "authors": "Pavitra Patel, A. A. Chaudhari, M. A. Pund, D. H. Deshmukh",
        "published": "2017-7-10",
        "citations": 7,
        "abstract": "<p>Speech emotion recognition is an important issue which affects the human machine interaction. Automatic recognition of human emotion in speech aims at recognizing the underlying emotional state of a speaker from the speech signal. Gaussian mixture models (GMMs) and the minimum error rate classifier (i.e. Bayesian optimal classifier) are popular and effective tools for speech emotion recognition. Typically, GMMs are used to model the class-conditional distributions of acoustic features and their parameters are estimated by the expectation maximization (EM) algorithm based on a training data set. In this paper, we introduce a boosting algorithm for reliably and accurately estimating the class-conditional GMMs. The resulting algorithm is named the Boosted-GMM algorithm. Our speech emotion recognition experiments show that the emotion recognition rates are effectively and significantly boosted by the Boosted-GMM algorithm as compared to the EM-GMM algorithm.<br />During this interaction, human beings have some feelings that they want to convey to their communication partner with whom they are communicating, and then their communication partner may be the human or machine. This work dependent on the emotion recognition of the human beings from their speech signal<br />Emotion recognition from the speaker’s speech is very difficult because of the following reasons: Because of the existence of the different sentences, speakers, speaking styles, speaking rates accosting variability was introduced. The same utterance may show different emotions. Therefore it is very difficult to differentiate these portions of utterance. Another problem is that emotion expression is depending on the speaker and his or her culture and environment. As the culture and environment gets change the speaking style also gets change, which is another challenge in front of the speech emotion recognition system.</p>",
        "link": "http://dx.doi.org/10.21013/jte.icsesd201706"
    },
    {
        "id": 1875,
        "title": "Gaussian-input Gaussian mixture model for representing density maps and atomic models",
        "authors": "Takeshi Kawabata",
        "published": "2018-7",
        "citations": 35,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jsb.2018.03.002"
    },
    {
        "id": 1876,
        "title": "An EM algorithm for singular Gaussian mixture models",
        "authors": "Khalil Masmoudi, Afif Masmoudi",
        "published": "2019",
        "citations": 2,
        "abstract": "In this paper, we introduce finite mixture models with singular multivariate\n   normal components. These models are useful when the observed data involves\n   collinearities, that is when the covariance matrices are singular. They are\n   also useful when the covariance matrices are ill-conditioned. In the latter\n   case, the classical approaches may lead to numerical instabilities and give\n   inaccurate estimations. Hence, an extension of the Expectation Maximization\n   algorithm, with complete proof, is proposed to derive the maximum likelihood\n   estimators and cluster the data instances for mixtures of singular\n   multivariate normal distributions. The accuracy of the proposed algorithm is\n   then demonstrated on the grounds of several numerical experiments. Finally,\n   we discuss the application of the proposed distribution to financial asset\n   returns modeling and portfolio selection.",
        "link": "http://dx.doi.org/10.2298/fil1915753m"
    },
    {
        "id": 1877,
        "title": "Gaussian Mixture Models for Temporal Depth Fusion",
        "authors": "Cevahir Cigla, Roland Brockers, Larry Matthies",
        "published": "2017-3",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wacv.2017.104"
    },
    {
        "id": 1878,
        "title": "GPGPU Implementation of Variational Bayesian Gaussian Mixture Models",
        "authors": "Hiroki Nishimoto, Takashi Nakada, Yasuhiko Nakashima",
        "published": "2019-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/candar.2019.00031"
    },
    {
        "id": 1879,
        "title": "Enhancement in Bearing Fault Classification Parameters Using Gaussian Mixture Models and Mel Frequency Cepstral Coefficients Features",
        "authors": "",
        "published": "2023-7-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.24425/aoa.2020.133149"
    },
    {
        "id": 1880,
        "title": "Robust trajectory optimization combining Gaussian mixture models with stochastic collocation",
        "authors": "Patrick Piprek, Florian Holzapfel",
        "published": "2017-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ccta.2017.8062710"
    },
    {
        "id": 1881,
        "title": "Revisiting Gaussian Mixture Models for Driver Identification",
        "authors": "Sasan Jafarnejad, German Castignani, Thomas Engel",
        "published": "2018-9",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icves.2018.8519588"
    },
    {
        "id": 1882,
        "title": "Detecting Extreme Temperature Events Using Gaussian Mixture Models",
        "authors": "Aytaç PAÇAL, Birgit Hassler, Katja Weigel, Mehmet Levent Kurnaz, Michael F Wehner, Veronika Eyring",
        "published": "No Date",
        "citations": 0,
        "abstract": "Extreme temperature events have traditionally been detected assuming a\nunimodal distribution of temperature data. We found that surface\ntemperature data can be described more accurately with a multimodal\nrather than a unimodal distribution. Here, we applied Gaussian Mixture\nModels (GMM) to daily near-surface maximum air temperature data from the\nhistorical and future Coupled Model Intercomparison Project Phase 6\n(CMIP6) simulations for 46 land regions defined by the Intergovernmental\nPanel on Climate Change (IPCC). Using the multimodal distribution, we\nfound that temperature extremes, defined based on daily data in the\nwarmest mode of the GMM distributions, are getting more frequent in all\nregions. Globally, a 10-year extreme temperature event relative to\n1980-2010 conditions will occur 15 times more frequently in the future\nunder 3.0C of Global Warming Levels (GWL). The\nfrequency increase can be even higher in tropical regions, such that\n10-year extreme temperature events will occur almost twice a week.\nAdditionally, we analysed the change in future temperature distributions\nunder different GWL and found that the hot temperatures are increasing\nfaster than cold temperatures in low latitudes, while the cold\ntemperatures are increasing faster than the hot temperatures in high\nlatitudes. The smallest changes in temperature distribution can be found\nin tropical regions, where the annual temperature range is small. Our\nmethod captures the differences in geographical regions and shows that\nthe frequency of extreme events will be even higher than reported in\nprevious studies.",
        "link": "http://dx.doi.org/10.22541/essoar.168275876.64237989/v1"
    },
    {
        "id": 1883,
        "title": "Distributed Depth Video Coding Based on Compressive Sensing and Gaussian Mixture Models",
        "authors": "Kang Wang, Xuguang Lan, Chuzhen Feng",
        "published": "2018-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cac.2018.8623451"
    },
    {
        "id": 1884,
        "title": "Hybrid Naïve Bayes Gaussian Mixture Models and Sar Polarimetry Based Automatic Flooded Vegetation Studies Using Palsar-2 Data",
        "authors": "Samvedya Surampudi, Vijay Kumar",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4696253"
    },
    {
        "id": 1885,
        "title": "Nearest-Neighbor Mixture Models for Non-Gaussian Spatial Processes",
        "authors": "Xiaotian Zheng, Athanasios Kottas, Bruno Sansó",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1214/23-ba1405"
    },
    {
        "id": 1886,
        "title": "Actively Improving Robot Navigation On Different Terrains Using Gaussian Process Mixture Models",
        "authors": "Lorenzo Nardi, Cyrill Stachniss",
        "published": "2019-5",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icra.2019.8794079"
    },
    {
        "id": 1887,
        "title": "EVM: A Fast Alternative to the EM Algorithm with Application to Gaussian Mixture Models",
        "authors": "Mark Britten-Jones",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3615408"
    },
    {
        "id": 1888,
        "title": "Robust Text-independent Speaker recognition with Short Utterances using Gaussian Mixture Models",
        "authors": "Rania Chakroun, Mondher Frikha",
        "published": "2020-6",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iwcmc48107.2020.9148102"
    },
    {
        "id": 1889,
        "title": "Optimality of Least-squares for Classification in Gaussian-Mixture Models",
        "authors": "Hossein Taheri, Ramtin Pedarsani, Christos Thrampoulidis",
        "published": "2020-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/isit44484.2020.9174267"
    },
    {
        "id": 1890,
        "title": "Estimation of 5G Core and RAN End-to-End Delay through Gaussian Mixture Models",
        "authors": "Diyar Fadhil, Rodolfo Oliveira",
        "published": "2023-6-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.37247/pacompus.1.23.7"
    },
    {
        "id": 1891,
        "title": "Multivariate data imputation using Gaussian mixture models",
        "authors": "Diogo S.F. Silva, Clayton V. Deutsch",
        "published": "2018-10",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.spasta.2016.11.002"
    },
    {
        "id": 1892,
        "title": "Gaussian Mixture PHD Filter with State-Dependent Jump Markov System Models",
        "authors": "Dohyeung Kim, Inseok Hwang",
        "published": "2019-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/dasc43569.2019.9081744"
    },
    {
        "id": 1893,
        "title": "Deep Gaussian mixture models",
        "authors": "Cinzia Viroli, Geoffrey J. McLachlan",
        "published": "2019-1",
        "citations": 58,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11222-017-9793-z"
    },
    {
        "id": 1894,
        "title": "Variational Inference of Finite Asymmetric Gaussian Mixture Models",
        "authors": "Ziyang Song, Ornela Bregu, Samr Ali, Nizar Bouguila",
        "published": "2019-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ssci44817.2019.9002954"
    },
    {
        "id": 1895,
        "title": "Data-driven Soft Sensors using Factor Graphs and Gaussian Mixture Models",
        "authors": "Andreas Gienger, Oliver Sawodny",
        "published": "2021-12-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cdc45484.2021.9682933"
    },
    {
        "id": 1896,
        "title": "Particle Flow Particle Filter for Gaussian Mixture Noise Models",
        "authors": "Soumyasundar Pal, Mark Coates",
        "published": "2018-4",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp.2018.8461435"
    },
    {
        "id": 1897,
        "title": "Vehicle Detection Using Machine Learning Model with the Gaussian Mixture Model (GMM)",
        "authors": "Rika Rosnelly, Bob Subhan Riza, Linda Wahyuni, S. Edy Victor Haryanto, Annas Prasetio",
        "published": "2022-12-30",
        "citations": 0,
        "abstract": "Motion tracking apps are used for a lot of different things, like finding traffic jams and counting the number of cars going through a traffic light. The datasets come from many places on the internet, like YouTube and public dataset archives. There are about 20 videos that are tagged with the words \"traffic\" and \"traffic camera video\" and run for 10 to 30 seconds. The Gaussian Mixture Models (GMM) method is the proposed model. It separates the background from the tracked object, which is needed to do motion tracking. Then, the GMM method groups pixel data based on the background color of each pixel. After the cluster is made, the input is matched as a distribution, with the most common distribution used as the background. The analysis was done using MATLAB2019B. The results of this study show that the GMM method can adapt to the background. This is shown by the fact that testing of some of the given conditions went well.",
        "link": "http://dx.doi.org/10.58346/jowua.2022.i4.016"
    },
    {
        "id": 1898,
        "title": "New image reconstruction algorithm for CCERT: LBP + Gaussian mixture model (GMM) clustering",
        "authors": "Yuxin Wang, Xuekai He, Yandan Jiang, Baoliang Wang, Haifeng Ji, Zhiyao Huang",
        "published": "2021-2-1",
        "citations": 6,
        "abstract": "Abstract\nThis work focuses on the study of the image reconstruction algorithm of capacitively coupled electrical resistance tomography (CCERT). With the combination of a linear back projection (LBP) algorithm and an unsupervised Gaussian mixture model (GMM) algorithm, a new image reconstruction algorithm for CCERT is proposed. The LBP algorithm is used to implement the initial image reconstruction. The GMM algorithm is adopted to acquire the gray level threshold which will be used for the establishment of the gray level threshold filter. The final reconstructed image can be obtained with the thresholding operation. With a developed 12-electrode CCERT prototype system, the new image reconstruction algorithm is tested in image reconstruction experiments. The experimental results show that the proposed new image reconstruction algorithm is effective. The image reconstruction results are satisfactory. Compared with the conventional image reconstruction algorithms, the new image reconstruction algorithm (LBP + GMM) can obtain better reconstructed images with smaller relative image errors. It can obtain the reconstructed images with fewer empirical preset parameters and less manual intervention. In addition, with the introduction of the GMM algorithm, a relatively more suitable and reasonable gray level threshold can be obtained because the GMM algorithm implements the clustering process by utilizing both mean and variance information on the gray level distribution. Thus, better image reconstruction results can be obtained.",
        "link": "http://dx.doi.org/10.1088/1361-6501/abbb66"
    },
    {
        "id": 1899,
        "title": "Segway 2.0: Gaussian mixture models and minibatch training",
        "authors": "Rachel C.W. Chan, Maxwell W. Libbrecht, Eric G. Roberts, William Stafford Noble, Michael M. Hoffman",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractSummarySegway performs semi-automated genome annotation, discovering joint patterns across multiple genomic signal datasets. We discuss a major new version of Segway and highlight its ability to model data with substantially greater accuracy. Major enhancements in Segway 2.0 include the ability to model data with a mixture of Gaussians, enabling capture of arbitrarily complex signal distributions, and minibatch training, leading to better learned parameters.Availability and ImplementationSegway and its source code are freely available for download at https://segway.hoffmanlab.org. We have made available scripts (https://doi.org/10.5281/zenodo.802940) and datasets (https://doi.org/10.5281/zenodo.802907) for this paper’s analysis.Contactmichael.hoffman@utoronto.ca",
        "link": "http://dx.doi.org/10.1101/147470"
    },
    {
        "id": 1900,
        "title": "Variational Inference of Finite Generalized Gaussian Mixture Models",
        "authors": "Srikanth Amudala, Samr Ali, Fatma Najar, Nizar Bouguila",
        "published": "2019-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ssci44817.2019.9002852"
    }
]