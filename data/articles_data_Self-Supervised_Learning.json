[
    {
        "id": 101,
        "title": "Enhancing Time Series Classification with Self-Supervised Learning",
        "authors": "Ali Ismail-Fawaz, Maxime Devanne, Jonathan Weber, Germain Forestier",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011611300003393"
    },
    {
        "id": 102,
        "title": "Using Semi-supervised Learning for Monaural Time-domain Speech Separation with a Self-supervised Learning-based SI-SNR Estimator",
        "authors": "Shaoxiang Dang, Tetsuya Matsumoto, Yoshinori Takeuchi, Hiroaki Kudo",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-85"
    },
    {
        "id": 103,
        "title": "Speech Recognition for Indigenous Language Using Self-Supervised Learning and Natural Language Processing",
        "authors": "Satoshi Tamura, Tomohiro Hattori, Yusuke Kato, Naoki Noguchi",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012396300003654"
    },
    {
        "id": 104,
        "title": "A study on a semi-supervised learning using self-supervised learning",
        "authors": "Daehak Kim",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.7465/jkdi.2023.34.6.967"
    },
    {
        "id": 105,
        "title": "CoBERT: Self-Supervised Speech Representation Learning Through Code Representation Learning",
        "authors": "Chutong Meng, Junyi Ao, Tom Ko, Mingxuan Wang, Haizhou Li",
        "published": "2023-8-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1390"
    },
    {
        "id": 106,
        "title": "Very High-Resolution Satellite Image Registration Based on Self-supervised Deep Learning",
        "authors": "Taeheon Kim, Jaewon Hur, Youkyung Han",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.7848/ksgpc.2023.41.4.217"
    },
    {
        "id": 107,
        "title": "Combining Self-Supervised and Supervised Learning with Noisy Labels",
        "authors": "Yongqi Zhang, Hui Zhang, Quanming Yao, Jun Wan",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10221957"
    },
    {
        "id": 108,
        "title": "Seismic data denoising by combining self-supervised and supervised learning",
        "authors": "Yen Sun, Paul Williamson",
        "published": "2023-12-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1190/image2023-3909418.1"
    },
    {
        "id": 109,
        "title": "SELF-SUPERVISED LEARNING FOR IMPROVED SAS TARGET RECOGNITION",
        "authors": "BW SHEFFIELD",
        "published": "2023-9-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25144/15919"
    },
    {
        "id": 110,
        "title": "Speech Emotion Recognition Using Transfer Learning and Self-Supervised Speech Representation Learning",
        "authors": "Babak Nasersharif, Marziye Azad",
        "published": "2023-5-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icee59167.2023.10334799"
    },
    {
        "id": 111,
        "title": "Leveraging Unsupervised and Self-Supervised Learning for Video Anomaly Detection",
        "authors": "Devashish Lohani, Carlos Crispim-Junior, Quentin Barthélemy, Sarah Bertrand, Lionel Robinault, Laure Rodet",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011663600003417"
    },
    {
        "id": 112,
        "title": "Self-supervised learning of deep visual representations",
        "authors": " Mathilde Caron",
        "published": "2023-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.48556/sif.1024.21.171"
    },
    {
        "id": 113,
        "title": "Extending Self-Distilled Self-Supervised Learning For Semi-Supervised Speaker Verification",
        "authors": "Jeong-Hwan Choi, Jehyun Kyung, Ju-Seok Seong, Ye-Rin Jeoung, Joon-Hyuk Chang",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/asru57964.2023.10389802"
    },
    {
        "id": 114,
        "title": "IPCL: Iterative Pseudo-Supervised Contrastive Learning to Improve Self-Supervised Feature Representation",
        "authors": "Sonal Kumar, Anirudh Phukan, Arijit Sur",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447607"
    },
    {
        "id": 115,
        "title": "Self-supervised Pre-training and Semi-supervised Learning for Extractive Dialog Summarization",
        "authors": "Yingying Zhuang, Jiecheng Song, Narayanan Sadagopan, Anurag Beniwal",
        "published": "2023-4-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3543873.3587680"
    },
    {
        "id": 116,
        "title": "Self-Supervised Adversarial Variational Learning",
        "authors": "Fei Ye, Adrian. G. Bors",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2023.110156"
    },
    {
        "id": 117,
        "title": "Dual Contrastive Learning for Self-Supervised ECG Mapping to Emotions and Glucose Levels",
        "authors": "Noy Lalzary, Lior Wolf",
        "published": "2023-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sensors56945.2023.10325116"
    },
    {
        "id": 118,
        "title": "Self-Supervised Skill Learning for Semi-Supervised Long-Horizon Instruction Following",
        "authors": "Benhui Zhuang, Chunhong Zhang, Zheng Hu",
        "published": "2023-3-28",
        "citations": 0,
        "abstract": "Language as an abstraction for hierarchical agents is promising to solve compositional long-time horizon decision-making tasks. The learning of the agent poses significant challenges, as it typically requires plenty of trajectories annotated with languages. This paper addresses the challenge of learning such an agent under the scarcity of language annotations. One approach for leveraging unannotated data is to generate pseudo-labels for unannotated trajectories using sparse seed annotations. However, as the scenes of the environment and tasks assigned to the agent are diverse, the inference of language instructions is sometimes incorrect, causing the policy to learn to ground incorrect instructions to actions. In this work, we propose a self-supervised language-conditioned hierarchical skill policy (SLHSP) which utilizes unannotated data to learn reusable and general task-related skills to facilitate learning from sparse annotations. We demonstrate that the SLHSP that learned with less than 10% of annotated trajectories has a comparable performance to one that learned with 100% of annotated data. Our approach to the challenging ALFRED benchmark leads to a notable improvement in the success rate over a strong baseline also optimized for sparsely annotated data.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12071587"
    },
    {
        "id": 119,
        "title": "Self-Supervised Acoustic Word Embedding Learning via Correspondence Transformer Encoder",
        "authors": "Jingru Lin, Xianghu Yue, Junyi Ao, Haizhou Li",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-359"
    },
    {
        "id": 120,
        "title": "Korean Text to Gloss: Self-Supervised Learning approach",
        "authors": "Thanh-Vu Dang, JinYoung Kim, Gwang-Hyun Yu, Ji Yong Kim, Young Hwan Park, ChilWoo Lee,  ",
        "published": "2023-2-28",
        "citations": 0,
        "abstract": "Natural Language Processing (NLP) has grown tremendously in recent years. Typically, bilingual, and multilingual translation models have been deployed widely in machine translation and gained vast attention from the research community. On the contrary, few studies have focused on translating between spoken and sign languages, especially non-English languages. Prior works on Sign Language Translation (SLT) have shown that a mid-level sign gloss representation enhances translation performance. Therefore, this study presents a new large-scale Korean sign language dataset, the Museum-Commentary Korean Sign Gloss (MCKSG) dataset, including 3828 pairs of Korean sentences and their corresponding sign glosses used in Museum-Commentary contexts. In addition, we propose a translation framework based on self-supervised learning, where the pretext task is a text-to-text from a Korean sentence to its back-translation versions, then the pre-trained network will be fine-tuned on the MCKSG dataset. Using self-supervised learning help to overcome the drawback of a shortage of sign language data. Through experimental results, our proposed model outperforms a baseline BERT model by 6.22%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30693/smj.2023.12.1.32"
    },
    {
        "id": 121,
        "title": "Self-Supervised Temporal Graph Learning based on Multi-Head Self-Attention Weighted Neighborhood Sequences",
        "authors": "Yulong Cao",
        "published": "2023-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bdai59165.2023.10256426"
    },
    {
        "id": 122,
        "title": "IMPROVING SELF-SUPERVISED LEARNING FOR MULTI-LABEL CLASSIFICATION USING MIX-BASED AUGMENTATIONS",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.35741/issn.0258-2724.58.1.66"
    },
    {
        "id": 123,
        "title": "A Review on Self-Supervised Learning",
        "authors": "Athul Raj, Srinjoy Dutta",
        "published": "2023-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.31871/ijntr.9.1.7"
    },
    {
        "id": 124,
        "title": "MSTDKD: a framework of using multiple self-supervised methods for semi-supervised learning",
        "authors": "JiaBin Liu, XuanMing Zhang, Jun Hu",
        "published": "2023-2-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2661030"
    },
    {
        "id": 125,
        "title": "Self-Distilled Self-supervised Representation Learning",
        "authors": "Jiho Jang, Seonhoon Kim, Kiyoon Yoo, Chaerin Kong, Jangho Kim, Nojun Kwak",
        "published": "2023-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00285"
    },
    {
        "id": 126,
        "title": "Image-Based Vehicle Classification by Synergizing Features from Supervised and Self-Supervised Learning Paradigms",
        "authors": "Shihan Ma, Jidong J. Yang",
        "published": "2023-2-1",
        "citations": 3,
        "abstract": "This paper introduces a novel approach to leveraging features learned from both supervised and self-supervised paradigms, to improve image classification tasks, specifically for vehicle classification. Two state-of-the-art self-supervised learning methods, DINO and data2vec, were evaluated and compared for their representation learning of vehicle images. The former contrasts local and global views while the latter uses masked prediction on multiple layered representations. In the latter case, supervised learning is employed to finetune a pretrained YOLOR object detector for detecting vehicle wheels, from which definitive wheel positional features are retrieved. The representations learned from these self-supervised learning methods were combined with the wheel positional features for the vehicle classification task. Particularly, a random wheel masking strategy was utilized to finetune the previously learned representations in harmony with the wheel positional features during the training of the classifier. Our experiments show that the data2vec-distilled representations, which are consistent with our wheel masking strategy, outperformed the DINO counterpart, resulting in a celebrated Top-1 classification accuracy of 97.2% for classifying the 13 vehicle classes defined by the Federal Highway Administration.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/eng4010027"
    },
    {
        "id": 127,
        "title": "Goal-Conditioned Flexible Object Manipulation by Self-Supervised Learning from Play",
        "authors": "Keigo Ishii, Shun Hiramatsu, Yuta Nomura, Shingo Murata",
        "published": "2023-11-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdl55364.2023.10364471"
    },
    {
        "id": 128,
        "title": "EMS2L: Enhanced Multi-Task Self-Supervised Learning for 3D Skeleton Representation Learning",
        "authors": "Lilang Lin, Jiaying Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1561/116.00000022"
    },
    {
        "id": 129,
        "title": "Renewable energy forecasting: A self-supervised learning-based transformer variant",
        "authors": "Jiarui Liu, Yuchen Fu",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.energy.2023.128730"
    },
    {
        "id": 130,
        "title": "Self-Supervised Adversarial Imitation Learning",
        "authors": "Juarez Monteiro, Nathan Gavenski, Felipe Meneguzzi, Rodrigo C. Barros",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191197"
    },
    {
        "id": 131,
        "title": "Self-Supervised Learning of Free-Hand Sketches with Bézier Curve Features",
        "authors": "Taner Gülez, Mustafa Sert",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ism59092.2023.00030"
    },
    {
        "id": 132,
        "title": "Dialect Speech Recognition Modeling using Corpus of Japanese Dialects and Self-Supervised Learning-based Model XLSR",
        "authors": "Shogo Miwa, Atsuhiko Kai",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-2463"
    },
    {
        "id": 133,
        "title": "Automatic Lung Segmentation in Chest X-Ray Images Using Self-Supervised Learning",
        "authors": "Peilin Li, Siyu Xia",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/ccc58697.2023.10240997"
    },
    {
        "id": 134,
        "title": "ViewMix: Augmentation for Robust Representation in Self-Supervised Learning",
        "authors": "Arjon Das, Xin Zhong",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2024.3353133"
    },
    {
        "id": 135,
        "title": "MT-SLVR: Multi-Task Self-Supervised Learning for Transformation In(Variant) Representations",
        "authors": "Calum Heggan, Tim Hospedales, Sam Budgett, Mehrdad Yaghoobi",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1064"
    },
    {
        "id": 136,
        "title": "Semi-supervised learning made simple with self-supervised clustering",
        "authors": "Enrico Fini, Pietro Astolfi, Karteek Alahari, Xavier Alameda-Pineda, Julien Mairal, Moin Nabi, Elisa Ricci",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00311"
    },
    {
        "id": 137,
        "title": "Self-supervised and supervised deep learning for PET image reconstruction",
        "authors": "Andrew J. Reader",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0203321"
    },
    {
        "id": 138,
        "title": "Self-Supervised Learning for Anomalous Sound Detection",
        "authors": "Kevin Wilkinghoff",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447156"
    },
    {
        "id": 139,
        "title": "Global Self-Supervised Graph Learning for Recommendation",
        "authors": "Xinyue Liu",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eebda60612.2024.10486045"
    },
    {
        "id": 140,
        "title": "CycleCL: Self-supervised Learning for Periodic Videos",
        "authors": "Matteo Destro, Michael Gygli",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00284"
    },
    {
        "id": 141,
        "title": "Self-Supervised Training for Bearing Fault Diagnosis via Momentum Contrast Learning",
        "authors": "Kai Wang, Chun Liu, Liang Xu",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cac59555.2023.10451088"
    },
    {
        "id": 142,
        "title": "Evolutionary Augmentation Policy Optimization for Self-Supervised Learning",
        "authors": "Noah Barrett, Zahra Sadeghi, Stan Matwin",
        "published": "2023",
        "citations": 0,
        "abstract": "Self-supervised Learning (SSL) is a machine learning algorithm for pretraining Deep Neural Networks (DNNs) without requiring manually labeled data. The central idea of this learning technique is based on an auxiliary stage aka pretext task in which labeled data are created automatically through data augmentation and exploited for pretraining the DNN. However, the effect of each pretext task is not well studied or compared in the literature. In this paper, we study the contribution of augmentation operators on the performance of self supervised learning algorithms in a constrained settings. We propose an evolutionary search method for optimization of data augmentation pipeline in pretext tasks and measure the impact of augmentation operators in several SOTA SSL algorithms. By encoding different combination of augmentation operators in chromosomes we seek the optimal augmentation policies through an evolutionary optimization mechanism. We further introduce methods for analyzing and explaining the performance of optimized SSL algorithms. Our results indicate that our proposed method can find solutions that outperform the accuracy of classification of SSL algorithms which confirms the influence of augmentation policy choice on the overall performance of SSL algorithms. We also compare optimal SSL solutions found by our evolutionary search mechanism and show the effect of batch size in the pretext task on two visual datasets.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54364/aaiml.2023.1167"
    },
    {
        "id": 143,
        "title": "Deep Learning-Based Self-Supervised Transfer Learning for Medical Image Classification",
        "authors": "M. Z. Shaikh, Samender Singh, Neeraj Varshney, Birendra Kumar Saraswat",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdt61202.2024.10488985"
    },
    {
        "id": 144,
        "title": "SSL2 Self-Supervised Learning meets semi-supervised learning: multiple clerosis segmentation in 7T-MRI from large-scale 3T-MRI",
        "authors": "Jiacheng Wang, Hao Li, Han Liu, Dewei Hu, Daiwei Lu, Keejin Yoon, Kelsey Barter, Francesca Bagnato, Ipek Oguz",
        "published": "2023-4-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2654522"
    },
    {
        "id": 145,
        "title": "OTF: Optimal Transport based Fusion of Supervised and Self-Supervised Learning Models for Automatic Speech Recognition",
        "authors": "Li Fu, Siqi Li, Qingtao Li, Fangzhu Li, Liping Deng, Lu Fan, Meng Chen, Youzheng Wu, Xiaodong He",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1609"
    },
    {
        "id": 146,
        "title": "Review on self supervised learning in medical image analysis",
        "authors": "Nitu Kumari, Sonali Agrawal",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cict59886.2023.10455714"
    },
    {
        "id": 147,
        "title": "Investigating self-supervised learning for Skin Lesion Classification",
        "authors": "Takumi Morita, Xian-Hua Han",
        "published": "2023-7-23",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/mva57639.2023.10215580"
    },
    {
        "id": 148,
        "title": "Exploring self-supervised learning in Multiview captcha recognition",
        "authors": "Mukhtar Opeyemi Yusuf, Divya Srivastava, Riti Kushwaha",
        "published": "2023-12-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/indicon59947.2023.10440750"
    },
    {
        "id": 149,
        "title": "MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets",
        "authors": "Ziyang Ma, Zhisheng Zheng, Changli Tang, Yujin Wang, Xie Chen",
        "published": "2023-8-20",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-822"
    },
    {
        "id": 150,
        "title": "Comparison between supervised and self-supervised deep learning for SEM image denoising",
        "authors": "Tomoyuki Okuda, Jun Chen, Takahiro Motoyoshi, Ryou Yumiba, Masayoshi Ishikawa, Yasutaka Toyoda",
        "published": "2023-4-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2660673"
    },
    {
        "id": 151,
        "title": "Self-Supervised Representation Learning with Cross-Context Learning between Global and Hypercolumn Features",
        "authors": "Zheng Gao, Chen Feng, Ioannis Patras",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00179"
    },
    {
        "id": 152,
        "title": "Biased Self-supervised Learning for ASR",
        "authors": "Florian L. Kreyssig, Yangyang Shi, Jinxi Guo, Leda Sari, Abdel-rahman Mohamed, Philip C. Woodland",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-2499"
    },
    {
        "id": 153,
        "title": "Adding Distance Information to Self-Supervised Learning for rich Representations",
        "authors": "Yeji Kim, Bai-Sun Kong",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10222633"
    },
    {
        "id": 154,
        "title": "Adopting Self-Supervised Learning into Unsupervised Video Summarization through Restorative Score.",
        "authors": "Mehryar Abbasi, Parvaneh Saeedi",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10222350"
    },
    {
        "id": 155,
        "title": "Phase retrieval network for multi-functional holography based on self-supervised learning",
        "authors": "Jialei Xie, Lei Jin",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3023658"
    },
    {
        "id": 156,
        "title": "Road Condition Anomaly Detection using Self-Supervised Learning from Audio",
        "authors": "U-Ju Gim",
        "published": "2023-9-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/itsc57777.2023.10421899"
    },
    {
        "id": 157,
        "title": "Self-supervised Learning with Temporary Exact Solutions: Linear Projection",
        "authors": "Evrim Ozmermer, Qiang Li",
        "published": "2023-7-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/indin51400.2023.10217918"
    },
    {
        "id": 158,
        "title": "Learning A Self-Supervised Domain-Invariant Feature Representation for Generalized Audio Deepfake Detection",
        "authors": "Yuankun Xie, Haonan Cheng, Yutian Wang, Long Ye",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1383"
    },
    {
        "id": 159,
        "title": "Class-Agnostic Self-Supervised Learning for Image Angle Classification",
        "authors": "Hyeonseok Kim, Yeejin Lee",
        "published": "2023-10-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/iccas59377.2023.10317040"
    },
    {
        "id": 160,
        "title": "Boosting Ultrasonic Image Classification via Self-Supervised Representation Learning",
        "authors": "Yajie Hou, Qingbing Sang",
        "published": "2023-3-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccr56747.2023.10194197"
    },
    {
        "id": 161,
        "title": "ASBERT: ASR-Specific Self-Supervised Learning with Self-Training",
        "authors": "Hyung Yong Kim, Byeong-Yeol Kim, Seung Woo Yoo, Youshin Lim, Yunkyu Lim, Hanbin Lee",
        "published": "2023-1-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/slt54892.2023.10023214"
    },
    {
        "id": 162,
        "title": "Augmentation Strategies for Self-Supervised Representation Learning from Electrocardiograms",
        "authors": "Matilda Andersson, Mattias Nilsson, Gabrielle Flood, Kalle Åström",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/eusipco58844.2023.10289960"
    },
    {
        "id": 163,
        "title": "Cross-modal Manifold Cutmix for Self-supervised Video Representation Learning",
        "authors": "Srijan Das, Michael Ryoo",
        "published": "2023-7-23",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/mva57639.2023.10216260"
    },
    {
        "id": 164,
        "title": "Language-Aware Multilingual Machine Translation with Self-Supervised Learning",
        "authors": "Haoran Xu, Jean Maillard, Vedanuj Goswami",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-eacl.38"
    },
    {
        "id": 165,
        "title": "Graph Neural Collaborative Filtering Algorithm Based on Self-Supervised Learning and Degree Centrality",
        "authors": "Hao Wang, Chunlong Yao",
        "published": "2023-7-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3613330.3613341"
    },
    {
        "id": 166,
        "title": "Multi-View Self-Supervised Learning For Multivariate Variable-Channel Time Series",
        "authors": "Thea Brüsch, Mikkel N. Schmidt, Tommy S. Alstrøm",
        "published": "2023-9-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mlsp55844.2023.10285993"
    },
    {
        "id": 167,
        "title": "Multimodal self-supervised learning for semantic analysis of PolSAR imagery",
        "authors": "Yanxin Dong, Ronny Hänsch",
        "published": "2023-7-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/igarss52108.2023.10283301"
    },
    {
        "id": 168,
        "title": "Robust Hypergraph-Augmented Graph Contrastive Learning for Graph Self-Supervised Learning",
        "authors": "Zeming Wang, Xiaoyang Li, Rui Wang, Changwen Zheng",
        "published": "2023-3-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3590003.3590053"
    },
    {
        "id": 169,
        "title": "Self-Supervised and Few-Shot Contrastive Learning Frameworks for Text Clustering",
        "authors": "Haoxiang Shi, Tetsuya Sakai",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3302913"
    },
    {
        "id": 170,
        "title": "Self-supervised boundary offline reinforcement learning",
        "authors": "Jiahao Shen",
        "published": "2024-3-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3026355"
    },
    {
        "id": 171,
        "title": "Applying Self-Supervised Learning to Image Quality Assessment in Chest CT Imaging",
        "authors": "Eléonore Pouget, Véronique Dedieu",
        "published": "2024-3-29",
        "citations": 0,
        "abstract": "Many new reconstruction techniques have been deployed to allow low-dose CT examinations. Such reconstruction techniques exhibit nonlinear properties, which strengthen the need for a task-based measure of image quality. The Hotelling observer (HO) is the optimal linear observer and provides a lower bound of the Bayesian ideal observer detection performance. However, its computational complexity impedes its widespread practical usage. To address this issue, we proposed a self-supervised learning (SSL)-based model observer to provide accurate estimates of HO performance in very low-dose chest CT images. Our approach involved a two-stage model combining a convolutional denoising auto-encoder (CDAE) for feature extraction and dimensionality reduction and a support vector machine for classification. To evaluate this approach, we conducted signal detection tasks employing chest CT images with different noise structures generated by computer-based simulations. We compared this approach with two supervised learning-based methods: a single-layer neural network (SLNN) and a convolutional neural network (CNN). The results showed that the CDAE-based model was able to achieve similar detection performance to the HO. In addition, it outperformed both SLNN and CNN when a reduced number of training images was considered. The proposed approach holds promise for optimizing low-dose CT protocols across scanner platforms.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/bioengineering11040335"
    },
    {
        "id": 172,
        "title": "Representation Uncertainty in Self-Supervised Learning as Variational Inference",
        "authors": "Hiroki Nakamura, Masashi Okada, Tadahiro Taniguchi",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01511"
    },
    {
        "id": 173,
        "title": "Feature Decoupling in Self-supervised Representation Learning for Open Set Recognition",
        "authors": "Jingyun Jia, Philip K. Chan",
        "published": "2023-6-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191920"
    },
    {
        "id": 174,
        "title": "Self-Supervised Learning of Depth Maps for Autonomous Cars",
        "authors": "Andrei-Sebastian Petrescu, Constantin-Cristian Damian, Daniela Coltuc",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/eusipco58844.2023.10290114"
    },
    {
        "id": 175,
        "title": "Self-Supervised Learning for Scanned Halftone Classification with Novel Augmentation Techniques",
        "authors": "Jing-Ming Guo, Sankarasrinivasan Seshathiri",
        "published": "2023-10-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10222434"
    },
    {
        "id": 176,
        "title": "Mixup Feature: A Pretext Task Self-Supervised Learning Method for Enhanced Visual Feature Learning",
        "authors": "Jiashu Xu, Sergii Stirenko",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3301561"
    },
    {
        "id": 177,
        "title": "Utilizing Self-Supervised Learning Features and Adapter Fine-Tuning for Enhancing Speech Emotion Recognition",
        "authors": "Tangxun Li, Junjie Hou",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mlbdbi60823.2023.10482145"
    },
    {
        "id": 178,
        "title": "Self-supervised learning in different domains",
        "authors": "A. Kamaleeva, I. Bikmullina",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0175305"
    },
    {
        "id": 179,
        "title": "Arabic Speech Recognition based on Self Supervised Learning",
        "authors": "Hiba Adreese Younis, Yusra Faisal Mohammad",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dese60595.2023.10469031"
    },
    {
        "id": 180,
        "title": "Meta-learning-based recommendation method for self-supervised hybrid comparison learning",
        "authors": "Huixin Jiang, Lingyu Yan, Donghua Liu, Xiang Wan",
        "published": "2023-11-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3013361"
    },
    {
        "id": 181,
        "title": "TimesURL: Self-Supervised Contrastive Learning for Universal Time Series Representation Learning",
        "authors": "Jiexi Liu, Songcan Chen",
        "published": "2024-3-24",
        "citations": 0,
        "abstract": "Learning universal time series representations applicable to various types of downstream tasks is challenging but valuable in real applications. Recently, researchers have attempted to leverage the success of self-supervised contrastive learning (SSCL) in Computer Vision(CV) and Natural Language Processing(NLP) to tackle time series representation. Nevertheless, due to the special temporal characteristics, relying solely on empirical guidance from other domains may be ineffective for time series and difficult to adapt to multiple downstream tasks. To this end, we review three parts involved in SSCL including 1) designing augmentation methods for positive pairs, 2) constructing (hard) negative pairs, and 3) designing SSCL loss. For 1) and 2), we find that unsuitable positive and negative pair construction may introduce inappropriate inductive biases, which neither preserve temporal properties nor provide sufficient discriminative features. For 3), just exploring segment- or instance-level semantics information is not enough for learning universal representation. To remedy the above issues, we propose a novel self-supervised framework named TimesURL. Specifically, we first introduce a frequency-temporal-based augmentation to keep the temporal property unchanged. And then, we construct double Universums as a special kind of hard negative to guide better contrastive learning. Additionally, we introduce time reconstruction as a joint optimization objective with contrastive learning to capture both segment-level and instance-level information. As a result, TimesURL can learn high-quality universal representations and achieve state-of-the-art performance in 6 different downstream tasks, including short- and long-term forecasting, imputation, classification, anomaly detection and transfer learning.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1609/aaai.v38i12.29299"
    },
    {
        "id": 182,
        "title": "HNSSL: Hard Negative-Based Self-Supervised Learning",
        "authors": "Wentao Zhu, Jingya Liu, Yufang Huang",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00506"
    },
    {
        "id": 183,
        "title": "A Hierarchical Vision Transformer Using Overlapping Patch and Self-Supervised Learning",
        "authors": "Yaxin Ma, Ming Li, Jun Chang",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191916"
    },
    {
        "id": 184,
        "title": "ViewCLR: Learning Self-supervised Video Representation for Unseen Viewpoints",
        "authors": "Srijan Das, Michael S. Ryoo",
        "published": "2023-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00553"
    },
    {
        "id": 185,
        "title": "Detecting Fake Audio of Arabic Speakers Using Self-Supervised Deep Learning",
        "authors": "Zaynab M. Almutairi, Hebah Elgibreen",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3286864"
    },
    {
        "id": 186,
        "title": "Learning by Sorting: Self-supervised Learning with Group Ordering Constraints",
        "authors": "Nina Shvetsova, Felix Petersen, Anna Kukleva, Bernt Schiele, Hilde Kuehne",
        "published": "2023-10-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01508"
    },
    {
        "id": 187,
        "title": "Comparative Analysis of Self-Supervised and Supervised Deep Learning Models for Ocular Disease Recognition",
        "authors": "Vijayalakshmi S, Kavitha K R, Mugilan R S, Naveen Sivaa S",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/itechsecom59882.2023.10435254"
    },
    {
        "id": 188,
        "title": "Topology-Aware Debiased Self-Supervised Graph Learning for Recommendation",
        "authors": "Lei Han, Hui Yan, Zhicheng Qiao",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smc53992.2023.10394615"
    },
    {
        "id": 189,
        "title": "Self-Supervised Contrastive Learning for Radar-Based Human Activity Recognition",
        "authors": "Mohammad Mahbubur Rahman, Sevgi Zubeyde Gurbuz",
        "published": "2023-5-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/radarconf2351548.2023.10149770"
    },
    {
        "id": 190,
        "title": "Self-supervised learning with Diffusion-based multichannel speech enhancement for speaker verification under noisy conditions",
        "authors": "Sandipana Dowerah, Ajinkya Kulkarni, Romain Serizel, Denis Jouvet",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1890"
    },
    {
        "id": 191,
        "title": "Structure-aware protein self-supervised learning",
        "authors": "Can (Sam) Chen, Jingbo Zhou, Fan Wang, Xue Liu, Dejing Dou",
        "published": "2023-4-3",
        "citations": 9,
        "abstract": "Abstract\n\nMotivation\nProtein representation learning methods have shown great potential to many downstream tasks in biological applications. A few recent studies have demonstrated that the self-supervised learning is a promising solution to addressing insufficient labels of proteins, which is a major obstacle to effective protein representation learning. However, existing protein representation learning is usually pretrained on protein sequences without considering the important protein structural information.\n\n\nResults\nIn this work, we propose a novel structure-aware protein self-supervised learning method to effectively capture structural information of proteins. In particular, a graph neural network model is pretrained to preserve the protein structural information with self-supervised tasks from a pairwise residue distance perspective and a dihedral angle perspective, respectively. Furthermore, we propose to leverage the available protein language model pretrained on protein sequences to enhance the self-supervised learning. Specifically, we identify the relation between the sequential information in the protein language model and the structural information in the specially designed graph neural network model via a novel pseudo bi-level optimization scheme. We conduct experiments on three downstream tasks: the binary classification into membrane/non-membrane proteins, the location classification into 10 cellular compartments, and the enzyme-catalyzed reaction classification into 384 EC numbers, and these experiments verify the effectiveness of our proposed method.\n\n\nAvailability and implementation\nThe Alphafold2 database is available in https://alphafold.ebi.ac.uk/. The PDB files are available in https://www.rcsb.org/. The downstream tasks are available in https://github.com/phermosilla/IEConv\\_proteins/tree/master/Datasets. The code of the proposed method is available in https://github.com/GGchen1997/STEPS_Bioinformatics.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.1093/bioinformatics/btad189"
    },
    {
        "id": 192,
        "title": "Graph Convolution Recommendation Algorithm Combined with Self-Supervised Learning",
        "authors": "Liu Guihong, Wang Ziyi",
        "published": "2023-7-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icpics58376.2023.10235695"
    },
    {
        "id": 193,
        "title": "Multi-Modal Self-Supervised Learning for Recommendation",
        "authors": "Wei Wei, Chao Huang, Lianghao Xia, Chuxu Zhang",
        "published": "2023-4-30",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3543507.3583206"
    },
    {
        "id": 194,
        "title": "Visual Kinematics Representation via Self-Supervised Object Tracking for Deep Reinforcement Learning",
        "authors": "Yixing Lan, Xin Xu, Qiang Fang, Yujun Zeng",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cac59555.2023.10452094"
    },
    {
        "id": 195,
        "title": "Retracted: Magnetic Tile Surface Defect Detection Methodology Based on Self-Attention and Self-Supervised Learning",
        "authors": "",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9890718"
    },
    {
        "id": 196,
        "title": "Application of self-supervised learning in natural language processing",
        "authors": "Ye Zhang",
        "published": "2024-2-28",
        "citations": 0,
        "abstract": "Self-supervised learning uses the label-free data learning model and has a significant impact on the NLP task. It reduces data annotation costs and improves performance. The main applications include pre-training models such as BERT and GPT, contrast learning, and pseudo-supervised and semi-supervised methods. It has been successfully applied in text classification, emotion analysis and other fields. Future research directions include mixed unsupervised learning, cross-modal learning and improving interpretability of models while focusing on ethical social issues.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/urpv6i8g3j"
    },
    {
        "id": 197,
        "title": "Self-Supervised Contrastive Learning In Spiking Neural Networks",
        "authors": "Yeganeh Bahariasl, Saeed Reza Kheradpisheh",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mvip62238.2024.10491173"
    },
    {
        "id": 198,
        "title": "Self-Supervised Learning Recommendation Algorithm Based on Meta-Paths",
        "authors": "Youyuan She, Caixiao Ouyang",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aict61584.2023.10452672"
    },
    {
        "id": 199,
        "title": "Self-Supervised Learning for Multimodal Non-Rigid 3D Shape Matching",
        "authors": "Dongliang Cao, Florian Bernard",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01701"
    },
    {
        "id": 200,
        "title": "Discriminative Spatiotemporal Alignment for Self-Supervised Video Correspondence Learning",
        "authors": "Qiaoqiao Wei, Hui Zhang, Jun-Hai Yong",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icme55011.2023.00316"
    }
]