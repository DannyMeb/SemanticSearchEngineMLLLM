[
    {
        "id": 7701,
        "title": "Self-supervised Learning in Symbolic Classification",
        "authors": "Xenia Naidenova, Sergey Kurbatov",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010732700003101"
    },
    {
        "id": 7702,
        "title": "SELF-SUPERVISED ACOUSTIC ANOMALY DETECTION VIA CONTRASTIVE LEARNING",
        "authors": "Hadi Hojjati",
        "published": "No Date",
        "citations": 0,
        "abstract": "We propose an acoustic anomaly detection algorithm based on the framework of contrastive learning. Contrastive learning is a recently proposed self-supervised approach that has shown promising results in image classification and speech recognition. However, its application in anomaly detection is underexplored. Earlier studies have demonstrated that it can achieve state-of-the-art performance in image anomaly detection, but its capability in anomalous sound detection is yet to be investigated. For the first time, we propose a contrastive learning-based framework that is suitable for acoustic anomaly detection. Since most existing contrastive learning approaches are targeted toward images, the effect of other data transformations on the performance of the algorithm is unknown. Our framework learns a representation from unlabeled data by applying audio-specific data augmentations.  We show that in the resulting latent space, normal and abnormal points are distinguishable. Experiments conducted on the MIMII dataset confirm that our approach can outperform competing methods in detecting anomalies.",
        "link": "http://dx.doi.org/10.36227/techrxiv.16828363.v1"
    },
    {
        "id": 7703,
        "title": "Self-Supervised Learning for Molecular Property Prediction",
        "authors": "Laurent Dillard",
        "published": "No Date",
        "citations": 2,
        "abstract": "Predicting molecular properties remains a challenging task with numerous potential applications, notably in drug discovery. Recently, the development of deep learning, combined with rising amounts of data, has provided powerful tools to build predictive models. Since molecules can be encoded as graphs, Graph Neural Networks (GNNs) have emerged as a popular choice of architecture to tackle this task. Training GNNs to predict molecular properties however faces the challenge of collecting annotated data which is a costly and time consuming process. On the other hand, it is easy to access large databases of molecules without annotations. In this setting, self-supervised learning can efficiently leverage large amounts of non-annotated data to compensate for the lack of annotated ones. In this work, we introduce a self-supervised framework for GNNs tailored specifically for molecular property prediction. Our framework uses multiple pretext tasks focusing on different scales of molecules (atoms, fragments and entire molecules). We evaluate our method on a representative set of GNN architectures and datasets and also consider the impact of the choice of input features. Our results show that our framework can successfully improve performance compared to training from scratch, especially in low data regimes. The improvement varies depending on the dataset, model architecture and, importantly, on the choice of input feature representation.",
        "link": "http://dx.doi.org/10.26434/chemrxiv-2021-vr43g"
    },
    {
        "id": 7704,
        "title": "Self-Supervised Representation Learning for Digital Agriculture",
        "authors": "Sudhir Sornapudi",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22541/au.167573772.22946655/v1"
    },
    {
        "id": 7705,
        "title": "Self-Supervised Learning for Molecular Property Prediction",
        "authors": "Laurent Dillard",
        "published": "No Date",
        "citations": 2,
        "abstract": "Predicting molecular properties remains a challenging task with numerous potential applications, notably in drug discovery. Recently, the development of deep learning, combined with rising amounts of data, has provided powerful tools to build predictive models. Since molecules can be encoded as graphs, Graph Neural Networks (GNNs) have emerged as a popular choice of architecture to tackle this task. Training GNNs to predict molecular properties however faces the challenge of collecting annotated data which is a costly and time consuming process. On the other hand, it is easy to access large databases of molecules without annotations. In this setting, self-supervised learning can efficiently leverage large amounts of non-annotated data to compensate for the lack of annotated ones. In this work, we introduce a self-supervised framework for GNNs tailored specifically for molecular property prediction. Our framework uses multiple pretext tasks focusing on different scales of molecules (atoms, fragments and entire molecules). We evaluate our method on a representative set of GNN architectures and datasets and also consider the impact of the choice of input features. Our results show that our framework can successfully improve performance compared to training from scratch, especially in low data regimes. The improvement varies depending on the dataset, model architecture and, importantly, on the choice of input feature representation.",
        "link": "http://dx.doi.org/10.33774/chemrxiv-2021-vr43g"
    },
    {
        "id": 7706,
        "title": "Enhancing Time Series Classification with Self-Supervised Learning",
        "authors": "Ali Ismail-Fawaz, Maxime Devanne, Jonathan Weber, Germain Forestier",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011611300003393"
    },
    {
        "id": 7707,
        "title": "Self-Training using Selection Network for Semi-supervised Learning",
        "authors": "Jisoo Jeong, Seungeui Lee, Nojun Kwak",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008940900230032"
    },
    {
        "id": 7708,
        "title": "Self-supervised learning for robotic bin-picking",
        "authors": "Liming Chen",
        "published": "No Date",
        "citations": 0,
        "abstract": "Endowing robots with human-like dexterity is a longstanding challenge in AI and robotics. State of the art research on robot manipulation is data driven through robot learning but robot data is particularly expensive to acquire. In this talk, I will showcase how robot learning for manipulation can be achieved through self-supervised learning using simulation empowered self-play.",
        "link": "http://dx.doi.org/10.52843/cassyni.5glmkd"
    },
    {
        "id": 7709,
        "title": "SELF-SUPERVISED ACOUSTIC ANOMALY DETECTION VIA CONTRASTIVE LEARNING",
        "authors": "Hadi Hojjati, Narges Armanfard",
        "published": "No Date",
        "citations": 1,
        "abstract": "We propose an acoustic anomaly detection algorithm based on the framework of contrastive learning. Contrastive learning is a recently proposed self-supervised approach that has shown promising results in image classification and speech recognition. However, its application in anomaly detection is underexplored. Earlier studies have demonstrated that it can achieve state-of-the-art performance in image anomaly detection, but its capability in anomalous sound detection is yet to be investigated. For the first time, we propose a contrastive learning-based framework that is suitable for acoustic anomaly detection. Since most existing contrastive learning approaches are targeted toward images, the effect of other data transformations on the performance of the algorithm is unknown. Our framework learns a representation from unlabeled data by applying audio-specific data augmentations.  We show that in the resulting latent space, normal and abnormal points are distinguishable. Experiments conducted on the MIMII dataset confirm that our approach can outperform competing methods in detecting anomalies.",
        "link": "http://dx.doi.org/10.36227/techrxiv.16828363.v2"
    },
    {
        "id": 7710,
        "title": "CERT: Contrastive Self-supervised Learning for Language Understanding",
        "authors": "Hongchao Fang, Pengtao Xie",
        "published": "No Date",
        "citations": 3,
        "abstract": "Pretrained language models such as BERT, GPT have shown great effectiveness in language understanding. The auxiliary predictive tasks in existing pretraining approaches are mostly defined on tokens, thus may not be able to capture sentence-level semantics very well. To address this issue,  we propose CERT: Contrastive self-supervised Encoder Representations from Transformers, which pretrains language representation models using contrastive self-supervised learning at the sentence level. CERT creates augmentations of original sentences using back-translation. Then it finetunes a pretrained language encoder (e.g., BERT) by predicting whether two augmented sentences originate from the same sentence. CERT is simple to use and can be flexibly plugged into any pretraining-finetuning NLP pipeline. We evaluate CERT on three language understanding tasks: CoLA, RTE, and QNLI. CERT outperforms BERT significantly.<br>",
        "link": "http://dx.doi.org/10.36227/techrxiv.12308378"
    },
    {
        "id": 7711,
        "title": "Self-Supervised Learning for Clustering of Wireless Spectrum Activity",
        "authors": "Ljupcho Milosheski",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4457361"
    },
    {
        "id": 7712,
        "title": "CERT: Contrastive Self-supervised Learning for Language Understanding",
        "authors": "Hongchao Fang, Pengtao Xie",
        "published": "No Date",
        "citations": 37,
        "abstract": "Pretrained language models such as BERT, GPT have shown great effectiveness in language understanding. The auxiliary predictive tasks in existing pretraining approaches are mostly defined on tokens, thus may not be able to capture sentence-level semantics very well. To address this issue,  we propose CERT: Contrastive self-supervised Encoder Representations from Transformers, which pretrains language representation models using contrastive self-supervised learning at the sentence level. CERT creates augmentations of original sentences using back-translation. Then it finetunes a pretrained language encoder (e.g., BERT) by predicting whether two augmented sentences originate from the same sentence. CERT is simple to use and can be flexibly plugged into any pretraining-finetuning NLP pipeline. We evaluate CERT on three language understanding tasks: CoLA, RTE, and QNLI. CERT outperforms BERT significantly.<br>",
        "link": "http://dx.doi.org/10.36227/techrxiv.12308378.v1"
    },
    {
        "id": 7713,
        "title": "A Snapshot-based Approach for Self-supervised Feature Learning and Weakly-supervised Classification on Point Cloud Data",
        "authors": "Xingye Li, Zhigang Zhu",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010230103990408"
    },
    {
        "id": 7714,
        "title": "SELF-SUPERVISED ACOUSTIC ANOMALY DETECTION VIA CONTRASTIVE LEARNING",
        "authors": "Hadi Hojjati, Narges Armanfard",
        "published": "No Date",
        "citations": 2,
        "abstract": "We propose an acoustic anomaly detection algorithm based on the framework of contrastive learning. Contrastive learning is a recently proposed self-supervised approach that has shown promising results in image classification and speech recognition. However, its application in anomaly detection is underexplored. Earlier studies have demonstrated that it can achieve state-of-the-art performance in image anomaly detection, but its capability in anomalous sound detection is yet to be investigated. For the first time, we propose a contrastive learning-based framework that is suitable for acoustic anomaly detection. Since most existing contrastive learning approaches are targeted toward images, the effect of other data transformations on the performance of the algorithm is unknown. Our framework learns a representation from unlabeled data by applying audio-specific data augmentations.  We show that in the resulting latent space, normal and abnormal points are distinguishable. Experiments conducted on the MIMII dataset confirm that our approach can outperform competing methods in detecting anomalies.",
        "link": "http://dx.doi.org/10.36227/techrxiv.16828363"
    },
    {
        "id": 7715,
        "title": "Lyme Disease Detection Using Progressive Resizing and Self-Supervised Learning Algorithmslyme Disease Detection Using Progressive Resizing and Self-Supervised Learning Algorithms",
        "authors": "Daryl Jacob, Om Nankar, Shilpa Gite, Shruti Patil, Ketan Kotecha",
        "published": "No Date",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4059738"
    },
    {
        "id": 7716,
        "title": "Self-supervised Learning from Semantically Imprecise Data",
        "authors": "Clemens-Alexander Brust, Björn Barz, Joachim Denzler",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010766700003124"
    },
    {
        "id": 7717,
        "title": "Self-Supervised Temporal Adaptive Learning for Weakly-Supervised Temporal Action Localization",
        "authors": "Jinrong Sheng, Jiaruo Yu, Ziqiang Li, Ao Li, Yongxin Ge",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4690808"
    },
    {
        "id": 7718,
        "title": "Using Semi-supervised Learning for Monaural Time-domain Speech Separation with a Self-supervised Learning-based SI-SNR Estimator",
        "authors": "Shaoxiang Dang, Tetsuya Matsumoto, Yoshinori Takeuchi, Hiroaki Kudo",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-85"
    },
    {
        "id": 7719,
        "title": "Phonetically Motivated Self-Supervised Speech Representation Learning",
        "authors": "Xianghu Yue, Haizhou Li",
        "published": "2021-8-30",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-905"
    },
    {
        "id": 7720,
        "title": "S4L: Self-Supervised Semi-Supervised Learning",
        "authors": "Xiaohua Zhai, Avital Oliver, Alexander Kolesnikov, Lucas Beyer",
        "published": "2019-10",
        "citations": 301,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv.2019.00156"
    },
    {
        "id": 7721,
        "title": "Contrastive Self-Supervised Learning for Stress Detection from ECG Data",
        "authors": "Suha Rabbani, Naimul Khan",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In recent literature, ECG-based stress assessment has become popular due to its proven correlation to stress and increased accessibility of ECG data through commodity hardware. However, most ECG-based stress assessment models use supervised learning, relying on manually-annotated data. Limited research is done in the area of self-supervised learning (SSL) approaches that leverage unlabelled data and none that utilize contrastive SSL. However, with the dominance of contrastive SSL in domains such as computer vision, it is essential to see if the same excellence in performance can be obtained on an ECG-based stress assessment dataset. In this paper, we propose a contrastive SSL model for stress assessment using ECG signals based on the SimCLR framework. We test our model on two ECG-based stress assessment datasets. We show that our proposed solution results in a 9% improvement in accuracy on the WESAD dataset and 3.7% on the RML dataset when compared with SOTA ECG-based SSL models for stress assessment. The development of more accurate stress assessment models, particularly those that employ non-invasive data such as ECG for assessment, leads to developments in wearable technology and the creation of better health monitoring applications in areas such as stress management and relaxation therapy.</p>",
        "link": "http://dx.doi.org/10.32920/22734386"
    },
    {
        "id": 7722,
        "title": "SelfMin: Self-Supervised Deep Learning for Advanced Mineralogical Analysis",
        "authors": "Ardiansyah Koeshidayatullah, Ivan Ferreira",
        "published": "No Date",
        "citations": 0,
        "abstract": "Mineralogical analysis is critical for understanding the origins and properties of various rock types. Recent advancements in artificial intelligence technologies, particularly supervised deep learning, have transformed qualitative and quantitative mineral analysis. However, current deep-learning approaches require high-quality annotated datasets to acquire and identify different mineralogical characteristics and properties. This is exacerbated by the time-consuming and error-prone labeling processes for the datasets. With self-supervised architectures matching supervised approaches in many computer vision tasks, it is timely to investigate the potential of Self-Supervised Learning (SSL) models in the geosciences. As a result, we use a self-supervised semantic segmentation model to identify and characterize minerals in thin sections, with the model attempting to obtain categories of interest from images without the need for human intervention in annotating the minerals. In this study, we adopted a Self-Supervised Transformer architecture and proposed SelfMin to automatically segment out pyrite minerals from other background gangue minerals in the thin section. Our proposed method achieved 80% in the mean Intersection over Union (mIoU) metric, indicating the model's ability to accurately segment minerals that were not labeled during the annotation process. This work describes the first use of self-supervised deep learning in mineralogical analysis. Further application of this proposed method would allow a robust and efficient advanced qualitative and quantitative mineralogical analysis. It also demonstrates how this technique can be implemented to avoid the need for a large volume of high-quality labeled datasets in other image-based deep learning geosciences analyses.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-2189"
    },
    {
        "id": 7723,
        "title": "Peer Review #3 of DynaMorph: self-supervised learning of morphodynamic states of live cells",
        "authors": "",
        "published": "2021-11-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15252/rc.2022652557"
    },
    {
        "id": 7724,
        "title": "Contrastive Self-Supervised Learning for Stress Detection from ECG Data",
        "authors": "Suha Rabbani, Naimul Khan",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In recent literature, ECG-based stress assessment has become popular due to its proven correlation to stress and increased accessibility of ECG data through commodity hardware. However, most ECG-based stress assessment models use supervised learning, relying on manually-annotated data. Limited research is done in the area of self-supervised learning (SSL) approaches that leverage unlabelled data and none that utilize contrastive SSL. However, with the dominance of contrastive SSL in domains such as computer vision, it is essential to see if the same excellence in performance can be obtained on an ECG-based stress assessment dataset. In this paper, we propose a contrastive SSL model for stress assessment using ECG signals based on the SimCLR framework. We test our model on two ECG-based stress assessment datasets. We show that our proposed solution results in a 9% improvement in accuracy on the WESAD dataset and 3.7% on the RML dataset when compared with SOTA ECG-based SSL models for stress assessment. The development of more accurate stress assessment models, particularly those that employ non-invasive data such as ECG for assessment, leads to developments in wearable technology and the creation of better health monitoring applications in areas such as stress management and relaxation therapy.</p>",
        "link": "http://dx.doi.org/10.32920/22734386.v1"
    },
    {
        "id": 7725,
        "title": "Peer Review #1 of DynaMorph: self-supervised learning of morphodynamic states of live cells",
        "authors": "",
        "published": "2021-11-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15252/rc.2022616772"
    },
    {
        "id": 7726,
        "title": "Self-Supervised Learning for Visual Obstacle Avoidance",
        "authors": "Tom van Dijk van Dijk",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.34641/mg.19"
    },
    {
        "id": 7727,
        "title": "Layer-Wise Training for Self-Supervised Learning on Graphs",
        "authors": "Oscar Pina, Veronica Vilaplana",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4694100"
    },
    {
        "id": 7728,
        "title": "Peer Review #2 of DynaMorph: self-supervised learning of morphodynamic states of live cells",
        "authors": "",
        "published": "2021-11-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15252/rc.2022740072"
    },
    {
        "id": 7729,
        "title": "Self-supervised and supervised deep learning for PET image reconstruction",
        "authors": "Andrew J. Reader",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1063/5.0203321"
    },
    {
        "id": 7730,
        "title": "Joint Supervised and Self-Supervised Learning for 3D Real World Challenges",
        "authors": "Antonio Alliegro, Davide Boscaini, Tatiana Tommasi",
        "published": "2021-1-10",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icpr48806.2021.9412483"
    },
    {
        "id": 7731,
        "title": "Adaptive Self-Supervised Graph Representation Learning",
        "authors": "Yunchi Gong",
        "published": "2022-1-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icoin53446.2022.9687176"
    },
    {
        "id": 7732,
        "title": "EgoFish3D: Egocentric 3D Pose Estimation from a Fisheye Camera via Self-Supervised Learning",
        "authors": "Yuxuan Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "Egocentric\nvision has a wide range of applications for human-centric activity recognition.\nHowever, the use of the egocentric fisheye camera allows wide angle coverage\nbut image distortion is introduced along with strong human body self-occlusion,\nwhich can impose significant challenges in data processing and model\nreconstruction. Unlike previous work only leveraging synthetic data for model\ntraining, this paper first presents a new real-world EgoCentric Human Action\n(ECHA) dataset. By using the self-supervised learning under multi-view\nconstraints, we propose a simple yet effective framework, namely EgoFish3D, for\negocentric 3D pose estimation from a single image in different real-world\nscenarios.",
        "link": "http://dx.doi.org/10.36227/techrxiv.18516119.v1"
    },
    {
        "id": 7733,
        "title": "Towards Self-supervised Learning for Multi-function Radar Behavior State Detection and Recognition",
        "authors": "HanCong Feng",
        "published": "No Date",
        "citations": 0,
        "abstract": "<div>The analysis of intercepted multi-function radar (MFR) signals has gained considerable attention in the field of cognitive electronic reconnaissance. With the rapid development of MFR, the switch between different work modes is becoming more flexible, increasing the agility of pulse parameters. Most of the existing approaches for recognizing MFR behaviors heavily depend on prior information, which can hardly be obtained in a non-cooperative way. This study develops a novel hierarchical contrastive self-supervise-based method for segmenting and clustering MFR pulse sequences. First, a convolutional neural network (CNN) with a limited receptive field is trained in a contrastive way to distinguish between pulse descriptor words (PDW) in the original order and the samples created by random permutations to detect the boundary between each radar word and perform segmentation. Afterward, the K-means++ algorithm with cosine distances is established to cluster the segmented PDWs according to the output vectors of the CNN’s last layer for radar words extraction. This segmenting and clustering process continues to go in the extracted radar word sequence, radar phase sequence, and so on, finishing the automatic extraction of MFR behavior states in the MFR hierarchical model. Simulation results show that without using any labeled data, the proposed method can effectively mine distinguishable patterns in the sequentially arriving PDWs and recognize the MFR behavior states under corrupted, overlapped pulse parameters.</div>",
        "link": "http://dx.doi.org/10.36227/techrxiv.17976062.v1"
    },
    {
        "id": 7734,
        "title": "Towards Self-supervised Learning for Multi-function Radar Behavior State Detection and Recognition",
        "authors": "HanCong Feng",
        "published": "No Date",
        "citations": 0,
        "abstract": "<div>The analysis of intercepted multi-function radar (MFR) signals has gained considerable attention in the field of cognitive electronic reconnaissance. With the rapid development of MFR, the switch between different work modes is becoming more flexible, increasing the agility of pulse parameters. Most of the existing approaches for recognizing MFR behaviors heavily depend on prior information, which can hardly be obtained in a non-cooperative way. This study develops a novel hierarchical contrastive self-supervise-based method for segmenting and clustering MFR pulse sequences. First, a convolutional neural network (CNN) with a limited receptive field is trained in a contrastive way to distinguish between pulse descriptor words (PDW) in the original order and the samples created by random permutations to detect the boundary between each radar word and perform segmentation. Afterward, the K-means++ algorithm with cosine distances is established to cluster the segmented PDWs according to the output vectors of the CNN’s last layer for radar words extraction. This segmenting and clustering process continues to go in the extracted radar word sequence, radar phase sequence, and so on, finishing the automatic extraction of MFR behavior states in the MFR hierarchical model. Simulation results show that without using any labeled data, the proposed method can effectively mine distinguishable patterns in the sequentially arriving PDWs and recognize the MFR behavior states under corrupted, overlapped pulse parameters.</div>",
        "link": "http://dx.doi.org/10.36227/techrxiv.17976062"
    },
    {
        "id": 7735,
        "title": "Group-Based Siamese Self-Supervised Learning",
        "authors": "Xinzheng Xu, Qingcong Geng, Zhongnian Li, Tongfeng Sun",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4622474"
    },
    {
        "id": 7736,
        "title": "Self-Supervised Learning and Network Architecture Search for Domain-Adaptive Landmark Detector",
        "authors": "kanji tanaka",
        "published": "No Date",
        "citations": 0,
        "abstract": "Fine-tuning a deep convolutional neural network (DCN) as a place-class detector (PCD) is a direct method to realize domain-adaptive visual place recognition (VPR). Although the PCD model is effective, a PCD model requires considerable amount of class-specific training examples and class-set maintenance in long-term large-scale VPR scenarios. Therefore, we propose to employ a DCN as a landmark-class detector (LCD), which allows to distinguish exponentially large numbers of different places by combining multiple landmarks, and furthermore, allows to select a stable part of the scenes (such as buildings) as landmark classes to reduce the need for class-set maintenance. However, the following important questions remain. 1) How we should mine such training examples (landmark objects) even when we have no domain-specific object detector? 2) How we should fine-tune the architecture and parameters of the DCN to a new domain-specific landmark set? To answer these questions, we present a self-supervised landmark mining approach for collecting pseudo-labeled landmark examples, and then consider the network architecture search (NAS) on the LCD task, which has significantly larger search space than typical NAS applications such as PCD. Extensive verification experiments demonstrate the superiority of the proposed framework to previous LCD methods with hand-crafted architectures and/or non-adaptive parameters, and 90% reduction in NAS cost compared with the naive NAS implementation.",
        "link": "http://dx.doi.org/10.31224/osf.io/26xnj"
    },
    {
        "id": 7737,
        "title": "Automatic Classification of THEMIS All-Sky Images via Self-Supervised Semi-Supervised Learning",
        "authors": "Jeremiah Johnson, Dogacan Ozturk, Hyunju Connor, Donald Hampton, Matthew Blandin, Amy Keesee",
        "published": "No Date",
        "citations": 0,
        "abstract": "Dynamic interactions between the solar wind and the magnetosphere give rise to dramatic auroral forms that have been instrumental in the ground-based study of magnetospheric dynamics. The general mechanism of aurora types and their large-scale patterns are well-known, but the morphology of small- to meso-scale auroral forms observed in all-sky imagers and their relation to magnetospheric dynamics&#160; and the coupling of the magnetosphere to the upper atmosphere remain in question. Machine learning has the potential to provide answers to these questions, but most existing auroral image data lack the ground-truth labels required for supervised learning and conventional statistical analyses. To mitigate this issue, we propose a novel self-supervised semi-supervised algorithm to automatically label the THEMIS all-sky image database. Specifically, we adapt the self-supervised Simple framework for Contrastive Learning of Representations (SimCLR) algorithm to learn latent representations of THEMIS all-sky images. These representations are finetuned using a small set of manually labeled data from the Oslo Aurora THEMIS (OATH) dataset, after which semi-supervised classification is used to train a classifier, beginning by training on the manually labeled OATH dataset and gradually incorporating the classifier&#8217;s most confident predictions on unlabeled data into the training dataset as ground-truth. We demonstrate that (a) classifiers fit to the learned representations of the manually labeled images achieve state&#8211;of&#8211;the&#8211;art performance, improving the classification accuracy by almost 10% over the current benchmark on labeled data; and (b) our model&#8217;s learned representations naturally cluster into more clusters than manually assigned categories, suggesting that existing categorizations are coarse and may obscure important connections between auroral types and their drivers. Finally, we introduce AuroraClick, a citizen science project with the goal of manually annotating a large representative sample of THEMIS all-sky images for the validation of our current models and the training of future models.&#160;&#160;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-2897"
    },
    {
        "id": 7738,
        "title": "Scene Representation Learning from Videos Using Self-Supervised and Weakly-Supervised Techniques",
        "authors": "Raghuveer Peri, Srinivas Parthasarathy, Shiva Sundaram",
        "published": "2022-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icip46576.2022.9897672"
    },
    {
        "id": 7739,
        "title": "Speech Recognition for Indigenous Language Using Self-Supervised Learning and Natural Language Processing",
        "authors": "Satoshi Tamura, Tomohiro Hattori, Yusuke Kato, Naoki Noguchi",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012396300003654"
    },
    {
        "id": 7740,
        "title": "Voice Activity Projection: Self-supervised Learning of Turn-taking Events",
        "authors": "Erik Ekstedt, Gabriel Skantze",
        "published": "2022-9-18",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2022-10955"
    },
    {
        "id": 7741,
        "title": "Noise-Tolerant Self-Supervised Learning for Audio-Visual Voice Activity Detection",
        "authors": "Ui-Hyun Kim",
        "published": "2021-8-30",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-43"
    },
    {
        "id": 7742,
        "title": "Graph Self Supervised Learning: the BT, the HSIC, and the VICReg",
        "authors": "Sayan Nag",
        "published": "No Date",
        "citations": 0,
        "abstract": "Self-supervised learning and pre-training strategies have developed over the last few years especially for Convolutional Neural Networks (CNNs). Recently application of such methods can also be noticed for Graph Neural Networks (GNNs). In this paper, we have used a graph based self-supervised learning strategy with different loss functions (Barlow Twins[? ], HSIC[? ], VICReg[? ]) which have shown promising results when applied with CNNs previously. We have also proposed a hybrid loss function combining the advantages of VICReg and HSIC and called it as VICRegHSIC. The performance of these aforementioned methods have been compared when applied to two different datasets namely MUTAG and PROTEINS. Moreover, the impact of different batch sizes, projector dimensions and data augmentation strategies have also been explored. The results are preliminary and we will be continuing to explore with other datasets.",
        "link": "http://dx.doi.org/10.31219/osf.io/tvmdu"
    },
    {
        "id": 7743,
        "title": "Applications of Self-Supervised Learning to Biomedical Signals: a Survey",
        "authors": "Federico Del Pup, Manfredo Atzori",
        "published": "No Date",
        "citations": 0,
        "abstract": "Over the last decade, deep learning applications in biomedical research\nhave exploded, demonstrating their ability to often outperform previous\nmachine learning approaches in various tasks. However, training deep\nlearning models for biomedical applications requires large amounts of\ndata annotated by experts, whose collection is often time- and cost-\nprohibitive. Self-Supervised Learning (SSL) has emerged as a prominent\nsolution for such problem, as it allows to learn powerful\nrepresentations from vast unlabeled data by producing supervisory\nsignals directly from the data. The high amount of recent works\nemploying the self-supervised learning paradigm for the analysis of\nbiomedical signals (biosignals) can make it difficult for researchers to\nhave a complete picture of the current research state. Therefore, this\npaper aims at outlining and clarifying the state-of-the-art in the\ndomain. The article: briefly summarizes the nature and acquisition\nmodality of the main biosignals; introduces the self-supervised learning\nmethod, focusing on the different pretraining strategies; provides a\nconcise overview of the works employing SSL for the analysis of\ndifferent types of biosignals; provides an overall analysis of critical\naspects to consider when employing SSL to biosignals, also highlighting\ncurrent open challenges. The analysis of the scientific literature\nhighlights the importance of SSL, confirming its potential to improve\nmodels’ performance and robustness, and to promote the integration of\ndeep learning into clinical tasks.",
        "link": "http://dx.doi.org/10.36227/techrxiv.22567021.v3"
    },
    {
        "id": 7744,
        "title": "Trading Through Earnings Seasons Using Self-Supervised Contrastive Representation Learning",
        "authors": "zhengxin ye, Björn  W. Schuller",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4698444"
    },
    {
        "id": 7745,
        "title": "Self-Supervised Contrastive Learning for Unsupervised Phoneme Segmentation",
        "authors": "Felix Kreuk, Joseph Keshet, Yossi Adi",
        "published": "2020-10-25",
        "citations": 33,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2020-2398"
    },
    {
        "id": 7746,
        "title": "A study on a semi-supervised learning using self-supervised learning",
        "authors": "Daehak Kim",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7465/jkdi.2023.34.6.967"
    },
    {
        "id": 7747,
        "title": "Self-Supervised Structure Learning for Crack Detection",
        "authors": "Kaige Zhang, Heng-Da Cheng",
        "published": "2023-2-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003252948-5"
    },
    {
        "id": 7748,
        "title": "CoBERT: Self-Supervised Speech Representation Learning Through Code Representation Learning",
        "authors": "Chutong Meng, Junyi Ao, Tom Ko, Mingxuan Wang, Haizhou Li",
        "published": "2023-8-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1390"
    },
    {
        "id": 7749,
        "title": "Applications of Self-Supervised Learning to Biomedical Signals: where are we now",
        "authors": "Federico Del Pup, Manfredo Atzori",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Over the last decade, deep learning applications in biomedical research have exploded, demonstrating the ability to often outperform previous machine learning approaches in various tasks. However, training deep learning models requires large amounts of data annotated by experts, whose collection is often time- and cost- prohibitive in the biomedical domain. Self-Supervised Learning (SSL) has emerged as a prominent solution for these problems, as it allows to learn powerful data representations in an unsupervised manner. Despite most applications in biomedical research targeted images, the high amount of recent works targeting biosignals can make it difficult for researchers to have a complete picture of the current situation. The aim of this paper is to outline and clarify the state of the art in the domain. The article briefly summarizes the nature and acquisition modality of biomedical signals, introduces the SSL method, and provides a complete but synthetic overview of the main works applying SSL for the analysis of biomedical signals. The analysis of the scientific literature highlights the importance of SSL, confirming its potential to improve the integration of deep learning into clinical tasks. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22567021.v2"
    },
    {
        "id": 7750,
        "title": "Self-supervised deep learning and EEG categorization",
        "authors": "Mats Svantesson",
        "published": "2024-5-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3384/9789180755429"
    },
    {
        "id": 7751,
        "title": "Very High-Resolution Satellite Image Registration Based on Self-supervised Deep Learning",
        "authors": "Taeheon Kim, Jaewon Hur, Youkyung Han",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7848/ksgpc.2023.41.4.217"
    },
    {
        "id": 7752,
        "title": "Self-Supervised Learning  For Hotspot Detection and Isolation from Thermal Images",
        "authors": "Shreyas Goyal, Jagath  C. Rajapakse",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4502477"
    },
    {
        "id": 7753,
        "title": "Applications of Self-Supervised Learning to Biomedical Signals: where are we now",
        "authors": "Federico Del Pup, Manfredo Atzori",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Over the last decade, deep learning applications in biomedical research have exploded, demonstrating the ability to often outperform previous machine learning approaches in various tasks. However, training deep learning models requires large amounts of data annotated by experts, whose collection is often time- and cost- prohibitive in the biomedical domain. Self-Supervised Learning (SSL) has emerged as a prominent solution for these problems, as it allows to learn powerful data representations in an unsupervised manner. Despite most applications in biomedical research targeted images, the high amount of recent works targeting biosignals can make it difficult for researchers to have a complete picture of the current situation. The aim of this paper is to outline and clarify the state of the art in the domain. The article briefly summarizes the nature and acquisition modality of biomedical signals, introduces the SSL method, and provides a complete but synthetic overview of the main works applying SSL for the analysis of biomedical signals. The analysis of the scientific literature highlights the importance of SSL, confirming its potential to improve the integration of deep learning into clinical tasks. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22567021.v1"
    },
    {
        "id": 7754,
        "title": "SKID: Self-Supervised Learning for Knee Injury Diagnosis from MRI Data",
        "authors": "Siladittya Manna, Saumik Bhattacharya, Umapada Pal",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In medical image analysis, the cost of acquiring high-quality data and their annotation by experts is a barrier in many medical applications. Most of the techniques used are based on supervised learning framework and need a large amount of annotated data to achieve satisfactory performance. As an alternative, in this paper, we propose a self-supervised learning (SSL) approach to learn the spatial anatomical representations from the frames of magnetic resonance (MR) video clips for the diagnosis of knee medical conditions. The pretext model learns meaningful spatial context-invariant representations. The downstream task in our paper is a class imbalanced multi-label classification. Different experiments show that the features learnt by the pretext model provide competitive performance in the downstream task. Moreover, the efficiency and reliability of the proposed pretext model in learning representations of minority classes without applying any strategy towards imbalance in the dataset can be seen from the results. To the best of our knowledge, this work is the first work of its kind in showing the effectiveness and reliability of self-supervised learning algorithms in class imbalanced multi-label classification tasks on MR videos.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.21382737.v1"
    },
    {
        "id": 7755,
        "title": "Self-Supervised Multi-Transformation Learning for Time Series Anomaly Detection",
        "authors": "Han Han, Han Chuang, Fan Haoyi",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4550916"
    },
    {
        "id": 7756,
        "title": "SSL-Unet: A Self-Supervised Learning Strategy Base on U-Net for Retinal Vessel Segmentation",
        "authors": "Chao Ma",
        "published": "No Date",
        "citations": 0,
        "abstract": "We propose a SSL-Unet model for retinal vascular segmentation as well as two self-supervised training strategies. The strategy can help the self-supervised module to learn pseudo labels for improving the segmentation performance. Moreover, the fusion of both self-supervised and supervised paradigms is applied to retinal segmentation for the first time. Meanwhile, it can also be extended to any segmentation network.",
        "link": "http://dx.doi.org/10.36227/techrxiv.16823236"
    },
    {
        "id": 7757,
        "title": "Enhanced Self-Supervised Learning with Autoencoder",
        "authors": "jiajie wu, junyan yang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4156193"
    },
    {
        "id": 7758,
        "title": "Applications of Self-Supervised Learning to Biomedical Signals: where are we now",
        "authors": "Federico Del Pup, Manfredo Atzori",
        "published": "No Date",
        "citations": 1,
        "abstract": "<p>Over the last decade, deep learning applications in biomedical research have exploded, demonstrating the ability to often outperform previous machine learning approaches in various tasks. However, training deep learning models requires large amounts of data annotated by experts, whose collection is often time- and cost- prohibitive in the biomedical domain. Self-Supervised Learning (SSL) has emerged as a prominent solution for these problems, as it allows to learn powerful data representations in an unsupervised manner. Despite most applications in biomedical research targeted images, the high amount of recent works targeting biosignals can make it difficult for researchers to have a complete picture of the current situation. The aim of this paper is to outline and clarify the state of the art in the domain. The article briefly summarizes the nature and acquisition modality of biomedical signals, introduces the SSL method, and provides a complete but synthetic overview of the main works applying SSL for the analysis of biomedical signals. The analysis of the scientific literature highlights the importance of SSL, confirming its potential to improve the integration of deep learning into clinical tasks. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22567021"
    },
    {
        "id": 7759,
        "title": "Advancing Inland Water Body Mapping with Self-Supervised Machine Learning",
        "authors": "Ankit Sharma, Mukund Narayanan, Idhayachandhiran Ilampooranan",
        "published": "No Date",
        "citations": 0,
        "abstract": "Traditional methods of mapping inland water bodies involve labor-intensive and manual data labeling, limiting their scalability to a larger extent. This study introduces a novel approach: self-supervised machine learning (SSML) for mapping inland water bodies. SSML is a training method where a model learns from data without the need for explicit human-labeled annotations. Using this technique, the study mapped inland water bodies in Pudukkottai, India, using LANDSAT-8 imagery from 2021. The training data for SSML were derived from two spectral indices: the Normalized Difference Vegetation Index and the Modified Normalized Difference Water Index. These indices were used to establish a threshold for automatically generating pseudo labels for two categories: water and non-water. This pseudo-labeled dataset was then utilized to train various machine learning models, including random forest, support vector machine, classification and regression tree, and gradient boosting. The accuracy of the final classified map was assessed using a spatial agreement test, which measures the degree of agreement of the classified map in relation to a reference dataset. The spatial agreement test used the Joint Research Commission (JRC) water map of 2021 as the reference dataset. The final inland water body map, derived from the SSML approach, demonstrated a high spatial agreement of 91% with the JRC water map. Among the SSML models, the random forest model outperformed others due to its ensemble nature. Compared to traditionally supervised classifiers (trained with 137 water points and 74 non-water points), the SSML models exhibited superior performance with a spatial agreement of 91%, significantly higher than the 67% achieved by the supervised model. This study is the first to demonstrate the application of SSML for mapping inland water bodies, offering an efficient and cost-effective alternative to traditional manual labeling. This approach holds significant potential for advancing remote sensing applications, particularly in regions where obtaining ground truth labeling is costly or impractical.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu24-16879"
    },
    {
        "id": 7760,
        "title": "Self-Supervised Learning and Network Architecture Search for Domain-Adaptive Landmark Detector",
        "authors": "kanji tanaka",
        "published": "No Date",
        "citations": 0,
        "abstract": "Fine-tuning a deep convolutional neural network (DCN) as a place-class detector (PCD) is a direct method to realize domain-adaptive visual place recognition (VPR). Although the PCD model is effective, a PCD model requires considerable amount of class-specific training examples and class-set maintenance in long-term large-scale VPR scenarios. Therefore, we propose to employ a DCN as a landmark-class detector (LCD), which allows to distinguish exponentially large numbers of different places by combining multiple landmarks, and furthermore, allows to select a stable part of the scenes (such as buildings) as landmark classes to reduce the need for class-set maintenance. However, the following important questions remain. 1) How we should mine such training examples (landmark objects) even when we have no domain-specific object detector? 2) How we should fine-tune the architecture and parameters of the DCN to a new domain-specific landmark set? To answer these questions, we present a self-supervised landmark mining approach for collecting pseudo-labeled landmark examples, and then consider the network architecture search (NAS) on the LCD task, which has significantly larger search space than typical NAS applications such as PCD. Extensive verification experiments demonstrate the superiority of the proposed framework to previous LCD methods with hand-crafted architectures and/or non-adaptive parameters, and 90% reduction in NAS cost compared with the naive NAS implementation.",
        "link": "http://dx.doi.org/10.31219/osf.io/45pq7"
    },
    {
        "id": 7761,
        "title": "Subseasonal-to-seasonal forecasts through self-supervised learning",
        "authors": "Jannik Thümmel, Felix Strnad, Jakob Schlör, Bedartha Goswami",
        "published": "No Date",
        "citations": 0,
        "abstract": "Sub-seasonal to seasonal (S2S) weather forecasts play a crucial role in guiding decision-making processes related to agricultural planning, energy management, and disaster mitigation. Operated on time scales spanning weeks to months, these forecasts distinguish themselves from short-term predictions in two key aspects: (i) the atmospheric dynamics on these timescales are accurately described only through statistical means, and (ii) these dynamics exhibit large-scale phenomena in both spatial and temporal dimensions. Despite the success of deep learning (DL) in short-term weather forecasting, DL-based S2S predictions face challenges arising from limited training data and significant predictability fluctuations due to varying atmospheric conditions. To enhance the reliability of S2S forecasts by incorporating the latest DL advancements, our proposal involves the application of the masked auto-encoder (MAE) framework. This framework aims to learn comprehensive representations of large-scale atmospheric phenomena from high-resolution global data. Beyond assessing the suitability of these learned representations for S2S forecasting, our investigation extends to their potential to account for climatic phenomena, such as the Madden-Julian Oscillation, recognized for enhancing predictability on S2S timescales.",
        "link": "http://dx.doi.org/10.5194/dkt-13-48"
    },
    {
        "id": 7762,
        "title": "SSL-Unet: A Self-Supervised Learning Strategy Base on U-Net for Retinal Vessel Segmentation",
        "authors": "Chao Ma",
        "published": "No Date",
        "citations": 0,
        "abstract": "We propose a SSL-Unet model for retinal vascular segmentation as well as two self-supervised training strategies. The strategy can help the self-supervised module to learn pseudo labels for improving the segmentation performance. Moreover, the fusion of both self-supervised and supervised paradigms is applied to retinal segmentation for the first time. Meanwhile, it can also be extended to any segmentation network.",
        "link": "http://dx.doi.org/10.36227/techrxiv.16823236.v1"
    },
    {
        "id": 7763,
        "title": "Bioacoustic Event Detection with Self-Supervised Contrastive Learning",
        "authors": "Peter C. Bermant, Leandra Brickson, Alexander J. Titus",
        "published": "No Date",
        "citations": 1,
        "abstract": "ABSTRACTWhile deep learning has revolutionized ecological data analysis, existing strategies often rely on supervised learning, which is subject to limitations on real-world applicability. In this paper, we apply self-supervised deep learning methods to bioacoustic data to enable unsupervised detection of bioacoustic event boundaries. We propose a convolutional deep neural network that operates on the raw waveform directly and is trained in accordance with the Noise Contrastive Estimation principle, which enables the system to detect spectral changes in the input acoustic stream. The model learns a representation of the input audio sampled at low frequency that encodes information regarding dissimilarity between sequential acoustic windows. During inference, we use a peak finding algorithm to search for regions of high dissimilarity in order to identify temporal boundaries of bioacoustic events. We report results using these techniques to detect sperm whale (Physeter macrocephalus) coda clicks in real-world recordings, and we demonstrate the viability of analyzing the vocalizations of other species (e.g. Bengalese finch syllable segmentation) in addition to other data modalities (e.g. animal behavioral dynamics, embryo development and tracking). We find that the self-supervised deep representation learning-based technique outperforms established threshold-based baseline methods without requiring manual annotation of acoustic datasets. Quantitatively, our approach yields a maximal R-value and F1-score of 0.887 and 0.876, respectively, and an area under the Precision-Recall curve (PR-AUC) of 0.917, while a baseline threshold detector acting on signal energy amplitude returns a maximal R-value and F1-score of 0.620 and 0.576, respectively, and a PR-AUC of 0.571. We also compare with a threshold detector using preprocessed (e.g. denoised) acoustic input. The findings of this paper establish the validity of unsupervised bioacoustic event detection using deep neural networks and self-supervised contrastive learning as an effective alternative to conventional techniques that leverage supervised methods for signal presence indication. Providing a means for highly accurate unsupervised detection, this paper serves as an important step towards developing a fully automated system for real-time acoustic monitoring of bioacoustic signals in real-world acoustic data. All code and data used in this study are available online.",
        "link": "http://dx.doi.org/10.1101/2022.10.12.511740"
    },
    {
        "id": 7764,
        "title": "Censer: Curriculum Semi-supervised Learning for Speech Recognition Based on Self-supervised Pre-training",
        "authors": "Bowen Zhang, Songjun Cao, Xiaoming Xhang, Yike Zhang, Long Ma, Takahiro Shinozaki",
        "published": "2022-9-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2022-10226"
    },
    {
        "id": 7765,
        "title": "Combining Self-Supervised and Supervised Learning with Noisy Labels",
        "authors": "Yongqi Zhang, Hui Zhang, Quanming Yao, Jun Wan",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10221957"
    },
    {
        "id": 7766,
        "title": "Seismic data denoising by combining self-supervised and supervised learning",
        "authors": "Yen Sun, Paul Williamson",
        "published": "2023-12-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1190/image2023-3909418.1"
    },
    {
        "id": 7767,
        "title": "SKID: Self-Supervised Learning for Knee Injury Diagnosis from MRI Data",
        "authors": "Siladittya Manna, Saumik Bhattacharya, Umapada Pal",
        "published": "No Date",
        "citations": 3,
        "abstract": "<p>In medical image analysis, the cost of acquiring high-quality data and their annotation by experts is a barrier in many medical applications. Most of the techniques used are based on supervised learning framework and need a large amount of annotated data to achieve satisfactory performance. As an alternative, in this paper, we propose a self-supervised learning (SSL) approach to learn the spatial anatomical representations from the frames of magnetic resonance (MR) video clips for the diagnosis of knee medical conditions. The pretext model learns meaningful spatial context-invariant representations. The downstream task in our paper is a class imbalanced multi-label classification. Different experiments show that the features learnt by the pretext model provide competitive performance in the downstream task. Moreover, the efficiency and reliability of the proposed pretext model in learning representations of minority classes without applying any strategy towards imbalance in the dataset can be seen from the results. To the best of our knowledge, this work is the first work of its kind in showing the effectiveness and reliability of self-supervised learning algorithms in class imbalanced multi-label classification tasks on MR videos.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.21382737"
    },
    {
        "id": 7768,
        "title": "Self-Supervised Dialogue Learning for Spoken Conversational Question Answering",
        "authors": "Nuo Chen, Chenyu You, Yuexian Zou",
        "published": "2021-8-30",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-120"
    },
    {
        "id": 7769,
        "title": "Self-Supervised Feature Learning by Learning to Spot Artifacts",
        "authors": "Simon Jenni, Paolo Favaro",
        "published": "2018-6",
        "citations": 70,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr.2018.00289"
    },
    {
        "id": 7770,
        "title": "Self-supervised Classification of Weather Systems based on Spatiotemporal Contrastive Learning",
        "authors": "Liwen Wang, Qian Li, Qi Lv",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/essoar.10510685.1"
    },
    {
        "id": 7771,
        "title": "S2RNN: Self-Supervised Reconfigurable Neural Network Hardware Accelerator for Machine Learning Applications",
        "authors": "Kasem Khalil, Bappaditya Dey, Magdy Bayoumi",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Neural networks have been commonly used in different domains. Hardware implementation of the neural networks is challenging to fit different applications’ requirements. This often necessitates realizing different neural network FPGA configurations from the very scratch specific to a given application. This paper proposes a flexible method that can be reconfigured in a self-supervised way to fit several ap?plications’ requirements, by providing only maximum available computational nodes a prior. The proposed method is based on reconfiguring the required number of hidden layers and hidden nodes of that layer based on a given application. Reconfigurability also allows to decide and update the number of active nodes, at layer (l+1), which receives computational results of l th layer nodes. A configuration block is used to send a signal to the control block which follows each node output. The control block decides which following nodes receive the output according to the corresponding signal value from the configuration block. Each node receives a signal to be enabled or disabled from the configuration block. Therefore, the number of inputs of each node and nodes in each layer is determined according to the desired performance. The goal here is to automatically propose the optimal NN configuration through reconfigurability to fit different applications, to achieve the maximum accuracy possible. The optimality can be demonstrated in terms of minimum average power, average delay, and area overhead as well as maximum throughput and accuracy. The main advantage of the proposed approach is the reusability of the optimized architecture (which is self-learned online) for the very first application/dataset, as the initial configuration for any new/next dataset/application rather than starting from scratch. We have demonstrated with experimental results, the proposed approach helps primarily to significantly reduce optimized architecture search cost (the number of online training iterations) as well as associated average power consumption for successive datasets/applications. Our proposed method demonstrates its effectiveness both quantitatively and qualitatively. The proposed method is verified against two different classification problems, MNIST and CIFAR-10. Our proposed reconfigurable method demonstrates stable accuracy of 98.97% and 98.95% against the state-of-the-art neural network with two different fixed configurations as (98.85% and 73.0%) for MNIST and (93.47% and 70.21%) for CIFAR-10, respectively. The proposed method also demonstrates a 20.9% reduction in average power dissipation against the state-of-the-art method. The proposed method is implemented and tested using VHDL and Altera FPGA. The results show resource utilization is comparable with the state-of-the-art method. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22728788.v1"
    },
    {
        "id": 7772,
        "title": "S2RNN: Self-Supervised Reconfigurable Neural Network Hardware Accelerator for Machine Learning Applications",
        "authors": "Kasem Khalil, Bappaditya Dey, Magdy Bayoumi",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Neural networks have been commonly used in different domains. Hardware implementation of the neural networks is challenging to fit different applications’ requirements. This often necessitates realizing different neural network FPGA configurations from the very scratch specific to a given application. This paper proposes a flexible method that can be reconfigured in a self-supervised way to fit several ap?plications’ requirements, by providing only maximum available computational nodes a prior. The proposed method is based on reconfiguring the required number of hidden layers and hidden nodes of that layer based on a given application. Reconfigurability also allows to decide and update the number of active nodes, at layer (l+1), which receives computational results of l th layer nodes. A configuration block is used to send a signal to the control block which follows each node output. The control block decides which following nodes receive the output according to the corresponding signal value from the configuration block. Each node receives a signal to be enabled or disabled from the configuration block. Therefore, the number of inputs of each node and nodes in each layer is determined according to the desired performance. The goal here is to automatically propose the optimal NN configuration through reconfigurability to fit different applications, to achieve the maximum accuracy possible. The optimality can be demonstrated in terms of minimum average power, average delay, and area overhead as well as maximum throughput and accuracy. The main advantage of the proposed approach is the reusability of the optimized architecture (which is self-learned online) for the very first application/dataset, as the initial configuration for any new/next dataset/application rather than starting from scratch. We have demonstrated with experimental results, the proposed approach helps primarily to significantly reduce optimized architecture search cost (the number of online training iterations) as well as associated average power consumption for successive datasets/applications. Our proposed method demonstrates its effectiveness both quantitatively and qualitatively. The proposed method is verified against two different classification problems, MNIST and CIFAR-10. Our proposed reconfigurable method demonstrates stable accuracy of 98.97% and 98.95% against the state-of-the-art neural network with two different fixed configurations as (98.85% and 73.0%) for MNIST and (93.47% and 70.21%) for CIFAR-10, respectively. The proposed method also demonstrates a 20.9% reduction in average power dissipation against the state-of-the-art method. The proposed method is implemented and tested using VHDL and Altera FPGA. The results show resource utilization is comparable with the state-of-the-art method. </p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.22728788"
    },
    {
        "id": 7773,
        "title": "A self-supervised domain-general learning framework for human ventral stream representation",
        "authors": "Talia Konkle, George A. Alvarez",
        "published": "No Date",
        "citations": 3,
        "abstract": "ABSTRACTAnterior regions of the ventral visual stream encode substantial information about object categories. Are top-down category-level forces critical for arriving at this representation, or can this representation be formed purely through domain-general learning of natural image structure? Here we present a fully self-supervised model which learns to represent individual images, rather than categories, such that views of the same image are embedded nearby in a low-dimensional feature space, distinctly from other recently encountered views. We find (i) category information implicitly emerges in the local similarity structure of this feature space, and (ii) these models learn hierarchical features which capture the structure of brain responses across the human ventral visual stream, on par with category-supervised models. These results provide computational support for a domain-general framework guiding the formation of visual representation, where the proximate goal is not explicitly about category information, but is instead to learn unique, compressed descriptions of the visual world.",
        "link": "http://dx.doi.org/10.1101/2020.06.15.153247"
    },
    {
        "id": 7774,
        "title": "SELF-SUPERVISED LEARNING FOR IMPROVED SAS TARGET RECOGNITION",
        "authors": "BW SHEFFIELD",
        "published": "2023-9-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.25144/15919"
    },
    {
        "id": 7775,
        "title": "Self-supervised learning of deep visual representations",
        "authors": " Mathilde Caron",
        "published": "2023-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.48556/sif.1024.21.171"
    },
    {
        "id": 7776,
        "title": "Self-supervised Deep Learning Approaches to Speaker Recognition: A Ph.D. Thesis Overview",
        "authors": "Umair Khan, Javier Hernando",
        "published": "2021-3-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/iberspeech.2021-38"
    },
    {
        "id": 7777,
        "title": "Leveraging Unsupervised and Self-Supervised Learning for Video Anomaly Detection",
        "authors": "Devashish Lohani, Carlos Crispim-Junior, Quentin Barthélemy, Sarah Bertrand, Lionel Robinault, Laure Rodet",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011663600003417"
    },
    {
        "id": 7778,
        "title": "Multi-task Self-Supervised Visual Learning",
        "authors": "Carl Doersch, Andrew Zisserman",
        "published": "2017-10",
        "citations": 303,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv.2017.226"
    },
    {
        "id": 7779,
        "title": "Self-Supervised Machine Learning Approach for Identifying Biochemical Influences on Protein-Ligand Binding Affinity",
        "authors": "Arjun Singh",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nDrug discovery is incredibly time-consuming and expensive, averaging over 10 years and $985 million per drug. Calculating the binding affinity between a target protein and a ligand is critical for discovering viable drugs. Although supervised machine learning (ML) models can predict binding affinity accurately, they suffer from lack of interpretability and inaccurate feature selection caused by multicollinear data. This study used self-supervised ML to reveal underlying protein-ligand characteristics that strongly influence binding affinity. Protein-ligand 3D models were collected from the PDBBind database and vectorized into 2422 features per complex. LASSO Regression and hierarchical clustering were utilized to minimize multicollinearity between features. Correlation analyses and Autoencoder-based latent space representations were generated to identify features significantly influencing binding affinity. A Generative Adversarial Network was used to simulate ligands with certain counts of a significant feature, and thereby determine the effect of a feature on improving binding affinity with a given target protein. It was found that the CC and CCCN fragment counts in the ligand notably influence binding affinity. Re-pairing proteins with simulated ligands that had higher CC and CCCN fragment counts could increase binding affinity by 34.99-37.62% and 36.83%-36.94%, respectively. This discovery contributes to a more accurate representation of ligand chemistry that can increase the accuracy, explainability, and generalizability of ML models so that they can more reliably identify novel drug candidates. Directions for future work include integrating knowledge on ligand fragments into supervised ML models, examining the effect of CC and CCCN fragments on fragment-based drug design, and employing computational techniques to elucidate the chemical activity of these fragments.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1091733/v1"
    },
    {
        "id": 7780,
        "title": "Cube2Vec: Self-Supervised Representation Learning for Sub-Surface Models",
        "authors": "P. Lang, T. Adeyemi, R. Schulze-Riegert",
        "published": "2020",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3997/2214-4609.202035056"
    },
    {
        "id": 7781,
        "title": "Self-Supervised Image Representation Learning Transcending Masking with Paired Image Overlay",
        "authors": "Yinheng Li, Han Ding, Shaofei Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4375452"
    },
    {
        "id": 7782,
        "title": "Self-Supervised Learning for Improving Automated Predictions of Cobb Angles from X-Ray Images: Machine Learning Study (Preprint)",
        "authors": "Lalitha Kalle, Peter Washington",
        "published": "No Date",
        "citations": 0,
        "abstract": "\nUNSTRUCTURED\nScoliosis is an abnormal spine curvature with a frontal plane deviation of more than 10 degrees and axial rotation. The measuring of the Cobb angle is time-consuming. It contributes to observer disparities due to variations in identifying the end vertebra, posing a challenge for inexperienced clinicians in accurately assessing scoliosis. SSL tasks expand the dataset before pretraining, improving the model’s efficiency at learning unlabeled features of data. To explore the use of SSL to address this issue, we used a dataset which comprises 609 x-ray spinal images depicting various scoliosis cases, each annotated with three Cobb angles (MA, TA, and BA). We applied SSL in the form of an image rotation pretext task to train a MobileNetV2 model to understand aspects of the images without any training data. We then fine-tuned this model against the same network without any SSL pre-training. We found that the model pre-trained with SSL outperformed the model without SSL pre-training, whether or not the model was initialized using ImageNet weights. This work demonstrates the promise of SSL for Cobb angle prediction using x-ray images. We recommend that the medical imaging research community explore further SSL pre-training strategies for regression tasks such as Cobb angle prediction.\n",
        "link": "http://dx.doi.org/10.2196/preprints.53791"
    },
    {
        "id": 7783,
        "title": "Survey on Self-Supervised Learning: Auxiliary Pretext Tasks and Contrastive Learning Methods in Imaging",
        "authors": "Saleh Albelwi",
        "published": "2022-4-14",
        "citations": 44,
        "abstract": "Although deep learning algorithms have achieved significant progress in a variety of domains, they require costly annotations on huge datasets. Self-supervised learning (SSL) using unlabeled data has emerged as an alternative, as it eliminates manual annotation. To do this, SSL constructs feature representations using pretext tasks that operate without manual annotation, which allows models trained in these tasks to extract useful latent representations that later improve downstream tasks such as object classification and detection. The early methods of SSL are based on auxiliary pretext tasks as a way to learn representations using pseudo-labels, or labels that were created automatically based on the dataset’s attributes. Furthermore, contrastive learning has also performed well in learning representations via SSL. To succeed, it pushes positive samples closer together, and negative ones further apart, in the latent space. This paper provides a comprehensive literature review of the top-performing SSL methods using auxiliary pretext and contrastive learning techniques. It details the motivation for this research, a general pipeline of SSL, the terminologies of the field, and provides an examination of pretext tasks and self-supervised methods. It also examines how self-supervised methods compare to supervised ones, and then discusses both further considerations and ongoing challenges faced by SSL.",
        "link": "http://dx.doi.org/10.3390/e24040551"
    },
    {
        "id": 7784,
        "title": "Extending Self-Distilled Self-Supervised Learning For Semi-Supervised Speaker Verification",
        "authors": "Jeong-Hwan Choi, Jehyun Kyung, Ju-Seok Seong, Ye-Rin Jeoung, Joon-Hyuk Chang",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/asru57964.2023.10389802"
    },
    {
        "id": 7785,
        "title": "Transfer Learning or Self-supervised Learning? A Tale of Two Pretraining Paradigms",
        "authors": "Xingyi Yang, Xuehai He, Yuxiao Liang, Yue Yang, Shanghang Zhang, Pengtao Xie",
        "published": "No Date",
        "citations": 2,
        "abstract": "Pretraining has become a standard technique in computer vision and natural language processing, which usually helps to improve performance substantially. Previously, the most dominant pretraining method is transfer learning (TL), which uses labeled data to learn a good representation network. Recently, a new pretraining approach -- self-supervised learning (SSL) -- has demonstrated promising results on a wide range of applications. SSL does not require annotated labels. It is purely conducted on input data by solving auxiliary tasks defined on the input data examples. The current reported results show that in certain applications, SSL outperforms TL and the other way around in other applications. There has not been a clear understanding on what properties of data and tasks render one approach outperforms the other. Without an informed guideline, ML researchers have to try both methods to find out which one is better empirically. It is usually  time-consuming to do so. In this work, we aim to address this problem. We perform a comprehensive comparative study between SSL and TL regarding which one works better under different properties of data and tasks, including domain difference between source and target tasks, the amount of pretraining data, class imbalance in source data, and usage of target data for additional pretraining, etc. The insights distilled from our comparative studies can help ML researchers decide which method to use based on the properties of their applications.",
        "link": "http://dx.doi.org/10.36227/techrxiv.12502298"
    },
    {
        "id": 7786,
        "title": "Unbiased and Augmentation-Free Self-Supervised Graph Representation Learning",
        "authors": "Ruyue Liu, Rong Yin, Yong Liu, Weiping Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4567046"
    },
    {
        "id": 7787,
        "title": "Label-Efficient Self-Supervised Speaker Verification With Information Maximization and Contrastive Learning",
        "authors": "Theo Lepage, Reda Dehak",
        "published": "2022-9-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2022-802"
    },
    {
        "id": 7788,
        "title": "Speech Emotion Recognition Using Transfer Learning and Self-Supervised Speech Representation Learning",
        "authors": "Babak Nasersharif, Marziye Azad",
        "published": "2023-5-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icee59167.2023.10334799"
    },
    {
        "id": 7789,
        "title": "Intrinsically Motivated Self-supervised Learning in Reinforcement Learning",
        "authors": "Yue Zhao, Chenzhuang Du, Hang Zhao, Tiejun Li",
        "published": "2022-5-23",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icra46639.2022.9812213"
    },
    {
        "id": 7790,
        "title": "A Domain Adaptive Adversarial Training Method Based on Self-Supervised Learning",
        "authors": "Chuqing Sun",
        "published": "2022-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mlise57402.2022.00070"
    },
    {
        "id": 7791,
        "title": "JGCL: Joint Self-Supervised and Supervised Graph Contrastive Learning",
        "authors": "Selahattin Akkas, Ariful Azad",
        "published": "2022-4-25",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3487553.3524722"
    },
    {
        "id": 7792,
        "title": "Self-omics: A Self-supervised Learning Framework for Multi-omics Cancer Data",
        "authors": "Sayed Hashim, Karthik Nandakumar, Mohammad Yaqub",
        "published": "2022-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811270611_0025"
    },
    {
        "id": 7793,
        "title": "Transfer Learning or Self-supervised Learning? A Tale of Two Pretraining Paradigms",
        "authors": "Xingyi Yang, Xuehai He, Yuxiao Liang, Yue Yang, Shanghang Zhang, Pengtao Xie",
        "published": "No Date",
        "citations": 7,
        "abstract": "Pretraining has become a standard technique in computer vision and natural language processing, which usually helps to improve performance substantially. Previously, the most dominant pretraining method is transfer learning (TL), which uses labeled data to learn a good representation network. Recently, a new pretraining approach -- self-supervised learning (SSL) -- has demonstrated promising results on a wide range of applications. SSL does not require annotated labels. It is purely conducted on input data by solving auxiliary tasks defined on the input data examples. The current reported results show that in certain applications, SSL outperforms TL and the other way around in other applications. There has not been a clear understanding on what properties of data and tasks render one approach outperforms the other. Without an informed guideline, ML researchers have to try both methods to find out which one is better empirically. It is usually  time-consuming to do so. In this work, we aim to address this problem. We perform a comprehensive comparative study between SSL and TL regarding which one works better under different properties of data and tasks, including domain difference between source and target tasks, the amount of pretraining data, class imbalance in source data, and usage of target data for additional pretraining, etc. The insights distilled from our comparative studies can help ML researchers decide which method to use based on the properties of their applications.",
        "link": "http://dx.doi.org/10.36227/techrxiv.12502298.v1"
    },
    {
        "id": 7794,
        "title": "Assessing Property Damage from Natural Disasters: Self-Supervised and Supervised Learning Models for Remote Sensing Imagery Analysis",
        "authors": "Xing Zi, Taoyuan Zhu, Yunxiao Shi, Xian Tao, Jun Li, Mukesh Prasad",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4699455"
    },
    {
        "id": 7795,
        "title": "A new self-supervised method for supervised learning",
        "authors": "Yuhang Yang, Zilin Ding, Xuan Cheng, Xiaomin Wang, Ming Liu",
        "published": "2021-12-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2626541"
    },
    {
        "id": 7796,
        "title": "Automatic feature extraction by supervised and contrastive self-supervised learning based on wavelet and hard negatives to detect HIFU lesion area",
        "authors": "Matineh Zavar, Hamid Reza Ghaffary, Hamid Tabatabaee",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe adoption of Deep Neural Networks has surged due to their ability to automatically extract features and employ diverse approaches in data analysis. This research proposes a novel feature extraction method that doesn't rely on labeled training data, particularly considering the utilization of hard negatives. Given the remarkable success of DNN-based models in analyzing various medical images, including disease diagnosis and detection, this paper delves into diagnosing the lesion area against the normal area, particularly in the context of the non-invasive treatment of HIFU. Monitoring and analyzing inputs related to the lesion area are crucial to prevent damage to normal tissue during the heating process. However, several challenges exist in ultrasound medical imaging, including small sample sizes, data lacking labels, and the time-intensive nature of deep supervised training. These challenges have motivated the introduction of a new self-supervised deep learning method. While supervised learning excels in accuracy, unlabeled data holds valuable information discarded in supervised approaches. Conversely, ultrasonic data's nature lies in the RF signal, offering a detailed acoustic structure of tissue. Acknowledging the limitations and advantages of each method, an effective approach leveraging both signal and image simultaneously is presented. This integrated method enhances diagnostic capabilities and contributes to improve monitoring of HIFU procedures. The proposed methodology for classifying HIFU lesion areas attained high performance metrics: 95% accuracy, 94% precision, 96% recall, and a 95% F1-score. These outcomes underscore the efficacy of the proposed method in accurately classifying HIFU lesion areas.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3721755/v1"
    },
    {
        "id": 7797,
        "title": "Individualized, self-supervised deep learning for blood glucose prediction",
        "authors": "Johannes Fuest, Marco Tacke, Leander Ullman, Peter Washington",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractThe current standard for monitoring blood glucose levels in diabetes patients are continuous glucose monitoring (CGM) devices, which are costly and carry the risk of complications, such as allergic reactions or skin irritations from the adhesive used to attach the CGM sensor to the skin. CGM devices are also highly visible and can thus act as a discomforting disease-marker for diabetes patients. To mitigate these issues, we develop and test a novel method that is able to predict blood glucose levels with only non-invasive predictor variables and a very small number of target variable measurements by using individualization and self-supervised deep learning. Using only a single blood glucose measurements per week, our method (6387.47 glucose-specific MSE) outperforms traditional deep learning performed with hourly measurements (8191.23 glucose-specific MSE). Across eight experiments where blood glucose measurements are more than one hour apart, our approach outperforms traditional deep learning without exception. Our findings suggest that self-supervised, individualized deep learning could provide an avenue towards alternatives to CGM devices that would be less costly, non-invasive, and thus more accessible.",
        "link": "http://dx.doi.org/10.1101/2023.08.19.23294318"
    },
    {
        "id": 7798,
        "title": "Improving Speech Emotion Recognition Using Self-Supervised Learning with Domain-Specific Audiovisual Tasks",
        "authors": "Lucas Goncalves, Carlos Busso",
        "published": "2022-9-18",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2022-11012"
    },
    {
        "id": 7799,
        "title": "Review for \"ACOVMD: Automatic COVID‐19 misinformation detection in Twitter using self‐trained semi‐supervised hybrid deep learning model\"",
        "authors": "",
        "published": "2022-7-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/issj.12475/v1/review1"
    },
    {
        "id": 7800,
        "title": "Self-Supervised Dictionary Learning Via Pseudo Label Embedding",
        "authors": "Shuai Shao, Lei Xing, Yanjiang Wang, Baodi Liu, Weifeng Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4362439"
    }
]