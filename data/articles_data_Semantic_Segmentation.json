[
    {
        "id": 12571,
        "title": "Simultaneous Object Detection and Semantic Segmentation",
        "authors": "Niels Salscheider",
        "published": "2020",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009142905550561"
    },
    {
        "id": 12572,
        "title": "Semantic Segmentation for Pet Detection",
        "authors": "Chibuzo Valentine Nwadike",
        "published": "No Date",
        "citations": 0,
        "abstract": "This research project encompasses an in-depth exploration of semantic segmentation methods for pet detection using the Oxford Pets Dataset. The primary objective involves the developmentof a convolutional neural network model rooted in deep-learning principles, designed to achieve precise segmentation and detection of pets within images. The approach integrates advanced image processing techniques, leveraging deep learning methodologies, and dataset augmentation strategies to enhance pet detection accuracy substantially. The outcomes underscore the considerable potential of semantic segmentation in elevating the effectiveness of pet detection applications. This study offers promising avenues for practical integration in real-world contexts such as pet care and surveillance systems. The achieved advancements underscore the proposed technique's viability and contribute to the broader discourse on enhancing object detection through sophisticated segmentation strategies.",
        "link": "http://dx.doi.org/10.14293/p2199-8442.1.sop-.pjpzw3.v1"
    },
    {
        "id": 12573,
        "title": "Single-step Adversarial Training for Semantic Segmentation",
        "authors": "Daniel Wiens, Barbara Hammer",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010788400003122"
    },
    {
        "id": 12574,
        "title": "Combining Deep Semantic Segmentation Network and Graph Convolutional Neural Network for Semantic Segmentation of Remote Sensing Imagery",
        "authors": "Song Ouyang, Yansheng Li",
        "published": "2020-12-31",
        "citations": 46,
        "abstract": "Although the deep semantic segmentation network (DSSN) has been widely used in remote sensing (RS) image semantic segmentation, it still does not fully mind the spatial relationship cues between objects when extracting deep visual features through convolutional filters and pooling layers. In fact, the spatial distribution between objects from different classes has a strong correlation characteristic. For example, buildings tend to be close to roads. In view of the strong appearance extraction ability of DSSN and the powerful topological relationship modeling capability of the graph convolutional neural network (GCN), a DSSN-GCN framework, which combines the advantages of DSSN and GCN, is proposed in this paper for RS image semantic segmentation. To lift the appearance extraction ability, this paper proposes a new DSSN called the attention residual U-shaped network (AttResUNet), which leverages residual blocks to encode feature maps and the attention module to refine the features. As far as GCN, the graph is built, where graph nodes are denoted by the superpixels and the graph weight is calculated by considering the spectral information and spatial information of the nodes. The AttResUNet is trained to extract the high-level features to initialize the graph nodes. Then the GCN combines features and spatial relationships between nodes to conduct classification. It is worth noting that the usage of spatial relationship knowledge boosts the performance and robustness of the classification module. In addition, benefiting from modeling GCN on the superpixel level, the boundaries of objects are restored to a certain extent and there are less pixel-level noises in the final classification result. Extensive experiments on two publicly open datasets show that DSSN-GCN model outperforms the competitive baseline (i.e., the DSSN model) and the DSSN-GCN when adopting AttResUNet achieves the best performance, which demonstrates the advance of our method.",
        "link": "http://dx.doi.org/10.3390/rs13010119"
    },
    {
        "id": 12575,
        "title": "High-Order Models in Semantic Image Segmentation",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/c2015-0-04313-1"
    },
    {
        "id": 12576,
        "title": "A Semantic Segmentation Method using Model Uncertainty",
        "authors": "Shuya Isobe, Shuichi Arai",
        "published": "2017",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.12792/icisip2017.019"
    },
    {
        "id": 12577,
        "title": "Semantic Segmentation using Light Attention Mechanism",
        "authors": "Yuki Hiramatsu, Kazuhiro Hotta",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009347206220625"
    },
    {
        "id": 12578,
        "title": "A Hierarchical Loss for Semantic Segmentation",
        "authors": "Bruce Muller, William Smith",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008946002600267"
    },
    {
        "id": 12579,
        "title": "Field &amp;amp; Road-CENet: Semantic Segmentation for Agricultural Machinery Trajectory Segmentation",
        "authors": "Jiahua Huang, Chuanfeng Wan, Caicong Wu",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nAgricultural machinery management is the key to agricultural production, andtrajectory segmentation lays an important foundation for machinerymanagement. For big data platform of agricultural machinery, it is hoped tosimultaneously improve both of segmentation accuracy and segmentationefficiency to satisfy the processing requirements. However, traditional machinelearning algorithms need to manually adjust parameters and do not integratemultiple features when dealing with trajectory segmentation. This paper aims atthe above problems by modifying the CE-Net model to improve the segmentationaccuracy and ensure the processing efficiency. A creative method for constructingtrajectory image from discrete trajectory data was developed in this paper. Thenew trajectory image showed both the temporal and the spatial characteristics ofthe operation. Then, a semantic segmentation algorithm, Field & Road- CENet,was put forward. The proposed algorithm modified the network CE-Net by addingtwo modules, Standard Convolution Residual Block and Global MaxpoolingAttention Mechanism, to fuse original feature information and enhance thesemantic expression of low-level feature maps. Two cotton sowing datasets werebuilt, including the meter level and the centimeter level. Experiment results showthat Field & Road-CENet performed well on both datasets. In the fieldsegmentation that is the most concerned, the identification accuracy reached97.8% and 95.2%, respectively, and the average accuracy of field and road was94.2% and 88.3%, respectively. In conclusion, this work verifies the feasibility ofusing semantic segmentation to realize trajectory segmentation of agriculturalmachinery. Compared with the current researches, the proposed method isapplicable to trajectory data with two precisions, which has stronger domaingeneralization ability. And it performs quite fast with an average inference time of 0.044 s for each image block, demonstrating that the proposed algorithm issuitable for the big data processing of agricultural machinery.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2571849/v1"
    },
    {
        "id": 12580,
        "title": "Event-Based Semantic-Aided Motion Segmentation",
        "authors": "Chenao Jiang, Julien Moreau, Franck Davoine",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012308100003660"
    },
    {
        "id": 12581,
        "title": "Copyright",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-805320-1.00003-8"
    },
    {
        "id": 12582,
        "title": "Deep Learning-Based Semantic Segmentation in Autonomous Driving",
        "authors": "Hrag-Harout Jebamikyous",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Perception is a fundamental task of autonomous driving systems, which gathers all the necessary information about the surrounding environment of the moving vehicle. Then a decision-making system takes the perception data as input and provides the optimum decision given a scenario, which maximizes the safety of the passengers. In this project, we have developed variants of the U-Net model to perform semantic segmentation on urban scene images to understand the surroundings of an autonomous vehicle. The U-Net model and its variants are adopted for semantic segmentation in this project to account for the power of the U-Net in handling large and small datasets. We have also compared the best-performing variant with other commonly used semantic segmentation models. The comparative analysis was performed using three well-known models, including FCN-16, FCN-8, and SegNet. After conducting sensitivity and comparative analysis, it is concluded that the U-Net variants performed the best in terms of the Intersection over Union (IoU) evaluation metric and other quality metrics.</p>",
        "link": "http://dx.doi.org/10.32920/25266736"
    },
    {
        "id": 12583,
        "title": "Deep Learning-Based Semantic Segmentation in Autonomous Driving",
        "authors": "Hrag-Harout Jebamikyous",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Perception is a fundamental task of autonomous driving systems, which gathers all the necessary information about the surrounding environment of the moving vehicle. Then a decision-making system takes the perception data as input and provides the optimum decision given a scenario, which maximizes the safety of the passengers. In this project, we have developed variants of the U-Net model to perform semantic segmentation on urban scene images to understand the surroundings of an autonomous vehicle. The U-Net model and its variants are adopted for semantic segmentation in this project to account for the power of the U-Net in handling large and small datasets. We have also compared the best-performing variant with other commonly used semantic segmentation models. The comparative analysis was performed using three well-known models, including FCN-16, FCN-8, and SegNet. After conducting sensitivity and comparative analysis, it is concluded that the U-Net variants performed the best in terms of the Intersection over Union (IoU) evaluation metric and other quality metrics.</p>",
        "link": "http://dx.doi.org/10.32920/25266736.v1"
    },
    {
        "id": 12584,
        "title": "Enet Semantic Segmentation Combined with Attention Mechanism",
        "authors": "Wei Bai",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nImage semantic segmentation is one of the core tasks of computer vision. It is widely used in fields such as unmanned driving, medical image processing, geographic information systems and intelligent robots. Aiming at the problem that the existing semantic segmentation algorithm ignores the different channel and location features of the feature map and the simple method when the feature map is fused, this paper designs a semantic segmentation algorithm that combines the attention mechanism. Firstly, dilated convolution is used, and a smaller downsampling factor is used to maintain the resolution of the image and obtain the detailed information of the image. Secondly, the attention mechanism module is introduced to assign weights to different parts of the feature map, which reduces the accuracy loss. The design feature fusion module assigns weights to the feature maps of different receptive fields obtained by the two paths, and merges them together to obtain the final segmentation result. Finally, through experiments, it was verified on the Camvid, Cityscapes and PASCAL VOC2012 datasets. Mean intersection over union (MIoU) and mean pixel accuracy (MPA) are used as metrics. The method in this paper can make up for the loss of accuracy caused by downsampling while ensuring the receptive field and improving the resolution, which can better guide the model learning. And the proposed feature fusion module can better integrate the features of different receptive fields. Therefore, the proposed method can significantly improve the segmentation performance compared to the traditional method.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-425438/v1"
    },
    {
        "id": 12585,
        "title": "OFFSED: Off-Road Semantic Segmentation Dataset",
        "authors": "Peter Neigel, Jason Rambach, Didier Stricker",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010349805520557"
    },
    {
        "id": 12586,
        "title": "Semantic Segmentation of PHT based on Improved DeeplabV3+",
        "authors": "Haiquan Fang",
        "published": "No Date",
        "citations": 0,
        "abstract": "This work aimed to address the two shortcomings of printed and\nhandwritten texts (PHT) classification. The classification accuracy of\nFCN and U-net, which are used for PHT pixel-level classification, still\nhas room to improve. PHT public datasets have small sample sizes, and\nthe generalization ability of the models are not good. In this paper,\nfirst, a pixel-level sample making method for PHT identification was\nproposed, and a PHT dataset 2021 (PHTD 2021), containing 3,000 samples,\nwas constructed. Second, because there is a large number of words but\nthe contours are small in documents, the DeeplabV3+ model was improved.\nThe network layer number and pooling times were reduced, and the\nconvolution kernel and dilated rate were increased. In the experiment,\nthe improved DeeplabV3+ model had a classification accuracy of 95.06%\non the test samples from PHTD 2021 data set. The improved DeeplabV3+\nmodel has a higher recognition accuracy than the FCN and DeeplabV3+\nmodels. Finally, after the classification of PHT, applications of\nhandwritten texts removal and handwritten texts extraction are provided.",
        "link": "http://dx.doi.org/10.22541/au.170670778.85262664/v1"
    },
    {
        "id": 12587,
        "title": "Feature Sharing Cooperative Network for Semantic Segmentation",
        "authors": "Ryota Ikedo, Kazuhiro Hotta",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010312505770584"
    },
    {
        "id": 12588,
        "title": "Beyond Semantic to Instance Segmentation: Weakly-Supervised Instance Segmentation via Semantic Knowledge Transfer and Self-Refinement",
        "authors": "Beomyoung Kim, Youngjoon Yoo, Chae Eun Rhee, Junmo Kim",
        "published": "2022-6",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr52688.2022.00424"
    },
    {
        "id": 12589,
        "title": "Semantic Segmentation via Global Convolutional Network and Concatenated Feature Maps",
        "authors": "Chuan Wang, Long Chang",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007251002920297"
    },
    {
        "id": 12590,
        "title": "GCCNet: Global Context Constraint Network for Semantic Segmentation",
        "authors": "Hyunwoo Kim, Huaiyu Li, Seok-Cheol Kee",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007705700002179"
    },
    {
        "id": 12591,
        "title": "GCCNet: Global Context Constraint Network for Semantic Segmentation",
        "authors": "Hyunwoo Kim, Huaiyu Li, Seok-Cheol Kee",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007705703800387"
    },
    {
        "id": 12592,
        "title": "Index",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-805320-1.00016-6"
    },
    {
        "id": 12593,
        "title": "Adding New Classes in Semantic Segmentation",
        "authors": "Kazuya Ueki",
        "published": "2019-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/nicoint.2019.00029"
    },
    {
        "id": 12594,
        "title": "Contents",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-805320-1.00004-x"
    },
    {
        "id": 12595,
        "title": "Semantic Segmentation For Pet Detection Using Convolutional Neural Network",
        "authors": "Chibuzo Nwadike",
        "published": "2023-11-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.54985/peeref.2311p9011908"
    },
    {
        "id": 12596,
        "title": "Semantic Segmentation for Pet Detection Using Convolutional Neural Network",
        "authors": "Chibuzo Valentine Nwadike",
        "published": "No Date",
        "citations": 0,
        "abstract": "This research project encompasses an in-depth exploration of semantic segmentation methods for pet detection using the Oxford Pets Dataset. The primary objective involves the developmentof a convolutional neural network model rooted in deep-learning principles, designed to achieve precise segmentation and detection of pets within images. The approach integrates advanced image processing techniques, leveraging deep learning methodologies, and dataset augmentation strategies to enhance pet detection accuracy substantially. The outcomes underscore the considerable potential of semantic segmentation in elevating the effectiveness of pet detection applications. This study offers promising avenues for practical integration in real-world contexts such as pet care and surveillance systems. The achieved advancements underscore the proposed technique's viability and contribute to the broader discourse on enhancing object detection through sophisticated segmentation strategies.",
        "link": "http://dx.doi.org/10.14293/p2199-8442.1.sop-.pjpzw3.v2"
    },
    {
        "id": 12597,
        "title": "Predicting Visual Importance of Mobile UI Using Semantic Segmentation",
        "authors": "Ami Yamamoto, Yuichi Sei, Yasuyuki Tahara, Akihiko Ohsuga",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011655800003393"
    },
    {
        "id": 12598,
        "title": "Colour Augmentation for Improved Semi-supervised Semantic Segmentation",
        "authors": "Geoff French, Michal Mackiewicz",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010807400003124"
    },
    {
        "id": 12599,
        "title": "Multimodal Semantic Segmentation in Autonomous Driving: A Review of Current Approaches and Future Perspectives",
        "authors": "Giulia Rizzoli, Francesco Barbato, Pietro Zanuttigh",
        "published": "2022-7-25",
        "citations": 13,
        "abstract": "The perception of the surrounding environment is a key requirement for autonomous driving systems, yet the computation of an accurate semantic representation of the scene starting from RGB information alone is very challenging. In particular, the lack of geometric information and the strong dependence on weather and illumination conditions introduce critical challenges for approaches tackling this task. For this reason, most autonomous cars exploit a variety of sensors, including color, depth or thermal cameras, LiDARs, and RADARs. How to efficiently combine all these sources of information to compute an accurate semantic description of the scene is still an unsolved task, leading to an active research field. In this survey, we start by presenting the most commonly employed acquisition setups and datasets. Then we review several different deep learning architectures for multimodal semantic segmentation. We will discuss the various techniques to combine color, depth, LiDAR, and other modalities of data at different stages of the learning architectures, and we will show how smart fusion strategies allow us to improve performances with respect to the exploitation of a single source of information.",
        "link": "http://dx.doi.org/10.3390/technologies10040090"
    },
    {
        "id": 12600,
        "title": "Background Image Editing with HyperStyle and Semantic Segmentation",
        "authors": "Syuusuke Ishihata, Ryohei Orihara, Yuichi Sei, Yasuyuki Tahara, Akihiko Ohsuga",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011661500003393"
    },
    {
        "id": 12601,
        "title": "Diagnosis of Brain Tumor using Semantic Segmentation and Advance-CNN Classification",
        "authors": "Afreen Habiba A.",
        "published": "2020-3-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.37200/ijpr/v24i5/pr201795"
    },
    {
        "id": 12602,
        "title": "Edge-Aware Network for Kidneys and Kidney Tumor Semantic Segmentation",
        "authors": "Andriy Myronenko, Ali Hatamizadeh",
        "published": "2019",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.24926/548719.009"
    },
    {
        "id": 12603,
        "title": "Experimental Application of Semantic Segmentation Models Fine-Tuned with Synthesized Document Images to Text Line Segmentation in a Handwritten Japanese Historical Document",
        "authors": "Sayaka Mori, Tetsuya Suzuki",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012433100003654"
    },
    {
        "id": 12604,
        "title": "Unsupervised Domain Extension for Nighttime Semantic Segmentation in Urban Scenes",
        "authors": "Sebastian Scherer, Robin Schön, Katja Ludwig, Rainer Lienhart",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010551500002996"
    },
    {
        "id": 12605,
        "title": "How deep learning is empowering semantic segmentation",
        "authors": "Uroosa Sehar, Muhammad Luqman Naseem",
        "published": "2022-9",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11042-022-12821-3"
    },
    {
        "id": 12606,
        "title": "Two-step Transfer Learning for Semantic Plant Segmentation",
        "authors": "Shunsuke Sakurai, Hideaki Uchiyama, Atsushi Shimada, Daisaku Arita, Rin-ichiro Taniguchi",
        "published": "2018",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006576303320339"
    },
    {
        "id": 12607,
        "title": "Front Matter",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-805320-1.00002-6"
    },
    {
        "id": 12608,
        "title": "Semantic segmentation algorithm based on transformer In Mobile Edge Computing",
        "authors": "XiBei Jia",
        "published": "No Date",
        "citations": 0,
        "abstract": "The semantic segmentation task is a basic task in the field of Mobile\nEdge Computing, which requires the classification of each pixel in the\nimage, which has higher requirements for classification accuracy than\nthe image classification task. Fine-grained classification tasks\nrequires more detailed information, in addition to classifying according\nto the semantic information and spatial information of each pixel unit\nand the surrounding pixels, it is also necessary to distinguish from\nadjacent pixels, which is one of the main difficulties of the current\nsegmentation task. However, high-resolution input images can bring more\ndetailed information, but they are often accompanied by expensive\ncomputing costs, so smaller resolution images will be put in practical\napplications to ensure computing speed. As another task of computer\nvision, super-resolution recovery focuses on extracting information from\nlow-resolution pictures and reasoning into higher-resolution feature\nmaps. Its recovered detail features contribute to the high-precision\nclassification of semantic segmentation tasks. Considering the\ncomplementarity of the two tasks, considering the use of transformer as\na feature extractor, the design algorithm realizes semantic segmentation\nand super-resolution recovery tasks at the same time, multi-task\nlearning can ensure that the backbone network obtains more common\nhigh-dimensional information, and then we use the results of\nsuper-resolution recovery branches to guide the semantic segmentation\ntask to provide more detailed information and finally obtain an\neffective improvement on the original baseline.",
        "link": "http://dx.doi.org/10.22541/au.167845518.89258745/v1"
    },
    {
        "id": 12609,
        "title": "Maxsignet: Light Learnable Layer for Semantic Cell Segmentation",
        "authors": "Reza Yazdi, Hassan Khotanlou",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4555986"
    },
    {
        "id": 12610,
        "title": "CAFseg: A Semantic segmentation network with cross aggregation fusion strategy for RGB-thermal semantic segmentation",
        "authors": "Shi Yi, Lang Wu, Xi Liu, Junjie Li, Gang Jiang",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.infrared.2023.105077"
    },
    {
        "id": 12611,
        "title": "General introduction",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-805320-1.00005-1"
    },
    {
        "id": 12612,
        "title": "Uncertainty-Based Detection of Adversarial Attacks in Semantic Segmentation",
        "authors": "Kira Maag, Asja Fischer",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012303500003660"
    },
    {
        "id": 12613,
        "title": "Improving Semantic Segmentation Performance in Underwater Images",
        "authors": "Alexandra Pereira Nunes, Aníbal Matos",
        "published": "No Date",
        "citations": 0,
        "abstract": "Nowadays, semantic segmentation is increasingly used in exploration by underwater robots, for example in autonomous navigation, so that the robot can recognise the nature and elements of its environment during the mission and act according to this classification to avoid collisions. Other applications can be found in the search for archaeological artefacts, in the inspection of underwater structures or in species monitoring. Therefore, it is necessary to try to improve the performance in these tasks as much as possible. To this end, we compare some methods for improving image quality and for data augmentation and test whether higher performance metrics can be achieved with both strategies. The experiments are performed with the SegNet implementations and the SUIM dataset with 8 common underwater classes to compare the obtained results with the already known ones. The results obtained with both strategies show that they are beneficial and lead to better performance results by achieving a mean IoU of 56% and an increased overall accuracy of 81.8%. The single result shows that there are 5 classes with an IoU value above 60% and only one class with an IoU value below 30%, which is a more reliable result and easier to use in real contexts.",
        "link": "http://dx.doi.org/10.20944/preprints202310.1767.v1"
    },
    {
        "id": 12614,
        "title": "Semantic Segmentation of Urban Street Scenes Using Deep Learning",
        "authors": "Amani Y. Noori, Dr. Shaimaa H. Shaker, Dr. Raghad Abdulaali Azeez",
        "published": "2022-1-20",
        "citations": 0,
        "abstract": "Scene classification is essential conception task used by robotics for understanding the environmental. The outdoor scene like urban street scene is composing of image with depth having greater variety than iconic object image. The semantic segmentation is an important task for autonomous driving and mobile robotics applications because it introduces enormous information need for safe navigation and complex reasoning. This paper introduces a model for classification all pixel’s image and predicates the right object that contains this pixel. This model adapts famous network image classification VGG16 with fully convolution network (FCN-8) and transfer learned representation by fine tuning for doing segmentation. Skip Architecture is added between layers to combine coarse, semantic, and local appearance information to generate accurate segmentation. This model is robust and efficiency because it efficient consumes low memory and faster inference time for testing and training on Camvid dataset. The output module is designed by using a special computer equipped by GPU memory NVIDIA GeForce RTX 2060 6G, and programmed by using python 3.7 programming language. The proposed system reached an accuracy 0.8804 and MIOU 73% on Camvid dataset.",
        "link": "http://dx.doi.org/10.14704/web/v19i1/web19156"
    },
    {
        "id": 12615,
        "title": "IFC-Based Semantic Segmentation and Semantic Enrichment of BIM for Bridges",
        "authors": "Hang Li, Fan Yang, Jiansong Zhang",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1061/9780784485262.061"
    },
    {
        "id": 12616,
        "title": "Unsupervised Domain Extension for Nighttime Semantic Segmentation in Urban Scenes",
        "authors": "Sebastian Scherer, Robin Schön, Katja Ludwig, Rainer Lienhart",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010551500380047"
    },
    {
        "id": 12617,
        "title": "Real-Time Semantic Segmentation Via Mutual Optimization of Spatial Details and Semantic Information",
        "authors": "Mengyuan Ma, Huiling Huang, Yi Yang, Yanbing Feng, Jun Han",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4528608"
    },
    {
        "id": 12618,
        "title": "Semantic Image Segmentation Using Transformers",
        "authors": "SAI KRISHNA DOPPALAPUDI, SUPREETHI K. P",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nSince the development of deep learning, FCNNs—particularly \"U-shaped\" encoder-decoder architectures—have excelled at various medical semantic segmentation tasks.\nFor the bulk of medical picture segmentation applications during the past ten years, Fully Convolutional Neural Networks (FCNNs) with contracting and expanding paths have gained importance. In FCNNs, the encoder plays a crucial role in learning both global and local features as well as contextual representations that the decoder can use to expect semantic output. Despite its success, FCNNs' ability to learn long-range spatial relationships is constrained by the locality of their convolutional layers. Motivated by the recent popularity of Transformers. We reframe the challenge of volumetric (3D) medical picture segmentation as a sequence-to-sequence prediction issue, drawing inspiration from the recent success of transformers for Natural Language Processing (NLP) in long-range sequence learning.\nDue to their ability to simulate long-range dependencies, transformers have proved to perform various natural language processing and computer vision tasks. Recent developments have shown how promising combining such transformers with CNN-based semantic picture segmentation algorithms is. The effectiveness of a pure transformer-based technique for picture segmentation has not yet been thoroughly investigated.\nEncoder-decoder-based Fully Converter Networks, a novel framework for semantic picture segmentation, will be investigated in this paper (FTN) We offer a novel architecture that successfully captures the global multi-scale information and learns sequence representations of the input volume using a transformer as the encoder, while also employing the well-proven \"U-shaped\" network design for the encoder and decoder. To figure out the final semantic segmentation output, the transformer encoder is directly coupled by skip connections to a decoder at various resolutions.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3699531/v1"
    },
    {
        "id": 12619,
        "title": "Cascaded Semantic Segmentation for Kidney and Tumor",
        "authors": "Xiaoshuai Hou, Chunmei Xie, Fengyi Li, Yang Nan",
        "published": "2019",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.24926/548719.002"
    },
    {
        "id": 12620,
        "title": "Pixel Level Instance Segmentation using Single Shot Detectors and Semantic Segmentation Networks",
        "authors": "Akash C, Laseena C A",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3441530"
    },
    {
        "id": 12621,
        "title": "Semantic Segmentation of Kidney Tumor using Convolutional Neural Networks",
        "authors": "Laura Daza, Catalina Gómez, Pablo Arbeláez",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.24926/548719.077"
    },
    {
        "id": 12622,
        "title": "Domain Adaptation in LiDAR Semantic Segmentation by Aligning Class Distributions",
        "authors": "Iñigo Alonso, Luis Riazuelo, Luis Montesano, Ana Murillo",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010610703300337"
    },
    {
        "id": 12623,
        "title": "SemSegDepth: A Combined Model for Semantic Segmentation and Depth Completion",
        "authors": "Juan Lagos, Esa Rahtu",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010838500003124"
    },
    {
        "id": 12624,
        "title": "Improve Semantic Segmentation of Remote sensing Images with K-Mean Pixel Clustering: A semantic segmentation post-processing method based on k-means clustering",
        "authors": "Xiaohui Zeng, Isabelle Chen, Pai Liu",
        "published": "2021-8-20",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/csaiee54046.2021.9543336"
    },
    {
        "id": 12625,
        "title": "Alignment and Fusion for Adaptive Domain Nighttime Semantic Segmentation",
        "authors": "Bao Zhang, Nianmin Yao",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4646555"
    },
    {
        "id": 12626,
        "title": "Edge-preserving Domain Adaptation for semantic segmentation of Medical Images",
        "authors": "Naimul Khan, Thong Vo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Domain Adaptation is a technique to address the lack of massive amounts of labeled data in unseen environments. Unsupervised domain adaptation is proposed to adapt a model to new modalities using solely labeled source data and unlabeled target domain data. Though many image-spaces domain adaptation methods have been proposed to capture pixel-level domain-shift, such techniques may fail to maintain high-level semantic information for the segmentation task. For the case of biomedical images, fine details such as blood vessels can be lost during the image transformation operations between domains. In this work, we propose a model that adapts between domains using cycle-consistent loss while maintaining edge details of the original images by enforcing an edge-based loss during the adaptation process. We demonstrate the effectiveness of our algorithm by comparing it to other approaches on two eye fundus vessels segmentation datasets. We achieve 1.1 to 9.2 increment in DICE score compared to the SOTA and ~5.2 increments compared to a vanilla CycleGAN implementation.</p>",
        "link": "http://dx.doi.org/10.32920/22734362.v1"
    },
    {
        "id": 12627,
        "title": "An improved semantic segmentation and fusion method for semantic SLAM",
        "authors": "Zijian Jia, Hairong Yan",
        "published": "2021-6-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icaica52286.2021.9497930"
    },
    {
        "id": 12628,
        "title": "Protrusion-oriented Point Cloud Semantic Segmentation",
        "authors": "Alexander Agathos, Philip Azariadis",
        "published": "2023-5-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14733/cadconfp.2023.95-100"
    },
    {
        "id": 12629,
        "title": "Domain Adaptation in LiDAR Semantic Segmentation by Aligning Class Distributions",
        "authors": "Iñigo Alonso, Luis Riazuelo, Luis Montesano, Ana Murillo",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010610700002994"
    },
    {
        "id": 12630,
        "title": "Project 1.A83\nRapid High-dimensional Semantic Segmentation With Echo State Networks",
        "authors": "Steven Gardner",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26226/morressier.608c2248dc2fa1af562471d6"
    },
    {
        "id": 12631,
        "title": "Histopathology: Deep machine learning based semantic segmentation features predict patient survival",
        "authors": "Vikas Ramachandra",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractIn this paper, we use deep learning techniques to segment different regions from breast cancer histopathology images, such as tumor nucleus, epithelium and stromal areas. Then, in the second stage, the deep segmentation features learned by the neural network are used to predict individual patient survival, using random forest based classification. We show that the deep segmentation network features can predict survival very well, and outperform classical computer vision based shape, texture and other feature descriptors used in earlier research for the same survival prediction task.",
        "link": "http://dx.doi.org/10.1101/2023.01.14.23284554"
    },
    {
        "id": 12632,
        "title": "Semantic Segmentation And Segmentation Refinement Using Machine Learning Case Study: Water Turbidity Segmentation",
        "authors": "Daniel Sande Bona, Aniati Murni, Petrus Mursanto",
        "published": "2019-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icares.2019.8914551"
    },
    {
        "id": 12633,
        "title": "Semantic Segmentation Framework for Atoll Satellite Imagery: An In-Depth Exploration Using Unet Variants and Segmentation Gym",
        "authors": "Ray Wang, Tahiya Chowdhury, Alejandra  C. Ortiz",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4757161"
    },
    {
        "id": 12634,
        "title": "BiSeg: Simultaneous Instance Segmentation and Semantic Segmentation with Fully Convolutional Networks",
        "authors": "Viet Pham, Satoshi Ito, Tatsuo Kozakaya",
        "published": "2017",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5244/c.31.60"
    },
    {
        "id": 12635,
        "title": "Semantic Segmentation in Red Relief Image Map by UX-Net",
        "authors": "Tomoya Komiyama, Kazuhiro Hotta, Kazuo Oda, Satomi Kakuta, Mikako Sano",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006716805970602"
    },
    {
        "id": 12636,
        "title": "Multi-class Semantic Segmentation of Skin Lesions via Fully Convolutional Networks",
        "authors": "Manu Goyal, Moi Yap, Saeed Hassanpour",
        "published": "2020",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009380302900295"
    },
    {
        "id": 12637,
        "title": "Edge-preserving Domain Adaptation for semantic segmentation of Medical Images",
        "authors": "Naimul Khan, Thong Vo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Domain Adaptation is a technique to address the lack of massive amounts of labeled data in unseen environments. Unsupervised domain adaptation is proposed to adapt a model to new modalities using solely labeled source data and unlabeled target domain data. Though many image-spaces domain adaptation methods have been proposed to capture pixel-level domain-shift, such techniques may fail to maintain high-level semantic information for the segmentation task. For the case of biomedical images, fine details such as blood vessels can be lost during the image transformation operations between domains. In this work, we propose a model that adapts between domains using cycle-consistent loss while maintaining edge details of the original images by enforcing an edge-based loss during the adaptation process. We demonstrate the effectiveness of our algorithm by comparing it to other approaches on two eye fundus vessels segmentation datasets. We achieve 1.1 to 9.2 increment in DICE score compared to the SOTA and ~5.2 increments compared to a vanilla CycleGAN implementation.</p>",
        "link": "http://dx.doi.org/10.32920/22734362"
    },
    {
        "id": 12638,
        "title": "Towards Bridging Semantic Gap to Improve Semantic Segmentation",
        "authors": "Yanwei Pang, Yazhao Li, Jianbing Shen, Ling Shao",
        "published": "2019-10",
        "citations": 69,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv.2019.00433"
    },
    {
        "id": 12639,
        "title": "Combining Semantic Self-Supervision and Self-Training for Domain Adaptation in Semantic Segmentation",
        "authors": "Joshua Niemeijer, Jorg P. Schafer",
        "published": "2021-7-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ivworkshops54471.2021.9669255"
    },
    {
        "id": 12640,
        "title": "Semantic Segmentation by Semi-Supervised Learning Using Time Series Constraint",
        "authors": "Takahiro Mano, Sota Kato, Kazuhiro Hotta",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011721800003417"
    },
    {
        "id": 12641,
        "title": "Hybrid Feature based Pyramid Network for Nighttime Semantic Segmentation",
        "authors": "Yuqi Li, Yinan Ma, Jing Wu, Chengnian Long",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010248503210328"
    },
    {
        "id": 12642,
        "title": "Fusion of Different Features by Cross Cooperative Learning for Semantic Segmentation",
        "authors": "Ryota Ikedo, Kazuhiro Hotta",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010889800003124"
    },
    {
        "id": 12643,
        "title": "Multi-stream CNN based Video Semantic Segmentation for Automated Driving",
        "authors": "Ganesh Sistu, Sumanth Chennupati, Senthil Yogamani",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007248400002108"
    },
    {
        "id": 12644,
        "title": "AuxNet: Auxiliary Tasks Enhanced Semantic Segmentation for Automated Driving",
        "authors": "Sumanth Chennupati, Ganesh Sistu, Senthil Yogamani, Samir Rawashdeh",
        "published": "2019",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007684106450652"
    },
    {
        "id": 12645,
        "title": "Fast Context Awareness Encoder for LiDAR Point Semantic Segmentation",
        "authors": "Tingyu Du, Dongxing Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nLiDAR sensor is a valuable tool for environmental perception as it can generate 3D point cloud data with reflectivity and position information by reflecting laser beams. However, it cannot provide the meaning of each point cloud cluster, which has led to many studies focusing on identifying semantic information about point clouds. This paper explores point cloud segmentation and presents a network that encodes point cloud data at different levels to obtain semantic information about the point cloud cluster. The local context awareness network uses the points and their surrounding points to contribute local features, which are then combined with global features to obtain a better understanding of the position, density, and other information of the point cloud. The feature extraction network provides highly abstracted information, allowing for more accurate semantic segmentation of the discrete points in space. The proposed algorithm is compared and verified against other Semantic KITTI data algorithms, and has achieved state-of-the-art performance. Due to its ability to note fine-grained features on the z-axis in space, the algorithm shows higher prediction accuracy for certain types of objects. Moreover, the training and validation time is short, and the algorithm can meet high real-time requirements for 3D perception tasks.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2935023/v1"
    },
    {
        "id": 12646,
        "title": "ContourNet:Research on Contour Based Nighttime Semantic Segmentation",
        "authors": "Yang Yang, Changjiang Liu, Hao Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nDue to the scarcity of nighttime semantic segmentation datasets and the high demand for network models, the development of semantic segmentation of nighttime scenes is still very slow. This paper proposes a new network model, ContourNet, which can model images in multiple stages, including local features with rich superficial appearance information, global features with rich deep semantic information, and intermediate layer features. At the same time, this paper uses multi head decoders to fuse different levels of features. In this paper, a separate contour network module for processing object contours is designed for night images with imperceptible texture and color information. This network module is parallel to the semantic network module to achieve accurate prediction of object contours. The performance is prominent, especially for objects that are far away, small objects, or objects with high contour continuity. A large number of experiments demonstrates that the ContourNet proposed in this paper can significantly improve the semantic segmentation ability of existing models for nighttime images, and can also improve the semantic segmentation accuracy of daytime images to a certain extent, with good generalization ability. Specifically, after adding the contour module in this article, MIoU has increased by 5.1% on the night dataset Rebecca; MIoU has increased by 2.5% on the daytime dataset CamVid.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2819907/v1"
    },
    {
        "id": 12647,
        "title": "Semantic segmentation based on semantic edge optimization",
        "authors": "Hao Hu, Hua Cai, Zhiyong Ma, Weigang Wang",
        "published": "2021-9-23",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/eiecs53707.2021.9587939"
    },
    {
        "id": 12648,
        "title": "3D Indoor Scene Semantic Segmentation using 2D Semantic Segmentation Projection",
        "authors": "Sang-Sik Yeom, Jong-Eun Ha",
        "published": "2020-11-30",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5302/j.icros.2020.20.0120"
    },
    {
        "id": 12649,
        "title": "Weakly Supervised Semantic Segmentation Based on Co-segmentation",
        "authors": "Tong Shen, Guosheng Lin, Lingqiao Liu, Chunhua Shen, Ian Reid",
        "published": "2017",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5244/c.31.17"
    },
    {
        "id": 12650,
        "title": "U-Net based Semantic Segmentation of Kidney and Kidney Tumours of CT Images",
        "authors": "Benjamin Bracke, Klaus Brinker",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010770900003123"
    },
    {
        "id": 12651,
        "title": "Temperature as a Regularizer for Semantic Segmentation",
        "authors": "Chanho Kim, Won-Sook Lee",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14428/esann/2021.es2021-158"
    },
    {
        "id": 12652,
        "title": "Dynamic deformable attention (DDANet) for semantic segmentation",
        "authors": "Kumar Rajamani, Hanna Siebert, Mattias P Heinrich",
        "published": "No Date",
        "citations": 1,
        "abstract": "Deep learning based medical image segmentation is an important step within diagnosis, which relies strongly on capturing sufficient spatial context without requiring too complex models that are hard to train with limited labelled data. Training data is in particular scarce for segmenting infection regions of CT images of COVID-19 patients.  Attention models help gather contextual information within deep networks and benefit semantic segmentation tasks. The recent criss-cross-attention module aims to approximate global self-attention while remaining memory and time efficient by separating horizontal and vertical self-similarity computations. However, capturing attention from all non-local locations can adversely impact the accuracy of semantic segmentation networks. We propose a new Dynamic Deformable Attention Network (DDANet) that enables a more accurate contextual information computation in a similarly efficient way. Our novel technique is based on a deformable criss-cross attention block that learns both attention coefficients and attention offsets in a continuous way. A deep segmentation network (in our case a U-Net \\cite{Jo2019}) that employs this attention mechanism is able to capture attention from pertinent non-local locations and also improves the performance on semantic segmentation tasks compared to criss-cross attention within a U-Net on a challenging COVID-19 lesion segmentation task. Our validation experiments show that the performance gain of the recursively applied dynamic deformable attention blocks comes from their ability to capture dynamic and precise (wider) attention context. Our DDANet achieves Dice scores of 73.4\\% and 61.3\\% for Ground-Glass-Opacity and Consolidation lesions for COVID-19 segmentation and improves the accuracy by 4.9\\% points compared to a baseline U-Net.",
        "link": "http://dx.doi.org/10.31224/osf.io/wcm24"
    },
    {
        "id": 12653,
        "title": "Semantic segmentation using high order information",
        "authors": "Parvin Razzaghi",
        "published": "2017-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iraniancee.2017.7985289"
    },
    {
        "id": 12654,
        "title": "Adapting Projection-Based Lidar Semantic Segmentation to Naturaldomains",
        "authors": "Kelian  Jean Lucien Massa, Hans Grobler",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4548898"
    },
    {
        "id": 12655,
        "title": "Semantic Segmentation of Multispectral Images using Res-Seg-net Model",
        "authors": "Nidhi Saxena, Kishore Babu N., Balasubramanian Raman",
        "published": "2020-2",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icsc.2020.00030"
    },
    {
        "id": 12656,
        "title": "Deep Semantic Segmentation Models in Computer Vision",
        "authors": "Paolo Andreini, Giovanna Maria Dimitri",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14428/esann/2022.es2022-5"
    },
    {
        "id": 12657,
        "title": "Multi-stream CNN based Video Semantic Segmentation for Automated Driving",
        "authors": "Ganesh Sistu, Sumanth Chennupati, Senthil Yogamani",
        "published": "2019",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007248401730180"
    },
    {
        "id": 12658,
        "title": "ATTransUNet: Semantic Segmentation Model for Building Segmentation from Aerial Image and Laser Data",
        "authors": "YUNUS SERHAT BICAKCI, Beytullah Sarica",
        "published": "2023-3-27",
        "citations": 0,
        "abstract": "The segmentation of buildings using aerial images and laser data (LIDAR) is a key area of study in computer vision and artificial intelligence. In this paper, we proposed a new deep learning-based framework architecture based on U-Net for the MapAI competition, which required participants to perform two tasks for segmenting buildings. On segmentation task 1, our model achieved an Intersection-over-Union (IoU) score of 0.7551 and a Boundary Intersection-over-Union (BIoU) score of 0.5613. On segmentation task 2, our model achieved an IoU score of 0.8555 and a BIoU score of 0.7127. These results demonstrate that our proposed method achieves competitive IoU and BIoU accuracies in building segmentation.",
        "link": "http://dx.doi.org/10.5617/nmi.10039"
    },
    {
        "id": 12659,
        "title": "Deep Guidance Decoder with Semantic Boundary Learning for Boundary-Aware Semantic Segmentation",
        "authors": "Qingfeng Liu, Hai Su, Mostafa El-Khamy",
        "published": "2022-1-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icce53296.2022.9730360"
    },
    {
        "id": 12660,
        "title": "Prior Semantic Harmonization Network for Few-Shot Semantic Segmentation",
        "authors": "Xinhao Yang, Liyan Ma, Yang Zhou, Yan Peng, Shaorong Xie",
        "published": "2022-10-16",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icip46576.2022.9897329"
    },
    {
        "id": 12661,
        "title": "Semantic recognition",
        "authors": "Lotfi Abdi, Aref Meddeb",
        "published": "2017-4-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3019612.3019636"
    },
    {
        "id": 12662,
        "title": "AuxNet: Auxiliary Tasks Enhanced Semantic Segmentation for Automated Driving",
        "authors": "Sumanth Chennupati, Ganesh Sistu, Senthil Yogamani, Samir Rawashdeh",
        "published": "2019",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007684100002108"
    },
    {
        "id": 12663,
        "title": "Weakly-Supervised Incremental Learning for Semantic Segmentation with Class Hierarchy",
        "authors": "Hyoseo Kim, Junsuk Choe",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4536538"
    },
    {
        "id": 12664,
        "title": "Convolutional Neural Networks Rarely Learn Shape for Semantic Segmentation",
        "authors": "Yixin Zhang, Maciej  A. Mazurowski",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4466923"
    },
    {
        "id": 12665,
        "title": "Lightweight Semantic Segmentation Network for Semantic Scene Understanding on Low-Compute Devices",
        "authors": "Hojun Son, James Weiland",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iros55552.2023.10342110"
    },
    {
        "id": 12666,
        "title": "Decoupled Iterative Deep Sensor Fusion for 3D Semantic Segmentation",
        "authors": "Fabian Duerr, Hendrik Weigel, Jürgen Beyerer",
        "published": "2021-9",
        "citations": 2,
        "abstract": " One of the key tasks for autonomous vehicles or robots is a robust perception of their 3D environment, which is why autonomous vehicles or robots are equipped with a wide range of different sensors. Building upon a robust sensor setup, understanding and interpreting their 3D environment is the next important step. Semantic segmentation of 3D sensor data, e.g. point clouds, provides valuable information for this task and is often seen as key enabler for 3D scene understanding. This work presents an iterative deep fusion architecture for semantic segmentation of 3D point clouds, which builds upon a range image representation of the point clouds and additionally exploits camera features to increase accuracy and robustness. In contrast to other approaches, which fuse lidar and camera features once, the proposed fusion strategy iteratively combines and refines lidar and camera features at different scales inside the network architecture. Additionally, the proposed approach can deal with camera failure as well as jointly predict lidar and camera segmentation. We demonstrate the benefits of the presented iterative deep fusion approach on two challenging datasets, outperforming all range image-based lidar and fusion approaches. An in-depth evaluation underlines the effectiveness of the proposed fusion strategy and the potential of camera features for 3D semantic segmentation. ",
        "link": "http://dx.doi.org/10.1142/s1793351x21400067"
    },
    {
        "id": 12667,
        "title": "Air-Tissue Boundary Segmentation in Real-Time Magnetic Resonance Imaging Video Using Semantic Segmentation with Fully Convolutional Networks",
        "authors": "Valliappan CA, Renuka Mannem, Prasanta Kumar Ghosh",
        "published": "2018-9-2",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2018-1939"
    },
    {
        "id": 12668,
        "title": "Transforming Semantic Segmentation into Instance Segmentation with a Guided U-Net",
        "authors": "Roman Lavrynenko, Nataliya Ryabova",
        "published": "2023-10-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/csit61576.2023.10324276"
    },
    {
        "id": 12669,
        "title": "Semantic Instance Meets Salient Object: Study on Video Semantic Salient Instance Segmentation",
        "authors": "Trung-Nghia Le, Akihiro Sugimoto",
        "published": "2019-1",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/wacv.2019.00194"
    },
    {
        "id": 12670,
        "title": "Semantic Grid Estimation with Occupancy Grids and Semantic Segmentation Networks",
        "authors": "Ozgur Erkent, Christian Wolf, Christian Laugier",
        "published": "2018-11",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icarcv.2018.8581180"
    }
]