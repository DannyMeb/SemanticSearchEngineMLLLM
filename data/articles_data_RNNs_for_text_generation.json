[
    {
        "id": 20571,
        "title": "Text Summarization in Assamese Language using Sequence to Sequence RNNs",
        "authors": "Pritom Jyoti Goutom,  , Nomi Baruah",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.17485/ijst/v16isp2.5429"
    },
    {
        "id": 20572,
        "title": "Unleashing the Melodic Potential: Music Generation with Char RNNs",
        "authors": "Devang Gangal, Yash Kadam",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/incoft60753.2023.10425396"
    },
    {
        "id": 20573,
        "title": "Sentiment classification on Tamil and Telugu text using RNNs and Transformers",
        "authors": "D. Sumathi, B. Gowtham, K. Naveen, H. Subramani",
        "published": "2021-11-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ictai53825.2021.9673365"
    },
    {
        "id": 20574,
        "title": "Word-Level Uncertainty Estimation for Black-Box Text Classifiers using RNNs",
        "authors": "Jakob Smedegaard Andersen, Tom Schöner, Walid Maalej",
        "published": "2020",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.coling-main.484"
    },
    {
        "id": 20575,
        "title": "Can Ready-to-Use RNNs Generate “Good” Text Training Data?",
        "authors": "Jia Hui Feng",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14569/ijacsa.2022.0130306"
    },
    {
        "id": 20576,
        "title": "Music Generation using Time Distributed Dense Stateful Char-RNNs",
        "authors": "Shobhan Banerjee, Manas Rath, Tanmaya Swain, Tapaswini Samant",
        "published": "2022-4-7",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/i2ct54291.2022.9824167"
    },
    {
        "id": 20577,
        "title": "What is the Role of Recurrent Neural Networks (RNNs) in an Image\n            Caption Generator?",
        "authors": "Marc Tanti, Albert Gatt, Kenneth Camilleri",
        "published": "2017",
        "citations": 38,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w17-3506"
    },
    {
        "id": 20578,
        "title": "Bengali abstractive text summarization using sequence to sequence RNNs",
        "authors": "Md Ashraful Islam Talukder, Sheikh Abujar, Abu Kaisar Mohammad Masum, Fahad Faisal, Syed Akhter Hossain",
        "published": "2019-7",
        "citations": 17,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icccnt45670.2019.8944839"
    },
    {
        "id": 20579,
        "title": "Regularizing RNNs for Caption Generation by Reconstructing the Past with the Present",
        "authors": "Xinpeng Chen, Lin Ma, Wenhao Jiang, Jian Yao, Wei Liu",
        "published": "2018-6",
        "citations": 53,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr.2018.00834"
    },
    {
        "id": 20580,
        "title": "Abstractive method of text summarization with sequence to sequence RNNs",
        "authors": "Abu Kaisar Mohammad Masum, Sheikh Abujar, Md Ashraful Islam Talukder, A.K.M. Shahariar Azad Rabby, Syed Akhter Hossain",
        "published": "2019-7",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icccnt45670.2019.8944620"
    },
    {
        "id": 20581,
        "title": "Data-to-Text Generation with Iterative Text Editing",
        "authors": "Zdeněk Kasner, Ondřej Dušek",
        "published": "2020",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.inlg-1.9"
    },
    {
        "id": 20582,
        "title": "Abstractive Headline Generation from Bangla News Articles Using Seq2Seq RNNs with Global Attention",
        "authors": "Ruhul Amin, Nabila Sabrin Sworna, Md Nazmul Khan Liton, Nahid Hossain",
        "published": "2021-8-5",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icsct53883.2021.9642642"
    },
    {
        "id": 20583,
        "title": "TUDA-Reproducibility @ ReproGen: Replicability of Human Evaluation of Text-to-Text and Concept-to-Text Generation",
        "authors": "Christian Richter, Yanran Chen, Steffen Eger",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.inlg-1.32"
    },
    {
        "id": 20584,
        "title": "TCTG:A Controllable Text Generation Method Using Text to Control Text Generation",
        "authors": "Liang Xuyuan, Tian Lihua, Li Chen",
        "published": "2021-10-22",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icsip52628.2021.9688767"
    },
    {
        "id": 20585,
        "title": "Generation of Company descriptions using concept-to-text and text-to-text deep models: dataset collection and systems evaluation",
        "authors": "Raheel Qader, Khoder Jneid, François Portet, Cyril Labbé",
        "published": "2018",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-6532"
    },
    {
        "id": 20586,
        "title": "Text-in-Context: Token-Level Error Detection for Table-to-Text Generation",
        "authors": "Zdeněk Kasner, Simon Mille, Ondřej Dušek",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.inlg-1.25"
    },
    {
        "id": 20587,
        "title": "Bangla E-mail Body to Subject generation using sequence to sequence RNNs",
        "authors": "Md Abrar Hamim, Moyin Talukder, Afraz Ul Haque, Md. Selim Reza, Md. Samiul Alim, Asif Iquebal Niloy",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10306627"
    },
    {
        "id": 20588,
        "title": "Text-to-Text Pre-Training for Data-to-Text Tasks",
        "authors": "Mihir Kale, Abhinav Rastogi",
        "published": "2020",
        "citations": 17,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.inlg-1.14"
    },
    {
        "id": 20589,
        "title": "Visualizing memorization in RNNs",
        "authors": "Andreas Madsen",
        "published": "2019-3-25",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23915/distill.00016"
    },
    {
        "id": 20590,
        "title": "Arabic Text to Image Generation Tasks",
        "authors": "Mourad BAHANI",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nCurrent AI systems have shown impressive results in the Automatic synthesis realistic images from texts descriptions tasks. In fact, Generative Adversarial Networks (GANs) are used mostly in this tasks. The Generator generates realistic images given noise and sentence vectors, and the discriminator produce a probability of how the synthetic images are reals. In this paper, in order to generate images from Arabic text, we fuse DF-GAN as a sample and efficient text-to-image generation framework and AraBERT architecture. To achieve this purpose, firstly, we re-create new datasets matching the Arabic text-to-image generation task by applying DeepL-Translator from English to Arabic on texts descriptions of original datasets. Secondly, we leverage the power of AraBERT which is trained on billions of Arabic words to produce a strong sentence embedding, and we reduce that vector's dimension to match with DF-GAN shape. Thirdly, we inject the reduced sentence embedding into the UPBlocks sections of DF-GAN and we train the proposed architecture on two challenging datasets. Following the previous works, we use CUB and Oxford-102 flowers as original datasets. Further, we measure our framework with FID and IS. Our framework is the first that achieve much success in generating high-resolution realistic and text matching images conditioned with Arabic text.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2163664/v1"
    },
    {
        "id": 20591,
        "title": "Personalized Persuasive Text Generation",
        "authors": "Mansoureh Motahari Nezhad, Mohammadreza Kangavari",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4453018"
    },
    {
        "id": 20592,
        "title": "A Review of Generative Adversarial Networks in Text Generation",
        "authors": "Jaden Cohen",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.58445/rars.975"
    },
    {
        "id": 20593,
        "title": "The Comparison of Word Embedding Techniques in RNNs for Vulnerability Detection",
        "authors": "Hai Nguyen, Songpon Teerakanok, Atsuo Inomata, Tetsutaro Uehara",
        "published": "2021",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010232301090120"
    },
    {
        "id": 20594,
        "title": "Sparse RNNs can support high-capacity classification",
        "authors": "Denis Turcu, L. F. Abbott",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractFeedforward network models performing classification tasks rely on highly convergent output units that collect the information passed on by preceding layers. Although convergent output-unit like neurons may exist in some biological neural circuits, notably the cerebellar cortex, neocortical circuits do not exhibit any obvious candidates for this role; instead they are highly recurrent. We investigate whether a sparsely connected recurrent neural network (RNN) can perform classification in a distributed manner without ever bringing all of the relevant information to a single convergence site. Our model is based on a sparse RNN that performs classification dynamically. Specifically, the interconnections of the RNN are trained to resonantly amplify the magnitude of responses to some external inputs but not others. The amplified and non-amplified responses then form the basis for binary classification. Furthermore, the network acts as an evidence accumulator and maintains its decision even after the input is turned off. Despite highly sparse connectivity, learned recurrent connections allow input information to flow to every neuron of the RNN, providing the basis for distributed computation. In this arrangement, the minimum number of synapses per neuron required to reach maximum memory capacity scales only logarithmically with network size. The model is robust to various types of noise, works with different activation and loss functions and with both backpropagation- and Hebbian-based learning rules. The RNN can also be constructed with a split excitation-inhibition architecture with little reduction in performance.",
        "link": "http://dx.doi.org/10.1101/2022.05.18.492540"
    },
    {
        "id": 20595,
        "title": "An Introduction to Recurrent Neural Networks (RNNs)",
        "authors": " ",
        "published": "No Date",
        "citations": 0,
        "abstract": "Understanding how RNNs work and its applications <strong> <strong> Author </strong> </strong> Wenyi Pi https://orcid.org/0009-0002-2884-2771 <strong> Introduction </strong> In the ever-evolving landscape of artificial intelligence (AI), bridging the gap between humans and machines has seen remarkable progress. Researchers and enthusiasts alike have tirelessly worked across numerous aspects of this field, bringing about amazing advancements.",
        "link": "http://dx.doi.org/10.59350/gjsvh-zbk81"
    },
    {
        "id": 20596,
        "title": "Unsupervised Code-switched Text Generation from Parallel Text",
        "authors": "Jie Chi, Brian Lu, Jason Eisner, Peter Bell, Preethi Jyothi, Ahmed M. Ali",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1050"
    },
    {
        "id": 20597,
        "title": "Domain-Specific Text Generation for Arabic Text Summarization",
        "authors": "Jezia Zakraoui, Jihad Mohamed AlJa'am, Imad Salah",
        "published": "2022-12-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icca56443.2022.10039630"
    },
    {
        "id": 20598,
        "title": "Improving Text Generation for Product Description via Human Behaviour",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "Text generation is an important method to generate high quality and available product description from product title. For the product description generation for online E-commerce application, the main problem is how to improve the quality of generated text. In other words, how we judge the quality of text. If all texts are already positive and available, then we find it impossible to manually judge which text is the better text for a product. So if we cannot judge which is a better text manually, we cannot improve the quality of generated text. In E-commerce, product description is to attract shoppers and improve sales. So we design a method to improve the quality of generated text based on user buying behaviour. Online result shows that our approach improve the sales of products by improving the text quality.",
        "link": "http://dx.doi.org/10.36227/techrxiv.170846525.55626336/v1"
    },
    {
        "id": 20599,
        "title": "Analysing Data-To-Text Generation Benchmarks",
        "authors": "Laura Perez-Beltrachini, Claire Gardent",
        "published": "2017",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w17-3537"
    },
    {
        "id": 20600,
        "title": "Domain-independent Data-to-Text Generation for Open Data",
        "authors": "Andreas Burgdorf, Micaela Barkmann, André Pomp, Tobias Meisen",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011272900003269"
    },
    {
        "id": 20601,
        "title": "Text Generation for Imbalanced Text Classification",
        "authors": "Suphamongkol Akkaradamrongrat, Pornpimon Kachamas, Sukree Sinthupinyo",
        "published": "2019-7",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/jcsse.2019.8864181"
    },
    {
        "id": 20602,
        "title": "Exploring Structural Encoding for Data-to-Text Generation",
        "authors": "Joy Mahapatra, Utpal Garain",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.inlg-1.44"
    },
    {
        "id": 20603,
        "title": "Learn Computer Vision Using OpenCV",
        "authors": "Sunila Gollapudi",
        "published": "2019",
        "citations": 25,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-4261-2"
    },
    {
        "id": 20604,
        "title": "Handling Rare Items in Data-to-Text Generation",
        "authors": "Anastasia Shimorina, Claire Gardent",
        "published": "2018",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-6543"
    },
    {
        "id": 20605,
        "title": "Controlled Text Generation with Adversarial Learning",
        "authors": "Federico Betti, Giorgia Ramponi, Massimo Piccardi",
        "published": "2020",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.inlg-1.5"
    },
    {
        "id": 20606,
        "title": "Revisiting Challenges in Data-to-Text Generation with Fact Grounding",
        "authors": "Hongmin Wang",
        "published": "2019",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-8639"
    },
    {
        "id": 20607,
        "title": "Text-To-Image Generation Using AI",
        "authors": "Pavithra V, Rosy S, Srinishanthini R B, Prinslin L",
        "published": "2023-4-27",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.55248/gengpi.234.4.38568"
    },
    {
        "id": 20608,
        "title": "Review for \"Ethical implications of text generation in the age of artificial intelligence\"",
        "authors": "",
        "published": "2022-2-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/beer.12479/v1/review1"
    },
    {
        "id": 20609,
        "title": "Review for \"Ethical implications of text generation in the age of artificial intelligence\"",
        "authors": "",
        "published": "2022-6-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/beer.12479/v2/review1"
    },
    {
        "id": 20610,
        "title": "Title Generation Model for which Sequence-to-Sequence RNNs with Attention and Copying Mechanisms are used",
        "authors": "Hyeon-gu Lee, Harksoo Kim",
        "published": "2017-7-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5626/jok.2017.44.7.674"
    },
    {
        "id": 20611,
        "title": "Music generation using RNNs and LSTMs",
        "authors": "H. Aditya, J. Dev, S. Das, A. Yadav",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003393580-32"
    },
    {
        "id": 20612,
        "title": "Automatic Question Generation from Indonesian Texts Using Text-to-Text Transformers",
        "authors": "Mukhlish Fuadi, Adhi Dharma Wibawa",
        "published": "2022-9-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ieit56384.2022.9967858"
    },
    {
        "id": 20613,
        "title": "Procedural Text Generation from a Photo Sequence",
        "authors": "Taichi Nishimura, Atsushi Hashimoto, Shinsuke Mori",
        "published": "2019",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-8650"
    },
    {
        "id": 20614,
        "title": "Political Event Coding as Text-to-Text Sequence Generation",
        "authors": "Yaoyao Dai, Benjamin Radford, Andrew Halterman",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.case-1.16"
    },
    {
        "id": 20615,
        "title": "Generation of Fine-Grained Movie Reviews – Text Segmentation and Sentiment Analysis",
        "authors": "Sree Renjini D.",
        "published": "2020-3-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5373/jardcs/v12sp4/20201549"
    },
    {
        "id": 20616,
        "title": "Self-Training from Self-Memory in Data-to-Text Generation",
        "authors": "Hoang Thang Ta",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4719908"
    },
    {
        "id": 20617,
        "title": "Text Generation",
        "authors": "Li Zhang, Jian-Tao Sun",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4614-8265-9_416"
    },
    {
        "id": 20618,
        "title": "EGAN: Generatives Adversarial Networks for Text Generation with Sentiments",
        "authors": "Andres Pautrat-Lertora, Renzo Perez-Lozano, Willy Ugarte",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011548100003335"
    },
    {
        "id": 20619,
        "title": "Tf-Gan: Text Feature Fusion Gan for Text-to-Image Generation",
        "authors": "Xiaoyan Jiang, Zhijun Fang, Jize Chen, Hamido Fujita",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4280052"
    },
    {
        "id": 20620,
        "title": "Controllable Sentence Simplification with a Unified Text-to-Text Transfer Transformer",
        "authors": "Kim Cheng Sheang, Horacio Saggion",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.inlg-1.38"
    },
    {
        "id": 20621,
        "title": "Text Generation",
        "authors": "Özgür Sahin",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6421-8_4"
    },
    {
        "id": 20622,
        "title": "Boosting Text Classification Performance on Sexist Tweets by Text Augmentation and Text Generation Using a Combination of Knowledge Graphs",
        "authors": "Sima Sharifirad, Borna Jafarpour, Stan Matwin",
        "published": "2018",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-5114"
    },
    {
        "id": 20623,
        "title": "Automatically Ranked Russian Paraphrase Corpus for Text Generation",
        "authors": "Vadim Gudkov, Olga Mitrofanova, Elizaveta Filippskikh",
        "published": "2020",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.ngt-1.6"
    },
    {
        "id": 20624,
        "title": "5. Deep Learning: RNNs and LSTMs",
        "authors": "",
        "published": "2020-11-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9781683924715-006"
    },
    {
        "id": 20625,
        "title": "Enhanced Transformer Model for Data-to-Text Generation",
        "authors": "Li GONG, Josep Crego, Jean Senellart",
        "published": "2019",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/d19-5615"
    },
    {
        "id": 20626,
        "title": "The Code2Text Challenge: Text Generation in Source Libraries",
        "authors": "Kyle Richardson, Sina Zarrieß, Jonas Kuhn",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w17-3516"
    },
    {
        "id": 20627,
        "title": "Cognitive Model Discovery via Disentangled RNNs",
        "authors": "Kevin J. Miller, Maria Eckstein, Matthew M. Botvinick, Zeb Kurth-Nelson",
        "published": "No Date",
        "citations": 2,
        "abstract": "AbstractComputational cognitive models are a fundamental tool in behavioral neuroscience. They instantiate in software precise hypotheses about the cognitive mechanisms underlying a particular behavior. Constructing these models is typically a difficult iterative process that requires both inspiration from the literature and the creativity of an individual researcher. Here, we adopt an alternative approach to learn parsimonious cognitive models directly from data. We fit behavior data using a recurrent neural network that is penalized for carrying information forward in time, leading to sparse, interpretable representations and dynamics. When fitting synthetic behavioral data from known cognitive models, our method recovers the underlying form of those models. When fit to laboratory data from rats performing a reward learning task, our method recovers simple and interpretable models that make testable predictions about neural mechanisms.",
        "link": "http://dx.doi.org/10.1101/2023.06.23.546250"
    },
    {
        "id": 20628,
        "title": "Expressive Text-to-Image Generation with Rich Text",
        "authors": "Songwei Ge, Taesung Park, Jun-Yan Zhu, Jia-Bin Huang",
        "published": "2023-10-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00694"
    },
    {
        "id": 20629,
        "title": "How to Imagine the World with Text? From Text-to-image Generation View",
        "authors": "Jingyi Liu",
        "published": "2023-4-1",
        "citations": 0,
        "abstract": "Words are an effective and convenient way to describe the world, but sometimes what the texts convey may be misunderstood by readers. The expression of pictures is more vivid, easy to understand and has no borders, but creating a painting often takes a long time. Text-to-image makes the two expressions complement each other: It makes every ordinary person a “painter”, so that they can feel the world, express themselves, and create more whimsy through many rich pictures. For this vision, technologists are trying their best to improve image generation models, which enables computers to generate high quality images with texts better. And they are solving some technical defects, for instance, sometimes the content of generated images is strange. In the future, text-to-image can be adapted to applications in AI such as computer-aided design, image editing, and be employed in the field of art such as movies and artworks, and then it may even make a big difference on people's life, enriching the public's spiritual world and conveying information by vivid images.",
        "link": "http://dx.doi.org/10.54097/hset.v39i.6619"
    },
    {
        "id": 20630,
        "title": "Ssd: Towards Better Text-Image Consistency Metric in Text-to-Image Generation",
        "authors": "Zhaorui Tan, Xi Yang, Zihan Ye, Qiufeng Wang, Yuyao Yan, Anh Nguyen, Kaizhu Huang",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4332128"
    },
    {
        "id": 20631,
        "title": "Towards Cross-Domain Transferability of Text Generation Models for Legal Text",
        "authors": "Vinayshekhar Bannihatti Kumar, Kasturi Bhattacharjee, Rashmi Gangadharaiah",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.nllp-1.9"
    },
    {
        "id": 20632,
        "title": "Text Generation and Processing",
        "authors": "Kyle Gorman, Richard Sproat",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-02179-4_7"
    },
    {
        "id": 20633,
        "title": "Automatic FAQ Generation Using Text-to-Text Transformer Model",
        "authors": "Santosh Vasisht, Varun Tirthani, Akhil Eppa, Punit Koujalgi, Ramamoorthy Srinath",
        "published": "2022-5-27",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/incet54531.2022.9823967"
    },
    {
        "id": 20634,
        "title": "Language Agnostic Gesture Generation Model: A Case Study of Japanese Speakers' Gesture Generation Using English Text-to-Gesture Model",
        "authors": "Genki Sakata, Naoshi Kaneko, Dai Hasegawa, Shinichi Shirakawa",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011643600003417"
    },
    {
        "id": 20635,
        "title": "Text Generation for Dataset Augmentation in Security Classification Tasks",
        "authors": "Alexander  Paul Welsh, Matthew Edwards",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4616394"
    },
    {
        "id": 20636,
        "title": "Feature Generation in Text Mining",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_100165"
    },
    {
        "id": 20637,
        "title": "Biomedical Data-to-Text Generation via Fine-Tuning Transformers",
        "authors": "Ruslan Yermakov, Nicholas Drago, Angelo Ziletti",
        "published": "2021",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.inlg-1.40"
    },
    {
        "id": 20638,
        "title": "Deep Graph Convolutional Encoders for Structured Data to Text Generation",
        "authors": "Diego Marcheggiani, Laura Perez-Beltrachini",
        "published": "2018",
        "citations": 30,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-6501"
    },
    {
        "id": 20639,
        "title": "Review for \"Ethical implications of text generation in the age of artificial intelligence\"",
        "authors": "Cristina Neesham",
        "published": "2022-7-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/beer.12479/v2/review2"
    },
    {
        "id": 20640,
        "title": "Estimating the scale of biomedical data generation using text mining",
        "authors": "Gabriel Rosenfeld, Dawei Lin",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractWhile the impact of biomedical research has traditionally been measured using bibliographic metrics such as citation or journal impact factor, the data itself is an output which can be directly measured to provide additional context about a publication’s impact. Data are a resource that can be repurposed and reused providing dividends on the original investment used to support the primary work. Moreover, it is the cornerstone upon which a tested hypothesis is rejected or accepted and specific scientific conclusions are reached. Understanding how and where it is being produced enhances the transparency and reproducibility of the biomedical research enterprise. Most biomedical data are not directly deposited in data repositories and are instead found in the publication within figures or attachments making it hard to measure. We attempted to address this challenge by using recent advances in word embedding to identify the technical and methodological features of terms used in the free text of articles’ methods sections. We created term usage signatures for five types of biomedical research data, which were used in univariate clustering to correctly identify a large fraction of positive control articles and a set of manually annotated articles where generation of data types could be validated. The approach was then used to estimate the fraction of PLOS articles generating each biomedical data type over time. Out of all PLOS articles analyzed (n = 129,918), ~7%, 19%, 12%, 18%, and 6% generated flow cytometry, immunoassay, genomic microarray, microscopy, and high-throughput sequencing data. The estimate portends a vast amount of biomedical data being produced: in 2016, if other publishers generated a similar amount of data then roughly 40,000 NIH-funded research articles would produce ~56,000 datasets consisting of the five data types we analyzed.One Sentence SummaryApplication of a word-embedding model trained on the methods sections of research articles allows for estimation of the production of diverse biomedical data types using text mining.",
        "link": "http://dx.doi.org/10.1101/182857"
    },
    {
        "id": 20641,
        "title": "Automatic Text Generation",
        "authors": "André Klahold, Madjid Fathi",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-27439-9_10"
    },
    {
        "id": 20642,
        "title": "Automatic Logical Forms Improve Fidelity in Table-to-Text Generation",
        "authors": "Iñigo Alonso, Eneko Agirre",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4432475"
    },
    {
        "id": 20643,
        "title": "Can the Transformer Be Used as a Drop-in Replacement for RNNs in Text-Generating GANs?",
        "authors": "Kevin Blin,  , Andrei Kucharavy,  ",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26615/978-954-452-072-4_021"
    },
    {
        "id": 20644,
        "title": "Text-to-Classic: A Diffusion Method for Classical Art Generation Based on Text",
        "authors": "Yi Li",
        "published": "2023-3-17",
        "citations": 0,
        "abstract": "Text-to-Image generation has recently become a hot research topic and diffusion models have achieved remarkable performance in this task. However, most previous researches aim at real scene generation. Few researches focus on classical art paintings. Besides, diffusion models are commonly heavy-weighted with a large number of parameters, which has a high computational cost. In this paper, we aim to solve the classical art paintings synthesis subtask. We propose a lightweight diffusion model Text-to-Classic(T2C) to synthesize classical art paintings according to text descriptions. Experiment results show that our method can achieve good performance with fewer parameters.",
        "link": "http://dx.doi.org/10.54097/fcis.v3i1.6030"
    },
    {
        "id": 20645,
        "title": "On Improving Text Generation Via Integrating Text Coherence",
        "authors": "Lisi Ai, Baoli Gao, Jianbing Zheng, Ming Gao",
        "published": "2019-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ccis48116.2019.9073682"
    },
    {
        "id": 20646,
        "title": "Semi-Supervised Neural Text Generation by Joint Learning of Natural Language Generation and Natural Language Understanding Models",
        "authors": "Raheel Qader, François Portet, Cyril Labbé",
        "published": "2019",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w19-8669"
    },
    {
        "id": 20647,
        "title": "Evaluating Semantic Accuracy of Data-to-Text Generation with Natural Language Inference",
        "authors": "Ondřej Dušek, Zdeněk Kasner",
        "published": "2020",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.inlg-1.19"
    },
    {
        "id": 20648,
        "title": "Reducing Non-Normative Text Generation from Language Models",
        "authors": "Xiangyu Peng, Siyan Li, Spencer Frazier, Mark Riedl",
        "published": "2020",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.inlg-1.43"
    },
    {
        "id": 20649,
        "title": "Multilingual Social Media Text Generation and Evaluation with Few-Shot Prompting",
        "authors": "Mack Blackburn",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gem-1.39"
    },
    {
        "id": 20650,
        "title": "Control Prefixes for Parameter-Efficient Text Generation",
        "authors": "Jordan Clive, Kris Cao, Marek Rei",
        "published": "2022",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2022.gem-1.31"
    },
    {
        "id": 20651,
        "title": "Guided Beam Search to Improve Generalization in Low-Resource Data-to-Text Generation",
        "authors": "Nicolas Garneau, Luc Lamontagne",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.inlg-main.1"
    },
    {
        "id": 20652,
        "title": "CDS Risk Premia Forecasting with Multi-Featured Deep Rnns: An Application on Br[I]Cs Countries",
        "authors": "Yasin Kutuk",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4360006"
    },
    {
        "id": 20653,
        "title": "Domain Specific Automatic Question Generation from Text",
        "authors": "Katira Soleymanzadeh",
        "published": "2017",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/p17-3014"
    },
    {
        "id": 20654,
        "title": "Decision letter for \"Ethical implications of text generation in the age of artificial intelligence\"",
        "authors": "",
        "published": "2022-2-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/beer.12479/v1/decision1"
    },
    {
        "id": 20655,
        "title": "Decision letter for \"Ethical implications of text generation in the age of artificial intelligence\"",
        "authors": "",
        "published": "2022-7-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/beer.12479/v2/decision1"
    },
    {
        "id": 20656,
        "title": "Towards Adversarial Genetic Text Generation",
        "authors": "Deniz Kavi",
        "published": "2021-3-27",
        "citations": 0,
        "abstract": "Text generation is the task of generating natural language, and producing outputs similar to or better than human texts. Due to deep learning’s recent success in the field of natural language processing, computer generated text has come closer to becoming indistinguishable to human writing. Genetic Algorithms have not been as popular in the field of text generation. We propose a genetic algorithm combined with text classification and clustering models which automatically grade the texts generated by the genetic algorithm. The genetic algorithm is given poorly generated texts from a Markov chain, these texts are then graded by a text classifier and a text clustering model. We then apply crossover to pairs of texts, with emphasis on those that received higher grades. Changes to the grading system and further improvements to the genetic algorithm are to be the focus of future research.",
        "link": "http://dx.doi.org/10.5121/csit.2021.110407"
    },
    {
        "id": 20657,
        "title": "Decision letter for \"Ethical implications of text generation in the age of artificial intelligence\"",
        "authors": "",
        "published": "2022-8-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/beer.12479/v3/decision1"
    },
    {
        "id": 20658,
        "title": "Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis",
        "authors": "Jun-Min Lee, Tae-Bin Ha",
        "published": "2023-10-24",
        "citations": 0,
        "abstract": "Generative Adversarial Networks (GAN) is a model for data synthesis, which creates plausible data through the competition of generator and discriminator. Although GAN application to image synthesis is extensively studied, it has inherent limitations to natural language generation. Because natural language is composed of discrete tokens, a generator has difficulty updating its gradient through backpropagation; therefore, most text-GAN studies generate sentences starting with a random token based on a reward system. Thus, the generators of previous studies are pre-trained in an autoregressive way before adversarial training, causing data memorization that synthesized sentences reproduce the training data. In this paper, we synthesize sentences using a framework similar to the original GAN. More specifically, we propose Text Embedding Space Generative Adversarial Networks (TESGAN) which generate continuous text embedding spaces instead of discrete tokens to solve the gradient backpropagation problem. Furthermore, TESGAN conducts unsupervised learning which does not directly refer to the text of the training data to overcome the data memorization issue. By adopting this novel method, TESGAN can synthesize new sentences, showing the potential of unsupervised learning for text synthesis. We expect to see extended research combining Large Language Models with a new perspective of viewing text as an continuous space.",
        "link": "http://dx.doi.org/10.3384/nejlt.2000-1533.2023.4855"
    },
    {
        "id": 20659,
        "title": "Hybridization of Intelligent Solutions Architecture for Text Understanding and Text Generation",
        "authors": "Anton Ivaschenko, Arkadiy Krivosheev, Anastasia Stolbova, Oleg Golovnin",
        "published": "2021-6-2",
        "citations": 5,
        "abstract": "This study proposes a new logical model for intelligent software architecture devoted to improving the efficiency of automated text understanding and text generation in industrial applications. The presented approach introduces a few patterns that provide a possibility to build adaptable and extensible solutions using machine learning technologies. The main idea is formalized by the concept of expounder hybridization. It summarizes an experience of document analysis and generation solutions development and social media analysis based on artificial neural networks’ practical use. The results of solving the task by the best expounder were improved using the method of aggregating multiple expounders. The quality of expounders’ combination can be further improved by introducing the pro-active competition between them on the basis of, e.g., auctioning algorithm, using several parameters including precision, solution performance and score. Analysis of the proposed approach was carried out using a dataset of legal documents including joint-stock company decision record sheets and protocols. The solution is implemented in an enterprise content management system and illustrated by an example of processing of legal documentation.",
        "link": "http://dx.doi.org/10.3390/app11115179"
    },
    {
        "id": 20660,
        "title": "Top-down signaling dynamically mediates information processing in biologically inspired RNNs",
        "authors": "Tomas Gallo Aquino, Robert Kim, Nuttida Rungratsameetaweemana",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractRecent studies have proposed employing biologically plausible recurrent neural networks (RNNs) to explore flexible decision making processes in the brain. However, the mechanisms underlying the integration of bottom-up factors (such as incoming sensory signals) and top-down factors (such as task instructions and selective attention) remain poorly understood, both within the context of these models and the brain. To address this question, we trained biologically inspired RNNs on complex cognitive tasks that require adaptive integration of these factors. By performing extensive dynamical systems analyses, we show that our RNN model is capable of seamlessly incorporating top-down signals with sensory signals to perform the complex tasks. Furthermore, through comprehensive local connectivity analyses, we identified important inhibitory feedback signals that efficiently modulate the bottom-up sensory coding in a task-driven manner. Finally, we introduced an anatomical constraint where a specific subgroup of neurons receives the sensory input signal, effectively creating a designated sensory area within the RNN. Through this constraint, we show that these “sensory” neurons possess the remarkable ability to multiplex and dynamically combine both bottom-up and top-down information. These findings are consistent with recent experimental results highlighting that such integration is a key factor in facilitating flexible decision making. Overall, our work provides a framework for generating testable hypotheses for the hierarchical encoding of task-relevant information.",
        "link": "http://dx.doi.org/10.1101/2023.10.17.562828"
    },
    {
        "id": 20661,
        "title": "Cross-modal text and visual generation: A systematic review. Part 1: Image to text",
        "authors": "Maciej Żelaszczyk, Jacek Mańdziuk",
        "published": "2023-5",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.inffus.2023.01.008"
    },
    {
        "id": 20662,
        "title": "TWT: Table with Written Text for Controlled Data-to-Text Generation",
        "authors": "Tongliang Li, Lei Fang, Jian-Guang Lou, Zhoujun Li",
        "published": "2021",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2021.findings-emnlp.107"
    },
    {
        "id": 20663,
        "title": "Controlling keywords and their positions in text generation",
        "authors": "Yuichi Sasazawa, Terufumi Morishita, Hiroaki Ozaki, Osamu Imaichi, Yasuhiro Sogawa",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2023.inlg-main.29"
    },
    {
        "id": 20664,
        "title": "Classification of compressed and uncompressed text documents",
        "authors": "S.N. Bharath Bhushan, Ajit Danti",
        "published": "2018-11",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.future.2018.04.054"
    },
    {
        "id": 20665,
        "title": "Review for \"Featuring periodic correlations via dual granularity inputs structured &lt;scp&gt;RNNs&lt;/scp&gt; ensemble load forecaster\"",
        "authors": "",
        "published": "2020-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/2050-7038.12571/v3/review1"
    },
    {
        "id": 20666,
        "title": "Review for \"Featuring periodic correlations via dual granularity inputs structured &lt;scp&gt;RNNs&lt;/scp&gt; ensemble load forecaster\"",
        "authors": "",
        "published": "2020-4-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/2050-7038.12571/v1/review3"
    },
    {
        "id": 20667,
        "title": "Recurrent Neural Networks (RNNs)",
        "authors": "Taweh Beysolow II",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-2734-3_6"
    },
    {
        "id": 20668,
        "title": "A Study on Text Rank Algorithm for Automatic Text Summarization and Question Generation",
        "authors": "G. Deena",
        "published": "2021-12-31",
        "citations": 0,
        "abstract": "This paper proposes a new rule-based approach to automated question generation. The proposed approach focuses on the analysis of both sentence syntax and semantic structure. The design and implementation of the proposed approach is also described in detail. Although the primary purpose of a design system is to generate query from sentences, automated evaluation results show that it can also perform great when reading comprehension datasets that focus on question output from paragraphs. With regard to human evaluation, the designed system performs better than all other systems and generates the most natural (human-like) questions. We present a fresh approach to automatic question generation that significantly increases the percentage of acceptable questions compared to prior state-of-the-art systems. In our system, we will take data from various sources for a particular topic and summarize it for the convenience of the people, so that they don't have to go through so multiple sites for relevant data.",
        "link": "http://dx.doi.org/10.48175/ijarsct-2302"
    },
    {
        "id": 20669,
        "title": "Latent Code and Text-based Generative Adversarial Networks for Soft-text Generation",
        "authors": "Md. Akmal Haidar, Mehdi Rezagholizadeh, Alan Do Omri, Ahmad Rashid",
        "published": "2019",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/n19-1234"
    },
    {
        "id": 20670,
        "title": "Review for \"Featuring periodic correlations via dual granularity inputs structured &lt;scp&gt;RNNs&lt;/scp&gt; ensemble load forecaster\"",
        "authors": "",
        "published": "2020-6-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/2050-7038.12571/v2/review1"
    }
]