[
    {
        "id": 26305,
        "title": "A Survey of Part-of-Speech Tagging",
        "authors": "LinFeng Dai",
        "published": "2024-3-25",
        "citations": 0,
        "abstract": "Part-of-Speech(POS) tagging, a fundamental task in natural language processing (NLP) that involves categorizing each word in a text into specific grammatical categories, is not only crucial for linguistic research but also serves as a prerequisite for more complex NLP applications such as syntactic analysis, entity recognition, and machine translation. This paper reveals the transition from the laborious process of manual annotation to the development of automated techniques, showcasing how the application of advanced deep learning (DL) and machine learning (ML) methods can enhance the efficiency and accuracy of POS tagging. Finally, the paper discusses the current challenges faced in POS tagging, along with corresponding solutions and potential future directions.",
        "keywords": "",
        "link": "http://dx.doi.org/10.53469/jtpes.2024.04(03).15"
    },
    {
        "id": 26306,
        "title": "Deep Learning Model for Tamil Part-of-Speech Tagging",
        "authors": "Hemakasiny Visuwalingam, Ratnasingam Sakuntharaj, Janaka Alawatugoda, Roshan Ragel",
        "published": "2024-4-6",
        "citations": 0,
        "abstract": "Abstract\nPart-of-Speech (POS) tagging is one of the popular Natural Language Processing (NLP) tasks. It is also considered to be a preliminary task for other NLP applications such as speech recognition, machine translation, and sentiment analysis. A few works have been published on POS tagging for the Tamil language. However, the performance of the POS tagger with unknown words is not explored in the literature. The appearance of unknown words is a frequently occurring problem in POS tagging and makes it a challenging task. In this paper, we propose a deep learning-based POS tagger for Tamil using Bi-directional Long Short Term Memory (BLSTM). The performance of the POS tagger was evaluated using known and unknown words. The POS tagger with regular word-level embeddings produces 99.83 and 92.46% accuracies for all known and 63.21% unknown words. It clearly shows that the accuracy decreases when the number of unknown words increases. To improve the performance of the POS tagger with unknown words, the proposed BLSTM model that uses word-level, character-level and pre-trained word embeddings. Test results of this model show a 2.57% improvement for 63.21% of unknown words, with an accuracy of 95.03%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1093/comjnl/bxae033"
    },
    {
        "id": 26307,
        "title": "BiLSTM with CRF Part-of-Speech Tagging for Khasi language",
        "authors": "Ransly Hoojon, Dr. Amitabha Nath",
        "published": "2023-3-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/i3cs58314.2023.10127278"
    },
    {
        "id": 26308,
        "title": "Improving part-of-speech tagging in Amharic language using deep neural network",
        "authors": "Sintayehu Hirpassa, G.S. Lehal",
        "published": "2023-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.heliyon.2023.e17175"
    },
    {
        "id": 26309,
        "title": "Decoding Neural Activity for Part-of-Speech Tagging (POS)",
        "authors": "Salman Ahmed, Muskaan Singh, Saugat Bhattacharyya, Damien Coyle",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smc53992.2023.10394253"
    },
    {
        "id": 26310,
        "title": "New Text Steganography Technique Based on Part-of-Speech Tagging and Format-Preserving Encryption",
        "authors": "",
        "published": "2024-1-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3837/tiis.2024.01.010"
    },
    {
        "id": 26311,
        "title": "Custom Hidden Markov Models for Effective Part-of-Speech Tagging",
        "authors": "Hassan Bin Khalid, Abu Bakar Siddique, Raja Hashim Ali",
        "published": "2023-11-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icet59753.2023.10374930"
    },
    {
        "id": 26312,
        "title": "A method for constructing concurrent processing model\nof Xiangxi Hmong part-of-speech tagging",
        "authors": "Liping Mo, Cuina Cheng, Songlv Feng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.55092/pcs2023020021"
    },
    {
        "id": 26313,
        "title": "Geez Part of Speech Tagging Using Deep Learning Approaches",
        "authors": "Habtamu Shiferaw Asmare, Abdulkerim Mohammed Yibre",
        "published": "2023-10-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ict4da59526.2023.10302264"
    },
    {
        "id": 26314,
        "title": "Ancient Chinese Word Segmentation and Part-of-Speech Tagging Using Distant Supervision",
        "authors": "Shuo Feng, Piji Li",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10097080"
    },
    {
        "id": 26315,
        "title": "Exploring Part-of-Speech Tagging Models in Malaysia's Multilingual",
        "authors": "Yean Ling Chan, Fang En Leong, Tong Ming Lim, Chi Wee Tan",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdxa61007.2024.10470884"
    },
    {
        "id": 26316,
        "title": "Toward accurate Amazigh part-of-speech tagging",
        "authors": "Rkia Bani, Samir Amri, Lahbib Zenkouar, Zouhair Guennoun",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "<span lang=\"EN-US\">Part-of-speech (POS) tagging is the process of assigning to each word in a text its corresponding grammatical information POS. It is an important pre-processing step in other natural language processing (NLP) tasks, so the objective of finding the most accurate one. The previous approaches were based on traditional machine learning algorithms, later with the development of deep learning, more POS taggers were adopted. If the accuracy of POS tagging reaches 97%, even with the traditional machine learning, for high resourced language like English, French, it’s far the case in low resource language like Amazigh. The most used approaches are traditional machine learning, and the results are far from those for rich language. In this paper, we present a new POS tagger based on bidirectional long short-term memory for Amazigh language and the experiments that have been done on real dataset shows that it outperforms the existing machine learning methods.</span>",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijai.v13.i1.pp572-580"
    },
    {
        "id": 26317,
        "title": "Deep Neural Networks for Part-of-Speech Tagging in Under-Resourced Amazigh",
        "authors": "Rkia Bani, Samir Amri, Lahbib Zenkouar, Zouhair Guennoun",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18280/ria.370310"
    },
    {
        "id": 26318,
        "title": "Combining conditional random fields and word embeddings to improve Amazigh part-of-speech Tagging",
        "authors": "Rkia Bani, Samir Amri, Lahbib Zenkouar, Zouhair Guennoun",
        "published": "2023-9-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eecsi59885.2023.10295911"
    },
    {
        "id": 26319,
        "title": "Grammar-Supervised End-to-End Speech Recognition with Part-of-Speech Tagging and Dependency Parsing",
        "authors": "Genshun Wan, Tingzhi Mao, Jingxuan Zhang, Hang Chen, Jianqing Gao, Zhongfu Ye",
        "published": "2023-3-27",
        "citations": 2,
        "abstract": "For most automatic speech recognition systems, many unacceptable hypothesis errors still make the recognition results absurd and difficult to understand. In this paper, we introduce the grammar information to improve the performance of the grammatical deviation distance and increase the readability of the hypothesis. The reinforcement of word embedding with grammar embedding is presented to intensify the grammar expression. An auxiliary text-to-grammar task is provided to improve the performance of the recognition results with the downstream task evaluation. Furthermore, the multiple evaluation methodology of grammar is used to explore an expandable usage paradigm with grammar knowledge. Experiments on the small open-source Mandarin speech corpus AISHELL-1 and large private-source Mandarin speech corpus TRANS-M tasks show that our method can perform very well with no additional data. Our method achieves relative character error rate reductions of 3.2% and 5.0%, a relative grammatical deviation distance reduction of 4.7% and 5.9% on AISHELL-1 and TRANS-M tasks, respectively. Moreover, the grammar-based mean opinion score of our method is about 4.29 and 3.20, significantly superior to the baseline of 4.11 and 3.02.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app13074243"
    },
    {
        "id": 26320,
        "title": "A hybrid part-of-speech tagger with annotated Kurdish corpus: advancements in POS tagging",
        "authors": "Dastan Maulud, Karwan Jacksi, Ismael Ali",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "Abstract\nWith the rapid growth of online content written in the Kurdish language, there is an increasing need to make it machine-readable and processable. Part of speech (POS) tagging is a critical aspect of natural language processing (NLP), playing a significant role in applications such as speech recognition, natural language parsing, information retrieval, and multiword term extraction. This study details the creation of the DASTAN corpus, the first POS-annotated corpus for the Sorani Kurdish dialect. The corpus, containing 74,258 words and thirty-eight tags, employs a hybrid approach utilizing the bigram hidden Markov model in combination with the Kurdish rule-based approach to POS tagging. This approach addresses two key problems that arise with rule-based approaches, namely misclassified words and ambiguity-related unanalyzed words. The proposed approach’s accuracy was assessed by training and testing it on the DASTAN corpus, yielding a 96% accuracy rate. Overall, this study’s findings demonstrate the effectiveness of the proposed hybrid approach and its potential to enhance NLP applications for Sorani Kurdish.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1093/llc/fqad066"
    },
    {
        "id": 26321,
        "title": "An Overview of Part-of-Speech Tagging Methods and Datasets for Malay Language",
        "authors": "Chi Log Chua, Tong Ming Lim, Kwee Teck See",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsecs58457.2023.10256423"
    },
    {
        "id": 26322,
        "title": "Public Hospital Review on Map Service with Part of Speech Tagging and Biterm Topic Modeling",
        "authors": "Moh Makruf, Arif Bramantoro",
        "published": "2023-4-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.12785/ijcds/130188"
    },
    {
        "id": 26323,
        "title": "Improving Extraction of Japanese Functional Expressions with Discontinuous Types through Part-Of-Speech Tagging",
        "authors": "Jun Liu, Renting Chen, Chaofan Liang",
        "published": "2023-6-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3608218.3608230"
    },
    {
        "id": 26324,
        "title": "Part-of-Speech (POS) Tagging for Standard Brunei Malay: A Probabilistic and Neural-Based Approach",
        "authors": "Izzati Mohaimin, Rosyzie A. Apong, Ashrol R. Damit",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.12720/jait.14.4.830-837"
    },
    {
        "id": 26325,
        "title": "Syllable-Based Multi-POSMORPH Annotation for Korean Morphological Analysis and Part-of-Speech Tagging",
        "authors": "Hyeong Jin Shin, Jeongyeon Park, Jae Sung Lee",
        "published": "2023-2-23",
        "citations": 2,
        "abstract": "Various research approaches have attempted to solve the length difference problem between the surface form and the base form of words in the Korean morphological analysis and part-of-speech (POS) tagging task. The compound POS tagging method is a popular approach, which tackles the problem using annotation tags. However, a dictionary is required for the post-processing to recover the base form and to dissolve the ambiguity of compound POS tags, which degrades the system performance. In this study, we propose a novel syllable-based multi-POSMORPH annotation method to solve the length difference problem within one framework, without using a dictionary for the post-processing. A multi-POSMORPH tag is created by combining POS tags and morpheme syllables for the simultaneous POS tagging and morpheme recovery. The model is implemented with a two-layer transformer encoder, which is lighter than the existing models based on large language models. Nonetheless, the experiments demonstrate that the performance of the proposed model is comparable to, or better than, that of previous models.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app13052892"
    },
    {
        "id": 26326,
        "title": "Part-of-Speech and Pragmatic Tagging of a Corpus of Film Dialogue: A Pilot Study",
        "authors": "Liviana Galiano, Alfonso Semeraro",
        "published": "2023-3",
        "citations": 1,
        "abstract": "AbstractThis article presents how a pilot study for automatically POS-tagging a corpus of orthographic transcriptions of film dialogues (Pavia Corpus of Film Dialogue) was dealt with and the related issues solved. The software CLAWS4, which is freely available on UCREL’s website, was used for the sake of comparability with reference corpora such as the BNC (both 1994 and 2014) and all the English corpora available on english-corpora.org (former BYU interface). The study highlights that automatic POS-tagging needs readjusting when applied to film dialogue and the accuracy of the tagging greatly benefits from the introduction of tags for pragmatic categories. This integrated approach of grammatical and pragmatic automatic tagging was realised through the writing of a Python script which post-processes the data output of CLAWS4.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s41701-022-00132-9"
    },
    {
        "id": 26327,
        "title": "Part of speech tagging of grammatical features related to L2 Chinese development: A case analysis of Stanza in the L2 writing context",
        "authors": "Ge Lan, Xiaofei Pan, Yachao Sun, Yuan Lu",
        "published": "2023-2-15",
        "citations": 1,
        "abstract": "Grammatical complexity has received extensive attention in second language acquisition. Although computational tools have been developed to analyze grammatical complexity, most relevant studies investigated this construct in the context of English as a second language. In response to an increasing number of L2 Chinese learners, it is important to extend the investigation of grammatical complexity in L2 Chinese. To promote relevant research, we evaluated the new computational tool,Stanza, on its accuracy of part-of-speech tagging for L2 Chinese writing. We particularly focused on eight grammatical features closely related to L2 Chinese development. Then, we reported the precisions, recalls, and F-scores for the individual grammatical features and offered a qualitative analysis of systematic tagging errors. In terms of the precision, three features have high rates, over 90% (i.e.,baandbeimarkers, classifiers, -deas noun modifier marker). For recall, four features have high rates, over 90% (i.e., aspect markers,baandbeimarkers, classifiers, -deas noun modifier marker). Overall, based on the F-scores, Stanza has a good tagging performance onbaandbeimarkers, classifiers, and -deas a noun modifier marker. This evaluation provides research implications for scholars who plan to use this computational tool to study L2 Chinese development in second language acquisition or applied linguistics in general.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fpsyg.2023.1139703"
    },
    {
        "id": 26328,
        "title": "PHONOLOGICAL SIGNALLING OF TOPIC MOVEMENT IN CONVERSATION DISCOURSE: AUTOMATIC TAGGING IN SPOKEN LANGUAGE CORPORA",
        "authors": "C CHEEPEN",
        "published": "2024-3-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25144/20298"
    },
    {
        "id": 26329,
        "title": "Improving Speech Enhancement Using Audio Tagging Knowledge From Pre-Trained Representations and Multi-Task Learning",
        "authors": "Shaoxiong Lin, Chao Zhang, Yanmin Qian",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/asru57964.2023.10389687"
    },
    {
        "id": 26330,
        "title": "Parts-of-Speech Tagging for Unknown Words in Assamese using Viterbi Algorithm",
        "authors": "Rituraj Phukan,  , Nomi Baruah, Shikhar Kr Sarma, Darpanjit Konwar",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17485/ijst/v16isp2.8203"
    },
    {
        "id": 26331,
        "title": "Part-Of-Speech Tagging for Balochi Language: A Data driven application of Conditional Random Fields",
        "authors": "Sami Ullah, Najma Imtiaz Ali, Shah Murad Chandio, Imtiaz Ali Brohi, Barkat Ali Laghari",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "Parts-of-Speech (POS) tagging involves the assignment of the correct part of speech or lexical category to individual words within a sentence in a natural language. This procedure holds significant in the field of Natural Language Processing (NLP) and find utility across a variety of NLP applications. Commonly, it constitutes the initial phase of natural language processing. Subsequent stages may encompass additional tasks such as chunking, parsing and more. Balochi stands as the predominant language in Balochistan,, ranking as the fourth most prevalent language in Pakistan. The field of natural language processing for Balochi is still in its nascent stages. In this research, we introduce an algorithm for Balochi part-of-speech tagging, leveraging machine learning techniques. The core of our approach relies on a Conditional Random Field model as the machine learning component. Careful consideration is given to selecting appropriate features for the CRF, taking into account the linguistic characteristics of Balochi. Balochi is currently considered a resource poor language, and thus, the available manually tagged data consists of only approximately 1500 sentences. The tagset used in this study created for research purpose, consisting of 16 different tags. The learning process incorporates tagged data. The algorithm demonstrates a high accuracy rate of 86.78% when applied to Balochi texts.  The training corpus comprises 40000 words, while the test corpus contains 10000 words.",
        "keywords": "",
        "link": "http://dx.doi.org/10.62019/abbdm.v4i1.111"
    },
    {
        "id": 26332,
        "title": "Exploring The Potential of HMMs in Linguistics for Part of Speech (POS) Tagging",
        "authors": "Mahnoor Iftikhar, Raja Hashim Ali, Memoona Saleem, Usama Arshad, Ali Zeeshan Ijaz, Nisar Ali, Muhammad Imad, Muhammad Abu Bakar, Ali Aftab",
        "published": "2023-10-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icit59216.2023.10335862"
    },
    {
        "id": 26333,
        "title": "Part-of-Speech Tagging for low resource languages: Activation function for deep learning network to work with Minimal Training Data",
        "authors": "Diganta Baishya, Rupam Baruah",
        "published": "2024-3-30",
        "citations": 0,
        "abstract": "Numerous natural language processing (NLP) applications exist today, especially for the most commonly spoken languages like English, Chinese, and Spanish. Popular traditional methods like Naive Bayes classifiers, Hidden Markov models, Conditional Random field-based classifiers, and other stochastic methods have contributed to this improvement over the last three decades. Recently, deep learning has led to exciting breakthroughs in several areas of artificial intelligence, including image processing and natural language processing. It is important to label words as parts of speech to begin developing most of the NLP applications. A deep study in this area reveals that these approaches require massive training data. Therefore, these approaches have not been helpful for languages not rich in digital resources. Applying these methods with very little training data prompts the need for innovative problem-solving. This paper describes our research, which examines the strengths and weaknesses of well-known approaches, such as conditional random fields and state-of-the-art deep learning models, when applied for part-of-speech tagging using minimal training data for Assamese and English. We also examine the factors affecting them. We discuss our deep learning architecture and the proposed activation function, which shows promise with little training data. The activation function categorizes words belonging to different classes with more confidence by using the outcomes of statistical methods. With minimal training, our deep learning architecture using the proposed PSM-Taylor SoftMax improves accuracy by 4%–9%, This technique is a combination of SMTaylor SoftMax and probability distribution.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3655023"
    },
    {
        "id": 26334,
        "title": "Automatinis kalbos dalių žymėjimas (POS) Tartu estų anglų kalbos mokinių tekstyne: mokinių klaidų poveikis CLAWS7 įrankio tikslumui",
        "authors": "Liina Tammekänd, Reeli Torn-Leesik",
        "published": "2023-12-28",
        "citations": 0,
        "abstract": "The present paper, which is a continuation of Tammekänd and Torn-Leesik’s (2022) study, aims to examine how learner errors affect the CLAWS7 tagger’s automated assignment of part-of-speech (POS) tags to a sample of 24,812 words of the Tartu Corpus of Estonian Learner English (TCELE). Learner errors causing tagging errors in the sample were identified, based on which a working error taxonomy was created. The POS-tagged and error-tagged samples were collated and compared to map correlations between learner and tagging errors. Error groups that correlated with significantly increased rates of tagging errors were identified. Possible reasons were suggested to account for the impact of learner errors on the tagger’s performance. The CLAWS7 tagger misanalysed only 2.8% of forms representing learners’ language errors but assigned wrong tags to every fifth spelling error (22%).",
        "keywords": "",
        "link": "http://dx.doi.org/10.15388/taikalbot.2023.20.9"
    },
    {
        "id": 26335,
        "title": "PHONEME MATCHING TECHNIQUES FOR SPEECH IDENTIFICATION PROBLEMS",
        "authors": "MJ CAREY, ES PARRIS",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25144/20336"
    },
    {
        "id": 26336,
        "title": "Part-of-Speech Tagging of Odia Language Using Statistical and Deep Learning Based Approaches",
        "authors": "Tusarkanta Dalai, Tapas Kumar Mishra, Pankaj K. Sa",
        "published": "2023-6-30",
        "citations": 4,
        "abstract": "Automatic part-of-speech (POS) tagging is a preprocessing step of many natural language processing tasks, such as named entity recognition, speech processing, information extraction, word sense disambiguation, and machine translation. It has already gained promising results in English and European languages. However, in Indian languages, particularly in the Odia language, it is not yet well explored because of the lack of supporting tools, resources, and morphological richness of the language. Unfortunately, we were unable to locate an open source POS tagger for the Odia language, and only a handful of attempts have been made to develop POS taggers for the Odia language. The main contribution of this research work is to present statistical approaches such as the maximum entropy Markov model and conditional random field (CRF), as well as deep learning based approaches, including the convolutional neural network (CNN) and bidirectional long short-term memory (Bi-LSTM) to develop the Odia POS tagger. A publicly accessible corpus annotated with the Bureau of Indian Standards (BIS) tagset is used in our work. However, most of the languages around the globe have used the dataset annotated with the Universal Dependencies (UD) tagset. Hence, to maintain uniformity, the Odia dataset should use the same tagset. Thus, following the BIS and UD guidelines, we constructed a mapping from the BIS tagset to the UD tagset. The maximum entropy Markov model, CRF, Bi-LSTM, and CNN models are trained using the Indian Languages Corpora Initiative corpus with the BIS and UD tagsets. We have experimented with various feature sets as input to the statistical models to prepare a baseline system and observed the impact of constructed feature sets. The deep learning based model includes the Bi-LSTM network, the CNN network, the CRF layer, character sequence information, and a pre-trained word vector. Seven different combinations of neural sequence labeling models are implemented, and their performance measures are investigated. It has been observed that the Bi-LSTM model with the character sequence feature and pre-trained word vector achieved a result with 94.58% accuracy.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3588900"
    },
    {
        "id": 26337,
        "title": "Gct: Gated Contextual Transformer for Sequential Audio Tagging",
        "authors": "Yuanbo Hou, Yun Wang, Wenwu Wang, Dick Botteldooren",
        "published": "2023-6-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10096842"
    },
    {
        "id": 26338,
        "title": "CED: Consistent Ensemble Distillation for Audio Tagging",
        "authors": "Heinrich Dinkel, Yongqing Wang, Zhiyong Yan, Junbo Zhang, Yujun Wang",
        "published": "2024-4-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446348"
    },
    {
        "id": 26339,
        "title": "Tagging Speech For Words In Low Resourced Monolingual Contexts of Sanskrit Shlokas",
        "authors": "Thanmayi S Hegde, V Vindhya, V R Badri Prasad",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/i-pact58649.2023.10434477"
    },
    {
        "id": 26340,
        "title": "An Experimental Comparison of Multi-View Self-Supervised Methods for Music Tagging",
        "authors": "Gabriel Meseguer-Brocal, Dorian Desblancs, Romain Hennequin",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447473"
    },
    {
        "id": 26341,
        "title": "Semantic Proximity Alignment: Towards Human Perception-Consistent Audio Tagging by Aligning with Label Text Description",
        "authors": "Wuyang Liu, Yanzhen Ren",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446928"
    },
    {
        "id": 26342,
        "title": "Efficient Large-Scale Audio Tagging Via Transformer-to-CNN Knowledge Distillation",
        "authors": "Florian Schmid, Khaled Koutini, Gerhard Widmer",
        "published": "2023-6-4",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10096110"
    },
    {
        "id": 26343,
        "title": "A Study on the Performance of Recurrent Neural Network based Models in Maithili Part of Speech Tagging",
        "authors": "Ankur Priyadarshi, Sujan Kumar Saha",
        "published": "2023-3-31",
        "citations": 2,
        "abstract": "This article presents our effort in developing a Maithili Part of Speech (POS) tagger. Substantial effort has been devoted to developing POS taggers in several Indian languages, including Hindi, Bengali, Tamil, Telugu, Kannada, Punjabi, and Marathi; but Maithili did not achieve much attention from the research community. Maithili is one of the official languages of India, with around 50 million native speakers. So, we worked on developing a POS tagger in Maithili. For the development, we use a manually annotated in-house Maithili corpus containing 56,126 tokens. The tagset contains 27 tags. We train a conditional random fields (CRF) classifier to prepare a baseline system that achieves an accuracy of 82.67%. Then, we employ several recurrent neural networks (RNN)-based models, including Long-short Term Memory (LSTM), Gated Recurrent Unit (GRU), LSTM with a CRF layer (LSTM-CRF), and GRU with a CRF layer (GRU-CRF) and perform a comparative study. We also study the effect of both word embedding and character embedding in the task. The highest accuracy of the system is 91.53%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3540260"
    },
    {
        "id": 26344,
        "title": "How Robust are Audio Embeddings for Polyphonic Sound Event Tagging?",
        "authors": "Jakob Abeßer, Sascha Grollmisch, Meinard Müller",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/taslp.2023.3293032"
    },
    {
        "id": 26345,
        "title": "FAIRY TALE-BASED SPEECH DEVELOPMENT TECHNIQUES FOR CHILDREN",
        "authors": "Kakhkharova Ozoda,  ",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "The article written on the topic \"Fairy tale-based speech development techniques for children\", offers suggestions for helping young children learn how to connect speech. The article aims to clarify the significance of fairy tales' influence on children's speech development. The article also emphasizes the concepts of the instructor organizing the speech development process while taking the pedagogical process into consideration.",
        "keywords": "",
        "link": "http://dx.doi.org/10.37547/ijp/volume04issue02-04"
    },
    {
        "id": 26346,
        "title": "Unified Keyword Spotting and Audio Tagging on Mobile Devices with Transformers",
        "authors": "Heinrich Dinkel, Yongqing Wang, Zhiyong Yan, Junbo Zhang, Yujun Wang",
        "published": "2023-6-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10095534"
    },
    {
        "id": 26347,
        "title": "Deep Neural Networks-based Classification Methodologies of Speech, Audio and Music, and its Integration for Audio Metadata Tagging",
        "authors": "Hosung Park, Yoonseo Chung, Ji-Hwan Kim",
        "published": "2023-4-20",
        "citations": 0,
        "abstract": "Videos contain visual and auditory information. Visual information in a video can include images of people, objects, and the landscape, whereas auditory information includes voices, sound effects, background music, and the soundscape. The audio content can provide detailed information on the story by conducting a voice and atmosphere analysis of the sound effects and soundscape. Metadata tags represent the results of a media analysis as text. The tags can classify video content on social networking services, like YouTube. This paper presents the methodologies of speech, audio, and music processing. Also, we propose integrating these audio tagging methods and applying them in an audio metadata generation system for video storytelling. The proposed system automatically creates metadata tags based on speech, sound effects, and background music information from the audio input. The proposed system comprises five subsystems: (1) automatic speech recognition, which generates text from the linguistic sounds in the audio, (2) audio event classification for the type of sound effect, (3) audio scene classification for the type of place from the soundscape, (4) music detection for the background music, and (5) keyword extraction from the automatic speech recognition results. First, the audio signal is converted into a suitable form, which is subsequently combined from each subsystem to create metadata for the audio content. We evaluated the proposed system using video logs (vlogs) on YouTube. The proposed system exhibits a similar accuracy to handcrafted metadata for the audio content, and for a total of 104 YouTube vlogs, achieves an accuracy of 65.83%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.13052/jwe1540-9589.2211"
    },
    {
        "id": 26348,
        "title": "Joint Music and Language Attention Models for Zero-Shot Music Tagging",
        "authors": "Xingjian Du, Zhesong Yu, Jiaju Lin, Bilei Zhu, Qiuqiang Kong",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447760"
    },
    {
        "id": 26349,
        "title": "Language-based transfer learning approaches for part-of-speech tagging on Saint Petersburg Corpus of Hagiographic texts (SKAT)",
        "authors": "Vadim V. Gudkov,  , Olga V. Mitrenina, Evgenii G. Sokolov, Angelina A. Koval,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "The article describes an experiment about training a part-of-speech tagger using artificial neural networks on the St. Petersburg Corpus of Hagiographic Texts (SKAT), which is being developed at the Department of Mathematical Linguistics of St. Petersburg State University. The corpus includes the texts of 23 manuscripts dating from the 15th–18th centuries with about 190,000 words usages, four of which were labelled manually. The bi-LSTM, distilled RuBERTtiny2 and RuBERT models were used to train a POS tagger. All of them were trained on modern Russian corpora and further fine-tuned to label Old Russian texts using a technique called language transfer. To fine-tune transformer-based language models it was necessary to tokenize the texts using byte pair encoding and map tokens from the original Russian-language tokenizer to the new one based on indices. Then the model was fine-tuned for the token classification task. To fine-tune the model, a tagged subcorpus of three hagiographical texts was used, which included 35,603 tokens and 2,885 sentences. The experiment took into account only the tags of the parts of speech, the classification included seventeen tags, thirteen of which corresponded to parts of speech, and the remaining four marked punctuation marks. To evaluate the quality of the model, the standard metrics F1 and Accuracy were used. According to automatic evaluation metrics, the RuBERT model showed the best result. Most of the errors were related to incorrect generalization of linear position patterns or to the similarity of word forms in both the extreme left and extreme right positions.",
        "keywords": "",
        "link": "http://dx.doi.org/10.21638/spbu09.2023.205"
    },
    {
        "id": 26350,
        "title": "Parts-of-speech tagging of Nepali texts with Bidirectional LSTM, Conditional Random Fields and HMM",
        "authors": "Ashish Pradhan, Archit Yajnik",
        "published": "2024-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-15679-1"
    },
    {
        "id": 26351,
        "title": "Exploiting Diversity of Automatic Transcripts from Distinct Speech Recognition Techniques for Children’s Speech",
        "authors": "Christopher Gebauer, Lars Rumberg, Hanna Ehlert, Ulrike Lüdtke, Joern Ostermann",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-926"
    },
    {
        "id": 26352,
        "title": "A COMPARISON OF LETTER-TO-SOUND CONVERSION TECHNIQUES FOR ENGLISH TEXT-TO-SPEECH SYNTHESIS",
        "authors": "RI DAMPER, Y MARCHAND, MJ ADAMSON, K GUSTAFSON",
        "published": "2024-1-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25144/18986"
    },
    {
        "id": 26353,
        "title": "Music Auto-Tagging with Robust Music Representation Learned via Domain Adversarial Training",
        "authors": "Haesun Joung, Kyogu Lee",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447318"
    },
    {
        "id": 26354,
        "title": "Investigation Of Data Augmentation Techniques For Bi-LSTM Based Direct Speech To Speech Translation",
        "authors": "Lalaram Arya, Ayush Agarwal, S. R. Mahadeva Prasanna",
        "published": "2023-2-23",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ncc56989.2023.10067896"
    },
    {
        "id": 26355,
        "title": "Beamforming using Different Window Techniques for Near-Field Speech in Anechoic and Reverberant Environment",
        "authors": "Amruth Ashok Gadag, Rajib Sharma, Deepak K T",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482942"
    },
    {
        "id": 26356,
        "title": "A Challenging Data Set for Evaluating Part-of-Speech Taggers",
        "authors": "Mattias Wahde, Minerva Suvanto, Marco Vedova",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012307200003636"
    },
    {
        "id": 26357,
        "title": "Listening Skill A Significant Part for Efficacious Coherent Speech",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/eel.v13i3.600"
    },
    {
        "id": 26358,
        "title": "Analyzing Delivery Area/Zone Tagging Techniques Within Fulfillment Centres For Last Mile Delivery Orders",
        "authors": "Muhammad Younus, Achmad Nurmandi, Suswanta Suswanta, Abdul Rehman",
        "published": "2023-7-22",
        "citations": 1,
        "abstract": "Last-mile delivery in e-commerce logistics is crucial and difficult, affecting consumer happiness and operational efficiency. Fulfillment centers use delivery area/zone marking to ease this operation. This study examines fulfillment center methods for optimizing last-mile delivery orders. This research first examines delivery area/zone labeling methods. These methods break geographical regions into smaller manageable parts for resource allocation and route optimization. Grid-based zoning, distance-based tagging, and contemporary machine learning methods for dynamic and adaptive zone identification will be investigated. The study then examines delivery area tagging implementation factors. Zone tagging success depends on population density, order frequency, traffic patterns, and delivery time windows. Emission regulations and sustainability targets will also be examined. Delivery area/zone tagging technology and tools are also examined. GPS tracking, GIS mapping, and real-time data analytics enable effective monitoring and modifications. IoT devices and predictive analytics will also be assessed for their impact on delivery performance. This study concludes with the benefits and drawbacks of delivery area/zone labeling. Delivery time, operational expenses, and customer experience improve. Fulfillment focuses face data privacy, algorithmic biases, and system scalability issues. In conclusion, this study examines fulfillment center delivery area/zone labeling for last-mile delivery orders. E-commerce and logistics stakeholders may maximize last-mile delivery by knowing the different methods, technology, and factors affecting them.",
        "keywords": "",
        "link": "http://dx.doi.org/10.58344/jws.v2i7.340"
    },
    {
        "id": 26359,
        "title": "Advanced Automated Tagging for Stack Overflow: A Multi-Stage Approach Using Deep Learning and NLP Techniques",
        "authors": "Isun Chehreh, Ebrahim Ansari, Bahram Sadeghi Bigham",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aisp61396.2024.10475258"
    },
    {
        "id": 26360,
        "title": "THE ROLE OF GAME TECHNIQUES IN TEACHING SPEECH CULTURE IN THE PHILOLOGICAL FIELD",
        "authors": "Mamatkulova Nilufar Boyzak kizi,  ",
        "published": "2024-4-1",
        "citations": 0,
        "abstract": "This article explores the role of game techniques in the process of teaching speech culture in the philological field. It highlights the relevance of using game approaches in educational practice in order to effectively develop students' communication  skills.  The  author  analyzes  the  basic  principles  and  methods  of  game  learning,  revealing  their applicability  and  effectiveness  in  the  context  of  the  formation  of  speech  culture.  The  pedagogical  aspects  of  the introduction of game techniques into the educational process of philological specialties, including the selection and adaptation  of  game  tasks,  evaluation  and  monitoring  of  results,  are  also  considered.  The  results  of  the  study emphasize the importance of game techniques as a means of stimulating active communication, increasing students' motivation  to  study  speech  culture  and  developing  their  skills  of  language  adaptation  and  etiquette.  Possible obstacles  and  ways  to  overcome  them  when  introducing  game  approaches  into  the  educational  process  are  also analyzed. In general, the article represents an important contribution to the pedagogical practice of teaching speech culture in the philological field, justifying the need and prospects for using game techniques to achieve educational goals.",
        "keywords": "",
        "link": "http://dx.doi.org/10.37547/ijp/volume04issue04-05"
    },
    {
        "id": 26361,
        "title": "Speech Synthesis: An Empirical Analysis of Various Techniques in Text to Speech Generation",
        "authors": "Tushar H. Ghorpade, Subhash K. Shinde",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccubea58933.2023.10392008"
    },
    {
        "id": 26362,
        "title": "Heterogeneous Network Framework with Attention Mechanism of Speech Enhancement for Car Intelligent Cockpit Speech Recognition",
        "authors": "YingWei Tan, XueFeng Ding",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482915"
    },
    {
        "id": 26363,
        "title": "Direct observation on argon tagging nitrobenzene radical anion in gas phase: Infrared photodissociation spectroscopy and theoretical calculation",
        "authors": "Yanhui Liu, Guanjun Wang, Yanying Zhao",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.saa.2023.122482"
    },
    {
        "id": 26364,
        "title": "Charged Particles Pair Production in pp Scattering: Survival Factor and Proton Tagging",
        "authors": "S. I. Godunov",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1134/s1063779624010064"
    },
    {
        "id": 26365,
        "title": "Urdu Speech Emotion Recognition using Speech Spectral Features and Deep Learning Techniques",
        "authors": "Soonh Taj, Ghulam Mujtaba Shaikh, Saif Hassan,  Nimra",
        "published": "2023-3-17",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icomet57998.2023.10099289"
    },
    {
        "id": 26366,
        "title": "Keynote Speech III: Sustainable Artificial Intelligence",
        "authors": "Robert Kozma",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icotl59758.2023.10435337"
    },
    {
        "id": 26367,
        "title": "NOVEL DIGITAL TECHNIQUES FOR ECHO CANCELLATION APPLIED TO SPEECH SIGNALS",
        "authors": "N KARIMIAN, P GAYDECKI",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25144/16365"
    },
    {
        "id": 26368,
        "title": "SICRN: Advancing Speech Enhancement through State Space Model and Inplace Convolution Techniques",
        "authors": "Changjiang Zhao, Shulin He, Xueliang Zhang",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446396"
    },
    {
        "id": 26369,
        "title": "Detection of Emotions from Speech using Deep Learning Techniques and Traditional Techniques: A Survey",
        "authors": "Rashmi Rani, Manoj Kumar Ramaiya",
        "published": "2023-12-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icacrs58579.2023.10404716"
    },
    {
        "id": 26370,
        "title": "RESULTS OF AN EXERCISE TO COLLECT 'GENUINE' SPOKEN ENQUIRIES USING WOZ TECHNIQUES",
        "authors": "RK MOORE, SR BROWNING",
        "published": "2024-4-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25144/20946"
    },
    {
        "id": 26371,
        "title": "Problems on Tagging of Parts of Speech of Chinese Two- Syllable Body Compound-Focused on Verb and Adjective",
        "authors": "Sunhee Lee,  ",
        "published": "2023-3-25",
        "citations": 0,
        "abstract": "This paper analyzed the partiality of 42 two-syllable body compound words with different parts of speech as verbs and adjectives in various dictionaries through the modification of adverbs of degree. Type A body compound words consist of a subject predicate structure except for three predicate object structures. It is difficult to say that this type of compound word is lexicalized as a typical adjective because it is found that it receives little modification of adverbs of degree. Type B body compound words consist of predicate object structures, and it is a general view that as the internal closeness increases, they have been lexically converted from predicate object phrases into heterologous verbs. Many of these compound words can be seen as verb adjectives and concurrent verbs because they are relatively actively modified by adverbs of degree. The internal closeness of Chinese compound words is generally higher in the predicate object structure than the subject predicate structure. As the lexical progress of the predicate object structure with high internal closeness is more active, it is thought that type B compound words are more formulated by adverbs of degree.",
        "keywords": "",
        "link": "http://dx.doi.org/10.14342/smog.2023.117.111"
    },
    {
        "id": 26372,
        "title": "Comparative analysis of various feature extraction techniques for classification of speech disfluencies",
        "authors": "Nitin Mohan Sharma, Vikas Kumar, Prasant Kumar Mahapatra, Vaibhav Gandhi",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.specom.2023.04.003"
    },
    {
        "id": 26373,
        "title": "Speech Enhancement using Deep Learning Techniques",
        "authors": "Ghanta Pavankalyan -, Gowtham Bobbili -",
        "published": "2024-3-6",
        "citations": 0,
        "abstract": "In current era of digital technology, speech enhancement has become one of the important challenges in day-to-day life for smoother conversation and understanding. Most of the recorded or live speech audio signals contain some form of noise such as street noise, barking sounds of dogs, conversation between multiple people, construction noise, car honking etc. The key feature of speech enhancement system is to execute in real time on a recorded waveform with minimal possible lag on any localized hardware with minimum computational \nresource.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36948/ijfmr.2024.v06i02.12384"
    },
    {
        "id": 26374,
        "title": "Data analysis in the ICARUS (SBN FD) Cosmic Ray Tagging system",
        "authors": "Anna Heggestuen",
        "published": "2024-1-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2172/2282439"
    },
    {
        "id": 26375,
        "title": "Natural Language Processing of A. Chekhov’s literary texts and of their English-language translation versions based on the methods of lemmatization and part-of-speech tagging",
        "authors": "E. A. Morozkina,  , A. D. Kornilova,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.33184/dokbsu-2023.2.8"
    },
    {
        "id": 26376,
        "title": "Enhancing Content Creation Workflows through Automatic Speech Recognition Techniques",
        "authors": "Randy Fayan, Zahra Montajabi, Rob Gonsalves",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5594/m002027"
    },
    {
        "id": 26377,
        "title": "Comparison of Data Augmentation Techniques on Filipino ASR for Children’s Speech",
        "authors": "Cathlyn Abion, Niel Carlo Lumapag, John Cairu Ramirez, Christchelle Resulto, Crisron Rudolf Lucas",
        "published": "2023-10-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sped59241.2023.10314952"
    },
    {
        "id": 26378,
        "title": "Part V Keynote Speech",
        "authors": "",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/apap59666.2023.10348500"
    },
    {
        "id": 26379,
        "title": "Analysis and Classification of Dysarthric Speech",
        "authors": "Vartika Tyagi, Amita Dev, Poonam Bansal",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482956"
    },
    {
        "id": 26380,
        "title": "IIITH MM2 Speech-Text: A preliminary data for automatic spoken data validation with matched and mismatched speech-text content",
        "authors": "Nayan Anand, Meenakshi Sirigiraju, Chiranjeevi Yarra",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482966"
    },
    {
        "id": 26381,
        "title": "Waveform based speech coding using nonlinear predictive techniques: a systematic review",
        "authors": "Gebremichael Kibret Sheferaw, Waweru Mwangi, Michael Kimwele, Adane Mamuye",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10772-023-10072-7"
    },
    {
        "id": 26382,
        "title": "Analysis of Non-Matching Reference Approach to Predict Speech Intelligibility",
        "authors": "A K Punnoose",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482980"
    },
    {
        "id": 26383,
        "title": "Exploration of Speech Rhythm in Deori L1 and L2",
        "authors": "Krisangi Saikia, Shakuntala Mahanta",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482990"
    },
    {
        "id": 26384,
        "title": "A STUDY OF VOCAL TRACT SHAPES USING MAGNETIC RESONANCE IMAGING AND ACOUSTIC REFLECTANCE TECHNIQUES",
        "authors": "JW DEVANEY, CC GOODYEAR",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25144/20325"
    },
    {
        "id": 26385,
        "title": "Efficacy of Current Dysarthric Speech Recognition Techniques",
        "authors": "Medha Malik, Ruqaiya Khanam",
        "published": "2023-12-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icacctech61146.2023.00111"
    },
    {
        "id": 26386,
        "title": "Improving Speech Emotion Recognition Using Data Augmentation and Balancing Techniques",
        "authors": "Chawki Barhoumi, Yassine Ben Ayed",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cw58918.2023.00051"
    },
    {
        "id": 26387,
        "title": "Tagging Neutrino Events with the SBND&amp;#x27;s Photon Detection System",
        "authors": "Francisco Nicolas Arnaldos",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2172/1993173"
    },
    {
        "id": 26388,
        "title": "Cross-Modal Fusion Techniques for Utterance-Level Emotion Recognition from Text and Speech",
        "authors": "Jiachen Luo, Huy Phan, Joshua Reiss",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10096885"
    },
    {
        "id": 26389,
        "title": "Automatic Speech Recognition using Machine Learning Techniques",
        "authors": "Ashutosh Shukla, Amrit Aanand, S. Nithiya",
        "published": "2023-1-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccci56745.2023.10128212"
    },
    {
        "id": 26390,
        "title": "Comparative Analysis of Direct Speech-to-Speech Translation and Voice Conversion Using Bi-LSTM",
        "authors": "Lalaram Arya, Sai Naga Venu Gopal Bhamidi, Shashi Prabha, S. R. Mahadeva Prasanna",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482964"
    },
    {
        "id": 26391,
        "title": "On occupying the silent parenthetical: Thinking-feeling after the Ends/ings (Part 1/2)",
        "authors": "Matthew Houdek",
        "published": "2024-3-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/00335630.2024.2330584"
    },
    {
        "id": 26392,
        "title": "Keynote Speech II: Healthcare and machine learning - a symbiotic relationship",
        "authors": "Sanghamitra Bandyopadhyay",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icotl59758.2023.10435130"
    },
    {
        "id": 26393,
        "title": "Feature Comparison for Speech Emotion Recognition on Hindi Language",
        "authors": "Surbhi Khurana, Amita Dev, Poonam Bansal",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482951"
    },
    {
        "id": 26394,
        "title": "Leveraging Speech Recognition for Smart Urban Last Mile Connectivity Enhancement",
        "authors": "Kanwar Dimple Singh, Rashmi Ashtt",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482920"
    },
    {
        "id": 26395,
        "title": "Rus dilbilimcilerin Rusça sözcük türlerine bakış açısı ve zamirlerin sözcük türleri bağlamında statü problemi",
        "authors": "Ali AKYAR",
        "published": "2023-2-21",
        "citations": 0,
        "abstract": "Bu çalışmada, Rus dilindeki sözcük türlerine dilbilimcilerin bakış açıları, sınıflandırmaları ve bu sınıflandırma çerçevesinde zamirlerin statüleriyle ilgili araştırma yapılmıştır.   Çalışmamız, tarihsel, karşılaştırma, inceleme-değerlendirme, betimleme ve sınıflandırma yöntemleri çerçevesinde yürütülmüş ve belirtilen yöntemler sayesinde konuyla ilgili bulgular elde edilmiştir. Elde ettiğimiz bulgular neticesinde dilbilimcilerin sözcüğe ve sözcük türlerine bakış açıları, sözcük türlerinin sınıflandırılması ve gelişim evresi araştırılmıştır. Bu araştırmalar sonucunda dilbilimcilerin sözcük türlerinin tasnifi konusunda farklı bakış açılarına sahip olduğu tespit edilmiş ve bu sınıflandırma farklılığından ötürü zamirlerin hangi kategoride değerlendirilmesi gerektiğiyle ilgili bir sorun olduğu ortaya çıkmıştır. Zamirlerin sözcük türü bağlamında statü sorunu, Rusça öğrenen Türk öğrenciler için bir öğrenim zorluğu olarak karşımıza çıkmaktadır. Bu çalışma, bahsi geçen probleme çözüm yolları sunma amacıyla hazırlanmıştır. Çalışmada yaptığımız incelemelerle, Rus dilinde sözcüklerin dilbilimciler tarafından farklı şekillerde sınıflandırma sorununun temel sebepleri arasında, sözcüklerin farklı kelime gruplarıyla bağımlı olmaları ve bu bağımlılıktan kaynaklanan benzerlik sorunlarının gösterildiği tespit edilmiştir. Zamirler; isim, sıfat, sayı gibi sözcük türleriyle bir bağıntı içerisindedir. Lakin bu ilişkileri zamirlerin bahsi geçen sözcük türleri arasında bölüştürülme sebeplerini haklı kılmamaktadır. Zamirler, konuşma ve yazı dili için oldukça önemli ve özel sözcüklerdir. Bu önemi ortaya çıkarmak ve sözcük türleri tasnifinde zamirlerin hak ettiği statülerinin belirlenmesi için bu özel kelime grubunun yapısal özelliklerinden ziyade anlamsal özelliklerinin temel alınması gerekmektedir. Bu çıkarımla zamirler çalışmamızda bağımsız sözcük türü olarak değerlendirilmiştir. Dilbilimcilerin sözcük türlerine bakış açıları ve zamirlerin bu kategorideki statüsü ile ilgili araştırmamıza ait bulgular çalışmamızın sonuç bölümünde verilmiştir.",
        "keywords": "",
        "link": "http://dx.doi.org/10.29000/rumelide.1252893"
    },
    {
        "id": 26396,
        "title": "Designing an IVR-based Speech Data Collection Framework for building Realistic Speech Corpus on Forensic Automatic Speaker Recognition",
        "authors": "Soma Khan, Joyanta Basu, Milton S. Bepari, Madhab Pal, Rajib Roy",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482934"
    },
    {
        "id": 26397,
        "title": "Designing and Developing a Marathi Speech Database for Native and Non-Native Emotional Speech in the Marathi Language",
        "authors": "Bharati D. Borade, Ratnadeep R. Deshmukh, Santosh K. Maher, Swapnil Waghmare",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482952"
    },
    {
        "id": 26398,
        "title": "Evaluation of Assamese Speech Data Transcriptions by Levenshtein Distance",
        "authors": "Rajesha N., Rejitha K. S., Narayan Kumar Choudhary",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482939"
    },
    {
        "id": 26399,
        "title": "Using Objective Speech Analysis Techniques for the Clinical Diagnosis and Assessment of Speech Disorders in Patients with Multiple Sclerosis",
        "authors": "Zeynep Z. Sonkaya, Bilgin Özturk, Rıza Sonkaya, Esra Taskiran, Ömer Karadas",
        "published": "2024-4-16",
        "citations": 0,
        "abstract": "Multiple sclerosis (MS) is one of the chronic and neurodegenerative diseases of the central nervous system (CNS). It generally affects motor, sensory, cerebellar, cognitive, and language functions. It is thought that identifying MS speech disorders using quantitative methods will make a significant contribution to physicians in the diagnosis and follow-up of MS patients. In this study, it was aimed to investigate the speech disorders of MS via objective speech analysis techniques. The study was conducted on 20 patients diagnosed with MS according to McDonald’s 2017 criteria and 20 healthy volunteers without any speech or voice pathology. Speech data obtained from patients and healthy individuals were analyzed with the PRAAT speech analysis program, and classification algorithms were tested to determine the most effective classifier in separating specific speech features of MS disease. As a result of the study, the K-nearest neighbor algorithm (K-NN) was found to be the most successful classifier (95%) in distinguishing pathological sounds which were seen in MS patients from those in healthy individuals. The findings obtained in our study can be considered as preliminary data to determine the voice characteristics of MS patients.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/brainsci14040384"
    },
    {
        "id": 26400,
        "title": "CTC-Based End-to-End Speech Recognition for Low Resource Language Sanskrit",
        "authors": " Suhani, Amita Dev, Poonam Bansal",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482943"
    },
    {
        "id": 26401,
        "title": "THE USE OF BINAURAL RECORDING TECHNIQUES IN THE ASSESSMENT OF SPEECH INTELLIGIBILITY USING WORD SCORES ON LONDON UNDERGROUND",
        "authors": "PW BARNETT",
        "published": "2024-3-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25144/20634"
    },
    {
        "id": 26402,
        "title": "The Development of a Thai Telephone Conversational Speech Corpus",
        "authors": "Sumonmas Thatphithakkul, Kwanchiva Thangthai, Sahatsawat Sriphol, Vataya Chunwijitra",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482925"
    },
    {
        "id": 26403,
        "title": "Speech Dataset Development for a Low-Resource Tibeto-Burman Tonal Language",
        "authors": "Thiyam Susma Devi, Pradip K. Das",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482932"
    },
    {
        "id": 26404,
        "title": "Speech Enhancement And Noise Reduction In Forensic Applications",
        "authors": "Surbhi Bharti, Prerna Jha, Medha Arora, Ashwni Kumar",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482986"
    },
    {
        "id": 26405,
        "title": "Mosque as a Bilingual Space – an Investigation on Speech Intelligibility in Mosque Acoustics Using Simulation Techniques",
        "authors": "",
        "published": "2023-7-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.24425/aoa.2021.138131"
    },
    {
        "id": 26406,
        "title": "Signal processing techniques used in speech recognition or synthesis. An overview",
        "authors": "Ivan Ralev, Georgi Krastev",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/telecom59629.2023.10409734"
    },
    {
        "id": 26407,
        "title": "Speech Recognition Using Machine Learning Techniques",
        "authors": "Arya Mishra, Namrata Dhanda, Kapil Kumar Gupta, Rajat Verma",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdt61202.2024.10489508"
    },
    {
        "id": 26408,
        "title": "NITK-KLESC: Kannada Language Emotional Speech Corpus for Speaker Recognition",
        "authors": "Shalini Tomar, Pragya Gupta, Shashidhar G Koolagudi",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482961"
    },
    {
        "id": 26409,
        "title": "A measure of differences in speech signals by the voice timbre",
        "authors": "V. V. Savchenko",
        "published": "2024-3-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11018-024-02294-1"
    },
    {
        "id": 26410,
        "title": "Evaluation of double acoustic tagging techniques to track American shad Alosa sapidissima movements at multiple spatial scales",
        "authors": "Aaron J. Bunch, James P. Henne, Dennis R. DeVries, Russell A. Wright, David L. Smith, Troy M. Farmer",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.fishres.2023.106636"
    },
    {
        "id": 26411,
        "title": "How Crowd Worker Factors Influence Subjective Annotations: A Study of Tagging Misogynistic Hate Speech in Tweets",
        "authors": "Danula Hettiachchi, Indigo Holcombe-James, Stephanie Livingstone, Anjalee De Silva, Matthew Lease, Flora D. Salim, Mark Sanderson",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "Crowdsourced annotation is vital to both collecting labelled data to train and test automated content moderation systems and to support human-in-the-loop review of system decisions. However, annotation tasks such as judging hate speech are subjective and thus highly sensitive to biases stemming from annotator beliefs, characteristics and demographics. We conduct two crowdsourcing studies on Mechanical Turk to examine annotator bias in labelling sexist and misogynistic hate speech. Results from 109 annotators show that annotator political inclination, moral integrity, personality traits, and sexist attitudes significantly impact annotation accuracy and the tendency to tag content as hate speech. In addition, semi-structured interviews with nine crowd workers provide further insights regarding the influence of subjectivity on annotations. In exploring how workers interpret a task — shaped by complex negotiations between platform structures, task instructions, subjective motivations, and external contextual factors — we see annotations not only impacted by worker factors but also simultaneously shaped by the structures under which they labour.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1609/hcomp.v11i1.27546"
    },
    {
        "id": 26412,
        "title": "Detecting Hate Speech in Hindi in Online Social Media",
        "authors": "Anushka Sharma, Rishabh Kaushal",
        "published": "2023-1-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icct56969.2023.10075749"
    },
    {
        "id": 26413,
        "title": "Enhancing Speech Emotion Recognition Through Multimodal Fusion and Advanced Feature Extraction Techniques",
        "authors": "Amitava Choudhury, Tanmay Bhowmik",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/incoft60753.2023.10425376"
    },
    {
        "id": 26414,
        "title": "Speech recognition-based packaging design techniques and graphic design",
        "authors": "Wenhua Fan",
        "published": "2024-1-1",
        "citations": 0,
        "abstract": "Abstract\nUsing speech recognition for packaging design is an effective way to enhance designers’ creative inspiration. Based on speech recognition technology, this paper constructs a speech recognition model with speech pre-emphasis, Hamming window split-frame plus window, and MFCC feature parameters and evaluates and analyzes the model. Then, the package design techniques and the functions of package graphics are explained in detail, and the quantitative analysis of data from package design techniques and package graphics design is carried out using the speech recognition model. The speech recognition model can recognize sixteen package design techniques in package design techniques, and the maximum and minimum recognition rates are 33.53% and 18.6%, respectively. The speech recognition model can recognize thirteen packaging graphic design keywords in packaging graphic design, with maximum and minimum recognition rates of 40.51% and 23.88%, respectively. Based on the speech recognition model, various packaging design techniques can be effectively recognized, which is conducive to enhancing designers’ inspiration in creating product packaging and promoting more innovative product packaging graphics.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2478/amns.2023.2.00143"
    },
    {
        "id": 26415,
        "title": "SPIRE-SIES: A Spontaneous Indian English Speech Corpus",
        "authors": "Abhayjeet Singh, Charu Shah, Rajashri Varadaraj, Sonakshi Chauhan, Prasanta Kumar Ghosh",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482940"
    },
    {
        "id": 26416,
        "title": "Few-shot meta multilabel classifier for low resource accented code-switched speech",
        "authors": "Sreeja Manghat, Sreeram Manghat, Tanja Schultz",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482982"
    },
    {
        "id": 26417,
        "title": "Fine-tuning the Wav2Vec2 Model for Automatic Speech Emotion Recognition System",
        "authors": "Devendra Kayande, Indra Ballav Sonowal, Ramesh K. Bhukya",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482992"
    },
    {
        "id": 26418,
        "title": "INTO_CASS_HEFEI: A Speech Corpus for Intonation and Prosody Study of Hefei Chinese",
        "authors": "Aijun Li, Yuan Ye, Ziyu Xiong",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482928"
    },
    {
        "id": 26419,
        "title": "Speech Recognition Applications in Enhancing Safety for Women in Built Environment",
        "authors": "Mani Gupta, Rashmi Ashtt, Monali Wankar, Ajay Monga",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482912"
    },
    {
        "id": 26420,
        "title": "Empirical Analysis of Machine Learning Models on Parkinson’s Speech Dataset",
        "authors": "Bhavika Sachdeva, Harshita Rathee, Pooja Gambhir, Poonam Bansal",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482963"
    },
    {
        "id": 26421,
        "title": "\"Enhancing Efficiency and Conservation via Speech Processing in Lutyens's Delhi Residential Revitalization\"",
        "authors": "Ar. Shweta Sharma, Rashmi Ashtt, Monali Wankar",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482994"
    },
    {
        "id": 26422,
        "title": "Paralinguistic and spectral feature extraction for speech emotion classification using machine learning techniques",
        "authors": "Tong Liu, Xiaochen Yuan",
        "published": "2023-5-15",
        "citations": 1,
        "abstract": "AbstractEmotion plays a dominant role in speech. The same utterance with different emotions can lead to a completely different meaning. The ability to perform various of emotion during speaking is also one of the typical characters of human. In this case, technology trends to develop advanced speech emotion classification algorithms in the demand of enhancing the interaction between computer and human beings. This paper proposes a speech emotion classification approach based on the paralinguistic and spectral features extraction. The Mel-frequency cepstral coefficients (MFCC) are extracted as spectral feature, and openSMILE is employed to extract the paralinguistic feature. The machine learning techniques multi-layer perceptron classifier and support vector machines are respectively applied into the extracted features for the classification of the speech emotions. We have conducted experiments on the Berlin database to evaluate the performance of the proposed approach. Experimental results show that the proposed approach achieves satisfied performances. Comparisons are conducted in clean condition and noisy condition respectively, and the results indicate better performance of the proposed scheme.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s13636-023-00290-x"
    },
    {
        "id": 26423,
        "title": "Research on Error Handling Techniques for Speech Interaction",
        "authors": "Rui Ma, Xuechao Zou, Pin Tao, Yixiang Tu",
        "published": "2023-9-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccs59700.2023.10335595"
    },
    {
        "id": 26424,
        "title": "Application of Speech Recognition Translator based on Evolutionary Multi-objective Optimization Algorithm",
        "authors": "Liyuan Liu",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/easct59475.2023.10392501"
    },
    {
        "id": 26425,
        "title": "Staging Sex: Best Practices, Tools, and Techniques for Theatrical Intimacy\n            <b>Staging Sex: Best Practices, Tools, and Techniques for Theatrical Intimacy</b>\n            , Chelsea Pace, with contributions from Laura Rikard, New York, United States of America, Routledge, 2020, 123 p., US $35.96 (paperback), ISBN 978-1-138-59648-1",
        "authors": "Heidi Malazdrewich",
        "published": "2023-11-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/23268263.2023.2278242"
    },
    {
        "id": 26426,
        "title": "Improving Hate Speech Detection: The Impact of Semantic Representations and Preprocessing Techniques",
        "authors": "Necva Bölücü, Aysegül Özerdem",
        "published": "2023-7-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/siu59756.2023.10224051"
    },
    {
        "id": 26427,
        "title": "Preface: Colorectal Cancer Screening Part II",
        "authors": "Aasma Shaukat",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.tige.2023.07.002"
    },
    {
        "id": 26428,
        "title": "Preface: Colorectal Cancer Screening Part I",
        "authors": "Aasma Shaukat",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.tige.2023.03.004"
    },
    {
        "id": 26429,
        "title": "Can AI Powered Speech-to-Text and Text-to-Speech techniques limit the interviewer bias in sensory and consumer research?",
        "authors": "Hester Kreuzen, Daniëlle Dull, Vera de Rover, Rignald Span",
        "published": "2023-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.foodqual.2023.104828"
    },
    {
        "id": 26430,
        "title": "ArmSpeech-POS: Eastern Armenian Part-of-Speech Tagged Corpus",
        "authors": "Varuzhan H. Baghdasaryan",
        "published": "2023",
        "citations": 0,
        "abstract": "Text chunking, Part-of-speech (POS) tagging, and named entity recognition (NER) are fundamental tasks in natural language processing (NLP). Part-of-speech (POS) tagging involves assigning grammatical labels to words in a sentence. Research shows that Armenian is a low-resourced language and there are not enough materials for developing higher accurate part-of-speech tagging systems in the Armenian language. This paper presents a fresh dataset for POS tagging in Armenian that follows the naming conventions of both Penn Treebank and Universal Dependencies tagsets, with two versions available. The dataset consists of 6081 sentences that were automatically annotated and then manually verified. The data was sourced from Armenian news websites, focusing on topics such as culture, medicine, and lifestyle, as well as 22 Armenian fairytales. The reason for having two versions of the POS tagset was to ensure compatibility and integration with all-natural language processing tools and models that use these standards. By standardizing the tagset, it becomes easier to compare and evaluate the effectiveness of different POS tagging models. The paper also describes data collection, cleaning, preprocessing, and processing steps. The ISMA translator was used for the annotation of the dataset, which not only performs machine translation but also conducts a syntactic and semantic analysis of the text and assigns a POS tag for each word in the sentence. The final corpus contains 13 groups of part-of-speech tags and a total of 57160 tagged tokens including the distinction between singular and plural parts of speech.",
        "keywords": "",
        "link": "http://dx.doi.org/10.51542/ijscia.v4i2.19"
    },
    {
        "id": 26431,
        "title": "Characterization of Deep Learning-Based Speech-Enhancement Techniques in Online Audio Processing Applications",
        "authors": "Caleb Rascon",
        "published": "2023-4-29",
        "citations": 3,
        "abstract": "Deep learning-based speech-enhancement techniques have recently been an area of growing interest, since their impressive performance can potentially benefit a wide variety of digital voice communication systems. However, such performance has been evaluated mostly in offline audio-processing scenarios (i.e., feeding the model, in one go, a complete audio recording, which may extend several seconds). It is of significant interest to evaluate and characterize the current state-of-the-art in applications that process audio online (i.e., feeding the model a sequence of segments of audio data, concatenating the results at the output end). Although evaluations and comparisons between speech-enhancement techniques have been carried out before, as far as the author knows, the work presented here is the first that evaluates the performance of such techniques in relation to their online applicability. This means that this work measures how the output signal-to-interference ratio (as a separation metric), the response time, and memory usage (as online metrics) are impacted by the input length (the size of audio segments), in addition to the amount of noise, amount and number of interferences, and amount of reverberation. Three popular models were evaluated, given their availability on public repositories and online viability, MetricGAN+, Spectral Feature Mapping with Mimic Loss, and Demucs-Denoiser. The characterization was carried out using a systematic evaluation protocol based on the Speechbrain framework. Several intuitions are presented and discussed, and some recommendations for future work are proposed.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23094394"
    },
    {
        "id": 26432,
        "title": "Age and Gender Estimation Through Speech: A Comparison of Various Techniques",
        "authors": "Maliha Shabbir, Amjad Hussain, Maqsood Muhammad Khan",
        "published": "2023-11-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icet59753.2023.10374670"
    },
    {
        "id": 26433,
        "title": "Early dementia detection with speech analysis and machine learning techniques",
        "authors": "Zerin Jahan, Surbhi Bhatia Khan, Mo Saraee",
        "published": "2024-4-11",
        "citations": 0,
        "abstract": "AbstractThis in-depth study journey explores the context of natural language processing and text analysis in dementia detection, revealing their importance in a variety of fields. Beginning with an examination of the widespread and influence of text data. The dataset utilised in this study is from TalkBank's DementiaBank, which is basically a vast database of multimedia interactions built with the goal of examining communication patterns in the context of dementia. The various communication styles dementia patients exhibit when communicating with others are seen from a unique perspective by this specific dataset. Thorough data preprocessing procedures, including cleansing, tokenization, and structuring, are undertaken, with a focus on improving prediction capabilities through the combination of textual and non-textual information in the field of feature engineering. In the subsequent phase, the precision, recall, and F1-score metrics of Support Vector Machines (SVM), K-Nearest Neighbours (KNN), Random Forest, and Artificial Neural Networks (ANN) are assessed. Empirical facts are synthesized using text analysis methods and models to formulate a coherent conclusion. The significance of text data analysis, the revolutionary potential of natural language processing, and the direction for future research are highlighted in this synthesis. Throughout this paper, readers are encouraged to leverage text data to embark on their own adventures in the evolving, data-centric world of dementia detection.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43621-024-00217-2"
    },
    {
        "id": 26434,
        "title": "Hate Speech Detection in Roman Urdu using Machine Learning Techniques",
        "authors": "Sarah Nasir, Ayesha Seerat, Muhammad Wasim",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icacs60934.2024.10473250"
    },
    {
        "id": 26435,
        "title": "Deep learning based fusion strategies for hate speech detection to combine the classifiers to improve classification performance",
        "authors": "G. Rajavikram, Mahesh Nemuragomula",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0161653"
    },
    {
        "id": 26436,
        "title": "Speech Сulture in the Professional Activities of a Lawyer: Methodological Techniques for Teaching Legal Writing",
        "authors": "Svetlana Doronina",
        "published": "2023-4-1",
        "citations": 0,
        "abstract": "The article describes the experience of teaching the course \"Fundamentals of Legal Writing\" to students of the training program \"Jurisprudence\". The teaching is based on the analysis of grammatical errors made by compilers of texts of jurisdictional genres. The undertaken functional approach to learning made it possible to establish that, depending on the type of speech generated (narration, reasoning, description), writers experience various difficulties. Thus, the learning tasks of the course are divided into three groups. The first is aimed at mastering the rules for constructing grammatical models inherent to official business speech (nominal, semi-predicative and passive constructions). The second is aimed at mastering effective ways of narrating about the circumstances of the offense. The skills being formed are focused on compiling interrogation protocols. The third group of exercises is aimed at mastering models of reasoning about the causal relationship of facts and the relationship between the event of an offense and legal norms. This skill is necessary when issuing decisions, sentences, judicial acts, etc. It is noted that the description as a type of speech is found in drawing up protocols of inspecting objects or documents and accounts for mainly speech errors associated with the selection of lexical means.",
        "keywords": "",
        "link": "http://dx.doi.org/10.14258/leglin(2023)2715"
    },
    {
        "id": 26437,
        "title": "Adversarial Example Detection Techniques in Speech Recognition Systems: A review",
        "authors": "Khalid Noureddine, Hamza Kheddar, Mohamed Maazouz",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ic2em59347.2023.10419688"
    },
    {
        "id": 26438,
        "title": "Unearthing “Vocal Transparency” Part Two: The Integration of the Miller Voice Method and the Michael Chekhov Technique—Breath for Transformation",
        "authors": "Kristi Dana",
        "published": "2023-10-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/23268263.2023.2272553"
    },
    {
        "id": 26439,
        "title": "The Telovelar Approach: Part 2—Surgical Techniques",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1097/01.cne.0000920228.30424.d9"
    },
    {
        "id": 26440,
        "title": "Leveraging Cross Lingual Speech Representations To Build ASR For Under-resourced Languages",
        "authors": "Sougata Mukherjee, Prashant Bannulmath, Deepak K T, S. R. Mahadeva Prasanna",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482936"
    },
    {
        "id": 26441,
        "title": "\"The Potential of Speech Technology to Enhance the Quality of Life in Historic Cities\"",
        "authors": "Shivani Goel, Rashmi Ashtt, Monali Wankar, Prasoon Gupta",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482924"
    },
    {
        "id": 26442,
        "title": "Speech Emotion Recognition Using Deep Neural Networks, Transfer Learning, and Ensemble Classification Techniques",
        "authors": "Serban MIHALACHE,  , Dragos BURILEANU,  ,  ",
        "published": "2023-9-29",
        "citations": 0,
        "abstract": "Speech emotion recognition (SER) is the task of determining the affective content present in speech, a promising research area of great interest in recent years, with important applications especially in the field of forensic speech and law enforcement operations, among others. In this paper, systems based on deep neural networks (DNNs) spanning five levels of complexity are proposed, developed, and tested, including systems leveraging transfer learning (TL) for the top modern image recognition deep learning models, as well as several ensemble classification techniques that lead to significant performance increases. The systems were tested on the most relevant SER datasets: EMODB, CREMAD, and IEMOCAP, in the context of: (i) classification: using the standard full sets of emotion classes, as well as additional negative emotion subsets relevant for forensic speech applications; and (ii) regression: using the continuously valued 2D arousal-valence affect space. The proposed systems achieved state-of-the-art results for the full class subset for EMODB (up to 83% accuracy) and performance comparable to other published research for the full class subsets for CREMAD and IEMOCAP (up to 55% and 62% accuracy). For the class subsets focusing only on negative affective content, the proposed solutions offered top performance vs. previously published state of the art results.",
        "keywords": "",
        "link": "http://dx.doi.org/10.59277/romjist.2023.3-4.10"
    },
    {
        "id": 26443,
        "title": "Automated Diagnosis of Parkinson’s Disease using Speech Signals with Machine Learning",
        "authors": "Parul Mann, Anmol Jha, Ritu Rani, Garima Jaiswal, Arun Sharma, Amita Dev",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482972"
    },
    {
        "id": 26444,
        "title": "Source Separation of Piano Concertos Using Musically Motivated Augmentation Techniques",
        "authors": "Yigitcan Özer, Meinard Müller",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/taslp.2024.3356980"
    },
    {
        "id": 26445,
        "title": "Enhancing Speech Quality in Air Traffic Control Communication Using DIUnet_V-Based Speech Enhancement Techniques",
        "authors": "Haijun LIANG, Yukun LI, Jianguo KONG, Qicong HAN, Chengyu YU",
        "published": "2024-4-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1587/transinf.2023edp7110"
    },
    {
        "id": 26446,
        "title": "A Review of multi-modal speech emotion recognition and various techniques used to solve emotion recognition on speech data",
        "authors": "Venkata Naga Pavani Sai Suchitra Nanduri, Chinmai Sagiri, S Satya Siva Manasa, Raavi Sanvithatesh, Ashwin M",
        "published": "2023-8-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icirca57980.2023.10220691"
    },
    {
        "id": 26447,
        "title": "Detecting Parkinson's disease from Speech signals using Boosting Ensemble Techniques",
        "authors": "P. Deepa, Rashmita Khilar",
        "published": "2023-1-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceconf57129.2023.10083634"
    },
    {
        "id": 26448,
        "title": "O-COCOSDA 2023 Contents",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482917"
    },
    {
        "id": 26449,
        "title": "Improving in-text citation reason extraction and classification using supervised machine learning techniques",
        "authors": "Imran Ihsan, Hameedur Rahman, Asadullah Shaikh, Adel Sulaiman, Khairan Rajab, Adel Rajab",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.csl.2023.101526"
    },
    {
        "id": 26450,
        "title": "Real-time Hate Speech Detection in Live Streaming Platforms using Quantum Machine Learning",
        "authors": "Geetika Gupta, Karuna Kadian, Raksha Jain, Vimal Dwivedi, Arun Sharma",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482977"
    },
    {
        "id": 26451,
        "title": "Transforming Shahjahanabad into a Smart Heritage City Integrating Good Governance, Speech, and IoT Technologies for Sustainable Urban Development",
        "authors": "Rashmi Ashtt, Mayank Mathur",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482930"
    },
    {
        "id": 26452,
        "title": "Keynote Speech I: Representation and decomposition of functions in DAGDNNs and structural network pruning",
        "authors": "Wen-Liang Hwang",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icotl59758.2023.10435226"
    },
    {
        "id": 26453,
        "title": "TECHNIQUES FOR IMPROVING SPEECH INTELLIGIBILITY OF ESP STUDENTS",
        "authors": "Olena PYSARCHYK, Anna NYPADYMKA",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.24919/2308-4863/60-3-35"
    },
    {
        "id": 26454,
        "title": "O-COCOSDA 2023 Committees",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482922"
    },
    {
        "id": 26455,
        "title": "Feature Extraction Techniques for Deep Learning based Speech Classification",
        "authors": "Shreya Chakravarty, Richa R. Khandelwal, Kanchan M. Dhote",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10307237"
    },
    {
        "id": 26456,
        "title": "O-COCOSDA 2023 Panel Discussion",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482997"
    },
    {
        "id": 26457,
        "title": "O-COCOSDA 2023 Panel Discussion",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482955"
    },
    {
        "id": 26458,
        "title": "O-COCOSDA 2023 Panel Discussion",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482933"
    },
    {
        "id": 26459,
        "title": "Arabic Speech Recognition Based on Encoder-Decoder Architecture of Transformer",
        "authors": " Mohanad Sameer,  Ahmed Talib,  Alla Hussein",
        "published": "2023-3-21",
        "citations": 2,
        "abstract": "Recognizing and transcribing human speech has become an increasingly important task. Recently, researchers have been more interested in automatic speech recognition (ASR) using End to End models. Previous choices for the Arabic ASR architecture have been time-delay neural networks, recurrent neural networks (RNN), and long short-term memory (LSTM). Preview end-to-end approaches have suffered from slow training and inference speed because of the limitations of training parallelization, and they require a large amount of data to achieve acceptable results in recognizing Arabic speech This research presents an Arabic speech recognition based on a transformer encoder-decoder architecture with self-attention to transcribe Arabic audio speech segments into text, which can be trained faster with more efficiency. The proposed model exceeds the performance of previous end-to-end approaches when utilizing the Common Voice dataset from Mozilla. In this research, we introduced a speech-transformer model that was trained over 110 epochs using only 112 hours of speech. Although Arabic is considered one of the languages that are difficult to interpret by speech recognition systems, we achieved the best word error rate (WER) of 3.2 compared to other systems whose training requires a very large amount of data. The proposed system was evaluated on the common voice 8.0 dataset without using the language model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.51173/jt.v5i1.749"
    },
    {
        "id": 26460,
        "title": "O-COCOSDA 2023 Cover Page",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482953"
    },
    {
        "id": 26461,
        "title": "O-COCOSDA 2023 Panel Discussion",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482926"
    },
    {
        "id": 26462,
        "title": "O-COCOSDA 2023 Panel Discussion",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482983"
    },
    {
        "id": 26463,
        "title": "O-COCOSDA 2023 Welcome Message",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482950"
    },
    {
        "id": 26464,
        "title": "O-COCOSDA 2023 Panel Discussion",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482970"
    },
    {
        "id": 26465,
        "title": "Advancing Ethical and Accurate Hate Speech Detection with Machine Learning Techniques",
        "authors": "Jorge White",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.61137/ijsret.vol.10.issue2.135"
    },
    {
        "id": 26466,
        "title": "Beyond Words: Extracting Emotions from Speech with AI Techniques",
        "authors": "Pratham Taneja, Ronak Bhatia, Shivam Gaur, Juhi Priyani",
        "published": "2023-8-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/indiscon58499.2023.10270809"
    },
    {
        "id": 26467,
        "title": "O-COCOSDA 2023 Panel Discussion",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482954"
    },
    {
        "id": 26468,
        "title": "O-COCOSDA 2023 Panel Discussion",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482949"
    },
    {
        "id": 26469,
        "title": "O-COCOSDA 2023 Panel Discussion",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482923"
    },
    {
        "id": 26470,
        "title": "O-COCOSDA 2023 Panel Discussion",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482998"
    },
    {
        "id": 26471,
        "title": "Preliminary Diagnosis of COVID-19 using Speech Processing Techniques",
        "authors": "Niharika Yerramsetty, Kusupati Deekshitha, Mahathi Mantrala,  Latha",
        "published": "2023-2-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciscois56541.2023.10100482"
    },
    {
        "id": 26472,
        "title": "O-COCOSDA 2023 Panel Discussion",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482941"
    },
    {
        "id": 26473,
        "title": "O-COCOSDA 2023 Program Schedule",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482919"
    },
    {
        "id": 26474,
        "title": "O-COCOSDA 2023 Panel Discussion",
        "authors": "",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482999"
    },
    {
        "id": 26475,
        "title": "Self-supervision and Controlling Techniques to Improve Counter Speech Generation",
        "authors": "Punyajoy Saha",
        "published": "2023-2-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3539597.3572991"
    },
    {
        "id": 26476,
        "title": "Promoting Simple and Engaging Brain–Computer Interface Designs for Children by Evaluating Contrasting Motion Techniques",
        "authors": "Kevin M. Pitt, Zachary J. Cole, Joshua Zosky",
        "published": "2023-10-4",
        "citations": 0,
        "abstract": "\nPurpose:\nThere is an increasing focus on using motion in augmentative and alternative communication (AAC) systems. In considering brain–computer interface access to AAC (BCI-AAC), motion may provide a simpler or more intuitive avenue for BCI-AAC control. Different motion techniques may be utilized in supporting competency with AAC devices including simple (e.g., zoom) and complex (behaviorally relevant animation) methods. However, how different pictorial symbol animation techniques impact BCI-AAC is unclear.\n\n\nMethod:\nSixteen healthy children completed two experimental conditions. These conditions included highlighting of pictorial symbols via both functional (complex) and zoom (simple) animation to evaluate the effects of motion techniques on P300-based BCI-AAC signals and offline (predicted) BCI-AAC performance.\n\n\nResults:\nFunctional (complex) animation significantly increased attentional-related P200/P300 event-related potential (ERP) amplitudes in the parieto-occipital area. Zoom (simple) animation significantly decreased N400 latency. N400 ERP amplitude was significantly greater, and occurred significantly earlier, on the right versus left side for the functional animation condition within the parieto-occipital bin. N200 ERP latency was significantly reduced over the left hemisphere for the zoom condition in the central bin. As hypothesized, elicitation of all targeted ERP components supported offline (predicted) BCI-AAC performance being similar between conditions.\n\n\nConclusion:\nStudy findings provide continued support for the use of animation in BCI-AAC systems for children and highlight differences in neural and attentional processing between complex and simple animation techniques.\n\n\nSupplemental Material:\n\nhttps://doi.org/10.23641/asha.24085623\n\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.1044/2023_jslhr-23-00292"
    },
    {
        "id": 26477,
        "title": "Geo-Tagging of Images Using Photographing Time Synchronization",
        "authors": "Sang-Hyeon Yoo, Seung-Hee Han, Seung-Min Oh",
        "published": "2023-5-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5392/jkca.2023.23.05.041"
    },
    {
        "id": 26478,
        "title": "Comparative Analysis of NLP Techniques for Hate Speech Classification in Online Communications",
        "authors": "Gregorius Airlangga",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "This research aimed to compare the effectiveness of two Natural Language Processing (NLP) techniques—SpaCy's word embeddings and Sklearn's TF-IDF vectorization—in identifying hate speech within online comments. Utilizing a balanced dataset, each model was meticulously assessed on its ability to classify comments as 'hateful' or 'non-hateful'. The evaluation metrics employed were precision, recall, F1-score, and overall accuracy. The model using SpaCy's word embeddings achieved an accuracy of 65%, with equal precision and recall for both classes. The Sklearn's TF-IDF vectorization model, however, demonstrated superior performance with an overall accuracy of 75% and an enhanced ability to correctly identify hateful comments, evidenced by a 77% recall rate. This suggests that the TF-IDF model is more adept at discerning nuanced expressions of hate speech. The study's findings highlight the critical role of vectorization methods in the field of automated content moderation and stress the importance of continued innovation and model adaptation to effectively manage the evolving nature of online hate speech.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33379/gtech.v8i1.3959"
    },
    {
        "id": 26479,
        "title": "High-resolution superlet transform based techniques for Parkinson's disease detection using speech signal",
        "authors": "Kavita Bhatt, N. Jayanthi, Manjeet Kumar",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.apacoust.2023.109657"
    },
    {
        "id": 26480,
        "title": "A Comparative Analysis of Speech Enhancement Techniques Based on Sparsity Features",
        "authors": "Raj Kumar, Manoj Tripathy, R. S. Anand",
        "published": "2023-3-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/spin57001.2023.10116123"
    },
    {
        "id": 26481,
        "title": "IMPROVING THE IMAGE-TO-SPEECH SYSTEM ACCURACY THROUGH INTEGRATION OF OPTICAL CHARACTER RECOGNITION AND LANGUAGE PROCESSING TECHNIQUES",
        "authors": "K.H. Nikoghosyan, E.A. Harutyunyan, D.M. Galstyan",
        "published": "2023",
        "citations": 0,
        "abstract": "Image-to-speech systems are a type of technology allowing for the conversion of visual information, such as images or videos, into auditory output. These systems use complex algorithms and machine learning techniques to recognize and describe visual content, allowing individuals who are visually impaired or blind to access in-formation that would otherwise be inaccessible to them. Image-to-speech systems are becoming increasingly sophisticated and can be integrated into a variety of devices, from smartphones to smart glasses. \nThis article presents an approach to improving the accuracy of the image-to-speech system by incorporating multiple techniques. The proposed system begins by using Tesseract, an optical character recognition (OCR) engine, to extract text infor-mation from images. However, OCR is often imperfect and produces errors, which can impact the accuracy of image-to-speech models. To address this issue, the Text-Davinci-002 engine was applied for post-processing OCR output, which can help to correct errors and improve the accuracy of the extracted text.\nFinally, the Microsoft Speech API was employed in order to generate speech from the extracted text. By integrating these three techniques, image-to-speech system accuracy was significantly improved. An example of the generated synthetic dataset showed that the proposed techniques improve image-to-speech system accuracy both on word and character levels, and also perform punctuation error correction.\nThis approach can be useful in various applications, including reading text from images, translating written text to speech, and assisting people with visual im-pairments.",
        "keywords": "",
        "link": "http://dx.doi.org/10.53297/18293336-2023.1-44"
    },
    {
        "id": 26482,
        "title": "Robust Speech Processing with Fuzzy Logic-Driven Anti-Spoofing Techniques",
        "authors": "Rashmi M, Yogeesh N, Girija D K, P. William",
        "published": "2023-10-18",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icssas57918.2023.10331804"
    },
    {
        "id": 26483,
        "title": "Human–Computer Interaction with a Real-Time Speech Emotion Recognition with Ensembling Techniques 1D Convolution Neural Network and Attention",
        "authors": "Waleed Alsabhan",
        "published": "2023-1-26",
        "citations": 8,
        "abstract": "Emotions have a crucial function in the mental existence of humans. They are vital for identifying a person’s behaviour and mental condition. Speech Emotion Recognition (SER) is extracting a speaker’s emotional state from their speech signal. SER is a growing discipline in human–computer interaction, and it has recently attracted more significant interest. This is because there are not so many universal emotions; therefore, any intelligent system with enough computational capacity can educate itself to recognise them. However, the issue is that human speech is immensely diverse, making it difficult to create a single, standardised recipe for detecting hidden emotions. This work attempted to solve this research difficulty by combining a multilingual emotional dataset with building a more generalised and effective model for recognising human emotions. A two-step process was used to develop the model. The first stage involved the extraction of features, and the second stage involved the classification of the features that were extracted. ZCR, RMSE, and the renowned MFC coefficients were retrieved as features. Two proposed models, 1D CNN combined with LSTM and attention and a proprietary 2D CNN architecture, were used for classification. The outcomes demonstrated that the suggested 1D CNN with LSTM and attention performed better than the 2D CNN. For the EMO-DB, SAVEE, ANAD, and BAVED datasets, the model’s accuracy was 96.72%, 97.13%, 96.72%, and 88.39%, respectively. The model beat several earlier efforts on the same datasets, demonstrating the generality and efficacy of recognising multiple emotions from various languages.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23031386"
    },
    {
        "id": 26484,
        "title": "Machine Learning Techniques for Hate Speech Detection on Social Media",
        "authors": "Chandradeep Bhatt, Nancy Saini, Rahul Chauhan, Ashok Kumar Sahoo",
        "published": "2023-9-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cisct57197.2023.10351228"
    },
    {
        "id": 26485,
        "title": "Maximum power point tracking techniques for low-cost solar photovoltaic applications – Part II: Mathematical Calculation and Measurement and Comparison, criteria on choices and suitable MPPT techniques",
        "authors": "",
        "published": "2024-1-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.24425/aee.2023.145410"
    },
    {
        "id": 26486,
        "title": "Generating Speech with Prosodic Prominence based on SSL-Visually Grounded Models",
        "authors": "Bella Septina Ika Hartanti, Dipta Tanaya, Kurniawati Azizah, Dessi Puji Lestari, Ayu Purwarianti, Sakriani Sakti",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482965"
    },
    {
        "id": 26487,
        "title": "What’s the Evidence?",
        "authors": "Nicole McGill",
        "published": "2023-3-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/22087168.2023.12370385"
    },
    {
        "id": 26488,
        "title": "An Isolated Words Balanced Corpus for Native and Non-Native Urdu Speakers in Automatic Speech Recognition",
        "authors": "Shalini V. Sathe, R. R. Deshmukh, Santosh K. Maher, Swapnil Waghmare",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482957"
    },
    {
        "id": 26489,
        "title": "An Analysis of Hate Speech Detection Techniques",
        "authors": "Ricky Krisdianto, Ivana Apriani, Peter Miracle Halim, Maria Susan Anggreainy, Afdhal Kurniawan",
        "published": "2023-9-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aidas60501.2023.10284673"
    },
    {
        "id": 26490,
        "title": "A Review of Feature Extraction and Classification Techniques in Speech Recognition",
        "authors": "Sonal Yadav, Amit Kumar, Ayu Yaduvanshi, Prateek Meena",
        "published": "2023-10-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42979-023-02158-5"
    },
    {
        "id": 26491,
        "title": "Explainable audio Classification of Playing Techniques with Layer-wise Relevance Propagation",
        "authors": "Changhong Wang, Vincent Lostanlen, Mathieu Lagrange",
        "published": "2023-6-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10095894"
    },
    {
        "id": 26492,
        "title": "State-of-the-Art Analysis of Deep Learning-Based Monaural Speech Source Separation Techniques",
        "authors": "Swati Soni, Ram Narayan Yadav, Lalita Gupta",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3235010"
    },
    {
        "id": 26493,
        "title": "Survey on Visual Speech Recognition using Deep Learning Techniques",
        "authors": "Ritika Chand, Pushpit Jain, Abhinav Mathur, Shiwansh Raj, Prashasti Kanikar",
        "published": "2023-3-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cscita55725.2023.10104811"
    },
    {
        "id": 26494,
        "title": "An Accurate Speech Emotion Analysis using Gradient Boosting and BiLSTM Techniques",
        "authors": "Ineesh Singh Raina, Nikhil Gupta, Gulshan Kumar, Geetanjali Rathee",
        "published": "2023-4-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/inc457730.2023.10263225"
    },
    {
        "id": 26495,
        "title": "Speech Emotion Recognition Using Deep Learning Transfer Models and Explainable Techniques",
        "authors": "Tae-Wan Kim, Keun-Chang Kwak",
        "published": "2024-2-15",
        "citations": 0,
        "abstract": "This study aims to establish a greater reliability compared to conventional speech emotion recognition (SER) studies. This is achieved through preprocessing techniques that reduce uncertainty elements, models that combine the structural features of each model, and the application of various explanatory techniques. The ability to interpret can be made more accurate by reducing uncertain learning data, applying data in different environments, and applying techniques that explain the reasoning behind the results. We designed a generalized model using three different datasets, and each speech was converted into a spectrogram image through STFT preprocessing. The spectrogram was divided into the time domain with overlapping to match the input size of the model. Each divided section is expressed as a Gaussian distribution, and the quality of the data is investigated by the correlation coefficient between distributions. As a result, the scale of the data is reduced, and uncertainty is minimized. VGGish and YAMNet are the most representative pretrained deep learning networks frequently used in conjunction with speech processing. In dealing with speech signal processing, it is frequently advantageous to use these pretrained models synergistically rather than exclusively, resulting in the construction of ensemble deep networks. And finally, various explainable models (Grad CAM, LIME, occlusion sensitivity) are used in analyzing classified results. The model exhibits adaptability to voices in various environments, yielding a classification accuracy of 87%, surpassing that of individual models. Additionally, output results are confirmed by an explainable model to extract essential emotional areas, converted into audio files for auditory analysis using Grad CAM in the time domain. Through this study, we enhance the uncertainty of activation areas that are generated by Grad CAM. We achieve this by applying the interpretable ability from previous studies, along with effective preprocessing and fusion models. We can analyze it from a more diverse perspective through other explainable techniques.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app14041553"
    },
    {
        "id": 26496,
        "title": "Students' Viewpoints Toward Part of Speech as the Fulcrum of Grammar",
        "authors": " Hustiana",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "This study concerned with students’ viewpoints toward part of speech which attempted to figure out the students’ viewpoints about parts of speech, to explore students’ problems in learning parts of speech, and to reveal the students’ strategies to be acquainted with part of speech. This research was a qualitative study where the data were collected by interview. The subjects of this research were 28 students (15 females and 13 males) in the third semester, English Education Department at Faculty of Training and Education of a State University in West Sulawesi who were chosen randomly. All of the students were interviewed about their viewpoints about parts of speech. Based on the result of the research, the researcher found that some students misunderstood the definition of part of speech, and some of them understand it. The students were found to have problems in learning parts of speech such as being less practice, not mastering the parts of speech well, lack of vocabulary, and inability to differentiate parts of speech, as well as lack of understanding. In the mean time, the students’ way to become familiar with parts of speech was by memorizing the word classes, knowing the characteristics of the word, paying attention to the position of the word in a sentence, knowing the meaning of the word, guessing the word, and looking at the word before and after in a sentence or text. The result of the study could be useful for future lectures about parts of speech.",
        "keywords": "",
        "link": "http://dx.doi.org/10.20885/jee.v9i2.31087"
    },
    {
        "id": 26497,
        "title": "Research on part-of-speech relationship between English-Chinese translation based on corpus",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23977/langl.2023.060101"
    },
    {
        "id": 26498,
        "title": "Speech Emotion Recognition Using Deep Learning Techniques and Augmented Features",
        "authors": "Shahed Mohammadi, Niloufar Hemati, Ali Hashemi, Haniye Zandiye",
        "published": "2023-9-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eecsi59885.2023.10295651"
    },
    {
        "id": 26499,
        "title": "Correlation-Based Machine Learning Techniques for Channel Estimation with Fluid Antennas",
        "authors": "Shuyan Ji, Constantinos Psomas, John Thompson",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447499"
    },
    {
        "id": 26500,
        "title": "A Comprehensive Investigation into The Noise Reduction Techniques for Speech",
        "authors": "Suryakant Tyagi, Annamaria R. Varkonyi-Koczy, Sandor Szenasi",
        "published": "2023-1-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sami58000.2023.10044486"
    },
    {
        "id": 26501,
        "title": "Impersonated Human Speech Chatbot with Adaptive Frequency Spectrum",
        "authors": "Gautam Chettiar, Kumar A. Shukla, Preet Nalwaya, Karman Sethi, Surya Prakash",
        "published": "2023-1-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icct56969.2023.10076120"
    },
    {
        "id": 26502,
        "title": "A comparison of text preprocessing techniques for hate and offensive speech detection in Twitter",
        "authors": "Anna Glazkova",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13278-023-01156-y"
    },
    {
        "id": 26503,
        "title": "Optimizing Direct Speech-to-Text Translation for un-orthographic low-resource tribal languages using source transliterations",
        "authors": "Tonmoy Rajkhowa, Amartya Roy Chowdhury, Prashant Bannulmath, Deepak K.T., S. R. Mahadeva Prasanna",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/o-cocosda60357.2023.10482960"
    },
    {
        "id": 26504,
        "title": "Analysis of Translation Techniques of Directive Speech Acts in WALL-E Film",
        "authors": "Galih Wisnu Bathara, Romel Noverino",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "The problem in this study relates to the study of translation, specifically on translation techniques which govern the way directive speech act is translated from English into Indonesian. This study aims to find out translation techniques of directive speech acts using Yule's theory (1996) and Molina and Albir's theory. The data sources of this study are WALL-E film and its Indonesian subtitles on a streaming platform Disney+ Hotstar. Based on the results, there are 81 data of directive speech, divided into Command with 20 data, Order with 41 data, Request with 11 data, and Suggestion with 9 data. The researcher also found 14 translation techniques which are used when translating English directive speech act into Indonesian from the sources of data, namely: amplification, borrowing, calque, compensation, discursive creation, established equivalent, generalization, linguistic amplification, linguistic compression, literal translation, modulation, particularization, reduction, and transposition. There were 37 data using single technique, 31 data using couplet technique, 11 data using triplet technique, and 2 data using quartet technique.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30998/jedu.v3i3.9474"
    }
]