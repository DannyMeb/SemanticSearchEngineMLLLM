[
    {
        "id": 5501,
        "title": "Hyperparameter Tuning Approaches",
        "authors": "Thomas Bartz-Beielstein, Martin Zaefferer",
        "published": "2023",
        "citations": 0,
        "abstract": "AbstractThis chapter provides a broad overview over the different hyperparameter tunings. It details the process of HPT, and discusses popular HPT approaches and difficulties. It focuses on surrogate optimization, because this is the most powerful approach. It introduces Sequential Parameter Optimization Toolbox (SPOT) as one typical surrogate method. SPOT is well established and maintained, open source, available on Comprehensive R Archive Network (CRAN), and catches mistakes. Because SPOT is open source and well documented, the human remains in the loop of decision-making. The introduction of SPOT is accompanied by detailed descriptions of the implementation and program code. This chapter particularly provides a deep insight in Kriging (aka Gaussian Process (GP) aka Bayesian Optimization (BO)) as a workhorse of this methodology. Thus it is very hands-on and practical.",
        "link": "http://dx.doi.org/10.1007/978-981-19-5170-1_4"
    },
    {
        "id": 5502,
        "title": "Hyperparameter Tuning and Optimization Applications",
        "authors": "Thomas Bartz-Beielstein",
        "published": "2023",
        "citations": 1,
        "abstract": "AbstractThis chapter reflects on advantages and sense of use of Hyperparameter Tuning (HPT) and its disadvantages. In particular it shows how important it is, to keep the human in the loop, even if HPT works perfectly. The chapter presents a collection of HPT studies. First, HPT applications in Machine Learning (ML) and Deep Learning (DL) are described. A special focus lies on automated ML, neural architecture search, and combined approaches. HPT software is presented. Finally, model based approaches, especially applications with Sequential Parameter Optimization Toolbox (SPOT) are discussed.",
        "link": "http://dx.doi.org/10.1007/978-981-19-5170-1_6"
    },
    {
        "id": 5503,
        "title": "Efficient Deep Learning Hyperparameter Tuning Using Cloud Infrastructure: Intelligent Distributed Hyperparameter Tuning with Bayesian Optimization in the Cloud",
        "authors": "Mercy Prasanna Ranjit, Gopinath Ganapathy, Kalaivani Sridhar, Vikram Arumugham",
        "published": "2019-7",
        "citations": 27,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cloud.2019.00097"
    },
    {
        "id": 5504,
        "title": "Hyperparameter Tuning in German Official Statistics",
        "authors": "Florian Dumpert, Elena Schmidt",
        "published": "2023",
        "citations": 1,
        "abstract": "AbstractThis chapter describes the special quality requirements placed on official statistics and builds a bridge to the tuning of hyperparameters in Machine Learning (ML). To carry out the latter optimally under consideration of constraints and to assess its quality is part of the tasks of the employees entrusted with this work. The chapter sheds special light on open questions and the need for further research.",
        "link": "http://dx.doi.org/10.1007/978-981-19-5170-1_7"
    },
    {
        "id": 5505,
        "title": "CNN Hyperparameter Tuning Applied to Iris Liveness Detection",
        "authors": "Gabriela Kimura, Diego Lucio, Alceu Britto Jr., David Menotti",
        "published": "2020",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008983904280434"
    },
    {
        "id": 5506,
        "title": "Hyperparameter Tuning with Simulated Annealing and Genetic Algorithm",
        "authors": "Yash  Sameer Bhandare, Mohammadreza Hajiarbabi",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4432719"
    },
    {
        "id": 5507,
        "title": "Optimized Hyperparameter Tuning for Flood Prediction and Comparative Analysis",
        "authors": "JYOTHISH V R, Sajimon Abraham",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4746253"
    },
    {
        "id": 5508,
        "title": "Automatic hyperparameter tuning of topology optimization algorithms using surrogate optimization",
        "authors": "Dat Ha, Josephine Carstensen",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThis paper presents a new approach that automates the tuning process in topology optimization of parameters that are traditionally defined by the user. The new method draws inspiration from hyperparameter optimization in machine learning. A new design problem is formulated where the topology optimization hyperparameters are defined as design variables and the problem is solved by surrogate optimization. The new design problem is nested, such that a topology optimization problem is solved as an inner problem.To encourage the identification of high-performing solutions while limiting the computational resource requirements, the outer objective function is defined as the original objective combined with penalization for intermediate densities and deviations from the prescribed material consumption.The contribution is demonstrated on density-based topology optimization with various hyperparameters and objectives, including compliance minimization, compliant mechanism design, and buckling load factor maximization. Consistent performance is observed across all tested examples. For a simple two hyperparameter case, the new framework is shown to reduce amount of times a topology optimization algorithm is executed by 90\\% without notably sacrificing the objective compared to a rigorous manual grid search.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3944293/v1"
    },
    {
        "id": 5509,
        "title": "Blocked Cross–Validation: A Precise and Efficient Method for Hyperparameter Tuning",
        "authors": "Giovanni Maria Merola",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nHyperparameter tuning plays a crucial role in optimizing the performance of predictive learners. Cross--validation (CV) is a widely adopted technique for estimating the error of different hyperparameter settings. Repeated cross--validation (RCV) has been commonly employed to reduce the variability of CV errors. In this paper, we introduce a novel approach called blocked cross--validation (BCV), where the repetitions are blocked with respect to both CV partition and the random behavior of the learner. Theoretical analysis and empirical experiments demonstrate that BCV provides more precise error estimates compared to RCV, even with a significantly reduced number of runs. We present extensive examples using real--world data sets to showcase the effectiveness and efficiency of BCV in hyperparameter tuning. Our results indicate that BCV outperforms RCV in hyperparameter tuning, achieving greater precision with fewer computations.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3221138/v1"
    },
    {
        "id": 5510,
        "title": "Hyperparameter Search for CT-Scan Classification Using Hyperparameter Tuning in Pre-Trained Model CNN With MLP",
        "authors": "Jasman Pardede, A.S. Purohita",
        "published": "2022-10-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icosnikom56551.2022.10034878"
    },
    {
        "id": 5511,
        "title": "PENERAPAN TUNING HYPERPARAMETER RANDOMSEARCHCV PADA ADAPTIVE BOOSTING UNTUK PREDIKSI KELANGSUNGAN HIDUP PASIEN GAGAL JANTUNG",
        "authors": "Tita Aulia Edi Putri, Tatik Widiharih, Rukun Santoso",
        "published": "2023-1-3",
        "citations": 3,
        "abstract": "Heart failure is the number one cause of death every year. Heart failure is a pathological condition characterized by abnormalities in heart function, which results in the failure of blood to be pumped to supply metabolic needs of tissues. The application of data mining and computational techniques to medical records can be an effective tool to predict each patient's survival who has heart failure symptoms. Data mining is a process of gathering important information from big data. The collection of important information is carried out through several processes, including statistical methods, mathematics, and artificial intelligence technology. The AdaBoost method is one of the supervised algorithms in data mining that is widely applied to make classification models. Hyperparameter Optimization is selecting the optimal set of hyperparameters for a learning algorithm. AdaBoost has hyperparameters requiring a classification process set, namely learning rate and n_estimators. RandomSearchCV is a random combination method of selected hyperparameters used to train the model. This research uses heart failure patient data collected at the Faisalabad Institute of Cardiology and at the Allied Hospital in Faisalabad (Punjab, Pakistan) from April to December 2015. The research uses learning rate: [-2.2] (log scale), n_estimators start from 10 to 776, and Kfold=5 and produces the best hyperparameters in learning rate=0.01 and n_estimators=443 with an accuracy value of 0.85 and AUC value of 0.897.",
        "link": "http://dx.doi.org/10.14710/j.gauss.11.3.397-406"
    },
    {
        "id": 5512,
        "title": "Short Review: Automated Hyperparameter Tuning Methods for High Accuracy Tabular Classification",
        "authors": "Abhas Kumar Sinha",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe problem of very high-accuracy classification has led to the development of several methods, systems like – XGBoost which often get state-of-the-art on tabular data classification and regression tasks. Deep learning methods on the other hand fail to achieve high accuracy most of the time where – 1. The dataset size is restricted 2. The tabular format of the dataset. We demonstrate custom models that get generated from AutoML systems and automatically tuned for peak hyperparameter settings, perform competitively well, with no human intervention for model creation, hyperparameter tuning, and dataset manipulation tasks to achieve state-of-the-art results compared to other methods and systems out there. We briefly discuss the approaches in AutoML to construct, train and tune deep learning models automatically and discuss the results we got from it on a hackathon competition organized by NCPI.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2314580/v1"
    },
    {
        "id": 5513,
        "title": "Hyperparameter Tuning",
        "authors": "Yigit Aydede",
        "published": "2023-8-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003381501-12"
    },
    {
        "id": 5514,
        "title": "Multi-Task Gaussian Process Upper Confidence Bound for Hyperparameter Tuning",
        "authors": "Bo Shen, Raghav Gnanasambandam, Rongxuan Wang, Zhenyu Kong",
        "published": "No Date",
        "citations": 1,
        "abstract": "In many scientific and engineering applications, Bayesian optimization (BO) is a\npowerful tool for hyperparameter tuning of a machine learning model, materials design\nand discovery, etc. BO guides the choice of experiments in a sequential way to find\na good combination of design points in as few experiments as possible. It can be formulated as a problem of optimizing a “black-box” function. Different from single-task\nBayesian optimization, Multi-task Bayesian optimization is a general method to efficiently optimize multiple different but correlated “black-box” functions. The previous\nworks in Multi-task Bayesian optimization algorithm queries a point to be evaluated\nfor all tasks in each round of search, which is not efficient. For the case where different tasks are correlated, it is not necessary to evaluate all tasks for a given query\npoint. Therefore, the objective of this work is to develop an algorithm for multi-task\nBayesian optimization with automatic task selection so that only one task evaluation\nis needed per query round. Specifically, a new algorithm, namely, multi-task Gaussian\nprocess upper confidence bound (MT-GPUCB), is proposed to achieve this objective.\nThe MT-GPUCB is a two-step algorithm, where the first step chooses which query\npoint to evaluate, and the second step automatically selects the most informative task\nto evaluate. Under the bandit setting, a theoretical analysis is provided to show that\nour proposed MT-GPUCB is no-regret under some mild conditions. Our proposed algorithm is verified experimentally on a range of synthetic functions as well as real-world\nproblems. The results clearly show the advantages of our query strategy for both design\npoint and task.",
        "link": "http://dx.doi.org/10.36227/techrxiv.16674400.v1"
    },
    {
        "id": 5515,
        "title": "Multi-Task Gaussian Process Upper Confidence Bound for Hyperparameter Tuning",
        "authors": "Bo Shen, Raghav Gnanasambandam, Rongxuan Wang, Zhenyu Kong",
        "published": "No Date",
        "citations": 2,
        "abstract": "In many scientific and engineering applications, Bayesian optimization (BO) is a\npowerful tool for hyperparameter tuning of a machine learning model, materials design\nand discovery, etc. BO guides the choice of experiments in a sequential way to find\na good combination of design points in as few experiments as possible. It can be formulated as a problem of optimizing a “black-box” function. Different from single-task\nBayesian optimization, Multi-task Bayesian optimization is a general method to efficiently optimize multiple different but correlated “black-box” functions. The previous\nworks in Multi-task Bayesian optimization algorithm queries a point to be evaluated\nfor all tasks in each round of search, which is not efficient. For the case where different tasks are correlated, it is not necessary to evaluate all tasks for a given query\npoint. Therefore, the objective of this work is to develop an algorithm for multi-task\nBayesian optimization with automatic task selection so that only one task evaluation\nis needed per query round. Specifically, a new algorithm, namely, multi-task Gaussian\nprocess upper confidence bound (MT-GPUCB), is proposed to achieve this objective.\nThe MT-GPUCB is a two-step algorithm, where the first step chooses which query\npoint to evaluate, and the second step automatically selects the most informative task\nto evaluate. Under the bandit setting, a theoretical analysis is provided to show that\nour proposed MT-GPUCB is no-regret under some mild conditions. Our proposed algorithm is verified experimentally on a range of synthetic functions as well as real-world\nproblems. The results clearly show the advantages of our query strategy for both design\npoint and task.",
        "link": "http://dx.doi.org/10.36227/techrxiv.16674400"
    },
    {
        "id": 5516,
        "title": "Resampling and Hyperparameter Tuning for Optimizing Breast Cancer Prediction Using Light Gradient Boosting",
        "authors": "Kartika Handayani, Erni Erni, Rangga Pebrianto, Ari Abdilah, Rifky Permana, Eni Pudjiarti",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012446100003848"
    },
    {
        "id": 5517,
        "title": "Hyperparameter tuning for federated learning – systems and practices",
        "authors": "Syed Zawad, Feng Yan",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-44-319037-7.00021-1"
    },
    {
        "id": 5518,
        "title": "Data Science Revealed",
        "authors": "Tshepo Chris Nokeri",
        "published": "2021",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6870-4"
    },
    {
        "id": 5519,
        "title": "Autoencoder-enabled Model Portability for Reducing Hyperparameter Tuning Efforts in Side-channel Analysis",
        "authors": "Marina Krček, Guilherme Perin",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nHyperparameter tuning represents one of the main challenges in deep learning-based profiling side-channel analysis. For each different side-channel dataset, the typical procedure to find a profiling model is applying hyperparameter tuning from scratch. The main reason is that side-channel measurements from various targets contain different underlying leakage distributions. Consequently, the same profiling model hyperparameters are usually not equally efficient for other targets. This paper considers autoencoders for dimensionality reduction to verify if encoded datasets from different targets enable the portability of profiling models and architectures. Successful portability reduces the hyperparameter tuning efforts as profiling model tuning is eliminated for the new dataset, and tuning autoencoders is simpler. We first search for the best autoencoder for each dataset and the best profiling model when the encoded dataset becomes the training set. Our results show no significant difference in tuning efforts using original and encoded traces, meaning that encoded data reliably represents the original data. Next, we verify how portable is the best profiling model among different datasets. Our results show that tuning autoencoders enables and improves portability while reducing the effort in hyperparameter search for profiling models. Lastly, we present a transfer learning case where dimensionality reduction might be necessary if the model is tuned for a dataset with fewer features than the new dataset. In this case, tuning of the profiling model is eliminated and training time reduced.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2443498/v1"
    },
    {
        "id": 5520,
        "title": "Fast Hyperparameter Tuning for Ising Machines",
        "authors": "Matthieu Parizy, Norihiro Kakuko, Nozomu Togawa",
        "published": "2023-1-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icce56470.2023.10043382"
    },
    {
        "id": 5521,
        "title": "Hyperparameter Tuning Deep Learning for Imbalanced Data",
        "authors": "Refi Riduan Achmad, Muhammad Haris",
        "published": "2023-6-25",
        "citations": 0,
        "abstract": "Imbalanced data is a challenge for the performance of classification algorithms. A situation where two classes consisting of the majority class dominate the minority class. As a result, algorithmic models tend to have high accuracy against the majority class. Imbalanced data can occur on any type of data, including data coming from Twitter. Twitter is one of the social media that is widely used to think about various things, including about the future Presidential candidate of the Republic of Indonesia in 2024. Tweet data was collected from October 8, 2022, to January 10, 2023. Anies Baswedan has a total of 34,962 tweets, Ganjar Pranowo 39,796 tweets, and Prabowo Subianto 12,398 tweets. These tweets can be identified to be categorized into positive sentiments and negative sentiments using several classification algorithm methods, namely Decision Tree, Naïve Bayes, and Deep Learning.  The dataset comes from the tweets of Twitter netizens who are scraped and preprocessed using the RapidMiner tool.  Prabowo Subianto's dataset achieved the best performance using the Deep Learning model with an accuracy rate of 85.42%, precision of 63.30%, recall of 91.77%, and AUC of 0.867.",
        "link": "http://dx.doi.org/10.51967/tepian.v4i2.2216"
    },
    {
        "id": 5522,
        "title": "Optimizing Radiation Emulator Training: Streamlined Hyperparameter Tuning with Automated Sherpa",
        "authors": "Park Sa Kim, Soonyoung Roh, Hwan-Jin Song",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThis study aimed to determine the optimal configuration of neural network emulators for numerical weather prediction with minimized trial and error by comparing the performance of emulators utilizing neurons obtained from multiple hidden layers (1-5 layers) automatically defined by the Sherpa library. Findings revealed that emulators with Sherpa-determined neurons demonstrated good results, stable performance, and low errors in numerical simulations. Optimal configurations manifested in one and two hidden layers, displaying a moderate enhancement with the incorporation of dual hidden layers. The mean neuron quantity per hidden layer, ascertained by Sherpa, spanned from 153 to 440, culminating in a 7-12 fold acceleration augmentation. These insights could guide the development of radiative physical neural network emulators as automatically determined hyperparameters can effectively reduce trial and error processes while maintaining stable outcomes. Further experimentation is recommended to establish the best balance between speed and accuracy, as this study did not identify optimized values for all hyperparameters. Overall, this research highlights the importance of hyperparameter optimization in designing efficient and accurate neural network emulators for weather prediction.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3285431/v1"
    },
    {
        "id": 5523,
        "title": "Epso: Based on Particle Swarm Optimization for Differential Privacy Hyperparameter Fine-Tuning Algorithm",
        "authors": "Qiang Gao, Han Sun, Zhifang Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4505818"
    },
    {
        "id": 5524,
        "title": "Hyperparameter Tuning in Offline Reinforcement Learning",
        "authors": "Andrew Tittaferrante, Abdulsalam Yassine",
        "published": "2022-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icmla55696.2022.00101"
    },
    {
        "id": 5525,
        "title": "Hyperparameter Tuning on Classification Algorithm with  Grid Search",
        "authors": "Wahyu Nugraha, Agung Sasongko",
        "published": "2022-5-21",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32520/stmsi.v11i2.1750"
    },
    {
        "id": 5526,
        "title": "Hyperparameter Tuning",
        "authors": "Umberto Michelucci",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-3790-8_7"
    },
    {
        "id": 5527,
        "title": "Automatic Hyperparameter Tuning in Sparse Matrix Factorization",
        "authors": "Ryota Kawasumi, Koujin Takeda",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "Abstract\nWe study the problem of hyperparameter tuning in sparse matrix factorization under a Bayesian framework. In prior work, an analytical solution of sparse matrix factorization with Laplace prior was obtained by a variational Bayes method under several approximations. Based on this solution, we propose a novel numerical method of hyperparameter tuning by evaluating the zero point of the normalization factor in a sparse matrix prior. We also verify that our method shows excellent performance for ground-truth sparse matrix reconstruction by comparing it with the widely used algorithm of sparse principal component analysis.",
        "link": "http://dx.doi.org/10.1162/neco_a_01581"
    },
    {
        "id": 5528,
        "title": "Xtune: An XAI-Based Hyperparameter Tuning Method for Time-series Forecasting Using Deep Learning",
        "authors": "Shimon Sumita, Hiroyuki Nakagawa, Tatsuhiro Tsuchiya",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nGiven a time-series dataset and deep learning based time-series forecasting method, how can we determine the optimal hyperparameter value efficiently? How can we determine this value without running the method with a large number of candidate values? In this study, we present \\textit{Xtune}, an efficient and novel hyperparameter tuning method, utilizing explainable AI, for a time-series forecasting using deep learning. Our proposed method has the following properties: (a) It is effective: it determines the optimal hyperparameter value of deep learning based time-series forecasting methods. (b) It is efficient: it does not need to run the method on various hyperparameter values. (c) It is applicable: it can be used to tune the hyperprameter tuning for the anomaly detection method utilizing deep learning-based time-series forecasting. Extensive experiments on real datasets and time-series forecasting methods demonstrate that \\textit{Xtune} does indeed determine the optimal hyperparameter value efficiently, and consistently outperforms the existing methods in terms of execution speed.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3008932/v1"
    },
    {
        "id": 5529,
        "title": "Fast Model Selection and Hyperparameter Tuning for Generative Models",
        "authors": "Luming Chen, Sujit K. Ghosh",
        "published": "2024-2-9",
        "citations": 0,
        "abstract": "Generative models have gained significant attention in recent years. They are increasingly used to estimate the underlying structure of high-dimensional data and artificially generate various kinds of data similar to those from the real world. The performance of generative models depends critically on a good set of hyperparameters. Yet, finding the right hyperparameter configuration can be an extremely time-consuming task. In this paper, we focus on speeding up the hyperparameter search through adaptive resource allocation, early stopping underperforming candidates quickly and allocating more computational resources to promising ones by comparing their intermediate performance. The hyperparameter search is formulated as a non-stochastic best-arm identification problem where resources like iterations or training time constrained by some predetermined budget are allocated to different hyperparameter configurations. A procedure which uses hypothesis testing coupled with Successive Halving is proposed to make the resource allocation and early stopping decisions and compares the intermediate performance of generative models by their exponentially weighted Maximum Means Discrepancy (MMD). The experimental results show that the proposed method selects hyperparameter configurations that lead to a significant improvement in the model performance compared to Successive Halving for a wide range of budgets across several real-world applications.",
        "link": "http://dx.doi.org/10.3390/e26020150"
    },
    {
        "id": 5530,
        "title": "Self-adaptive Decomposition and Incremental Hyperparameter Tuning Across Multiple Problems",
        "authors": "Jialin Liu, Xin Yao",
        "published": "2019-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ssci44817.2019.9002966"
    },
    {
        "id": 5531,
        "title": "Breast Cancer Detection Using ResNet with Hyperparameter Tuning",
        "authors": "Jiatai Mu",
        "published": "2023-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icpeca56706.2023.10076197"
    },
    {
        "id": 5532,
        "title": "Hyperparameter Tuning for Address Validation using Optuna",
        "authors": "Mariya Evtimova",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "Public institutions generally share personal information on their websites. That allows the possibility to find personal information when performing internet searches quickly. However, the personal information that is on the internet is not always accurate and can lead to misunderstandings and ambiguity concerning the accessible postal address information. That can be crucial if the information is used to find the location of the corresponding person or to use it as a postal address for correspondence. Many websites contain personal information, but sometimes as people change the web address, information is not up to date or is incorrect. To synchronize the available personal information on the internet could be used an algorithm for validation and verification of the personal addresses. In the paper, a hyperparameter tuning for address validation using the ROBERTa model of the Hugging Face Transformers library. It discusses the implementation of hyperparameter tuning for address validation and its evaluation to achieve high precision and accuracy.",
        "link": "http://dx.doi.org/10.37394/232018.2024.12.10"
    },
    {
        "id": 5533,
        "title": "Automatic Hyperparameter Tuning in Deep Convolutional Neural Networks Using Asynchronous Reinforcement Learning",
        "authors": "Patrick Neary",
        "published": "2018-7",
        "citations": 30,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccc.2018.00017"
    },
    {
        "id": 5534,
        "title": "Forecasting Electricity Consumption Using Deep Learning Methods with Hyperparameter Tuning",
        "authors": "Serkan Ayvaz, Onur Arslan",
        "published": "2020-10-5",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/siu49456.2020.9302338"
    },
    {
        "id": 5535,
        "title": "Hyperparameter Tuning using Quantum Genetic Algorithms",
        "authors": "Athanasios Lentzas, Christoforos Nalmpantis, Dimitris Vrakas",
        "published": "2019-11",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ictai.2019.00199"
    },
    {
        "id": 5536,
        "title": "Neural Networks",
        "authors": "Tshepo Chris Nokeri",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6870-4_12"
    },
    {
        "id": 5537,
        "title": "A Linear Programming Enhanced Genetic Algorithm for Hyperparameter Tuning in Machine Learning",
        "authors": "Ankur Sinha, Paritosh Pankaj",
        "published": "2023-7-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cec53210.2023.10254162"
    },
    {
        "id": 5538,
        "title": "Ensemble Approach with Hyperparameter Tuning for Credit Worthiness Prediction",
        "authors": "Pavitha N, Shounak Sugave",
        "published": "2022-10-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/gcat55367.2022.9971879"
    },
    {
        "id": 5539,
        "title": "Hyperparameter tuning methods in automated machine learning",
        "authors": "Yang Zebin, Zhang Aijun",
        "published": "2020-5-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1360/n012019-00092"
    },
    {
        "id": 5540,
        "title": "Enhancing Plant Disease Classification through Manual CNN Hyperparameter Tuning",
        "authors": "Khaoula Taji, Fadoua Ghanimi",
        "published": "2023-12-27",
        "citations": 0,
        "abstract": "Diagnosing plant diseases is a challenging task due to the complex nature of plants and the visual similarities among different species. Timely identification and classification of these diseases are crucial to prevent their spread in crops. Convolutional Neural Networks (CNN) have emerged as an advanced technology for image identification in this domain. This study explores deep neural networks and machine learning techniques to diagnose plant diseases using images of affected plants, with a specific emphasis on developing a CNN model and highlighting the importance of hyperparameters for precise results. The research involves processes such as image preprocessing, feature extraction, and classification, along with a manual exploration of diverse hyperparameter settings to evaluate the performance of the proposed CNN model trained on an openly accessible dataset. The study compares customized CNN models for the classification of plant diseases, demonstrating the feasibility of disease classification and automatic identification through machine learning-based approaches. It specifically presents a CNN model and traditional machine learning methodologies for categorizing diseases in apple and maize leaves, utilizing a dataset comprising 7023 images divided into 8 categories. The evaluation criteria indicate that the CNN achieves an impressive accuracy of approximately 98.02%.",
        "link": "http://dx.doi.org/10.56294/dm2023112"
    },
    {
        "id": 5541,
        "title": "Cluster Analysis",
        "authors": "Tshepo Chris Nokeri",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6870-4_10"
    },
    {
        "id": 5542,
        "title": "Survival Analysis",
        "authors": "Tshepo Chris Nokeri",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6870-4_11"
    },
    {
        "id": 5543,
        "title": "Multi-objective machine training based on Bayesian hyperparameter tuning",
        "authors": "Pedro J. Zufiria, Carlos Borrajo, Miguel Taibo",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191772"
    },
    {
        "id": 5544,
        "title": "Efficient hyperparameter tuning for predicting student performance with Bayesian optimization",
        "authors": "Saleh Albahli",
        "published": "2023-11-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11042-023-17525-w"
    },
    {
        "id": 5545,
        "title": "Hyperparameter Tuning of Ml Using Rsm to Determine Parameters Affecting the Gas Diffusivity in Coalbed Reservoirs",
        "authors": "P. Naveen",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3997/2214-4609.202211020"
    },
    {
        "id": 5546,
        "title": "AutoML Hyperparameter Tuning of Generative DNN Architecture for Nanophotonic Device Design",
        "authors": "Toshiaki Koike-Akino, Keisuke Kojima, Ye Wang",
        "published": "2022",
        "citations": 0,
        "abstract": "We introduce an automated machine learning (AutoML) framework to construct a deep neural network model relevant for inverse design of nanophotonic devices without relying on manual trial-and-error hyperparameter tuning.",
        "link": "http://dx.doi.org/10.1364/cleo_at.2022.jw3a.44"
    },
    {
        "id": 5547,
        "title": "Tuning: Methodology",
        "authors": "Thomas Bartz-Beielstein, Martin Zaefferer, Olaf Mersmann",
        "published": "2023",
        "citations": 0,
        "abstract": "AbstractThis chapter lays the groundwork and presents an introduction to the process of tuning Machine Learning (ML) and Deep Learning (DL) hyperparameters and the respective methodology used in this book. The key elements such as the hyperparameter tuning process and measures of tunability and performance are defined. Practical considerations are presented and all the ingredients needed for successful hyperparameter tuning are explained. A special focus lies on how to prepare the data. This might be the most thorough overview presented yet.",
        "link": "http://dx.doi.org/10.1007/978-981-19-5170-1_2"
    },
    {
        "id": 5548,
        "title": "Logistic Regression Analysis",
        "authors": "Tshepo Chris Nokeri",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6870-4_5"
    },
    {
        "id": 5549,
        "title": "Advanced Parametric Methods",
        "authors": "Tshepo Chris Nokeri",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6870-4_2"
    },
    {
        "id": 5550,
        "title": "Time-Series Analysis",
        "authors": "Tshepo Chris Nokeri",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6870-4_3"
    },
    {
        "id": 5551,
        "title": "High Per Parameter: A Large-Scale Study of Hyperparameter Tuning for Machine Learning Algorithms",
        "authors": "Moshe Sipper",
        "published": "2022-9-2",
        "citations": 4,
        "abstract": "Hyperparameters in machine learning (ML) have received a fair amount of attention, and hyperparameter tuning has come to be regarded as an important step in the ML pipeline. However, just how useful is said tuning? While smaller-scale experiments have been previously conducted, herein we carry out a large-scale investigation, specifically one involving 26 ML algorithms, 250 datasets (regression and both binary and multinomial classification), 6 score metrics, and 28,857,600 algorithm runs. Analyzing the results we conclude that for many ML algorithms, we should not expect considerable gains from hyperparameter tuning on average; however, there may be some datasets for which default hyperparameters perform poorly, especially for some algorithms. By defining a single hp_score value, which combines an algorithm’s accumulated statistics, we are able to rank the 26 ML algorithms from those expected to gain the most from hyperparameter tuning to those expected to gain the least. We believe such a study shall serve ML practitioners at large.",
        "link": "http://dx.doi.org/10.3390/a15090315"
    },
    {
        "id": 5552,
        "title": "Automatic hyperparameter tuning in on-line learning: Classic Momentum and ADAM",
        "authors": "Pawel Wawrzynski, Pawel Zawistowski, Lukasz Lepak",
        "published": "2020-7",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn48605.2020.9207204"
    },
    {
        "id": 5553,
        "title": "Beans classification using decision tree and random forest with randomized search hyperparameter tuning",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.28919/cmbn/8225"
    },
    {
        "id": 5554,
        "title": "Classification Using Decision Trees",
        "authors": "Tshepo Chris Nokeri",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6870-4_8"
    },
    {
        "id": 5555,
        "title": "Towards Artificial Neural Network Based Intrusion Detection with Enhanced Hyperparameter Tuning",
        "authors": "Andrei Nicolae Calugar, Weizhi Meng, Haijun Zhang",
        "published": "2022-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/globecom48099.2022.10000809"
    },
    {
        "id": 5556,
        "title": "Deep Learning on Active Sonar Data Using Bayesian Optimization for Hyperparameter Tuning",
        "authors": "Henrik Berg, Karl Thomas Hjelmervik",
        "published": "2021-1-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icpr48806.2021.9412347"
    },
    {
        "id": 5557,
        "title": "Hyperparameter Tuning for Deep Neural Networks Based Optimization Algorithm",
        "authors": "D. Vidyabharathi, V. Mohanraj",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32604/iasc.2023.032255"
    },
    {
        "id": 5558,
        "title": "Machine Learning Using H2O",
        "authors": "Tshepo Chris Nokeri",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6870-4_13"
    },
    {
        "id": 5559,
        "title": "Convolutional Neural Network Hyperparameter Tuning with Adam Optimizer for ECG Classification",
        "authors": "Sena Yagmur SEN, Nalan OZKURT",
        "published": "2020-10-15",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/asyu50717.2020.9259896"
    },
    {
        "id": 5560,
        "title": "Novel classification method of plastic wastes with optimal hyperparameter tuning of Inception_ResnetV2",
        "authors": "Sahng-Won Lee",
        "published": "2021-8-30",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icoiact53268.2021.9563917"
    },
    {
        "id": 5561,
        "title": "Hyperparameter tuning of GDBT models for prediction of heart disease",
        "authors": "Qingcong Lv",
        "published": "2023-4-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2668449"
    },
    {
        "id": 5562,
        "title": "Back to the Classics",
        "authors": "Tshepo Chris Nokeri",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6870-4_9"
    },
    {
        "id": 5563,
        "title": "Efficient Botnet Detection using Feature Ranking and Hyperparameter Tuning",
        "authors": "Meshal Farhan, Mostafa G.",
        "published": "2019-4-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5120/ijca2019918739"
    },
    {
        "id": 5564,
        "title": "Hyperparameter Tuning Algorithm Comparison with Machine Learning Algorithms",
        "authors": "Farel Arden, Cutifa Safitri",
        "published": "2022-12-13",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icitisee57756.2022.10057630"
    },
    {
        "id": 5565,
        "title": "Grid search hyperparameter tuning in additive manufacturing processes",
        "authors": "Michael Ogunsanya, Joan Isichei, Salil Desai",
        "published": "2023-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.mfglet.2023.08.056"
    },
    {
        "id": 5566,
        "title": "Hyperparameter Tuning with Scikit-Learn and PySpark",
        "authors": "Abdelaziz Testas",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-9751-3_16"
    },
    {
        "id": 5567,
        "title": "Global Study: Influence of Tuning",
        "authors": "Martin Zaefferer, Olaf Mersmann, Thomas Bartz-Beielstein",
        "published": "2023",
        "citations": 0,
        "abstract": "AbstractExpanding the more focused analyses from previous chapters, this chapter takes a broader view at the tuning process. That means, rather than tuning an individual model, this investigation considers the tuning of multiple models, with different tuners, and varying data sets. The core aim is to see how characteristics of the data and the model choice may impact the tuning procedure. We investigate five hypotheses, concerning the necessity of tuning, the impact of data characteristics, the impact of the target variable type, the impact of model choice, and benchmarking. Not only does this entail an in-depth tuning study, but we also tie our results to a measure of problem difficulty and use consensus ranking to aggregate the diverse experimental results.",
        "link": "http://dx.doi.org/10.1007/978-981-19-5170-1_12"
    },
    {
        "id": 5568,
        "title": "Algorithms for Hyperparameter Tuning of LSTMs for Time Series Forecasting",
        "authors": "Harshal Dhake, Yashwant Kashyap, Panagiotis Kosmopoulos",
        "published": "2023-4-14",
        "citations": 4,
        "abstract": "The rapid growth in the use of Solar Energy for sustaining energy demand around the world requires accurate forecasts of Solar Irradiance to estimate the contribution of solar power to the power grid. Accurate forecasts for higher time horizons help to balance the power grid effectively and efficiently. Traditional forecasting techniques rely on physical weather parameters and complex mathematical models. However, these techniques are time-consuming and produce accurate results only for short forecast horizons. Deep Learning Techniques like Long Short Term Memory (LSTM) networks are employed to learn and predict complex varying time series data. However, LSTM networks are susceptible to poor performance due to improper configuration of hyperparameters. This work introduces two new algorithms for hyperparameter tuning of LSTM networks and a Fast Fourier Transform (FFT) based data decomposition technique. This work also proposes an optimised workflow for training LSTM networks based on the above techniques. The results show a significant fitness increase from 81.20% to 95.23% and a 53.42% reduction in RMSE for 90 min ahead forecast after using the optimised training workflow. The results were compared to several other techniques for forecasting solar energy for multiple forecast horizons.",
        "link": "http://dx.doi.org/10.3390/rs15082076"
    },
    {
        "id": 5569,
        "title": "A systematic review of hyperparameter tuning techniques for software quality prediction models",
        "authors": "Ruchika Malhotra, Madhukar Cherukuri",
        "published": "2024-1-25",
        "citations": 0,
        "abstract": "BACKGROUND: Software quality prediction models play a crucial role in identifying vulnerable software components during early stages of development, and thereby optimizing the resource allocation and enhancing the overall software quality. While various classification algorithms have been employed for developing these prediction models, most studies have relied on default hyperparameter settings, leading to significant variability in model performance. Tuning the hyperparameters of classification algorithms can enhance the predictive capability of quality models by identifying optimal settings for improved accuracy and effectiveness. METHOD: This systematic review examines studies that have utilized hyperparameter tuning techniques to develop prediction models in software quality domain. The review focused on diverse areas such as defect prediction, maintenance estimation, change impact prediction, reliability prediction, and effort estimation, as these domains demonstrate the wide applicability of common learning algorithms. RESULTS: This review identified 31 primary studies on hyperparameter tuning for software quality prediction models. The results demonstrate that tuning the parameters of classification algorithms enhances the performance of prediction models. Additionally, the study found that certain classification algorithms exhibit high sensitivity to their parameter settings, achieving optimal performance when tuned appropriately. Conversely, certain classification algorithms exhibit low sensitivity to their parameter settings, making tuning unnecessary in such instances. CONCLUSION: Based on the findings of this review, the study conclude that the predictive capability of software quality prediction models can be significantly improved by tuning their hyperparameters. To facilitate effective hyperparameter tuning, we provide practical guidelines derived from the insights obtained through this study.",
        "link": "http://dx.doi.org/10.3233/ida-230653"
    },
    {
        "id": 5570,
        "title": "Finding Hyperplanes Using Support Vectors",
        "authors": "Tshepo Chris Nokeri",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6870-4_7"
    },
    {
        "id": 5571,
        "title": "ODL-BCI: Optimal deep learning model for brain-computer interface to classify students confusion via hyperparameter tuning",
        "authors": "Md Ochiuddin Miah, Umme Habiba, Md Faisal Kabir",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractBrain-computer interface (BCI) research has gained increasing attention in educational contexts, offering the potential to monitor and enhance students’ cognitive states. Real-time classification of students’ confusion levels using electroencephalogram (EEG) data presents a significant challenge in this domain. Since real-time EEG data is dynamic and highly dimensional, current approaches have some limitations for predicting mental states based on this data. This paper introduces an optimal deep learning (DL) model for the BCI, ODL-BCI, optimized through hyperparameter tuning techniques to address the limitations of classifying students’ confusion in real time. Leveraging the “confused student EEG brainwave” dataset, we employ Bayesian optimization to fine-tune hyperparameters of the proposed DL model. The model architecture comprises input and output layers, with several hidden layers whose nodes, activation functions, and learning rates are determined utilizing selected hyperparameters. We evaluate and compare the proposed model with some state-of-the-art methods and standard machine learning (ML) classifiers, including Decision Tree, AdaBoost, Bagging, MLP, Näıve Bayes, Random Forest, SVM, and XG Boost, on the EEG confusion dataset. Our experimental results demonstrate the superiority of the optimized DL model, ODL-BCI. It boosts the accuracy between 4% and 9% over the current approaches, outperforming all other classifiers in the process. The ODL-BCI implementation source codes can be accessed by anyone athttps://github.com/MdOchiuddinMiah/ODL-BCI.",
        "link": "http://dx.doi.org/10.1101/2023.10.30.564829"
    },
    {
        "id": 5572,
        "title": "Genetic Algorithm For Convolutional Neural Network Hyperparameter Tuning",
        "authors": "Fian Yulio Santoso, Eko Sediyono, Hindriyanto Dwi Purnomo",
        "published": "2023-9-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccit58132.2023.10273928"
    },
    {
        "id": 5573,
        "title": "High-Quality Time-Series Analysis",
        "authors": "Tshepo Chris Nokeri",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6870-4_4"
    },
    {
        "id": 5574,
        "title": "Hyperparameter Tuning and its Effects on Cardiac Arrhythmia Prediction",
        "authors": "Renan Soares de Andrades, Mateus Grellert, Mateus Beck Fonseca",
        "published": "2019-10",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bracis.2019.00104"
    },
    {
        "id": 5575,
        "title": "Optimal Hyperparameter Tuning of Convolutional Neural Networks for Visual Sentiment Analysis",
        "authors": "Sahiti Cheguru, Vijayalata Y",
        "published": "2021-10-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.29042/2021-11-5-20-31"
    },
    {
        "id": 5576,
        "title": "Automated Hyperparameter Tuning for Airfoil Shape Optimization with Neural Network Models",
        "authors": "Taeho Jeong, Pavankumar Koratikere, Leifur T. Leifsson",
        "published": "2024-1-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2514/6.2024-2671"
    },
    {
        "id": 5577,
        "title": "Auptimizer - an Extensible, Open-Source Framework for Hyperparameter Tuning",
        "authors": "Jiayi Liu, Samarth Tripathi, Unmesh Kurup, Mohak Shah",
        "published": "2019-12",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigdata47090.2019.9006330"
    },
    {
        "id": 5578,
        "title": "Hyperparameter Tuning for Medicare Fraud Detection in Big Data",
        "authors": "John T. Hancock, Taghi M. Khoshgoftaar",
        "published": "2022-8-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s42979-022-01348-x"
    },
    {
        "id": 5579,
        "title": "Optimizing CNNs for Facial Paralysis Detection: A Hyperparameter Tuning Approach",
        "authors": "Salamet Nur Himawan, Adi Suheryadi, Muhamad Mustamiin",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icic60109.2023.10382112"
    },
    {
        "id": 5580,
        "title": "AutoDDC: Hyperparameter Tuning for Direct Data-Driven Control",
        "authors": "Valentina Breschi, Simone Formentin",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/mcs.2023.3310368"
    },
    {
        "id": 5581,
        "title": "Agent-Based Collaborative Random Search for Hyperparameter Tuning and Global Function Optimization",
        "authors": "Ahmad Esmaeili, Zahra Ghorrati, Eric T. Matson",
        "published": "2023-5-5",
        "citations": 5,
        "abstract": "Hyperparameter optimization is one of the most tedious yet crucial steps in training machine learning models. There are numerous methods for this vital model-building stage, ranging from domain-specific manual tuning guidelines suggested by the oracles to the utilization of general purpose black-box optimization techniques. This paper proposes an agent-based collaborative technique for finding near-optimal values for any arbitrary set of hyperparameters (or decision variables) in a machine learning model (or a black-box function optimization problem). The developed method forms a hierarchical agent-based architecture for the distribution of the searching operations at different dimensions and employs a cooperative searching procedure based on an adaptive width-based random sampling technique to locate the optima. The behavior of the presented model, specifically against changes in its design parameters, is investigated in both machine learning and global function optimization applications, and its performance is compared with that of two randomized tuning strategies that are commonly used in practice. Moreover, we have compared the performance of the proposed approach against particle swarm optimization (PSO) and simulated annealing (SA) methods in function optimization to provide additional insights into its exploration in the search space. According to the empirical results, the proposed model outperformed the compared random-based methods in almost all tasks conducted, notably in a higher number of dimensions and in the presence of limited on-device computational resources.",
        "link": "http://dx.doi.org/10.3390/systems11050228"
    },
    {
        "id": 5582,
        "title": "A Systematic Comparison of search-Based approaches for LDA hyperparameter tuning",
        "authors": "Annibale Panichella",
        "published": "2021-2",
        "citations": 28,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.infsof.2020.106411"
    },
    {
        "id": 5583,
        "title": "Hyperparameter Tuning Menggunakan GridsearchCV pada Random Forest untuk Deteksi Malware",
        "authors": "Iik Muhamad Malik Matin",
        "published": "2023-5-6",
        "citations": 0,
        "abstract": "Random forest merpuakan algoritma machine learning yang populer digunakan untuk klasifikasi. Dalam mendeteksi malware, Random forest dapat membantu mengidentifikasi malware dengan akurasi yang baik. Namun, untuk meningkatkan performa model, diperlukan proses hyperparameter tuning. GridsearchCV adalah metode hyperparameter tuning yang memungkinkan pengguna untuk melakukan pemindaian pada sejumlah hyperparameter yang dipilih. Dalam paper ini, kami melakukan eksperimen dengan menggunakan GridsearchCV untuk melakukan hyperparameter tuning pada Random forest untuk tugas deteksi malware. Hasil eksperimen menunjukkan bahwa dengan melakukan hyperparameter tuning dapat meningkatkan akurasi model dalam mengidentifikasi malware",
        "link": "http://dx.doi.org/10.32722/multinetics.v9i1.5578"
    },
    {
        "id": 5584,
        "title": "Utilizing Support Vector Machine Algorithm and Feature Reduction for Accurate Breast Cancer Detection An Exploration of Normalization and Hyperparameter Tuning Techniques",
        "authors": "VALABOJU SHIVA KUMAR CHARY",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIn this work, we will evaluate the impact of independent component analysis (ICA) on a breast cancer decision support system's feature reduction capabilities. The Wisconsin Diagnostic Breast Cancer (WDBC) dataset will be utilised to construct a one-dimensional feature vector (IC). We will study the performance of k-NN, ANN, RBFNN, and SVM classifiers in spotting mistakes using the original 30 features. Additionally, we will compare the IC-recommended classification with the original feature set using multiple validation and division approaches. The classifiers will be tested based on specificity, sensitivity, accuracy, F-score, Youden's index, discriminant power, and receiver operating characteristic (ROC) curve. This effort attempts to boost the medical decision support system's efficiency while minimising computational complexity.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3531811/v2"
    },
    {
        "id": 5585,
        "title": "Utilizing Support Vector Machine Algorithm and Feature Reduction for Accurate Breast Cancer Detection An Exploration of Normalization and Hyperparameter Tuning Techniques",
        "authors": "VALABOJU SHIVA KUMAR CHARY",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIn this work, we will evaluate the impact of independent component analysis (ICA) on a breast cancer decision support system's feature reduction capabilities. The Wisconsin Diagnostic Breast Cancer (WDBC) dataset will be utilised to construct a one-dimensional feature vector (IC). We will study the performance of k-NN, ANN, RBFNN, and SVM classifiers in spotting mistakes using the original 30 features. Additionally, we will compare the IC-recommended classification with the original feature set using multiple validation and division approaches. The classifiers will be tested based on specificity, sensitivity, accuracy, F-score, Youden's index, discriminant power, and receiver operating characteristic (ROC) curve. This effort attempts to boost the medical decision support system's efficiency while minimising computational complexity.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3531811/v1"
    },
    {
        "id": 5586,
        "title": "AD-TUNING: An Adaptive CHILD-TUNING Approach to Efficient Hyperparameter Optimization of Child Networks for Speech Processing Tasks in the SUPERB Benchmark",
        "authors": "Gaobin Yang, Jun Du, Maokui He, Shutong Niu, Baoxiang Li, Jiakui Li, Chin-Hui Lee",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1167"
    },
    {
        "id": 5587,
        "title": "An Introduction to Simple Linear Regression",
        "authors": "Tshepo Chris Nokeri",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6870-4_1"
    },
    {
        "id": 5588,
        "title": "A Simple Gaussian Kernel Classifier with Automated Hyperparameter Tuning",
        "authors": "Kosuke Fukumori, Toshihisa Tanaka",
        "published": "2019-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/apsipaasc47483.2019.9023147"
    },
    {
        "id": 5589,
        "title": "Optimal Hyperparameter Tuning using Meta-Learning for Big Traffic Datasets",
        "authors": "Khac-Hoai Nam Bui, Hongsuk Yi",
        "published": "2020-2",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigcomp48618.2020.0-100"
    },
    {
        "id": 5590,
        "title": "Hyperparameter self-tuning for data streams",
        "authors": "Bruno Veloso, João Gama, Benedita Malheiro, João Vinagre",
        "published": "2021-12",
        "citations": 22,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.inffus.2021.04.011"
    },
    {
        "id": 5591,
        "title": "The Role of Hyperparameter Optimization in Fine-Tuning of Cnn Models",
        "authors": "Mikolaj Wojciuk, Zaneta Swiderska-Chadaj, Krzysztf Siwek, Arkadiusz Gertych",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4087642"
    },
    {
        "id": 5592,
        "title": "Everyone’s a Winner! On Hyperparameter Tuning of Recommendation Models",
        "authors": "Faisal Shehzad, Dietmar Jannach",
        "published": "2023-9-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3604915.3609488"
    },
    {
        "id": 5593,
        "title": "Analysis of Hyperparameter Tuning in Neural Style Transfer",
        "authors": "Siddhant Khandelwal, Sarthak Rana, Kavita Pandey, Prashant Kaushik",
        "published": "2018-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/pdgc.2018.8745881"
    },
    {
        "id": 5594,
        "title": "Improved Energy Consumption Prediction using XGBoost with Hyperparameter tuning",
        "authors": "Yashaswini. R, Vinay. S",
        "published": "2022-12-26",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icerect56837.2022.10060356"
    },
    {
        "id": 5595,
        "title": "Grid Search-Based Hyperparameter Tuning and Classification of Microarray Cancer Data",
        "authors": "B. H Shekar, Guesh Dagnew",
        "published": "2019-2",
        "citations": 91,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icaccp.2019.8882943"
    },
    {
        "id": 5596,
        "title": "Case Study I: Tuning Random Forest (Ranger)",
        "authors": "Thomas Bartz-Beielstein, Sowmya Chandrasekaran, Frederik Rehbach, Martin Zaefferer",
        "published": "2023",
        "citations": 0,
        "abstract": "AbstractThis case study gives a hands-on description of Hyperparameter Tuning (HPT) methods discussed in this book. The Random Forest (RF) method and its implementation  was chosen because it is the method of the first choice in many Machine Learning (ML) tasks. RF is easy to implement and robust. It can handle continuous as well as discrete input variables. This and the following two case studies follow the same HPT pipeline: after the data set is provided and pre-processed, the experimental design is set up. Next, the HPT experiments are performed. The R package  is used as a “datascope” to analyze the results from the HPT runs from several perspectives: in addition to Classification and Regression Trees (CART), the analysis combines results from surface, sensitivity and parallel plots with a classical regression analysis. Severity is used to discuss the practical relevance of the results from an error-statistical point-of-view. The well proven R package  is used as a uniform interface from the methods of the packages  and  to the ML methods. The corresponding source code is explained in a comprehensible manner.",
        "link": "http://dx.doi.org/10.1007/978-981-19-5170-1_8"
    },
    {
        "id": 5597,
        "title": "Case Study III: Tuning of Deep Neural Networks",
        "authors": "Thomas Bartz-Beielstein, Sowmya Chandrasekaran, Frederik Rehbach",
        "published": "2023",
        "citations": 2,
        "abstract": "AbstractA surrogate model based Hyperparameter Tuning (HPT) approach for Deep Learning (DL) is presented. This chapter demonstrates how the architecture-level parameters (hyperparameters) of Deep Neural Networks (DNNs) that were implemented in / can be optimized. The implementation of the tuning procedure is 100% accessible from R, the software environment for statistical computing. How the software packages (, , and ) can be combined in a very efficient and effective manner will be exemplified in this chapter. The hyperparameters of a standard DNN are tuned. The performances of the six Machine Learning (ML) methods discussed in this book are compared to the results from the DNN. This study provides valuable insights in the tunability of several methods, which is of great importance for the practitioner.",
        "link": "http://dx.doi.org/10.1007/978-981-19-5170-1_10"
    },
    {
        "id": 5598,
        "title": "Use of Augmentation Data and Hyperparameter Tuning in Batik Type Classification using the CNN Model",
        "authors": "Siti Auliaddina, Toni Arifin",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32520/stmsi.v13i1.3395"
    },
    {
        "id": 5599,
        "title": "U-Net Tuning Hyperparameter for Segmentation in Amniotic Fluid Ultrasonography Image",
        "authors": "Putu Desiana Wulaning Ayu, Gede Angga Pradipta",
        "published": "2022-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icoris56080.2022.10031294"
    },
    {
        "id": 5600,
        "title": "A MOM-based ensemble method for robustness, subsampling and hyperparameter tuning",
        "authors": "Joon Kwon, Guillaume Lecué, Matthieu Lerasle",
        "published": "2021-1-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1214/21-ejs1814"
    }
]