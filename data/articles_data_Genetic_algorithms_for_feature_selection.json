[
    {
        "id": 33905,
        "title": "Special Issue “Algorithms for Feature Selection”",
        "authors": "Muhammad Adnan Khan",
        "published": "2023-7-31",
        "citations": 1,
        "abstract": "This Special Issue of the open access journal Algorithms is dedicated to showcasing cutting-edge research in algorithms for feature selection [...]",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/a16080368"
    },
    {
        "id": 33906,
        "title": "Feature selection using genetic algorithms for improving accuracy in image classification tasks",
        "authors": "Andrei Dugaesescu, David-Traian Iancu",
        "published": "2023-6-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ecai58194.2023.10194193"
    },
    {
        "id": 33907,
        "title": "Automated Feature Engineering for AutoML Using Genetic Algorithms",
        "authors": "Kevin Shi, Sherif Saad",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012090400003555"
    },
    {
        "id": 33908,
        "title": "Assessing the Ability of Genetic Programming for Feature Selection in Constructing Dispatching Rules for Unrelated Machine Environments",
        "authors": "Marko Đurasević, Domagoj Jakobović, Stjepan Picek, Luca Mariot",
        "published": "2024-2-4",
        "citations": 0,
        "abstract": "The automated design of dispatching rules (DRs) with genetic programming (GP) has become an important research direction in recent years. One of the most important decisions in applying GP to generate DRs is determining the features of the scheduling problem to be used during the evolution process. Unfortunately, there are no clear rules or guidelines for the design or selection of such features, and often the features are simply defined without investigating their influence on the performance of the algorithm. However, the performance of GP can depend significantly on the features provided to it, and a poor or inadequate selection of features for a given problem can result in the algorithm performing poorly. In this study, we examine in detail the features that GP should use when developing DRs for unrelated machine scheduling problems. Different types of features are investigated, and the best combination of these features is determined using two selection methods. The obtained results show that the design and selection of appropriate features are crucial for GP, as they improve the results by about 7% when only the simplest terminal nodes are used without selection. In addition, the results show that it is not possible to outperform more sophisticated manually designed DRs when only the simplest problem features are used as terminal nodes. This shows how important it is to design appropriate composite terminal nodes to produce high-quality DRs.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/a17020067"
    },
    {
        "id": 33909,
        "title": "AN ANALYSIS OF FEATURE SELECTION TECHNIQUES FOR AN EVOLUTIONARY APPROACH TO GENETIC ALGORITHMS",
        "authors": "V Vasanthi, E Vishnu Prasath, R Manoj Kumar, R Mukesh",
        "published": "2023-1-1",
        "citations": 0,
        "abstract": "Data magnitude is growing expeditiously, which pretends the challenges to extensive majority of current mining and\nlearning algorithms, such as the bane of dimensionality, huge storage requirement, and enormous computational cost.\nFeature selection has been proven to be an effective and efcient way to prepare high-dimensional data for data mining and machine learning. The\nrecent evolution of novel techniques and new types of data and aspects not only advances existing feature selection research but also emerges the\nfeature selection constantly, becoming applicable to a expansive range of applications. In this entry, we aim to provide a basic introduction to\nfeature selection including basic concepts, classications of existing systems, recent development, and applications.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36106/ijar/9214104"
    },
    {
        "id": 33910,
        "title": "Modeling the Telemarketing Process Using Genetic Algorithms and Extreme Boosting: Feature Selection and Cost-Sensitive Analytical Approach",
        "authors": "Nazeeh Ghatasheh, Ismail Altaharwa, Khaled Aldebei",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3292840"
    },
    {
        "id": 33911,
        "title": "Carousel Greedy Algorithms for Feature Selection in Linear Regression",
        "authors": "Jiaqi Wang, Bruce Golden, Carmine Cerrone",
        "published": "2023-9-19",
        "citations": 0,
        "abstract": "The carousel greedy algorithm (CG) was proposed several years ago as a generalized greedy algorithm. In this paper, we implement CG to solve linear regression problems with a cardinality constraint on the number of features. More specifically, we introduce a default version of CG that has several novel features. We compare its performance against stepwise regression and more sophisticated approaches using integer programming, and the results are encouraging. For example, CG consistently outperforms stepwise regression (from our preliminary experiments, we see that CG improves upon stepwise regression in 10 of 12 cases), but it is still computationally inexpensive. Furthermore, we show that the approach is applicable to several more general feature selection problems.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/a16090447"
    },
    {
        "id": 33912,
        "title": "FSF-GA: A Feature Selection Framework for Phenotype Prediction Using Genetic Algorithms",
        "authors": "Mohammad Erfan Mowlaei, Xinghua Shi",
        "published": "2023-5-9",
        "citations": 1,
        "abstract": "(1) Background: Phenotype prediction is a pivotal task in genetics in order to identify how genetic factors contribute to phenotypic differences. This field has seen extensive research, with numerous methods proposed for predicting phenotypes. Nevertheless, the intricate relationship between genotypes and complex phenotypes, including common diseases, has resulted in an ongoing challenge to accurately decipher the genetic contribution. (2) Results: In this study, we propose a novel feature selection framework for phenotype prediction utilizing a genetic algorithm (FSF-GA) that effectively reduces the feature space to identify genotypes contributing to phenotype prediction. We provide a comprehensive vignette of our method and conduct extensive experiments using a widely used yeast dataset. (3) Conclusions: Our experimental results show that our proposed FSF-GA method delivers comparable phenotype prediction performance as compared to baseline methods, while providing features selected for predicting phenotypes. These selected feature sets can be used to interpret the underlying genetic architecture that contributes to phenotypic variation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/genes14051059"
    },
    {
        "id": 33913,
        "title": "Comparative Analysis of Feature Selection Algorithms for Automated IoT Device Fingerprinting",
        "authors": "Ahmet Aksoy, Sundeep Varma, Ganesha Moorthy, Enya Pan, Gorkem Kar",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012379100003648"
    },
    {
        "id": 33914,
        "title": "Simultaneously feature selection and parameters optimization by teaching–learning and genetic algorithms for diagnosis of breast cancer",
        "authors": "Alok Kumar Shukla",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s41060-024-00513-0"
    },
    {
        "id": 33915,
        "title": "GA-FCFNN: A new forecasting method combining feature selection methods and feedforward neural networks using genetic algorithms",
        "authors": "Rongtao Zhang, Xueling Ma, Chao Zhang, Weiping Ding, Jianming Zhan",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ins.2024.120566"
    },
    {
        "id": 33916,
        "title": "FEATURE SELECTION WITH GENETIC ALGORITHMS AND ITS EFFECT ON CLASSIFICATION PERFORMANCE IN MEDICAL DATASETS",
        "authors": "Ömer DEPERLİOĞLU",
        "published": "2023-3-27",
        "citations": 0,
        "abstract": "Günümüzde çok büyük boyuttaki tıbbi veri tabanlarından, klinik karar destek sistemlerinin faydalı bilgiler elde etmesi oldukça zorlaşmıştır. Genetik algoritmalar (GA) yaygın olarak kullanılan bir özellik seçme yöntemidir ve en iyi çözümleri verebilir. Bu çalışmada, çok sayıda karmaşık verilere sahip olan tıbbi verilerden özellik seçimi yapmak ve en uygun özellik alt kümesini oluşturarak sınıflandırma başarısını artırmak için GA içeren bir model önerilmiştir. Önerilen yöntemin performansını değerlendirmek için çalışmada en çok bilinen ve rahatlıkla ulaşılabilen 5 tıbbi veri kümesi ve 7 farklı denetimli sınıflandırma yöntemi kullanılmıştır. Her veri kümesi ile her sınıflandırıcı için ayrı ayrı özellik seçimi ve sınıflandırma uygulamaları yapılmıştır.  Bu uygulamalarda elde edilen sonuçlar, önerilen yaklaşımla yapılan sınıflandırmalarda, veri kümesine bağlı olarak, Doğruluk oranında dolayısıyla makine öğrenmesi modeli performansında ortalama %2 ile %21 arasında artış sağlandığını ortaya koymuştur. Ayrıca yapılan çalışmalarda denetimli sınıflandırma algoritmalarından Rastgele Ormanın bütün veri kümelerinde diğer algoritmalardan daha iyi sonuçlar verdiği görülmekte ve tıbbi veri kümelerindeki sınıflandırma başarısı ile öne çıktığı görülmüştür.",
        "keywords": "",
        "link": "http://dx.doi.org/10.21923/jesd.1117976"
    },
    {
        "id": 33917,
        "title": "GAAMmf: genetic algorithm with aggressive mutation and decreasing feature set for feature selection",
        "authors": "Rejer Izabela, Lorenz Krzysztof",
        "published": "2023-12",
        "citations": 0,
        "abstract": "AbstractThis paper introduces a modified version of a genetic algorithm with aggressive mutation (GAAM), one of the genetic algorithms (GAs) used for feature selection. The modification proposed in this study expands the original GAAM’s capabilities by allowing not only feature selection but also feature reduction. To obtain this effect, we applied the concept of ranks used in the non-dominated sorting genetic algorithm (NSGA) and the concept of penalty term used in the Holland genetic algorithm. With those two concepts, we managed to balance the importance of two competing criteria in the GAAM fitness function: classification accuracy and the feature subset’s size. To assess the algorithm’s effectiveness, we evaluated it on eleven datasets with different characteristics and compared the results with eight reference methods: GAAM, Melting GAAM, Holland GA with a penalty term, NSGA-II, Correlation-based Feature Selection, Lasso, Sequential Forward Selection, and IniPG (an algorithm for particle swarm optimisation). The main conclusion drawn from this study is that the genetic algorithm with aggressive mutation and decreasing feature set (GAAMmf) introduced in this paper returned feature sets with a significantly smaller number of features than almost all reference methods. Furthermore, GAAMmf outperformed most of the methods in terms of classification accuracy (except the original GAAM). In contrast to Holland GA and NSGA-II, GAAMmf was able to perform the feature reduction task for all datasets, regardless of the initial number of features.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10710-023-09458-y"
    },
    {
        "id": 33918,
        "title": "Enhancing feature selection with a novel hybrid approach incorporating genetic algorithms and swarm intelligence techniques",
        "authors": "Salsabila Benghazouani, Said Nouh, Abdelali Zakrani, Ihsane Haloum, Mostafa Jebbar",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "Computing advances in data storage are leading to rapid growth in large-scale datasets. Using all features increases temporal/spatial complexity and negatively influences performance. Feature selection is a fundamental stage in data preprocessing, removing redundant and irrelevant features to minimize the number of features and enhance the performance of classification accuracy. Numerous optimization algorithms were employed to handle feature selection (FS) problems, and they outperform conventional FS techniques. However, there is no metaheuristic FS method that outperforms other optimization algorithms in many datasets. This motivated our study to incorporate the advantages of various optimization techniques to obtain a powerful technique that outperforms other methods in many datasets from different domains. In this article, a novel combined method GASI is developed using swarm intelligence (SI) based feature selection techniques and genetic algorithms (GA) that uses a multi-objective fitness function to seek the optimal subset of features. To assess the performance of the proposed approach, seven datasets have been collected from the UCI repository and exploited to test the newly established feature selection technique. The experimental results demonstrate that the suggested method GASI outperforms many powerful SI-based feature selection techniques studied. GASI obtains a better average fitness value and improves classification performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijece.v14i1.pp944-959"
    },
    {
        "id": 33919,
        "title": "Feature importance feedback with Deep Q process in ensemble-based metaheuristic feature selection algorithms",
        "authors": "Jhansi Lakshmi Potharlanka, Nirupama Bhat M",
        "published": "2024-2-5",
        "citations": 1,
        "abstract": "AbstractFeature selection is an indispensable aspect of modern machine learning, especially for high-dimensional datasets where overfitting and computational inefficiencies are common concerns. Traditional methods often employ either filter, wrapper, or embedded approaches, which have limitations in terms of robustness, computational load, or capability to capture complex interactions among features. Despite the utility of metaheuristic algorithms like Particle Swarm Optimization (PSO), Firefly Algorithm (FA), and Whale Optimization (WOA) in feature selection, there still exists a gap in efficiently incorporating feature importance feedback into these processes. This paper presents a novel approach that integrates the strengths of PSO, FA, and WOA algorithms into an ensemble model and further enhances its performance by incorporating a Deep Q-Learning framework for relevance feedbacks. The Deep Q-Learning module intelligently updates feature importance based on model performance, thereby fine-tuning the selection process iteratively. Our ensemble model demonstrates substantial gains in effectiveness over traditional and individual metaheuristic approaches. Specifically, the proposed model achieved a 9.5% higher precision, an 8.5% higher accuracy, an 8.3% higher recall, a 4.9% higher AUC, and a 5.9% higher specificity across multiple software bug prediction datasets and samples. By resolving some of the key issues in existing feature selection methods and achieving superior performance metrics, this work paves the way for more robust and efficient machine learning models in various applications, from healthcare to natural language processing scenarios. This research provides an innovative framework for feature selection that promises not only superior performance but also offers a flexible architecture that can be adapted for a variety of machine learning challenges.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-024-53141-w"
    },
    {
        "id": 33920,
        "title": "Compressional Sonic Log Prediction Experiment Using Machine Learning: Algorithms and Feature Selection",
        "authors": "R. Afifi, F. Anifowose",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3997/2214-4609.2023631004"
    },
    {
        "id": 33921,
        "title": "Evolutionary Computation for Feature Selection and Feature Construction",
        "authors": "Bing Xue, Mengjie Zhang",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3583133.3595050"
    },
    {
        "id": 33922,
        "title": "STR-based feature extraction and selection for genetic feature discovery in neurological disease genes",
        "authors": "Jasbir Dhaliwal, John Wagner",
        "published": "2023-2-11",
        "citations": 1,
        "abstract": "AbstractGene expression, often determined by single nucleotide polymorphisms, short repeated sequences known as short tandem repeats (STRs), structural variants, and environmental factors, provides means for an organism to produce gene products necessary to live. Variation in expression levels, sometimes known as enrichment patterns, has been associated with disease progression. Thus, the STR enrichment patterns have recently gained interest as potential genetic markers for disease progression. However, to the best of our knowledge, we are unaware of any study that evaluates and explores STRs, particularly trinucleotide sequences, as machine learning features for classifying neurological disease genes for the purpose of discovering genetic features. Thus, in this paper, we proposed a new metric and a novel feature extraction and selection algorithm based on statistically significant STR-based features and their respective enrichment patterns to create a statistically significant feature set. The proposed new metric has shown that the neurological disease family genes have a non-random AA, AT, TA, TG, and TT enrichment pattern. This is an important result, as it supports prior research that has established that certain trinucleotides, such as AAT, ATA, ATT, TAT, and TTA, are favored during protein misfolding. In contrast, trinucleotides, such as TAA, TAG, and TGA, are favored during premature termination codon mutations as they are stop codons. This suggests that the metric has the potential to identify patterns that may be genetic features in a sample of neurological genes. Moreover, the practical performance and high prediction results of the statistically significant STR-based feature set indicate that variations in STR enrichment patterns can distinguish neurological disease genes. In conclusion, the proposed approach may have the potential to discover differential genetic features for other diseases.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-023-29376-4"
    },
    {
        "id": 33923,
        "title": "Literature Review on Hybrid Evolutionary Approaches for Feature Selection",
        "authors": "Jayashree Piri, Puspanjali Mohapatra, Raghunath Dey, Biswaranjan Acharya, Vassilis C. Gerogiannis, Andreas Kanavos",
        "published": "2023-3-20",
        "citations": 7,
        "abstract": "The efficiency and the effectiveness of a machine learning (ML) model are greatly influenced by feature selection (FS), a crucial preprocessing step in machine learning that seeks out the ideal set of characteristics with the maximum accuracy possible. Due to their dominance over traditional optimization techniques, researchers are concentrating on a variety of metaheuristic (or evolutionary) algorithms and trying to suggest cutting-edge hybrid techniques to handle FS issues. The use of hybrid metaheuristic approaches for FS has thus been the subject of numerous research works. The purpose of this paper is to critically assess the existing hybrid FS approaches and to give a thorough literature review on the hybridization of different metaheuristic/evolutionary strategies that have been employed for supporting FS. This article reviews pertinent documents on hybrid frameworks that were published in the period from 2009 to 2022 and offers a thorough analysis of the used techniques, classifiers, datasets, applications, assessment metrics, and schemes of hybridization. Additionally, new open research issues and challenges are identified to pinpoint the areas that have to be further explored for additional study.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/a16030167"
    },
    {
        "id": 33924,
        "title": "Genetic Algorithms and Feature Selection for Improving the Classification Performance in Healthcare",
        "authors": "Alaa Alassaf, Eman Alarbeed, Ghady Alrasheed, Abdulsalam Almirdasie, Shahd Almutairi, Mohammed Abullah Al-Hagery, Faisal Saeed",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14569/ijacsa.2024.0150375"
    },
    {
        "id": 33925,
        "title": "Feature Selection Techniques in Learning Algorithms to Predict Truthful Data",
        "authors": "P Usha,  , M P Anuradha",
        "published": "2023-3-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17485/ijst/v16i10.2102"
    },
    {
        "id": 33926,
        "title": "Investigation of machine learning algorithms on heart disease through dominant feature detection and feature selection",
        "authors": "Fuat Türk",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11760-024-03060-0"
    },
    {
        "id": 33927,
        "title": "Augmentation of Densest Subgraph Finding Unsupervised Feature Selection Using Shared Nearest Neighbor Clustering",
        "authors": "Deepesh Chugh, Himanshu Mittal, Amit Saxena, Ritu Chauhan, Eiad Yafi, Mukesh Prasad",
        "published": "2023-1-3",
        "citations": 1,
        "abstract": "Determining the optimal feature set is a challenging problem, especially in an unsupervised domain. To mitigate the same, this paper presents a new unsupervised feature selection method, termed as densest feature graph augmentation with disjoint feature clusters. The proposed method works in two phases. The first phase focuses on finding the maximally non-redundant feature subset and disjoint features are added to the feature set in the second phase. To experimentally validate, the efficiency of the proposed method has been compared against five existing unsupervised feature selection methods on five UCI datasets in terms of three performance criteria, namely clustering accuracy, normalized mutual information, and classification accuracy. The experimental analyses have shown that the proposed method outperforms the considered methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/a16010028"
    },
    {
        "id": 33928,
        "title": "Evolutionary Multi-Objective Feature Selection Algorithms on Multiple Smart Sustainable Community Indicator Datasets",
        "authors": "Mubarak Saad Almutairi",
        "published": "2024-2-10",
        "citations": 0,
        "abstract": "The conceptual fusion of smart city and sustainability indicators has inspired the emergence of the smart sustainable city (SSC). Given the early stage of development in this field, most SSC studies have been primarily theoretical. Notably, existing empirical studies have overlooked the crucial aspect of feature engineering in the context of SSC, despite its significance in advancing SSC initiatives. This paper introduces an approach advocating for feature subset selection to maximize prediction accuracy and minimize computational time across diverse SSC indicators encompassing socio-cultural, economic, environmental, and governance categories. The study systematically collected multiple datasets on SSC indicators, covering various themes within the SSC framework. Employing six carefully chosen multiple-objective evolutionary feature selection algorithms, the research selected feature subsets. These subsets were then utilized in modeling algorithms to predict SSC indicators. The proposal enhanced prediction accuracy for life expectancy, online shopping intentions, energy consumption, air quality, water quality, and traffic flow for a smart and sustainable city by minimizing the subset features. The findings underscore the efficacy of feature subset selection in generating minimal features, thereby enhancing both prediction accuracy and computational efficiency in the realm of SSC indicators. For researchers aiming to develop sustainable systems for real-time data monitoring within SSC, the identified subset features offer a valuable resource, negating the necessity for extensive dataset collection. The provided SSC datasets are anticipated to serve as a catalyst, inspiring researchers to embark on empirical studies that explore SSC development from diverse perspectives, ultimately contributing to a more profound understanding of the SSC dynamics.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/su16041511"
    },
    {
        "id": 33929,
        "title": "A Review on Optimization Algorithms for Feature Selection",
        "authors": "T.S. Sindhu, N. Kumaratharan, P. Anandan",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icscss57650.2023.10169444"
    },
    {
        "id": 33930,
        "title": "Feature Selection Using Quantum Inspired Island Model Genetic Algorithm for Wheat Rust Disease Detection and Severity Estimation",
        "authors": "Sourav Samanta, Sanjay Chatterji, Sanjoy Pratihar",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012380000003660"
    },
    {
        "id": 33931,
        "title": "A Comparative Analysis of Nature-Inspired Feature Selection Algorithms in Predicting Student Performance",
        "authors": "Thomas Trask",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00256"
    },
    {
        "id": 33932,
        "title": "A Fuzzy Integral Approach for Ensembling Unsupervised Feature Selection Algorithms",
        "authors": "Amin Hashemi, Mohammad Bagher Dowlatshahi",
        "published": "2023-1-25",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/csicc58665.2023.10105330"
    },
    {
        "id": 33933,
        "title": "Indoor Scene Recognition: An Attention-Based Approach Using Feature Selection-Based Transfer Learning and Deep Liquid State Machine",
        "authors": "Ranjini Surendran, Ines Chihi, J. Anitha, D. Jude Hemanth",
        "published": "2023-9-8",
        "citations": 1,
        "abstract": "Scene understanding is one of the most challenging areas of research in the fields of robotics and computer vision. Recognising indoor scenes is one of the research applications in the category of scene understanding that has gained attention in recent years. Recent developments in deep learning and transfer learning approaches have attracted huge attention in addressing this challenging area. In our work, we have proposed a fine-tuned deep transfer learning approach using DenseNet201 for feature extraction and a deep Liquid State Machine model as the classifier in order to develop a model for recognising and understanding indoor scenes. We have included fuzzy colour stacking techniques, colour-based segmentation, and an adaptive World Cup optimisation algorithm to improve the performance of our deep model. Our proposed model would dedicatedly assist the visually impaired and blind to navigate in the indoor environment and completely integrate into their day-to-day activities. Our proposed work was implemented on the NYU depth dataset and attained an accuracy of 96% for classifying the indoor scenes.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/a16090430"
    },
    {
        "id": 33934,
        "title": "A filter feature selection for high-dimensional data",
        "authors": "Fatima Zahra Janane, Tayeb Ouaderhman, Hasna Chamlal",
        "published": "2023-1",
        "citations": 4,
        "abstract": " In a classification problem, before building a prediction model, it is very important to identify informative features rather than using tens or thousands which may penalize some learning methods and increase the risk of over-fitting. To overcome these problems, the best solution is to use feature selection. In this article, we propose a new filter method for feature selection, by combining the Relief filter algorithm and the multi-criteria decision-making method called TOPSIS (Technique for Order Preference by Similarity to Ideal Solution), we modeled the feature selection task as a multi-criteria decision problem. Exploiting the Relief methodology, a decision matrix is computed and delivered to Technique for Order Preference by Similarity to Ideal Solution in order to rank the features. The proposed method ends up giving a ranking to the features from the best to the mediocre. To evaluate the performances of the suggested approach, a simulation study including a set of experiments and case studies was conducted on three synthetic dataset scenarios. Finally, the obtained results approve the effectiveness of our proposed filter to detect the best informative features. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1177/17483026231184171"
    },
    {
        "id": 33935,
        "title": "Prediction of Heart Disease using Machine Learning Algorithms with Feature Selection Techniques",
        "authors": "G. Murugesan, C.T. Kavitha, G.G. Jabakumar, E. Swarnalatha",
        "published": "2023-3-1",
        "citations": 0,
        "abstract": "Data is an asset in the digital era, and enormous data was generating day by day in all the fields, including the healthcare industry. The data on the healthcare industry data consists of personal information and disease-related information about a patient and stored in various formats and units. Machine learning and Artificial Intelligence techniques will help us analyze the voluminous amount of data to identify the hidden patterns of a specific disease from the healthcare data and help us predict a particular disease in the future. In this paper, we proposed a decision support system to predict heart disease, especially cardiovascular disease, through machine learning algorithms. This system experimented with the reduced set feature of the UCI Machine learning repository dataset using a linear kernel-based support vector machine algorithm. This system has also compared it with other machine learning algorithms such as K-Nearest Neighbours, Decision tree, and Random forest in Python. All four machine learning algorithms' performance has been evaluated based on accuracy, misclassification rate, precision, recall, and f-score value. From the experimental results, SVM with a linear kernel function classification algorithm produces better accuracy of 95.08% compared with others for predicting heart disease.",
        "keywords": "",
        "link": "http://dx.doi.org/10.18137/cardiometry.2023.26.778786"
    },
    {
        "id": 33936,
        "title": "Impact of Feature Selection Algorithms on Network Intrusion Detection",
        "authors": "Samyak Jain, Siddharth Bihani, Satyam Jaiswal, Anshul Arora",
        "published": "2023-8-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iswta58588.2023.10250134"
    },
    {
        "id": 33937,
        "title": "Early Prediction of Diabetes Using Feature Selection and Machine Learning Algorithms",
        "authors": "Jafar Abdollahi, Solmaz Aref",
        "published": "2024-1-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42979-023-02545-y"
    },
    {
        "id": 33938,
        "title": "Big data feature selection method based on genetic algorithm optimization",
        "authors": "Xiangchao Wang",
        "published": "2023-6-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2671579"
    },
    {
        "id": 33939,
        "title": "AutoFe-Sel: A Meta-learning based methodology for Recommending Feature Subset Selection Algorithms",
        "authors": "",
        "published": "2023-7-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3837/tiis.2023.07.002"
    },
    {
        "id": 33940,
        "title": "Detecting Android Malware with an Enhanced Genetic Algorithm for Feature Selection and Machine Learning",
        "authors": "B. Swarajya Lakshmi, S. Pranavi, C. Jayalakshmi, K. Gayatri, M. Sireesha, A. Akhila",
        "published": "2023-4-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.55248/gengpi.2023.4.4.34984"
    },
    {
        "id": 33941,
        "title": "A feature-thresholds guided genetic algorithm based on a multi-objective feature scoring method for high-dimensional feature selection",
        "authors": "Shaobo Deng, Yulong Li, Junke Wang, Rutun Cao, Min Li",
        "published": "2023-11",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.asoc.2023.110765"
    },
    {
        "id": 33942,
        "title": "Classification of the Cardiac Arrhythmia Using Combined Feature Selection Algorithms",
        "authors": "Murat Tunç, Gülnur Begüm Cangöz",
        "published": "2024-3-28",
        "citations": 0,
        "abstract": "The prediction of heart disease has gained great importance in recent years. Efficient monitoring of cardiac patients can save tremendous number of lives. This paper presents a method for classification and prediction of electrocardiogram data obtained from 452 patients representing the risk of cardiac arrhythmia. The aim of the study is to select highly related features with arrhythmia risk by using three different feature selection algorithms. In addition, various machine learning models are utilized for the classification task such as k-Nearest Neighbors (k-NN), Support Vector Machines (SVM) and Decision Tree (DT). The experimental results show that combination of a purposed feature selection method which later is called “Matched Selection” using SVM classifier outperforms other combinations and have an accuracy of 81.27% while k-NN and DT classifiers have an accuracy of 69.66% and 73.50% respectively. The study, in which detailed analyses are presented comparatively, is promising for the future studies.",
        "keywords": "",
        "link": "http://dx.doi.org/10.55525/tjst.1324854"
    },
    {
        "id": 33943,
        "title": "Modified K-Means Clustering Algorithms for Feature Selection",
        "authors": "Ayeasha Akhter, Ken Ferens",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/csce60160.2023.00083"
    },
    {
        "id": 33944,
        "title": "Breast Cancer Prediction Feature Selection Using ML Algorithms",
        "authors": "Lin Jiang",
        "published": "2023-7-1",
        "citations": 0,
        "abstract": "Abstract\nBreast cancer is a disease that breast epithelial cells uncontrolled hyperplasia under the effects of several different carcinogens. The early symptoms of breast cancer are breast lesions, nipple discharge and axillary fossa lymphadenectasis. Breast cancer can directly threat the life of patient by casing various organ lesions and metastasis of cancer cells in the late stage of suffering from this disease. The method of classifying tumors into malignant or benign is the main challenge that needed to be dealt with to treat patient in a correct way. This paper shows the different classification models to predict the kind of breast cancer. All data used to distinguish the type of breast cancer in the research comes from UCI repository. Some simple classifiers are employed in the research, for instance, Decision Tree Classifier, Extreme Gradient Boosting, Naïve Bayes Classifier, Gradient Boosting, Support Vector Machine. The results show that using Support Vector Machine algorithm the prediction accuracy of breast cancer reaches 99.7%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1742-6596/2547/1/012021"
    },
    {
        "id": 33945,
        "title": "Data Quality Assessment and Recommendation of Feature Selection Algorithms: An Ontological Approach",
        "authors": "Aparna Nayak, Bojan Božić, Luca Longo",
        "published": "2023-4-20",
        "citations": 0,
        "abstract": "Feature selection plays an important role in machine learning and data mining problems. Identifying the best feature selection algorithm that helps to remove irrelevant and redundant features is a complex task. This research tries to address it by recommending a feature selection algorithm based on dataset meta-features. The main contribution of the work is the use of Semantic Web principles to develop a recommendation model for the feature selection algorithm. As a result, dataset meta-features are modeled in a domain ontology, and a set of Semantic Web rule language (SWRL) predictive rules have been proposed to recommend a feature selection algorithm. The result of this research is a feature selection algorithm recommendation based on the data characteristics and quality (FSDCQ) ontology, which not only helps with recommendations but also finds the data points with data quality violations. An experiment is conducted on the classification datasets from the UCI repository to evaluate the proposed ontology. The usefulness and effectiveness of the proposed method is evaluated by comparing it with the widely used method in the literature for the recommendation. Results show that the ontology-based recommendations are equally good as the widely used recommendation model, which is k-NN, with added benefits.",
        "keywords": "",
        "link": "http://dx.doi.org/10.13052/jwe1540-9589.2219"
    },
    {
        "id": 33946,
        "title": "Automated Network Incident Identification through Genetic Algorithm-Driven Feature Selection",
        "authors": "Ahmet Aksoy, Luis Valle, Gorkem Kar",
        "published": "2024-1-9",
        "citations": 0,
        "abstract": "The cybersecurity landscape presents daunting challenges, particularly in the face of Denial of Service (DoS) attacks such as DoS Http Unbearable Load King (HULK) attacks and DoS GoldenEye attacks. These malicious tactics are designed to disrupt critical services by overwhelming web servers with malicious requests. In contrast to DoS attacks, there exists nefarious Operating System (OS) scanning, which exploits vulnerabilities in target systems. To provide further context, it is essential to clarify that NMAP, a widely utilized tool for identifying host OSes and vulnerabilities, is not inherently malicious but a dual-use tool with legitimate applications, such as asset inventory services in company networks. Additionally, Domain Name System (DNS) botnets can be incredibly damaging as they harness numerous compromised devices to inundate a target with malicious DNS traffic. This can disrupt online services, leading to downtime, financial losses, and reputational damage. Furthermore, DNS botnets can be used for other malicious activities like data exfiltration, spreading malware, or launching other cyberattacks, making them a versatile tool for cybercriminals. As attackers continually adapt and modify specific attributes to evade detection, our paper introduces an automated detection method that requires no expert input. This innovative approach identifies the distinct characteristics of DNS botnet attacks, DoS HULK attacks, DoS GoldenEye attacks, and OS-Scanning, explicitly using the NMAP tool, even when attackers alter their tactics. By harnessing a representative dataset, our proposed method ensures robust detection of such attacks against varying attack parameters or behavioral shifts. This heightened resilience significantly raises the bar for attackers attempting to conceal their malicious activities. Significantly, our approach delivered outstanding outcomes, with a mid 95% accuracy in categorizing NMAP OS scanning and DNS botnet attacks, and 100% for DoS HULK attacks and DoS GoldenEye attacks, proficiently discerning between malevolent and harmless network packets. Our code and the dataset are made publicly available.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics13020293"
    },
    {
        "id": 33947,
        "title": "A comparative study of bread wheat varieties identification on feature extraction, feature selection and machine learning algorithms",
        "authors": "Serhat Kılıçarslan, Sabire Kılıçarslan",
        "published": "2024-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00217-023-04372-0"
    },
    {
        "id": 33948,
        "title": "Feature selection based on improved principal component analysis",
        "authors": "Zhangyu Li, Yihui Qiu",
        "published": "2023-3-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3590003.3590036"
    },
    {
        "id": 33949,
        "title": "Twitter Data Feature Selection Using Enhanced Genetic Algorithm",
        "authors": "K. Brindha, E. Ramadevi",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "Feature selection is a basic critical task in sentiment analysis, especially while analyzing Twitter data for stock market sentiment. This paper proposes an enhanced genetic algorithm (GA) for feature selection utilizing Finance Yahoo stocks data and openly accessible Twitter data. The objective is to distinguish the most relevant features that can successfully anticipate stock market sentiment. The proposed GA integrates methods to enhance the investigation and double-dealing capacities, empowering it to look through a bigger feature space and work on the nature of chosen features. The algorithm starts by introducing a populace of random binary chromosomes, with every chromosome addressing a feature subset. Wellness assessment is performed utilizing sentiment analysis strategies to survey the prescient force of each feature subset. Trial assessment utilizing Finance Yahoo stocks and Twitter data shows that the enhanced GA beats customary GA and PSO strategies concerning exactness and forecast performance. The proposed approach gives important experiences to sentiment analysis and feature selection with regards to stock market sentiment utilizing Twitter data.",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/tjjpt.v44.i4.2670"
    },
    {
        "id": 33950,
        "title": "Research on Computational Methods and Algorithms for  Dimensionality Reduction and Feature Selection in High-Dimensional Data",
        "authors": "",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.33168/jliss.2023.0301"
    },
    {
        "id": 33951,
        "title": "Recognition of Disease in Leaves Using Genetic Algorithm and Neural Network Based Feature Selection",
        "authors": "D Angayarkanni,  , L Jayasimman",
        "published": "2023-5-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17485/ijst/v16i19.218"
    },
    {
        "id": 33952,
        "title": "Fusion of Feature Selection Techniques and Machine learning Algorithms for Attack Classification on 802.11 Wi-Fi AWID Dataset",
        "authors": "Sofia Jamil, Mayank Agarwal",
        "published": "2023-6-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/gcon58516.2023.10183427"
    },
    {
        "id": 33953,
        "title": "Genetic Algorithm based Feature Selection to Enhance Breast Cancer Classification",
        "authors": "Utpal Kant Singh, Minakhi Rout",
        "published": "2023-4-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/inc457730.2023.10263100"
    },
    {
        "id": 33954,
        "title": "Evolutionary Algorithms Based Feature Selection For Remote Sensing Image Classification",
        "authors": "Mohammed Bilel Amri, Dounia Yedjour, Mohammed El Amin Larabi",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icfsp59764.2023.10372938"
    },
    {
        "id": 33955,
        "title": "Descriptive Analysis of Feature Selection and Clustering Algorithms for Optimized Drug Toxicity Prediction Model",
        "authors": "Deepak Rawat,  Meenakshi, Rohit Bajaj",
        "published": "2023-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ic3i59117.2023.10397782"
    },
    {
        "id": 33956,
        "title": "Analysis of Different Variants of Relief Based Algorithms for Feature Selection in Medical Applications",
        "authors": "Alok Kumar, Mahipal Singh Choudhry",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccis60361.2023.10425149"
    },
    {
        "id": 33957,
        "title": "Review of Metaheuristic Algorithms in Feature Selection based on Parkinson Disease",
        "authors": "Edjola K. Naka",
        "published": "2023-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cscs59211.2023.00042"
    },
    {
        "id": 33958,
        "title": "EEG Multi-Objective Feature Selection using a Genetic Procedure with Hybrid Mutation Operator",
        "authors": "Corina Cîmpanu",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cscs59211.2023.00029"
    },
    {
        "id": 33959,
        "title": "Fast Genetic Algorithm for feature selection — A qualitative approximation approach",
        "authors": "Mohammed Ghaith Altarabichi, Sławomir Nowaczyk, Sepideh Pashami, Peyman Sheikholharam Mashhadi",
        "published": "2023-7-15",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3583133.3595823"
    },
    {
        "id": 33960,
        "title": "Enhancing intrusion detection with imbalanced data classification and feature selection in machine learning algorithms",
        "authors": "",
        "published": "2024-3-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.19101/ijatee.2023.10101620"
    },
    {
        "id": 33961,
        "title": "Feature Selection and Dimensionality Reduction for Unbalanced Liver Disease Classification with Optimized Machine Learning Algorithms",
        "authors": "Abd Allah Aouragh, Mohamed Bahaj",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cist56084.2023.10409967"
    },
    {
        "id": 33962,
        "title": "Scale Abbreviation with Recursive Feature Elimination and Genetic Algorithms: An Illustration with the Test Emotions Questionnaire",
        "authors": "Sevilay Kilmen, Okan Bulut",
        "published": "2023-1-21",
        "citations": 1,
        "abstract": "Psychological scales play a key role in the assessment, screening, and diagnosis of latent variables, such as emotions, mental health, and well-being. In practice, researchers need shorter scales of psychological traits to save administration time and cost. Thus, a variety of optimization algorithms have been proposed to abbreviate lengthy psychological scales into shorter instruments efficiently. The main goal of this application is to form an abbreviated scale with fewer items while maintaining reliability, relationships among the subscales, and model fit for the full scale. In this study, we use an optimization algorithm (genetic algorithm) and a feature selection algorithm (recursive feature elimination) to abbreviate a psychological scale automatically. Although both algorithms search for an optimal subset of features within a large pool of features, the search mechanism underlying each algorithm is quite different. The genetic algorithm employs a systematic but computationally-expensive sampling process to find the optimal features, whereas recursive feature elimination removes the least important features iteratively until a desired number of features are retained. In this study, we use a 77-item measure of test emotions (Test Emotions Questionnaire) to demonstrate how these algorithms can be used for scale abbreviation. We generate a 40-item short form using each algorithm and compare the quality of the selected items against the full-length scale. The results indicate that both methods can provide researchers and practitioners with a systematic procedure for creating psychometrically sound, shorter versions of lengthy psychological instruments.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/info14020063"
    },
    {
        "id": 33963,
        "title": "Efficient Feature Selection Approach for Prediction of Cervical Cancer Using Machine Learning Algorithms",
        "authors": "Alauddeen Shaikh, Priyanka Verma, Ketki Deshmukh",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mosicom59118.2023.10458795"
    },
    {
        "id": 33964,
        "title": "Feature Selection Based Ensemble Support Vector Machine for Financial Fraud Detection in IoT",
        "authors": "Sreekanth Rallapalli, Dattaguru Hegde, Ramya Thatikonda",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/easct59475.2023.10392566"
    },
    {
        "id": 33965,
        "title": "Comparison of Various Feature Selection Algorithms in Speech Emotion Recognition",
        "authors": "Kamaldeep Kaur, Parminder Singh",
        "published": "2023-8-17",
        "citations": 0,
        "abstract": "Speech Emotion Recognition (SER) plays a predominant role in human-machine interaction. SER is a challenging task because of number of complexities involved in it. For an accurate emotion classification system, feature extraction is the first and important step carried out on speech signals. And after the features are extracted, it is very important to select the best features out of all and reject the redundant and least important features. Feature selection methods play an important role in SER performance. The classifier gets the selected features, so as to reduce the unnecessary overload and perform better to classify the emotions. In this study, a good combination of features is selected from Punjabi Emotional Speech Database. Then a number of feature selection algorithms are explored and experimented upon, to select the best features. 1D-CNN is used for classification purpose. The results are shown and compared on the basis of number of performance metrics. LASSO has shown the best performance results as compared to other feature selection methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.53799/ajse.v22i2.357"
    },
    {
        "id": 33966,
        "title": "Genetic algorithm for feature selection of EEG heterogeneous data",
        "authors": "Aurora Saibene, Francesca Gasparini",
        "published": "2023-5",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2022.119488"
    },
    {
        "id": 33967,
        "title": "Exploring SLUG: Feature Selection Using Genetic Algorithms and Genetic Programming",
        "authors": "Nuno M. Rodrigues, João E. Batista, William La Cava, Leonardo Vanneschi, Sara Silva",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "AbstractWe present SLUG, a recent method that uses genetic algorithms as a wrapper for genetic programming and performs feature selection while inducing models. SLUG was shown to be successful on different types of classification tasks, achieving state-of-the-art results on the synthetic datasets produced by GAMETES, a tool for embedding epistatic gene–gene interactions into noisy datasets. SLUG has also been studied and modified to demonstrate that its two elements, wrapper and learner, are the right combination that grants it success. We report these results and test SLUG on an additional six GAMETES datasets of increased difficulty, for a total of four regular and 16 epistatic datasets. Despite its slowness, SLUG achieves the best results and solves all but the most difficult classification tasks. We perform further explorations of its inner dynamics and discover how to improve the feature selection by enriching the communication between wrapper and learner, thus taking the first step toward a new and more powerful SLUG.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42979-023-02106-3"
    },
    {
        "id": 33968,
        "title": "Study of the Various Selection Techniques in Genetic Algorithms",
        "authors": "Parminder Kaur",
        "published": "2023-3-20",
        "citations": 0,
        "abstract": "This study examines a variety of selection strategies typically employed in contemporary genetic algorithms. This paper examines the classification of various selection procedures and their merits and downsides.  Key Words: Genetic Algorithms, Genetic operators, diversity",
        "keywords": "",
        "link": "http://dx.doi.org/10.55041/ijsrem18264"
    },
    {
        "id": 33969,
        "title": "An Optimized Hybrid Approach for Feature Selection Based on Chi-Square and Particle Swarm Optimization Algorithms",
        "authors": "Amani Abdo, Rasha Mostafa, Laila Abdel-Hamid",
        "published": "2024-1-25",
        "citations": 0,
        "abstract": "Feature selection is a significant issue in the machine learning process. Most datasets include features that are not needed for the problem being studied. These irrelevant features reduce both the efficiency and accuracy of the algorithm. It is possible to think about feature selection as an optimization problem. Swarm intelligence algorithms are promising techniques for solving this problem. This research paper presents a hybrid approach for tackling the problem of feature selection. A filter method (chi-square) and two wrapper swarm intelligence algorithms (grey wolf optimization (GWO) and particle swarm optimization (PSO)) are used in two different techniques to improve feature selection accuracy and system execution time. The performance of the two phases of the proposed approach is assessed using two distinct datasets. The results show that PSOGWO yields a maximum accuracy boost of 95.3%, while chi2-PSOGWO yields a maximum accuracy improvement of 95.961% for feature selection. The experimental results show that the proposed approach performs better than the compared approaches.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/data9020020"
    },
    {
        "id": 33970,
        "title": "Study of feature selection algorithms to improve arrhythmia detection performance on ECG signal",
        "authors": "I Putu Bagus Erix Wijaya, Satria Mandala",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icicyta60173.2023.10429013"
    },
    {
        "id": 33971,
        "title": "Review on Hybrid Swarm Algorithms for Feature Selection",
        "authors": "Abubakr S. Issa, Yossra H. Ali, Tarik A. Rashid",
        "published": "2023-10-30",
        "citations": 0,
        "abstract": "    Feature selection represents one of the critical processes in machine learning (ML). The fundamental aim of the problem of feature selection is to maintain performance accuracy while reducing the dimension of feature selection. Different approaches were created for classifying the datasets. In a range of optimization problems, swarming techniques produced better outcomes. At the same time, hybrid algorithms have gotten a lot of attention recently when it comes to solving optimization problems. As a result, this study provides a thorough assessment of the literature on feature selection problems using hybrid swarm algorithms that have been developed over time (2018-2021). Lastly, when compared with current feature selection procedures, the majority of hybrid algorithms enhance classification accuracy.",
        "keywords": "",
        "link": "http://dx.doi.org/10.24996/ijs.2023.64.10.38"
    },
    {
        "id": 33972,
        "title": "Set-based integer-coded fuzzy granular evolutionary algorithms for high-dimensional feature selection",
        "authors": "H. Saadatmand, M.-R. Akbarzadeh-T",
        "published": "2023-7",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.asoc.2023.110240"
    },
    {
        "id": 33973,
        "title": "A Comparative Analysis of Feature Selection Algorithms for Cancer Classification Using Gene Expression Microarray Data",
        "authors": "Wafaa Mustafa Abduallah",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18280/ria.370316"
    },
    {
        "id": 33974,
        "title": "Software Fault Prediction using Wrapper based Feature Selection Approach employing Genetic Algorithm",
        "authors": "Hrishikesh Kumar, Himansu Das",
        "published": "2023-2-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/otcon56053.2023.10113911"
    },
    {
        "id": 33975,
        "title": "Predicting Dyslexia with Machine Learning: A Comprehensive Review of Feature Selection, Algorithms, and Evaluation Metrics",
        "authors": "Velmurugan S",
        "published": "2023-7-28",
        "citations": 0,
        "abstract": "This literature review explores the use of machine learning-based approaches for the diagnosis and treatment of dyslexia, a learning disorder that affects reading and spelling skills. Various machine learning models, such as artificial neural networks (ANNs), support vector machines (SVMs), and decision trees, have been used to classify individuals as either dyslexic or non-dyslexic based on functional magnetic resonance imaging (fMRI) and electroencephalography (EEG) data. These models have shown promising results for early detection and personalized treatment plans. However, further research is needed to validate these approaches and identify optimal features and models for dyslexia diagnosis and treatment.",
        "keywords": "",
        "link": "http://dx.doi.org/10.35566/jbds/v3n1/s"
    },
    {
        "id": 33976,
        "title": "Wrapper-based optimized feature selection using nature-inspired algorithms",
        "authors": "Namrata Karlupia, Pawanesh Abrol",
        "published": "2023-6",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00521-023-08383-6"
    },
    {
        "id": 33977,
        "title": "BLB-GAFS: An Efficient, Multi-Objective Genetic Algorithm Based Feature Selection Method for Intrusion Detection Systems",
        "authors": "Arihant Singh, Kaushik Roy",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ssci52147.2023.10371959"
    },
    {
        "id": 33978,
        "title": "Genetic Operator based Binary Chaotic Grey Wolf Optimizer for Feature Selection",
        "authors": "Raj Kumar, Tirath Prasad Sahu",
        "published": "2023-2-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/otcon56053.2023.10114026"
    },
    {
        "id": 33979,
        "title": "Feature Selection using Genetic Algorithm for Microarray Data Classification",
        "authors": "Sanjay Prajapati, Himansu Das, Mahendra Kumar Gourisaria",
        "published": "2023-2-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/otcon56053.2023.10113937"
    },
    {
        "id": 33980,
        "title": "Heart Disease Prediction with Feature Selection Based on Metaheuristic Optimization Algorithms and Electronic Filter Model",
        "authors": "Ibrahim Isik",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13369-023-08515-z"
    },
    {
        "id": 33981,
        "title": "An improved feature point selection algorithm for point cloud data",
        "authors": "Xuedong Jing, Xueqi Shan, Yuwei Zhang",
        "published": "2023-5-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2679106"
    },
    {
        "id": 33982,
        "title": "A comparative study of optimization algorithms for feature selection on ML-based classification of agricultural data",
        "authors": "Zeynep Garip, Ekin Ekinci, Murat Erhan Çimen",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10586-023-04165-w"
    },
    {
        "id": 33983,
        "title": "A comparative evaluation of nature-inspired algorithms for feature selection problems",
        "authors": "Mariappan Premalatha, Murugan Jayasudha, Robert Čep, Jayaraju Priyadarshini, Kanak Kalita, Prasenjit Chatterjee",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.heliyon.2023.e23571"
    },
    {
        "id": 33984,
        "title": "Hybrid Feature Selection (RFEMI) Techniques and Intrusion Detection Systems for Web Attacks Detection Using Supervised Machine Learning Algorithms.",
        "authors": "Ibrahim Abobaker",
        "published": "2023-8-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ficloud58648.2023.00020"
    },
    {
        "id": 33985,
        "title": "A Review of Machine Learning Algorithms and Feature Selection Techniques for Cardiovascular Disease Prediction: Insights and Implications",
        "authors": "Abhigya Mahajan, Baijnath Kaushik",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccubea58933.2023.10392135"
    },
    {
        "id": 33986,
        "title": "Analyzing Physics-Inspired Metaheuristic Algorithms in Feature Selection with K-Nearest-Neighbor",
        "authors": "Jayaraju Priyadarshini, Mariappan Premalatha, Robert Čep, Murugan Jayasudha, Kanak Kalita",
        "published": "2023-1-9",
        "citations": 22,
        "abstract": "In recent years, feature selection has emerged as a major challenge in machine learning. In this paper, considering the promising performance of metaheuristics on different types of applications, six physics-inspired metaphor algorithms are employed for this problem. To evaluate the capability of dimensionality reduction in these algorithms, six diverse-natured datasets are used. The performance is compared in terms of the average number of features selected (AFS), accuracy, fitness, convergence capabilities, and computational cost. It is found through experiments that the accuracy and fitness of the Equilibrium Optimizer (EO) are comparatively better than the others. Finally, the average rank from the perspective of average fitness, average accuracy, and AFS shows that EO outperforms all other algorithms.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app13020906"
    },
    {
        "id": 33987,
        "title": "A Feature-Free Approach to Automated Algorithm Selection",
        "authors": "Mohamad Alissa, Kevin Sim, Emma Hart",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3583133.3595832"
    },
    {
        "id": 33988,
        "title": "Exploring the Impact of Univariate Feature Selection Method on Machine Learning Algorithms for Heart Disease Prediction",
        "authors": "Mainul Islam, Rafiqul Islam",
        "published": "2023-6-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ncim59001.2023.10212832"
    },
    {
        "id": 33989,
        "title": "A new ranking-based stability measure for feature selection algorithms",
        "authors": "Deepak Kumar Rakesh, Raj Anwit, Prasanta K. Jana",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00500-022-07767-5"
    },
    {
        "id": 33990,
        "title": "Classification of Parkinson Disease with Feature Selection using Genetic Algorithm",
        "authors": "Mahnoor Iftikhar, Nisar Ali, Raja Hashim Ali, Abdul Bais",
        "published": "2023-9-24",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ccece58730.2023.10288649"
    },
    {
        "id": 33991,
        "title": "Software Reliability Prediction Using Deep Learning  and Feature Selection Algorithms",
        "authors": "Shahbaa I. Khalee, Lumia Faiz Salih",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.47001/irjiet/2024.802002"
    },
    {
        "id": 33992,
        "title": "Optimized Computational Diabetes Prediction with Feature Selection Algorithms",
        "authors": "Xi Li, Michele Curiger, Rolf Dornberger, Thomas Hanne",
        "published": "2023-4-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3596947.3596948"
    },
    {
        "id": 33993,
        "title": "KNN And Naïve Bayes Algorithms for Improving Prediction of Indonesian Film Ratings using Feature Selection Techniques",
        "authors": " Frentzen, Jansen Wiratama, Raymond Sunardi Oetama",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ibdap58581.2023.10271977"
    },
    {
        "id": 33994,
        "title": "Multi-objective metaheuristic optimization algorithms for wrapper-based feature selection: a literature survey",
        "authors": "Anitha Gopalakrishnan, Vinodhini Vadivel",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "In the data mining and machine learning (ML) discipline, feature selection problem is considered among many researchers in the recent times. Feature selection process targets to minimize feature set number and maximize performance accuracy by identifying optimal features. Multiple objectives are considered while identifying the optimal feature hence multi-objective metaheuristic optimization algorithms (MOMOAs) are applied. In this study, literature review is performed MOMOAs-for solving wrapper feature selection problem (WFS). The literature review for solving WFS problem and discuss the challenges faced by the researchers in solving the feature selection problem. The literature review is performed on all relevant studies published in the last 12 years [2009-2022]. A detailed overview of the feature selection preliminaries, MOMOAs-WFS, role of the classifier in feature selection problem are presented. The outcome of this literature review is to highlight the existing works related to WFS problem using MOMOAs. Finally, the research areas for improvement are identified and emphasized for the scientists to survey in the field of MOMOAs.",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/eei.v12i5.4757"
    },
    {
        "id": 33995,
        "title": "A Framework for Feature Selection using Data Value Metric and Genetic Algorithm",
        "authors": "Ojie Deborah, Akazue Maureen, Imianvan Anthony",
        "published": "2023-1-25",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5120/ijca2023922533"
    },
    {
        "id": 33996,
        "title": "Multi-Class Sentiment Classification using Feature Selection and Machine Learning Algorithms",
        "authors": "A. H. A. Hussein, Mohammed I. Habelalmateen, Gobinath Ravindran, V Malsoru, J. Rajalakshmi",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciics59993.2023.10421075"
    },
    {
        "id": 33997,
        "title": "Data-Driven Diabetes Risk Factor Prediction Using Machine Learning Algorithms with Feature Selection Technique",
        "authors": "Israt Jahan Kakoly, Md. Rakibul Hoque, Najmul Hasan",
        "published": "2023-3-10",
        "citations": 5,
        "abstract": "As type 2 diabetes becomes more prevalent across the globe, predicting its sources becomes more important. However, there is a big void in predicting the risk factors of this disease. Thus, the purpose of this study is to predict diabetes risk factors by applying machine learning (ML) algorithms. Two-fold feature selection techniques (i.e., principal component analysis, PCA, and information gain, IG) have been applied to boost the prediction accuracy. Then, the optimal features are fed into five ML algorithms, namely decision tree, random forest, support vector machine, logistic regression, and KNN. The primary data used to train the ML model were collected based on the safety procedure described in the Helsinki Declaration, 2013, and 738 records were included in the final analysis. The result has shown an accuracy level of over 82.2%, with an AUC (area under the ROC curve) value of 87.2%. This research not only identified the most important clinical and nonclinical factors in diabetes prediction, but it also found that the clinical risk factor (glucose) is the most relevant for diabetes prediction, followed by dietary factors. The noteworthy contribution of this research is the identification of previously unclassified factors left over from the previous study that considered both clinical and non-clinical aspects.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/su15064930"
    },
    {
        "id": 33998,
        "title": "Improving Intrusion Detection Using Machine Learning Algorithms with Feature Selection based on Information Gain",
        "authors": "Abdellah Mazighi, Lahoucine Ballihi, Ghizlane Orhanou",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/adacis59737.2023.10424105"
    },
    {
        "id": 33999,
        "title": "Application of machine learning algorithms and feature selection in rapeseed (Brassica napus L.) breeding for seed yield",
        "authors": "Masoud Shahsavari, Valiollah Mohammadi, Bahram Alizadeh, Houshang Alizadeh",
        "published": "2023-6-16",
        "citations": 4,
        "abstract": "Abstract\nBackground\nStudying the relationships between rapeseed seed yield (SY) and its yield-related traits can assist rapeseed breeders in the efficient indirect selection of high-yielding varieties. However, since the conventional and linear methods cannot interpret the complicated relations between SY and other traits, employing advanced machine learning algorithms is inevitable. Our main goal was to find the best combination of machine learning algorithms and feature selection methods to maximize the efficiency of indirect selection for rapeseed SY.\n\nResults\nTo achieve that, twenty-five regression-based machine learning algorithms and six feature selection methods were employed. SY and yield-related data from twenty rapeseed genotypes were collected from field experiments over a period of 2 years (2019–2021). Root mean square error (RMSE), mean absolute error (MAE), and determination coefficient (R2) were used to evaluate the performance of the algorithms. The best performance with all fifteen measured traits as inputs was achieved by the Nu-support vector regression algorithm with quadratic polynomial kernel function (R2 = 0.860, RMSE = 0.266, MAE = 0.210). The multilayer perceptron neural network algorithm with identity activation function (MLPNN-Identity) using three traits obtained from stepwise and backward selection methods appeared to be the most efficient combination of algorithms and feature selection methods (R2 = 0.843, RMSE = 0.283, MAE = 0.224). Feature selection suggested that the set of pods per plant and days to physiological maturity along with plant height or first pod height from the ground are the most influential traits in predicting rapeseed SY.\n\nConclusion\nThe results of this study showed that MLPNN-Identity along with stepwise and backward selection methods can provide a robust combination to accurately predict the SY using fewer traits and therefore help optimize and accelerate SY breeding programs of rapeseed.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s13007-023-01035-9"
    },
    {
        "id": 34000,
        "title": "Lung Cancer Detection by Multiple Feature Subset Extraction and Selection based on SVM-Weights and Genetic Algorithm-Neural Network",
        "authors": "S S Ashwini,  , M Z Kurian, M V Chidanandamurthy, M Nagaraja",
        "published": "2023-8-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17485/ijst/v16i29.1093"
    },
    {
        "id": 34001,
        "title": "Coastal Sentiment Review Using Naïve Bayes with Feature Selection Genetic Algorithm",
        "authors": "Oman Somantri, Ratih Hafsarah Maharrani, Santi Purwaningrum",
        "published": "2023-6-3",
        "citations": 0,
        "abstract": "Purpose: The tourism potential in the maritime sector can be Indonesia's mainstay at this time, especially in enjoying the charm of the natural beauty of the coast as people know Indonesia is an archipelagic country. The purpose of this study is to find the best model by applying the feature selection genetic algorithm (GA) and Information Gain (IG) to get the best Naïve Bayes (NB) model and the best features to produce the best level of sentiment classification accuracy.Methods: The stages of the research were carried out by going through the process of searching, pre-processing, analyzing research data using the Naïve Bayes model and optimizing genetic algorithms, validating data, and model evaluation.Result: The experimental results show that the best model is naïve Bayes based on information gain and the genetic algorithm yields an accuracy rate of 86.34%.Novelty: The main contribution to this research is proposing a new model of the best NB optimization model by applying an optimization algorithm in the search for feature selection to increase sentiment classification accuracy.",
        "keywords": "",
        "link": "http://dx.doi.org/10.15294/sji.v10i3.43988"
    },
    {
        "id": 34002,
        "title": "A genetic algorithm-based feature selection approach for diabetes prediction",
        "authors": "Kirti Kangra, Jaswinder Singh",
        "published": "2024-6-1",
        "citations": 0,
        "abstract": "<p>Genetic algorithms have emerged as a powerful optimization technique for feature selection due to their ability to search through a vast feature space efficiently. This study discusses the importance of feature selection for prediction in healthcare and prominently focuses on diabetes mellitus. Feature selection is essential for improving the performance of prediction models, by finding significant features and removing unnecessary among them. The study aims to identify the most informative subset of features. Diabetes is a chronic metabolic disorder that poses significant health challenges worldwide. For the experiment, two datasets related to diabetes were downloaded from Kaggle and the results of both (datasets) with and without feature selection using the genetic algorithm were compared. Machine learning classifiers and genetic algorithms were combined to increase the precision of diabetes risk prediction. In the preprocessing phase, feature selection, machine learning classifiers, and performance metrics methods were applied to make this study feasible. The results of the experiment showed that genetic algorithm + logistic regression i.e., 80% (accuracy) works better for PIMA diabetes, and for Germany diabetes dataset genetic algorithm + random forest and genetic algorithm + K-Nearest Neighbor i.e., 98.5% performed better than other chosen classifiers. The researchers can better comprehend the importance of feature selection in healthcare through this study.</p>",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijai.v13.i2.pp1489-1498"
    },
    {
        "id": 34003,
        "title": "Genetic Algorithm Based Feature Selection and Optimized Edge Detection for Brain Tumor Detection",
        "authors": "Niyathi Thota, Mahesh Vallapuri, Bhavana V",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iementech60402.2023.10423434"
    },
    {
        "id": 34004,
        "title": "Revealing the Inner Dynamics of Evolutionary Algorithms with Convection Selection",
        "authors": "Maciej Komosinski, Konrad Miazga",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3583133.3590708"
    },
    {
        "id": 34005,
        "title": "Adaptive Ranking and Selection Based Genetic Algorithms for Data-Driven Problems",
        "authors": "Kimia Vahdat, Sara Shashaani",
        "published": "2023-12-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wsc60868.2023.10408610"
    },
    {
        "id": 34006,
        "title": "Feature Selection for Classification on High- Dimensional Data Using Swarm Optimization Algorithms",
        "authors": "Pradeep kumar D, Sowmya BJ, Anitha Kanavalli, Deeptashree D",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/csitss60515.2023.10334228"
    },
    {
        "id": 34007,
        "title": "Feature Selection From MagFace Face Recognition Model With Optimization Algorithms",
        "authors": "Mehmet Fatih OZDEMIR, Davut HANBAY",
        "published": "2023-9-1",
        "citations": 0,
        "abstract": "In recent years, many studies have been carried out in the field of artificial intelligence in the literature with the development of equipment. Face recognition algorithms have an important place among these developments. Among the face recognition algorithms, the most successful ones are usually deep learning approaches. Models such as SphereFace, CosFace, ArcFace, and MagFace are important deep learning models in the literature. Despite their success, deep learning models are often computationally costly. Therefore, advanced methods are needed to reduce the computational load for these models. One of the most valid methods for this is to choose the most valuable one among embedding features for face recognition. Thus, cost can be reduced, and accuracy values can be increased even more. In this study, the most valuable of the 512 embedded features in the MagFace model was tried to be obtained by using PSO, GA, SCA, and DE optimization algorithms. As a result, accuracy values of 99.83%, 98.57%, and 98.65% were reached for 193, 252, and 280 features selected in the LFW, CFP, and AGEDB datasets, respectively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.35234/fumbd.1233505"
    },
    {
        "id": 34008,
        "title": "H2O Algorithm for Jatropha Curcas Disease Identification with Feature Selection using Genetic Algorithm",
        "authors": "Rahmat Ramadhani, Triando Hamonangan Saragih, Muhammad Haekal",
        "published": "2023-2-19",
        "citations": 0,
        "abstract": "Jatropha curcas is a plant that can be used as a substitute for diesel fuel. Lack of knowledge of farmers and the limited number of experts and extension agents into the problem of dealing with the disease Jatropha curcas plant which resulted in lower quality of Jatropha curcas. H2O Algorithm can be used for Jatropha Curcas disease identification. Based on previous research, H2O Algorithm gave 96.066%. In this research, we used Genetic Algorithm to do feature selection. H2O algorithm with feature selection gave average accuracy 97.03%, that means were better than without feature selection. The parameters that we got are number of populations 600, crossover rate 0.8 and mutation rate 0.2, and number of iterations 400. However, the time spent using feature selection is so longer than without feature selection.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33795/jtia.v4i1.77"
    },
    {
        "id": 34009,
        "title": "Multi-surrogate assisted multi-objective evolutionary algorithms for feature selection in regression and classification problems with time series data",
        "authors": "Raquel Espinosa, Fernando Jiménez, José Palma",
        "published": "2023-4",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ins.2022.12.004"
    },
    {
        "id": 34010,
        "title": "Efficient Feature Selection in High Dimensional Data Based on Enhanced Binary Chimp Optimization Algorithms and Machine Learning",
        "authors": "Farid Ayeche, Adel Alti",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "AbstractFeature selection with the highest performance accuracy is the biggest win for multidimensional data. The Chimpanzee Optimization Algorithm (ChOA) serves as a crucial technique for dealing with multidimensional global optimization issues. However, ChOA often lacks fast convergence and good selection of sensitive attributes leading to poor performance. To address these issues, most significant features were selected using two variants of ChOA called BChimp1 and BChimp2 (BChimp1 and BChimp are available at : https://www.mathworks.com/matlabcentral/fileexchange/133267-binary-chimpoptimization-algorithm-forfeatures-selection. September 22, 202). BChimp1 selects the optimal solution from the four best possible solutions and it applies a stochastic crossover on four moving solutions to deeply speed-up convergence level. BChimp2 uses the sigmoid function to select the significant features. Then, these features were trained using six-well known classifiers. The proposed techniques tend to select the most significant features, speed up the convergence rate and decrease training time for high-dimensional data. 23 standard datasets with six well-known classifiers were employed to assess the performance of BChimp1 and BChimp2. Experimental results validate the efficiency of BChimp1 and BChimp2 in enhancing accuracy by 83.83% and 82.02%, and reducing dimensionality by 42.77% and 72.54%, respectively. However, time-evaluation results of BChimp1 and BChimp2 in all datasets showed fast convergence and surpassed current optimization algorithms such as PSO, GWA, GOA, and GA.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s44230-023-00048-w"
    },
    {
        "id": 34011,
        "title": "Improved minority attack detection in <scp>Intrusion Detection System</scp> using efficient feature selection algorithms",
        "authors": "R. R. Rejimol Robinson, K. P. Anagha Madhav, Ciza Thomas",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": "AbstractMachine Learning and Data Mining algorithms are used extensively to enhance the performance of Intrusion Detection Systems. The number of training instances and the dimensionality of data are crucial factors affecting the performance of the model built during the training of any supervised learning algorithms. A sufficient proportion of instances having relevant features from all classes of attacks and normal traffic are considered most desirable while building the classification model that classifies the network traffic into attack and normal. This paper proposes a methodology to improve the accuracy of the model by giving importance to the relevant features that can contribute to model building. The feature selection using correlation‐based and information gain‐based techniques during training and testing contributes much to the detection of stealthier attacks and minority attacks. Then the features of the less detected attacks are identified as the second phase of the filter that is used to improve the performance. The relevant features of stealthy attacks are identified based on the correlation of corresponding features of the attack and normal data as the attacks are made stealthy mostly by making it resemble the normal traffic. Finally, the attacks that are rarely found in the training data are oversampled to improve their detection. CICIDS 2017 data set is employed as it comprises stealthier attacks generated using modern tools. NSL KDD data set is also used for evaluation to compare the proposed work with existing literature as it is used in most of the available literature. The results show superior performance with an accuracy of 99.8%, false positive rate of 0.2%, and a detection rate and 99.8%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1111/exsy.13546"
    },
    {
        "id": 34012,
        "title": "Analyzing the impact of feature selection methods on machine learning algorithms for heart disease prediction",
        "authors": "Zeinab Noroozi, Azam Orooji, Leila Erfannia",
        "published": "2023-12-18",
        "citations": 1,
        "abstract": "AbstractThe present study examines the role of feature selection methods in optimizing machine learning algorithms for predicting heart disease. The Cleveland Heart disease dataset with sixteen feature selection techniques in three categories of filter, wrapper, and evolutionary were used. Then seven algorithms Bayes net, Naïve Bayes (BN), multivariate linear model (MLM), Support Vector Machine (SVM), logit boost, j48, and Random Forest were applied to identify the best models for heart disease prediction. Precision, F-measure, Specificity, Accuracy, Sensitivity, ROC area, and PRC were measured to compare feature selection methods' effect on prediction algorithms. The results demonstrate that feature selection resulted in significant improvements in model performance in some methods (e.g., j48), whereas it led to a decrease in model performance in other models (e.g. MLP, RF). SVM-based filtering methods have a best-fit accuracy of 85.5. In fact, in a best-case scenario, filtering methods result in + 2.3 model accuracy. SVM-CFS/information gain/Symmetrical uncertainty methods have the highest improvement in this index. The filter feature selection methods with the highest number of features selected outperformed other methods in terms of models' ACC, Precision, and F-measures. However, wrapper-based and evolutionary algorithms improved models' performance from sensitivity and specificity points of view.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-023-49962-w"
    },
    {
        "id": 34013,
        "title": "Metaheuristic and Data Mining Algorithms-based Feature Selection Approach for Anomaly Detection",
        "authors": "Zahra Nemati, Ali Mohammadi, Ali Bayat, Abbas Mirzaei",
        "published": "2024-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/03772063.2023.2299673"
    },
    {
        "id": 34014,
        "title": "On Feature Selection Algorithms for Effective Botnet Detection",
        "authors": "Meher Afroz, Muntaka Ibnath, Ashikur Rahman, Jakia Sultana, Raqeebir Rab",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10922-024-09817-9"
    },
    {
        "id": 34015,
        "title": "Hybrid genetic algorithm based feature selection to diagnosis breast cancer",
        "authors": "Rajeswari Chhual Singh, Santosh Kumar Maharana, Subasish Mohapatra",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0132883"
    },
    {
        "id": 34016,
        "title": "Hybrid Filter-Genetic Feature Selection Method For Arabic Sentiment Analysis",
        "authors": "Muneer A.S. Hazaa, Saleh Ahmed Ali Hussein Salah",
        "published": "2023-6-13",
        "citations": 0,
        "abstract": "The dramatic increase in user comments describing their feelings about products, services, and events brings sentiment analysis to the forefront as a way to monitor public opinion about products and events. Feature selection is an important subtask of sentiment analysis, which aims to improve the performance of learning algorithms and reduce the dimensionality of a problem. Feature selection is an important subtask of sentiment analysis, as it can improve the performance of learning algorithms while reducing the dimensionality of a problem. Moreover, the high-dimensional feature spaces caused by the morphological richness of Arabic motivate further research in this area. In this paper, a hybrid filter-based and genetic feature selection algorithm is proposed using four machine learning algorithms, namely decision tree, Naive-Bayes, K-NN and meta-ensemble methods. The performance of the proposed algorithm is compared with the performance of baseline models. A wide range of experiments are conducted on two standard Arabic datasets. The experimental results clearly show that the improved methods outperform the other baseline models for Arabic sentiment analysis. The results show that the improved models outperform traditional approaches in terms of classification accuracy, with a 5% increase in the macro average of F1.",
        "keywords": "",
        "link": "http://dx.doi.org/10.59167/tujnas.v8i1.1487"
    },
    {
        "id": 34017,
        "title": "Genetic Algorithm Combined with the K-Means Algorithm: A Hybrid Technique for Unsupervised Feature Selection",
        "authors": "Hachemi Bennaceur, Meznah Almutairy, Norah Alhussain",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/iasc.2023.038723"
    },
    {
        "id": 34018,
        "title": "Enhancing Predictive Models: An In-depth Analysis of Feature Selection Techniques Coupled with Boosting Algorithms",
        "authors": "Neny Sulistianingsih, Galih Hendro Martono",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "This research addresses the critical need to enhance predictive models for fetal health classification using Cardiotocography (CTG) data. The literature review underscores challenges in imbalanced labels, feature selection, and efficient data handling. This paper aims to enhance predictive models for fetal health classification using Cardiotocography (CTG) data by addressing challenges related to imbalanced labels, feature selection, and efficient data handling. The study uses Recursive Feature Elimination (RFE) and boosting algorithms (XGBoost, AdaBoost, LightGBM, CATBoost, and Histogram-Based Boosting) to refine model performance. The results reveal notable variations in precision, Recall, F1-Score, accuracy, and AUC across different algorithms and RFE applications. Notably, Random Forest with XGBoost exhibits superior performance in precision (0.940), Recall (0.890), F1-Score (0.920), accuracy (0.950), and AUC (0.960). Conversely, Logistic Regression with AdaBoost demonstrates lower performance. The absence of RFE also impacts model effectiveness. In conclusion, the study successfully employs RFE and boosting algorithms to enhance fetal health classification models, contributing valuable insights for improved prenatal diagnosis.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30812/matrik.v23i2.3788"
    },
    {
        "id": 34019,
        "title": "A Comparative Analysis of Feature Selection Algorithms in Cross Domain\nSentiment Classification",
        "authors": "Lipika Goel, Sonam Gupta, Avdhesh Gupta, Neha Nandal, Siddhi Nath Ranjan, Pradeep Gupta",
        "published": "2024-2-2",
        "citations": 0,
        "abstract": "\nBackground:\nCross-domain Sentiment Classification is a well-researched field in\nsentiment analysis. The biggest challenge in CDSC arises from the differences in domains and\nfeatures, which cause a decrease in model performance when applying source domain features\nto predict sentiment in the target domain. To address this challenge, several feature selection\nmethods can be employed to identify the most relevant features for training and testing in\nCDSC.\n\n\nMethod:\nThe primary objective of this study is to perform a comparative analysis of different\nfeature selection methods on the various CDSC tasks. In this study, statistical test-based feature\nselection methods using 18 classifiers for the CDSC task has been implemented. The impact\nof these feature selection methods on Amazon product reviews, specifically those in the\nDVD, Electronics, Kitchen, and TV domains, has been compared. Total 12x18 experiments\nwere conducted for each feature selection method by varying source and target domain pairs\nfrom the Amazon product reviews dataset and by using 18 classifiers. Performance evaluation\nmeasures are accuracy and f-score.\n\n\nResults:\nFrom the experiments, it has been inferred that the CSDC task depends on various factors\nfor a good performance, from the right domain selection to the right feature selection\nmethod. We have concluded that the best training dataset is Electronics as it gives more precise\nresults while testing in either domain selected for our study.\n\n\nConclusion:\nCross-domain sentiment analysis is a dynamic and interdisciplinary field that offers\nvaluable insights for understanding how sentiment varies across different domains.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.2174/0126662558276889240125062857"
    },
    {
        "id": 34020,
        "title": "Lung Cancer Disease Prediction and Classification based on Feature Selection method using Bayesian Network, Logistic Regression, J48, Random Forest, and Naïve Bayes Algorithms",
        "authors": "J. Viji Cripsy, T. Divya",
        "published": "2023-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsmdi57622.2023.00066"
    },
    {
        "id": 34021,
        "title": "Deep self-supervised machine learning algorithms with a novel feature elimination and selection approaches for blood test-based multi-dimensional health risks classification",
        "authors": "Onder Tutsoy, Gizem Gul Koç",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "Abstract\nBackground\nBlood test is extensively performed for screening, diagnoses and surveillance purposes. Although it is possible to automatically evaluate the raw blood test data with the advanced deep self-supervised machine learning approaches, it has not been profoundly investigated and implemented yet.\n\nResults\nThis paper proposes deep machine learning algorithms with multi-dimensional adaptive feature elimination, self-feature weighting and novel feature selection approaches. To classify the health risks based on the processed data with the deep layers, four machine learning algorithms having various properties from being utterly model free to gradient driven are modified.\n\nConclusions\nThe results show that the proposed deep machine learning algorithms can remove the unnecessary features, assign self-importance weights, selects their most informative ones and classify the health risks automatically from the worst-case low to worst-case high values.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s12859-024-05729-2"
    },
    {
        "id": 34022,
        "title": "Domain generated algorithms detection applying a combination of a deep feature selection and traditional machine learning models",
        "authors": "Mohamed Hassaoui, Mohamed Hanini, Said El Kafhali",
        "published": "2023-1-26",
        "citations": 4,
        "abstract": "The use of command and control (C2) servers in cyberattacks has risen considerably, attackers frequently employ the domain generated algorithm (DGA) technique to conceal their C2 servers. Various machine learning models have been suggested for binary identification of domain names as either benign or DGA domain. The Existing techniques are inefficient and have real-time detection issues and are also very data hypersensitive, therefore, they can be circumvented by the attackers. The main problem this article addresses is how to automatically detect DGA in a way that does not rely solely on reverse engineering, not strongly affected by data size, and allows detection of this DGA in real time. This paper presents DTFS-DGA model that combine neural networks models with traditional machine learning models and maintains its performance even if the data size changes to detect DGA in real time. The model uses 15 linguistics and networks features with the features extracted by long short-term memory and convolutional neural network to classify domain names using random forest and support vector machines. The comprehensive experimental findings confirm the suggested model’s accuracy. To be precise, the model achieve an average accuracy of 99.8 % for the classification.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/jcs-210139"
    },
    {
        "id": 34023,
        "title": "Effect of Genetic Algorithm as a Feature Selection for Image Classification",
        "authors": "Tamara A. Anai, Muhaned Al-Hashimi, Mays Afif Anaee",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "     Analysis of image content is important in the classification of images, identification, retrieval, and recognition processes. The medical image datasets for content-based medical image retrieval (  are large datasets that are limited by high computational costs and poor performance. The aim of the proposed method is to enhance this image retrieval and classification by using a genetic algorithm (GA) to choose the reduced features and dimensionality. This process was created in three stages. In the first stage, two algorithms are applied to extract the important features; the first algorithm is the Contrast Enhancement method and the second is a Discrete Cosine Transform algorithm. In the next stage, we used datasets of the medical images using GA-based feature selection to find feature vectors. Images from the datasets and images from the query are recognized using a correlation coefficient. The third stage of the proposed method used a diverse density algorithm feedback technique to enhance the performance of the . Images of breast cancer, brain cancer, lung cancer, thyroid cancer, etc., may be retrieved using the suggested procedure. By using a feature selection algorithm based on GA to determine the best subset of features, the challenge of system dimensionality is reduced. The suggested method has greater accuracy in precision, recall, and F-score than the other techniques. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.24996/ijs.2023.64.11.42"
    },
    {
        "id": 34024,
        "title": "Software Fault Prediction Using an Optimised Feature Selection Process Based on a Genetic Algorithm",
        "authors": "S. Kaliraj, Y. Veera Raghav Reddy",
        "published": "2023-9-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.15866/irea.v11i5.23539"
    },
    {
        "id": 34025,
        "title": "Non-Dominated Sorting Genetic Algorithm-Based Dynamic Feature Selection for Intrusion Detection System",
        "authors": "Abubaker Jumaah Rabash, Mohd Zakree Ahmad Nazri, Azrulhizam Shapii, Mohammad Kamrul Hasan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3328395"
    },
    {
        "id": 34026,
        "title": "Feature Selection with a Binary Flamingo Search Algorithm and a Genetic Algorithm",
        "authors": "Rama Krishna Eluri, Nagaraju Devarakonda",
        "published": "2023-7",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-15467-x"
    },
    {
        "id": 34027,
        "title": "Customer Classification Using Naive Bayes Classifier With Genetic Algorithm Feature Selection",
        "authors": "Juliansyah Putra Tanjung, Fenny Chintya Tampubolon, Ari Wahyuda Panggabean, M. Anjas Asmara Nandrawan",
        "published": "2023-2-14",
        "citations": 0,
        "abstract": "There is a tendency to decrease the number of speedy customers in the operational area of ​​North Sumatra due to customer dissatisfaction. Termination of employment is carried out by the customer against PT. Telekomunikasi Indonesia, Tbk in North Sumatra. There is no management of customer data classification so that classification information based on certain product purchases cannot be known. Naïve Bayes is a classification algorithm that is easy to use but has weaknesses which result in poor performance, therefore feature selection is needed, the genetic algorithm is an algorithm that is able to select attributes in research, will be selected based on the highest weight so that the accuracy of the prediction results is more optimal. The steps taken in the measurement model using the Naive Bayes Classifier (NBC) approach and the model using the GA-NBC approach obtained accurate results from cross validation measurements, Confusion Matrix, ROC curves for the classification of existing and speedy telephone subscribers. The stages of the Naive Bayes process are: data collection, data preprocessing, processing of the Naive Bayes Classifier algorithm. Then the results are validated and evaluated using the Text Mining Algorithm, and calculating the parameters based on the genetic algorithm. The accuracy produced by the Naive Bayes Classifier model is 85.08%. The accuracy produced by the Naive Bayes Classifier model with the selection of Genetic Algorithm features increased to 89.31%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33395/sinkron.v8i1.12182"
    },
    {
        "id": 34028,
        "title": "Machine learning for detecting fake accounts and genetic algorithm-based feature selection",
        "authors": "Amine Sallah, El Arbi Abdellaoui Alaoui, Stéphane C.K. Tekouabou, Said Agoujil",
        "published": "2024",
        "citations": 0,
        "abstract": "Abstract\nPeople rely extensively on online social networks (OSNs) in Africa, which aroused cyber attackers’ attention for various nefarious actions. This global trend has not spared African online communities, where the proliferation of OSNs has provided new opportunities and challenges. In Africa, as in many other regions, a burgeoning black-market industry has emerged, specializing in the creation and sale of fake accounts to serve various purposes, both malicious and deceptive. This paper aims to build a set of machine-learning models through feature selection algorithms to predict the fake account, increase performance, and reduce costs. The suggested approach is based on input data made up of features that describe the profiles being investigated. Our findings offer a thorough comparison of various algorithms. Furthermore, compared to machine learning without feature selection and Boruta, machine learning employing the suggested genetic algorithm-based feature selection offers a clear runtime advantage. The final prediction model achieves AUC values between 90% and 99.6%. The findings showed that the model based on the features chosen by the GA algorithm provides a reasonable prediction quality with a small number of input variables, less than 31% of the entire feature space, and therefore permits the accurate separation of fake from real users. Our results demonstrate exceptional predictive accuracy with a significant reduction in input variables using the genetic algorithm, reaffirming the effectiveness of our approach.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1017/dap.2023.46"
    },
    {
        "id": 34029,
        "title": "H2O ALGORITHM FOR JATROPHA CURCAS DISEASE IDENTIFICATION WITH FEATURE SELECTION USING GENETIC ALGORITHM",
        "authors": "Rahmat Ramadhani, Triando Hamonangan Saragih, Muhammad Haekal",
        "published": "2023-2-20",
        "citations": 0,
        "abstract": "Jatropha curcas is a plant that can be used as a substitute for diesel fuel. Lack of knowledge of farmers and the limited number of experts and extension agents into the problem of dealing with the disease Jatropha curcas plant which resulted in lower quality of Jatropha curcas. H2O Algorithm can be used for Jatropha Curcas disease identification. Based on previous research, H2O Algorithm gave 96.066%. In this research, we used Genetic Algorithm to do feature selection. H2O algorithm with feature selection gave average accuracy 97.03%, that means were better than without feature selection. The parameters that we got are number of populations 600, crossover rate 0.8 and mutation rate 0.2, and number of iterations 400. However, the time spent using feature selection is so longer than without feature selection.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33795/jtia.v4i1.2788"
    },
    {
        "id": 34030,
        "title": "Innovative hybrid metaheuristic algorithms: exponential mutation and dual-swarm strategy for hybrid feature selection problem",
        "authors": "Debashis Dutta, Subhabrata Rath",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s41870-023-01649-1"
    },
    {
        "id": 34031,
        "title": "Classification of acute leukaemias with a hybrid use of feature selection algorithms and deep learning-based architectures",
        "authors": "Fatma Akalın, Nejat Yumusak",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5505/pajes.2022.62282"
    },
    {
        "id": 34032,
        "title": "Automated Input Variable Selection for Analog Methods Using Genetic Algorithms",
        "authors": "P. Horton, O. Martius, S. L. Grimm",
        "published": "2024-4",
        "citations": 0,
        "abstract": "AbstractAnalog methods (AMs) have long been used for precipitation prediction and climate studies. However, they rely on manual selections of parameters, such as predictor variables and analogy criteria. Previous work showed the potential of genetic algorithms (GAs) to optimize most of the AM parameters. This research goes one step further and investigates the potential of GAs for automating the selection of the input variables and the analogy criteria (distance metric between two data fields) in AMs. Our study focuses on the prediction of daily precipitation in central Europe, specifically Switzerland, as a representative case. Comparative analysis against established methods demonstrates the superiority of GA‐optimized AMs in terms of predictive accuracy. The selected input variables exhibit strong associations with key meteorological processes that influence the generation of precipitation. Further, we identify a new analogy criterion inspired by the Teweles‐Wobus criterion, which consistently performs better than other Euclidean distances and could be used in classic AMs. In contrast to conventional stepwise selection approaches, GA‐optimized AMs display a preference for a flatter structure characterized by a single level of analogy and an increased number of variables. Overall, our study demonstrates the successful application of GAs in automating input variable selection for AMs, with potential implications for application in diverse locations and data exploration to predict alternative predictands. In a broader context, GAs could be used to perform input variable selection in other data‐driven methods, opening perspectives for a broad range of applications.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1029/2023wr035715"
    },
    {
        "id": 34033,
        "title": "A Comprehensive Review of Feature Selection and Feature Selection Stability in Machine Learning",
        "authors": "Mustafa BÜYÜKKEÇECİ, Mehmet Cudi OKUR",
        "published": "2023-12-1",
        "citations": 1,
        "abstract": "Feature selection is a dimension reduction technique used to select features that are relevant to machine learning tasks. Reducing the dataset size by eliminating redundant and irrelevant features plays a pivotal role in increasing the performance of machine learning algorithms, speeding up the learning process, and building simple models. The apparent need for feature selection has aroused considerable interest amongst researchers and has caused feature selection to find a wide range of application domains including text mining, pattern recognition, cybersecurity, bioinformatics, and big data. As a result, over the years, a substantial amount of literature has been published on feature selection and a wide variety of feature selection methods have been proposed. The quality of feature selection algorithms is measured not only by evaluating the quality of the models built using the features they select, or by the clustering tendencies of the features they select, but also by their stability. Therefore, this study focused on feature selection and feature selection stability. In the pages that follow, general concepts and methods of feature selection, feature selection stability, stability measures, and reasons and solutions for instability are discussed.",
        "keywords": "",
        "link": "http://dx.doi.org/10.35378/gujs.993763"
    },
    {
        "id": 34034,
        "title": "Feature Selection based Performance Analysis of Machine Learning Algorithms in Network Intrusion Detection",
        "authors": "Samrat Kumar Dey,  ",
        "published": "2024",
        "citations": 0,
        "abstract": "Information and data security is one of the most challenging tasks for the massive-scale digital revolution all over the world. The very first step to secure our data is to identify invasive conduct and intrusive behavior. However, due to the high scalability of most modern systems and the complex nature of the attacks, the traditional detection system is less reliable. To overcome this challenge, it is necessary to build intelligent and adaptive intrusion detection technologies. That is why this research developed an intrusion detection system using commonly used ML algorithms and analyzed performance from different perspectives. In our pipeline, this exploration applied both supervised and unsupervised learning algorithms. The training and test data were split in multiple ways to evaluate the performance of the models. From the experimental results, it was found that the Light Gradient Boosting Machine (LightGBM) performs better in our context in terms of both precision and recall.",
        "keywords": "",
        "link": "http://dx.doi.org/10.59738/jstr.v5i1.23(1-8).nuyz9622"
    },
    {
        "id": 34035,
        "title": "Ensemble feature selection with adaptive weights",
        "authors": "Chengquan He, Zhuping Li, Haifeng Guo, mengmeng Li, Donghua Yang, Bo Zheng, Tiansheng Ye, Hongzhi Wang",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3006189"
    },
    {
        "id": 34036,
        "title": "Novel Hybrid Genetic Arithmetic Optimization for Feature Selection and Classification of Pulmonary Disease Images",
        "authors": "S. Nivetha, H. Hannah Inbarani",
        "published": "2023-9-12",
        "citations": 0,
        "abstract": "The difficulty in predicting early cancer is due to the lack of early illness indicators. Metaheuristic approaches are a family of algorithms that seek to find the optimal values for uncertain problems with several implications in optimization and classification problems. An automated system for recognizing illnesses can respond with accuracy, efficiency, and speed, helping medical professionals spot abnormalities and lowering death rates. This study proposes the Novel Hybrid GAO (Genetic Arithmetic Optimization algorithm based Feature Selection) (Genetic Arithmetic Optimization Algorithm-based feature selection) method as a way to choose the features for several machine learning algorithms to classify readily available data on COVID-19 and lung cancer. By choosing just important features, feature selection approaches might improve performance. The proposed approach employs a Genetic and Arithmetic Optimization to enhance the outcomes in an optimization approach.",
        "keywords": "",
        "link": "http://dx.doi.org/10.4018/ijskd.330150"
    },
    {
        "id": 34037,
        "title": "A Feature Selection Approach Based on Memory Space Computation Genetic Algorithm Applied in Bearing Fault Diagnosis Model",
        "authors": "Chun-Yao Lee, Truong-An Le, Chun-Lin Hung",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3274696"
    },
    {
        "id": 34038,
        "title": "Fast Genetic Algorithm for feature selection — A qualitative approximation approach",
        "authors": "Mohammed Ghaith Altarabichi, Sławomir Nowaczyk, Sepideh Pashami, Peyman Sheikholharam Mashhadi",
        "published": "2023-1",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2022.118528"
    },
    {
        "id": 34039,
        "title": "Parkinson’s Disease Detection Using Filter Feature Selection and a Genetic Algorithm with Ensemble Learning",
        "authors": "Abdullah Marish Ali, Farsana Salim, Faisal Saeed",
        "published": "2023-8-31",
        "citations": 2,
        "abstract": "Parkinson’s disease (PD) is a neurodegenerative disorder marked by motor and non-motor symptoms that have a severe impact on the quality of life of the affected individuals. This study explores the effect of filter feature selection, followed by ensemble learning methods and genetic selection, on the detection of PD patients from attributes extracted from voice clips from both PD patients and healthy patients. Two distinct datasets were employed in this study. Filter feature selection was carried out by eliminating quasi-constant features. Several classification models were then tested on the filtered data. Decision tree, random forest, and XGBoost classifiers produced remarkable results, especially on Dataset 1, where 100% accuracy was achieved by decision tree and random forest. Ensemble learning methods (voting, stacking, and bagging) were then applied to the best-performing models to see whether the results could be enhanced further. Additionally, genetic selection was applied to the filtered data and evaluated using several classification models for their accuracy and precision. It was found that in most cases, the predictions for PD patients showed more precision than those for healthy individuals. The overall performance was also better on Dataset 1 than on Dataset 2, which had a greater number of features.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/diagnostics13172816"
    },
    {
        "id": 34040,
        "title": "Novel Network Intrusion Detection Based on Feature Filtering Using FLAME and New Cuckoo Selection in a Genetic Algorithm",
        "authors": "Kawthar Alzboon, Jehad Al-Nihoud, Wafa Alsharafat",
        "published": "2023-11-28",
        "citations": 1,
        "abstract": "Recently, networks have faced a significant challenge in terms of security due to constant unauthorized access by hackers, resulting in the compromise of network user data. To enhance network security, there are various approaches that can be employed, including the utilization of firewalls, encryption, and antivirus software. Among these methods, one type of system that can be implemented is an intrusion detection system (IDS), which actively monitors the network to identify any intrusions. In order to effectively detect any unauthorized or malicious activities, sophisticated techniques such as genetic algorithms, cuckoo searches, and FLAME are employed. This research proposes a novel IDS that aims to improve the detection of intrusions. The proposed IDS initially conducts feature filtration using fuzzy clustering through the local approximation of the membership algorithm (FLAME), which effectively reduces the number of features that need to be analyzed and processed. Subsequently, the system detects attacks by implementing an extended classifier system (XCS) that incorporates a genetic algorithm (GA) to enhance the accuracy of intrusion detection. By incorporating the cuckoo search and selection within GA, while considering different crossover and mutation probabilities, instead of solely relying on traditional GA, it is anticipated that intrusion detection accuracy will be improved. To evaluate the performance of the proposed IDS, it was tested on the KDD99 dataset and compared with several other IDSs that were also tested on the same dataset. The experimental results clearly indicate that the proposed IDS significantly enhances the detection rate (DR) and accuracy while also significantly reducing the false alarm rate (FAR) and these impressive results were 100%, 99.99% and 0.05% respectively. The performance comparisons reveal that, overall, the proposed IDS outperforms several existing IDSs in terms of intrusion detection performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app132312755"
    },
    {
        "id": 34041,
        "title": "Effect of Principal Component Analysis on Genetic Algorithm Feature Selection",
        "authors": "Auapong Yaicharoen, Kotaro Hashikura, Md Abdus Samad Kamal, Kou Yamada",
        "published": "2023-5-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ecti-con58255.2023.10153253"
    },
    {
        "id": 34042,
        "title": "Cost-sensitive max-margin feature selection for SVM using alternated sorting method genetic algorithm",
        "authors": "Khalid Y. Aram, Sarah S. Lam, Mohammad T. Khasawneh",
        "published": "2023-5",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2023.110421"
    },
    {
        "id": 34043,
        "title": "Cross‐project defect prediction method based on genetic algorithm feature selection",
        "authors": "Zhixi Hu, Yi Zhu",
        "published": "2023-12",
        "citations": 3,
        "abstract": "AbstractWith the continuous development of Internet technology, the role of software in life is increasing, and software defect prediction (SDP) is a key means to ensure software reliability. SDP is to predict the modules that may have defects in advance based on the historical data of software projects, and its purpose is to maximize the use of testing resources. However, in the actual development process, the project that needs to be predicted is often a new project for which there is little or no historical data. Therefore, how to use the massive data of other related projects to build a cross‐project software defect prediction (CPDP) model has received extensive attention from scholars. However, due to the differences in data distribution and class imbalance between different projects, the performance of CPDP is greatly affected. Therefore, on the basis of CPDP, this article proposes a feature selection method based on genetic algorithm (genetic algorithm feature selection, GAFS). GAFS mainly includes two stages: feature selection and ensemble training. In the feature selection stage, this article proposes a global search adaptive feature selection method based on genetic algorithm, which uses the integrated training results of candidate feature subsets on target data to migrate the optimal feature subset. In the ensemble training phase, the EasyEnsemble method is used to alleviate the class imbalance problem, multiple naive Bayesian classifiers are constructed, and then the final model is constructed through ensemble learning. In this article, F1‐score and MCC are used as the test indicator, and comparative experiments are carried out on AEEEM and Promise. The results show that compared with the five comparison methods, GAFS can improve the average F1‐score and MCC much more. For example, GAFS can improve the average F1‐score value by 38.9%, 31.6%, 35.1%, 22.0%, and 31.6%, respectively. In most cases, it can effectively improve the performance of the model and achieve better prediction results.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/eng2.12670"
    },
    {
        "id": 34044,
        "title": "Feature selection algorithms highlight the importance of the systolic segment for normal/murmur PCG beat classification",
        "authors": "Rima Touahria, Abdenour Hacine-Gharbi, Philippe Ravier",
        "published": "2023-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.bspc.2023.105288"
    },
    {
        "id": 34045,
        "title": "Bio-Inspired Feature Selection Algorithms With Their Applications: A Systematic Literature Review",
        "authors": "Tin H. Pham, Bijan Raahemi",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3272556"
    },
    {
        "id": 34046,
        "title": "Controlling Hybrid Evolutionary Algorithms in Subset Selection for Multimodal Optimization",
        "authors": "Ole Jakob Mengshoel, Xavier Sánchez Díaz, Fredrik Foss",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3583133.3590545"
    },
    {
        "id": 34047,
        "title": "Prediction of Cardiac Illness using Machine Learning Algorithms with and without Feature Selection",
        "authors": "Jeethu Philip, Bala Srujan Kumar Reddy Gade, Kameswari Sai Pranamya Kyl,  Alka, Charan Reddy Guntaka",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10306836"
    },
    {
        "id": 34048,
        "title": "Feature Selection Using a Combination of Ant Colony Optimization and Random Forest Algorithms Applied To Isolation Forest Based Intrusion Detection System",
        "authors": "O. Lifandali, N. Abghour, Z. Chiba",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.procs.2023.03.106"
    },
    {
        "id": 34049,
        "title": "Optimizing Region of Interest Selection for Effective Embedding in Video Steganography Based on Genetic Algorithms",
        "authors": "Nizheen A. Ali, Ramadhan J. Mstafa",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/csse.2023.039957"
    },
    {
        "id": 34050,
        "title": "Detecting the Anomaly Attacks in Industrial IoT using Hybrid Feature Selection Based Modified Convolutional Neural Network",
        "authors": "Sreekanth Rallapalli, Vikas Kumar Tiwari, Vidya Sagar S D, Piyush Kumar Pareek",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/easct59475.2023.10393443"
    },
    {
        "id": 34051,
        "title": "Leveraging Explainability with K-Fold Feature Selection",
        "authors": "Artur Ferreira, Mário Figueiredo",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011744400003411"
    },
    {
        "id": 34052,
        "title": "A tutorial-based survey on feature selection: Recent advancements on feature selection",
        "authors": "Amir Moslemi",
        "published": "2023-11",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.engappai.2023.107136"
    },
    {
        "id": 34053,
        "title": "Machine learning approach for seed analysis using feature selection technique and evolutionary algorithms",
        "authors": "Amjan Shaik, Nishath Ansari, M. Neelakantappa, Amtul Nimra, K. Purnachand, Saikumar Tara",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0125198"
    },
    {
        "id": 34054,
        "title": "Efficient Prediction of Seasonal Infectious Diseases Using Hybrid Machine Learning Algorithms with Feature Selection Techniques",
        "authors": "K. Indhumathi, K. Sathesh Kumar",
        "published": "2023-11",
        "citations": 0,
        "abstract": " Early seasonal disease risk identification is the most challenging task in the medical industry. The capacity to detect patients at risk of improvement throughout their hospital stay is critical for effective patient allocation and care among patients with seasonal diseases. Patient risk factor prediction is the most important issue in reducing victim mortality. Machine learning plays a vital role in identifying the risk level of patients. In this research, we consider four seasonal diseases such as dengue, malaria, typhoid, and pneumonia. In this research, the researcher finds the dangerous symptoms of victims based on their age group. The real-time dataset was used in this study. The dataset for this study was gathered from hospitals in the Madurai district between 2019 and 2020. Feature selection is the prime element of patient risk recognition. It is used to pick the most accurate attributes for prediction. The dataset is divided into 70% training data and 30% testing data. This research proposes the feature selection method Boruta-XGBoost for improving accuracy. In this research, we discuss various attribute selection algorithms, including the Boruta algorithm, the XGBoost algorithm, the recursive feature elimination method (RFE), and the PRF-BXGBoost (Patient Risk Factor-Boruta-XGBoost) algorithm. The proposed method provides greater accuracy when compared to other variable selection methods. The time complexity of the proposed method is low when compared to other algorithms. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1142/s0218213023500446"
    },
    {
        "id": 34055,
        "title": "Identifying Early Biomarkers of Multiple Sclerosis with Feature Selection Algorithms",
        "authors": "Krishna Kant Dixit, Upendra Singh Aswal, A. Deepak, K Mayuri, Manish Sararswat, Amit Srivastava",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/upcon59197.2023.10434913"
    },
    {
        "id": 34056,
        "title": "An examination of the hybrid meta-heuristic machine learning algorithms for early diagnosis of type II diabetes using big data feature selection",
        "authors": "Fatemeh Navazi, Yufei Yuan, Norm Archer",
        "published": "2023-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.health.2023.100227"
    },
    {
        "id": 34057,
        "title": "Screening of serum exosome markers for colorectal cancer based on Boruta and multi-cluster feature selection algorithms",
        "authors": "Jian Zhu, Junjie Luo, Yao Ma",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13273-023-00348-z"
    },
    {
        "id": 34058,
        "title": "Evaluation of Machine Learning Algorithms on Finding Drinking Water Quality Based on Feature Selection Methodologies",
        "authors": "K. Devi Priya, Sanga Monish Sai, Venu Gopal Reddy Pagadala, Dasari Praveen Kumar",
        "published": "2023-3-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaccs57279.2023.10112799"
    },
    {
        "id": 34059,
        "title": "Metaheuristic-Based Feature Selection Methods for Diagnosing Sarcopenia with Machine Learning Algorithms",
        "authors": "Jaehyeong Lee, Yourim Yoon, Jiyoun Kim, Yong-Hyuk Kim",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "This study explores the efficacy of metaheuristic-based feature selection in improving machine learning performance for diagnosing sarcopenia. Extraction and utilization of features significantly impacting diagnosis efficacy emerge as a critical facet when applying machine learning for sarcopenia diagnosis. Using data from the 8th Korean Longitudinal Study on Aging (KLoSA), this study examines harmony search (HS) and the genetic algorithm (GA) for feature selection. Evaluation of the resulting feature set involves a decision tree, a random forest, a support vector machine, and naïve bayes algorithms. As a result, the HS-derived feature set trained with a support vector machine yielded an accuracy of 0.785 and a weighted F1 score of 0.782, which outperformed traditional methods. These findings underscore the competitive edge of metaheuristic-based selection, demonstrating its potential in advancing sarcopenia diagnosis. This study advocates for further exploration of metaheuristic-based feature selection’s pivotal role in future sarcopenia research.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/biomimetics9030179"
    },
    {
        "id": 34060,
        "title": "Improved feature selection using a hybrid side-blotched lizard algorithm and genetic algorithm approach",
        "authors": "Amr Abdel-aal, Ibrahim El-Henawy",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "<span lang=\"EN-US\">Feature selection entails choosing the significant features among a wide collection of original features that are essential for predicting test data using a classifier. Feature selection is commonly used in various applications, such as bioinformatics, data mining, and the analysis of written texts, where the dataset contains tens or hundreds of thousands of features, making it difficult to analyze such a large feature set. Removing irrelevant features improves the predictor performance, making it more accurate and cost-effective. In this research, a novel hybrid technique is presented for feature selection that aims to enhance classification accuracy. A hybrid binary version of side-blotched lizard algorithm (SBLA) with genetic algorithm (GA), namely SBLAGA, which combines the strengths of both algorithms is proposed. We use a sigmoid function to adapt the continuous variables values into a binary one, and evaluate our proposed algorithm on twenty-three standard benchmark datasets. Average classification accuracy, average number of selected features and average fitness value were the evaluation criteria. According to the experimental results, SBLAGA demonstrated superior performance compared to SBLA and GA with regards to these criteria. We further compare SBLAGA with four wrapper feature selection methods that are widely used in the literature, and find it to be more efficient.</span>",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijece.v13i5.pp5737-5746"
    },
    {
        "id": 34061,
        "title": "Deep learning and genetic algorithm-based ensemble model for feature selection and classification of breast ultrasound images",
        "authors": "Mohsin Furkh Dar, Avatharam Ganivada",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.imavis.2024.105018"
    },
    {
        "id": 34062,
        "title": "A feature selection based on genetic algorithm for intrusion detection of industrial control systems",
        "authors": "Yushan Fang, Yu Yao, Xiaoli Lin, Jiaxuan Wang, Hao Zhai",
        "published": "2024-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cose.2023.103675"
    },
    {
        "id": 34063,
        "title": "Hybrid Filter and Genetic Algorithm-Based Feature Selection for Improving Cancer Classification in High-Dimensional Microarray Data",
        "authors": "Waleed Ali, Faisal Saeed",
        "published": "2023-2-12",
        "citations": 9,
        "abstract": "The advancements in intelligent systems have contributed tremendously to the fields of bioinformatics, health, and medicine. Intelligent classification and prediction techniques have been used in studying microarray datasets, which store information about the ways used to express the genes, to assist greatly in diagnosing chronic diseases, such as cancer in its earlier stage, which is important and challenging. However, the high-dimensionality and noisy nature of the microarray data lead to slow performance and low cancer classification accuracy while using machine learning techniques. In this paper, a hybrid filter-genetic feature selection approach has been proposed to solve the high-dimensional microarray datasets problem which ultimately enhances the performance of cancer classification precision. First, the filter feature selection methods including information gain, information gain ratio, and Chi-squared are applied in this study to select the most significant features of cancerous microarray datasets. Then, a genetic algorithm has been employed to further optimize and enhance the selected features in order to improve the proposed method’s capability for cancer classification. To test the proficiency of the proposed scheme, four cancerous microarray datasets were used in the study—this primarily included breast, lung, central nervous system, and brain cancer datasets. The experimental results show that the proposed hybrid filter-genetic feature selection approach achieved better performance of several common machine learning methods in terms of Accuracy, Recall, Precision, and F-measure.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/pr11020562"
    },
    {
        "id": 34064,
        "title": "AEGA: enhanced feature selection based on ANOVA and extended genetic algorithm for online customer review analysis",
        "authors": "Gyananjaya Tripathy, Aakanksha Sharaff",
        "published": "2023-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11227-023-05179-2"
    },
    {
        "id": 34065,
        "title": "Co-operative Co-evolutionary Many-objective Embedded Multi-label Feature Selection with Decomposition-based PSO",
        "authors": "Kaan Demir, Bach Nguyen, Bing Xue, Mengjie Zhang",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3583131.3590373"
    },
    {
        "id": 34066,
        "title": "Benchmarking feature selection and feature extraction methods to improve the performances of machine-learning algorithms for patient classification using metabolomics biomedical data",
        "authors": "Justine Labory, Evariste Njomgue-Fotso, Silvia Bottini",
        "published": "2024-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.csbj.2024.03.016"
    },
    {
        "id": 34067,
        "title": "Union k-Fold Feature Selection on Microarray Data",
        "authors": "Artur Ferreira, Mário Figueiredo",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012135800003541"
    },
    {
        "id": 34068,
        "title": "An enhanced multimodal multi-objective genetic algorithm with a novel adaptive crossover mechanism for feature selection",
        "authors": "Mengting Ji, Yongli Liu, Hao Chao",
        "published": "2023-11-4",
        "citations": 0,
        "abstract": "Nowadays, multimodal multi-objective optimization problems (MMOPs) have received increasing attention from many researchers. In such problems, there are situations where two or more Pareto Sets (PSs) correspond to the same Pareto Front (PF). It is crucial to obtain as many PSs as possible without compromising the performance of the objective space. Therefore, this paper proposes an enhanced multimodal multi-objective genetic algorithm with a novel adaptive crossover mechanism, named AEDN_NSGAII. In the AEDN_NSGAII, the special crowding distance strategy can provide potential development opportunities for individuals with a larger crowding distance. An adaptive crossover mechanism is established by combining the simulated binary crossover (SBX) operator and the Laplace crossover (LP) operator, which adaptively improves the ability to obtain Pareto optimal solutions. Meanwhile, an elite selection mechanism can efficiently get more excellent individuals as parents to enhance the diversity of the decision space. Then, the proposed algorithm is evaluated on the CEC2019 test suite by the Friedman method and discussed for its feasibility through ablation experiments and boxplot analysis of PSP indicators. Experimental results show that AEDN_NSGAII can effectively search for more PSs without weakening the diversity and convergence of objective space. Finally, the performance of AEDN_NSGAII on the multimodal feature selection problem is compared with that of the other four algorithms. The statistical analysis demonstrates that the proposed algorithm has great potential for resolving this issue.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/jifs-233135"
    },
    {
        "id": 34069,
        "title": "An efficient feature selection and classification system for microarray cancer data using genetic algorithm and deep belief networks",
        "authors": "Morolake Oladayo Lawrence, Rasheed Gbenga Jimoh, Waheed Babatunde Yahya",
        "published": "2024-3-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-024-18802-y"
    },
    {
        "id": 34070,
        "title": "FEATURE SELECTION METHOD BASED ON GENETIC ALGORITHM WITH WRAPPER-EMBEDDED TECHNIQUE FOR MEDICAL RECORD CLASSIFICATION",
        "authors": "Yuda Syahidin, Nur Ulfa Maulidevi, Kridanto Surendro",
        "published": "2023-2-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3587828.3587856"
    },
    {
        "id": 34071,
        "title": "Feature Selection and Hyperparameters Optimization Employing a Hybrid Model Based on Genetic Algorithm and Artificial Neural Network: Forecasting Dividend Payout Ratio",
        "authors": "Fatih Konak, Mehmet Akif Bülbül, Diler Türkoǧlu",
        "published": "2024-1-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10614-023-10530-z"
    },
    {
        "id": 34072,
        "title": "A Double Lexicase Selection Operator for Bloat Control in Evolutionary Feature Construction for Regression",
        "authors": "Hengzhe Zhang, Qi Chen, Bing Xue, Wolfgang Banzhaf, Mengjie Zhang",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3583131.3590365"
    },
    {
        "id": 34073,
        "title": "A review of feature selection methods based on meta-heuristic algorithms",
        "authors": "Zohre Sadeghian, Ebrahim Akbari, Hossein Nematzadeh, Homayun Motameni",
        "published": "2023-2-27",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/0952813x.2023.2183267"
    },
    {
        "id": 34074,
        "title": "A Comparative Analysis of Machine Learning Algorithms for Credit Risk Scoring using Chi-Square Feature Selection",
        "authors": "Hery Dian Septama, Titin Yulianti, Deny Budiyanto, Sherly Martina Mulyadi, Amanda Hasna Cahyana",
        "published": "2023-10-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccteie60099.2023.10366576"
    },
    {
        "id": 34075,
        "title": "Novel Feature Selection Algorithms Based on  Crowding Distance and Pearson Correlation  Coefficient",
        "authors": "Abdesslem Layeb,  ",
        "published": "2023-4-8",
        "citations": 0,
        "abstract": "Feature Selection is an important phase in classification models. Feature Selection is an effective task used to decrease the dimensionality and eliminate redundant and unrelated features. In this paper, three novel algorithms for feature selection problem are proposed. The first one is a filter method, the second one is a wrapper method, and the last one is a hybrid filter method. Both the proposed algorithms use the crowding distance used in the multiobjective optimization as a new metric to assess the importance of the features. The idea behind the use of the crowding distance is that the less crowded features have great impacts on the target attribute (class), and the crowded features have generally the same impact on the class attribute. To enhance the crowded distance, a combination with other metrics will give good results. In this work, the hybrid method combines between the crowding distance and Pearson correlation coefficient to well order the importance of features. Experiments on well-known benchmark datasets including large microarray datasets have shown the effectiveness and the robustness of the proposed algorithms.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5815/ijisa.2023.02.04"
    },
    {
        "id": 34076,
        "title": "Multiclass classification of texture images using greedy feature selection algorithms",
        "authors": "Vladislav Konevsky, Andrey Gaidel, David Asatryan, Rustam Paringer, Alexander Kupriyanov, Mariam Haroutunian",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0136507"
    },
    {
        "id": 34077,
        "title": "Feature Selection for the Low Industrial Yield of Cane Sugar Production Based on Rule Learning Algorithms",
        "authors": "Yohan Gil Rodríguez, Raisa Socorro Llanes, Alejandro Rosete, Lisandra Bravo Ilisástigui",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "This article presents a model based on machine learning for the selection of the characteristics that most influence the low industrial yield of cane sugar production in Cuba. The set of data used in this work corresponds to a period of ten years of sugar harvests from 2010 to 2019. A process of understanding the business and of understanding and preparing the data is carried out. The accuracy of six rule learning algorithms is evaluated: CONJUNCTIVERULE, DECISIONTABLE, RIDOR, FURIA, PART and JRIP. The results obtained allow us to identify: R417, R379, R378, R419a, R410, R613, R1427 and R380, as the indicators that most influence low industrial performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.14313/jamris/1-2023/2"
    },
    {
        "id": 34078,
        "title": "A novel smart feature selection strategy of lithium-ion battery degradation modelling for electric vehicles based on modern machine learning algorithms",
        "authors": "Huzaifa Rauf, Muhammad Khalid, Naveed Arshad",
        "published": "2023-9",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.est.2023.107577"
    },
    {
        "id": 34079,
        "title": "A comparative analysis of meta-heuristic optimization algorithms for feature selection on ML-based classification of heart-related diseases",
        "authors": "Şevket Ay, Ekin Ekinci, Zeynep Garip",
        "published": "2023-7",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11227-023-05132-3"
    },
    {
        "id": 34080,
        "title": "Deep Curious Feature Selection: A Recurrent, Intrinsic-Reward Reinforcement Learning Approach to Feature Selection",
        "authors": "Michal Moran, Goren Gordon",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tai.2023.3282564"
    },
    {
        "id": 34081,
        "title": "Effective EEG Feature Selection for Interpretable MDD (Major Depressive Disorder) Classification",
        "authors": "Vojtech Mrazek, Soyiba Jawed, Muhammad Arif, Aamir Saeed Malik",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3583131.3590398"
    },
    {
        "id": 34082,
        "title": "Genetic Clustering Algorithm-Based Feature Selection and Divergent Random Forest for Multiclass Cancer Classification Using Gene Expression Data",
        "authors": "L. Senbagamalar, S. Logeswari",
        "published": "2024-2-5",
        "citations": 0,
        "abstract": "AbstractComputational identification and classification of clinical disorders gather major importance due to the effective improvement of machine learning methodologies. Cancer identification and classification are essential clinical areas to address, where accurate classification for multiple types of cancer is still in a progressive stage. In this article, we propose a multiclass cancer classification model that categorizes the five different types of cancers using gene expression data. To perform efficient analysis of the available clinical data, we propose feature selection and classification methods. We propose a genetic clustering algorithm (GCA) for optimal feature selection from the RNA-gene expression data, consisting of 801 samples belonging to the five major classes of cancer. The proposed feature selection method reduces the 1621 gene expressions into a cluster of 21 features. The optimum feature set acts as input data to the proposed divergent random forest. Based on the features computed, the proposed classifier categorizes the data samples into 5 different classes of cancers, including breast cancer, colon cancer, kidney cancer, lung cancer, and prostate cancer. The proposed divergent random forest provided performance improvisation in terms of accuracy with 95.21%, specificity with 93%, and sensitivity with 94.29% which outperformed all the other existing multiclass classification algorithms.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s44196-024-00416-9"
    },
    {
        "id": 34083,
        "title": "Hybrid Feature Generation and Selection with a Focus on Novel Genetic-Based Generated Feature Method for Modeling Products in the Sulfur Recovery Unit",
        "authors": "Farshad Moayedi, Hossein Abolghasemi, Saeid Shokri, Hamid Ganji, Amir Hossein Hamedi",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13369-023-07609-y"
    },
    {
        "id": 34084,
        "title": "Feature Selection based on Genetic Algorithm for Classification of Mammogram Using K-means, k-NN and Euclidean Distance",
        "authors": " Kameran Adil Ibrahim",
        "published": "2023-2-1",
        "citations": 1,
        "abstract": "There have been several supervised classification attempts for mammograms in the recent times, but very few research works have focused on unsupervised classification to explore its potentialities and weaknesses. I have in this paper attempted to utilize unsupervised clusters to classify malignant, and benign mammograms samples. MiniMIAS database has total 322 mammogram images out which 64 are benign and 51 are malignant. I used 115 images for my experimentation i.e. 64 benign and 51 malignant. Out of these 115, 60% were used for training and 40% for testing. Therefore from 64 benign cases 39 images were used for training and rest for testing, and out of 51 malignant cases 31 images were used for training and rest for testing., the classifications was done on the bases of the features selected using genetic algorithm. Attempts have also been made to study the performance of each feature selected by Genetic Algorithm (GA) in classification. The initially identified clusters using K-means are used to classify 60 unknown samples using k-NN. The proposed work got reasonably good results with 96.23% accuracy for malignant samples, 95.37% for benign. The proposed work can help the radiologists and oncologist as second opinion during screening sessions for early detection.",
        "keywords": "",
        "link": "http://dx.doi.org/10.25130/tjps.v22i9.883"
    },
    {
        "id": 34085,
        "title": "Interpretable stock price forecasting model using genetic algorithm-machine learning regressions and best feature subset selection",
        "authors": "Kyung Keun Yun, Sang Won Yoon, Daehan Won",
        "published": "2023-3",
        "citations": 24,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2022.118803"
    },
    {
        "id": 34086,
        "title": "Detection of Android Malware Using Genetic Algorithm based Optimized Feature Selection",
        "authors": " Bharathi P,  Karthik M,  Suma Sri M,  Sai Manoj K,  Tapaswini K",
        "published": "2023-4-23",
        "citations": 0,
        "abstract": "Android platform due to open source characteristic and Google backing has the largest global market share. Being the world's most popular operating system, it has drawn the attention of cyber criminals operating particularly through wide distribution of malicious applications. This paper proposes an effectual machine-learning based approach for Android Malware Detection making use of evolutionary Genetic algorithm for discriminatory feature selection. Selected features from Genetic algorithm are used to train machine learning classifiers and their capability in identification of Malware before and after feature selection is compared. The experimentation results validate that Genetic algorithm gives most optimized feature subset helping in reduction of feature dimension to less than half of the original feature-set. For machine learning classifiers, a classification accuracy of over 94% can be maintained with a large feature reduction, thereby improving classification accuracy computational complexity of learning classifiers.",
        "keywords": "",
        "link": "http://dx.doi.org/10.48175/ijarsct-9337"
    },
    {
        "id": 34087,
        "title": "Feature selection optimization based on genetic algorithm for support vector classification varieties of raisin",
        "authors": "Yudi Ramdhani, Dhia Fauziah Apra, Doni Purnama Alamsyah",
        "published": "2023-4-1",
        "citations": 1,
        "abstract": "Grapes are one of the fruit plants that grow that propagate in certain fields. Grapes can be processed into juice, wine, raisins, and so on. Raisins are dried grapes. Raisins have a distinctive taste and aroma. Raisins are a concentrated and nutritious source of carbohydrates, containing antioxidants, potassium, fiber and iron. To increase the accuracy value, the optimize selection genetic algorithm (GA) is used. This research was conducted modeling using the support vector machine (SVM) and SVM algorithms based on optimize selection GA by using the raisin (raisin varieties) dataset obtained from the UCI machine learning repository. The research dataset is divided into training data and testing data. The data sharing will be carried out using the cross validation and split validation operators. Data validation with 10-Fold-validation on the SVM algorithm has the best level of performance among 5 other algorithms such as; Naïve Bayes, K-nearest neighbor (K-NN), decision tree (DT), neural network, and random forest (RF). The SVM algorithm produces accuracy and area under the curve (AUC) values of 87.11% for accuracy and 0.928 for AUC. Optimization in this study using optimize selection GA. SVM based on optimize selection GA produces accuracy and AUC values of 87.67% for accuracy and 0.930 for AUC.",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijeecs.v30.i1.pp192-199"
    },
    {
        "id": 34088,
        "title": "Bankruptcy Prediction Using Genetic Algorithm-Support Vector Machine (GA-SVM) Feature Selection and Stacking",
        "authors": "Wiena Faqih Abror, Alamsyah Alamsyah, Muhammad Aziz",
        "published": "2023-7-19",
        "citations": 1,
        "abstract": "Bankruptcy is an impact caused by a company's financial failure. Financial failure in the company must be avoided so as not to cause losses to the company. In the research that was carried out utilizing a data set from the Taiwan Economic Journal as many as 6,819 to be trained using machine learning algorithms using classification techniques. The goal obtained from the research conducted is to obtain a classification technique with the best accuracy results. The method used in this research is preprocessing using the synthetic minority over-sampling technique to handling unbalanced data sets. Then, the results of the balanced data set will be processed using a genetic algorithm-support vector machine feature selection algorithm to reduce the attributes of the data set. Data sets that have experienced reduced attributes will be trained using the stacking method with a single classifier base learner in the form of k-nearest neighbors, naïve bayes, decision trees with classification and regression tree models, gradient boosting decision trees, and light gradient boosting. The meta-learner used in the stacking method is extreme gradient boosting. The results of the accuracy obtained from the research conducted were 99.22%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.52465/joiser.v1i2.180"
    },
    {
        "id": 34089,
        "title": "Detection of Android Malware using Feature Selection with a Hybrid Genetic Algorithm and Simulated Annealing (SVM and DBN)",
        "authors": "Et al. E. Padmalatha",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "Because of the widespread use of the Android operating system and the simplicity with which applications can be created on the Android platform, anyone can easily create malware using pre-made tools. Due to the spread of malware among many helpful applications, Android users are experiencing issues. In this study, we showed how to use permissions gleaned from static analysis to identify Android malware. Utilising support vector machines and deep belief networks, we choose the pertinent features from the set of permissions based on this methodology. The suggested technique increases the effectiveness of Android malware detection.",
        "keywords": "",
        "link": "http://dx.doi.org/10.17762/ijritcc.v11i10.8698"
    },
    {
        "id": 34090,
        "title": "Feature Selection Improves Speech Based Parkinson's Disease Detection Performance",
        "authors": "Ayşe Tekindor, Eda Aydın",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012347300003657"
    },
    {
        "id": 34091,
        "title": "A GENETIC INVESTIGATION OF ANTHROPOMETRIC TRAIT FEATURE SELECTION SCHEME (GIANT-FS) FOR IDENTIFICATION OF BIOMARKERS TO DIAGNOSE CANCER DISEASE",
        "authors": "Thamizhselvi Elumalai, Geetha Vaithiyanathan",
        "published": "2023-2-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21817/indjcse/2023/v14i1/231401077"
    },
    {
        "id": 34092,
        "title": "Combination of Stacking with Genetic Algorithm Feature Selection to Improve Default Prediction in P2P Lending",
        "authors": "Dwika Ananda Agustina Pertiwi, Kamilah Ahmad, Tiara Lailatul Nikmah,  Alamsyah, Budi Prasetiyo, Much Aziz Muslim",
        "published": "2023-10-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icoris60118.2023.10352271"
    },
    {
        "id": 34093,
        "title": "Neural Network-Based Approach for Supervised Nonlinear Feature Selection",
        "authors": "Mamadou Kanouté, Edith Grall-Maës, Pierre Beauseroy",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012185700003595"
    },
    {
        "id": 34094,
        "title": "Feature Selection Techniques for Enhancing Credit Card Fraud Detection Performance: A Hybrid Metaheuristic Approach Using Nature-Inspired Algorithms",
        "authors": "Pravalika Sure, Satwik Pandey, Tanmay Parnami,  Gaurang, Aryan Saxena",
        "published": "2024-2-29",
        "citations": 0,
        "abstract": "Abstract: The surge in credit card usage has led to a parallel increase in fraudulent transactions, necessitating advanced detection systems. Traditional methods encounter challenges with high-dimensional and imbalanced datasets. This paper proposes a comprehensive approach integrating metaheuristic algorithms and deep learning techniques to enhance fraud detection accuracy. The first contribution, the Rock Hyrax Swarm Optimization Feature Selection (RHSOFS) algorithm, draws inspiration from the collective behaviors of rock hyrax swarms to effectively select relevant features from high-dimensional datasets. RHSOFS identifies an optimal subset of features critical for fraud detection through supervised machine learning. Complementing this, the second contribution leverages a hybrid deep learning model. Beginning by organizing transactional data and constructing a Logical Graph of Behavior Profile (LGBP) to abstract transaction details, the Modified Butterfly Optimization Algorithm (MBOA) selects important features from the dataset. The hybrid model, integrating Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN), establishes rational connections between transactional characteristics, enhancing detection performance. To evaluate the approach, comparative efficiency analyses against existing methods, including Differential Evolutionary Feature Selection (DEFS), Genetic Algorithm Feature Selection (GAFS), Particle Swarm Optimization Feature Selection (PSOFS), and Ant Colony Optimization Feature Selection (ACOFS), are conducted. Results demonstrate the superiority of the approach in terms of both reliability and recognition rate, validated through rigorous statistical testing. The proposed hybrid approach signifies a significant advancement in credit card fraud detection systems, offering enhanced accuracy and efficiency in combating fraudulent activities amidst the growing complexity of transactional datasets.",
        "keywords": "",
        "link": "http://dx.doi.org/10.22214/ijraset.2024.58549"
    },
    {
        "id": 34095,
        "title": "Building a Cloud-IDS by Hybrid Bio-Inspired Feature Selection Algorithms Along With Random Forest Model",
        "authors": "Mhamad Bakro, Rakesh Ranjan Kumar, Mohammad Husain, Zubair Ashraf, Arshad Ali, Syed Irfan Yaqoob, Mohammad Nadeem Ahmed, Nikhat Parveen",
        "published": "2024",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2024.3353055"
    },
    {
        "id": 34096,
        "title": "An adaptive and enhanced framework for daily stock market prediction using feature selection and ensemble learning algorithms",
        "authors": "Mahmut Sami Sivri, Alp Ustundag",
        "published": "2024-1-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/2573234x.2023.2263522"
    },
    {
        "id": 34097,
        "title": "FUEL INCREASE SENTIMENT ANALYSIS USING SUPPORT VECTOR MACHINE WITH PARTICLE SWARM OPTIMIZATION AND GENETIC ALGORITHM AS FEATURE SELECTION",
        "authors": "Laura Imanuela Mustamu, Yuliant Sibaroni",
        "published": "2023-6-26",
        "citations": 0,
        "abstract": "BBM, or fuel oil, is one of the essential needs of the Indonesian people. The government's policy regarding the increase in fuel prices raises many opinions from the public. Twitter is one of the social media that Indonesian people often use to express opinions on a topic. In this study, sentiment analysis was carried out on public opinion regarding the fuel price increase policy from Twitter social media. This research is expected to help determine public opinion regarding the fuel price increase policy with positive, neutral and negative sentiments. The sentiment analysis method used is the Support Vector Machine (SVM) classification algorithm. The results of the accuracy of SVM were compared with accuracy by adding a feature selection process. The Particle Swarm Optimization (PSO) and Genetic Algorithm (GA) algorithms are used for the feature selection method. After several experiments using the three methods, the SVM method with the Radial Basis Function (RBF) kernel produced the best accuracy of 71.2%. The combination of the SVM method with the RBF and PSO kernels obtained an accuracy of 68.84%, and the combination of the RBF and GA kernel SVM methods obtained an accuracy of 69.52%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.52436/1.jutif.2023.4.3.881"
    },
    {
        "id": 34098,
        "title": "An Exploratory Analysis of Feature Selection for Malware Detection with Simple Machine Learning Algorithms",
        "authors": "Md Ashikur Rahman, Syful Islam, Yusuf Sulistyo Nugroho, Fatah Yasin Al Irsyadi, Md Javed Hossain",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.24138/jcomss-2023-0091"
    },
    {
        "id": 34099,
        "title": "Multimodal deep learning for chronic kidney disease prediction: leveraging feature selection algorithms and ensemble models",
        "authors": "N. J. Subashini, K. Venkatesh",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/1206212x.2023.2262786"
    },
    {
        "id": 34100,
        "title": "Feature selection techniques and classification algorithms for student performance classification: a review",
        "authors": "Muhamad Aqif Hadi Alias, Najidah Hambali, Mohd Azri Abdul Aziz, Mohd Nasir Taib, Rozita Jailani",
        "published": "2024-6-1",
        "citations": 0,
        "abstract": "The process of categorizing students’ performance based on input data, encompassing demographic information and final exam results, is recognized as student performance classification. Educational data mining has gained traction in assessing students’ performance. However, this study entails the need to analyze the diverse attributes of students’ information within an educational institution by using data mining techniques. This study thoroughly examines both previous and current methodologies presented by researchers, addressing two main aspects: data preprocessing and classification algorithms applied in student performance classification. Data preprocessing specifically delves into the exploration of feature selection techniques, encompassing three types of feature selection and search methods. These techniques aim to identify the most significant features, eliminate unnecessary ones, and reduce data dimensionality. In addition, classification algorithms play a crucial role in categorizing or predicting student performance. Models such as k-nearest neighbors (KNN), decision tree (DT), artificial neural networks (ANN), and linear models (LR) were scrutinized based on their performance in prior research. Ultimately, this study highlights the potential for further exploration of feature selection techniques like information gain, Chi-square, and sequential selection, particularly when applied to new datasets such as students’ online learning activities, utilizing a variety of classification algorithms.",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijece.v14i3.pp3230-3243"
    },
    {
        "id": 34101,
        "title": "Correlation Feature Selection (CFS) and Feature Weighting (CFW) Based Improved BPSO for Gene Selection and Cancer Classification",
        "authors": "Tirath Prasad Sahu,  Ankita",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3625156.3625199"
    },
    {
        "id": 34102,
        "title": "Stereo 3D Object Detection Using a Feature Attention Module",
        "authors": "Kexin Zhao, Rui Jiang, Jun He",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "Stereo 3D object detection remains a crucial challenge within the realm of 3D vision. In the pursuit of enhancing stereo 3D object detection, feature fusion has emerged as a potent strategy. However, the design of the feature fusion module and the determination of pivotal features in this fusion process remain critical. This paper proposes a novel feature attention module tailored for stereo 3D object detection. Serving as a pivotal element for feature fusion, this module not only discerns feature importance but also facilitates informed enhancements based on its conclusions. This study delved into the various facets aided by the feature attention module. Firstly, a interpretability analysis was conducted concerning the function of the image segmentation methods. Secondly, we explored the augmentation of the feature fusion module through a category reweighting strategy. Lastly, we investigated global feature fusion methods and model compression strategies. The models devised through our proposed design underwent an effective analysis, yielding commendable performance, especially in small object detection within the pedestrian category.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/a16120560"
    },
    {
        "id": 34103,
        "title": "Optimal route selection model in freight transport with customer collection approach using genetic and fuzzy algorithms",
        "authors": "Mohammad Saeid Erfannejad, Ali Paydar, Salman Safavi",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijor.2024.137932"
    },
    {
        "id": 34104,
        "title": "On the Effect of Temporal Heterogeneity on Selection Pressure of Evolutionary Algorithms",
        "authors": "Victor Manuel Sanchez Sanchez, Carlos Gershenson Garcia, Carlos Ignacio Hernandez Castellanos",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3583133.3590749"
    }
]