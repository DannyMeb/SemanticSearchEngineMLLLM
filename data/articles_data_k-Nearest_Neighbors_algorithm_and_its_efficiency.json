[
    {
        "id": 8905,
        "title": "Genetic Disorder Prediction Using K-Nearest Neighbors Algorithm",
        "authors": "Shreya Mahajan -, Saylee Mahajan -",
        "published": "2023-12-14",
        "citations": 0,
        "abstract": "There are many websites available which can be used to calculate the chances of certain diseases occurring in a person such as diabetes, Atherosclerotic Cardiovascular Disease and many others. People use these kind of websites to gain knowledge and rough insights about their health by inputting their body statistics. This project mainly focuses on the genetic aspect of the person’s health. This paper discusses the making of a website which states if the offspring carries the genetic disorder or not.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36948/ijfmr.2023.v05i06.10405"
    },
    {
        "id": 8906,
        "title": "Leaf Recognition Using K-Nearest Neighbors Algorithm with Zernike Moments",
        "authors": "Zhuohao Jia, Simon Liao",
        "published": "2023-7-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icivc58118.2023.10270642"
    },
    {
        "id": 8907,
        "title": "Application and comparison of decision tree algorithm and  K-Nearest Neighbors algorithm in heart disease prediction",
        "authors": "Yiran Wang",
        "published": "2024-1-31",
        "citations": 0,
        "abstract": "In the past two decades, rapid industrialization and urbanization have led to tremendous economic growth and an improvement in people's living standards. However, the impact of people's irregular lifestyles and habits on their health has gradually emerged. Among them, cardiovascular diseases have become particularly prominent, with increasing incidence and mortality rates, especially in developing countries. Heart disease is a major cause of the rising death rates. Early-stage prediction of heart disease poses a major challenge in clinical analysis. Today, the adoption of appropriate decision support systems to achieve cost reduction in clinical trials has become a future development trend for many hospitals. This study compares decision tree classification and K-nearest neighbors (KNN) classification algorithms to seek better diagnostic performance for heart disease. The existing dataset of heart disease patients from the Cleveland database is used to te3st and demonstrate the performance of all algorithms, providing support for the establishment of a heart disease prediction system. This, in turn, can assist doctors in making more accurate diagnoses and timely interventions before the onset of heart disease, thereby reducing the mortality rate of heart disease from the source.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/30/20230082"
    },
    {
        "id": 8908,
        "title": "Active learning accelerated Monte-Carlo simulation based on the modified K-nearest neighbors algorithm and its application to reliability estimations",
        "authors": "Zhifeng Xu, Jiyin Cao, Gang Zhang, Xuyong Chen, Yushun Wu",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.dt.2022.09.012"
    },
    {
        "id": 8909,
        "title": "Artificial Neural Network Based Categorization of Diabetes Mellitus and its Comparison with K-Nearest Neighbors Algorithm",
        "authors": "Raju Ranjan, Sachin Gupta, Sachin Sharma, Sura Rahim Alatba, Anusha Sreeram, Sowmya Fernandez",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icacite57410.2023.10182961"
    },
    {
        "id": 8910,
        "title": "SelB-k-NN: A Mini-Batch K-Nearest Neighbors Algorithm on AI Processors",
        "authors": "Yifeng Tang, Cho-Li Wang",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ipdps54959.2023.00088"
    },
    {
        "id": 8911,
        "title": "Prediction of Heart Disease using Forest Algorithm over K-nearest neighbors using Machine Learning with Improved Accuracy",
        "authors": "R.K.N.S. Shanmukha, K. Thinakaran",
        "published": "2023-2-14",
        "citations": 0,
        "abstract": "Aim: To perform Predicting heart disease using the Forest algorithm and comparing its feature extraction precision with the K-nearest neighbors algorithm for working on the precision of the forecast. Materials and Methods: In the proposed work, Predicting heart disease was carried out using machine learning algorithms such as K-nearest neighbors algorithm (n=10) and Forest Algorithm (n=10). Here the pretest power examination was done with gpower 80% and the sample size for the two gatherings was 20. Results: From The implemented experiment, the Forest algorithm accuracy is significantly better and it is 90.0% than the K-nearest neighbors algorithm 83.00%. There is a measurable 2-tailed significant distinction in exactness for two calculations is 0.001 (p<0.05) by performing Independent samples T-tests. Conclusion: The Forest algorithm got better Accuracy and classification of digits better than K-nearest neighbors algorithm for Predicting heart disease.",
        "keywords": "",
        "link": "http://dx.doi.org/10.18137/cardiometry.2022.25.15001506"
    },
    {
        "id": 8912,
        "title": "Comparison of Breast Cancer Classification Using the Decision Tree ID3 Algorithm and K-Nearest Neighbors Algorithm",
        "authors": "Zyhan Faradilla Daldiri, Desti Fitriati",
        "published": "2023-3-3",
        "citations": 0,
        "abstract": "One of the main causes of death is cancer. The most common cancer in women is breast cancer. Breast cancer (Carcinoma mammae) is defined as a malignant neoplasm originating from the parenchyma. Breast cancer ranks first in terms of the highest number of cancers in Indonesia and is one of the first contributors to cancer deaths. Globocan data in 2020, the number of new cases of breast cancer reached 68,858 cases (16.6%) of the total 396,914 new cases of cancer in Indonesia. Meanwhile, the number of deaths reached more than 22 thousand cases (Romkom, 2022). This death rate is increasing due to lack of information about the early symptoms and dangers of breast cancer itself. From this lack of information, a system is needed that can provide information about breast cancer such as early diagnosis. Classification data mining techniques can be used to predict which patients will develop breast cancer and which do not with several parameters. In this study, a comparison of the classification of breast cancer using the Decision Tree ID3 algorithm and the K-Nearest Neighbors algorithm will be carried out. Attribute data used consists of Menopause, Tumor-Size, Node-Caps, Deg-Malig, Breast, Breast-Squad and Irradiant. The main objective of this study is to improve classification performance in breast cancer diagnosis by applying feature selection to several classification algorithms. The Decision Tree ID3 algorithm has an accuracy rate of 93.333% and the K-Nearest Neighbors algorithm has an accuracy rate of 76.6667%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.34288/jri.v5i2.406"
    },
    {
        "id": 8913,
        "title": "Brain tumor detection using random forest algorithm in comparison with k-nearest neighbors algorithm to measure the accuracy, precision and recall",
        "authors": "M. Sandeep, A. Deepak",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0158397"
    },
    {
        "id": 8914,
        "title": "Predicting Agricultural Product Unit Production Using the K-Nearest Neighbors Algorithm",
        "authors": "Nebri Mohamed-Amine, Moussaid Abdellatif, Belaid Bouikhalene",
        "published": "2023-11-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ictmod59086.2023.10472900"
    },
    {
        "id": 8915,
        "title": "An adaptive mutual K-nearest neighbors clustering algorithm based on maximizing mutual information",
        "authors": "Yizhang Wang, Wei Pang, Zhixiang Jiao",
        "published": "2023-5",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2022.109273"
    },
    {
        "id": 8916,
        "title": "On incremental radius algorithm for k Nearest Neighbors over compact data structure k²-tree",
        "authors": "Rodrigo Torres-Avilés",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sccc59417.2023.10315737"
    },
    {
        "id": 8917,
        "title": "Improving the Performance of the K-Nearest Neighbors Algorithm with Parallelization in Dask",
        "authors": "Amin Rezanejad, Amir Seyed Danesh",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aisp61396.2024.10475304"
    },
    {
        "id": 8918,
        "title": "Performance analysis of vehicle detection using K-nearest neighbors comparing with fuzzy k-modes algorithm",
        "authors": "D. Manivarma, A. Akilandeswari",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0159810"
    },
    {
        "id": 8919,
        "title": "Heart Plaque Detection with Improved Accuracy using K-Nearest Neighbors classifier Algorithm in comparison with Least Squares Support Vector Machine",
        "authors": "V.S. Kumar, K. Vidhya",
        "published": "2023-2-14",
        "citations": 0,
        "abstract": "Aim: The objective of the work is to evaluate the performance of the k-Nearest Neighbor classifier in detecting heart plaque with high accuracy and comparing it with the Least Squares Support Vector Machine. Materials and Methods: The Kaggle dataset on Heart Plaque Disease yielded a total of 20 samples. Clincalc, which has two groups: alpha, power, and enrollment ratio, is used to assess G power of 0.08 with 95% confidence interval for samples. The training dataset (n = 489 [70 percent]) and the test dataset (n = 277 [30 percent]) are divided into two groups. Accuracy is used to assess the performance of the k-Nearest Neighbor algorithm and the Least Squares Support Vector Machine. Results: The accuracy of the k-Nearest Neighbor algorithm was 86 % and 67.3 % for the Least Squares Support Vector Machine technique. Since p (2-tailed) < 0.05, in SPSS statistical analysis, a significant difference exists between the two groups. Conclusion: In this work, the k-Nearest Neighbor algorithm outperformed the Least Squares Support Vector Machine algorithm in detecting heart plaque disease in the dataset under consideration.",
        "keywords": "",
        "link": "http://dx.doi.org/10.18137/cardiometry.2022.25.15901594"
    },
    {
        "id": 8920,
        "title": "Predicting S&amp;P 500 Index ETF (SPY) During COVID-19 via K-Nearest Neighbors (KNN) Algorithm",
        "authors": "",
        "published": "2023-5-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.33423/jaf.v23i2.6149"
    },
    {
        "id": 8921,
        "title": "kM++kNN : A fast algorithm for the exact search of k-nearest neighbors",
        "authors": "Raphael Lopes de Souza, Osvaldo Luiz de Oliveira",
        "published": "2023-6-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/cisti58278.2023.10211848"
    },
    {
        "id": 8922,
        "title": "Research on Intelligent Clustering of Textile Fabric Pattern Based on K-Nearest Neighbors Algorithm",
        "authors": "Mingjuan Li",
        "published": "2023-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceib57887.2023.10170418"
    },
    {
        "id": 8923,
        "title": "Sentiment Analysis Of Tourist Reviews Using K-Nearest Neighbors Algorithm And Support Vector Machine",
        "authors": "Anita Wulan Sari, Teguh Iman Hermanto, Meriska Defriani",
        "published": "2023-7-1",
        "citations": 0,
        "abstract": "After Indonesia was awarded as a country with extraordinary natural charm, many foreign tourists came to Indonesia. According to the records of the Central Bureau of Statistics for 2020, approximately 5.47 million foreign tourists entered Indonesia. With the large number of foreign tourist visits, the need for tourist attractions is increasing, but finding information is now not difficult. One source of information for finding reviews of tourist attractions is TripAdvisor. On this website, there is a lot of information or reviews about various tourist attractions. However, the number of reviews makes tourists confused about identifying the quality of tourist attractions to be visited, so sentiment analysis needs to be done. Sentiment analysis itself is a technique to extract, identify, and understand sentiments or opinions contained in a text. In this research, two classification methods will be used in sentiment analysis techniques, namely K-Nearest Neighbors (K-NN) and Support Vector Machine (SVM). Besides that, the object of this research will be to focus on the most popular tourist attractions in Indonesia according to Trip Advisor, namely Waterbom Bali, Mandala Suci Wenara Wana, Teras Sawah Tegalalang, Pura Tanah Lot, and Pura Luhur Uluwatu. The purpose of the research is to find out the results of accurate sentiment analysis for the five tourist attractions and compare the two algorithms used. and after testing, it was found that the Support Vector Machine algorithm is superior to the K-Nearest Neighbors algorithm.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33395/sinkron.v8i3.12447"
    },
    {
        "id": 8924,
        "title": "Enhancing Breast Cancer Prediction with an Advanced K-Nearest Neighbors (KNN) Algorithm Integrated with Feedback Support Mechanism",
        "authors": "Christian Arthur, Kristoko Dwi Hartomo",
        "published": "2023-12-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icteca60133.2023.10491036"
    },
    {
        "id": 8925,
        "title": "Study on Weighted K-Nearest Neighbors Indoor Location Algorithm Based on Random Forest Access Point Selection",
        "authors": "Zhehao Zhou, Yuanjian Liu, Guyue Zhu, Shuangde Li",
        "published": "2023-5-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iws58240.2023.10222030"
    },
    {
        "id": 8926,
        "title": "Blockchain technology-based FinTech banking sector involvement using adaptive neuro-fuzzy-based K-nearest neighbors algorithm",
        "authors": "Husam Rjoub, Tomiwa Sunday Adebayo, Dervis Kirikkaleli",
        "published": "2023-3-10",
        "citations": 9,
        "abstract": "AbstractThe study aims to investigate the financial technology (FinTech) factors influencing Chinese banking performance. Financial expectations and global realities may be changed by FinTech’s multidimensional scope, which is lacking in the traditional financial sector. The use of technology to automate financial services is becoming more important for economic organizations and industries because the digital age has seen a period of transition in terms of consumers and personalization. The future of FinTech will be shaped by technologies like the Internet of Things, blockchain, and artificial intelligence. The involvement of these platforms in financial services is a major concern for global business growth. FinTech is becoming more popular with customers because of such benefits. FinTech has driven a fundamental change within the financial services industry, placing the client at the center of everything. Protection has become a primary focus since data are a component of FinTech transactions. The task of consolidating research reports for consensus is very manual, as there is no standardized format. Although existing research has proposed certain methods, they have certain drawbacks in FinTech payment systems (including cryptocurrencies), credit markets (including peer-to-peer lending), and insurance systems. This paper implements blockchain-based financial technology for the banking sector to overcome these transition issues. In this study, we have proposed an adaptive neuro-fuzzy-based K-nearest neighbors’ algorithm. The chaotic improved foraging optimization algorithm is used to optimize the proposed method. The rolling window autoregressive lag modeling approach analyzes FinTech growth. The proposed algorithm is compared with existing approaches to demonstrate its efficiency. The findings showed that it achieved 91% accuracy, 90% privacy, 96% robustness, and 25% cyber-risk performance. Compared with traditional approaches, the recommended strategy will be more convenient, safe, and effective in the transition period.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s40854-023-00469-3"
    },
    {
        "id": 8927,
        "title": "Classification of Corporate Tax Compliance in Indonesia Based on k-Nearest Neighbors Algorithm",
        "authors": "Nur Uddin, Agustine Dwianika, Irma Paramita Sofia, Rodrigue Tchamna",
        "published": "2023-6-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aiiot58121.2023.10174541"
    },
    {
        "id": 8928,
        "title": "Research on Evaluating Teaching Quality of Accounting Courses Based on Improved K-nearest Neighbors Algorithm(KNN)",
        "authors": "Jian Sun",
        "published": "2023-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceib57887.2023.10170702"
    },
    {
        "id": 8929,
        "title": "Classification of Events in Selected Industrial Processes Using Weighted Key Words and K-Nearest Neighbors Algorithm",
        "authors": "Mateusz Walczak, Aneta Poniszewska-Marańda, Krzysztof Stepień",
        "published": "2023-9-15",
        "citations": 1,
        "abstract": "The problem of classifying events in the industry is related to a large amount of accumulated text data including, among others, communication between the company and the client, whose expectations regarding the quality of its service are constantly growing. The currently used solutions for handling incoming requests have numerous disadvantages; they imply additional costs for the company and often a high level of customer dissatisfaction. A partial solution to this problem may be the automation of event classification; for example, by means of an expert IT system. The presented work proposes the solution to the problem of classifying text events. For this purpose, textual descriptions of events were used, which were collected for many years by companies from many different industries. A large part of text events are various types of problems reported by company customers. As part of this work, a complex text-classification process was constructed by using the K-Nearest Neighbors algorithm. The demonstrated classification process uses two novel proposed mechanisms: the dynamic extension of stop list and weighted keywords. Both of the mechanisms aim to improve the classification performance by solving typical problems that occur when using a fixed stop list and a classical keyword extraction approach by using TF or TF-IDF methods. Finally, the Text Events Categorizer system that implements the proposed classification process was described.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app131810334"
    },
    {
        "id": 8930,
        "title": "A PM2.5 Forewarning Algorithm Using k-Nearest Neighbors Machine Learning at Changpuek, Chiang Mai, Thailand",
        "authors": "Nopparat Pochai, Kaboon Thongtha",
        "published": "2023-8-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3625704.3625749"
    },
    {
        "id": 8931,
        "title": "Gravitational clustering algorithm based on mutual K-nearest neighbors",
        "authors": "Zhenming Ma, Jiaqi Xu, Ruixi Li, Jinpeng Chen",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3611450.3611462"
    },
    {
        "id": 8932,
        "title": "k-NNN: Nearest Neighbors of Neighbors for Anomaly Detection",
        "authors": "Ori Nizan, Ayellet Tal",
        "published": "2024-1-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacvw60836.2024.00110"
    },
    {
        "id": 8933,
        "title": "Application of Data Mining with K-Nearest Neighbors Algorithm for Shallot Price Prediction",
        "authors": "Yuana Inka Dewi Br Sinulingga, Donny Avianto",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "Shallots are an important and widely consumed bulb crop in Indonesia, both for medicinal and culinary purposes. However, shallot yield is substantially affected by its supply, often leading to significant price fluctuations that greatly impact consumers and producers, especially farmers. Farmers who cannot accurately predict shallot prices often incur losses when selling to shallot distributors. If this problem is not resolved, it may discourage farmers from cultivating shallots. Therefore, a prediction system is needed to forecast shallot prices in the future, thus helping farmers make the right decisions. This research uses the K-Nearest Neighbors (KNN) algorithm for shallot price prediction. KNN classifies data into specific categories based on the closest distance to a set of k patterns for each category, using the Euclidean distance formula to calculate the distance. The dataset consists of 303 entries with five features: farmer price, seller price, retail price, seed price, and yield. The test results of the Shallot Price Prediction System in North Sumatra Province, Indonesia, using the K-Nearest Neighbors Algorithm, showed the best performance when using 80% training data and 20% testing data, with a value of k=2, resulting in a Mean Absolute Error (MAE) of 25,786 and a Mean Squared Error (MSE) of 72. This system empowers farmers to predict the future price of shallots before selling their crops to distributors.",
        "keywords": "",
        "link": "http://dx.doi.org/10.32996/jcsts.2023.5.4.5"
    },
    {
        "id": 8934,
        "title": "Outlier Detection and Spectrum Feature Extraction Based on Nearest-Neighbors Correlation and Random Forest Algorithm",
        "authors": "Rodney Martinez Alonso, David Plets, Sofie Pollin, Luc Martens, Wout Joseph",
        "published": "2023-5-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icc45041.2023.10279819"
    },
    {
        "id": 8935,
        "title": "Classification of the Ionospheric Disturbances Caused by Geomagnetic and Seismic Activity with K-Nearest Neighbors Algorithm",
        "authors": "Cafer Budak, Secil Karatay, Faruk Erken, Ali Cinar",
        "published": "2024-4-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11277-024-10965-z"
    },
    {
        "id": 8936,
        "title": "Comparison of Performance of K-Nearest Neighbors and Neural Network Algorithm in Bitcoin Price Prediction",
        "authors": "Eko Aziz Apriadi, Sriyanto Sriyanto, Sri Lestari, Suhendro Yusuf Irianto",
        "published": "2024-3-31",
        "citations": 0,
        "abstract": "This research evaluates and compares the performance of two prediction methods, namely K-Nearest Neighbors (K-NN) and Neural Network, in the context of Bitcoin price prediction. Historical Bitcoin price data is used as input to train and test both algorithms. Experimental results show that the K-NN algorithm produces a Root Mean Square Error (RSME) of 389,770 and a Mean Absolute Error (MAE) of 89,261, while the Neural Network has an RSME of 614,825 and an MAE of 284,190. Performance comparison analysis shows that, on this dataset, K-NN has better performance in predicting Bitcoin prices compared to Neural Network. These findings provide important insights for the selection of crypto asset price prediction models, especially Bitcoin, in financial and investment environments",
        "keywords": "",
        "link": "http://dx.doi.org/10.33395/sinkron.v8i2.13418"
    },
    {
        "id": 8937,
        "title": "Efficiency analysis of k-Nearest Neighbors machine learning  method for 10-minutes ahead forecasts of electric energy  production at an onshore wind farm",
        "authors": "Inajara RUTYNA",
        "published": "2024-1-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.15199/48.2024.01.31"
    },
    {
        "id": 8938,
        "title": "Voice Conversion With Just Nearest Neighbors",
        "authors": "Matthew Baas, Benjamin van Niekerk, Herman Kamper",
        "published": "2023-8-20",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-419"
    },
    {
        "id": 8939,
        "title": "OCR Based Image Text to Speech Conversion using K-Nearest Neighbors and Comparing with Fuzzy K-Means Clustering Algorithm",
        "authors": "M. Pandu Babu, Anitha G",
        "published": "2023-5-25",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/accai58221.2023.10200864"
    },
    {
        "id": 8940,
        "title": "Evaluation of the implementation of machine learning algorithm K-Nearest Neighbors (KNN) using rapid miner on  junior high school student learning outcomes",
        "authors": "Lucky Heriyanti Jufri, Dadan Dasari",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "The focus of the PISA 2022 assessment is on the subjects of Mathematics, Language and Science. Therefore, these subjects are compulsory subjects at every level of education. Because learning activities are the most important activities, the success of a learning activity is measured by the learning outcomes that have reached completeness or failed. Prediction of completeness or failure can be done by classifying data using the K-Nearest Neighbors (KNN) algorithm using the RapidMiner application. The KNN algorithm is one of the classification methods for a set of data based on learning data that has been classified before. The data used are student learning outcomes in Mathematics, Indonesian Language and Science subjects at the junior high school education level in Padang city. This research aims to predict student learning outcomes in Mathematics, Indonesian and Science subjects based on student score completeness by comparing various k values to obtain the best performance of this algorithm. The results obtained after analyzing the KNN algorithm are Classification using the KNN algorithm is most accurate when the value of k = 5 and k = 7. Where by using the value of k, the accuracy of the KNN algorithm reaches the maximum result of 94.12%. Thus, this algorithm can help teachers to predict or find out how appropriate student completeness.\r\n ",
        "keywords": "",
        "link": "http://dx.doi.org/10.31629/jg.v8i2.6590"
    },
    {
        "id": 8941,
        "title": "Explainable Outlier Detection Using Feature Ranking for k-Nearest Neighbors, Gaussian Mixture Model and Autoencoders",
        "authors": "Lucas Krenmayr, Markus Goldstein",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011631900003411"
    },
    {
        "id": 8942,
        "title": "The Comparison of K-Nearest Neighbors and Random Forest Algorithm to Recognize Indonesian Sign Language in a Real-Time",
        "authors": "Aaqila Dhiyaanisafa Goenawan, Sri Hartati",
        "published": "2024-2-29",
        "citations": 0,
        "abstract": "Purpose: Comparing 2 models or prototype programs which can recognize Indonesian Sign Language System or Sistem Isyarat Bahasa Indonesia (SIBI) fonts from hand gesture and translate it’s into writing Messages in real-time.Methods: After selecting datasets and reprocessed by the researcher into 1 dataset, which are a combination of several sign image datasets of the SIBI letters images available on the Kaggle website, the dataset is converted into landmarks. The landmarks are divided into 26 sign classes and preprocessed to a total of 19,826 rows of data, and then divided into 67% training data and 33% test data. Next, both K-NN and Random Forest algorithm are implemented into different program and get tested into 2 different tests, model evaluation and real-time. At the end, the result is compared to see the increase of accuracy level of both K-Nearest Neighbors (K-NN) and Random Forest algorithm.Result: The constructed and trained model is then evaluated and the results of Precision, Recall, Accuracy, and F1-Score are 99.88% using the Random Forest algorithm. The results of real-time program testing with the K-Nearest Neighbors algorithm get higher results, where the average accuracy value reaches 99%.Novelty: From the result shows that the model built with the Random Forest algorithm is superior, but the K-Nearest Neighbors algorithm is better in real-time testing. Therefore, image data and its diversity should be increased, in order to improve recognition accuracy. The program could be enhanced by adding a function where the program can recognize hand gesture, not only one or two hands but also can recognize a hand gesture with movements so the program can recognize static and dynamic letter (required hands movement).",
        "keywords": "",
        "link": "http://dx.doi.org/10.15294/sji.v11i1.48475"
    },
    {
        "id": 8943,
        "title": "Retracted: Detection of Power Data Outliers Using Density Peaks Clustering Algorithm Based on <i>K</i>-Nearest Neighbors",
        "authors": "",
        "published": "2023-7-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9890424"
    },
    {
        "id": 8944,
        "title": "Incorporating Connectivity in k-Nearest Neighbors Regression",
        "authors": "Mohamed A. Mahfouz",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/imsa58542.2023.10217502"
    },
    {
        "id": 8945,
        "title": "Classification of Siam Orange Ripeness Level using K-Nearest Neighbors Algorithm and Features Gray Level Run Length Matrix",
        "authors": "Mustika Mentari, Cahya Rahmad, Moch. Syifa’ Muchlisin, Septian Enggar Sukmana",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/comnetsat59769.2023.10420620"
    },
    {
        "id": 8946,
        "title": "Diabetes Mellitus Early Detection Simulation using The K-Nearest Neighbors Algorithm with Cloud-Based Runtime (COLAB)",
        "authors": "Mohamad Jamil, Budi Warsito, Adi Wibowo, Kiswanto Kiswanto",
        "published": "2023-8-16",
        "citations": 1,
        "abstract": "Diabetes Mellitus is a genetically and clinically heterogeneous metabolic disorder with manifestations of loss of carbohydrate tolerance characterized by high blood glucose levels as a result of insulin insufficiency. Public knowledge of diabetes mellitus 39.30% is influenced by public health education and information about diabetes mellitus that the public has ever received. Early detection of diabetes mellitus can prevent the development of chronic complications and allow timely and rapid treatment. The aim of this study is to simulate the early detection of diabetes mellitus with the K-Nearest Neighbors (K-NN) algorithm using Cloud-Base Runtime (COLAB). The highest accuracy is 76% in K=3, the highest precision is 68% in K=3 and the highest recall is 60% in K=3.  The researchers used K-NN as a method to classify data from the Pima Indians Diabetes Database and obtained a fairly good accuracy value of 76% with a value of k = 3.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33096/ilkom.v15i2.1510.215-221"
    },
    {
        "id": 8947,
        "title": "Classification with K-Nearest Neighbors Algorithm: Comparative Analysis between the Manual and Automatic Methods for K-Selection",
        "authors": "Tsvetelina Mladenova, Irena Valova",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14569/ijacsa.2023.0140444"
    },
    {
        "id": 8948,
        "title": "IIR Shelving Filter, Support Vector Machine and k-Nearest Neighbors Algorithm Application for Voltage Transients and Short-Duration RMS Variations Analysis",
        "authors": "Vladislav Liubčuk, Gediminas Kairaitis, Virginijus Radziukynas, Darius Naujokaitis",
        "published": "2024-1-9",
        "citations": 0,
        "abstract": "This paper focuses on both voltage transients and short-duration RMS variations, and presents a unique and heterogeneous approach to their assessment by applying AI tools. The database consists of both real (obtained from Lithuanian PQ monitoring campaigns) and synthetic data (obtained from the simulation and literature review). Firstly, this paper investigates the fundamental grid component and its harmonics filtering with an IIR shelving filter. Secondly, in a key part, both SVM and KNN are used to classify PQ events by their primary cause in the voltage–duration plane as well as by the type of short circuit in the three-dimensional voltage space. Thirdly, since it seemed to be difficult to interpret the results in the three-dimensional space, the new method, based on Clarke transformation, is developed to convert it to two-dimensional space. The method shows an outstanding performance by avoiding the loss of important information. In addition, a geometric analysis of the fault voltage in both two-dimensional and three-dimensional spaces revealed certain geometric patterns that are undoubtedly important for PQ classification. Finally, based on the results of a PQ monitoring campaign in the Lithuanian distribution grid, this paper presents a unique discussion regarding PQ assessment gaps that need to be solved in anticipation of a great leap forward and refers them to PQ legislation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/inventions9010012"
    },
    {
        "id": 8949,
        "title": "A new sample reduction method for decreasing the running time of the k-nearest neighbors algorithm to diagnose patients with congestive heart failure: backward iterative elimination",
        "authors": "Yalcin Isler, Ugur Ozturk, Ebru Sayilgan",
        "published": "2023-3-25",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s12046-023-02105-3"
    },
    {
        "id": 8950,
        "title": "Confidence of a k-Nearest Neighbors Python Algorithm for the 3D Visualization of Sedimentary Porous Media",
        "authors": "Manuel Bullejos, David Cabezas, Manuel Martín-Martín, Francisco Javier Alcalá",
        "published": "2023-1-1",
        "citations": 9,
        "abstract": "In a previous paper, the authors implemented a machine learning k-nearest neighbors (KNN) algorithm and Python libraries to create two 3D interactive models of the stratigraphic architecture of the Quaternary onshore Llobregat River Delta (NE Spain) for groundwater exploration purposes. The main limitation of this previous paper was its lack of routines for evaluating the confidence of the 3D models. Building from the previous paper, this paper refines the programming code and introduces an additional algorithm to evaluate the confidence of the KNN predictions. A variant of the Similarity Ratio method was used to quantify the KNN prediction confidence. This variant used weights that were inversely proportional to the distance between each grain-size class and the inferred point to work out a value that played the role of similarity. While the KNN algorithm and Python libraries demonstrated their efficacy for obtaining 3D models of the stratigraphic arrangement of sedimentary porous media, the KNN prediction confidence verified the certainty of the 3D models. In the Llobregat River Delta, the KNN prediction confidence at each prospecting depth was a function of the available data density at that depth. As expected, the KNN prediction confidence decreased according to the decreasing data density at lower depths. The obtained average-weighted confidence was in the 0.44−0.53 range for gravel bodies at prospecting depths in the 12.7−72.4 m b.s.l. range and was in the 0.42−0.55 range for coarse sand bodies at prospecting depths in the 4.6−83.9 m b.s.l. range. In a couple of cases, spurious average-weighted confidences of 0.29 in one gravel body and 0.30 in one coarse sand body were obtained. These figures were interpreted as the result of the quite different weights of neighbors from different grain-size classes at short distances. The KNN algorithm confidence has proven its suitability for identifying these anomalous results in the supposedly well-depurated grain-size database used in this study. The introduced KNN algorithm confidence quantifies the reliability of the 3D interactive models, which is a necessary stage to make decisions in economic and environmental geology. In the Llobregat River Delta, this quantification clearly improves groundwater exploration predictability.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/jmse11010060"
    },
    {
        "id": 8951,
        "title": "Enhancing Diabetic Retinopathy Detection Using CNNs with Dimensionality Reduction Techniques and K-Nearest Neighbors Ensembles",
        "authors": "Chaymaa Lahmar, Ali Idri",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012191900003598"
    },
    {
        "id": 8952,
        "title": "A novel density peaks clustering algorithm for automatic selection of clustering centers based on K-nearest neighbors",
        "authors": "Zhihe Wang, Huan Wang, Hui Du, Shiyin Chen, Xinxin Shi",
        "published": "2023",
        "citations": 1,
        "abstract": "<abstract>\n\t\t\t<p>The density peak clustering algorithm (DPC) requires manual determination of cluster centers, and poor performance on complex datasets with varying densities or non-convexity. Hence, a novel density peak clustering algorithm is proposed for the automatic selection of clustering centers based on K-nearest neighbors (AKDPC). First, the AKDPC classifies samples according to their mutual K-nearest neighbor values into core and non-core points. Second, the AKDPC uses the average distance of K nearest neighbors of a sample as its density. The smaller the average distance is, the higher the density. Subsequently, it selects the highest density sample among all unclassified core points as a center of the new cluster, and the core points that satisfy the merging condition are added to the cluster until no core points satisfy the condition. Afterwards, the above steps are repeated to complete the clustering of all core points. Lastly, the AKDPC labels the unclassified non-core points similar to the nearest points that have been classified. In addition, to prove the validity of AKDPC, experiments on manual and real datasets are conducted. By comparing the AKDPC with classical clustering algorithms and excellent DPC-variants, this paper demonstrates that AKDPC presents higher accuracy.</p>\n\t\t</abstract>",
        "keywords": "",
        "link": "http://dx.doi.org/10.3934/mbe.2023528"
    },
    {
        "id": 8953,
        "title": "Hierarchical Belief K-Nearest Neighbors for Human Activity Recognition",
        "authors": "Yilin Dong, Yong Zhou",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/ccc58697.2023.10240988"
    },
    {
        "id": 8954,
        "title": "Perbandingan Algoritma Naïve Bayes dan K-Nearest Neighbors untuk Klasifikasi Metabolik Sindrom",
        "authors": "Fitriana Sholekhah, Adinda Dwi Putri, Rahmaddeni Rahmaddeni, Luasiana Efrizoni",
        "published": "2024-2-24",
        "citations": 0,
        "abstract": "Kondisi medis yang dikenal sebagai sindrom metabolik berpotensi meningkatkan kemungkinan penyakit jantung koroner, stroke, serangan jantung dan diabetes tipe 2. Sindrom metabolik juga dapat menyebabkan gula darah tinggi, kadar kolesterol rendah, obesitas secara bersamaan dan kelebihan lemak di daerah pinggang. Jika kombinasi dari ketiga kondisi ini terjadi maka dapat dikatakan penyakit ini  sebagai sindrom metabolik. Selain itu, sindrom metabolik juga dikaitkan dengan resistensi insulin, artinya dimana sel-sel tubuh tidak merespon baik terhadap efek insulin yang menyebabkan kadar gula darah tinggi karena gula tidak terserap ke dalam sel dengan baik. Sindrom metabolik tumbuh seiring meningkatnya obesitas di Asia, dengan perkiraan prevalensi yang terus naik. Ini berpotensi meningkatkan kasus penyakit kardiovaskular dan risiko kematian. Oleh karena itu, perlu dikembangkan model untuk mendiagnosis sindrom metabolik. Penelitian ini bertujuan untuk membandingkan kinerja algoritma klasifikasi utama, yaitu Naïve Bayes (NB) dan K-Nearest Neighbors (KNN) dalam mendeteksi sindrom metabolik. Hasil dari penelitian ini menunjukkan bahwa penggunaan algoritma Naïve Bayes menghasilkan akurasi sebesar 79%, sedangkan akurasi tertinggi dari algoritma K-Nearest Neighbors (KNN) adalah 82%. Kesimpulannya, dari hasil penelitian ini menunjukkan bahwa algoritma K-NN dengan pembagian data 50:50 lebih efektif dalam memprediksi dan mengklasifikasikan sindrom metabolik.",
        "keywords": "",
        "link": "http://dx.doi.org/10.57152/malcom.v4i2.1249"
    },
    {
        "id": 8955,
        "title": "Bearing fault detection in induction motors using the ROCOF and k-nearest neighbors algorithm",
        "authors": "Gerardo Avalos-Almazan, Sarahi Aguayo-Tapia, Jose Rangel-Magdaleno, Mario R.A. Paternina",
        "published": "2023-8-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sdemped54949.2023.10271434"
    },
    {
        "id": 8956,
        "title": "Prediction of Life Expectancy of Lung Cancer Patients Post Thoracic Surgery using K-Nearest Neighbors and Bat Algorithm",
        "authors": "Muhamad Nur Arifiansyah",
        "published": "2023-3-10",
        "citations": 1,
        "abstract": "\r\n\r\n\r\n\r\nLung cancer is one of the deadliest cancers, accounting for 11.6% of cancer diagnoses in the world. Death in lung cancer patients can occur in various ways and one of the treatments for lung cancer patients that can be done is thoracic surgery. Thoracic surgery is generally considered a medium risk procedure, but thoracic surgery has a high risk, one of the risks is that if the patient loses blood which will result in the death of the patient. In this study, the method used to implement predictive life expectancy in post-thoracic surgery patients is the bat algorithm for feature selection and the KNN algorithm for classifying data. The dataset used in this study was obtained from the UCI Machine Learning Repository, namely the thoracic surgery dataset which contains 470 data with 16 attributes. The results of the study in predicting the life expectancy of patients after thoracic surgery were carried out with 3 tests. The first test is testing the population with the best accuracy of 87.23%, the second test is convergent testing with the best accuracy of 87.23% and the third test is the comparison test of KNN which produces the best accuracy of 87.23%. The bat algorithm succeeded in increasing the accuracy of the KNN classification by 5.23% from 81.91%.  \r\n\r\n\r\n\r\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.15294/jaist.v4i2.60846"
    },
    {
        "id": 8957,
        "title": "Robustness Certification of k-Nearest Neighbors",
        "authors": "Nicolò Fassina, Francesco Ranzato, Marco Zanella",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdm58522.2023.00020"
    },
    {
        "id": 8958,
        "title": "Comparing the Prediction of Numeric Patterns on Form C1 Using the K-Nearest Neighbors (K-NN) Method and a Combination of K-Nearest Neighbors (K-NN) with Connected Component Labeling (CCL)",
        "authors": "Uci Suriani, Tri Basuki Kurniawan",
        "published": "2023-12-3",
        "citations": 0,
        "abstract": "Indonesia's elections serve as a cornerstone of its democratic system, with the active participation of its citizens being of paramount importance. To bolster transparency and civic engagement during these elections, the SITUNG system (Election Result Information System) is employed for the tabulation of election results. However, the current tabulation process remains manual, potentially leading to data entry errors and a reduced accuracy of election outcomes. This research endeavor seeks to enhance the efficiency and accuracy of election result tabulation by employing the K-Nearest Neighbors (K-NN) method for recognizing numeric patterns on Form C1, both independently and in combination with Connected Component Labeling (CCL). The K-NN method demonstrates a commendable 60.0% accuracy in recognizing numeric patterns from the original Form C1 data. However, when combined with CCL, the accuracy drops to 51.2%. This research makes a significant contribution by simplifying the tabulation process and improving the accuracy of election results in Indonesia through the application of the K-NN method. The technology is anticipated to fortify democracy by promoting a more transparent and participatory electoral process for the citizens.",
        "keywords": "",
        "link": "http://dx.doi.org/10.51519/journalisi.v5i4.592"
    },
    {
        "id": 8959,
        "title": "Customized K-nearest neighbors’ algorithm for malware detection",
        "authors": "Mosleh M. Abualhaj, Ahmad Adel Abu-Shareha, Qusai Y. Shambour, Adeeb Alsaaidah, Sumaya N. Al-Khatib, Mohammed Anbar",
        "published": "2024",
        "citations": 2,
        "abstract": "The security and integrity of computer systems and networks highly depend on malware detection. In the realm of malware detection, the K-Nearest Neighbors (KNN) algorithm is a well-liked and successful machine learning algorithm. However, the choice of an acceptable distance metric parameter has a significant impact on the KNN algorithm's performance. This study tries to improve malware detection by adjusting the KNN algorithm's distance metric parameter. The distance metric greatly influences the similarity or dissimilarity between instances in the feature space. The KNN algorithm for malware detection can be more accurate and effective by carefully choosing or modifying the distance metric. This paper analyzes multiple distance metrics, including Minkowski distance, Manhattan distance, and Euclidean distance. These metrics account for the traits of malware samples while capturing various aspects of similarity. The effectiveness of the KNN algorithm is evaluated using the MalMem-2022 malware dataset, and the results are broken down into these three-distance metrics. The experimental findings show that, among the three distance metric parameters, the Euclidean and Minkowski distance metric parameters considerably produced the best outcomes with binary classification. While with multiclass classification, the KNN algorithm has achieved the highest outcomes using Manhattan distance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5267/j.ijdns.2023.9.012"
    },
    {
        "id": 8960,
        "title": "Implementation of the K-Nearest Neighbors Algorithm in the AgroWeather System for Plant Recommendations Based on Weather Predictions",
        "authors": "Peti Savitri, Heri Purwanto, Teguh Wiharko, Edwar J. Ramdon, Edi Ardiansyah, Baiq Ega Aulia",
        "published": "2023-10-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tssa59948.2023.10366995"
    },
    {
        "id": 8961,
        "title": "Enhancing malware detection performance: leveraging K-Nearest Neighbors with Firefly Optimization Algorithm",
        "authors": "Adeeb Al Saaidah, Mosleh M. Abualhaj, Qusai Y. Shambour, Ahmad Adel Abu-Shareha, Laith Abualigah, Sumaya N. Al-Khatib, Yousef H Alraba’nah",
        "published": "2024-3-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-024-18914-5"
    },
    {
        "id": 8962,
        "title": "Comprehensive Analysis and Classification of Skin Diseases based on Image Texture Features using K-Nearest Neighbors Algorithm",
        "authors": "Mamet Adil Araaf, Kristiawan Nugroho, De Rosal Ignatius Moses Setiadi",
        "published": "2023-9-20",
        "citations": 6,
        "abstract": "Skin is the largest organ in humans, it functions as the outermost protector of the organs inside. Therefore, the skin is often attacked by various diseases, especially cancer. Skin cancer is divided into two, namely benign and malignant. Malignant has the potential to spread and increase the risk of death. Skin cancer detection traditionally involves time-consuming laboratory tests to determine malignancy or benignity. Therefore, there is a demand for computer-assisted diagnosis through image analysis to expedite disease identification and classification. This study proposes to use the K-nearest neighbor (KNN) classifier and Gray Level Co-occurrence Matrix (GLCM) to classify these two types of skin cancer. Apart from that, the average filter is also used for preprocessing. The analysis was carried out comprehensively by carrying out 480 experiments on the ISIC dataset. Dataset variations were also carried out using random sampling techniques to test on smaller datasets, where experiments were carried out on 3297, 1649, 825, and 210 images. Several KNN parameters, namely the number of neighbors (k)=1 and distance (d)=1 to 3 were tested at angles 0, 45, 90, and 135. Maximum accuracy results were 79.24%, 79.39%, 83.63%, and 100% for respectively 3297, 1649, 825, and 210. These findings show that the KNN method is more effective in working on smaller datasets, besides that the use of the average filter also has a significant contribution in increasing the accuracy.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33633/jcta.v1i1.9185"
    },
    {
        "id": 8963,
        "title": "Effective detection of Alzheimer's disease by optimizing fuzzy K-nearest neighbors based on salp swarm algorithm",
        "authors": "Dongwan Lu, Yinggao Yue, Zhongyi Hu, Minghai Xu, Yinsheng Tong, Hanjie Ma",
        "published": "2023-6",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compbiomed.2023.106930"
    },
    {
        "id": 8964,
        "title": "Modelling the Solubility of Metformin in Supercritical Carbon Dioxide using a k-Nearest Neighbors Regressor",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.59287/as-proceedings.422"
    },
    {
        "id": 8965,
        "title": "Quantifying Train-Evaluation Overlap with Nearest Neighbors",
        "authors": "Gauri Kambhatla, Thuy Nguyen, Eunsol Choi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.183"
    },
    {
        "id": 8966,
        "title": "A New Algorithm for Large-Scale Geographically Weighted Regression with K-Nearest Neighbors",
        "authors": "Xiaoyue Yang, Yi Yang, Shenghua Xu, Jiakuan Han, Zhengyuan Chai, Gang Yang",
        "published": "2023-7-21",
        "citations": 1,
        "abstract": "Geographically weighted regression (GWR) is a classical method for estimating nonstationary relationships. Notwithstanding the great potential of the model for processing geographic data, its large-scale application still faces the challenge of high computational costs. To solve this problem, we proposed a computationally efficient GWR method, called K-Nearest Neighbors Geographically weighted regression (KNN-GWR). First, it utilizes a k-dimensional tree (KD tree) strategy to improve the speed of finding observations around the regression points, and, to optimize the memory complexity, the submatrices of neighbors are extracted from the matrix of the sample dataset. Next, the optimal bandwidth is found by referring to the spatial clustering relationship explained by K-means. Finally, the performance and accuracy of the proposed KNN-GWR method was evaluated using a simulated dataset and a Chinese house price dataset. The results demonstrated that the KNN-GWR method achieved computational efficiency thousands of times faster than existing GWR algorithms, while ensuring accuracy and significantly improving memory optimization. To the best of our knowledge, this method was able to run hundreds of thousands or millions of data on a standard computer, which can inform improvement in the efficiency of local regression models.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ijgi12070295"
    },
    {
        "id": 8967,
        "title": "A WiFi Indoor Location Tracking Algorithm Based on Improved Weighted K Nearest Neighbors and Kalman Filter",
        "authors": "Jiusong Hu, Congwei Hu",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3263583"
    },
    {
        "id": 8968,
        "title": "Efficiency of novel K-means algorithm in human recognition system through palm vein images in comparison with K-nearest neighbor algorithm for better accuracy",
        "authors": "Hari Priya Mekala, Parthiban Selvarasu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0134678"
    },
    {
        "id": 8969,
        "title": "Recognizing steel elements with BRDF and k-nearest neighbors",
        "authors": "Adam Ciszkiewicz, Janusz Jaglarz, Tadeusz Uhl",
        "published": "2023-11-19",
        "citations": 0,
        "abstract": "The paper deals with analysis of recognition of surface quality with reflective structures. Such surfaces are common in metallic materials cut using a saw or polished. There are no easy methods to identify such elements after machining. This issue is crucial in the industry for quality control as recognition of the elements, for instance after failure, allows for a detailed study of their manufacturing process. Firstly, six cuboid steel elements were obtained from a larger beam with a circular saw. Then, the bidirectional reflection distribution function (BRDF) was obtained for each element 3 times. The BRDF profiles were used in custom recognition software based on the K-nearest neighbors algorithm. In total, 140 variants of the classifier were tested and analyzed. Additionally, each variant was solved 200 times with different splits of the dataset. The results showed a high multiclass accuracy in all considered variants of the algorithm, with multiple variants achieving 100% accuracy. This level of performance was attained with only 1 to 2 training samples per class. Its low numerical complexity, easy experimental procedure, and “one-shot” nature allow for fast recognition, which is crucial in industrial applications.",
        "keywords": "",
        "link": "http://dx.doi.org/10.24425/mms.2023.147958"
    },
    {
        "id": 8970,
        "title": "Denmune: Density Peak Based Clustering Using Mutual Nearest Neighbors",
        "authors": "Mohamed Abbas, Adel El-Zoghabi, Amin Shoukry",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4581471"
    },
    {
        "id": 8971,
        "title": "Implementation of the K-Nearest Neighbor Algorithm to Predict Air Pollution",
        "authors": " Claudyana Gabrillia Evitania",
        "published": "2023-11-29",
        "citations": 0,
        "abstract": "Air pollution is a serious issue that impacts air quality and human health. In this study, the K-Nearest Neighbor (KNN) algorithm is applied using Rapidminer software to predict air pollution levels. The research aims to predict air pollution levels based on various air quality parameters such as particulates, PM10, PM2.5, CO, NO2, SO2, and O3. By implementing the K-Nearest Neighbor algorithm in Rapidminer, the predicted values for air pollution data resulted in an accuracy of 93.94%. This study concludes that employing the K-Nearest Neighbor algorithm using Rapidminer software can be an effective method for predicting air pollution levels. With a strong accuracy rate of 93.94%, this can have a positive impact on both human health and the environment. The predictive model developed can aid decision-making and enhance awareness among the public regarding the importance of maintaining air quality management.",
        "keywords": "",
        "link": "http://dx.doi.org/10.58777/its.v1i1.123"
    },
    {
        "id": 8972,
        "title": "Local interpretation of nonlinear regression model with k-nearest neighbors",
        "authors": "Hiromasa Kaneko",
        "published": "2023-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.dche.2022.100078"
    },
    {
        "id": 8973,
        "title": "Multi-Density Datasets Clustering Using K-Nearest Neighbors and Chebyshev’s Inequality",
        "authors": "Amira Bouchemal, Mohamed Tahar Kimour",
        "published": "2023-10-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.31449/inf.v47i8.4719"
    },
    {
        "id": 8974,
        "title": "Investigation of the Properties of First Nearest Neighbors’ Graphs",
        "authors": "A.A. Kislitsyn A.A., Yu.N. Orlov, M.V. Goguev",
        "published": "2023-4",
        "citations": 0,
        "abstract": "In this study we present a benchmark of statistical distributions of the first nearest neighbors in random graphs. We consider distribution of such graphs by the number of disconnected fragments, fragments by the number of involved nodes, and nodes by their degrees. The statements about the asymptotic properties of these distributions for graphs of large dimension are proved. The problem under investigation is to estimate the probability of realization of a certain structure of the first nearest neighbors graph depending on the distribution function of distances between the elements of the studied set. It is shown that, up to isomorphism, the graph of the first nearest neighbors does not depend on the distance distribution. This fact makes it possible to conduct numerical experiments on the construction of basic statistics based on a uniform distribution of distances and obtain tabulated data as a result of numerical modeling. We also discuss the approximation of the distribution of graph vertices by degrees, which allows us to estimate the proportion of randomness for a particular structure resulting from clustering elements of a certain set by the nearest neighbor method. The asymptotic analysis of the fragment distribution is discussed.",
        "keywords": "",
        "link": "http://dx.doi.org/10.26583/sv.15.1.02"
    },
    {
        "id": 8975,
        "title": "Enhanced Oversampling Framework in Conjunction with Nearest Neighbors",
        "authors": "Aneena Kurian, Linda Sara Mathew",
        "published": "2023-4-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceeict56924.2023.10157904"
    },
    {
        "id": 8976,
        "title": "Fast geometrical extraction of nearest neighbors from multi-dimensional data",
        "authors": "Yasir Aziz, Kashif Hussain Memon",
        "published": "2023-4",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2022.109183"
    },
    {
        "id": 8977,
        "title": "OPTIMIZATION OF THE K-NEAREST NEIGHBORS ALGORITHM USING THE ELBOW METHOD ON STROKE PREDICTION",
        "authors": "Febri Sutomo, Daffa Ammar Muaafii, Daffa Naufaldi Al Rasyid, Yogiek Indra Kurniawan, Lasmedi Afuan, Teguh Cahyono, Eddy Maryanto, Dadang Iskandar",
        "published": "2023-2-10",
        "citations": 0,
        "abstract": "Stroke is the second most deadly disease in the world according to WHO. The sufferer has an injury to the nervous system. Because of this, health experts, especially in the field of nursing, need special attention. Technological advances continue to change over time so that information needs are needed in life. Currently the data on stroke sufferers is extensive enough so that adequate information presentation techniques are needed so that the information received is very accurate and in accordance with user needs. Therefore, it is necessary to process data mining on stroke patient data to obtain useful information for users. This study aims to prove the performance of the Elbow Method to produce the optimum k value in the stroke prediction data using the K-Nearest Neighbors (KNN) algorithm. The optimum k value is generated from the Elbow Method which is executed with the Google Collaboratory using the Python programming language. The test results show that the Elbow Method produces the optimum k value at k = 7. The KNN model that uses the optimum k value from the Elbow Method can increase the accuracy and precision values ​​reaching 6% and 0.12, respectively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.52436/1.jutif.2023.4.1.839"
    },
    {
        "id": 8978,
        "title": "JADE with k Nearest Neighbors Surrogate Model",
        "authors": "Konrad Krawczyk, Jarosław Arabas",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3583133.3596382"
    },
    {
        "id": 8979,
        "title": "Probabilistic Local Mean K-Nearest Neighbors Classification",
        "authors": "Dian Liu, Chunyu Jiang, Yixin Cao",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eebda60612.2024.10485665"
    },
    {
        "id": 8980,
        "title": "Data-Efficient Finetuning Using Cross-Task Nearest Neighbors",
        "authors": "Hamish Ivison, Noah A. Smith, Hannaneh Hajishirzi, Pradeep Dasigi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.576"
    },
    {
        "id": 8981,
        "title": "Improving Frequency Stability Assessment through K-Nearest Neighbors and Machine Learning Techniques",
        "authors": "Bwandakassy Elenga Baningobera, Irina Oleinikova",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isgteurope56780.2023.10408184"
    },
    {
        "id": 8982,
        "title": "Evaluation of Improved K-Nearest Neighbors for Indoor Positioning System in Real Complex Buildings",
        "authors": "Seyed Ali Zibaei, Rahim Ali Abbaspour",
        "published": "2023-5-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icwr57742.2023.10139137"
    },
    {
        "id": 8983,
        "title": "Breast cancer prediction using K Nearest Neighbors, Support Vector Machine Techniques",
        "authors": "P. Visalatchi, V. Sasirekha",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "Breast cancer is the trickiest and sneakiest diseases that modern science is aware of. It is one of the most important causes of death for women worldwide. We introduce the SVM (Support Vector Machine) and KNN (K Nearest Neighbors), which are the machine learning algorithms for breast disease diagnosis by training its attributes, and we present an original prediction of breast cancer. The suggested system employs 10-fold cross validation to produce accurate results. The UCI machine learning warehouse was used to obtain the Wisconsin breast melanoma diagnosis data set. The accurateness, sensitiveness, specificity, false detection rate, false exclusion rate, and Matthews' correlation coefficient are used to evaluate the presentation of the suggested system.",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/tjjpt.v44.i4.1389"
    },
    {
        "id": 8984,
        "title": "On Out-of-Distribution Detection for Audio with Deep Nearest Neighbors",
        "authors": "Zaharah Bukhsh, Aaqib Saeed",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10094846"
    },
    {
        "id": 8985,
        "title": "Interval-Valued Data Based Local Mean K-Nearest Neighbors Classifier",
        "authors": "Chunyu Jiang, Dian Liu, Cheng Ma",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/auteee60196.2023.10407827"
    },
    {
        "id": 8986,
        "title": "TNN: A transfer learning classifier based on weighted nearest neighbors",
        "authors": "Haiyang Sheng, Guan Yu",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jmva.2022.105126"
    },
    {
        "id": 8987,
        "title": "Yes, we CANN: Constrained Approximate Nearest Neighbors for local feature-based visual localization",
        "authors": "Dror Aiger, André Araujo, Simon Lynen",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01227"
    },
    {
        "id": 8988,
        "title": "Vibration-based monitoring of agro-industrial machinery using a k-Nearest Neighbors (kNN) classifier with a Harmony Search (HS) frequency selector algorithm",
        "authors": "Francisco Javier Gomez-Gil, Víctor Martínez-Martínez, Ruben Ruiz-Gonzalez, Lidia Martínez-Martínez, Jaime Gomez-Gil",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compag.2023.108556"
    },
    {
        "id": 8989,
        "title": "Classification of Flood-Prone Areas Using 10-Fold Cross Validation and K-Nearest Neighbors",
        "authors": "Adyatma Andhika Bagaskara, Kristoko Dwi Hartomo",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32520/stmsi.v13i1.3637"
    },
    {
        "id": 8990,
        "title": "DETERMINANTS OF CONSUMER EGG PRICES IN TURKIYE USING K-NEAREST NEIGHBORS REGRESSION ANALYSIS",
        "authors": "",
        "published": "2024-4-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.36899/japs.2024.3.0742"
    },
    {
        "id": 8991,
        "title": "Perbandingan Algoritma Support Vector Machine dan K-Nearest Neighbors Pada  Sinyal Tubuh Perokok",
        "authors": "Alif Musthofa, Majid Rahardi",
        "published": "2023-12-30",
        "citations": 0,
        "abstract": "Merokok adalah kebiasaan yang sulit dihilangkan dalam masyarakat. Rokok mengandung bahan berbahaya dan bisa menyebabkan kanker serta penyakit pernapasan. Merokok juga meningkatkan risiko infeksi tuberkulosis. Perokok pasif yang terpapar asap rokok sangat berisiko bagi kesehatan. Penelitian ini bertujuan untuk melakukan evaluasi dan perbandingan antara algoritma Support Vector Machine (SVM) dan K-Nearest Neighbors (KNN) dalam klasifikasi sinyal tubuh perokok. Hasil evaluasi menunjukkan bahwa penggunaan SVM dengan kernel linear dan metode forward selection menghasilkan akurasi tertinggi sebesar 75%, yang melampaui akurasi tertinggi KNN sebesar 72%. Dari hasil tersebut penggunaan metode forward selection meningkatkan akurasi dibandingkan dengan penggunaan semuafitur yang tersedia, kecuali pada SVM dengan kernel RBF. Evaluasi pada penelitian ini menggunakan Confuntion Matrix dan Record klasifikasi. Adapun hasil kinerja model pada class “Tidak merokok” menggunakan SVM mendapatkan nilai presisi (84%), recall (75%), f-1 score(79%) dan KNN mendapatkan nilai presisi (75%), recall (83%), f-1 score(79%). Sedangkan pada class “Merokok” menggunakan SVM mendapatkan nilai presisi (64%), recall (75%), f-1 score(69%) dan KNN mendapatkan nilai presisi (64%), recall (53%), f-1 score(58%).",
        "keywords": "",
        "link": "http://dx.doi.org/10.33022/ijcs.v12i6.3290"
    },
    {
        "id": 8992,
        "title": "Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis",
        "authors": "Renrui Zhang, Liuhui Wang, Ziyu Guo, Jianbo Shi",
        "published": "2023-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00130"
    },
    {
        "id": 8993,
        "title": "High-Level K-Nearest Neighbors (HLKNN): A Supervised Machine Learning Model for Classification Analysis",
        "authors": "Elife Ozturk Kiyak, Bita Ghasemkhani, Derya Birant",
        "published": "2023-9-10",
        "citations": 1,
        "abstract": "The k-nearest neighbors (KNN) algorithm has been widely used for classification analysis in machine learning. However, it suffers from noise samples that reduce its classification ability and therefore prediction accuracy. This article introduces the high-level k-nearest neighbors (HLKNN) method, a new technique for enhancing the k-nearest neighbors algorithm, which can effectively address the noise problem and contribute to improving the classification performance of KNN. Instead of only considering k neighbors of a given query instance, it also takes into account the neighbors of these neighbors. Experiments were conducted on 32 well-known popular datasets. The results showed that the proposed HLKNN method outperformed the standard KNN method with average accuracy values of 81.01% and 79.76%, respectively. In addition, the experiments demonstrated the superiority of HLKNN over previous KNN variants in terms of the accuracy metric in various datasets.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12183828"
    },
    {
        "id": 8994,
        "title": "Enhancing the Ranking Context of Dense Retrieval through Reciprocal Nearest Neighbors",
        "authors": "George Zerveas, Navid Rekabsaz, Carsten Eickhoff",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.665"
    },
    {
        "id": 8995,
        "title": "ANALISA PERBANDINGAN KINERJA ALGORITMA C4.5 DAN ALGORITMA K-NEAREST NEIGHBORS UNTUK KLASIFIKASI PENERIMA BEASISWA",
        "authors": "Agung Purwanto, Handoyo Widi Nugroho",
        "published": "2023-1-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.33365/jti.v17i1.2370"
    },
    {
        "id": 8996,
        "title": "Study of the K-Nearest Neighbors Method with Various Features for Text Classification in Machine Learning",
        "authors": "Neli Kalcheva, Maya Todorova, Ivaylo Penev",
        "published": "2023-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icai58806.2023.10339061"
    },
    {
        "id": 8997,
        "title": "A Closer Look at k-Nearest Neighbors Grammatical Error Correction",
        "authors": "Justin Vasselli, Taro Watanabe",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.bea-1.19"
    },
    {
        "id": 8998,
        "title": "Predictive Modeling of Seismic Events: A Comparative Analysis Of K-Nearest Neighbors and Random Forest Algorithms",
        "authors": "Dayang Sun",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "This study processes and predicts seismic data using data visualization approaches, K-nearest neighbors (KNN) and the random forest (RF) algorithms. The analysis's dataset includes a number of variables connected to earthquakes.  The primary goal is to devise a forecast algorithm capable of accurately categorizing seismic events, data visualization tools are utilized to gain insights into the dataset, producing informative charts that depict the distribution and correlations among different variables. This visual evaluation aids in pinpointing anomalies or trends, facilitating a deeper understanding of the data's characteristics and guiding decisions during the modeling phase. Subsequently, the KNN method classifies earthquake occurrences based on their attributes, predicting the class label by considering the characteristics of its nearest neighbors. Additionally, Accurate classification of seismic events is enhanced by using RF, an ensemble learning technique that combines many decision trees to produce predictions. To optimize outcomes, the study adjusts the random forest model's hyperparameters through cross-validation. The study compares the performance of KNN and RF using a confusion matrix. The confusion matrix shows a thorough insight of categorization performance, which provides a comprehensive view of categorization efficacy. This assessment underscores the models' precision and effectiveness in classifying seismic events.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/cjyajb25"
    },
    {
        "id": 8999,
        "title": "KLASIFIKASI TINGKAT KOMPETENSI MAHASISWA UNISKA MENGGUNAKAN KOMBINASI ALGORITMA K-NEAREST NEIGHBORS (KNN) DAN MANHATTAN DISTANCE",
        "authors": "Andie Andie, Hasanuddin Hasanuddin",
        "published": "2023-1-14",
        "citations": 0,
        "abstract": "Kompetensi adalah kemampuan kerja setiap individu yang mencakup aspek pengetahuan, keterampilan, dan sikap kerja yang sesuai dengan standardisasi yang diharapkan. Pada dunia kerja, kompetensi dibutuhkan untuk mengetahui tipe pekerjaan seperti apa yang tepat bagi seseorang. Apabila kompetensi atas diri seorang karyawan telah diketahui maka perusahaan pun mampu membantu untuk mengembangkan pribadi melalui training atau pelatihan tertentu. Dataset pada penelitian ini diambil dari mahasiswa uniska yang akan mempersiapkan diri ke dunia kerja . Salah satu cara untuk mengklasifikasi tingkat kompetesi mahasiswa dalam machine learning yaitu menggunakan dataset sebagai data latih agar dapat dilakukan pengujian performa dengan metode klasifikasi yang tepat. Metode yang digunakan dalam penelitian ini yaitu algoritma K-Nearest Neighbor (KNN), dimana merupakan sebuah metode untuk melakukan klasifikasi terhadap objek berdasarkan data pembelajaran yang jaraknya paling dekat dengan objek tersebut. Dari hasil pengujian yang telah dilakuan dapat disimpulkan bahwa penerapan metode K-NN dengan Manhattan Distance diperoleh hasil akurasi tertinggi dengan nilai sebesar 94%, dengan k=5. Persentase tersebut menunjukkan bahwa Manhattan Distance bekerja dengan baik dalam memberikan rekomendasi untuk klasifikasi kompetensi mahasiswa.",
        "keywords": "",
        "link": "http://dx.doi.org/10.31602/tji.v14i1.8001"
    },
    {
        "id": 9000,
        "title": "Enhancing Recommender Systems through Hybrid Fusion of SVD/SVD++ and k-Nearest Neighbors",
        "authors": "Nabil Azri, Adil Haddi, Abdelghani Azri",
        "published": "2023-11-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sita60746.2023.10373705"
    },
    {
        "id": 9001,
        "title": "Sentimen Analysis Pada Penggunaan System Kecerdasan Buatan di Twitter Menggunakan K-Nearest Neighbors",
        "authors": "Andi Subasar",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "Studi sentiment analysis saat ini mempunyai peran pada sebuah studi dengan tugas mengklasifikasikan atau mengelompokkan polaritas dari sebuah teks dapat berupa dokumen, kalimat, atau pun opini masyarakat. Polaritas ini sendiri harus mempunyai makna dimana pada sebuat teks dokumen, kalimat atau opini yang memiliki nilai makna positif atau negative. tujuan penelitian ini adalah untuk mendapatkan tingkat polaritas positif dan negative opinin masyarakat tentang bagaimana tingkat penggunaan aplikasi Artificial Intelegent yang telah tersebar saat ini. Berdasarkan hasil analisis sentiment yang telah dilakukan menggunakan metode K-Nearest Neighbors, menggunakan dataset yang telah dikumpul-kan pada Kaggle secara public, maka dapat disimpulkan tingkat nilai polari-tas positif yaitu dengan tingkat akurasi 61%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54650/jusibi.v5i2.509"
    },
    {
        "id": 9002,
        "title": "Training-Time Attacks against K-nearest Neighbors",
        "authors": "Ara Vartanian, Will Rosenbaum, Scott Alfeld",
        "published": "2023-6-26",
        "citations": 0,
        "abstract": "Nearest neighbor-based methods are commonly used for classification tasks and as subroutines of other data-analysis methods. \nAn attacker with the capability of inserting their own data points into the training set can manipulate the inferred nearest neighbor structure.\nWe distill this goal to the task of performing a training-set data insertion attack against k-Nearest Neighbor classification (kNN).\nWe prove that computing an optimal training-time (a.k.a. poisoning) attack against kNN classification is NP-Hard, even when k = 1 and the attacker can insert only a single data point.\nWe provide an anytime algorithm to perform such an attack, and a greedy algorithm for general k and attacker budget.\nWe provide theoretical bounds and empirically demonstrate the effectiveness and practicality of our methods on synthetic and real-world datasets.\nEmpirically, we find that kNN is vulnerable in practice and that dimensionality reduction is an effective defense.\nWe conclude with a discussion of open problems illuminated by our analysis.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1609/aaai.v37i8.26198"
    },
    {
        "id": 9003,
        "title": "Classical and fast parameters tuning in nearest neighbors with stop condition",
        "authors": "Samya Tajmouati, Bouazza El Wahbi, Mohamed Dakkon",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s12597-023-00650-3"
    },
    {
        "id": 9004,
        "title": "Comparing Time Series Nearest Neighbors and Artificial Neural Networks for Hyper Spectral Image Analysis",
        "authors": "Deepak Mehta, Vaishali Singh, Neeraj Sharma",
        "published": "2024-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icocwc60930.2024.10470781"
    },
    {
        "id": 9005,
        "title": "Perbandingan Kinerja K-Nearest Neighbors  dan Naive Bayes Untuk Klasifikasi Perilaku Nasabah Pada Pembayaran Kredit Bank",
        "authors": "Anang Susilo",
        "published": "2023-11-22",
        "citations": 0,
        "abstract": ":Credit customers are people who use banking services or other financial services. to use bank money in its business activities, so it expects that the bank's credit can meet business capital needs. To reach information to increase profits and reduce company losses, we need a method that can provide knowledge to support the company's data. Research data can be obtained from processing classification data from credit customer data that are categorized as potential or not potential in the next credit grant. Data processing can be done using machine learning, namely classification techniques. This technique will produce a predictive churn model to determine which customer categories belong to a group. potential smooth or jammed. The Naive Bayes method was chosen because it can produce maximum accuracy with little training data. Meanwhile, the K-Nearest Neighbor method was chosen because it is robust against noise data. The performance of the two methods will be compared, so that it can be seen which method is better in classifying documents. The results obtained show that the Naive Bayes method has better performance with an accuracy rate of 70%, while the K-Nearest Neighbor method has a fairly low accuracy rate of 40%. Thus, it can be seen the accuracy value displayed by applying the classification algorithm. K-Nears Neighbors and Naïve Bayes. Parameter category. which in this study are account numbers, names of debtors, collectibility in the categories: current, DPK (on special mention), substandard, doubtful, loss. Then clarified with a description of the type of loan, collectability of ADK (computer data archive), type of business.\r\n ",
        "keywords": "",
        "link": "http://dx.doi.org/10.47233/jsit.v3i3.1264"
    },
    {
        "id": 9006,
        "title": "K-NN’S NEAREST NEIGHBORS METHOD FOR CLASSIFYING TEXT DOCUMENTS BY THEIR TOPICS",
        "authors": "N. I. Boyko, V. Yu. Mykhailyshyn",
        "published": "2023-10-13",
        "citations": 0,
        "abstract": "Context. Optimization of the method of nearest neighbors k-NN for the classification of text documents by their topics and experimentally solving the problem based on the method.\r\nObjective. The study aims to study the method of nearest neighbors k-NN for classifying text documents by their topics. The task of the study is to classify text documents by their topics based on a dataset for the optimal time and with high accuracy.\r\nMethod. The k-nearest neighbors (k-NN) method is a metric algorithm for automatic object classification or regression. The k-NN algorithm stores all existing data and categorizes the new point based on the distance between the new point and all points in the training set. For this, a certain distance metric, such as Euclidean distance, is used. In the learning process, k-NN stores all the data from the training set, so it belongs to the “lazy” algorithms since learning takes place at the time of classification. The algorithm makes no assumptions about the distribution of data and it is nonparametric. The task of the k-NN algorithm is to assign a certain category to the test document x based on the categories k of the nearest neighbors from the training dataset. The similarity between the test document x and each of the closest neighbors is scored by the category to which the neighbor belongs. If several of k’s closest neighbors belong to the same category, then the similarity score of that category for the test document x is calculated as the sum of the category scores for each of these closest neighbors. After that, the categories are ranked by score, and the test document is assigned to the category with the highest score.\r\nResults. The k-NN method for classifying text documents has been successfully implemented. Experiments have been conducted with various methods that affect the efficiency of k-NN, such as the choice of algorithm and metrics. The results of the experiments showed that the use of certain methods can improve the accuracy of classification and the efficiency of the model.\r\nConclusions. Displaying the results on different metrics and algorithms showed that choosing a particular algorithm and metric can have a significant impact on the accuracy of predictions. The application of the ball tree algorithm, as well as the use of different metrics, such as Manhattan or Euclidean distance, can lead to improved results. Using clustering before applying k-NN has been shown to have a positive effect on results and allows for better grouping of data and reduces the impact of noise or misclassified points, which leads to improved accuracy and class distribution.",
        "keywords": "",
        "link": "http://dx.doi.org/10.15588/1607-3274-2023-3-9"
    },
    {
        "id": 9007,
        "title": "Detection of malaria parasites from blood images using random forest algorithm in comparison with k-nearest neighbors to maximize the accuracy, precision and sensitivity",
        "authors": "Y. Poorna Chandra, N. P. G. Bhavani",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0186141"
    },
    {
        "id": 9008,
        "title": "Hybrid Genetic Algorithm With k-Nearest Neighbors for Radial Distribution Network Reconfiguration",
        "authors": "Seungchan Jo, Jae-Young Oh, Jaeho Lee, Seokhwa Oh, Hee Seung Moon, Chen Zhang, Rajit Gadh, Yong Tae Yoon",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tsg.2023.3324328"
    },
    {
        "id": 9009,
        "title": "COMPARISON OF SMOTE RANDOM FOREST AND SMOTE K-NEAREST NEIGHBORS CLASSIFICATION ANALYSIS ON IMBALANCED DATA",
        "authors": "Jus Prasetya, Abdurakhman Abdurakhman",
        "published": "2023-4-6",
        "citations": 0,
        "abstract": "In machine learning study, classification analysis aims to minimize misclassification and also maximize the results of prediction accuracy. The main characteristic of this classification problem is that there is one class that significantly exceeds the number of samples of other classes. SMOTE minority class data is studied and extrapolated so that it can produce new synthetic samples. Random forest is a classification method consisting of a combination of mutually independent classification trees. K-Nearest Neighbors which is a classification method that labels the new sample based on the nearest neighbors of the new sample. SMOTE generates synthesis data in the minority class, namely class 1 (cervical cancer) to 585 observation respondents (samples) so that the total observation respondents are 1208 samples. SMOTE random forest resulted an accuracy of 96.28%, sensitivity 99.17%, specificity 93.44%, precision 93.70%, and AUC 96.30%. SMOTE K-Nearest Neighborss resulted an accuracy of 87.60%, sensitivity 77.50%, specificity 97.54%, precision 96.88%, and AUC 82.27%. SMOTE random forest produces a perfect classification model, SMOTE K-Nearest neighbors classification produces a good classification model, while the random forest and K-Nearest neighbors classification on imbalanced data results a failed classification model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.14710/medstat.15.2.198-208"
    },
    {
        "id": 9010,
        "title": "Forecasting Earnings Using k-Nearest Neighbors",
        "authors": "Peter D. Easton, Martin M. Kapons, Steven J. Monahan, Harm H. Schütt, Eric H. Weisbrod",
        "published": "2023-11-1",
        "citations": 1,
        "abstract": "ABSTRACT\nWe use a simple k-nearest neighbors algorithm (hereafter, k-NN*) to forecast earnings. k-NN* forecasts of one-, two-, and three-year-ahead earnings are more accurate than those generated by popular extant forecasting approaches. k-NN* forecasts of two- and three-year (one-year)-ahead EPS and aggregate three-year EPS are more (less) accurate than those generated by analysts. The association between the unexpected earnings implied by k-NN* and the contemporaneous market-adjusted return (i.e., the earnings association coefficient (EAC)) is positive and exceeds the EAC on unexpected earnings implied by alternate approaches. A trading strategy that is long (short) firms for which k-NN* predicts positive (negative) earnings growth earns positive risk-adjusted returns that exceed those earned by similar trading strategies that are based on alternate forecasts. The k-NN* algorithm generates an empirically reliable ex ante indicator of forecast accuracy that identifies situations when the k-NN* EAC is larger and the k-NN* trading strategy is more profitable.\nData Availability: Data are available from the public sources described in the text.\nJEL Classifications: C21; C53; G17; M41.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2308/tar-2021-0478"
    },
    {
        "id": 9011,
        "title": "A new improved clustering method of incomplete data based on K-nearest neighbors",
        "authors": "Teqi Hao, Qing Shi, Zipeng Sun",
        "published": "2023-1-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icpeca56706.2023.10076121"
    },
    {
        "id": 9012,
        "title": "PERBANDINGAN METODE ALGORITMA NAÏVE BAYES DAN K-NEAREST NEIGHBORS UNTUK KLASIFIKASI PENYAKIT STROKE",
        "authors": "Khairul Akmal, Ahmad Faqih, Fatihanursari Dikananda",
        "published": "2023-3-14",
        "citations": 0,
        "abstract": "Stroke selaku serupa penyakit yang meninggali strata ketiga di Indonesia sesudah jantung serta kanker. Kerapkali setiap individu bermalas-malasan dalam mendapati terdapatnya penyakit stroke. Minimnya kekuatan kedokteran di Indonesia membikin rakyat sukar guna mengetahui dengan cara dini penyakit stroke. Stroke yaitu sesuatu sindrom klinis yang diisyarati dengan tandasnya peranan otak dengan cara berat yang bisa mengakibatkan kematian. Tujuan riset ini guna pengelompokan hasil kira-kira penyakit stroke dengan pendekatan algoritma Naïve Bayes serta K-Nearest Neighbors menurut kriteria-kriteria dalam penyakit stroke antara lain kategori genitalia, umur pesakit, darah tinggi, riwayat sakit jantung, sempat menikah, kategori profesi, kategori tempat bermukim, kandungan gula darah, BMI, status merokok. Statistik yang dibubuhkan dalam riset ini ialah Stroke Prediction Dataset yang diperoleh pada repositori Kaggle yang yaitu salah satu yang populer di negeri Data Science serta Machine Learning. Kali ini perubahan masa revolusi industri 4.0 yang bergerak selaras di segi teknologi serta ilmu kesehatan akibatnya selaku suatu yang bisa berharga dengan mengenakan Machine Learning. Banyak sekali faedah yang dibubuhkan dalam menduga sebagian penyakit yang bisa di proyeksi. Eksklusifnya penyakit stroke dengan mengenakan tilikan algoritma Naïve Bayes serta K-Nearest Neighbors guna tiap-tiap elastis nya. Implementasi cara ini mengenakan Cross Validation adalah data training serta data testing dibikin kuota dalam melaksanakan pengetesan. Pemanfaatan algoritma Naïve Bayes serta K-Nearest Neighbors bisa di terapkan selaku materi evaluasi guna membikin sistem pandai yang dibubuhkan oleh para pakar kesehatan guna pengumpulan ketetapan yang bagus di segi ke penjagaan serta medis dalam memacu hasil pemeriksaan pesakit stroke. Hasil ketelitian yang didapat dengan mengenakan algoritma K-Nearest Neighbors sebesar 94,36% hasil pengelompokan bisa dibubuhkan guna menolong dokter dalam pemeriksaan penyakit stroke.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36040/jati.v7i1.6367"
    },
    {
        "id": 9013,
        "title": "KLASIFIKASI TINGKAT PENJUALAN VIDEO GAME DENGAN MENGGUNAKAN METODE K – NEAREST NEIGHBORS",
        "authors": "Nadhif Nurul Fajri Adzani, Wina Witanti, Fajri Rakhmat Umbara",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "Klasifikasi Tingkat Penjualan Video Game Dengan Menggunakan Metode K – Nearest Neighbors memiliki fungsi untuk mengklasifikasikan video game berdasarkan penjualannya, dan memerlukan variabel, seperti genre, platform, publisher, best seller. Permasalahan yang terjadi di Platform penjualan game seperti di Steam, Epic games, etc. Adalah dimana saat gamers membeli game tersebut dan ternyata game tersebut tidak sesuai dengan ekspetasi dari gamers yang membeli game tersebut alhasil game tidak lagi dimainkan. Oleh karena itu, solusi yang dibuat disini yaitu klasifikasi video game berdasarkan karakteristik yang menggunakan metode KNN, dimana nantinya video game akan dibagi berdasarkan karakteristiknya, dan akan ditampilkan beberapa game sesuai klasifikasi karakternya, sehingga diharapkan dapat meminimalisir kejadian pembeli game / gamers yang menyesal karena tidak sesuai dengan ekspetasi mereka",
        "keywords": "",
        "link": "http://dx.doi.org/10.31949/infotech.v9i2.7371"
    },
    {
        "id": 9014,
        "title": "Analisis Komparasi Algoritma Data Mining Naive Bayes, K-Nearest Neighbors dan Regresi Linier Dalam  Prediksi Harga Emas",
        "authors": "Muhammad Muharrom",
        "published": "2023-12-24",
        "citations": 0,
        "abstract": "The results of implementing Orange Data Mining for forecasting the value of the Gold Price are displayed on the Test and Score widget. RMSE and MAE values were obtained from each model from the test. The RMSE and MAE values for the K-Nearest Neighbor (K-NN) method are 0.007 and 0.006, respectively, while for the Support Vector Machine (SVM) method are 0.006 and 0.005. The RMSE and MAE values for the Linear Regression method are 0.004 and 0.003, respectively. Compared to the K-Nearest Neighbor and SVM methods, the Linear Regression method is the best at predicting changes in Gold prices based on the RMSE and MAE data mentioned above. For future research, this best practice method needs to be studied more deeply. It is recommended for future research to compare the Linear Regression method with alternative approaches using the Orange tool set or other related tools.",
        "keywords": "",
        "link": "http://dx.doi.org/10.47065/bit.v4i4.986"
    },
    {
        "id": 9015,
        "title": "Flexible K Nearest Neighbors Classifier: Derivation and Application for Ion-mobility Spectrometry-based Indoor Localization",
        "authors": "Philipp Müller",
        "published": "2023-9-25",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ipin57070.2023.10332541"
    },
    {
        "id": 9016,
        "title": "Development of Optimal k-Nearest Neighbors (KNN) Model to Predict Demolition Waste Generation in Redevelopment Area",
        "authors": "Gi-Wook Cha, Won-Hwa Hong",
        "published": "2023-2-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21086/ksles.2023.2.30.1.20"
    },
    {
        "id": 9017,
        "title": "CLASSIFICATION OF THE GEOCHEMICAL COMPOSITION OF METEORITE OF PUNGGUR (ASTOMULYO) BY k-NEAREST NEIGHBOR ALGORITHM",
        "authors": "Triyana Muliawati",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "The fall of a meteorite in Astomulyo Village, Punggur, Lampung Province in early 2021 is an interesting topic for further study. This rare object has been suggested to have a unique geochemical composition and a special connection with other meteorites. We aimed to trace its classification by comparing it with other well-known meteorites studied previously. We approach the classification process using the k-nearest neighbor algorithm. The database used 211 represents the geochemical data for each known meteorite group from chemical analyses of meteorites. As a result, we identified that with a k-value = 5 and the proportion of test data 5/95 (in %), the geochemical composition of this meteorite is relatively close to that of the H-type chondrite group with a value accuracy of 91.67%. These results are consistent with the fact that the meteorite of Punggur has a high total iron and metallic composition.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30598/variancevol5iss2page185-192"
    },
    {
        "id": 9018,
        "title": "INCORPORATING DENSITY IN K-NEAREST NEIGHBORS REGRESSION",
        "authors": "Mohamed A. Mahfouz,  ",
        "published": "2023-6-20",
        "citations": 0,
        "abstract": "The application of the traditional k-nearest neighbours in regression analysis suffers from several difficulties when only a limited number of samples are available.  In this paper, two decision models based on density are proposed. In order to reduce testing time, a k-nearest neighbours table (kNN-Table) is maintained to keep the neighbours of each object x along with their weighted Manhattan distance to x and a binary vector representing the increase or the decrease in each dimension compared to x’s values. In the first decision model, if the unseen sample having a distance to one of its neighbours x less than the farthest neighbour of x’s neighbour then its label is estimated using linear interpolation otherwise linear extrapolation is used. In the second decision model, for each neighbour x of the unseen sample, the distance of the unseen sample to x and the binary vector are computed. Also, the set S of nearest neighbours of x are identified from the kNN-Table. For each sample in S, a normalized distance to the unseen sample is computed using the information stored in the kNN-Table and it is used to compute the weight of each neighbor of the neighbors of the unseen object. In the two models, a weighted average of the computed label for each neighbour is assigned to the unseen object. The diversity between the two proposed decision models and the traditional kNN regressor motivates us to develop an ensemble of the two proposed models along with traditional kNN regressor. The ensemble is evaluated and the results showed that the ensemble achieves significant increase in the performance compared to its base regressors and several related algorithms.",
        "keywords": "",
        "link": "http://dx.doi.org/10.26483/ijarcs.v14i3.6989"
    },
    {
        "id": 9019,
        "title": "Application of Linear Discriminant Analysis and k-Nearest Neighbors Techniques to Recommendation Systems",
        "authors": "Javier Bilbao, Imanol Bilbao",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "Among the different techniques of Machine Learning, we have selected various of them, such as SVM, CART, MLP, kNN, etc. to predict the score of a particular wine and give a recommendation to a user. In this paper, we present the results from the LDA and kNN techniques, applied to data of Rioja red wines, specifically with Rioja Qualified Denomination of Origin. Principal Component Analysis has been used previously to create a new and smaller set of data, with a smaller number of characteristics to manage, contrast, and interpret these data more easily. From the results of both classifiers, LDA and kNN, we can conclude that they can be useful in the recommendation system.",
        "keywords": "",
        "link": "http://dx.doi.org/10.37394/23209.2024.21.16"
    },
    {
        "id": 9020,
        "title": "Density peaks clustering based on shared nearest neighbors and dense degree",
        "authors": "Xue Zhang, Jianhua Qu",
        "published": "2023-4-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsp58490.2023.10248587"
    },
    {
        "id": 9021,
        "title": "Comparison of Random Forest with K-Nearest Neighbors to Detect Fake News with Improved Accuracy",
        "authors": "K. S. Sri Saranya, A. Hency Juliet",
        "published": "2023-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ic3i59117.2023.10397893"
    },
    {
        "id": 9022,
        "title": "NFT Coin Price Prediction (non-fungible token)using K-Nearest Neighbors Method",
        "authors": "Adena Wahyu Gumelar, Tacbir Hendro Pudjiantoro, Puspita Nurul Sabrina",
        "published": "2023-3-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.46254/an13.20230382"
    },
    {
        "id": 9023,
        "title": "Exhaled Breath Analysis Based Diabetes Detection with k-Nearest Neighbors Classifier",
        "authors": "Piotr J Smieja, Jiang Lu, Qingquan Sun, Xingang Fu, Ting Zhang",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iscid59865.2023.00037"
    },
    {
        "id": 9024,
        "title": "Self-Paced Self-Training Based on K-Nearest Neighbors",
        "authors": "Yongzheng Ma, Zhengkai Sun, Yintong Zhang, Hongjiao Guan, Xinxiao Qiao",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3650215.3650235"
    },
    {
        "id": 9025,
        "title": "Optimum k-Nearest Neighbors for Heading Synchronization on a Swarm of UAVs under a Time-Evolving Communication Network",
        "authors": "Rigoberto Martínez-Clark, Javier Pliego-Jimenez, Juan Francisco Flores-Resendiz, David Avilés-Velázquez",
        "published": "2023-5-26",
        "citations": 3,
        "abstract": "Heading synchronization is fundamental in flocking behaviors. If a swarm of unmanned aerial vehicles (UAVs) can exhibit this behavior, the group can establish a common navigation route. Inspired by flocks in nature, the k-nearest neighbors algorithm modifies the behavior of a group member based on the k closest teammates. This algorithm produces a time-evolving communication network, due to the continuous displacement of the drones. Nevertheless, this is a computationally expensive algorithm, especially for large groups. This paper contains a statistical analysis to determine an optimal neighborhood size for a swarm of up to 100 UAVs, that seeks heading synchronization using a simple P-like control algorithm, in order to reduce the calculations on every UAV, this is especially important if it is intended to be implemented in drones with limited capabilities, as in swarm robotics. Based on the literature of bird flocks, that establishes that the neighborhood of every bird is fixed around seven teammates, two approaches are treated in this work: (i) the analysis of the optimum percentage of neighbors from a 100-UAV swarm, that is necessary to achieve heading synchronization, and (ii) the analysis to determine if the problem is solved in swarms of different sizes, up to 100 UAVs, while maintaining seven nearest neighbors among the members of the group. Simulation results and a statistical analysis, support the idea that the simple control algorithm behaves like a flock of starlings.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/e25060853"
    },
    {
        "id": 9026,
        "title": "Implementation Of Modified K-Nearest Neighbor Algorithm In Electronic Nose System To Detect Gastroesophageal Reflux Disease",
        "authors": "Ade Moehammad Fajrin, Muhammad Niswar, Ady Wahyudi Paundu",
        "published": "2023-7-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isitia59021.2023.10221113"
    },
    {
        "id": 9027,
        "title": "Analisis Sentimen Terhadap Aplikasi Canva Menggunakan Algoritma Naive Bayes Dan K-Nearest Neighbors",
        "authors": "Dany Pratmanto, Fabriyan Fandi Dwi Imaniawan",
        "published": "2023-7-28",
        "citations": 0,
        "abstract": "The sentiment analysis used in the Canva application involves collecting user reviews or feedback. Then, a sentiment analysis algorithm is applied to classify the reviews as positive or negative. Sentiment analysis can help the company understand user opinions about the Canva application and how the application can meet user needs. The process of sentiment analysis in the Canva application involves collecting user reviews or feedback, which are then classified using a sentiment analysis algorithm. The research results show that the KNN algorithm has an accuracy rate of 83.92%, while Naive Bayes only has an accuracy rate of 77.41%. The KNN algorithm also has higher recall and precision values than Naive Bayes, namely 83.66% and 84.49%, respectively. In addition, the AUC value generated by the KNN algorithm is also higher than Naive Bayes, namely 95.00% compared to 94.50%. Therefore, it can be concluded that the KNN algorithm is more suitable for data classification in this research. This research can contribute to the development of the Canva application and improve the quality of service for its users.",
        "keywords": "",
        "link": "http://dx.doi.org/10.31294/coscience.v3i2.1917"
    },
    {
        "id": 9028,
        "title": "Analisis Sentimen Sepak Bola Indonesia pada Twitter menggunakan K-Nearest Neighbors dan Random Forest",
        "authors": "Dedy Agung Prabowo,  Sudianto",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "Twitter merupakan salah satu media sosial yang paling banyak digunakan saat ini. Twitter memungkinkan pengguna untuk memberikan berita dan komentar terbaru tentang peristiwa yang sedang berlangsung di Dunia. Di Indonesia, laga final piala AFF Suzuki Cup 2020 menjadi perbincangan hangat karena untuk keenam kalinya Indonesia menjadi runner-up setelah tahun 2000, 2002, 2004, 2010, dan 2016 penampilan Timnas Indonesia. Dengan banyaknya opini dan kritik yang beredar, membedakan opini positif dan negatif membutuhkan waktu yang lama. Oleh karena itu, diperlukan suatu model analisis sentimen yang dapat mengklasifikasikan opini positif dan negatif sebagai bahan evaluasi bagi Timnas Indonesia di masa yang akan datang. Pada penelitian ini, klasifikasi analisis sentimen menggunakan metode algoritme K-Nearest Neighbors dan Random Forest. Data yang digunakan berasal dari balasan kicauan akun Twitter Joko Widodo terkait ucapan selamat kepada Timnas Indonesia usai bertanding melawan Thailand di AFF Suzuki Cup 2020. Berdasarkan hasil pengujian, akurasi algoritme K-Nearest Neighbors 75% lebih baik daripada algoritme Random Forest dengan akurasi 71%",
        "keywords": "",
        "link": "http://dx.doi.org/10.36085/jsai.v6i2.5337"
    },
    {
        "id": 9029,
        "title": "Aplikasi Berbasis Website Untuk Mendeteksi Status Gizi Balita Menggunakan Metode K-Nearest Neighbors (KNN)",
        "authors": "Alven Safik Ritonga, Isnaini Muhandhis",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "Mendeteksi status gizi balita merupakan suatu hal yang penting dalam upaya pemantauan dan perawatan kesehatan balita. Dalam penelitian ini, kami mengusulkan penggunaan metode K-Nearest Neighbors (KNN) untuk mendeteksi status gizi balita berdasarkan atribut yang relevan seperti berat badan, tinggi badan, usia, jenis kelamin, dan asupan nutrisi. Penelitian ini melibatkan pengembangan sebuah aplikasi berbasis komputer yang menggunakan algoritma KNN untuk melakukan klasifikasi status gizi balita. Data balita yang telah dikumpulkan dari sumber yang sah digunakan untuk melatih model KNN. Setelah pelatihan, model ini dapat memprediksi status gizi balita baru berdasarkan atribut yang dimasukkan. Dalam eksperimen kami, kami menguji dan mengevaluasi performa model KNN dengan menggunakan metrik evaluasi seperti akurasi, presisi, recall, dan F1-score. Dalam aplikasi praktis, model KNN dapat digunakan sebagai alat bantu dalam menentukan status gizi balita dan memberikan rekomendasi tindakan yang tepat, seperti peningkatan asupan nutrisi atau perawatan medis yang diperlukan. Penelitian ini memberikan kontribusi dalam bidang pemantauan dan perawatan gizi balita dengan menggabungkan metode KNN sebagai alat deteksi status gizi. Aplikasi yang dikembangkan dapat membantu para tenaga medis dan orang tua dalam memantau dan mengambil tindakan yang tepat terkait dengan gizi balita. Aplikasi yang sudah dibangun dalam bentuk website, dapat membantu untuk mendeteksi status gizi balita. Pada penerapan metode K-NN pada data status gizi balita, diperoleh keberhasilan aplikasi dalam mendeteksi status gizi balita dengan keakurasian 74.73%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.61628/jsce.v5i1.1081"
    },
    {
        "id": 9030,
        "title": "K-Nearest Neighbors Method for Recommendation System in Bangkalan’s Tourism",
        "authors": "Devie Rosa Anamisa, Achmad Jauhari, Fifin Ayu Mufarroha",
        "published": "2023-5-8",
        "citations": 2,
        "abstract": "The more tourist objects are in an area, the more challenging it is for local governments to increase the selling value of these attractions. The government always strives to develop tourist attraction areas by prioritizing the beauty of tourist attractions. However, visitors often have difficulty in determining tourist objects that match their criteria because of the many choices. The research developed a tourist attraction recommendation system for visitors by applying machine learning techniques. The machine learning technique used was the K-Nearest Neighbor (KNN) method. Several trials were conducted with a dataset of 315 records, consisting of 11 attributes and 21 tourist attractions. Based on the dataset, the preprocessing stage was previously carried out to improve the data format by selecting data where the data were separated based on existing criteria, then calculating the closest distance and determining the value of k in the KNN method. The results are divided into five folds for each classification method. The highest system accuracy obtained at KNN is 78% at k=1. It shows that the KNN method can provide recommendations for three tourist attraction classes in Bangkalan. Applying the KNN method in the recommendation system determines several alternative tourist objects that tourists can visit according to their criteria in natural, cultural, and religious tourist objects.",
        "keywords": "",
        "link": "http://dx.doi.org/10.21512/comtech.v14i1.7993"
    },
    {
        "id": 9031,
        "title": "Expanding Reverse Nearest Neighbors",
        "authors": "Wentao Li, Maolin Cai, Min Gao, Dong Wen, Lu Qin, Wei Wang",
        "published": "2023-12",
        "citations": 0,
        "abstract": "\n            In a graph, the reverse nearest neighbors (RNN) of vertex\n            f\n            refer to the set of vertices that consider\n            f\n            as their nearest neighbor. When\n            f\n            represents a facility like a subway station, its RNN comprises potential users who prefer the nearest facility. In practice, there may be\n            underutilized\n            facilities with small RNN sizes, and relocating these facilities to expand their service can be costly or infeasible. A more cost-effective approach involves selectively upgrading some edges (e.g., reducing their weights) to expand the RNN sizes of underutilized facilities. This motivates our research on the\n            Expanding Reverse Nearest Neighbors\n            (ERNN) problem, which aims to maximize the RNN size of a target facility by upgrading a limited number of edges. Solving the ERNN problem allows underutilized facilities to serve more users and alleviate the burden on other facilities. Despite numerous potential applications, ERNN is hard to solve: It can be proven to be NP-hard and APX-hard, and it exhibits non-monotonic and non-submodular properties. To overcome these challenges, we propose novel greedy algorithms that improve efficiency by minimizing the number of edges that need to be processed and the cost of processing each edge. Experimental results demonstrate that the proposed algorithms achieve orders of magnitude speedup compared to the standard greedy algorithm while greatly expanding the RNN.\n          ",
        "keywords": "",
        "link": "http://dx.doi.org/10.14778/3636218.3636220"
    },
    {
        "id": 9032,
        "title": "Exploring collaborative filtering through K-Nearest Neighbors and Non-Negative Matrix Factorization",
        "authors": "Sagedur Raman",
        "published": "2024-4-15",
        "citations": 0,
        "abstract": "Collaborative filtering (CF) algorithms have received a lot of interest in recommender systems due to their ability to give personalized recommendations by exploiting user-item interaction data. In this article, we explore two popular CF methods—K-Nearest Neighbors (KNN) Regression and Non-Negative Matrix Factorization (NMF)—in detail as we dig into the world of collaborative filtering. Our goal is to evaluate their performance on the MovieLens 1M dataset and offer information about their advantages and disadvantages. A thorough explanation of the significance of recommender systems in contemporary content consumption settings is given at the outset of our examination. We look into Collaborative Filtering's complexities and how it uses user choices to produce tailored recommendations. Then, after setting the scene, we explain the KNN Regression and NMF approaches, going over their guiding principles and how they apply to recommendation systems. We conduct an extensive investigation of KNN Regression and NMF on the MovieLens 1M dataset to provide a thorough evaluation. We describe the model training processes, performance measures, and data pre-processing steps used. We measure and analyse the predicted accuracy of these strategies using empirical studies, revealing light on their effectiveness when applied to various user preferences and content categories.",
        "keywords": "",
        "link": "http://dx.doi.org/10.47813/2782-2818-2024-4-2-0201-0211"
    },
    {
        "id": 9033,
        "title": "Lung Cancer Stage Classification Utilizing k-Nearest Neighbors (k-NN) and Convolutional Neural Networks (CNN)",
        "authors": "Venna Venkata Reddy, Pokuri Venkata Pavan Kumar, Koneru Suvarna Vani",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/incoft60753.2023.10425683"
    },
    {
        "id": 9034,
        "title": "COMPARATIVE PERFORMANCE ANALYSIS BETWEEN K-NEAREST NEIGHBORS AND FEED-FORWARD NEURAL NETWORKS IN CLASSIFYING DIMENSIONALITYREDUCED IMAGE DATA OF HAND-WRITTEN DIGITS.",
        "authors": "Krish S. Kamath",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "Image classication is an essential tool used across various industries in our technologically enabled world. The process utilises the power of\nmachine learning algorithms to transform industries and solve complex real-world problems. In machine learning, how does a streamlined and\nstraightforward algorithm like the k-Nearest Neighbors algorithm perform, compared to a more intricate Backpropagation multilayer neural\nnetwork like Feedforward Neural Network, especially in the case of image classication? This research aims to examine this comparative\nperformance analysis, illuminating the intriguing complexities and efciencies inherent in these contrasting approaches. Drawing from Yuchun\nLee's 1991 ndings, which revealed that both the backpropagation algorithm and the k-nearest neighbours algorithm had closely matched error\nrates of approximately 5.14% and 5.15%, respectively, on regular, non-dimensionally reduced data, this study hypothesises that a backpropagation\nalgorithm, like the FeedForward Neural Network, and K-Nearest Neighbors might demonstrate comparable performance on such data. To perform\nthis experimental analysis, however, various mediums are used. Python and essential libraries, including numpy, matplotlib, sklearn, and keras, are\nused to evaluate the research hypothesis. The experiment employs a Backpropagation Neural Network and K-Nearest Neighbors model, trained\nand tested on dimensionally reduced data. keras is employed for data acquisition, sklearn for creating the two separate models, and matplotlib for\ndata and result visualization. This approach facilitates acquiring a more nuanced comparison of the two models' performance under varying data\nconditions. This research reveals distinctive/similar performance characteristics of both Backpropagation Neural Networks and K-Nearest\nNeighbors models when processing dimensionally reduced image data. The results are essential, for it enhances our comprehension of these\nmodels' behaviour in this particular context, thus providing a foundation for informed decisions in subsequent research and practical applications in\nimage classication.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36106/ijsr/9722495"
    },
    {
        "id": 9035,
        "title": "RecBERT: Semantic Recommendation Engine with Large Language Model Enhanced Query Segmentation for k-Nearest Neighbors Ranking Retrieval",
        "authors": "Richard Wu",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/icn.2024.0004"
    },
    {
        "id": 9036,
        "title": "Research on the Public’s Support for Emergency Infrastructure Projects Based on K-Nearest Neighbors Machine Learning Algorithm",
        "authors": "Caiyun Cui, Huan Cao, Qianwen Shao, Tingyu Xie, Yaming Li",
        "published": "2023-9-30",
        "citations": 0,
        "abstract": "The public’s support for emergency infrastructure projects, which will affect the government’s credibility, social stability, and development, is very important. However, there are few systematic research findings on public support for emergency infrastructure projects. In order to explore the factors influencing the public’s support and the degree of influence of each factor on the public’s support, this paper employs K-Nearest Neighbors (KNN), a learning curve with m-fold cross-validation, grid search, and random forest to study the public’s support for emergency infrastructure projects and its influencing factors. In this paper, a prediction model of the public’s support for emergency infrastructure projects is developed based on KNN from data drawn from a questionnaire survey of 445 local residents concerning Wuhan Leishenshan Hospital, China. Two optimization algorithms, the learning curve with m-fold cross-validation and the grid search algorithm, are proposed to optimize the key parameters of the KNN predictive model. Additionally, quantitative analysis is conducted by using the random forest algorithm to assess the importance of various factors influencing public support. The results show that the prediction accuracy and model stability of the KNN prediction model based on the grid search algorithm are better than those using a learning curve with m-fold cross-validation. Furthermore, the random forest algorithm quantitative analysis shows that the most important factor influencing the public’s support is government attention. The conclusions drawn from this paper provide a theoretical reference and practical guidance for decision making and the sustainable development of emergency infrastructure projects in China.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/buildings13102495"
    },
    {
        "id": 9037,
        "title": "Identification of disease-related miRNAs based on Weighted K-Nearest Known Neighbors and Inductive Matrix Completion",
        "authors": "Ahmet Toprak",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijdmb.2023.10058135"
    },
    {
        "id": 9038,
        "title": "A Weighted Ensemble Classification Algorithm Based on Nearest Neighbors for Multi-Label Data Stream",
        "authors": "Hongxin Wu, Meng Han, Zhiqiang Chen, Muhang Li, Xilong Zhang",
        "published": "2023-10-31",
        "citations": 1,
        "abstract": "With the rapid development of data stream, multi-label algorithms for mining dynamic data become more and more important. At the same time, when data distribution changes, concept drift will occur, which will make the existing classification models lose effectiveness. Ensemble methods have been used for multi-label classification, but few methods consider both the accuracy and diversity of base classifiers. To address the above-mentioned problem, a Weighted Ensemble classification algorithm based on Nearest Neighbors for Multi-Label data stream (WENNML) is proposed. WENNML uses data blocks to train Active candidate Ensemble Classifiers (AEC) and Passive candidate Ensemble Classifiers (PEC). The base classifiers of AEC and PEC are dynamically updated using geometric and diversity weighting methods. When the difference value between the number of current instances and the number of warning instances reaches the passive warning value, the algorithm selects the optimal base classifiers from AEC and PEC according to the subset accuracy and hamming score and puts them into the predictive ensemble classifiers. Experiments are carried out on 12 kinds of datasets with 9 comparison algorithms. The results show that WENNML achieves the best average rankings among the four evaluation metrics.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3570960"
    },
    {
        "id": 9039,
        "title": "Empowering Pregnant Women with Tailored Food Recommendations through K-Nearest Neighbors in Android Application",
        "authors": "Stevanus Kurniawan, Raymond Sunardi Oetama",
        "published": "2024-4-4",
        "citations": 0,
        "abstract": "When at a restaurant, pregnant women often face difficulties in choosing healthy and appropriate foods during pregnancy, primarily due to lack of knowledge, uncertainty about food ingredients, and difficulty in remembering the list of foods to avoid. This research aims to assist restaurants and pregnant women in avoiding consuming foods containing unhealthy ingredients for pregnant women. Our solution is to develop an Android-based application that can detect foods containing ingredients that pregnant women should not consume and then offer alternative foods that are similar to those foods. The application is developed using the Rapid Application Development method, and the algorithm used is the K-nearest Neighbor. The application has been tested with a User Acceptance Test with an 84-90% acceptance rate.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33379/gtech.v8i2.4084"
    },
    {
        "id": 9040,
        "title": "K<sup>2</sup>NN: Self-Supervised Learning with Hierarchical Nearest Neighbors for Remote Sensing",
        "authors": "Jianlong Yuan, Yuanhong Xu, Zhibin Wang",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10096425"
    },
    {
        "id": 9041,
        "title": "ANALISIS SENTIMEN TERHADAP TWIT MAXIM PADA TWITTER MENGGUNAKAN R PROGRAMMING DAN K NEAREST NEIGHBORS",
        "authors": "Muhamad Trian Diwandanu, Lulu Mawaddah Wisudawati",
        "published": "2023",
        "citations": 0,
        "abstract": "Usaha transportasi saat ini sudah banyak yang berbasis online dalam pelayanannya seperti pemesanan, pembayaran dan pemberian ulasan. Salah satu jasa transportasi online yang sudah ada di Indonesia yaitu Maxim. Masyarakat biasanya memberikan opini mereka terhadap layanan yang diberikan oleh Maxim melalui Twitter. Twit yang ditulis oleh masyarakat pengguna Twitter merupakan sumber data yang valid untuk dilakukan analisis sentimen. Tujuan penulisan ini adalah melakukan analisis sentimen terhadap twit maxim pada Twitter. Metode klasifikasi analisis sentimen pada penulisan ini menggunakan K Nearest Neighbors (KNN) untuk mengklasifikasi data serta Lexicon-Based sebagai penetap sentimen positif, negatif dan netral. Tahapan awal pada analisis sentimen ini yaitu tahap pengambilan data, pre-processing, yang terdiri dari Filtering & Casefolding, perbaikan kata tidak baku, mengubah kata bernegasi, Stopword Removal dan penghapusan spasi berlebih. Setelah itu, dilakukan pelabelan data dan pemberian skor menggunakan metode Lexicon Based. Dataset hasil dari pre-processing dan Lexicon Based digunakan untuk proses klasifikasi menggunakan KNN. Hasil terbaik didapatkan menggunakan data latih 80% sebanyak 702 data dan data uji 20% sebanyak 175 data dengan k=1 dengan akurasi sebesar 95,43%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.35760/ik.2023.v28i1.7909"
    },
    {
        "id": 9042,
        "title": "KOMPARASI ALGORITMA KLASIFIKASI NAIVE BAYES DAN K-NEAREST NEIGHBORS DALAM ANALISIS SENTIMEN TERHADAP OPINI FILM PADA TWITTER",
        "authors": "Muhammad Muharrom",
        "published": "2023-3-28",
        "citations": 0,
        "abstract": "The fact that social media is so unreliable does not prevent Twitter users from using the service. Twitter is one of a few social media platforms that allows users to engage in conversation, share information, or even reveal their true identities, such as when discussing a movie's plot. A tweet or comment about a movie that is posted on Twitter may be viewed as a tool to improve the quality of movie production. To understand this, one can use sentimen analysis to categorize as either negative or positive by comparing the Naive Bayes and k-Nearest Neighbors algorithms to determine which one is the most accurate. The results of the two algorithms' comparative testing reveal that the Nave Bayes algorithm has a higher rata-rata accuracy of 99.63% with an AUC of around 1.000, while the K-NN algorithm has a higher rata-rata accuracy of 99.25% with an AUC of 1.000.",
        "keywords": "",
        "link": "http://dx.doi.org/10.55606/jitek.v3i1.1147"
    },
    {
        "id": 9043,
        "title": "A Rapid Risk Assessment Method for Distribution Network Based on K-Nearest Neighbors",
        "authors": "Siming He, Hai Li, Yuxin Lan, Caiyuan Liang, Chen Li, Zhiyu Mao",
        "published": "2023-12-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/apet59977.2023.10489398"
    },
    {
        "id": 9044,
        "title": "Regression Analysis of Song Popularity based on Ridge, K-Nearest Neighbors and Multiple-Layers Neural Networks",
        "authors": "Aoran Dong, Ruizhe Qiu, Zhen Ye",
        "published": "2023-4-1",
        "citations": 0,
        "abstract": "Contemporarily, human beings are working on the implementation of artificial intelligence technology in the arts fields, where the music is one of the directions. Before humans can create a song with artificial intelligence, it is necessary to understand the song first. This research tries to find out the relationship between the song's popularity and several selected songs' physical parameters based on statistics and machine learning. According to the analysis, this research proves that there is no significant relationship between selected physical parameters and the song's popularity. In addition, machine learning algorithms also do not find the potential relationships between them. In this case, it is safe to conclude that creating the song by considering these selected physical parameters is meaningless. On this basis, scholars should try to find out what factors make the song popular in terms of analyzing songs differently. These results shed light on guiding further exploration of future music analysis and artificial intelligence in music fields.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v39i.6602"
    },
    {
        "id": 9045,
        "title": "Probabilistic Nearest Neighbors Classification",
        "authors": "Bruno Fava, Paulo C. Marques F., Hedibert F. Lopes",
        "published": "2023-12-30",
        "citations": 0,
        "abstract": "Analysis of the currently established Bayesian nearest neighbors classification model points to a connection between the computation of its normalizing constant and issues of NP-completeness. An alternative predictive model constructed by aggregating the predictive distributions of simpler nonlocal models is proposed, and analytic expressions for the normalizing constants of these nonlocal models are derived, ensuring polynomial time computation without approximations. Experiments with synthetic and real datasets showcase the predictive performance of the proposed predictive model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/e26010039"
    },
    {
        "id": 9046,
        "title": "Consistency of the <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mml:mi>k</mml:mi></mml:math>-nearest neighbors rule for functional data",
        "authors": "Ahmad Younso",
        "published": "2023-1-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5802/crmath.402"
    },
    {
        "id": 9047,
        "title": "NNVDC: A new versatile density-based clustering method using k-Nearest Neighbors",
        "authors": "Rabinder Kumar Prasad, Rosy Sarmah, Subrata Chakraborty, Sauravjyoti Sarmah",
        "published": "2023-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.120250"
    },
    {
        "id": 9048,
        "title": "TUNING HYPERPARAMETERS OF SELF-ORGANIZING MAPS IN COMBINATION WITH K-NEAREST NEIGHBORS FOR IOT MALWARE DETECTION",
        "authors": "Huu Noi Nguyen,  ",
        "published": "2023-6-28",
        "citations": 0,
        "abstract": "In the Internet of Things, sensor devices often generate massive sensory data across multiple domains and applications. Identifying IoT malware from a huge amount of such IoT data is often a challenging task. In our previous studies, analytic techniques were applied to reduce dimensionality and discover valuable information from the original data. Particularly, the Self-organizing Maps (SOM)-based classifier with an AutoEncoder is used to create an end-to-end IoT malware detection model. However, the SOM-based classifier has a constraint that new instances may be incorrectly classified if they are mapped into unlabelled neurons in the SOM map. To address this issue, in this study, a novel hybrid between SOM-based classifier and well-known classification algorithms like K-Nearest Neighbors, Support Vector Machine, Softmax, Random Forest. In this hybrid, classification methods will help to correctly assign labels for instances mapped into the unlabeled neurons. In addition, this article investigates hyperparameter optimization methods for optimizing SOM hyperparameters. Our proposed methods were tested on the NBaIoT dataset with various experimental settings. Experimental results illustrate that SOMKNN often performs better than stand-alone techniques, including the SOM classifier.",
        "keywords": "",
        "link": "http://dx.doi.org/10.56651/lqdtu.jst.v12.n1.654.ict"
    },
    {
        "id": 9049,
        "title": "KLASIFIKASI TINGKAT KEMATANGAN BUAH PEPAYA CALIFORNIA DALAM RUANG WARNA HSV (HUE SATURATION VALUE) DENGAN ALGORITMA K-NEAREST NEIGHBORS",
        "authors": "A Isatul Masruroh, Sorikhi ., Achmad Syauqi",
        "published": "2023-3-6",
        "citations": 0,
        "abstract": "Papaya fruit is in great demand by people at home and abroad, thus proving that this one agricultural product has become a global need that is in great demand and sought after. To determine the papaya harvest based on the color of the fruit skin, the ripeness of the papaya starts from unripe, unripe (half-ripe) and overripe so that the researchers put forward an idea to answer the problem in determining the ripeness of papaya fruit, which is mostly done manually, still has some weaknesses and requires the process is quite long, has low accuracy and is inconsistent. Based on these problems, a system was created to classify the ripeness level of papaya by utilizing the HSV color features using the K-Nearest Neighbor (K-NN) algorithm. This classification uses image processing by utilizing MATLAB software to create a classification system with three classification classes, namely raw, half cooked and cooked. The classification generated using the K-Nearest Neighbor (K-NN) algorithm shows an accuracy of 86.6667%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36308/iris.v1i1.470"
    },
    {
        "id": 9050,
        "title": "Revisiting distance metrics in k-nearest neighbors algorithms: Implications for sovereign country credit rating assessments",
        "authors": "Ali Çetin, Ali Büyüklü",
        "published": "2024",
        "citations": 0,
        "abstract": "The k-Nearest Neighbors algorithm, a fundamental machine learning technique,\n   typically employs the Euclidean distance metric for proximity-based data\n   classification. This research focuses on the Feature Importance Infused\n   k-Nearest Neighbors model, an advanced form of k-Nearest Neighbors.\n   Diverging from traditional algorithm uniform weighted Euclidean distance,\n   Feature Importance Infused k-Nearest Neighbors introduces a specialized\n   distance weighting system. This system emphasizes critical features while\n   reducing the impact of lesser ones, thereby enhancing classification\n   accuracy. Empirical studies indicate a 1,7% average accuracy improvement\n   with proposed model over conventional model, attributed to its effective\n   handling of feature importance in distance calculations. Notably, a\n   significant positive correlation was observed between the disparity in\n   feature importance levels and the model's accuracy, highlighting proposed\n   model?s proficiency in handling variables with limited explanatory power.\n   These findings suggest proposed model?s potential and open avenues for\n   future research, particularly in refining its feature importance weighting\n   mechanism, broadening dataset applicability, and examining its compatibility\n   with different distance metrics.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2298/tsci231111008c"
    },
    {
        "id": 9051,
        "title": "k-nearest neighbors prediction and classification for spatial data",
        "authors": "Mohamed-Salem Ahmed, Mamadou N’diaye, Mohammed Kadi Attouch, Sophie Dabo-Niange",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43071-023-00041-2"
    },
    {
        "id": 9052,
        "title": "Innovative brain tumor detection technique using K-nearest neighbors and compared with support vector machine",
        "authors": "K. Gopisai, S. Adarsh Rag",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0178990"
    },
    {
        "id": 9053,
        "title": "PERBANDINGAN ALGORITMA SUPPORT VECTOR MACHINE DAN K-NEAREST NEIGHBORS PADA KEMATANGAN BUAH SAWIT",
        "authors": "Syawaluddin Kadafi Parinduri, Rika Rosnelly, Anton Purnama, Ameliana Sihotang, Mimi Chintya Adelina",
        "published": "2023-11-29",
        "citations": 0,
        "abstract": "Berdasarkan pengamatan dan hasi dari observasi, buah kelapa sawit memiliki suatu warna buah yang hampir sama yaitu berwarna hitam pekat atau hitam agak kekuning-kuningan saat mentah, dan berwarna merah tua saat matang. Sangat sulit untuk membedakan buah kelapa sawit yang matang dan mentah. Tandan buah kelapasawit memiliki jumlah  buah yang banyak, dalam satu tandan diperkirakan beratnya mencapai kurang lebih 20 sampai 30 Kilogram. Untuk dapat mengetahui kematangan buah sawit tersebut, dibutuhkan  suatu  sistem untuk melakukan klasifikasi kematangan buah secara otomatis. Metode Support Vector Machine (SVM) dan K-Nearest neighbors (K-NN) dapat digunakan untuk klasifikasi buah kelapa sawit yang matang dan mentah. Kedua Metode ini akan digunakan untuk melihat  kelebihan akurasi tertinggi. Sehingga Kedua metode ini, akan dibandingkan. dan bekerja baik dangan ruang dimensi yang tinggi dengan menggunakan bantuan aplikasi Orange data mining. Hasil yang diperoleh pada metode Support Vector Machine (SVM) skenario satu,  mendapatkan nilai akurasi yang sangat baik, yaitu 100%. Pada skenario dua, dengan menggunakan  metode K-Nearest neighbors (K-NN) mendapatkan nilai akurasi yang sangat baik juga sebesar 100%.. Hal ini membuktikan bahwa kedua metode tersebut dapat digunakan untuk mengklasifikasikan kematangan buah kelapa sawit dengan hasil yang sangat baik.",
        "keywords": "",
        "link": "http://dx.doi.org/10.32699/device.v13i2.5400"
    },
    {
        "id": 9054,
        "title": "Transferring experiences in k-nearest neighbors based multiagent reinforcement learning: an application to traffic signal control",
        "authors": "Ana Lucia C. Bazzan, Vicente N. de Almeida, Monireh Abdoos",
        "published": "2023-9-27",
        "citations": 0,
        "abstract": "The increasing demand for mobility in our society poses various challenges to traffic engineering, computer science in general, and artificial intelligence in particular. Increasing the capacity of road networks is not always possible, thus a more efficient use of the available transportation infrastructure is required. Another issue is that many problems in traffic management and control are inherently decentralized and/or require adaptation to the traffic situation. Hence, there is a close relationship to multiagent reinforcement learning. However, using reinforcement learning poses the challenge that the state space is normally large and continuous, thus it is necessary to find appropriate schemes to deal with discretization of the state space. To address these issues, a multiagent system with agents learning independently via a learning algorithm was proposed, which is based on estimating Q-values from k-nearest neighbors. In the present paper, we extend this approach and include transfer of experiences among the agents, especially when an agent does not have a good set of k experiences. We deal with traffic signal control, running experiments on a traffic network in which we vary the traffic situation along time, and compare our approach to two baselines (one involving reinforcement learning and one based on fixed times). Our results show that the extended method pays off when an agent returns to an already experienced traffic situation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/aic-220305"
    },
    {
        "id": 9055,
        "title": "Evaporation Prediction with Wavelet-Based Hyperparameter Optimized K-Nearest Neighbors and Extreme Gradient Boosting Algorithms in a Semi-Arid Environment",
        "authors": "Okan Mert Katipoğlu",
        "published": "2023-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s40710-023-00669-0"
    },
    {
        "id": 9056,
        "title": "Komparasi Algoritma K-Nearest Neighbors dan Naïve Bayes dalam Klasifikasi Penyakit Diabetes Gestasional",
        "authors": "Annisa Khoirala Ermy Pily,  Oktavianda, Fanesa Aprilia,  Rahmaddeni, Lusiana Efrizoni",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "Diabetes merupakan penyakit metabolik dengan gejala hiperglikemia akibat gangguan sekresi insulin dan aksi insulin. Diabetes gestasional adalah gangguan toleransi glukosa pada wanita hamil. Saat kehamilan, plasenta menghasilkan hormon baru seperti human placental lactogen (HPL), hormon estrogen, dan hormon peningkat resistensi insulin. Gejala diabetes gestasional tidak selalu mudah dikenali, dan seringkali penderitanya mengalami gejala awal secara tidak sadar. Penelitian ini bertujuan untuk membandingkan performa dua algoritma yaitu K-NN dan Naïve Bayes dengan Feature Selection dalam mengklasifikasikan penderita diabetes gestasional.  Hasil error terendah dari feature selection dengan iterasi K=4, memperoleh MAE 0.317, MSE 0.142, dan RMSE 0.377. Hasil akurasi pada model KNN dengan K=5 , tanpa Feature Selection sebesar 80% dan K-NN dengan Feature Selection sebesar 77%. Sementara itu, Naïve Bayes tanpa Feature Selection sebesar 77% dan Naïve Bayes dengan Feature Selection sebesar 80%. Dari hasil tersebut K-NN tanpa Feature Selection dan Naïve Bayes dengan Feature Selection mendapatkan hasil yang lebih baik.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33022/ijcs.v13i1.3714"
    },
    {
        "id": 9057,
        "title": "Comparative Analysis of the Performance of the Decision Tree and K-Nearest Neighbors Methods in Classifying Coffee Leaf Diseases",
        "authors": " Suryadi, Murhaban Murhaban, Rivansyah Suhendra",
        "published": "2023-12-19",
        "citations": 0,
        "abstract": "This study aimed to develop and compare classification models utilizing Decision Tree and K-Nearest Neighbors (KNN) in the detection of diseases in coffee leaf images. The dataset comprises coffee leaf images categorized into four different disease types, namely Nodisease, Miner, Phoma, and Rust. To facilitate model training and testing, the dataset was divided into training and validation data using a cross-validation approach. Both the Decision Tree and KNN models underwent meticulous parameter tuning. The experimental results reveal that the Decision Tree model achieved an accuracy rate of 98.20% on the validation data, while the KNN model achieved an accuracy rate of 75.01%. Furthermore, the Decision Tree model exhibited an AUC of 0.9879, recall of 0.9820, precision of 0.9835, and an F1-score of 0.9819 on the validation data. Conversely, the KNN model achieved an AUC of 0.9465, recall of 0.7501, precision of 0.7569, and an F1-score of 0.7485. These findings suggest that the Decision Tree model surpasses the KNN model in accurately detecting coffee leaf diseases, as demonstrated by higher accuracy and other evaluation metrics. However, the relevance of the KNN model remains contingent on application requirements and modeling preferences. These outcomes may contribute to the development of automated systems for disease detection in coffee plants, ultimately promoting more sustainable agricultural practices.",
        "keywords": "",
        "link": "http://dx.doi.org/10.34306/conferenceseries.v4i1.649"
    },
    {
        "id": 9058,
        "title": "Classification of Predicting Customer Ad Clicks Using Logistic Regression and k-Nearest Neighbors",
        "authors": "Yasi Dani, Maria Artanta Ginting",
        "published": "2023-1-21",
        "citations": 2,
        "abstract": "Nowadays, conventional marketing techniques have changed to online (digital) marketing techniques requiring internet access. Online marketing techniques have many advantages, especially in terms of cost efficiency and fast information delivery to the public. Therefore, many companies are interested in online marketing and advertising on social media platforms and websites. However, one of the challenges for companies in online marketing is determining the right target consumers since if they target consumers who are not interested in buying the product, the advertising costs will be high. One use of online advertising is clicks on ads which is a marketing measurement of how many users click on the online ad. Thus, companies need a click prediction system to know the right target consumers. And different types of advertisers and search engines rely on modeling to predict ad clicks accurately. This paper constructs the customer ad clicks prediction model using the machine learning approach that becomes more sophisticated in effectively predicting the probability of a click. We propose two classification algorithms: the logistic regression (LR) classifier, which produces probabilistic outputs, and the k-nearest neighbors (k-NN) classifier, which produces non-probabilistic outputs. Furthermore, this study compares the two classification algorithms and determines the best algorithm based on their performance. We calculate the confusion matrix and several metrics: precision, recall, accuracy, F1-score, and AUC-ROC. The experiments show that the logistic regression algorithm performs best on a given dataset.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30630/joiv.7.1.1017"
    },
    {
        "id": 9059,
        "title": "Penerapan Algoritma K-Nearest Neighbors untuk Klasifikasi Fragmen Metagenom Berdasarkan Ekstraksi Fitur K-Mers",
        "authors": "Ryan Ananda Nolly, Amanda Fitria, Kana Saputra S",
        "published": "2023-7-3",
        "citations": 0,
        "abstract": "Penelitian di bidang metagenomika menjadi salah satu bidang kajian bioinformatika yang terus berkembang. Metagenom merupakan sebuah teknik yang bertujuan untuk mengumpulkan gen-gen yang diambil secara langsung dari lingkungan dan mengenalisis informasi genetika di dalamnya. Data yang diambil langsung dari lingkungan memungkinkan fragmen yang dihasilkan mengandung berbagai mikroorganisme, sehingga akan berakibat pada terjadinya kesalahan perakitan terhadap fragmen metagenom. Proses binning (pengelompokan) dapat dilakukan dengan dua pendekatan, yaitu pendekatan homologi dan pendekatan komposisi. Pendekatan secara komposisi tidak perlu membandingkan dan menyimpulkan setiap hasil pencarian pada setiap level taksonomi sehingga waktu yang diperlukan untuk pengelompokan lebih cepat dibandingkan dengan pendekatan secara homologi.Pada proses binning (pengelompokan) dengan pendekatan komposisi, teknik yang dilakukan adalah dengan supervised learning. Tujuan dari penelitian ini adalah untuk mengklasifikasi fragmen metagenom menggunakan algoritma KNN dan K-Mers sebagai ekstraksi fitur. Selain itu, untuk menghitung tingkat akurasi klasifikasi fragmen metagenom menggunakan confusion matrix. Metode K-Mers yang digunakan sebagai ekstraksi fitur bertujuan untuk mempartisi data dan membentuk satu atau lebih kelompok yang memiliki kesamaan, sehingga perhitungan untuk mencari tingkat akurasi menjadi lebih mudah didapatkan. Berdasarkan hasil pengujian yang dilakukan menunjukkan bahwa semakin rendah nilai K yang digunakanpada KNN maka semakin tinggi akurasi yang diperoleh. Pada pengujian ini diperoleh perhitungan akurasi sebesar 94,37% dimana nilai K untuk KNN adalah 3 dan nilai K untuk K-Mers adalah 3. Hasil klasifikasi fragmen metagenom menggunakan algoritma KNN berdasarkan ekstraksi fitur K-Mers dapat dilakukan dengan baik.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30872/jim.v17i1.5779"
    },
    {
        "id": 9060,
        "title": "Analisa Sentimen Tentang Ibu Kota Nusantara (IKN) Dengan Menggunakan Algoritma K-Nearest Neighbors (KNN) dan Naïve Bayes",
        "authors": "Choirul Huda, Mesra Betty Yel",
        "published": "2024-2-17",
        "citations": 0,
        "abstract": "\n\n\nPemindahan ibu kota bukan merupakan suatu fenomena yang baru. Senin, 17 Januari 2022 nama “Nusantara” diumumkan pertama kali oleh kepala Bappenas Suharso Monoarfa. Panja RUU IKN menyetujui “Nusantara” sebagai nama ibu kota negara setelah delapan fraksi menyetujui. Terletak di Kalimantan Timur, Nusantara adalah sebuah kata yang akan mengganti posisi Jakarta sebagai ibu kota negara Indonesia. Pemindahan Ibu Kota Nusantara (IKN) menimbulkan berbagai macam pro dan kontra. Mulai dari pemilihan lokasi, pengesahan Undang-Undang yang dinilai terlalu terburu-buru, dan akhir-akhir ini pemerintah juga mengajak masyarakat Indonesia untuk membantu mendukung untuk membangun Ibu Kota Nusantara. Menurut seorang pejabat dari Kementerian Perencanaan Pembangunan Nasional Indonesia, pemerintah bertekad untuk memindahkan ibu kota Indonesia keluar dari pulau jawa. Pada April 2019, rencana 10 tahun untuk memindahkan semua kantor pemerintahan ke ibukota baru diumumkan Kementrian Perencanaan Pembangunan Nasional merekomendasikan tiga provinsi yaitu Kalimantan Selatan, Kalimantan Tengah, dan Kalimantan Timur yang memenuhi syarat ibu kota baru, termasuk bebas dari gempa bumi, tsunami dan gunung berapi. Dari nama ini pemerintah dan DPR berharap agar ibu kota yang berlokasi di Sepakunegara (sekitar Penajam Paser Utara dan Kutai Kartanegara) menjadi symbol identitas nasional, kota dunia untuk semua dan menjadi penggerak ekonomi Indonesia masa depan.\n\n\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.55338/jikomsi.v7i1.2846"
    },
    {
        "id": 9061,
        "title": "Ensemble k-nearest neighbors based on centroid displacement",
        "authors": "Alex X. Wang, Stefanka S. Chukova, Binh P. Nguyen",
        "published": "2023-6",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ins.2023.02.004"
    },
    {
        "id": 9062,
        "title": "Improved Accuracy in Early Identification of Ischaemic Stroke using K- Nearest Neighbors with Support Vector Machine",
        "authors": "S. Manikandan, Anitha. G, Josiah Samuel Raj. J",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/accai58221.2023.10200194"
    },
    {
        "id": 9063,
        "title": "Integration of Swarm Intelligence with KNN for Optimal Nearest Neighbors Value Prediction",
        "authors": "Aniketh Anchalia, Anirudh Kakati, Ambika Patil, B N Bhavana, Ankit Paudel, Shilpa Chaudhari",
        "published": "2023-7-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/conecct57959.2023.10234790"
    },
    {
        "id": 9064,
        "title": "Klasifikasi Citra Cuaca Menggunakan  Inception-V3 dan K-Nearest Neighbors",
        "authors": "Iqbal Giffari Ritonga, Rika Rosnelly, Pius Deski Manalu, Teresa Tamba, Kristine Wau",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "Weather imagery has a crucial role in various sectors, such as aviation, maritime and agriculture. Weather conditions have a big impact on activities in these fields and greatly influence operations. Classifying weather images can be done by analyzing weather image data, which can be used to predict the type of weather that may occur. The results of these weather predictions have significant value in daily decision making in these various sectors. One method for classifying weather images can be done by first extracting weather image features using Inception-V3 which is then calculated using the K-Nearest Neighbors method. This research uses 1748 weather images with 4 categories to carry out training which produces a model with Accuracy 91%, F1 91%, Recall 91%, Precision 91%, and uses 8 weather images with 4 categories to carry out testing which produces classifications with all correct values. every image.",
        "keywords": "",
        "link": "http://dx.doi.org/10.34012/jutikomp.v6i2.4052"
    },
    {
        "id": 9065,
        "title": "Voting Scheme Nearest Neighbors by Difference Distance Metrics Measurement",
        "authors": "Gede Angga Pradipta, Made Liandana, Putu Desiana Wulaning Ayu, Dandy Pramana Hostiadi, Putu Sumardika Eka Putra",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "K-Nearest Neighbor (KNN) is a widely used method for both classification and regression cases. This algorithm, known for its simplicity and effectiveness, relies primarily on the Euclidean formula for distance metrics. Therefore, this study aimed to develop a voting model where observations were made using different distance calculation formulas. The nearest neighbors algorithm was divided based on differences in distance measurements, with each resulting model contributing a vote to determine the final class. Consequently, three methods were proposed, namely k-nearest neighbors (KNN), Local Mean-based KNN, and Distance-Weighted neighbor (DWKNN), with an inclusion of a voting scheme. The robustness of these models was tested using umbilical cord data characterized by imbalance and small dataset size. The results showed that the proposed voting model for nearest neighbors consistently improved performance by an average of 1-2% across accuracy, precision, recall, and F1 score when compared to the conventional non-voting method.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30595/juita.v11i2.19298"
    },
    {
        "id": 9066,
        "title": "R-positivity and existence of Zero-Temperature Limits of Gibbs Measures on Nearest Neighbors Matrices – CORRIGENDUM",
        "authors": "Jorge Littin Curinao, Gerardo Corredor Rincón",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1017/jpr.2024.11"
    },
    {
        "id": 9067,
        "title": "Leveraging Noisy Labels of Nearest Neighbors for Label Correction and Sample Selection",
        "authors": "Hua Jiang, Yixiong Chen, Li Liu, Xiaoguang Han, Xiao-Ping Zhang",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10446280"
    },
    {
        "id": 9068,
        "title": "Sentimen Analisis Pandangan Masyarakat Terhadap Vaksinasi Covid 19 Menggunakan K-Nearest Neighbors",
        "authors": "Dyah Apriliani, Ardi Susanto, Muhammad Fikri Hidayattullah, Ginanjar Wiro Sasmito",
        "published": "2023-1-27",
        "citations": 0,
        "abstract": "Abstrak - Pandemi covid 19 yang terjadi sangat meresahkan masyarakat. Banyak masyarakat yang terpapar maupun kehilangan keluarga mereka karena virus ini. Untuk mencegah semakin menyebarnya virus covid 19, pemerintah menyelenggarakan program vaksinasi. Program vaksinasi yang dilakukan menuai pro dan kontra dari masyarakat. Berdasarkan permasalahan tersebut, maka dalam penelitian ini akan melakukan proses klasifikasi pandangan masyarakat terhadap vaksinasi Covid 19. Data penelitian yang digunakan diambil dari twitter sebanyak 2241 data. Data akan diklasifikasikan menjadi 2 kelas yaitu positif dan negatif. Proses klasifikasi akan dilakukan dengan menggunakan metode K-Nearest Neighbors (KNN).  Tahapan pertama yang dilakukan adalah pengambilan data dari twitter, pelabelan data, preprocesing data di phyton, pembobotan TF-IDF, pembuatan model, pengujian model dan evaluasi model. Dari penelitian ini didapatkan akurasi terbaik sebesar 79,25% dengan menggunakan parameter K-Fold 10 dan KNN 5.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30591/jpit.v8i1.4759"
    },
    {
        "id": 9069,
        "title": "PERBANDINGAN JARAK EUCLIDEAN, MANHATTAN, CHEBYSHEV PADA KLASIFIKASI STATUS GIZI BALITA MENGGUNAKAN METODE K-NEAREST NEIGHBORS (KNN)",
        "authors": "Junia Uni Umamatun Nysa, Ali Mahmudi, Karina Auliasari",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "Penelitian ini membandingkan keakuratan jarak Euclidean, Manhattan, dan Chebyshev dalam klasifikasi status gizi balita menggunakan metode K-Nearest Neighbors (KNN). Data status gizi anak balita dari Posyandu digunakan untuk melatih model KNN dan membandingkan keakuratan ketiga metode jarak. Tujuan penelitian ini adalah membandingkan keakuratan jarak dan mengembangkan sistem pendukung keputusan berbasis web untuk kader Posyandu. Metodologi penelitian mencakup studi literatur, pengumpulan data, perancangan sistem, implementasi, dan pengujian sistem. Hasilnya diharapkan memberikan informasi mengenai metode jarak yang optimal dalam penentuan status gizi balita dengan KNN.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36040/jati.v7i4.7544"
    },
    {
        "id": 9070,
        "title": "Analisis Performa Algoritma Support Vector Machine dan Algoritma K-Nearest Neighbors untuk Kasus Penyakit Mulut dan Kuku pada Sapi di Jawa Timur",
        "authors": " Alifta Putri Ramadhani",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "Penyakit mulut dan kuku (PMK) saat ini tengah mewabah di Indonesia. Penyakit ini umunya menyerang hewan berkuku genap atau belah yaitu seperti sapi, kerbau hingga domba atau kambing. Gejala Penyakit ini tidak ditularkan ke manusia atau bukan penyakit zoonosis. Memprediksi penyakit mulut dan kuku pada sapi merupakan suatu permasalahan yang solusinya dapat dilakukan dengan menggunakan machine learning. Terdapat beberapa metode yang berbeda maka hasil akurasi juga akan berbeda-beda. Penelitian ini bertujuan untuk membandingkan performa algoritma Support Vector Machine dan algoritma K-Nearest Neighbor. Dalam penelitian ini jumlah dataset berjumlah 540 baris dan 12 kolom. Pada penelitian algoritma Support Vector Machine menggunakan beberapa kernel yaitu kernel rbf, kernel linear, kernel poly, dan kernel sigmoid lalu untuk algoritma K-Nearest Neighbors menggunakan nilai K=1 hingga K=20. Penelitian ini juga menggunakan beberapa skenario yaitu perbandingan jumlah data latih dan jumlah data uji yang pertama data latih 70% dan data uji 30% lalu yang kedua data latih 80% data uji 20% dan yang ketiga 90% data latih 10% data uji. Pengunaan algoritma Support Vector Machine dan algoritma K-Nearest Neighbors digunakan untuk memperoleh hasil yangrelevan atau akurat dalam memprediksi penyakit mulut dan kuku pada sapi. Hasil yang diperoleh dari penelitian ini untuk kedua algoritma dapat di katakan baik karena sama- sama memiliki nilai akurasi yang tinggi yaitu sebesar 100%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36526/ztr.v6i1.3489"
    },
    {
        "id": 9071,
        "title": "Optimized k-nearest neighbors for classification of prosthetic hand movements using electromyography signal",
        "authors": "Padmini Sahu, Bikesh Kumar Singh, Neelamshobha Nirala",
        "published": "2024-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.engappai.2024.108390"
    },
    {
        "id": 9072,
        "title": "Improving k-Nearest Neighbors Model using SMOTE with Bagging Ensemble",
        "authors": "Ivana Meiska, Syifa Melinda Naf'an, Ig. Prasetya Dwi Wibawa, Meta Kallista, Brilliant Friezka Aina, Asif Awaludin",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/apwimob59963.2023.10365600"
    },
    {
        "id": 9073,
        "title": "Multivariate nearest‐neighbors Gaussian processes with random covariance matrices",
        "authors": "Isabelle Grenier, Bruno Sansó, Jessica L. Matthews",
        "published": "2024-5",
        "citations": 0,
        "abstract": "AbstractWe propose a non‐stationary spatial model based on a normal‐inverse‐Wishart framework, conditioning on a set of nearest‐neighbors. The model, called nearest‐neighbor Gaussian process with random covariance matrices is developed for both univariate and multivariate spatial settings and allows for fully flexible covariance structures that impose no stationarity or isotropic restrictions. In addition, the model can handle duplicate observations and missing data. We consider an approach based on integrating out the spatial random effects that allows fast inference for the model parameters. We also consider a full hierarchical approach that leverages the sparse structures induced by the model to perform fast Monte Carlo computations. Strong computational efficiency is achieved by leveraging the adaptive localized structure of the model that allows for a high level of parallelization. We illustrate the performance of the model with univariate and bivariate simulations, as well as with observations from two stationary satellites consisting of albedo measurements.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/env.2839"
    },
    {
        "id": 9074,
        "title": "Spatiotemporal <i>K</i>-Nearest Neighbors Algorithm and Bayesian Approach for Estimating Urban Link Travel Time Distribution From Sparse GPS Trajectories",
        "authors": "Wenwen Qin, Mingfeng Zhang, Wu Li, Yunyi Liang",
        "published": "2023-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mits.2023.3296331"
    },
    {
        "id": 9075,
        "title": "scGAMNN: Graph Antoencoder-Based Single-Cell RNA Sequencing Data Integration Algorithm Using Mutual Nearest Neighbors",
        "authors": "Bai Zhang, Hanwen Wu, Yan Wang, Chenxu Xuan, Jie Gao",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/jbhi.2023.3311340"
    },
    {
        "id": 9076,
        "title": "Design and Implementation of a High-Speed Low-Power <i>K</i>-Nearest-Neighbors-based Algorithm for Detecting Micro-Single-Event-Latchups",
        "authors": "Junkai Zhao, Kwen-Siong Chong, Wei Shu, Mengu Cho, Joseph S. Chang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tns.2024.3379497"
    },
    {
        "id": 9077,
        "title": "Analyze the Lack of Accuracy in Stock Price Prediction using Novel K-Nearest Neighbors Regression Compared with Logistic Regression to Improve Accuracy",
        "authors": "Nagubandi Vinay, Mahaveerakannan R",
        "published": "2023-4-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iconstem56934.2023.10142304"
    },
    {
        "id": 9078,
        "title": "Innovative compressive strength prediction for recycled aggregate/concrete using K-nearest neighbors and meta-heuristic optimization approaches",
        "authors": "Min Duan",
        "published": "2024-12",
        "citations": 0,
        "abstract": "AbstractThis paper presents a groundbreaking method for predicting the compressive strength (Fc) of recycled aggregate concrete (RAC) through the application of K-nearest neighbors (KNN) analysis. The task of designing mixture proportions to achieve the desired Fc can be remarkably intricate, owing to the intricate interplay among the components involved. Machine learning (ML) algorithms have exhibited considerable promise in tackling this complexity effectively. In pursuit of enhanced prediction accuracy, this research introduces a semi-empirical approach that seamlessly integrates strategies, including optimization techniques. This study incorporates two meta-heuristic methods, the Fire Hawk optimizer (FHO) and Runge–Kutta optimization (RUK) to enhance model accuracy. The research results reveal three separate models: KNFH, KNRK, and a single KNN model, each providing valuable insights for precise Fc prediction. Remarkably, the KNFH model stands out as a top performer, boasting an impressive R2 value of 0.994 and a meager RMSE value of 1.122. These findings not only validate the accuracy and reliability of the KNFH model but also highlight its effectiveness in predicting Fc outcomes. This approach holds great promise for precise Fc forecasting in the construction industry. Integrating meta-heuristic algorithms significantly improves model accuracy, leading to more reliable forecasts with profound implications for construction projects and their outcomes. This research marks a significant advancement in predicting Fc using ML, offering valuable tools for engineers and builders.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s44147-023-00348-9"
    },
    {
        "id": 9079,
        "title": "PERBANDINGAN ALGORITMA NAÏVE BAYES CLASSIFIER DAN K-NEAREST NEIGHBORS UNTUK  ANALISIS SENTIMEN COVID-19 DI TWITTER",
        "authors": "Habibi Aulia Nur Syifa Habibi, Arie Nugroho, Rina Firliana",
        "published": "2023-3-10",
        "citations": 0,
        "abstract": "COVID-19 muncul di Tiongkok pada tahun 2019. Di Indonesia pada tahun 2020 terdapat lebih dari 3000 kasus positif COVID-19 dengan angka kematian sebesar 9,1%. Belum tuntasnya upaya pemerintah dalam memutus mata rantai penyebaran COVID-19 membuat masyarakat resah akan pandemi ini. Banyak masyarakat yang ingin menyampaikan aspirasinya di media sosial yang dianggap cocok sebagai wadah yang mewakili aspirasi pandemi COVID-19. Salah satunya adalah twitter. Banyak sekali pesan teks yang dikirimkan, ada yang positif dan ada yang negatif, sehingga sulit untuk mendapatkan informasi yang selaras karena keberagaman pesan teks yang dikirimkan. Salah satu cara untuk mengatasinya adalah dengan analisis sentimen. Penelitian ini memiliki proses antara lain text preprocessing, pembobotan kata, klasifikasi dengan algoritma K-Nearest Neighbors (KNN) dan Naïve Bayes Classifiers (NBC). Hasil yang didapatkan KNN mendapatkan akurasi sebesar 72.37% sedangkan NBC sebesar 67.84%. KNN merupakan algoritma klasifikasi terbaik untuk klasifikasi sentimen negatif, label negatif yang diprediksi benar pada KNN lebih besar yaitu 393 dibandingkan dengan NBC yaitu 339. Sedangkan NBC merupakan algoritma terbaik untuk klasifikasi sentimen positif, label positif yang diprediksi benar NBC yaitu 275 lebih besar dibandingkan dengan KNN yaitu 262.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33884/jif.v11i01.7069"
    },
    {
        "id": 9080,
        "title": "A NOTE ON THE -NEAREST NEIGHBORS RULE FOR SPATIAL FUNCTIONAL DATA IN REGRESSION MODEL WITH SURROGATE SCALAR RESPONSE",
        "authors": "Kowir Pambo Bello, Stéphane BOUKA",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17654/0972086324008"
    },
    {
        "id": 9081,
        "title": "Klasifikasi Jamur Beracun Menggunakan Algoritma Naïve Bayes dan K-Nearest Neighbors",
        "authors": "Gracia Mianda Caroline Batubara, Anita Desiani, Ali Amran",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "Jamur adalah salah satu organisme eukariot heterotrof dengan jenis yang sangat banyak, sekitar 1.500.000 di dunia. Namun, pengenalan akan jamur masih sangat kurang, dimana jumlah jamur yang sudah dikenali hanya sebanyak 74.000 jenis. Beragamnya jenis jamur ini membuat pengenalan akan klasifikasi jamur menjadi sangat penting agar manusia tidak mengonsumsi jamur beracun yang akan memberikan dampak negatif. Penelitian ini bertujuan untuk menemukan algoritma terbaik dalam pengklasifikasian jamur beracun dan tidak beracun. Klasifikasi jamur berdasarkan ciri-cirinya dapat dilakukan melalui penerapan algoritma Naïve Bayes dan k-Nearest Neighbors (kNN) pada dataset jamur. Hasilnya, algoritma Naïve Bayes memberikan rata-rata akurasi sebesar 92%, lebih kecil dibanding k-Nearest Neighbors yang memberikan rata-rata akurasi sebesar 98%. Rata-rata presisi algoritma Naïve Bayes dan k-Nearest Neighbors sama, yaitu 92,5%. Rata-rata recall algoritma Naïve bayes sebesar 91,5% dan algoritma k-Nearest Neighbors sebesar 98%. Berdasarkan rata-rata akurasi, presisi, dan recall kedua algoritma tersebut, dapat disimpulkan bahwa algoritma k-Nearest Neighbors lebih baik dibanding algoritma Naïve Bayes dalam klasifikasi jamur beracun. Namun, rata-rata akurasi, presisi, dan recall dari algoritma Naïve Bayes masih tergolong sangat baik karena nilainya berada diatas 90%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54082/jiki.68"
    },
    {
        "id": 9082,
        "title": "PERBANDINGAN PERFORMA MODEL MACHINE LEARNING SUPPORT VECTOR MACHINE, NEURAL NETWORK, DAN  K-NEAREST NEIGHBORS DALAM PREDIKSI HARGA SAHAM",
        "authors": "Sudriyanto Sudriyanto, Fatimatus Syahro, Novi Fitriani",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "This study aims to analyze the performance of three prediction models, namely K-Nearest Neighbors (K-NN), Neural Network (NN), and Support Vector Machine (SVM), in predicting the stock price of PT Astra International Tbk (ASII.JK). The research encompasses the initial stages through evaluation using optimal parameters for these three algorithms. The research findings reveal that the K-NN prediction model has the lowest Root Mean Square Error (RMSE) value, with a value of 0.037, indicating the most accurate prediction compared to the other models. Despite the NN model having an RMSE of 0.048, which is higher than K-NN, it still provides reasonably accurate predictions. Meanwhile, the SVM model has an RMSE of 0.075, indicating a higher level of error in its predictions. Based on these results, the recommendation is to utilize the K-NN model as the preferred choice for predicting the ASII.JK stock price.",
        "keywords": "",
        "link": "http://dx.doi.org/10.24929/jars.v2i1.2983"
    },
    {
        "id": 9083,
        "title": "Target Planning for UAV Merchant Ship Recognition Based on KNN Nearest Neighbor Algorithm",
        "authors": "Meili Zhang, Yue Yang, Hongmei Pei, Weili Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012272700003807"
    },
    {
        "id": 9084,
        "title": "Application of K-Nearest Neighbors Algorithms for Void Classification in Composite Oriented Strand Board",
        "authors": "C. Bowland, S. Callander, Y. Eftekhari, G. Gu, W. Hu, B. Jin, C. Li, J. McCaslin, F. Nguyen, C. Schaal, X. Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.33599/nasampe/c.23.0117"
    },
    {
        "id": 9085,
        "title": "The Classification of “Program Sembako”  recipients in Payobasung West Sumatra based on the K-nearest neighbors classifier",
        "authors": "HAZMIRA YOZZA, NINDI MAULA AZIZAH, LYRA YULIANTI, IZZATI RAHMI",
        "published": "2023-6-3",
        "citations": 0,
        "abstract": "The \"Sembako Program\" is a program carried out by the Indonesian government to improve the welfare of low-income communities. The purposes of this study are: (a) to determine the classification of households that deserve to receive basic-food assistance in Koto Panjang Payobasung, West Sumatra, using the KNN classifier and (b) to determine the optimal number of nearest neighbors used in the classification process. The measure of proximity between objects used is the Gower dissimilarity coefficient. This research used primary data consisting of 175 households collected purposively in a survey conducted on all households in Payobasung.  The optimal K value is determined by implementing a 5-fold cross-validation procedure. The result showed that the best classification process is when K = 3 nearest neighbors are used since it produces the highest accuracy coefficient and Mattews correlation coefficient (MCC). Therefore, for further work, in deciding the eligibility of a household to receive the Sembako Program in Payobasung, KNN can be used by considering its 3 nearest neighbors",
        "keywords": "",
        "link": "http://dx.doi.org/10.24815/jn.v23i2.29738"
    },
    {
        "id": 9086,
        "title": "Predicting Non-Performing Loan's Risk Level Using K-Means Clustering and K-Nearest Neighbors",
        "authors": "Muhammad Mizan Siregar, Roslina Roslina, B Herawan Hayadi",
        "published": "2023-3-5",
        "citations": 0,
        "abstract": "In data mining, clustering is an unsupervised learning technique often used to group data by similarity. Clustering, especially the K-means clustering algorithm, is a feasible tool for expanding a dataset label by increasing the cluster's number according to the label's categories. This research extends the credit loan label data set from two categories (non-performing and performing loans) to four risk levels (high risk, medium risk, low risk, and no risk). The combination of three K-nearest neighbor’s distance metrics, Euclidean, Manhattan, and Chebyshev distance, with four different K values (K = 3, K = 5, K = 7, and K = 9) produced the best model with accuracy, precision, and recall values of 90%, 90.53571%, and 90%, from the model using the Euclidean distance with K = 9.",
        "keywords": "",
        "link": "http://dx.doi.org/10.35842/icostec.v2i1.60"
    },
    {
        "id": 9087,
        "title": "Boosting cluster tree with reciprocal nearest neighbors scoring",
        "authors": "Wen-Bo Xie, Zhen Liu, Bin Chen, Jaideep Srivastava",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.engappai.2023.107438"
    },
    {
        "id": 9088,
        "title": "Applying <i>k</i>‐nearest neighbors to time series forecasting: Two new approaches",
        "authors": "Samya Tajmouati, Bouazza E. L. Wahbi, Adel Bedoui, Abdallah Abarda, Mohamed Dakkon",
        "published": "2024-2-25",
        "citations": 0,
        "abstract": "AbstractThe k‐nearest neighbors algorithm is one of the prominent techniques used in classification and regression. Despite its simplicity, the k‐nearest neighbors has been successfully applied in time series forecasting. However, the selection of the number of neighbors and feature selection is a daunting task. In this paper, we introduce two methodologies for forecasting time series that we refer to as Classical Parameters Tuning in Weighted Nearest Neighbors and Fast Parameters Tuning in Weighted Nearest Neighbors. The first approach uses classical parameters tuning that compares the most recent subsequence with every possible subsequence from the past of the same length. The second approach reduces the neighbors' search set, which leads to significantly reduced grid size and hence a lower computational time. To tune the models' parameters, both methods implement an approach inspired by cross‐validation for weighted nearest neighbors. We evaluate the forecasting performance and accuracy of our models. Then, we compare them to other approaches, especially, Seasonal Autoregressive Integrated Moving Average, Holt Winters, and Exponential Smoothing State Space Model. Real data examples on retail and food services sales in the United States and milk production in the United Kingdom are analyzed to demonstrate the application and efficiency of the proposed approaches.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/for.3093"
    },
    {
        "id": 9089,
        "title": "Intelligent Fat Predictor: Leveraging Linear Regression and K Nearest Neighbors in Obesity diseases.",
        "authors": "Mona Mohamed,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "One of the major lifestyle disorders brought on by unwholesome daily routines and inherited ailments is obesity and overweight. And this illness is a risk factor for a wide range of chronic illnesses, such as cancer, diabetes, metabolic syndrome, and cardiovascular conditions. Additionally, according to the World Health Organization (WHO), 30% of deaths worldwide will be caused by lifestyle illnesses by 2030. These deaths can be prevented by appropriately identifying and treating risk factors that relate to these diseases as well as by implementing behavioral engagement policies. Thence, the study is leveraging machine learning (ML) techniques for analyzing data and discovering new patterns for predicting body fat. The problem of predicting fat classifies as a regression, hence, we are deploying two regression techniques to deal with the regression dataset. These techniques are used linear regression (LR) and k nearest neighbors (KNN) which fall under umbral of ML. The two techniques are applied on real datasets. The dataset has 252 records. The results showed the LR has the highest score than the KNN model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54216/ijaaci.030101"
    },
    {
        "id": 9090,
        "title": "Histopathological image classification with unsupervised approaches using deep convolutional autoencoder and k-nearest neighbors",
        "authors": "Shamima Nasrin, Md. Zahangir Alom, Tarek M. Taha",
        "published": "2023-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3005188"
    },
    {
        "id": 9091,
        "title": "Wastewater pipe condition rating model using K- Nearest Neighbors",
        "authors": "Sai Nethra Betgeri, Shashank Reddy Vadyala, John C. Matthews, Mahboubeh Madadi, Greta Vladeanu",
        "published": "2023-2",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.tust.2022.104921"
    },
    {
        "id": 9092,
        "title": "Linear Regression and K Nearest Neighbors Machine Learning Models for Person Fat Forecasting",
        "authors": "Alshaimaa A. Tantawy,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "Predicting a person's person fat percentage is an important part of keeping tabs on their health and fitness. An accurate assessment of person fat allows for the development of individualized programmer for health and wellbeing, the promotion of illness prevention, and the evaluation of the efficacy of weight management initiatives. This study reviews the current state of the art in person fat prediction approaches, which includes the use of machine learning algorithms. Obesity is a chronic condition characterized by high levels of person fat and is linked to several health issues. Since several methods exist for estimating person fat percentage to evaluate obesity, these assessments are usually expensive and need specialized equipment. Therefore, determining obesity and its associated disorders requires an accurate estimate of person fat proportion according to readily available person measures. This paper presented a machine-learning model for forecasting person fat. This problem is a regression, so this paper used two regression models to deal with the regression dataset. This paper used linear regression (LR) and k nearest neighbors (KNN). The two models were applied to real datasets. The dataset has 252 records. The results showed the LR has the highest score than the KNN model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54216/ijaaci.030204"
    },
    {
        "id": 9093,
        "title": "KLASIFIKASI PENGGUNA HASHTAG PADA APLIKASI TIKTOK MENGGUNAKAN PERBANDINGAN METODE K-NEAREST NEIGHBORS DAN NAÏVE BAYES CLASSIFIER",
        "authors": "Moh. Aulia Miftakhurahmat, Nur Safitri, Putri Aulia Kusnadi, Chaerur Rozikin",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "Penelitian ini bertujuan untuk membandingkan penggunaan algoritma machine learning yaitu, K-Nearest Neighbors (KNN) dengan algoritma Naive Bayes classifier dalam memberikan rekomendasi hashtag untuk pengguna aplikasi TikTok. Dataset yang digunakan dalam penelitian ini adalah dataset hashtag TikTok yang diambil dari sebuah website yang berdasarkan dari setiap kategori. Pada penelitian ini dilakukan pemodelan dengan menggunakan algoritma K-Nearest Neighbors (KNN) dan Naive Bayes classifier untuk memprediksi hashtag yang sesuai untuk pengguna Tiktok berdasarkan pada hashtag yang sedang populer digunakan. Kemudian dilakukan evaluasi kinerja kedua metode dengan menggunakan precision, recall, f1 score dan  accuracy. Pada penelitian ini penulis akan membandingkan performa klasifikasi model yang telah dibuat menggunakan metode K-Nearest Neighbors dan Naive Bayes Classifier, tujuan perbandingan kinerja ini adalah untuk mempelajari metode mana yang memiliki kinerja terbaik dalam hal merekomendasikan penggunaan hashtag. Hasil dari penelitian ini menunjukan bahwa perbandingan dari kedua metode dapat memberikan klasifikasi rekomendasi hastag yang baik dengan nilai f1 score dan accuracy yang cukup tinggi.",
        "keywords": "",
        "link": "http://dx.doi.org/10.23960/jitet.v11i3.3150"
    },
    {
        "id": 9094,
        "title": "A link prediction method based on topological nearest-neighbors similarity in directed networks",
        "authors": "Feipeng Guo, Wei Zhou, Zifan Wang, Chunhua Ju, Shaobo Ji, Qibei Lu",
        "published": "2023-5",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jocs.2023.102002"
    },
    {
        "id": 9095,
        "title": "PENERAPAN METODE K-NEAREST NEIGHBORS (KNN) DALAM KLASIFIKASI GOLONGAN SIM DI DAERAH KABUPATEN MANOKWARI",
        "authors": "Ilham Luqman Hakim, Andi Saputra, Merlyn Florensia Sahetapi, Yansi Ratte, Anan Ansi Ahoren",
        "published": "2024-2-6",
        "citations": 0,
        "abstract": "SIM merupakan dokumen resmi yang dikeluarkan oleh otoritas pemerintahan dalam hal ini adalah Kepolisian yang diberikan kepada warga negara yang telah lulus dalam uji keterampilan dalam menggunakan kendaraan. Dengan memiliki SIM warga negara telah secara legal dan sah untuk mengendarai kendaraan di jalan raya. Namun di Kabupaten Manokwari untuk kepengurusan SIM masih tergolong sulit sebab kurang efisien nya sistem yang digunakan. Sehingga untuk meningkatkan efisiensi kepengurusan SIM salah satu cara yang dapat digunakan adalah klasifikasi data dengan metode K-Nearest Neighbors (KNN). Data pada penelitian ini diperoleh dari SATPAS Polresta Manokwari berupa data daftar peserta uji SIM di kota Manokwari. Tujuan utama dari penelitian ini yaitu meningkatkan akurasi dan efisiensi pengelolaan data SIM dengan menggunakan pola dan hubungan antar data berdasarkan prinsip kedekatan. Hasil klasifikasi yang dilakukan mendapat nilai akurasi tertinggi sebesar 68% dan nilai K = 46 dengan model KNN untuk klasifikasi nya adalah golongan SIM berdasarkan umur dan jenis permohonan. Dengan hasil yang telah diperoleh dapat memberi manfaat bahwa jika terdapat data baru yang masuk sistem akan langsung mengetahui masuk ke dalam jenis golongan SIM mana data yang baru saja masuk tersebut.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36040/jati.v7i6.8266"
    },
    {
        "id": 9096,
        "title": "Texture and Color Descriptor Features-based Vacant Parking Space Detection using K-Nearest Neighbors",
        "authors": "A F M Saifuddin Saif, Zainal Rasyid Mahayuddin",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14569/ijacsa.2024.0150203"
    },
    {
        "id": 9097,
        "title": "IDENTIFIKASI PENYAKIT DAUN APEL MENGGUNAKAN GLCM DAN HSV DENGAN METODE KNN (K-NEAREST NEIGHBORS)",
        "authors": "Fabian Safuddin Miqdad, Istiadi Istiadi, Aviv Yuniar Rahman",
        "published": "2023-12-30",
        "citations": 0,
        "abstract": "Peran teknologi informasi di segala bidang saat ini semakin meningkat, terutama dalam menunjang aktivitas inti pengguna. Sesuai dengan perkembangan teknologi, informasi seringkali menggunakan teknologi canggih, khususnya teknologi komputasi multimedia interaktif untuk mengolah data menjadi  informasi yang lebih berguna dan efektif. Apel adalah sumber fitokimia yang banyak dikonsumsi dan kaya, dan studi epidemiologi telah menghubungkan konsumsi apel dengan penurunan risiko beberapa kanker, penyakit kardiovaskular, asma, dan diabetes. Penyakit tanaman merupakan ketidak normalan pada tanaman yang dapat mengganggu pertumbuhan tanaman Apel. Penyakit pada tanaman dapat mempengaruhi perekonomian dan mengurangi kuantitas serta kualitas produksi pada pertanian Apel. Identifikasi sering dilakukan secara manual yaitu melihat objek secara langsung. Untuk itu sering memakan waktu sangat lama kurang efektif ketika jumlah data cukup banyak dengan  sumber daya tidak banyak. Namun diera sekarang ini perkembangan teknologi begitu cepat. Oleh karena itu akan melakukan penelitian dengan menggunakan HSV dan GLCM dengan metode KNN sebagai klasifikasi daun apel, identifikasi penyakit pada daun tanaman sejak dini dapat membantu untuk mencegah kerugian tanaman Apel. Pada penelitian ini menggunakan metode GLCM untuk ekstraksi ciri dan metode KNN untuk proses identifikasi penyakit daun apel menggunakan metode KNN. Tahapan identifikasi yaitu mengubah ukuran awal, konversi dari warna awal ke HSV, konversi warna HSV ke derajat keabuan, ekstraksi ciri metode GLCM dan diidentifikasi dengan metode KNN. Hasil pengujian yang dilakukan pada penelitian ini dengan nilai tertinggi untuk ekstraksi HSV mendapatkan nilai akurasi 75% dan untuk ekstraksi GLCM mendapatkan nilai akurasi 74%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.31328/ciastech.v6i1.5345"
    },
    {
        "id": 9098,
        "title": "Latin Hypercube Sampling Approach to Improve K-Nearest Neighbors Performance on Imbalanced Data",
        "authors": "Khairul Umam Syaliman, Adli Abdillah Nababan, Miftahul Jannah, Arif Hamied Nababan, Ryan Dhika Priyatna, Erwin Panggabean",
        "published": "2023-11-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icosnikom60230.2023.10364465"
    },
    {
        "id": 9099,
        "title": "Entropy and K-Nearest Neighbors-Based Feature Extraction for Bearing Fault Detection",
        "authors": "Sinta Uri El Hakim, Irfan Bahiuddin, Rokhmat Arifianto, Syahirul Alim Ritonga",
        "published": "2024-2-2",
        "citations": 0,
        "abstract": "Bearing failures in rotating machines can lead to significant operational challenges, causing up to 45-55% of engine failures and severely impacting performance and productivity. Timely detection of bearing anomalies is crucial to prevent machine failures and associated downtime. Therefore, an approach for early bearing failure detection using entropy-based machine learning is proposed and evaluated while combined with a classifier based on K-Nearest Neighbors (KNN) and Support Vector Machine (SVM). Entropy-based feature extraction should be able to effectively capture the intricate patterns and variations present in the vibration signals, providing a comprehensive representation of the underlying dynamics. The results of the classification carried out by KNN-Entropy have an accuracy value of 98%, while the SVM-Entropy model has an accuracy of 96%. Hence, the Entropy-based feature extraction giving the best accuracy when it is coupled with KNN.",
        "keywords": "",
        "link": "http://dx.doi.org/10.22219/kinetik.v9i1.1814"
    },
    {
        "id": 9100,
        "title": "Face Gender Classification by Using Improve Binary Particle Swarm Optimization and K-Nearest Neighbors",
        "authors": " Minh Ly Duc,  Dong Phan Tan",
        "published": "2023",
        "citations": 0,
        "abstract": "This paper studies the application of the Binary particle swarm optimization (BPSO) algorithm to the optimal search for facial features and gender classification by K-Nearest Neighbors (K-NN) model. The results show that the accuracy and processing time of the model is much better than that of VGG16, VGG19, Resnet50, Senet50, Face Net, Open Face and FbDeep Face models. a large-scale GenderFace80K dataset with 80,000 facial images with gender annotation used in the research model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.46647/ijetms.2023.v07i05.031"
    },
    {
        "id": 9101,
        "title": "Perbandingan K-Nearest Neighbors, Support Vector Dan Random Forest Pada Prediksi Medical Cost",
        "authors": " Anggista Oktavia Praneswara",
        "published": "2023-8-30",
        "citations": 0,
        "abstract": "Asuransi kesehatan adalah kontrak yang mengharuskan membayar sebagian atau seluruh biaya perawatan terkait masalah kesehatan yang dialami. Pengguna asuransi harus membayar premi dengan membayar iuran dalam periode yang telah ditentukan. Dalam praktiknya, pembayaran premi asuransi kesehatan bisa langsung dipotong dari gaji bulanan yang didapat. Maka dari itu, penelitian ini dilakukan dengan mengimplementasikan sebuah algoritma prediksi biaya medis yang dikeluarkan per individu dengan menggunakan perbandingan 3 algoritma yaitu K-Nearest Neighbor, Support Vector Machine dan Random Forest dengan dataset yang diambil kaggle dengan nama insurance.csv berdasarkan kolom usia, jenis kelamin, indeks Massa Tubuh ( BMI ), jumlah anak dalam satu keluarga, individu perokok atau tidak, wilayah tempat tinggal penerima asuransi kesehatan dan biaya medis yang ditanggung oleh asuransi kesehatan. Metode penelitian dilakukan dengan pemeriksaan data dengan melakukan analisi pada dataset serta membagi data menjadi data training dan data test. Hasil penelitian pada algoritma KNN memiliki nilai prediksi MSE sebesar 9651.5, algoritma Random Forest memiliki nilai prediksi MSE sebesar 9755.4, sedangkan algoritma SVM memiliki nilai prediksi MSE sebesar 9312.6.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33022/ijcs.v12i4.3298"
    },
    {
        "id": 9102,
        "title": "K-nearest neighbors for the automatic discrimination of alpha, beta and gamma rays in a phoswich detector",
        "authors": "Y. Morishita, Y. Kitayama",
        "published": "2023-11-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nssmicrtsd49126.2023.10338057"
    },
    {
        "id": 9103,
        "title": "Accuracy Improvement of Flooded Area Detection from Satellite Images using Novel K-Nearest Neighbors in Comparison with Support Vector Machine",
        "authors": "Cheruvupalli Vamsi, V. Amudha, Soundharyaa Shri Harini. R",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/accai58221.2023.10199536"
    },
    {
        "id": 9104,
        "title": "A Comparative Analysis Of Logistic Regression and K-Nearest Neighbors Algorithms In Diagnosis Of Diabetes",
        "authors": "Hasan Mahdi Mahi, Adeeb Shahriar Zaman",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "Machine Learning techniques have gained prominence in medical diagnosis due to their ability to uncover patterns in complex data-sets, thereby giving accurate disease classification. In this study, we mainly focus on the application of two widely used Machine Learning algorithms, Logistic Regression and K-Nearestneighbors( KNN), for the purpose of distinguishing patients with diabetes from those without. Our research aims to shed light on the comparative accuracy and performance of these algorithms in a medical context. The methodology section outlines experimental setup, detailing data processing, algorithm training and testing procedures. A comprehensive data-set comprising medical attributes is utilized for evaluation and accuracy metrics are employed to quantify the performance of the algorithms. Results has shown efficacy of both the algorithms and our findings showcase the strengths and limitations of each approach, contributing on the applicability in medical decision making. By offering a nuanced comparison, we illuminate a path for more robust and accurate disease identification techniques, further enhancing patient care and medical outcomes.\nGANIT J. Bangladesh Math. Soc. 43.1 (2023) 01- 07",
        "keywords": "",
        "link": "http://dx.doi.org/10.3329/ganit.v43i2.70794"
    }
]