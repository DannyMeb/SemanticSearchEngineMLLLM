[
    {
        "id": 11305,
        "title": "Semantic Properties of Cosine Based Bias Scores for Word Embeddings",
        "authors": "Sarah Schröder, Alexander Schulz, Fabian Hinder, Barbara Hammer",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012577200003654"
    },
    {
        "id": 11306,
        "title": "Analysis of the Semantic Shift in Diachronic Word Embeddings for Spanish Before and After COVID-19",
        "authors": "Esteban Rodríguez Betancourt, Edgar Casasola Murillo",
        "published": "2023-9-21",
        "citations": 0,
        "abstract": "Words can shift their meaning across time. This study shows the results obtained by the exploratory analysis of the semantic shifting on Spanish vocabulary using Diachronic Word Embeddings. Diachronic data consists of a 2018 Spanish corpus, before the COVID-19 outbreak, and a second corpus with documents from 2021. This paper addresses the construction of the diachronic Spanish word embeddings model, as well as the results obtained by the analysis using a non-supervised distance vector technique. The results allowed us to identify topics with the most semantic shift between those periods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.19153/cleiej.26.2.4"
    },
    {
        "id": 11307,
        "title": "Word Embeddings and Semantic Spaces in Natural Language Processing",
        "authors": "Peter J. Worth",
        "published": "2023",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.4236/ijis.2023.131001"
    },
    {
        "id": 11308,
        "title": "Leveraging Multilingual Transfer for Unsupervised Semantic Acoustic Word Embeddings",
        "authors": "Christiaan Jacobs, Herman Kamper",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/lsp.2023.3347154"
    },
    {
        "id": 11309,
        "title": "Understanding and Creating Word Embeddings",
        "authors": "Avery Blankenship, Sarah Connell, Quinn Dombrowski",
        "published": "2024-1-31",
        "citations": 0,
        "abstract": "\n            Word embeddings allow you to analyze the usage of different terms in a corpus of texts by capturing information about their contextual usage. Through a primarily theoretical lens, this lesson will teach you how to prepare a corpus and train a word embedding model. You will explore how word vectors work, how to interpret them, and how to answer humanities research questions using them.\n          ",
        "keywords": "",
        "link": "http://dx.doi.org/10.46430/phen0116"
    },
    {
        "id": 11310,
        "title": "Clustering and Visualising Documents using Word Embeddings",
        "authors": "Jonathan Reades, Jennie Williams",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "\n            This lesson uses word embeddings and clustering algorithms in Python to identify groups of similar documents in a corpus of approximately 9,000 academic abstracts. It will teach you the basics of dimensionality reduction for extracting structure from a large corpus and how to evaluate your results.\n          ",
        "keywords": "",
        "link": "http://dx.doi.org/10.46430/phen0111"
    },
    {
        "id": 11311,
        "title": "OPI at SemEval-2023 Task 1: Image-Text Embeddings and Multimodal Information Retrieval for Visual Word Sense Disambiguation",
        "authors": "Slawomir Dadas",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.semeval-1.22"
    },
    {
        "id": 11312,
        "title": "UoR-NCL at SemEval-2023 Task 1: Learning Word-Sense and Image Embeddings for Word Sense Disambiguation",
        "authors": "Thanet Markchom, Huizhi Liang, Joyce Gitau, Zehao Liu, Varun Ojha, Lee Taylor, Jake Bonnici, Abdullah Alshadadi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.semeval-1.3"
    },
    {
        "id": 11313,
        "title": "Contextualized vs. Static Word Embeddings for Word-based Analysis of Opposing Opinions",
        "authors": "Wassakorn Sarakul, Attapol T. Rutherford",
        "published": "2023-6-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/jcsse58229.2023.10202014"
    },
    {
        "id": 11314,
        "title": "Semantic Interest Modeling and Content-Based Scientific Publication Recommendation Using Word Embeddings and Sentence Encoders",
        "authors": "Mouadh Guesmi, Mohamed Amine Chatti, Lamees Kadhim, Shoeb Joarder, Qurat Ul Ain",
        "published": "2023-9-15",
        "citations": 0,
        "abstract": "The fast growth of data in the academic field has contributed to making recommendation systems for scientific papers more popular. Content-based filtering (CBF), a pivotal technique in recommender systems (RS), holds particular significance in the realm of scientific publication recommendations. In a content-based scientific publication RS, recommendations are composed by observing the features of users and papers. Content-based recommendation encompasses three primary steps, namely, item representation, user modeling, and recommendation generation. A crucial part of generating recommendations is the user modeling process. Nevertheless, this step is often neglected in existing content-based scientific publication RS. Moreover, most existing approaches do not capture the semantics of user models and papers. To address these limitations, in this paper we present a transparent Recommendation and Interest Modeling Application (RIMA), a content-based scientific publication RS that implicitly derives user interest models from their authored papers. To address the semantic issues, RIMA combines word embedding-based keyphrase extraction techniques with knowledge bases to generate semantically-enriched user interest models, and additionally leverages pretrained transformer sentence encoders to represent user models and papers and compute their similarities. The effectiveness of our approach was assessed through an offline evaluation by conducting extensive experiments on various datasets along with user study (N = 22), demonstrating that (a) combining SIFRank and SqueezeBERT as an embedding-based keyphrase extraction method with DBpedia as a knowledge base improved the quality of the user interest modeling step, and (b) using the msmarco-distilbert-base-tas-b sentence transformer model achieved better results in the recommendation generation step.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/mti7090091"
    },
    {
        "id": 11315,
        "title": "SexWEs: Domain-Aware Word Embeddings via Cross-Lingual Semantic Specialisation for Chinese Sexism Detection in Social Media",
        "authors": "Aiqi Jiang, Arkaitz Zubiaga",
        "published": "2023-6-2",
        "citations": 2,
        "abstract": "The goal of sexism detection is to mitigate negative online content targeting certain gender groups of people. However, the limited availability of labeled sexism-related datasets makes it problematic to identify online sexism for low-resource languages.\nIn this paper, we address the task of automatic sexism detection in social media for one low-resource language -- Chinese. Rather than collecting new sexism data or building cross-lingual transfer learning models, we develop a cross-lingual domain-aware semantic specialisation system in order to make the most of existing data. Semantic specialisation is a technique for retrofitting pre-trained distributional word vectors by integrating external linguistic knowledge (such as lexico-semantic relations) into the specialised feature space. To do this, we leverage semantic resources for sexism from a high-resource language (English) to specialise pre-trained word vectors in the target language (Chinese) to inject domain knowledge. We demonstrate the benefit of our sexist word embeddings (SexWEs) specialised by our framework via intrinsic evaluation of word similarity and extrinsic evaluation of sexism detection. Compared with other specialisation approaches and Chinese baseline word vectors, our SexWEs shows an average score improvement of 0.033 and 0.064 in both intrinsic and extrinsic evaluations, respectively. The ablative results and visualisation of SexWEs also prove the effectiveness of our framework on retrofitting word vectors in low-resource languages.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1609/icwsm.v17i1.22159"
    },
    {
        "id": 11316,
        "title": "Word embeddings for protein sequence analysis",
        "authors": "Ana Marta Sequeira, Ivan Gomes, Miguel Rocha",
        "published": "2023-8-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cibcb56990.2023.10264897"
    },
    {
        "id": 11317,
        "title": "Word and Image Embeddings in Pill Recognition",
        "authors": "Richárd Rádli, Zsolt Vörösházi, László Czúni",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012460800003660"
    },
    {
        "id": 11318,
        "title": "Competing Views of Word Meaning: Word Embeddings and Word Senses",
        "authors": "Gregory Grefenstette, Patrick Hanks",
        "published": "2023-6-2",
        "citations": 0,
        "abstract": "Abstract\nAt least since the invention of writing, people have been troubled by the problem of what a word means. Dictionaries have traditionally been written with numbered word senses, giving the impression that the different senses of a word are fixed abstract entities, which can be used to separate usages into neat piles according to their different meanings. Adam Kilgarriff’s daring 1997 article ‘I Don’t Believe in Word Senses’ challenged this traditional view of word meaning, presenting an account in which ‘the basic units are occurrences of the word in context’. Kilgarriff went on to develop the Sketch Engine, a statistical tool that enables lexicographers and NLP researchers, teachers, and students to explore the relationship between meanings and collocations (words and their contexts). In this review article, we compare the information provided by Kilgarriff’s Word Sketches with the recently developed Word Embedding techniques and with the results of Corpus Pattern Analysis.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1093/ijl/ecad005"
    },
    {
        "id": 11319,
        "title": "A comparison of multiple word embeddings and performance analysis",
        "authors": "Jinghua Wang, Zhongtian Lin",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "Based on IMDB data sets for sentiment analysis, this research evaluates the performance of two types of neural networks, namely FNN and BERT. According to the experimental findings, both varieties of neural networks performed well (over 80%) on IMDB data sets. BERT performs the best of them all. The version of FNN improves when the number of layers is increased. The causes behind BERT's outstanding performance are then further examined in this research. In this article, it is hypothesized that a few factors, such as feature extraction capability and classification capability, account for BERT's exceptional performance. The results show that for the two coupling variables of BERT assumed in this paper, including feature extraction and classification ability, BERT has obvious advantages in feature extracting, and its classification ability has certain advantages over SVM and MLP. The deep learning model has achieved excellent performance in the sentiment classification task. The next step of this paper will focus on the robustness of the BERT model in sentiment analysis.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/6/20230719"
    },
    {
        "id": 11320,
        "title": "Reactions to science communication: discovering social network topics using word embeddings and semantic knowledge",
        "authors": "Bernardo Cerqueira de Lima, Renata Maria Abrantes Baracho, Thomas Mandl, Patricia Baracho Porto",
        "published": "2023-9-22",
        "citations": 0,
        "abstract": "AbstractSocial media platforms that disseminate scientific information to the public during the COVID-19 pandemic highlighted the importance of the topic of scientific communication. Content creators in the field, as well as researchers who study the impact of scientific information online, are interested in how people react to these information resources. This study aims to devise a framework that can sift through large social media datasets and find specific feedback to content delivery, enabling scientific content creators to gain insights into how the public perceives scientific information, and how their behavior toward science communication (e.g., through videos or texts) is related to their information-seeking behavior. To collect public reactions to scientific information, the study focused on Twitter users who are doctors, researchers, science communicators, or representatives of research institutes, and processed their replies for two years from the start of the pandemic. The study aimed in developing a solution powered by topic modeling enhanced by manual validation and other machine learning techniques, such as word embeddings, that is capable of filtering massive social media datasets in search of documents related to reactions to scientific communication. The architecture developed in this paper can be replicated for finding any documents related to niche topics in social media data.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13278-023-01125-5"
    },
    {
        "id": 11321,
        "title": "Content-Based Recommender System using Word Embeddings for Pedagogical Resources",
        "authors": "Chahrazed Mediani, Saad Harous, Mahieddine Djoudi",
        "published": "2023-10-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/pais60821.2023.10321989"
    },
    {
        "id": 11322,
        "title": "A method for constructing word sense embeddings based on word sense induction",
        "authors": "Yujia Sun, Jan Platoš",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "AbstractPolysemy is an inherent characteristic of natural language. In order to make it easier to distinguish between different senses of polysemous words, we propose a method for encoding multiple different senses of polysemous words using a single vector. The method first uses a two-layer bidirectional long short-term memory neural network and a self-attention mechanism to extract the contextual information of polysemous words. Then, a K-means algorithm, which is improved by optimizing the density peaks clustering algorithm based on cosine similarity, is applied to perform word sense induction on the contextual information of polysemous words. Finally, the method constructs the corresponding word sense embedded representations of the polysemous words. The results of the experiments demonstrate that the proposed method produces better word sense induction than Euclidean distance, Pearson correlation, and KL-divergence and more accurate word sense embeddings than mean shift, DBSCAN, spectral clustering, and agglomerative clustering.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-023-40062-3"
    },
    {
        "id": 11323,
        "title": "Simplify: Automatic Arabic Sentence Simplification using Word Embeddings",
        "authors": "Yousef SalahEldin, Caroline Sabty",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.arabicnlp-1.35"
    },
    {
        "id": 11324,
        "title": "Enc-Dec RNN Acoustic Word Embeddings learned via Pairwise Prediction",
        "authors": "Adhiraj Banerjee, Vipul Arora",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-483"
    },
    {
        "id": 11325,
        "title": "Representation of Semantic Word Embeddings Based on SLDA and Word2vec Model",
        "authors": "Tang Huanling, Zhu Hui, Wei Hongmin, Zheng Han, Mao Xueli, Lu Mingyu, Guo Jin",
        "published": "2023-5",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/cje.2021.00.113"
    },
    {
        "id": 11326,
        "title": "Comparative Analysis of Word Embeddings for Multiclass Cyberbullying Detection",
        "authors": "Azhi Faraj, Semih Utku",
        "published": "2024-2-20",
        "citations": 0,
        "abstract": "Cyberbullying has emerged as a pervasive concern in modern society, particularly within social media platforms. This phenomenon encompasses employing digital communication to instill fear, threaten, harass, or harm individuals. Given the prevalence of social media in our lives, there is an escalating need for effective methods to detect and combat cyberbullying. This paper aims to explore the utilization of word embeddings and to discern the comparative effectiveness of trainable word embeddings, pre-trained word embeddings, and fine-tuned language models in multiclass cyberbullying detection. Distinguishing from previous binary classification methods, our research delves into nuanced multiclass detection. The exploration of word embeddings holds significant promise due to its ability to transform words into dense numerical vectors within a high-dimensional space. This transformation captures intricate semantic and syntactic relationships inherent in language, enabling machine learning (ML) algorithms to discern patterns that might signify cyberbullying. In contrast to previous research, this work delves beyond primary binary classification and centers on the nuanced realm of multiclass cyberbullying detection. The research employs diverse techniques, including convolutional neural networks and bidirectional long short-term memory, alongside well-known pre-trained models such as word2vec and bidirectional encoder representations from transformers (BERT). Moreover, traditional ML algorithms such as K-nearest neighbors, Random Forest, and Naïve Bayes are integrated to evaluate their performance vis-à-vis deep learning models. The findings underscore the promise of a fine-tuned BERT model on our dataset, yielding the most promising results in multiclass cyberbullying detection, and achieving the best-recorded accuracy of 85% on the dataset.",
        "keywords": "",
        "link": "http://dx.doi.org/10.21928/uhdjst.v8n1y2024.pp55-63"
    },
    {
        "id": 11327,
        "title": "Enhanced sentiment analysis based on improved word embeddings and XGboost",
        "authors": "Amina Samih, Abderrahim Ghadi, Abdelhadi Fennan",
        "published": "2023-4-1",
        "citations": 1,
        "abstract": "<span lang=\"EN-US\">Sentiment analysis is a well-known and rapidly expanding study topic in natural language processing (NLP) and text classification. This approach has evolved into a critical component of many applications, including politics, business, advertising, and marketing. Most current research focuses on obtaining sentiment features through lexical and syntactic analysis. Word embeddings explicitly express these characteristics. This article proposes a novel method, improved words vector for sentiments analysis (IWVS), using XGboost to improve the F1-score of sentiment classification. The proposed method constructed sentiment vectors by averaging the word embeddings (Sentiment2Vec). We also investigated the Polarized lexicon for classifying positive and negative sentiments. The sentiment vectors formed a feature space to which the examined sentiment text was mapped to. Those features were input into the chosen classifier (XGboost). We compared the F1-score of sentiment classification using our method via different machine learning models and sentiment datasets. We compare the quality of our proposition to that of baseline models, term frequency-inverse document frequency (TF-IDF) and Doc2vec, and the results show that IWVS performs better on the F1-measure for sentiment classification. At the same time, XGBoost with IWVS features was the best model in our evaluation.</span>",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijece.v13i2.pp1827-1836"
    },
    {
        "id": 11328,
        "title": "Joining LDA and Word Embeddings for Covid-19 Topic Modeling on English and Arabic Data",
        "authors": "Amina Amara, Mohamed Ali Hadj Taieb, Mohamed Ben Aouicha",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012320900003636"
    },
    {
        "id": 11329,
        "title": "Which Word Embeddings for Modeling Web Search Queries? Application to the Study of Search Strategies",
        "authors": "Claire Ibarboure, Ludovic Tanguy, Franck Amadieu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012177600003598"
    },
    {
        "id": 11330,
        "title": "Effectiveness of ELMo embeddings, and semantic models in predicting review helpfulness",
        "authors": "Muhammad Shahid Iqbal Malik, Aftab Nawaz, Mona Mamdouh Jamjoom, Dmitry I. Ignatov",
        "published": "2023-11-16",
        "citations": 1,
        "abstract": "Online product reviews (OPR) are a commonly used medium for consumers to communicate their experiences with products during online shopping. Previous studies have investigated the helpfulness of OPRs using frequency-based, linguistic, meta-data, readability, and reviewer attributes. In this study, we explored the impact of robust contextual word embeddings, topic, and language models in predicting the helpfulness of OPRs. In addition, the wrapper-based feature selection technique is employed to select effective subsets from each type of features. Five feature generation techniques including word2vec, FastText, Global Vectors for Word Representation (GloVe), Latent Dirichlet Allocation (LDA), and Embeddings from Language Models (ELMo), were employed. The proposed framework is evaluated on two Amazon datasets (Video games and Health & personal care). The results showed that the ELMo model outperformed the six standard baselines, including the fine-tuned Bidirectional Encoder Representations from Transformers (BERT) model. In addition, ELMo achieved Mean Square Error (MSE) of 0.0887 and 0.0786 respectively on two datasets and MSE of 0.0791 and 0.0708 with the wrapper method. This results in the reduction of 1.43% and 1.63% in MSE as compared to the fine-tuned BERT model on respective datasets. However, the LDA model has a comparable performance with the fine-tuned BERT model but outperforms the other five baselines. The proposed framework demonstrated good generalization abilities by uncovering important factors of product reviews and can be evaluated on other voting platforms.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/ida-230349"
    },
    {
        "id": 11331,
        "title": "Reason-able embeddings: Learning concept embeddings with a transferable neural reasoner",
        "authors": "Dariusz Max Adamski, Jędrzej Potoniec",
        "published": "2023-6-2",
        "citations": 0,
        "abstract": "We present a novel approach for learning embeddings of ALC knowledge base concepts. The embeddings reflect the semantics of the concepts in such a way that it is possible to compute an embedding of a complex concept from the embeddings of its parts by using appropriate neural constructors. Embeddings for different knowledge bases are vectors in a shared vector space, shaped in such a way that approximate subsumption checking for arbitrarily complex concepts can be done by the same neural network, called a reasoner head, for all the knowledge bases. To underline this unique property of enabling reasoning directly on embeddings, we call them reason-able embeddings. We report the results of experimental evaluation showing that the difference in reasoning performance between training a separate reasoner head for each ontology and using a shared reasoner head, is negligible.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/sw-233355"
    },
    {
        "id": 11332,
        "title": "Resume Analysis in Portuguese using Word Embeddings: Development of a Decision Support System for Candidate Selection",
        "authors": "Manoel Garcia de Sousa Neto, Filipe Saraiva",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "Este estudo propõe o uso de word embeddings para analisar e comparar currículos em português com descrições para vagas de emprego. Apresenta o desenvolvimento de um sistema de suporte à decisão que identifica a adequação dos candidatos com base em sua experiência profissional. O estudo utiliza diferentes modelos de word embeddings, como Word2Vec, Wang2Vec, FastText e GloVe, para gerar representações numéricas de palavras em currículos e descrições de empregos, a fim de avaliar o desempenho desses modelos no contexto da língua portuguesa. A pesquisa tem como objetivo auxiliar na análise de currículos e aprimorar a precisão dos processos de seleção de candidatos.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5753/eniac.2023.234609"
    },
    {
        "id": 11333,
        "title": "Dom2Vec - Detecting DGA Domains Through Word Embeddings and AI/ML-Driven Lexicographic Analysis",
        "authors": "L. Torrealba Aravena, P. Casas, J. Bustos-Jiménez, G. Capdehourat, M. Findrik",
        "published": "2023-10-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/cnsm59352.2023.10327913"
    },
    {
        "id": 11334,
        "title": "Clustering experiments with the Astro benchmarking data set with semantic document embeddings – off-the-shelf vs. custom embeddings created from citations, text, and both",
        "authors": "Paul Donner",
        "published": "2023-5-19",
        "citations": 0,
        "abstract": "What accounts for the observed better quality of publication-level topical science clustering solutions which use only citation relations as input data, compared to those using sophisticated semantic similarity data derived from both citations and textual terms? A survey of empirical work relevant to the concept of unconscientious referencing practices indicates that purely citation-based methods should be affected by significant ‘citation noise’, unlike text-based methods. This study continues work with the Astro benchmarking data set for bibliometric clustering by applying semantic representation learning techniques to scientific documents in order to isolate the clustering performance difference between direct citations and textual terms. We investigate variants of Random Indexing embeddings learned on this data set and one pre-trained off-the-shelf semantic document embedding, SPECTER. The evaluation is performed with four previously introduced validation data sets but using a newly suggested clustering evaluation measure.",
        "keywords": "",
        "link": "http://dx.doi.org/10.55835/643fed628e529cfebf33f797"
    },
    {
        "id": 11335,
        "title": "SCALE: Semantic Code Analysis via Learned Embeddings",
        "authors": "Jason Abohwo, Ojas Nimase, Paul Zhou, Kyle Liu, Nathan Zhang, Diego Almanza, Avi Mehra, Michael Lutz",
        "published": "2023-11-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icoabcd59879.2023.10390981"
    },
    {
        "id": 11336,
        "title": "Email Phishing Detection with BLSTM and Word Embeddings",
        "authors": "Rafał Wolert, Mariusz Rawski",
        "published": "2023-6-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.24425/ijet.2023.146496"
    },
    {
        "id": 11337,
        "title": "Sentiment Analysis for Patient Reviews in Hospitals by CNN and LSTM Neural Networks Using Pretrained Word Embeddings",
        "authors": "Turan Goktug Altundogan, Mehmet Karakose, Sümeyye Yılmazer, Eray Hanoğlu, Sedef Demirel",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/asyu58738.2023.10296829"
    },
    {
        "id": 11338,
        "title": "eBLEU: Unexpectedly Good Machine Translation Evaluation Using Simple Word Embeddings",
        "authors": "Muhammad ElNokrashy, Tom Kocmi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.wmt-1.61"
    },
    {
        "id": 11339,
        "title": "Beyond word embeddings: A survey",
        "authors": "Francesca Incitti, Federico Urli, Lauro Snidaro",
        "published": "2023-1",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.inffus.2022.08.024"
    },
    {
        "id": 11340,
        "title": "Enhancing Semantic Understanding by Visualizing Sentence-Level Embeddings",
        "authors": "Akshata Upadhye",
        "published": "2023-11-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5120/ijca2023923275"
    },
    {
        "id": 11341,
        "title": "Representing affect information in word embeddings",
        "authors": "Yuhan Zhang, Wenqi Chen, Ruihan Zhang, Xiajie Zhang",
        "published": "2023-1-27",
        "citations": 1,
        "abstract": "A growing body of research in natural language processing (NLP) and natural language understanding (NLU) is investigating human-like knowledge learned or encoded in the word embeddings from large language models. This is a step towards understanding what knowledge language models capture that resembles human understanding of language and communication. Here, we investigated whether and how the affect meaning of a word (i.e., valence, arousal, dominance) is encoded in word embeddings pre-trained in large neural networks. We used the human-labeled dataset (Mohammad 2018) as the ground truth and performed various correlational and classification tests on four types of word embeddings. The embeddings varied in being static or contextualized, and how much affect specific information was prioritized during the pre-training and fine-tuning phase. Our analyses show that word embedding from the vanilla BERT model (Devlin et al. 2019) did not saliently encode the affect information of English words. Only when the BERT model was fine-tuned on emotion related tasks or contained extra contextualized information from emotion-rich contexts could the corresponding embedding encode more relevant affect information.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3765/elm.2.5391"
    },
    {
        "id": 11342,
        "title": "Acoustic Word Embeddings for Untranscribed Target Languages with Continued Pretraining and Learned Pooling",
        "authors": "Ramon Sanabria, Ondřej Klejch, Hao Tang, Sharon Goldwater",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-268"
    },
    {
        "id": 11343,
        "title": "Deriving Translational Acoustic Sub-Word Embeddings",
        "authors": "Amit Meghanani, Thomas Hain",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/asru57964.2023.10389747"
    },
    {
        "id": 11344,
        "title": "Unsupervised Semantic Variation Prediction using the Distribution of Sibling Embeddings",
        "authors": "Taichi Aida, Danushka Bollegala",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.429"
    },
    {
        "id": 11345,
        "title": "GARI: Graph Attention for Relative Isomorphism of Arabic Word Embeddings",
        "authors": "Muhammad Ali, Maha Alshmrani, Jianbin Qin, Yan Hu, Di Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.arabicnlp-1.16"
    },
    {
        "id": 11346,
        "title": "Using Domain-Specific Word Embeddings to Examine the Demand for Skills",
        "authors": "Sugat Chaturvedi, Kanika Mahajan, Zahra Siddique",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4634499"
    },
    {
        "id": 11347,
        "title": "A Place Recommendation Approach Using Word Embeddings in Conceptual Spaces",
        "authors": "Omid R. Abbasi, Ali A. Alesheikh",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3241806"
    },
    {
        "id": 11348,
        "title": "Group-Sparse Matrix Factorization for Transfer Learning of Word Embeddings",
        "authors": "Kan Xu, Xuanyi Zhao, Hamsa Bastani, Osbert Bastani",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4730050"
    },
    {
        "id": 11349,
        "title": "ChatGPT-EDSS: Empathetic Dialogue Speech Synthesis Trained from ChatGPT-derived Context Word Embeddings",
        "authors": "Yuki Saito, Shinnosuke Takamichi, Eiji Iimori, Kentaro Tachibana, Hiroshi Saruwatari",
        "published": "2023-8-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1095"
    },
    {
        "id": 11350,
        "title": "Deep neural networks and weighted word embeddings for sentiment analysis of drug product reviews",
        "authors": "Derwin Suhartono, Kartika Purwandari, Nicholaus Hendrik Jeremy, Samuel Philip, Panji Arisaputra, Ivan Halim Parmonangan",
        "published": "2023",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.procs.2022.12.182"
    },
    {
        "id": 11351,
        "title": "「マスクされた単語埋め込みと2段階クラスタリングを用いた動詞の意味フレーム推定」の解説",
        "authors": "Kosuke Yamada",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5715/jnlp.30.827"
    },
    {
        "id": 11352,
        "title": "Exploring Word Embeddings for Text Classification: A Comparative Analysis",
        "authors": " Satya Mohan Chowdary G,  T Ganga Bhavani,  D Konda Babu,  B Prasanna Rani,  K Sireesha",
        "published": "2023",
        "citations": 0,
        "abstract": "For language tasks like text classification and sequence labeling, word embeddings are essential for providing input characteristics in deep models. There have been many word embedding techniques put out in the past ten years, which can be broadly divided into classic and context-based embeddings. In this study, two encoders—CNN and BiLSTM—are used in a downstream network architecture to analyze both forms of embeddings in the context of text classification. Four benchmarking classification datasets with single-label and multi-label tasks and a range of average sample lengths are selected in order to evaluate the effects of word embeddings on various datasets. CNN routinely beats BiLSTM, especially on datasets that don't take document context into account, according to the evaluation results with confidence intervals. CNN is therefore advised above BiLSTM for datasets involving document categorization where context is less predictive of class membership. Concatenating numerous classic embeddings or growing their size for word embeddings doesn't greatly increase performance, while there are few instances when there are marginal gains. Contrarily, context-based embeddings like ELMo and BERT are investigated, with BERT showing better overall performance, particularly for longer document datasets. On short datasets, both context-based embeddings perform better, but on longer datasets, no significant improvement is seen.In conclusion, this study emphasizes the significance of word embeddings and their impact on downstream tasks, highlighting the advantages of BERT over ELMo, especially for lengthier documents, and CNN over BiLSTM for certain scenarios involving document classification.",
        "keywords": "",
        "link": "http://dx.doi.org/10.46647/ijetms.2023.v07i05.007"
    },
    {
        "id": 11353,
        "title": "Exploring Afrikaans word embeddings with analogies and nearest neighbours",
        "authors": "Tanja Gaustad, Roald Eiselen",
        "published": "2023-1-26",
        "citations": 0,
        "abstract": "This paper presents an exploration of word embeddings for Afrikaans using the analogies and nearest neighbours methodologies. We compare the results on three types of embeddings (fastText, FLAIR and GloVe) on a novel analogy data set for Afrikaans, inspired by the Bigger Analogy Test Set: BATS (Gladkova et al. 2016). Our analysis shows that for Afrikaans, similar to English, the types of embeddings influence the quality of analogies found for different linguistic tasks. Our investigation also demonstrates, however, that these Afrikaans embeddings do not encode as clear a linguistic representation as with English embeddings. The exact reason for this is subject to future work, but the added morphological complexity and the lack of data most likely play a role.",
        "keywords": "",
        "link": "http://dx.doi.org/10.55492/dhasa.v4i01.4443"
    },
    {
        "id": 11354,
        "title": "Evaluation of Stacked Embeddings for Arabic Word Sense Disambiguation",
        "authors": "Rim Laatar, Chafik Aloulou, Lamia Hadrich Belguith",
        "published": "2023-6-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.13053/cys-27-2-4281"
    },
    {
        "id": 11355,
        "title": "Emotion Label Encoding Using Word Embeddings for Speech Emotion Recognition",
        "authors": "Eimear Stanley, Eric DeMattos, Anita Klementiev, Piotr Ozimek, Georgia Clarke, Michael Berger, Dimitri Palaz",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1591"
    },
    {
        "id": 11356,
        "title": "Quality of word and concept embeddings in targetted biomedical domains",
        "authors": "Salvatore Giancani, Riccardo Albertoni, Chiara Eva Catalano",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.heliyon.2023.e16818"
    },
    {
        "id": 11357,
        "title": "Analysis of Musytarak Al-Lafdzi the Word “Kutiba” in the Qur'an: A Study of Semantic Analysis",
        "authors": "Hima Roiku Dinia, Unzilatun Nikmah, Nur Ila Ifawati",
        "published": "2024-1-31",
        "citations": 0,
        "abstract": "The diversity of meanings in Musytarak lands in the Al-Qur'an is a challenge in the translation process, which causes ambiguity and the potential for multiple understandings if it needs to be translated or understood correctly. An example is lafadz, \"kutiba,\" which has various meanings in the Qur'an that are very different from the original. This research aims to identify the meaning of the mustard lafdzi phenomenon, especially the lafadz “khutba\" in the Al-Qur'an. This research is descriptive and qualitative using the literature review method. The data in this research comes from the Al-Qur'an, translations from several sources, and scientific works in relevant journals or books. The data was then analyzed descriptively to conclude a brief description. This research shows that Lafadz khutba is a lafa lafdzi repeated 11 times in the Koran and has several meanings. Lafadz kutiba means furidha (Required) found in Surah Al-Baqarah verses 178,180, 183, 216, 246, and An-Nisa' verse 77. Lafadz Kutiba means ju'ila (Made), found in Surah Ali Imron verse 154 and At-Taubah verses 120-121. The lafadz kutiba, meaning qudhiya (Determined or determined), is in Surah An-Nisa's verse 127 and Al-Hajj's verse 4. Thus, these results contribute to understanding the complexity of the meaning of \"Kutiba\" in the Al-Qur'an, emphasizing the importance of context in interpretation and translation to avoid misunderstandings.",
        "keywords": "",
        "link": "http://dx.doi.org/10.21009/jsq.20.1.02"
    },
    {
        "id": 11358,
        "title": "Gloss Alignment using Word Embeddings",
        "authors": "Harry Walsh, Ozge Mercanoglu Sincan, Ben Saunders, Richard Bowden",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icasspw59220.2023.10193013"
    },
    {
        "id": 11359,
        "title": "Emotion-enriched word embeddings for Turkish",
        "authors": "Hande Aka Uymaz, Senem Kumova Metin",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.120011"
    },
    {
        "id": 11360,
        "title": "Measuring and Mitigating Gender Bias in Contextualized Word Embeddings",
        "authors": "Pradeep Kamboj, Shailender Kumar, Vikram Goyal",
        "published": "2023-10-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icbds58040.2023.10346586"
    },
    {
        "id": 11361,
        "title": "Substitution-based Semantic Change Detection using Contextual Embeddings",
        "authors": "Dallas Card",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-short.52"
    },
    {
        "id": 11362,
        "title": "Learning Word Embeddings for Ukrainian: A Comparative Study of FastText Hyperparameters",
        "authors": "Nataliia Romanyshyn, Dmytro Chaplynskyi, Kyrylo Zakharov",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.unlp-1.3"
    },
    {
        "id": 11363,
        "title": "Anomaly Detection via Word Embeddings and Neural Networks",
        "authors": "Junchao Dong, Fang Pan, Xiaoli Hu, Wenyan Wang",
        "published": "2023-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isctis58954.2023.10213109"
    },
    {
        "id": 11364,
        "title": "Evaluation of word embedding models used for diachronic semantic change analysis",
        "authors": "Yulia Maslennikova, Vladimir Bochkarev",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "Abstract\nIn the last decade, the quantitative analysis of diachronic changes in language and lexical semantic changes have become the subject of active research. A significant role was played by the development of new effective techniques of word embedding. This direction has been effectively demonstrated in a number of studies. Some of them have focused on the analysis of the optimal type of word2vec models, hyperparameters for training, and evaluation techniques. In this research, we used Corpus of Historical American English (COHA). The paper demonstrates the results of multiple training runs and the comparison of word2vec models with different variations of hyperparameters used for lexical semantic change detection. In addition to traditional word similarities and analogical reasoning tests, we used testing on an extended set of synonyms. We have evaluated word2vec models on the set of more than 100,000 English synsets that were randomly selected from the WordNet database. We have shown that changing the word2vec model parameters (such as a dimension of word embedding, a size of context window, a type of model, a word discard rate etc.) can significantly impact on the resulting word embedding vector space and the detected lexical semantic changes. Additionally, the results strongly depended on properties of the corpus, such as word frequency distribution.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1742-6596/2701/1/012082"
    },
    {
        "id": 11365,
        "title": "Embedding of word vectors with emotion and semantic information by semi-supervised deep learning method: enhancement of sentiment analysis",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56452/7-3-107"
    },
    {
        "id": 11366,
        "title": "The Meaning of the Word “Wazir” in the Qur’an: A Semantic Analysis",
        "authors": "Mohammad Rizal Nur Rochim, Kharis Nugroho, Andri Nirwana",
        "published": "2023-10-24",
        "citations": 0,
        "abstract": "The purpose of this study is to explore and understand the meaning of the word \"wazir\" in the Quran. This study employs a library research method, which requires the researcher to conduct a thorough examination of various textual sources and literature related to the word. The approach used in this research is Toshihiko Izutsu's Quranic semantic approach. The research findings indicate that the meaning of the word \"wazir\" in the Quran is complex, with strong connotations related to the concepts of sin and heavy or significant accountability. Understanding the word \"wazir\" is crucial, as it not only reflects linguistic understanding but also has profound moral and ethical implications in Islam. Semantic analysis of the word \"wazir\" provides insights for a deeper understanding of the moral and ethical values embedded in the Quran, as well as how this vocabulary reflects and portrays the fundamental principles of the religion in the sacred text.",
        "keywords": "",
        "link": "http://dx.doi.org/10.22373/jim.v20i2.20205"
    },
    {
        "id": 11367,
        "title": "A Semantic Partitioning Method for Large-Scale Training of Knowledge Graph Embeddings",
        "authors": "Yuhe Bai",
        "published": "2023-4-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3543873.3587537"
    },
    {
        "id": 11368,
        "title": "Semantic Mapping with Confidence Scores through Metric Embeddings and Gaussian Process Classification",
        "authors": "Jungseok Hong, Suveer Garg, Volkan Isler",
        "published": "2023-5-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icra48891.2023.10161342"
    },
    {
        "id": 11369,
        "title": "Domain-Specific Word Embeddings with Structure Prediction",
        "authors": "David Lassner, Stephanie Brandl, Anne Baillot, Shinichi Nakajima",
        "published": "2023-3-27",
        "citations": 1,
        "abstract": "Abstract\nComplementary to finding good general word embeddings, an important question for representation learning is to find dynamic word embeddings, for example, across time or domain. Current methods do not offer a way to use or predict information on structure between sub-corpora, time or domain and dynamic embeddings can only be compared after post-alignment. We propose novel word embedding methods that provide general word representations for the whole corpus, domain- specific representations for each sub-corpus, sub-corpus structure, and embedding alignment simultaneously. We present an empirical evaluation on New York Times articles and two English Wikipedia datasets with articles on science and philosophy. Our method, called Word2Vec with Structure Prediction (W2VPred), provides better performance than baselines in terms of the general analogy tests, domain-specific analogy tests, and multiple specific word embedding evaluations as well as structure prediction performance when no structure is given a priori. As a use case in the field of Digital Humanities we demonstrate how to raise novel research questions for high literature from the German Text Archive.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1162/tacl_a_00538"
    },
    {
        "id": 11370,
        "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
        "authors": "Paul Stöwer, Achim Schilling, Andreas Maier, Patrick Krauss",
        "published": "2023-11-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdl55364.2023.10364535"
    },
    {
        "id": 11371,
        "title": "Semantic Filtering Global and Local Embeddings Fusion for Few-Shot Image Classification",
        "authors": "Luyu Nong, Min Wu",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3633637.3633707"
    },
    {
        "id": 11372,
        "title": "Investigating Semantic Subspaces of Transformer Sentence Embeddings through Linear Structural Probing",
        "authors": "Dmitry Nikolaev, Sebastian Padó",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.blackboxnlp-1.11"
    },
    {
        "id": 11373,
        "title": "SEARCHFORMER: Semantic patent embeddings by siamese transformers for prior art search",
        "authors": "Konrad Vowinckel, Volker D. Hähnke",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.wpi.2023.102192"
    },
    {
        "id": 11374,
        "title": "A Semantic Study of the Chinese Word “qing” and Its Corresponding Word “light” in English",
        "authors": "Ping Hu, Yin Wang",
        "published": "2023-3-30",
        "citations": 0,
        "abstract": "This article is aimed to analyze a semantic study of the Chinese word &ldquo;qing&rdquo; and its corresponding word &ldquo;light&rdquo; in English according to the framework of Lexical Typology suggested in fran&ccedil;ois (2008). From this article, we can clearly see the different semantic meanings of &ldquo;light&rdquo; in English. It will be shown by empirical observation sand functional properties. And they will be compared with the corresponding Chinese word &ldquo;qing&rdquo;to show similarities and differences of these two totally different language meanings.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5539/ass.v19n2p109"
    },
    {
        "id": 11375,
        "title": "Word Embeddings for Model-Driven Engineering",
        "authors": "José Antonio Hernández López, Carlos Durá, Jesús Sánchez Cuadrado",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/models58315.2023.00036"
    },
    {
        "id": 11376,
        "title": "Multi-objective search for gender-fair and semantically correct word embeddings",
        "authors": "Max Hort, Rebecca Moussa, Federica Sarro",
        "published": "2023-1",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.asoc.2022.109916"
    },
    {
        "id": 11377,
        "title": "Identifying sarcasm using heterogeneous word embeddings: a hybrid and ensemble perspective",
        "authors": "Ravi Teja Gedela, Pavani Meesala, Ujwala Baruah, Badal Soni",
        "published": "2023-5-22",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00500-023-08368-6"
    },
    {
        "id": 11378,
        "title": "LTRC at SemEval-2023 Task 6: Experiments with Ensemble Embeddings",
        "authors": "Pavan Baswani, Hiranmai Sri Adibhatla, Manish Shrivastava",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.semeval-1.116"
    },
    {
        "id": 11379,
        "title": "An Innovative Similar Complaint Recommendation Model Integrating Semantic and Graph Embeddings",
        "authors": "Ruisi Li, Renwei Ou, Dejun Wang",
        "published": "2023-7-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ispds58840.2023.10235356"
    },
    {
        "id": 11380,
        "title": "Improving visual-semantic embeddings by learning semantically-enhanced hard negatives for cross-modal information retrieval",
        "authors": "Yan Gong, Georgina Cosma",
        "published": "2023-5",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2022.109272"
    },
    {
        "id": 11381,
        "title": "Boosting Semantic Segmentation from the Perspective of Explicit Class Embeddings",
        "authors": "Yuhe Liu, Chuanjian Liu, Kai Han, Quan Tang, Zengchang Qin",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00082"
    },
    {
        "id": 11382,
        "title": "Towards Turkish Word Embeddings: An Intrinsic Evaluation",
        "authors": "Oğuz Ali Arslan, Berfin Duman, Hakan Erdem, Can Günyel, Bike Sönmez, Doğukan Arslan",
        "published": "2023-9-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ubmk59864.2023.10286768"
    },
    {
        "id": 11383,
        "title": "Automated Identification and Prioritization of Self-Admitted Technical Debt Using NLP Word Embeddings",
        "authors": "Satya Mohan Chowdary G, Prasanna Kumar R",
        "published": "2023-10-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icssas57918.2023.10331839"
    },
    {
        "id": 11384,
        "title": "Study of Word Embeddings for Enhanced Cyber Security Named Entity Recognition",
        "authors": "Smita Srivastava, Biswajit Paul, Deepa Gupta",
        "published": "2023",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.procs.2023.01.027"
    },
    {
        "id": 11385,
        "title": "A Neighbourhood-Aware Differential Privacy Mechanism for Static Word Embeddings",
        "authors": "Danushka Bollegala, Shuichi Otake, Tomoya Machide, Ken-ichi Kawarabayashi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-ijcnlp.7"
    },
    {
        "id": 11386,
        "title": "Measuring document similarity with weighted averages of word embeddings",
        "authors": "Bryan Seegmiller, Dimitris Papanikolaou, Lawrence D.W. Schmidt",
        "published": "2023-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eeh.2022.101494"
    },
    {
        "id": 11387,
        "title": "Pre-trained Word Embeddings In Deep Multi-label Personality Classification Of YouTube Transliterations",
        "authors": "Mohmad Azhar Teli, Manzoor Ahmad Chachoo",
        "published": "2023-2-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isacc56298.2023.10084047"
    },
    {
        "id": 11388,
        "title": "Investigating the Frequency Distortion of Word Embeddings and Its Impact on Bias Metrics",
        "authors": "Francisco Valentini, Juan Sosa, Diego Slezak, Edgar Altszyler",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.9"
    },
    {
        "id": 11389,
        "title": "Word embeddings for retrieving tabular data from research publications",
        "authors": "Alberto Berenguer, Jose-Norberto Mazón, David Tomás",
        "published": "2024-4",
        "citations": 1,
        "abstract": "AbstractScientists face challenges when finding datasets related to their research problems due to the limitations of current dataset search engines. Existing tools for searching research datasets rely on publication content or metadata, do not considering the data contained in the publication in the form of tables. Moreover, scientists require more elaborate inputs and functionalities to retrieve different parts of an article, such as data presented in tables, based on their search purposes. Therefore, this paper proposes a novel approach to retrieve relevant tabular datasets from publications. The input of our system is a research problem stated as an abstract from a scientific paper, and the output is a set of relevant tables from publications that are related to the research problem. This approach aims to provide a better solution for scientists to find useful datasets that support them in addressing their research problems. To validate this approach, experiments were conducted using word embedding from different language models to calculate the semantic similarity between abstracts and tables. The results showed that contextual models significantly outperformed non-contextual models, especially when pre-trained with scientific data. Furthermore, the importance of context was found to be crucial for improving the results.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10994-023-06472-0"
    },
    {
        "id": 11390,
        "title": "Analyzing Acoustic Word Embeddings from Pre-Trained Self-Supervised Speech Models",
        "authors": "Ramon Sanabria, Hao Tang, Sharon Goldwater",
        "published": "2023-6-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10096099"
    },
    {
        "id": 11391,
        "title": "Measuring Political Narratives in African News Media: A Word Embeddings Approach",
        "authors": "Risa Kitagawa, Fiona Shen-Bayh",
        "published": "2023-10-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1086/727593"
    },
    {
        "id": 11392,
        "title": "Resolving Gendered Ambiguous Pronouns with Gender-Fair Modeling Based on BERT Word Embeddings",
        "authors": "Zhi Ling",
        "published": "2023-3-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3594315.3594367"
    },
    {
        "id": 11393,
        "title": "Context-aware composition of agent policies by Markov decision process entity embeddings and agent ensembles",
        "authors": "Nicole Merkle, Ralf Mikut",
        "published": "2024-1-9",
        "citations": 1,
        "abstract": "Computational agents support humans in many areas of life and are therefore found in heterogeneous contexts. This means that agents operate in rapidly changing environments and can be confronted with huge state and action spaces. In order to perform services and carry out activities satisfactorily, i.e. in a goal-oriented manner, agents require prior knowledge and therefore have to develop and pursue context-dependent policies. The problem here is that prescribing policies in advance is limited and inflexible, especially in dynamically changing environments. Moreover, the context (i.e. the external and internal state) of an agent determines its choice of actions. Since the environments in which agents operate can be stochastic and complex in terms of the number of states and feasible actions, activities are usually modelled in a simplified way by Markov decision processes so that, for example, agents with reinforcement learning are able to learn policies, i.e. state-action pairs, that help to capture the context and act accordingly to optimally perform activities. However, training policies for all possible contexts using reinforcement learning is time-consuming. A requirement and challenge for agents is to learn strategies quickly and respond immediately in cross-context environments and applications, e.g., the Internet, service robotics, cyber-physical systems. In this work, we propose a novel simulation-based approach that enables a) the representation of heterogeneous contexts through knowledge graphs and entity embeddings and b) the context-aware composition of policies on demand by ensembles of agents running in parallel. The evaluation we conducted with the “Virtual Home” dataset indicates that agents with a need to switch seamlessly between different contexts, e.g. in a home environment, can request on-demand composed policies that lead to the successful completion of context-appropriate activities without having to learn these policies in lengthy training steps and episodes, in contrast to agents that use reinforcement learning. The presented approach enables both context-aware and cross-context applicability of untrained computational agents. Furthermore, the source code of the approach as well as the generated data, i.e. the trained embeddings and the semantic representation of domestic activities, is open source and openly accessible on Github and Figshare.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/sw-233531"
    },
    {
        "id": 11394,
        "title": "Persona and Contextual Semantic Embeddings for Entity Alignment",
        "authors": "Chang Lu, Hongtao Zhou, Housheng Su",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciea58696.2023.10241455"
    },
    {
        "id": 11395,
        "title": "Lightweight Multi-Semantic Hierarchy-Aware Poincaré Knowledge Graph Embeddings",
        "authors": "Dong Zhu, Yao Lin, Haonan Tan, Le Wang, Zhaoquan Gu",
        "published": "2023-12-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icpads60453.2023.00194"
    },
    {
        "id": 11396,
        "title": "Mongolian Compound Word Semantic Web Word Vector Evaluation Research",
        "authors": "Du La,  Hasi, Yang Ding",
        "published": "2023-8-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/prml59573.2023.10348312"
    },
    {
        "id": 11397,
        "title": "SEMANTIC-STYLISTIC TRANSPOSITION OF ADJECTIVES “VIRUSNYI” / “VIRALNYI”",
        "authors": "Mуroslava MAMYCH",
        "published": "2023",
        "citations": 0,
        "abstract": "The article is devoted to the study of the manifestations of semantic and stylistic transposition of adjectives in the language of the mass media, using the example of the change in meaning, spheres of distribution and compatibility of the words “virusnyi” and “viralnyi”. The facts of the expansion of the meaning of the very concept “transposition” in Ukrainian linguistics have been identified. It is emphasized that manifestations of stylistic transposition and related dynamics of semantic structure and lexical conjugation of words are always in the field of linguists view. First of all, this problem attracted the attention of grammarians who interpret transposition as the transfer of words from one part of the language, and this is a narrow understanding of this process.\nThe activity of the specified lexemes in the media sphere (on the websites of marketers, advertisers), as well as in the press, in particular on the pages of the newspaper “Govorimo po-ukrainsky”, was monitored. Changes in the semantics of the words “virusnyi” and “viralnyi” in explanatory and specialized dictionaries were analyzed. It is assumed that the word “virusnyi” will be replaced by the concept “viralnyi” in media marketing and advertising.\nAccording to preliminary conclusions, the nominations “virusnyi” and “viralnyi” still compete in network marketing. This is due, we assume, to the desire to “displace” the word “virusnyi” with negative associations that the concept has, which refers to explanations of the ways of spreading diseases, and to find a less well-known generic concept for the field of advertising, which can be classified as a term.\nSo, both with regard to the word “virusnyi” and with regard to the lexeme “viralnyi”, we trace the expressive processes of semantic and stylistic transposition, specialization of use in the latest horizons of servicing network communication requests.",
        "keywords": "",
        "link": "http://dx.doi.org/10.37919/0201-419x-2023.98.9"
    },
    {
        "id": 11398,
        "title": "Learning Nearest Neighbour Informed Latent Word Embeddings to Improve Zero-Shot Machine Translation",
        "authors": "Nishant Kambhatla, Logan Born, Anoop Sarkar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.iwslt-1.27"
    },
    {
        "id": 11399,
        "title": "Contextualized Word Embeddings via Generative Adversarial Learning of Syntagmatic and Paradigmatic Structure",
        "authors": "Chao Wei, Wei Zhao, Liang Chen, Yibo Wang",
        "published": "2023-12-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/csecs60003.2023.10428465"
    },
    {
        "id": 11400,
        "title": "Improvements to Embedding-Matching Acoustic-to-Word ASR Using Multiple-Hypothesis Pronunciation-Based Embeddings",
        "authors": "Hao Yen, Woojay Jeon",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10095705"
    },
    {
        "id": 11401,
        "title": "A Fistful of Vectors: A Tool for Intrinsic Evaluation of Word Embeddings",
        "authors": "Roberto Ascari, Anna Giabelli, Lorenzo Malandri, Fabio Mercorio, Mario Mezzanzanica",
        "published": "2024-1-22",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s12559-023-10235-3"
    },
    {
        "id": 11402,
        "title": "Characterizing Bias in Word Embeddings Towards Analyzing Gender Associations in Philippine Texts",
        "authors": "Lance Calvin L. Gamboa, Maria Regina Justina E. Estuar",
        "published": "2023-7-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aic57670.2023.10263949"
    },
    {
        "id": 11403,
        "title": "The Impact of Word Splitting on the Semantic Content of Contextualized Word Representations",
        "authors": "Aina Garí Soler, Matthieu Labeau, Chloé Clavel",
        "published": "2024-4-5",
        "citations": 0,
        "abstract": "Abstract\nWhen deriving contextualized word representations from language models, a decision needs to be made on how to obtain one for out-of-vocabulary (OOV) words that are segmented into subwords. What is the best way to represent these words with a single vector, and are these representations of worse quality than those of in-vocabulary words? We carry out an intrinsic evaluation of embeddings from different models on semantic similarity tasks involving OOV words. Our analysis reveals, among other interesting findings, that the quality of representations of words that are split is often, but not always, worse than that of the embeddings of known words. Their similarity values, however, must be interpreted with caution.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1162/tacl_a_00647"
    },
    {
        "id": 11404,
        "title": "“Greece” semantic field in Marina Tsvetaeva’s idiolect",
        "authors": "Natalia Izotova,  , Liudmila Tabachenko,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "The presentation of an author’s individual linguistic picture of the world by describing the structure and content of semantic fields is one of the relevant areas of literary texts’ and author idiolects’ analysis in modern linguistics. The article is devoted to the semantic and associative analysis of the lexemes comprising the “Greece” semantic field in Marina Tsvetaeva’s idiolect. The analysis enables to state the correlations between the “Greece” and other key semantic fields and to identify universal and the author’s individual semantic meanings and associations of the lexemes, which form the core and periphery of the semantic field “Greece”. The latter aspect of the analysis has not come into the linguistic research focus yet. The analysis of semantic fields is especially effective in the study of Marina Tsvetaeva’s idiolect, which is characterized by semantic compression, dynamism in the unfolding of meanings and semantic capacity of words. The core of the semantic field under study is the lexeme Greece, the center of the field includes the one-root words Greek, a Greek, the synonym Hellas, as well as its derivatives. The periphery of the field consists of toponyms, names of garments, numerous ancient anthroponyms and theonyms. The lexemes of the semantic field “Greece” also represent other significant semantic fields in Marina Tsvetaeva’s poetic, prose and epistolary texts. They denote the following meanings and associations: ‘culture’, ‘education’, ‘creativity’, ‘love for freedom’, ‘Orthodox faith’, ‘kindness, generosity’. The semantic field “Greece” is mainly associated with people dear to the poetess: her father Ivan Tsvetaev, Maximilian Voloshin, Rainer Maria Rilke. Recreating the spirit and culture of Greece, Tsvetaeva embodied the image of an era close to her, a country native to her in spirit and in which she did not have to be disappointed.",
        "keywords": "",
        "link": "http://dx.doi.org/10.21638/spbu30.2023.108"
    },
    {
        "id": 11405,
        "title": "Improving entity linking by combining semantic entity embeddings and cross-attention encoder",
        "authors": "Shi Li, Yongkang Zhang",
        "published": "2024-1-10",
        "citations": 0,
        "abstract": "Entity linking is an important task for information retrieval and knowledge graph construction. Most existing methods use a bi-encoder structure to encode mentions and entities in the same space, and learn contextual features for entity linking. However, this type of system still faces some problems: (1) the entity embedding part of the model only learns from the local context of the target entity, which is too unique for entity linking model to learn the context commonality of information; (2) the entity disambiguation part only uses similarity calculation once to determine the target entity, resulting in insufficient interaction between the mentions and candidate entities, and ineffective recall of real entities. We propose a new entity linking model based on graph neural network. Different from other bi-encoder retrieval systems, this paper introduces a fine-grained semantic enhancement information into the entity embedding part of the bi-encoder to reduce the specificity of the model. Then, the cross-attention encoder is used to re-rank the target mention and each candidate entity after the entity retrieval model. Experimental results show that although the model is not optimal in inference speed, it outperforms all baseline methods on the AIDA-CoNLL dataset, and has good generalization effects on four datasets in different fields such as MSNBC and ACE2004.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/jifs-233124"
    },
    {
        "id": 11406,
        "title": "Interpretable Word Sense Representations via Definition Generation: The Case of Semantic Change Analysis",
        "authors": "Mario Giulianelli, Iris Luden, Raquel Fernandez, Andrey Kutuzov",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.176"
    },
    {
        "id": 11407,
        "title": "The Influence of Word Embeddings on the Performance of Sentiment Classification",
        "authors": "Rong Huang, Qianyi Chen, Jun Tang, Jianjie Song",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "Word embeddings are widely used in natural language processing for mapping words into a numerical representation in vector space. Their quality can be influenced by a variety of factors such as training methods and corpus, which in turn impact machine learning performance. As a whole, larger corpora result in higher-quality word embeddings and improved classification accuracy when the training method is same and the corpus is different. However, the content of the corpus will also affect the classification performance. In this work, we study the relationship between several common word embeddings and sentiment classification models through a series of comparative experiments. Comparison results reveal that in addition to the training method and corpus size, the corpus content and dimensionality also play a significant role in determining the quality of word embeddings. Therefore, when dealing with specific tasks, it is necessary to comprehensively consider these factors, so as to obtain better results. This work provides an improved understanding of factors for consideration that may lead to more efficient sentiment classification.",
        "keywords": "",
        "link": "http://dx.doi.org/10.56028/ijcit.1.4.1.2023"
    },
    {
        "id": 11408,
        "title": "Compressed models for co-reference resolution: enhancing efficiency with debiased word embeddings",
        "authors": "Georgios Ioannides, Aishwarya Jadhav, Aditi Sharma, Samarth Navali, Alan W. Black",
        "published": "2023-10-28",
        "citations": 0,
        "abstract": "AbstractThis work presents a comprehensive approach to reduce bias in word embedding vectors and evaluate the impact on various Natural Language Processing (NLP) tasks. Two GloVe variations (840B and 50) are debiased by identifying the gender direction in the word embedding space and then removing or reducing the gender component from the embeddings of target words, while preserving useful semantic information. Their gender bias is assessed through the Word Embedding Association Test. The performance of co-reference resolution and text classification models trained on both original and debiased embeddings is evaluated in terms of accuracy. A compressed co-reference resolution model is examined to gauge the effectiveness of debiasing techniques on resource-efficient models. To the best of the authors’ knowledge, this is the first attempt to apply compression techniques to debiased models. By analyzing the context preservation of debiased embeddings using a Twitter misinformation dataset, this study contributes valuable insights into the practical implications of debiasing methods for real-world applications such as person profiling.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-023-45677-0"
    },
    {
        "id": 11409,
        "title": "Sentiment Analysis of Code-Mixed Telugu-English Data Leveraging Syllable and Word Embeddings",
        "authors": "Upendar Rao Rayala, Karthick Seshadri, Nagesh Bhattu Sristy",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "Learning the inherent meaning of a word in Natural Language Processing (NLP) has motivated researchers to represent a word at various levels of abstraction, namely character-level, morpheme-level, and subword-level vector representations. Syllable-Aware Word Embedding (SAWE) can effectively handle agglutinative and fusion-based NLP tasks. However, research attempts on assessing the SAWE on such extrinsic NLP tasks has been scanty, especially for low-resource languages in the context of code-mixing with English. A model to learn SAWE to extract semantics at fine-grained subunits of a word is proposed in this article, and the representative ability of the embeddings is assessed through sentiment analysis of code-mixed Telugu-English review corpora. Multilingual societies and advancements in communication technologies have accounted for the prolific usage of mixed data, which renders the State-of-the-Art (SOTA) sentiment analysis models developed based on monolingual data ineffective. Social media users in the Indian subcontinent exhibit a tendency to mix English and their respective native language (using the phonetic form of English) in expressing their opinions or sentiments. A code-mixing scenario provides flexibility to borrow words from a foreign language, usage of shorthand notations, elongation of vowels, and usage of words without following syntactic/grammatical rules, which renders the sentiment analysis of code-mixed data challenging to perform. Deep neural architectures like Long Short-Term Memory and Gated Recurrent Unit networks have been shown to be effective in solving several NLP tasks, such as sequence labeling, named entity recognition, and machine translation. In this article, a framework to perform sentiment analysis on a code-mixed Telugu-English review corpus is implemented. Both word embedding and SAWE are input to a unified deep neural network that contains a two-level Bidirectional Long Short-Term Memory/Gated Recurrent Unit network with Softmax as the output layer. The proposed model leverages the advantages of both word embedding and SAWE, which enable the proposed model to outperform existing SOTA code-mixed sentiment analysis models on a Telugu-English code-mixed dataset of the International Institute of Information Technology–Hyderabad and a dataset curated by the authors. The improvement realized by the proposed model on these datasets is [3% increase in F1-score and 2% increase in accuracy] and [7% increase in F1-score and 5% in accuracy], respectively, in comparison with the best-performing SOTA model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3620670"
    },
    {
        "id": 11410,
        "title": "A Comparative Analysis of Word Embeddings Techniques for Italian News Categorization",
        "authors": "Federica Rollo, Giovanni Bonisoli, Laura Po",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2024.3367246"
    },
    {
        "id": 11411,
        "title": "Enhancing Interpretability Using Human Similarity Judgements to Prune Word Embeddings",
        "authors": "Natalia Flechas Manrique, Wanqian Bao, Aurelie Herbelot, Uri Hasson",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.blackboxnlp-1.13"
    },
    {
        "id": 11412,
        "title": "KLASIFIKASI SENTIMEN VAKSIN COVID-19 MENGGUNAKAN K-NEAREST NEIGHBOR BERDASARKAN WORD EMBEDDINGS FASTTEXT PADA TWITTER",
        "authors": "Afri Naldi, Surya Agustian",
        "published": "2023-6-16",
        "citations": 0,
        "abstract": "Pada akhir 2019 muncul penyakit semacam flu yang menginfeksi paru-paru di kota Wuhan. Diduga penyakit tersebut diduga berasal dari kelelawar. WHO memberi nama penyakit ini dengan nama Covid-19 dan virus ini tersebar ke seluruh dunia sehingga menyebabkan pandemi. Pemerintah mengambil indakan vaksinasi untuk mengatasi virus ini, namun mendapat respon pro dan kontra dari masyarakat. Ada banyak penelitian yang membahas sentimen masyarakat terhadap vaksinasi salah satunya adalah klasifikasi sentimen. Penelitian ini membahas klasifikasi sentimen terhadap vaksin covid-19 menggunakan algoritma K-Nearest Neighbor dan Fasttext pada twitter. Data diperoleh dengan cara crawling menggunakan bahasa pemograman pyton dan Twitter API. Pelabelan data dilakukan dengan teknik crowdsourcing dan majority voting. Data yang digunakan setelah proses penyeimbangan adalah 6000 data training, 778 data development dan 400 data test. Hasil pengujian setelah berbagai eksperimen dan feature engineering mendapatkan hasil terbaik dengan nilai akurasi 69% dan f1-score 60%. Hasil ini merupakan hasil terbaik dibanding penelitian sebelumnya dengan dataset yang sama.",
        "keywords": "",
        "link": "http://dx.doi.org/10.31849/zn.v5i2.12548"
    },
    {
        "id": 11413,
        "title": "Robust Word Vectors: Context-Informed Embeddings for Noisy Texts",
        "authors": "V. Malykh, T. Khakhulin, V. Logacheva",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10958-023-06523-w"
    },
    {
        "id": 11414,
        "title": "Learning Dynamic Contextualised Word Embeddings via Template-based Temporal Adaptation",
        "authors": "Xiaohang Tang, Yi Zhou, Danushka Bollegala",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-long.520"
    },
    {
        "id": 11415,
        "title": "A deep neural framework for named entity recognition with boosted word embeddings",
        "authors": "Archana Goyal, Vishal Gupta, Manish Kumar",
        "published": "2023-7-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-16176-1"
    },
    {
        "id": 11416,
        "title": "Semantic Embeddings for Arabic Retrieval Augmented Generation (ARAG)",
        "authors": "Hazem Abdelazim, Mohamed Tharwat, Ammar Mohamed",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14569/ijacsa.2023.01411135"
    },
    {
        "id": 11417,
        "title": "Semantic relations classification in Hindi compound nouns using embeddings",
        "authors": "Vandana Dwivedi, Sanjukta Ghosh",
        "published": "2023-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s41870-023-01374-9"
    },
    {
        "id": 11418,
        "title": "Sentiment-semantic word vectors - A new method to estimate management sentiment",
        "authors": "Minh Tri Phan",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4723125"
    },
    {
        "id": 11419,
        "title": "A Comparison of Word Embeddings for Comment Toxicity Detection: Detection Power of Computer",
        "authors": "Prasanna Kumar R, Bharathi Mohan G, Elakkiya R, Varsha P",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccsai59793.2023.10421356"
    },
    {
        "id": 11420,
        "title": "Self-admitted technical debt classification using natural language processing word embeddings",
        "authors": "Ahmed F. Sabbah, Abualsoud A. Hanani",
        "published": "2023-4-1",
        "citations": 0,
        "abstract": "<p>Recent studies show that it is possible to detect technical dept automatically from source code comments intentionally created by developers, a phenomenon known as self-admitted technical debt. This study proposes a system by which a comment or commit is classified as one of five dept types, namely, requirement, design, defect, test, and documentation. In addition to the traditional term frequency-inverse document frequency (TF-IDF), several word embeddings methods produced by different pre-trained language models were used for feature extraction, such as Word2Vec, GolVe, bidirectional encoder representations from transformers (BERT), and FastText. The generated features were used to train a set of classifiers including naive Bayes (NB), random forest (RF), support vector machines (SVM), and two configurations of convolutional neural network (CNN). Two datasets were used to train and test the proposed systems. Our collected dataset (A-dataset) includes a total of 1,513 comments and commits manually labeled. Additionally, a dataset, consisting of 4,071 labeled comments, used in previous studies (M-dataset) was also used in this study. The RF classifier achieved an accuracy of 0.822 with A-dataset and 0.820 with the M-dataset. CNN with A-dataset achieved an accuracy of 0.838 using BERT features. With M-dataset, the CNN achieves an accuracy of 0.809 and 0.812 with BERT and Word2Vec, respectively.</p>",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijece.v13i2.pp2142-2155"
    },
    {
        "id": 11421,
        "title": "Beyond Word-Based Model Embeddings: Contextualized Representations for Enhanced Social Media Spam Detection",
        "authors": "Sawsan Alshattnawi, Amani Shatnawi, Anas M.R. AlSobeh, Aws A. Magableh",
        "published": "2024-3-7",
        "citations": 1,
        "abstract": "As social media platforms continue their exponential growth, so do the threats targeting their security. Detecting disguised spam messages poses an immense challenge owing to the constant evolution of tactics. This research investigates advanced artificial intelligence techniques to significantly enhance multiplatform spam classification on Twitter and YouTube. The deep neural networks we use are state-of-the-art. They are recurrent neural network architectures with long- and short-term memory cells that are powered by both static and contextualized word embeddings. Extensive comparative experiments precede rigorous hyperparameter tuning on the datasets. Results reveal a profound impact of tailored, platform-specific AI techniques in combating sophisticated and perpetually evolving threats. The key innovation lies in tailoring deep learning (DL) architectures to leverage both intrinsic platform contexts and extrinsic contextual embeddings for strengthened generalization. The results include consistent accuracy improvements of more than 10–15% in multisource datasets, unlocking actionable guidelines on optimal components of neural models, and embedding strategies for cross-platform defense systems. Contextualized embeddings like BERT and ELMo consistently outperform their noncontextualized counterparts. The standalone ELMo model with logistic regression emerges as the top performer, attaining exceptional accuracy scores of 90% on Twitter and 94% on YouTube data. This signifies the immense potential of contextualized language representations in capturing subtle semantic signals vital for identifying disguised spam. As emerging adversarial attacks exploit human vulnerabilities, advancing defense strategies through enhanced neural language understanding is imperative. We recommend that social media companies and academic researchers build on contextualized language models to strengthen social media security. This research approach demonstrates the immense potential of personalized, platform-specific DL techniques to combat the continuously evolving threats that threaten social media security.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app14062254"
    },
    {
        "id": 11422,
        "title": "Contextual Embeddings for Ukrainian: A Large Language Model Approach to Word Sense Disambiguation",
        "authors": "Yurii Laba, Volodymyr Mudryi, Dmytro Chaplynskyi, Mariana Romanyshyn, Oles Dobosevych",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.unlp-1.2"
    },
    {
        "id": 11423,
        "title": "Dispersing the clouds of doubt: can cosine similarity of word embeddings help identify relation-level metaphors in Slovene?",
        "authors": "Mojca Brglez",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.bsnlp-1.8"
    },
    {
        "id": 11424,
        "title": "Towards hate speech detection in low-resource languages: Comparing ASR to acoustic word embeddings on Wolof and Swahili",
        "authors": "Christiaan Jacobs, Nathanaël Carraz Rakotonirina, Everlyn Asiko Chimoto, Bruce A. Bassett, Herman Kamper",
        "published": "2023-8-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-421"
    },
    {
        "id": 11425,
        "title": "Depression tendency detection method based on multi-feature fusion of BERT word embeddings",
        "authors": "Lin Han, Xu Zhang",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3011971"
    },
    {
        "id": 11426,
        "title": "Semantic Role Labeling for Amharic Text Using Multiple Embeddings and Deep Neural Network",
        "authors": "Bemnet Meresa Hailu, Yaregal Assabie, Yenewondim Biadgie Sinshaw",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3263147"
    },
    {
        "id": 11427,
        "title": "An interactive method for measuring gender bias and evaluating bias in Chinese word embeddings",
        "authors": "Chunlin Qin, Xin Zhang, Chaoran Zhou, Yan Liu",
        "published": "2023-4-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2673321"
    },
    {
        "id": 11428,
        "title": "An Efficient Aspect-based Sentiment Classification with Hybrid Word\nEmbeddings and CNN Framework",
        "authors": "Monika Agrawal, Nageswara Rao Moparthi",
        "published": "2024-3",
        "citations": 0,
        "abstract": "\nBackground:\nAs the e-commerce product reviews and social media posts are increasing\nenormously, the size of the database for polarity/ sentiment detection is a challenging task, and\nagain, predicting polarities associated with respect to aspect terms end to end in a sentence is a havoc\nin real-time applications. Human behavior is influenced by the various opinions generated in society.\nPublic opinion influences our decisions most often. Businesses and establishments always\nneed to collect the opinion of the society, which they try to obtain using customer feedback forms\nand questionnaires or surveys, which help them to be aware of the shortcomings if any, and to use\nsuggestions to improve quality. It works in the same way for customers as well and the opinions of\nother customers about a particular product can come in handy when deciding to buy a product.\n\n\nObjectives:\nIn this work, an efficient Aspect-based Sentiment Classification technique has been introduced\nwith a hybrid, multiple-word embedding methods and implemented using the CNN\nframework on large databases.\n\n\nMethods:\nMost of the traditional models have a limitation on the dependency for one or more similar\ntypes of aspect words for sentiment classification problem. However, these conventional models\nsuch as TF-ID, Word 2Vec and Glove method consumes much more time for word embedding process\nand Aspect terms generation and further process of aspect level sentiment classification. Further,\nthese models are facing problems of high true negative rate and misclassification rate on large\naspect databases in sentiment classification. In this article, we have introduced an efficient Proposed\nensemble word embedding model in the CNN network and defined Hybrid Word2 Vec method, Hybrid\nGlove word embedding method and Hybrid Random Forest model for sentiment classification.\n\n\nResults:\nExperiments on a widely used benchmark prove that the proposed word embedding method-\nbased classification technique results in to higher true positive rate with minimal misclassifications\nand also supports better runtime and accuracy than the traditional word embedding-based aspect\nlevel classification approaches.\n\n\nConclusion:\nIn this article, a hybrid ensemble feature ranking-based classification model is proposed on the large aspect databases. In this work, advanced multiple-word embedding methods are\nimplemented to improve the essential feature extraction problem in the aspect level sentiment process. These multiple-word embedding methods are applied to the sentiment databases in the CNN\nframework.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.2174/0122103279275188231205094007"
    },
    {
        "id": 11429,
        "title": "Text sentiment classification of Amazon reviews using word embeddings and convolutional neural networks",
        "authors": "Mohammed Qorich, Rajae El Ouazzani",
        "published": "2023-7",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11227-023-05094-6"
    },
    {
        "id": 11430,
        "title": "Fine-tuning Sentence-RoBERTa to Construct Word Embeddings for Low-resource Languages from Bilingual Dictionaries",
        "authors": "Diego Bear, Paul Cook",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.americasnlp-1.7"
    },
    {
        "id": 11431,
        "title": "A Word Embeddings based Approach for Author Profiling: Gender and Age Prediction",
        "authors": "Karunakar Kavuri, M Kavitha",
        "published": "2023-7-13",
        "citations": 0,
        "abstract": "Author Profiling (AP) is a method of identifying the demographic profiles such as age, gender, location, native language and personality traits of an author by processing their written texts. The AP techniques are used in multiple applications such as literary research, marketing, forensics and security. The researchers identified various differences in the authors writing styles by analysing various datasets. The differences in writing styles are represented as stylistic features. The researchers extracted several style based features like structural, content, word, character, syntactic, readability and semantic features to recognize the profiles of the authors. Traditionally, the researchers extracted various feature combinations for differentiating the profiles of authors. Several existing works are used Machine Learning (ML) methods for predicting the author characteristics of a new author. The existing works achieved good accuracies for predicting the author characteristics by considering the both stylistic features and ML algorithms combination. Recently, in advent of Deep Learning (DL) techniques the researchers are proposed approaches to author profiling by using these techniques. Few researchers identified that the deep learning techniques performance is good for author profiles prediction than the results of style based features. In this work, a word embeddings based approach is proposed for gender and age prediction. In this approach, the experiment conducted with different word embedding models such as Word2Vec, GloVe, FastText and BERT for generating word vectors for words. The documents are converted as vectors by using the document representation technique which uses the word embeddings of words. The document vectors are transferred to three different ML algorithms such as Extreme Gradient Boosting (XGBoost), Random Forest (RF) and Logistic Regression (LR) for generating the trained model. This model is used for predicating the accuracy of age and gender prediction. The XGBoost classifier with word embeddings of BERT achieved good accuracies for age and gender prediction than other word embeddings and ML algorithms. The experiment implemented on PAN 2014 competition Reviews dataset for age and gender prediction. The proposed approach attained best accuracies for predicting age and gender than the performances of various existing approaches proposed for AP.",
        "keywords": "",
        "link": "http://dx.doi.org/10.17762/ijritcc.v11i7s.6996"
    },
    {
        "id": 11432,
        "title": "Combining conditional random fields and word embeddings to improve Amazigh part-of-speech Tagging",
        "authors": "Rkia Bani, Samir Amri, Lahbib Zenkouar, Zouhair Guennoun",
        "published": "2023-9-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eecsi59885.2023.10295911"
    },
    {
        "id": 11433,
        "title": "The effects of gender bias in word embeddings on patient phenotyping in the mental health domain",
        "authors": "Gizem Sogancioglu, Heysem Kaya, Albert Ali Salah",
        "published": "2023-9-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/acii59096.2023.10388203"
    },
    {
        "id": 11434,
        "title": "CIF-RNNT: Streaming ASR Via Acoustic Word Embeddings with Continuous Integrate-and-Fire and RNN-Transducers",
        "authors": "Wen Shen Teo, Yasuhiro Minami",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10448492"
    },
    {
        "id": 11435,
        "title": "Benchmark for Evaluation of Danish Clinical Word Embeddings",
        "authors": "Martin Sundahl Laursen, Jannik Skyttegaard Pedersen, Pernille Just Vinholt, Rasmus Søgaard Hansen, Thiusius Rajeeth Savarimuthu",
        "published": "2023-3-1",
        "citations": 1,
        "abstract": "\n\n\nIn natural language processing, benchmarks are used to track progress and identify useful models. Currently, no benchmark for Danish clinical word embeddings exists. This paper describes the development of a Danish benchmark for clinical word embeddings. The clinical benchmark consists of ten datasets: eight intrinsic and two extrinsic. Moreover, we evaluate word embeddings trained on text from the clinical domain, general practitioner domain and general domain on the established benchmark. All the intrinsic tasks of the benchmark are publicly available.\n\n\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.3384/nejlt.2000-1533.2023.4132"
    },
    {
        "id": 11436,
        "title": "MySemCloud: Semantic-aware Word Cloud Editing",
        "authors": "Michael Huber, Martin Nöllenburg, Anaïs Villedieu",
        "published": "2023-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/pacificvis56936.2023.00024"
    },
    {
        "id": 11437,
        "title": "Going Beyond Sentence Embeddings: A Token-Level Matching Algorithm for Calculating Semantic Textual Similarity",
        "authors": "Hongwei Wang, Dong Yu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-short.49"
    },
    {
        "id": 11438,
        "title": "Density and Entropy of Spoken Syllables in American English and Japanese English Estimated with Acoustic Word Embeddings",
        "authors": "Yusuke Shozui, Nobuaki Minematsu, Noriko Nakanishi, Daisuke Saito",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/slate.2023-25"
    },
    {
        "id": 11439,
        "title": "Racist discourse in a German far-right blog: A corpus-driven approach using word embeddings",
        "authors": "Simon Meier-Vieracker",
        "published": "2024-3",
        "citations": 0,
        "abstract": " Newer forms of racism in the context of right-wing extremism are characterised by an apparent distancing from overt racist devaluations. In addition or even beyond biological features, it is now cultural characteristics attributed to social groups which serve as grounds for practices of othering and social exclusion. This paper analyses racist discourse in the comment sections of the influential far-right blog pi-news.com where these practices can be observed in detail. With reference to discourse analytical approaches to racism and using corpus-linguistic, data-driven methods, especially word embeddings and collocations, it is shown how racism is linguistically and discursively expressed. Next to both overt and more implicit racist nominations and predications, the notion of Heimat (‘homeland’) is analysed; it is used to draw racist demarcations without relying on overtly racialising terms. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1177/09579265231204510"
    },
    {
        "id": 11440,
        "title": "Examining the effect of whitening on static and contextualized word embeddings",
        "authors": "Shota Sasaki, Benjamin Heinzerling, Jun Suzuki, Kentaro Inui",
        "published": "2023-5",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ipm.2023.103272"
    },
    {
        "id": 11441,
        "title": "Structural Semantic Distance Between Synonymous Two-Word Terms",
        "authors": "Asta Mitkevičienė",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.35321/all89-07"
    },
    {
        "id": 11442,
        "title": "Word to Sentence Visual Semantic Similarity for Caption Generation: Lessons Learned",
        "authors": "Ahmed Sabir",
        "published": "2023-7-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/mva57639.2023.10215754"
    },
    {
        "id": 11443,
        "title": "Arabic Sentiment Analysis Based on Word Embeddings and Deep Learning",
        "authors": "Nasrin Elhassan, Giuseppe Varone, Rami Ahmed, Mandar Gogate, Kia Dashtipour, Hani Almoamari, Mohammed A. El-Affendi, Bassam Naji Al-Tamimi, Faisal Albalwy, Amir Hussain",
        "published": "2023-6-19",
        "citations": 3,
        "abstract": "Social media networks have grown exponentially over the last two decades, providing the opportunity for users of the internet to communicate and exchange ideas on a variety of topics. The outcome is that opinion mining plays a crucial role in analyzing user opinions and applying these to guide choices, making it one of the most popular areas of research in the field of natural language processing. Despite the fact that several languages, including English, have been the subjects of several studies, not much has been conducted in the area of the Arabic language. The morphological complexities and various dialects of the language make semantic analysis particularly challenging. Moreover, the lack of accurate pre-processing tools and limited resources are constraining factors. This novel study was motivated by the accomplishments of deep learning algorithms and word embeddings in the field of English sentiment analysis. Extensive experiments were conducted based on supervised machine learning in which word embeddings were exploited to determine the sentiment of Arabic reviews. Three deep learning algorithms, convolutional neural networks (CNNs), long short-term memory (LSTM), and a hybrid CNN-LSTM, were introduced. The models used features learned by word embeddings such as Word2Vec and fastText rather than hand-crafted features. The models were tested using two benchmark Arabic datasets: Hotel Arabic Reviews Dataset (HARD) for hotel reviews and Large-Scale Arabic Book Reviews (LARB) for book reviews, with different setups. Comparative experiments utilized the three models with two-word embeddings and different setups of the datasets. The main novelty of this study is to explore the effectiveness of using various word embeddings and different setups of benchmark datasets relating to balance, imbalance, and binary and multi-classification aspects. Findings showed that the best results were obtained in most cases when applying the fastText word embedding using the HARD 2-imbalance dataset for all three proposed models: CNN, LSTM, and CNN-LSTM. Further, the proposed CNN model outperformed the LSTM and CNN-LSTM models for the benchmark HARD dataset by achieving 94.69%, 94.63%, and 94.54% accuracy with fastText, respectively. Although the worst results were obtained for the LABR 3-imbalance dataset using both Word2Vec and FastText, they still outperformed other researchers’ state-of-the-art outcomes applying the same dataset.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/computers12060126"
    },
    {
        "id": 11444,
        "title": "Distilled non-semantic speech embeddings with binary neural networks for low-resource devices",
        "authors": "Harlin Lee, Aaqib Saeed",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patrec.2023.11.028"
    },
    {
        "id": 11445,
        "title": "Semantic Preference of the Word Okaa-san and Mama in Tsukuba Web Corpus: A Corpus Linguistic Analysis",
        "authors": "Mellati Riandi Putri, Elvi Citraresmana, Inu Isnaeni Sidiq",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "The use of loanwords is common in Japanese people's daily lives, such as the use of'mama' as a term for mother rather than 'okaa-san'. Using corpus linguistic analysis, this study sought to discover how okaa-san and mama are discussed in Japanese society on the internet. The mixed technique was utilized in this study, with collocate strength calculated using MI Score and subsequently categorized by using USAS semantic categories. It was discovered that the phrase okaa-san is usually used to refer to social activities, states, and processes such as the tight relationship between mother and kid. Meanwhile, the term mother is used to refer to emotional behaviors, states, and processes.",
        "keywords": "",
        "link": "http://dx.doi.org/10.18196/jjlel.v7i2.19217"
    },
    {
        "id": 11446,
        "title": "COMPARATIVE ANALYSIS OF SOME RUSSIAN AND OSSETIAN KINSHIP TERMS (LEXICO-SEMANTIC AND WORD-FORMATION ASPECTS)",
        "authors": "Н.Т. ЕДЗИЕВА",
        "published": "2024-3-22",
        "citations": 0,
        "abstract": "В статье рассматривается актуальный вопрос современной лингвистики – проблема перевода некоторых терминов родства с русского языка на осетинский и наоборот. В русском языке значительная часть терминов родства по восходящей и нисходящей линии (названия предков и потомков) образуются с помощью префикса пра-, а в осетинском языке большинство терминов родства образовано описательным способом. Часть ученых предлагает слитное написание описательных терминов родства, что, на наш взгляд, препятствует естественному восприятию слов в тексте. Наиболее проблематичным при осуществлении художественного перевода с русского на осетинский становится перевод таких терминов бокового родства, как «дядя» и «тетя», поскольку в осетинском языке для каждого из них есть два обозначения: патрилинейного (со стороны отца) – «фыды хо», «фыды ҆фсымæр»; матрилинейного (со стороны матери) – «мады хо», «мады ҆фсымæр». В некоторых текстах перевод подобных амбивалентных единиц с русского языка на осетинский (если неизвестна сторона родства) может считаться некорректным. Перевод осетинских единиц на русский может также представлять затруднения, т.к. в этом случае необходимо подчеркнуть, с чьей стороны осуществляется родственная связь (отца или матери). Некоторые термины родства в осетинском языке, постепенно переходят в разряд архаизмов, в основном под влиянием русского языка, но при осуществлении перевода художественной литературы или школьных учебников, на наш взгляд, следует использовать варианты, которые на сегодняшний день считаются архаизмами. Кроме того, некоторые «осетинизированные» варианты заимствованных терминов родства (в частности, «бабу», «деду») уже включены в ряд школьных учебников, что не способствует развитию осетинского языка и отражению его национальной специфики. В статье также уделяется внимание некоторым терминам свойства. Указывается, что осетинский менталитет оказывает влияние на использование тех или иных вариантов в разговорной речи. В качестве практического материала привлекаются фрагменты из современного осетинского перевода Библии, изданного в 2022 г. к 1100-летию крещения Алании.\nThe article deals with an urgent issue of modern linguistics – the problem of translating some kinship terms from Russian into Ossetian and vice versa. In the Russian language, a significant part of the terms of kinship in the ascending and descending line (names of ancestors and descendants) are formed using the prefix -pra, and in the Ossetian language, most terms of kinship are formed in a descriptive way. Some scientists suggest the combined spelling of descriptive terms of kinship, which, in our opinion, prevents the natural perception of words in the text. The most problematic when translating literary works from Russian into Ossetian is the translation of such terms of lateral kinship as uncle and aunt, since in the Ossetian language there are two designations for each of them: on the father's side – fydy ho, fydy ҆fsymær; on the mother's side – mady ho, mady ҆fsymær. In some texts, the translation from Russian into Ossetian (if the side of kinship is unknown) may remain incorrect. When translating from Ossetian into Russian, such ambiguity becomes impossible, because in this case it is necessary to emphasize the side of the kinship (father or mother). Russian, namely, in colloquial speech, are gradually passing into the category of archaisms, mainly under the influence of the Russian language, but when translating fiction or school textbooks, in our opinion, it is necessary to use variants that are currently considered archaisms. Nevertheless, some assimilated versions of kinship terms (in particular, babu, dedu) have already been included in a number of school textbooks, which, in our opinion, does not contribute to the development of the Ossetian language and the reflection of its national specifics. The article also pays attention to some terms of the property. The author of the article points out that the Ossetian mentality influences the use of certain variants in colloquial speech. Fragments from the modern Ossetian translation of the Bible, published in 2022, on the 1100th anniversary of the baptism of Alanya, are used as practical material, since all the resources of the Ossetian language are used here to the maximum.",
        "keywords": "",
        "link": "http://dx.doi.org/10.46698/vnc.2024.90.51.002"
    },
    {
        "id": 11447,
        "title": "The Etymology, Word-formation and Cognitive Semantic Analysis on the Color Words of Chinese ‘Chi(赤)/Hong(紅)’ series and Korean ‘붉다/빨갛다’ series",
        "authors": "Na Liu",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25021/jcll.2023.12.143.149"
    },
    {
        "id": 11448,
        "title": "Human Factor Identification in Aviation Accidents Using Contextual Word Embeddings",
        "authors": "July Bias Macêdo, Plìnio M. S. Ramos, Caio Souto Maior, Márcio J. C. Moura, Isis Didier Lins",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3850/978-981-18-8071-1_p233-cd"
    },
    {
        "id": 11449,
        "title": "Multilingual Word Embeddings for Low-Resource Languages using Anchors and a Chain of Related Languages",
        "authors": "Viktor Hangya, Silvia Severini, Radoslav Ralev, Alexander Fraser, Hinrich Schütze",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.mrl-1.8"
    },
    {
        "id": 11450,
        "title": "Assessing Word Importance Using Models Trained for Semantic Tasks",
        "authors": "David Javorsky, Ondřej Bojar, François Yvon",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.563"
    },
    {
        "id": 11451,
        "title": "Prediction of Chinese Semantic Word Formation Patterns Based on Annotated Corpus",
        "authors": "Min Lu",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmnwc60182.2023.10435927"
    },
    {
        "id": 11452,
        "title": "An improved sentiment classification model based on data quality and word embeddings",
        "authors": "Asma Siagh, Fatima Zohra Laallam, Okba Kazar, Hajer Salem",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11227-023-05099-1"
    },
    {
        "id": 11453,
        "title": "Radiological Report Generation from Chest X-ray Images Using Pre-trained Word Embeddings",
        "authors": "Fahd Saleh Alotaibi, Navdeep Kaur",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11277-024-10886-x"
    },
    {
        "id": 11454,
        "title": "Detecting the Political Bias in News Articles and Similarity Using Word Embeddings in American Journalism",
        "authors": "Apoorv Kumar Sinha, Sanskriti Sanjay Kumar Singh, Shreyas Sai",
        "published": "2023-6-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ciisca59740.2023.00033"
    },
    {
        "id": 11455,
        "title": "Adaptive map matching based on dynamic word embeddings for indoor positioning",
        "authors": "Xinyue Lan, Lijia Zhang, Zhuoling Xiao, Bo Yan",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neucom.2023.126545"
    },
    {
        "id": 11456,
        "title": "Semantic Ambiguity Detection in Sentence Classification using Task-Specific Embeddings",
        "authors": "Jong Myoung Kim, Young-jun Lee, Sangkeun Jung, Ho-jin Choi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.acl-industry.41"
    },
    {
        "id": 11457,
        "title": "A Heterogeneous Directed Graph Attention Network for inductive text classification using multilevel semantic embeddings",
        "authors": "Mu Lin, Tao Wang, Yifan Zhu, Xiaobo Li, Xin Zhou, Weiping Wang",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2024.111797"
    },
    {
        "id": 11458,
        "title": "Efficacy of Deep Neural Embeddings-Based Semantic Similarity in Automatic Essay Evaluation",
        "authors": "Manik Hendre, Prasenjit Mukherjee, Raman Preet, Manish Godse",
        "published": "2023-5-18",
        "citations": 0,
        "abstract": "Semantic similarity is used extensively for understanding the context and meaning of the text data. In this paper, use of the semantic similarity in an automatic essay evaluation system is proposed. Different text embedding methods are used to compute the semantic similarity. Recent neural embedding methods including Google sentence encoder (GSE), embeddings for language models (ELMo), and global vectors (GloVe) are employed for computing the semantic similarity. Traditional methods of textual data representation such as TF-IDF and Jaccard index are also used in finding the semantic similarity. Experimental analysis of an intra-class and inter-class semantic similarity score distributions shows that the GSE outperforms other methods by accurately distinguishing essays from the same or different set/topic. Semantic similarity calculated using the GSE method is further used for finding the correlation with human rated essay scores, which shows high correlation with the human-rated scores on various essay traits.",
        "keywords": "",
        "link": "http://dx.doi.org/10.4018/ijcini.323190"
    },
    {
        "id": 11459,
        "title": "A semantic study of “heavy” and its corresponding Chinese word “zhong”",
        "authors": "Ping Hu",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "This paper aims to analyze the English adjective “heavy” and its corresponding word in Chinese, “zhong”, using the framework of lexical typology as suggested by François (2008). Through this article, we gain a comprehensive understanding of the various semantic meanings associated with “heavy” in English. These semantic meanings are derived from empirical observations and functional properties. Moreover, we compare these meanings with their corresponding counterparts in Chinese, revealing both similarities and differences with the word “zhong”. In the English language, “heavy” is connected to several senses, as defined by the Oxford Dictionary. It can refer to something weighing a lot, being worse than usual, not delicate when modifying, being thick as a material, being full of something, being large and powerful when modifying machines, being busy, or being involved in physically demanding work (heavy digging/lifting). Additionally, “heavy” can modify actions like “fall” or “hit”, describe a substantial amount of food, indicate excessive use, modify sounds, imply seriousness or difficulty, describe large bodies of water (e.g., sea/ocean), and pertain to weather conditions, air, and soil. Furthermore, it can connote strictness in certain contexts. Several of these meanings find parallels in the Chinese word “zhong”, such as referring to something that weighs a lot, modifying machines to signify size and power, relating to physically demanding work (e.g., heavy digging/lifting), describing the fall or impact of objects, indicating a substantial amount of food, or denoting seriousness or difficulty. Moreover, both “heavy” and “zhong” share the function of modifying actions related to drinking, smoking, or sleeping. However, it is important to note that in Chinese, alternative words like “chen” or “si” can also be used to express similar ideas.",
        "keywords": "",
        "link": "http://dx.doi.org/10.59400/fls.v5i2.1642"
    },
    {
        "id": 11460,
        "title": "Peculiarities of Semantic and Word-Formation Development of the Lexical Unit пилот",
        "authors": "Olga Dudurich",
        "published": "2024-2-4",
        "citations": 0,
        "abstract": "The article describes the mechanism of the developing of a new meaning of the lexeme пилот in the Russian language. It is proved that the new lexico-semantic variant \"experimental, trial\" initially arises in the semantic structure of the word pilot in English. Its transition into Russian, however, is not a process of mechanical calquing, but an active process of adaptation of the lexeme in the recipient language. Morphological peculiarities of Russian language determine the introduction of the new meaning in three different forms: the noun пилот, the adjectival phrase пилотный проект and the analytical structure пилот-проект. The neosemantism пилот forms the derivatives пилотировать and пилотаж with the meaning \"to manage pilot projects\". The adjective пилотный is actively used as an attribute with nouns denoting subjects of testing. The development of semantics introduces into the meaning of the adjective the seme of ʽinnovativenessʼ, which is absent in the donor language.",
        "keywords": "",
        "link": "http://dx.doi.org/10.14258/filichel(2024)1-11"
    },
    {
        "id": 11461,
        "title": "Comparison of the accuracy of Japanese synonym identifications using word embeddings in the radiological technology field",
        "authors": "Ayako Yagahara, Noriya Yokohama",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "AbstractThe terminology in radiological technology is crucial, encompassing a broad range of principles from radiation to medical imaging, and involving various specialists. This study aimed to evaluate the accuracy of automatic synonym detection considering the characteristics of the Japanese language by Word2vec and fastText in the radiological technology field for the terminology elaboration. We collected around 340 thousand abstracts in Japanese. First, preprocessing of the abstract data was performed. Then, training models were created with Word2vec and fastText with different architectures: continuous bag-of-words (CBOW) and skip-gram, and vector sizes. Baseline synonym sets were curated by two experts, utilizing terminology resources specific to radiological technology. A term in the dataset input into the generated models, and the top-10 synonym candidates which had high cosine similarities were obtained. Subsequently, precision, recall, F1-score, and accuracy for each model were calculated. The fastText model with CBOW at 300 dimensions was most precise in synonym detection, excelling in cases with shared n-grams. Conversely, fastText with skip-gram and Word2vec were favored for synonyms without common n-grams. In radiological technology, where n-grams are prevalent, fastText with CBOW proved advantageous, while in informatics, characterized by abbreviations and transliterations, Word2vec with CBOW was more effective.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-023-49708-8"
    },
    {
        "id": 11462,
        "title": "Perovskite‐based electrocatalyst discovery and design using word embeddings from retrained <scp>SciBERT</scp> language model",
        "authors": "Arun Muthukkumaran, Shrayas Raghunathan, Arjun Ravichandran, Raghunathan Rengaswamy",
        "published": "2023-7",
        "citations": 1,
        "abstract": "AbstractWith the ever‐increasing volume of scientific literature, there is a strong need to develop methods that allow rigorous information identification. In this contribution, a state‐of‐the‐art natural language processing (NLP) model was used to select perovskite materials for electrocatalytic applications from literature. This was accomplished by obtaining word embeddings for perovskite materials from the NLP model and subsequently designing downstream tasks to discover perovskite‐based electrocatalyst materials. However, embeddings could be obtained only for materials available in the literature. Consequently, a novel methodology was devised to generate embeddings for newly designed materials. Results from the analysis showed that the computed embeddings could be used to rank materials for their suitability for electrocatalytic applications. Further, the word embeddings were also employed as features in predicting the electrocatalytic activity of perovskite‐based electrocatalysts. The analysis demonstrated that the fidelity of regression models increased when the embeddings were used as features.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/aic.18068"
    },
    {
        "id": 11463,
        "title": "Expressivity-aware Music Performance Retrieval using Mid-level Perceptual Features and Emotion Word Embeddings",
        "authors": "Shreyan Chowdhury, Gerhard Widmer",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3632754.3632761"
    },
    {
        "id": 11464,
        "title": "Hybrid embeddings for transition-based dependency parsing of free word order languages",
        "authors": "Fatima Tuz Zuhra, Khalid Saleem",
        "published": "2023-5",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ipm.2023.103334"
    },
    {
        "id": 11465,
        "title": "A Deep Learning Approach for Author Profiling using Word Embeddings",
        "authors": "Dr. T. Raghunadha Reddy, B. Madhubala, G. Varshini, S. K . Fayaz",
        "published": "2023-5-31",
        "citations": 0,
        "abstract": "Abstract: The task of author profiling involves predicting various characteristics of an author based on their writing style, such as their age, gender, native language, and personality traits. The PAN2013 shared task focused on author profiling in social media, where participants were tasked with predicting the gender and age of Twitter users based on their tweets. In recent years, deep learning approaches have become popular for author profiling. Two popular models are GloVe and FastText are used by the researchers to generate word embeddings. GloVe is a word embedding model that represents words as vectors in a highdimensional space, while FastText takes into account subword information to represent words. Both models have been shown to be effective for various natural language processing tasks. For the PAN2013 task, participants used various deep learning models with GloVe and FastText embeddings to predict the age and gender of Twitter users. Some approaches used a combination of multiple models to improve the performance. In this article, we focused on improving the accuracy of age and gender classification on the PAN2013 dataset, which is a benchmark corpus for author profiling. We utilized deep learning models such as Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN) classifiers to classify authors based on their age and gender. We also used pre-trained word embeddings such as FastText and GloVe to represent the text data. Our results showed that the LSTM model achieved an accuracy of 57.53% for age classification and 60.48% gender classification, while the CNN model achieved an accuracy of 59.32% for age classification and 52.21% for gender classification. We observed that these models have been shown to be effective for various natural language processing tasks and can be used for other author profiling tasks as well.",
        "keywords": "",
        "link": "http://dx.doi.org/10.22214/ijraset.2023.51765"
    },
    {
        "id": 11466,
        "title": "Effect of Attention and Self-Supervised Speech Embeddings on Non-Semantic Speech Tasks",
        "authors": "Payal Mohapatra, Akash Pandey, Yueyuan Sui, Qi Zhu",
        "published": "2023-10-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3581783.3612855"
    },
    {
        "id": 11467,
        "title": "Learning Multi-Stage Multi-Grained Semantic Embeddings for E-Commerce Search",
        "authors": "Binbin Wang, Mingming Li, Zhixiong Zeng, Jingwei Zhuo, Songlin Wang, Sulong Xu, Bo Long, Weipeng Yan",
        "published": "2023-4-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3543873.3584638"
    },
    {
        "id": 11468,
        "title": "Preliminary Tasks of Word Embeddings Comparison of Unaligned Audio and Text Data for the Kazakh Language",
        "authors": "Zhanibek Kozhirbayev, Talgat Islamgozhayev, Altynbek Sharipbay, Arailym Serkazyyeva, Zhandos Yessenbayev",
        "published": "2023-10-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wi-iat59888.2023.00072"
    },
    {
        "id": 11469,
        "title": "Application of Convolutional Neural Network (CNN) and Word Embeddings on Plot Summaries for Movie Prediction",
        "authors": "Kean Soh Zhe Herng, Yen-Min Jasmina Khaw, Seng Poh Lim, Tan Joi San",
        "published": "2023-9-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aidas60501.2023.10284629"
    },
    {
        "id": 11470,
        "title": "Effect of dimensionality change on the bias of word embeddings",
        "authors": "Rohit Raj Rai, Amit Awekar",
        "published": "2024-1-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3632410.3632499"
    },
    {
        "id": 11471,
        "title": "Improving Oral Reading Fluency Assessment Through Sub-Sequence Matching of Acoustic Word Embeddings",
        "authors": "Yihao Wang, Zhongdi Wu, Joseph Nese, Akihito Kamata, Vedant Nilabh, Eric C. Larson",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10447029"
    },
    {
        "id": 11472,
        "title": "Word embeddings for topic modeling: An application to the estimation of the economic policy uncertainty index",
        "authors": "Hairo U. Miranda-Belmonte, Victor Muñiz-Sánchez, Francisco Corona",
        "published": "2023-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2022.118499"
    },
    {
        "id": 11473,
        "title": "On combining image features and word embeddings for image captioning",
        "authors": "Mateusz Bartosiewicz, Marcin Iwanowski, Martika Wiszniewska, Karolina Frączak, Paweł Leśnowolski",
        "published": "2023-9-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.15439/2023f997"
    },
    {
        "id": 11474,
        "title": "Multi-objective Search for Gender-fair and Semantically Correct Word Embeddings (HOP GECCO'23)",
        "authors": "Max Hort, Rebecca Moussa, Federica Sarro",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3583133.3595847"
    },
    {
        "id": 11475,
        "title": "Text Classification of Climate Change Tweets using Artificial Neural Networks, FastText Word Embeddings, and Latent Dirichlet Allocation",
        "authors": "John Daves S. Baguio, Billy A. Lu, Christine F. Peña",
        "published": "2023-6-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/apsit58554.2023.10201782"
    },
    {
        "id": 11476,
        "title": "Multi-day activity pattern recognition based on semantic embeddings of activity chains",
        "authors": "Wenxiang Li, Yuliang Zhang, Yifan Chen, Longyuan Ding, Yijun Zhu, Xiqun (Michael) Chen",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.tbs.2023.100682"
    },
    {
        "id": 11477,
        "title": "A Sememe Prediction Method Based on the Central Word of a Semantic Field",
        "authors": "Guanran Luo, Yunpeng Cui",
        "published": "2024-1-19",
        "citations": 0,
        "abstract": "A “sememe” is an indivisible minimal unit of meaning in linguistics. Manually annotating sememes in words requires a significant amount of time, so automated sememe prediction is often used to improve efficiency. Semantic fields serve as crucial mediators connecting the semantics between words. This paper proposes an unsupervised method for sememe prediction based on the common semantics between words and semantic fields. In comparison to methods based on word vectors, this approach demonstrates a superior ability to align the semantics of words and sememes. We construct various types of semantic fields through ChatGPT and design a semantic field selection strategy to adapt to different scenario requirements. Subsequently, following the order of word–sense–sememe, we decompose the process of calculating the semantic sememe similarity between semantic fields and target words. Finally, we select the word with the highest average semantic sememe similarity as the central word of the semantic field, using its semantic primes as the predicted result. On the BabelSememe dataset constructed based on the sememe knowledge base HowNet, the method of semantic field central word (SFCW) achieved the best results for both unstructured and structured sememe prediction tasks, demonstrating the effectiveness of this approach. Additionally, we conducted qualitative and quantitative analyses on the sememe structure of the central word.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics13020413"
    },
    {
        "id": 11478,
        "title": "Factors Influencing the Semantic Context Benefit to Foreign-accented Word Recognition",
        "authors": "Kailun Zhao",
        "published": "2024-3",
        "citations": 0,
        "abstract": "The current review discusses about the nature of semantic context benefit in accented listening comprehension by reviewing and analyzing the main listener and stimulus factors influencing the benefit of semantic context. This review investigates the impact of various factors, including age, vocabulary knowledge, second language proficiency, accent strength, noise interference, and accent familiarity, on the effectiveness of semantic context in aiding the comprehension of accented speech. Semantic context plays a crucial role in facilitating comprehension but its efficacy varies across different characteristics. Understanding these factors can inform the development of effective strategies for improving accented speech perception and optimizing language learning environments. Identifying the interplay between these variables is essential for addressing challenges in intercultural communication and promoting linguistic diversity in multilingual contexts.",
        "keywords": "",
        "link": "http://dx.doi.org/10.56397/jlcs.2024.03.15"
    },
    {
        "id": 11479,
        "title": "Influence of Cultural Differences on Word Meaning and Semantic Comprehension in English-Chinese Translation",
        "authors": "Kong Yan",
        "published": "2023-3-9",
        "citations": 0,
        "abstract": "In this study, we conduct the in-depth analysis of influence of cultural differences on the word meaning and semantic comprehension in English-Chinese translation. Translation is a speech activity that re-expresses what is expressed in the first language (source language) in a second language (target language), hence, the consideration of the cultural issues will be essential. In the process of English-Chinese translation, the application of form and meaning in English and Chinese is not absolutely separated, that is, Chinese is not only expressed in terms of meaning and English is not only expressed in form. We provide the novel suggestions for the translation methods considering the culture which will guide the translation performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.7753/ijsea1203.1026"
    },
    {
        "id": 11480,
        "title": "Exploring Word Sense Distribution in Ukrainian with a Semantic Vector Space Model",
        "authors": "Nataliia Cheilytko, Ruprecht von Waldenfels",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.unlp-1.9"
    },
    {
        "id": 11481,
        "title": "Semantic Specialization for Knowledge-based Word Sense Disambiguation",
        "authors": "Sakae Mizuki, Naoaki Okazaki",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.eacl-main.251"
    },
    {
        "id": 11482,
        "title": "Duality-Induced Regularizer for Semantic Matching Knowledge Graph Embeddings",
        "authors": "Jie Wang, Zhanqiu Zhang, Zhihao Shi, Jianyu Cai, Shuiwang Ji, Feng Wu",
        "published": "2023-2-1",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tpami.2022.3161804"
    },
    {
        "id": 11483,
        "title": "Classification of News Texts with GloVe Word Embeddings and Neural Networks",
        "authors": "Hulya HARK, Meral KARAKURT, Cengiz HARK, Ali KARCİ",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "Dijital haberlerin artan miktarları, istenilen türdeki haberlere doğru ve hızlı bir şekilde erişim için haber metinlerinin kategorilere ayrılmasını gerektirmektedir. Bu çalışmada, ön-eğitimli kelime gömülmelerinin, Uzun Ömürlü Kısa Dönem Bellek Ağı (Long-Short Term Memory, LSTM) ve Evrişimsel Sinir Ağları (Convolutional Neural Network, CNN) gibi derin öğrenme modelleri üzerindeki etkisi araştırılmaktadır. Global Vektör (GloVe) kelime gömülmelerinden alınan bağlamsal temsilleri girdi olarak alan LSTM ve CNN ağları kullanılarak haber metinleri sınıflandırılmıştır. Kapsamlı ve karşılaştırmalı araştırmaların eksikliği nedeniyle GloVe gömme katmanı tarafından sağlanan bağlamsal temsiller farklı sınıflandırıcılar ve veri setleri üzerinde test edilmektedir. Deneysel süreçler boyunca Türkçe Haber başlıklarından oluşan Turkish Headlines veri seti ve BBC News Classification veri setleri kullanılmıştır. Kelime gömülmelerinin ağlar üzerindeki etkisini ortaya koymak için deneysel süreçler aynı parametreler ile tekrarlanmıştır. LSTM modelinde Glove kelime gömülme yöntemi kullanıldığında modelin başarısının %81’den %91’e çıktığı gözlemlenmektedir. CNN modelinde ise Glove kelime gömülmelerinin modelin başarısının olumlu yansımadığı görülmektedir.",
        "keywords": "",
        "link": "http://dx.doi.org/10.29132/ijpas.1265301"
    },
    {
        "id": 11484,
        "title": "Regressing Word and Sentence Embeddings for Low-Resource Neural Machine Translation",
        "authors": "Inigo Jauregi Unanue, Ehsan Zare Borzeshi, Massimo Piccardi",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tai.2022.3187680"
    },
    {
        "id": 11485,
        "title": "Automatically Assembling a Custom-Built Training Corpus for Improving the Learning of In-Domain Word/Document Embeddings",
        "authors": "Yolanda Blanco-Fernández, Alberto Gil-Solla, José J. Pazos-Arias, Diego Quisi-Peralta",
        "published": "2023",
        "citations": 0,
        "abstract": "Embedding models turn words/documents into real-number vectors via co-occurrence data from unrelated texts. Crafting domain-specific embeddings from general corpora with limited domain vocabulary is challenging. Existing solutions retrain models on small domain datasets, overlooking potential of gathering rich in-domain texts. We exploit Named Entity Recognition and Doc2Vec for autonomous in-domain corpus creation. Our experiments compare models from general and in-domain corpora, highlighting that domain-specific training attains the best outcome.",
        "keywords": "",
        "link": "http://dx.doi.org/10.15388/23-infor527"
    },
    {
        "id": 11486,
        "title": "The Voice Category in the Even Language: Semantic Specificity, Interaction of Indicators in the Word Form",
        "authors": "S.I. Sharina",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25693/svgv.2023.42.1.003"
    },
    {
        "id": 11487,
        "title": "An Analysis of Semantically-Aligned Speech-Text Embeddings",
        "authors": "Muhammad Huzaifah, Ivan Kukanov",
        "published": "2023-1-9",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/slt54892.2023.10023147"
    },
    {
        "id": 11488,
        "title": "ABOUT THE CHANGES IN THE SEMANTIC DEVELOPMENT OF THE WORD",
        "authors": "G Rozikova",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56292/sjfsu/vol29_iss2/a105"
    },
    {
        "id": 11489,
        "title": "Learning adversarial semantic embeddings for zero-shot recognition in open worlds",
        "authors": "Tianqi Li, Guansong Pang, Xiao Bai, Jin Zheng, Lei Zhou, Xin Ning",
        "published": "2024-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2024.110258"
    },
    {
        "id": 11490,
        "title": "SEMANTIC AND PRAGMATIC TRANSFORMATIONS OF THE RUSSIAN WORD MATUSHKA ‘MOTHER’",
        "authors": "М.А. Кронгауз",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "В статье исследуются семантические и прагматические особенности слова матушка. Благодаря наличию эмоциональных и оценочных компонентов матушка легче, чем слово мать, отрывается от исходного значения и в большей степени подвергается метафорическим переносам. Основами для метафорического переноса становятся такие компоненты значения, как ‘кормилица’, ‘повелительница’, ‘заступница’, ‘близость’, ‘привычность’. В позиции обращения прагматические характеристики адресата оказываются еще более разнообразными. Такое обращение может в зависимости от коммуникативной ситуации выражать ‘покровительственность’, ’превосходство’, ’добродушие’, ’игривость’, ‘фамильярность’, ’доброжелательность’. В позиции обращения происходит семантическое опустошение слова, т. е. удаление от исходного значения, связанного с потерей компонентов значения. Максимальным удалением можно считать гендерное опустошение, т. е. использование слова матушка по отношению к мужчине.\nThe article explores semantic and pragmatic features of the word matushka. Because of the emotional and evaluative components, matushka is easier is more easily detached from its original meaning than the word mat’, and is more prone to metaphorical transfers. The basis for metaphorical transference are such components of meaning as 'feeder', 'overlord', 'defender', 'intimacy', 'habituality'. The pragmatic characteristics of the addressee are even more varied when matushka is used as a form of address. Such addressing (depending on the communicative situation) may express 'patronage', 'superiority', 'good nature', 'playfulness', 'familiarity', 'goodwill'. In the position of addressing there happens a semantic emptying of the word, that is, the removal from the original value associated with the loss of components of the meaning. The marker of maximum distance can be considered gender devastation, that is, the use of the word matushka when addressing a male.",
        "keywords": "",
        "link": "http://dx.doi.org/10.37632/pi.2023.300.5.007"
    },
    {
        "id": 11491,
        "title": "Measuring Lexico-Semantic Alignment in Debates with Contextualized Word Representations",
        "authors": "Aina Garí Soler, Matthieu Labeau, Chloé Clavel",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.sicon-1.6"
    },
    {
        "id": 11492,
        "title": "Semantic dementia in Arabic: An assessment of Arabic word reading within sentences",
        "authors": "Taim A. Muayqil",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/23279095.2023.2276436"
    },
    {
        "id": 11493,
        "title": "Variance Matters: Detecting Semantic Differences without Corpus/Word Alignment",
        "authors": "Ryo Nagata, Hiroya Takamura, Naoki Otani, Yoshifumi Kawasaki",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.965"
    },
    {
        "id": 11494,
        "title": "A Word Sense Distribution-based approach for Semantic Change Prediction",
        "authors": "Xiaohang Tang, Yi Zhou, Taichi Aida, Procheta Sen, Danushka Bollegala",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.231"
    },
    {
        "id": 11495,
        "title": "Polymeaning-Word Congruency and  Memory Division Support the Semantic/Syntactic/Episodic  Model of Native Language",
        "authors": "Zi-Jian Cai",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.4236/psych.2023.1412103"
    },
    {
        "id": 11496,
        "title": "Effect of contextual diversity on word recognition in different semantic contexts",
        "authors": "Zhongchen Mu",
        "published": "2024-2",
        "citations": 0,
        "abstract": "AbstractEfficient word recognition is important to facilitate reading comprehension. Two important factors influence word recognition—word frequency (WF) and contextual diversity (CD)—but studies have not reached consistent conclusions on their role. Based on previous studies, the present study strictly controlled the anticipation of sentence context on target words. In the context of the semantic incongruence of Chinese sentences—that is, when the context is equivalent and low in anticipation of the target noun—CD effects were found on late processing indicators of the eye movement data of parafoveal words, and the CD feature of parafoveal words led to a significant parafoveal‐on‐foveal effect. However, none of these results were found in the semantically reasonable (semantic congruence) context. The results suggested that high CD words are better at adapting to unexposed or learned contexts, which was not the case for high WF words.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/pchj.716"
    },
    {
        "id": 11497,
        "title": "Retracted: Accurate Estimation of English Word Similarity Based on Semantic Network",
        "authors": "",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9842343"
    },
    {
        "id": 11498,
        "title": "SzegedAI at SemEval-2023 Task 1: Applying Quasi-Symbolic Representations in Visual Word Sense Disambiguation",
        "authors": "Gábor Berend",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.semeval-1.270"
    },
    {
        "id": 11499,
        "title": "Shahmukhi named entity recognition by using contextualized word embeddings",
        "authors": "Amina Tehseen, Toqeer Ehsan, Hannan Bin Liaqat, Xiangjie Kong, Amjad Ali, Ala Al-Fuqaha",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.120489"
    },
    {
        "id": 11500,
        "title": "Using word embeddings to analyse audience effects and individual differences in parenting Subreddits",
        "authors": "Melody Sepahpour-Fard, Michael Quayle, Maria Schuld, Taha Yasseri",
        "published": "2023-9-20",
        "citations": 0,
        "abstract": "AbstractThis paper explores how individuals’ language use in gender-specific groups (“mothers” and “fathers”) compares to their interactions when referred to as “parents.” Language adaptation based on the audience is well-documented, yet large-scale studies of naturally-occurring audience effects are rare. To address this, we investigate audience and gender effects in the context of parenting, where gender plays a significant role. We focus on interactions within Reddit, particularly in the parenting Subreddits r/Daddit, r/Mommit, and r/Parenting, which cater to distinct audiences. By analyzing user posts using word embeddings, we measure similarities between user-tokens and word-tokens, also considering differences among high and low self-monitors. Results reveal that in mixed-gender contexts, mothers and fathers exhibit similar behavior in discussing a wide range of topics, while fathers emphasize more on educational and family advice. Single-gender Subreddits see more focused discussions. Mothers in r/Mommit discuss medical care, sleep, potty training, and food, distinguishing themselves. In terms of individual differences, we found that, especially on r/Parenting, high self-monitors tend to conform more to the norms of the Subreddit by discussing more of the topics associated with the Subreddit.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1140/epjds/s13688-023-00412-7"
    },
    {
        "id": 11501,
        "title": "Finding words that aren’t there: Using word embeddings to improve dictionary search for low-resource languages",
        "authors": "Antti Arppe, Andrew Neitsch, Daniel Dacanay, Jolene Poulin, Daniel Hieber, Atticus Harrigan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.americasnlp-1.15"
    },
    {
        "id": 11502,
        "title": "Word Embeddings of Country and Product Names Using Manchu Corpus",
        "authors": "Sung-hoon Jung, Jeong-up Do, Woon-ho Choi",
        "published": "2024-2-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.35559/tjoh.58.7"
    },
    {
        "id": 11503,
        "title": "Aligning Word Embeddings from BERT to Vocabulary-Free Representations",
        "authors": "Alejandro Rodriguez Perez, Korn Sooksatra, Pablo Rivas, Ernesto Quevedo, Javier Turek, Gisela Bichler, Tomas Cerny, Laurie Giddens, Stacie Petter",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/csce60160.2023.00023"
    },
    {
        "id": 11504,
        "title": "Application of specialized word embeddings and named entity and attribute recognition to the problem of unsupervised automated clinical coding",
        "authors": "Namrata Nath, Sang-Heon Lee, Ivan Lee",
        "published": "2023-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compbiomed.2023.107422"
    }
]