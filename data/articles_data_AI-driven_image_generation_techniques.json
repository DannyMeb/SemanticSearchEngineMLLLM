[
    {
        "id": 28705,
        "title": "Semantic-Driven Global-Local Cooperative Contrastive Learning for Medical Report Generation",
        "authors": "Shuchang Ye, Mingyuan Meng, David Dagan Feng, Jinman Kim",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dicta60407.2023.00042"
    },
    {
        "id": 28706,
        "title": "Text-To-Image Generation Using AI",
        "authors": "Pavithra V, Rosy S, Srinishanthini R B, Prinslin L",
        "published": "2023-4-27",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.55248/gengpi.234.4.38568"
    },
    {
        "id": 28707,
        "title": "AI-DRIVEN IMAGE DESCRIPTION",
        "authors": "",
        "published": "2024-4-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets51519"
    },
    {
        "id": 28708,
        "title": "Mammograms-Based Breast Cancer Detection Using Ai Image Processing Techniques",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/jclm.v11i1.617"
    },
    {
        "id": 28709,
        "title": "An Evaluation of AI-Driven Data Mining Techniques for Large-Scale Data Processing",
        "authors": "Sheetal Choudhary, Naghma Khatoon, K. Ranjith Singh, Divya K, Santosh D. Kumar, Abhishek Kumar Gupta",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smartgencon60755.2023.10441964"
    },
    {
        "id": 28710,
        "title": "AI image generation boosts Kansei engineering design process",
        "authors": "Shigekazu Ishihara, Rueikai Kuo, Keiko Ishihara",
        "published": "2023",
        "citations": 0,
        "abstract": "Methods of Kansei engineering help the design process by surveying users’ latent Kansei, then reflecting it on product and service development and continuous elaborations of them (Nagamachi, 1991, 2012). Through our applications of Kansei engineering to product development, we have learned that there are several common difficulties. 1. Evaluation samples’ lack of variety: products in the market have limitations in design. 2. Everyone is encouraged to participate in the design process with Kansei engineering: non-designers participation greatly contributes to successful products. 3. Designers are few and too busy: designers’ efforts should be reduced and make time to think more innovatively. In this study, to ease these problems, we have applied AI image generators, a recent development of artificial intelligence, to the Kansei engineering design process.Milkcarton Kansei studies result (Ishihara et al., 1996) is the starting point of this study. First, we examine StableDiffusion (Rombach et al. 2021), an image generation artificial intelligence system. StableDiffusion (SD) seems to lack milkcarton’s shape knowledge. Then we made incremental learning of its shape with the “Hypernetworks” framework. A common method to make innovative ideas is borrowing ideas from neighboring areas. Milkcarton in red is quite a few. On the other hand, our Beer can Kansei study (Ishihara, 1998) shows that Red color has strong relation between Kansei of Premium, Gorgeous, Affected, and Showy. Then, we try to apply a red color. The AI-generated “Red flower milkcarton” is nicely designed. Our 1996 study showed that blue has the preferred color for milkcarton. Blue abstract shapes are too often used for it; then people have Kansei as “simple”, “proper” and “monotonous”. In this attempt, we seek a “modern” and “refined” touch to blue and abstract design. The AI-generated design successfully incorporated modern touch to blue-based design. Also, we have tried more novel ideas of “Colorful painting modern milkcarton”. Milkcartons have different colors and have been implicitly or explicitly intended for “Juvenile” and “Tender” Kansei. This trial also adds modern touch, and novel designs are obtained. Finally, “Jackson Pollock painting milkcarton” was examined. The result reflects his abstract painting in the 1940s, before his invention of “drop painting”.In its long-year quest for Kansei engineering, KE methodology shows its stimulating role of innovative and problem-solving design. This study challenged the use of cutting-edge AI technology to boost more innovative designs. Along with AI technology extends, further methods for boosting innovative creation interacting with humans.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54941/ahfe1002988"
    },
    {
        "id": 28711,
        "title": "A Study Of AI Techniques In Image Processing",
        "authors": "Lakshmi Kumari -",
        "published": "2023-3-24",
        "citations": 0,
        "abstract": "Digital image processing is the process of manipulating digital image with the help of various algorithms which will result into the removal of any distortion of images while transfer or while storage. The image processing techniques will includes various methods like image enhancement, image restoration image segmentation ,image compression ,image manipulation ,image generation, image –to-image translation. This paper studies about different image processing task that can be performed on different types of images so as to enhance or restore the images.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36948/ijfmr.2023.v05i02.1997"
    },
    {
        "id": 28712,
        "title": "Automated cheque image processing AI driven recognition for efficient banking",
        "authors": "",
        "published": "2023-10-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets44875"
    },
    {
        "id": 28713,
        "title": "Data-driven modeling of power generation for a coal power plant under cycling",
        "authors": "Himanshu Sharma, Laurentiu Marinovici, Veronica Adetola, Herbert T. Schaef",
        "published": "2023-1",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.egyai.2022.100214"
    },
    {
        "id": 28714,
        "title": "Evaluating Deep Learning Techniques for Blind Image Super-Resolution within a High-Scale Multi-Domain Perspective",
        "authors": "Valdivino Alexandre de Santiago Júnior",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "Despite several solutions and experiments have been conducted recently addressing image super-resolution (SR), boosted by deep learning (DL), they do not usually design evaluations with high scaling factors. Moreover, the datasets are generally benchmarks which do not truly encompass significant diversity of domains to proper evaluate the techniques. It is also interesting to remark that blind SR is attractive for real-world scenarios since it is based on the idea that the degradation process is unknown, and, hence, techniques in this context rely basically on low-resolution (LR) images. In this article, we present a high-scale (8×) experiment which evaluates five recent DL techniques tailored for blind image SR: Adaptive Pseudo Augmentation (APA), Blind Image SR with Spatially Variant Degradations (BlindSR), Deep Alternating Network (DAN), FastGAN, and Mixture of Experts Super-Resolution (MoESR). We consider 14 datasets from five different broader domains (Aerial, Fauna, Flora, Medical, and Satellite), and another remark is that some of the DL approaches were designed for single-image SR but others not. Based on two no-reference metrics, NIQE and the transformer-based MANIQA score, MoESR can be regarded as the best solution although the perceptual quality of the created high-resolution (HR) images of all the techniques still needs to improve.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ai4030032"
    },
    {
        "id": 28715,
        "title": "Empowering Autistic Children’s Emotional Development through AI-Based Image Generation System",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25236/far.2023.051604"
    },
    {
        "id": 28716,
        "title": "Why AI-Driven Analytics Are Essential for Next-Generation Pipeline Condition Assessments",
        "authors": "Marshall Kennedy, Boyu Liu, Eric Toffin",
        "published": "2023-8-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1061/9780784485033.017"
    },
    {
        "id": 28717,
        "title": "AI-Driven User Story Generation",
        "authors": "Carlos Alberto Dos Santos, Kevin Bouchard, Fabio Petrillo",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/acdsa59508.2024.10467677"
    },
    {
        "id": 28718,
        "title": "Skilled Resilience: Revitalizing Asian American and Pacific Islander Entrepreneurship Through AI-Driven Social Media Marketing Techniques",
        "authors": "Vanya Shrivastava",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4507541"
    },
    {
        "id": 28719,
        "title": "Extracting features of tomato viral leaf diseases using image processing techniques",
        "authors": "Sanjeela Sagar, Jaswinder Singh",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "<span>Agriculture is the main livelihood of Indians. More than 50% of Indian population Is dependent on it and it contributes about 18% of Indian gross domestic product (GDP). According to Inc42, the agricultural sector of India is predicted to increase to US$ 24 billion by 2025. With the increase in population, the demand for food also increases, but more than 30% of crops get affected due to crop diseases. Overall, India lost approximately five million hectares of crop area to flash floods, cyclonic storms, floods, cloudbursts, and landslides till 2021. In that case, there is a need to prevent crops from diseases to fulfil demand supply ratio. This paper presents the feature extraction of tomato viral leaf diseases using various image processing techniques. Most of the research uses Convolutional Neural networks to extract the features of these diseases, but these neural networks are not performing much accurately in real scenarios, so there is a need to extract the features using image processing methods. During the study, it is found that these diseases have different colours, shapes and textures and these features can be used with convolution neural networks to bring more accurate results in real scenarios.</span>",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijai.v13.i1.pp925-932"
    },
    {
        "id": 28720,
        "title": "Explore the Future Earth with Wander 2.0: AI Chatbot Driven By Knowledge-base Story Generation and Text-to-image Model",
        "authors": "Yuqian Sun, Ying Xu, Chenhang Cheng, Yihua Li, Chang Hee Lee, Ali Asadipour",
        "published": "2023-4-19",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3544549.3583931"
    },
    {
        "id": 28721,
        "title": "AI-driven image analysis for cancer cell biology",
        "authors": "Gillian Lovell",
        "published": "2023-4-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18609/ioi.2023.007"
    },
    {
        "id": 28722,
        "title": "Channeling Creativity Through a Deeper Understanding of AI Image Generation",
        "authors": "Joyce Lee, Natalie Summers",
        "published": "2023-7-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3588029.3599743"
    },
    {
        "id": 28723,
        "title": "Text-to-Image Generation using Generative AI",
        "authors": "Reshma S",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "Abstract—This survey reviews text-to-image generation by using different approaches. One of the approaches identified in this study is Cross-modal Semantic Matching Generative Adversarial Networks (CSM-GAN), which is used to increase semantic consistency between text  descriptions and synthesised pictures for fine-grained text- to-image creation. This includes other two modules, Text  Encoder Module and Textual-Visual Semantic Matching  Module. We further discussed about Imagen which is a text- to-image diffusion model with photorealism and deep  language understanding, which is used on the COCO dataset. Lastly, we discussed about Text to image synthesis used to automates image generation using conditional generative models and GAN, enhancing artificial intelligence and deep learning. Based on these approaches we present a review of text to image generation using generative AI.  Keywords— Generative AI, Diffusion model, Text-to- image, Imagen, CSM-GAN",
        "keywords": "",
        "link": "http://dx.doi.org/10.55041/ijsrem25320"
    },
    {
        "id": 28724,
        "title": "Democratizing Personal Website Creation: An AI- Driven Approach for Effortless, Cost-efficient, and High-Quality Web Page Generation",
        "authors": "Jason Yang, Tiancheng Xu",
        "published": "2023-10-28",
        "citations": 0,
        "abstract": "As the world becomes increasingly digitized, the demand for personalized websites is also gradually growing [1]. However, creating a personal website is not an easy task. Generally speaking, people can invest time and effort to learn programming languages for website development, or they can spend money to purchase services fromprofessional web development companies. Both of these methods require significant investment in terms of time or money. To democratize the creation of personal websites, we have developed a program that automatically generates personalized web pages. Users simply need to input instructions in natural language, and the program will generate a personalized website based on the information provided. Websites produced in this manner usually have high quality while simultaneously saving substantial amounts of time and money [2].",
        "keywords": "",
        "link": "http://dx.doi.org/10.5121/csit.2023.131917"
    },
    {
        "id": 28725,
        "title": "Identifying Race and Gender Bias in Stable Diffusion AI Image Generation",
        "authors": "Aadi Chauhan, Taran Anand, Tanisha Jauhari, Arjav Shah, Rudransh Singh, Arjun Rajaram, Rithvik Vanga",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaic60265.2024.10433840"
    },
    {
        "id": 28726,
        "title": "AI-Driven Prediction of Average Per Capita GDP: Exploring Linear and Nonlinear Statistical Techniques",
        "authors": " Suhail Najm Abbood",
        "published": "2024-4-4",
        "citations": 0,
        "abstract": "Average per capita GDP income is an important economic indicator. Economists use this term to determine the amount of progress or decline in the country's economy. It is also used to determine the order of countries and compare them with each other. Average per capita GDP income was first studied using the Time Series (Box Jenkins method), and the second is linear and non-linear regression; these methods are the most important and most commonly used statistical methods for forecasting because they are flexible and accurate in practice. The comparison is made to determine the best method between the two methods mentioned above using specific statistical criteria. The research found that the best approach is to build a model for predicting Iraq’s average GDP per capita income by relying on the amounts of average GDP per capita income in the past years (1981-2020). The researcher found that in a second way, it became clear that the non-linear regression model of the Asian model was the best model representing (average per capita GDP income) in Iraq, and this model was used to predict the period (20221-2027). When comparing the two methods of projected amounts up to 2027, it was found that the best method was the second based on the indicator mean absolute percentage error (MAPE) because he has the least value.",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/jes.1273"
    },
    {
        "id": 28727,
        "title": "Artificial Intelligence and Comics : An Educational Approach to AI Image Generation Technology",
        "authors": "Hyuk–Chu Kwon",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.51467/asko.2023.12.19.4.38"
    },
    {
        "id": 28728,
        "title": "A Generative AI-driven Application: Use of Large Language Models for Traffic Scenario Generation",
        "authors": "Çağrı Güzay, Ege Özdemir, Yahya Kara",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eleco60389.2023.10415934"
    },
    {
        "id": 28729,
        "title": "Experiment and Evaluation of Architectural Image Generation through Artificial Intelligence-Based Text Image Generation Tool",
        "authors": "Dong Ho Lee, Sung Hak Ko",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.12813/kieae.2023.23.5.013"
    },
    {
        "id": 28730,
        "title": "A Crowd-Ai Dynamic Neural Network Hyperparameter Optimization Approach for Image-Driven Social Sensing Applications",
        "authors": "Yang Zhang, Ruohan Zhong, Lanyu Shang, Dong Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4399140"
    },
    {
        "id": 28731,
        "title": "AI-based matchmaking as an innovative tool for a network-driven event industry",
        "authors": "Dirk Hagen",
        "published": "2023-6-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2664391"
    },
    {
        "id": 28732,
        "title": "Colourify: Image Colourization using AI techniques",
        "authors": "Eeshita Deepta, Neha Juyal, Khushi Pareek, Bhawna Jha, Sumita Gupta",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10306379"
    },
    {
        "id": 28733,
        "title": "Face and liveness detection with criminal identification using machine learning and image processing techniques for security system",
        "authors": "Pratibha Shinde, Ajay R. Raundale",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "<p>In the past, real-world photos have been used to train classifiers for face liveness identification since the related face presentation attacks (PA) and real-world images have a high degree of overlap. The use of deep convolutional neural networks (CNN) and real-world face photos together to identify the liveness of a face, however, has received very little study. A face recognition system should be able to identify real faces as well as efforts at faking utilizing printed or digital presentations. A true spoofing avoidance method involves observing facial liveness, such as eye blinking and lip movement. However, this strategy is rendered useless when defending against replay assaults that use video. The anti-spoofing technique consists of two modules: the ConvNet classifier module and the blinking eye module, which measure lip and eye movement. The results of the testing demonstrate that the developed module is capable of identifying various face spoof assaults, including those made with the use of posters, masks, or smartphones. To assess the convolutional features in this study adaptively fused from deep CNN produced face pictures and convolutional layers learned from real-world identification. Extensive tests using intra-database and cross-database scenarios on cutting-edge face anti-spoofing databases including CASIA, OULU, NUAA and replay-attack dataset demonstrate that the proposed solution methods for face liveness detection. The algorithm has a 94.30% accuracy rate.</p>",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijai.v13.i1.pp722-729"
    },
    {
        "id": 28734,
        "title": "Next-Generation Closed-Loop Neural Interfaces: Circuit and AI-driven innovations",
        "authors": "Mahsa Shoaran",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mssc.2023.3309782"
    },
    {
        "id": 28735,
        "title": "Generation of high-fidelity signatures for AI/ML training database generation",
        "authors": "Matthew Rigney, Brad Seal, Chris Porter",
        "published": "2023-6-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2663906"
    },
    {
        "id": 28736,
        "title": "Social Biases through the Text-to-Image Generation Lens",
        "authors": "Ranjita Naik, Besmira Nushi",
        "published": "2023-8-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3600211.3604711"
    },
    {
        "id": 28737,
        "title": "Human-Centered and AI-driven Generation of 6-DoF Extended Reality",
        "authors": "Jit Chatterjee, Maria Torres Vega",
        "published": "2023-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3573381.3597232"
    },
    {
        "id": 28738,
        "title": "AI-assisted secure data transmission techniques for next-generation HetNets: A review",
        "authors": "Himanshu Sharma, Gitika Sharma, Neeraj Kumar",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.comcom.2023.12.015"
    },
    {
        "id": 28739,
        "title": "Comparative Analysis of Architectural Image Generation Capabilities and Characteristics of AI Rendering Programs",
        "authors": "Yoo Kyung Seol",
        "published": "2024-3-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17548/ksaf.2024.03.30.141"
    },
    {
        "id": 28740,
        "title": "BIOFEEDBACK-DRIVEN SOUND AND IMAGE GENERATION",
        "authors": "María Castelló, Claudio Burguez, Mikaela Pisani, Marcos Umpiérrez",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ibneur.2023.08.2022"
    },
    {
        "id": 28741,
        "title": "Revolutionary AI-Driven Techniques for Comprehensive Medical Service Enhancement with Enhanced Security Protocols",
        "authors": "Ankita Agarwal, Rajiv Ranjan Singh, Deepak Mehta",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ictbig59752.2023.10456143"
    },
    {
        "id": 28742,
        "title": "AI-Driven Optimization of Job Advertisements through Knowledge-Based Techniques and Semantic Matching",
        "authors": "Shatha Ajaj",
        "published": "2024-2-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21608/pserj.2024.260755.1308"
    },
    {
        "id": 28743,
        "title": "AI Image Generation Study Utilizing ChatGPT and Midjourney",
        "authors": "SangJi Park, KyoungSoo Kim",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.29056/jdaem.2023.12.06"
    },
    {
        "id": 28744,
        "title": "Studies Advanced in Image Generation Techniques based on Deep Learning",
        "authors": "Chang Liu",
        "published": "2023-4-1",
        "citations": 0,
        "abstract": "A popular area of study in computer vision is image generation. How to improve the authenticity and diversity of generated images, and how to reduce the use of hardware resources and the size of model storage to make it more conducive to model landing are the focus and difficulty of image generation algorithms. Moreover, in practical applications, many other tasks are closely related to the image generation task, utilizing the created picture can lower the cost of data collecting, and the produced picture's quality directly influences how well some activities work. This article first introduces the definition of the generated model in supervised learning and unsupervised learning, and analyzes several reasons why learning should be generated into a model. It also introduces the development of the generated models in China and abroad, and makes a simple classification of the generated models with the previous depth degree.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v39i.6646"
    },
    {
        "id": 28745,
        "title": "Controllable image generation and manipulation",
        "authors": "Ioannis Patras",
        "published": "2023-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3592572.3596476"
    },
    {
        "id": 28746,
        "title": "Live Power Generation Predictions via AI-Driven Resilient Systems in Smart Microgrids",
        "authors": "Xueyi Wang, Shancang Li, Muddesar Iqbal",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tce.2024.3371256"
    },
    {
        "id": 28747,
        "title": "AI-Driven Simplification of 3D Animation: Bridgingthe Gap between 2D and 3D with a Unity Package for predictive Pose Generation and Streamlined workflows",
        "authors": "Jiaxu Li, John Morris",
        "published": "2024-2-24",
        "citations": 0,
        "abstract": "This paper addresses the challenge of simplifying 3D animation by introducing a Unity package that harnesses artificial intelligence (AI) to convert 2D images or videos into 3D animation frames [2]. The background to this problem lies in the arduous and time-consuming nature of 3D animation, which often deters developers and artists from pursuing their creative visions [1]. Our proposed solution leverages AI algorithms to predict 3D poses and movements from 2D sources, making animation more accessible and cost-effective. Our package utilizes vector mathematics and Unity's capabilities, primarily focusing on establishing the body as an anchor for limb rotations. Challenges included intricate angle calculations and addressing orientation discrepancies. We resolved these challenges by refining the AI algorithms and providing user-friendly features [4]. Experimentation involved assessing accuracy, usability, and efficiency. While accuracy in complex scenarios remains a challenge, user feedback highlighted its potential for efficiency and time-saving. Ultimately, this tool bridges the gap between 2D and 3D animation, offering accessibility, costeffectiveness, and streamlined workflows [3]. Its potential impact on animation and game development makes it a valuable addition for both professionals and enthusiasts.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5121/csit.2024.140410"
    },
    {
        "id": 28748,
        "title": "Applied Generative AI and Deep Learning Techniques to Optimize\\Automate Strategic Geophysical Workflows and Insights Generation",
        "authors": "A. Dubovik, J. Aguas, H. Gill, R. Khudorozhkov",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3997/2214-4609.202439052"
    },
    {
        "id": 28749,
        "title": "Integrating AI-driven marketing analytics techniques into the classroom: pedagogical strategies for enhancing student engagement and future business success",
        "authors": "Kamaal Allil",
        "published": "2024-1-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1057/s41270-023-00281-z"
    },
    {
        "id": 28750,
        "title": "Image Generation and Feedback Based on Deep Learning in Visual Communication Design",
        "authors": "Ganlin Cheng",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/easct59475.2023.10393578"
    },
    {
        "id": 28751,
        "title": "Realistic image generation in virtual reality using deep learning techniques",
        "authors": "Biqin Deng",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3026441"
    },
    {
        "id": 28752,
        "title": "AI-Driven Industry 4.0: Advancing Quality Control through Cutting-Edge Image Processing for Automated Defect Detection",
        "authors": "Makund Arora",
        "published": "2023-8-30",
        "citations": 1,
        "abstract": "In the age of Industry 4.0, cutting-edge technology is revolutionizing manufacturing processes, with quality control playing a critical role in ensuring product reliability and customer satisfaction. Traditional manual inspection approaches are time-consuming, arbitrary, and prone to errors. This research paper proposes a breakthrough way for automatic defect diagnosis that leverages cutting-edge image processing techniques to improve quality control in Industry 4.0. Using data from actual manufacturing processes, the study comprises extensive trial and evaluation of the proposed solution. The study's findings provide crucial insights for improving quality control methods in the age of Industry 4.0, as well as for improving defect detection systems in the manufacturing industry.",
        "keywords": "",
        "link": "http://dx.doi.org/10.47760/ijcsmc.2023.v12i08.003"
    },
    {
        "id": 28753,
        "title": "The Work of Art in the Age of AI Image Generation",
        "authors": "Mark Coeckelbergh",
        "published": "2023-6-12",
        "citations": 0,
        "abstract": "AI image generators such as DALL-E 2 are deep learning models that enable users to generate digital images based on natural language text prompts. The impressive and often surprising results leave many people puzzled: is this art, and if so, who created the art: the human or the AI? These are not just theoretical questions; they have practical ethical and legal implications, for example when raising authorship and copyright issues. This essay offers two conceptual points of entrance that may help to understand what is going on here. First it briefly discusses the question whether this this art and who or what is the artist based on aesthetics, philosophy of art, and thinking about creativity and computing. Then it asks the question regarding human-technology relations. It shows that existing notions such as instrument, extension, and (quasi) other are insufficient to conceptualize the use of this technology, and proposes instead to understand what happens as processes and performances, in which artistic subjects, objects, and roles emerge. It is concluded that based on most standard criteria in aesthetics, AI image generation can in principle create art, and that the process can be seen as poietic performances involving humans and non-humans potentially leading to the emergence of new artistic (quasi)subjects and roles in the process.",
        "keywords": "",
        "link": "http://dx.doi.org/10.59490/jhtr.2023.1.7025"
    },
    {
        "id": 28754,
        "title": "ControlStyle: Text-Driven Stylized Image Generation Using Diffusion Priors",
        "authors": "Jingwen Chen, Yingwei Pan, Ting Yao, Tao Mei",
        "published": "2023-10-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3581783.3612524"
    },
    {
        "id": 28755,
        "title": "AI-Driven Nutritional Assessment Improving Diets with Machine Learning and Deep Learning for Food Image Classification",
        "authors": "Naresh Kumar Sripada, Sai Chetana Challa, Srishanka Kothakonda",
        "published": "2023-10-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icssas57918.2023.10331787"
    },
    {
        "id": 28756,
        "title": "Automated Netlist Generation from Offline Hand-Drawn Circuit Diagrams",
        "authors": "Waqas Uzair, Douglas Chai, Alexander Rassau",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dicta60407.2023.00057"
    },
    {
        "id": 28757,
        "title": "AI-Driven Innovations in Cryptography: Enhancing Key Generation and Security",
        "authors": "Ananda Priya B, Gnanachandra P, Seenivasan M",
        "published": "2023",
        "citations": 0,
        "abstract": "In this paper, we introduce a novel approach for securing confidential data through a symmetric key cryptographic algorithm called the modified Hill Cipher by utilizing rhotrices. We provide a step-by-step procedure to implement this method and elucidate the process through an example. The modified Hill Cipher technique uses AI to generate key rhotrix and incorporates the use of rhotrices and rhotrix algebra to encrypt plain text and decrypt cipher text.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1051/e3sconf/202339908001"
    },
    {
        "id": 28758,
        "title": "Magenta Hydrogen – An AI-Driven Hydrogen Production Associated with CO2 Plume Utilization for Geothermal Power Generation",
        "authors": "Klemens Katterbauer, Saleh F. Hassan, Moataz O. Abu Al Saud, Ali Yousef",
        "published": "2023-10-9",
        "citations": 0,
        "abstract": "Abstract\nEnergy and hydrogen have a long history together; more than 200 years ago, hydrogen-powered the first internal combustion engines and is now a crucial component of the contemporary refining sector. It emits no greenhouse gases or pollutants directly and is light, storable, and energy-dense. But adoption of hydrogen in areas where it is virtually nonexistent, like transportation, buildings, and power generation, is necessary for it to significantly contribute to clean energy transitions (Simpson and Lutz 2007).\nToday, hydrogen is gaining unheard-of momentum. The opportunity to make hydrogen a significant component of our future clean and secure energy supply should not be missed by the entire globe. Today, providing hydrogen to industrial users is a significant global industry. The worldwide demand for hydrogen, which has increased more than triple since 1975, is still on the rise. To produce hydrogen, 6% of the world's natural gas and 2% of its coal are used.\nAs a result, the generation of hydrogen results in annual CO2 emissions of around 830 million tonnes, which is equal to the combined emissions of the United Kingdom and Indonesia. Hydrogen can be collected from water, biomass, fossil fuels, or a combination of the three. Currently, natural gas serves as the main fuel for producing hydrogen, contributing about 75 percent of the 70 million tonnes of dedicated hydrogen produced annually worldwide. This makes up around 6% of the world's natural gas consumption. Due to coal's dominance in China, gas comes in second, and only a small portion is created by the usage of oil and electricity (Soltani, Rosen and Dincer 2014).",
        "keywords": "",
        "link": "http://dx.doi.org/10.2118/214902-ms"
    },
    {
        "id": 28759,
        "title": "Enhancing Data Engineering Efficiency with AI: Utilizing Retrieval-Augmented Generation, Reinforcement Learning from Human Feedback, and Fine-Tuning Techniques",
        "authors": "",
        "published": "2024-3-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets50070"
    },
    {
        "id": 28760,
        "title": "Embroidery Robotics: An Innovative Approach to AI-based Online Learning and Image Generation",
        "authors": "Ling Chen, Tianxin Zhang, Jing Chen",
        "published": "2023-8-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wrcsara60131.2023.10261779"
    },
    {
        "id": 28761,
        "title": "Identifying Race and Gender Bias in Latent Diffusion AI Image Generation",
        "authors": "Taran Anand, Aadi Chauhan, Tanisha Jauhari, Arjav Shah, Rudransh Singh, Benjamin Liang, Rupsha Dutta",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4602033"
    },
    {
        "id": 28762,
        "title": "EXPLORING THE ROLE OF TEXT-TO-IMAGE AI IN CONCEPT GENERATION",
        "authors": "Ross Brisco, Laura Hay, Sam Dhami",
        "published": "2023-7",
        "citations": 3,
        "abstract": "AbstractArtificial intelligence (AI) capable of generating images from a text prompt are becoming increasingly prevalent in society and design. The general public can use their computers and mobile devices to ask a complex text-to-image AI to create an image which is in some cases indistinguishable from that which a human could create using a computer graphics package. These images are shared on social media and have been used in the creation of art projects, documents and publications. This exploratory study aimed to identify if modern text-to-image AI (Midjourney, DALL-E 2, and Disco Diffusion) could be used to replace the designer in the concept generation stage of the design process. Teams of design students were asked to evaluate AI generated concepts from 15 to a final concept. The outcomes of this research are a first of its kind for the field of engineering design, in the identification of barriers in the use of current text-to-image AI for the purpose of engineering design. The discussion suggests how this can be overcome in the short term and what knowledge the research community needs to build to overcome these barriers in the long term.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1017/pds.2023.184"
    },
    {
        "id": 28763,
        "title": "Use of AI-driven Code Generation Models in Teaching and Learning Programming: a Systematic Literature Review",
        "authors": "Doga Cambaz, Xiaoling Zhang",
        "published": "2024-3-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3626252.3630958"
    },
    {
        "id": 28764,
        "title": "AI and Blockchain Based Platform for Empowering Content Creators: Enabling NFT – Driven Content Sharing, Inspiration Generation, and Collaborative Interaction",
        "authors": "Sri Likhita Adru, Sandra Johnson, M. Hemalatha",
        "published": "2023-9-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icosec58147.2023.10276305"
    },
    {
        "id": 28765,
        "title": "AI Advancements: Comparison of Innovative Techniques",
        "authors": "Hamed Taherdoost, Mitra Madanchian",
        "published": "2023-12-20",
        "citations": 0,
        "abstract": "In recent years, artificial intelligence (AI) has seen remarkable advancements, stretching the limits of what is possible and opening up new frontiers. This comparative review investigates the evolving landscape of AI advancements, providing a thorough exploration of innovative techniques that have shaped the field. Beginning with the fundamentals of AI, including traditional machine learning and the transition to data-driven approaches, the narrative progresses through core AI techniques such as reinforcement learning, generative adversarial networks, transfer learning, and neuroevolution. The significance of explainable AI (XAI) is emphasized in this review, which also explores the intersection of quantum computing and AI. The review delves into the potential transformative effects of quantum technologies on AI advancements and highlights the challenges associated with their integration. Ethical considerations in AI, including discussions on bias, fairness, transparency, and regulatory frameworks, are also addressed. This review aims to contribute to a deeper understanding of the rapidly evolving field of AI. Reinforcement learning, generative adversarial networks, and transfer learning lead AI research, with a growing emphasis on transparency. Neuroevolution and quantum AI, though less studied, show potential for future developments.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ai5010003"
    },
    {
        "id": 28766,
        "title": "Ameliorating Semantic Search Through Advanced AI Techniques",
        "authors": "Ravikumar V, Dharmesh Dhabliya, Mala Mathur, Sidhant Das, Ritesh Kumar, Srikrishna B Rao",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smartgencon60755.2023.10442780"
    },
    {
        "id": 28767,
        "title": "Automatic Generation of CEP Rules using Data Analysis Techniques and Model-Driven Engineering",
        "authors": "Mohsen Gholami, Bahman Zamani, Behrouz Shahgholi Ghahfarokhi",
        "published": "2023-10-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iot60973.2023.10365361"
    },
    {
        "id": 28768,
        "title": "AI and Beyond: New Techniques for Simulation and Design in HEP",
        "authors": "Kevin Pedro",
        "published": "2023-5-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2172/1975521"
    },
    {
        "id": 28769,
        "title": "Exploring AI-driven Innovations in Image Communication Systems for Enhanced Medical Imaging Applications",
        "authors": "Suresh Dodda,  Suman Narne, Sathishkumar Chintala, Satyanarayan Kanungo, Tolu Adedoja, Sourabh Sharma",
        "published": "2024-4-4",
        "citations": 0,
        "abstract": "Artificial intelligence (AI) has emerged as a promising avenue for enhancing medical imaging systems and improving clinical workflows. This research explores innovative applications of AI and deep learning for image communication networks in healthcare. Specifically, we develop an intelligent image compression framework that optimizes data transmission and speeds interpretation of radiology scans. Our approach combines convolutional neural networks, generative adversarial networks, and specialized image filters to balance communication efficiency, diagnostic accuracy, and system latency. Rigorous experiments validate superior performance over traditional methods and commercial products across modalities including MRI, CT, and ultrasound. Crucially, the proposed methods demonstrate expert-level precision in anatomy labeling and pathology detection. By intelligently streamlining image transfer and analytics, this AI-powered system could facilitate ubiquitous, real-time diagnostics via telemedicine. Enhanced connectivity between imaging devices and clinical specialists can improve patient outcomes and reduce healthcare costs. Our solutions set the stage for more advanced AI integration in imaging networks and data-intensive medicine",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/jes.1409"
    },
    {
        "id": 28770,
        "title": "Abstract 5418: AI-driven image analysis enables simplified, label-free cytotoxicity screening",
        "authors": "Gillian Lovell, Daniel A. Porto, Jasmine Trigg, Nevine Holtz, Nicola Bevan, Timothy Dale, Daniel Appledorn",
        "published": "2023-4-4",
        "citations": 0,
        "abstract": "Abstract\nThe increasing use of precious, patient-derived cells has driven the need for non-perturbing and label-free cell measurements, particularly in the oncology field. To address this we developed the Incucyte® AI Cell Health Analysis Software Module, which uses two pre-trained deep neural networks to perform automated, unbiased analysis of Phase contrast images to segment individual cells and perform label-free Live/Dead cell classification. The neural networks which perform cell instance segmentation and infer cell viability were trained on a wide diversity of cell types with varied morphologies, ensuring that the analysis is applicable across a variety of adherent and suspension tumor cell types. Here, we demonstrate the application of this analysis across diverse and commonly used biological models of breast cancer, glioblastoma, and B-cell lymphoma. In each case, cells were treated with chemotherapeutic compounds or biosimilar antibodies and Phase contrast images were acquired at regular intervals over 3 - 4 days using the Incucyte® Live-Cell Analysis System. Using the Incucyte® AI Cell Health Analysis cells were accurately segmented and the percentage of dead cells were quantified over time without the requirement for a fluorescent reporter or other exogenous label, and with limited user input. Four breast cancer cell lines were treated with a panel of chemotherapeutics designed to target specific expression patterns. AI Cell Health analysis showed that Estrogen receptor (ER) inhibitor Tamoxifen selectively induced &gt;60% cell death only in ER positive cell lines BT474 and MCF7; dual epidermal growth factor receptor (EGFR/HER2) inhibitor Lapatinib induced cell death in AU565, BT474 and MCF7 which express these surface markers. In contrast, Lapatinib and Tamoxifen induced morphological change - but minimal cell death - in triple negative MDA-MB-231 cells. Three glioblastoma cell lines A172, U87 and T98G were treated with a larger panel of chemotherapeutic compounds and for four of the active compounds, efficacy was also determined. Cisplatin, doxorubicin, vinblastine and taxol induced concentration-dependent cell death in A172 and T98G cells; U87 cells displayed resistance to each of these compounds with a maximal 46.5% cell death induced by doxorubicin. Ramos B-cell lymphoma cells were exposed to increasing concentrations of monoclonal antibody Rituximab and the biosimilar Truxima®. The antibodies induced specific cell death via the surface marker CD20 in a time and concentration-dependent manner with similar efficacy (IC50 Rituximab 94.7 ng/mL; Truxima® 110.3 ng/mL), while antibody control IgG1 remained non-perturbing to cells. These results demonstrate that the Incucyte® AI Cell Health Analysis is applicable to a broad range of cancer types cultured in 2D monolayer. This unbiased method enables accurate, label-free quantification of cytotoxic effects induced by clinically relevant therapeutics.\nCitation Format: Gillian Lovell, Daniel A. Porto, Jasmine Trigg, Nevine Holtz, Nicola Bevan, Timothy Dale, Daniel Appledorn. AI-driven image analysis enables simplified, label-free cytotoxicity screening. [abstract]. In: Proceedings of the American Association for Cancer Research Annual Meeting 2023; Part 1 (Regular and Invited Abstracts); 2023 Apr 14-19; Orlando, FL. Philadelphia (PA): AACR; Cancer Res 2023;83(7_Suppl):Abstract nr 5418.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1158/1538-7445.am2023-5418"
    },
    {
        "id": 28771,
        "title": "Antibiograms image classification based on AI techniques",
        "authors": "Ruaa Jasim Al Gharrawi, Alyaa Abdulhussein Al-Joda",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0199701"
    },
    {
        "id": 28772,
        "title": "Data-Driven Next-Generation Wireless Networking: Embracing AI for Performance and Security",
        "authors": "Jiahao Xue, Zhe Qu, Shangqing Zhao, Yao Liu, Zhuo Lu",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccn58024.2023.10230189"
    },
    {
        "id": 28773,
        "title": "A Comparative Review of AI Techniques for Automated Code Generation in Software Development: Advancements, Challenges, and Future Directions",
        "authors": "Ayman Odeh, Nada Odeh, Abdul Salam Mohammed",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "Artificial Intelligence (AI), as one of the most important fields of computer science, plays a significant role in the software development life cycle process, especially in the implementation phase, where developers require considerable effort to convert software requirements and design into code. Automated Code Generation (ACG) using AI can help in this phase. Automating the code generation process is becoming increasingly popular as a solution to address various software development challenges and increase productivity. In this work, we provide a comprehensive review and discussion of traditional and AI techniques used for ACG, their challenges, and limitations. By analysing a selection of related studies, we will identify all AI methods and algorithms used for ACG, extracting the evaluation metrics and criteria such as Accuracy, Efficiency, Scalability, Correctness, Generalization, and more. These criteria will be used to perform a comparative result for AI methods used for ACG, exploring their applications, strengths, weaknesses, performance, and future applications.",
        "keywords": "",
        "link": "http://dx.doi.org/10.18421/tem131-76"
    },
    {
        "id": 28774,
        "title": "A Design Methodology of MMIC Power Amplifiers Using AI-driven Design Techniques",
        "authors": "Liyuan Xue, Haijun Fan, Yuan Ding, Bo Liu",
        "published": "2023-7-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smacd58065.2023.10192155"
    },
    {
        "id": 28775,
        "title": "Data-driven approach for AI-based crack detection: techniques, challenges, and future scope",
        "authors": "Priti S. Chakurkar, Deepali Vora, Shruti Patil, Sashikala Mishra, Ketan Kotecha",
        "published": "2023-10-25",
        "citations": 1,
        "abstract": "This article provides a systematic literature review on the application of artificial intelligence (AI) technology for detecting cracks in civil infrastructure, which is a critical issue affecting the performance and longevity of these structures. Traditional crack detection methods involve manual inspection, which is laborious and time-consuming, especially in urban areas. Therefore, automatic crack detection with AI technology has gained popularity due to its ability to identify degradation of roads in real-time, leading to increased safety and reliability. This review emphasizes two key approaches for crack detection: deep learning and traditional computer vision, with a focus on data-driven aspects that rely primarily on data from training datasets to detect and quantify the severity level of the crack. The article highlights the advantages and drawbacks of each approach and provides an overview of various crack detection models, feature extraction techniques, datasets, potential issues, and future directions. The research concludes that deep learning-based methods used for crack classification, localization and segmentation have shown better performance than traditional computer vision techniques, especially in terms of accuracy. However, deep learning methods require large amounts of training data and computational power, which can be a significant limitation. Additionally, the article identifies a lack of 3D datasets, unsupervised learning algorithms are rarely used to train crack detection model, and datasets having road images with variety of road textures such as asphalt and cement etc. as challenges for future research in this field. A need for 3D and combined texture datasets as challenges for future research in this field.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/frsc.2023.1253627"
    },
    {
        "id": 28776,
        "title": "Compact &amp; Efficient Monopole Antenna Designs Based on AI-Driven EM Optimization Techniques",
        "authors": "K. Sreelekha, C. Sai Sudeep, S. Sreekar, Bikash Ranjan Behera",
        "published": "2023-4-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaia57370.2023.10169413"
    },
    {
        "id": 28777,
        "title": "Investigating and Implementing the Efficiency of Image Restoration Techniques in Digital Image Processing",
        "authors": "Kalyan Acharjya, S. Yuvaraj, Varsha D. Jadhav, Amritpal Sidhu, Deepak Kumar Sinha, Ojasvee Kaneria",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smartgencon60755.2023.10442169"
    },
    {
        "id": 28778,
        "title": "User Friendly and Adaptable Discriminative AI: Using the Lessons from the Success of LLMs and Image Generation Models",
        "authors": "Son  The Nguyen, Theja Tulabandhula, Mary Beth Watson-Manheim",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4662955"
    },
    {
        "id": 28779,
        "title": "AI Innovator: Text to Image Generation using GAN",
        "authors": "Mrudula Nimbarte, Alfiya Hussain, Kanak Budhlani, Chirag Bansod, Mayur Ramdham, Om Kanhe, Amit Khullar",
        "published": "2024-2-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sceecs61402.2024.10482008"
    },
    {
        "id": 28780,
        "title": "A Multi-Modal Story Generation Framework with AI-Driven Storyline Guidance",
        "authors": "Juntae Kim, Yoonseok Heo, Hogeon Yu, Jongho Nang",
        "published": "2023-3-8",
        "citations": 0,
        "abstract": "An automatic story generation system continuously generates stories with a natural plot. The major challenge of automatic story generation is to maintain coherence between consecutive generated stories without the need for human intervention. To address this, we propose a novel multi-modal story generation framework that includes automated storyline decision-making capabilities. Our framework consists of three independent models: a transformer encoder-based storyline guidance model, which predicts a storyline using a multiple-choice question-answering problem; a transformer decoder-based story generation model that creates a story that describes the storyline determined by the guidance model; and a diffusion-based story visualization model that generates a representative image visually describing a scene to help readers better understand the story flow. Our proposed framework was extensively evaluated through both automatic and human evaluations, which demonstrate that our model outperforms the previous approach, suggesting the effectiveness of our storyline guidance model in making proper plans.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12061289"
    },
    {
        "id": 28781,
        "title": "The Impact of AI-Driven Narrative Generation, Exemplified by ChatGPT, on the Preservation of Human Creative Originality and Uniqueness",
        "authors": "Yuehua Lai",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "The appearance of Artificial Intelligence (AI) systems have become more adept at generating original texts, becoming the realm of storytelling, as exemplified by ChatGPT and similar language models. This has sparked a growing debate about its impact on the originality and uniqueness of human creativity and thinking. Bringing up the question of whether AI-driven narrative generation is a benefit or a detriment to humanity, this paper delves into the evolution of AI storytelling, examines the capabilities and limitations of large language models like ChatGPT, even under their impressive fluency, and further explores the implications for human creativity and intellectual diversity. While AI storytelling tools have undoubtedly revolutionised content generation, this paper argues that they do not inherently erode human originality and uniqueness and more so cannot authentically replicate the distinctiveness of human thinking. Instead, with conscientious implementation, AI writing technologies may serve as powerful complementary tools that can enhance human creativity, expand the diversity of voices and perspectives, provide more widespread access to the means of storytelling and personal expression, and optimise our human literary activities in a manner that elevates rather than erodes the uniqueness of human literary work when used thoughtfully and ethically.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2753-7048/26/20230865"
    },
    {
        "id": 28782,
        "title": "Pose-driven attention-guided image generation for person re-Identification",
        "authors": "Amena Khatun, Simon Denman, Sridha Sridharan, Clinton Fookes",
        "published": "2023-5",
        "citations": 18,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2022.109246"
    },
    {
        "id": 28783,
        "title": "A Next Generation Library of AI-Based Data-Driven Services for the Built Environment",
        "authors": "Elissaios Sarmas, Stathis Stamatopoulos, Panagiotis Kapsalis, Konstantinos Touloumis, Vangelis Marinakis",
        "published": "2023-7-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iisa59645.2023.10345945"
    },
    {
        "id": 28784,
        "title": "Towards Next-Generation Healthcare: Architectural Insights into an AI-Driven, Smartwatch-Compatible mHealth Application",
        "authors": "Avnish Singh Jat, Tor-Morten Grønli, Abdullah Raza Lakhan",
        "published": "2023-10-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14445/22312803/ijctt-v71i10p111"
    },
    {
        "id": 28785,
        "title": "Evaluating Pavement Lane Markings in Metropolitan Road Networks with a Vehicle-Mounted Retroreflectometer and AI-Based Image Processing Techniques",
        "authors": "Sangyum Lee, Byoung Hooi Cho",
        "published": "2023-3-28",
        "citations": 1,
        "abstract": "The objectives of this study were to evaluate pavement lane markings in a metropolitan road network and to develop a maintenance strategy for safe daytime and night-time driving. To achieve this, data on the retroreflectivity and physical defect ratio of lane markings were collected remotely using a vehicle-mounted retroreflectometer and high-resolution camera. The retroreflectivity was measured and analyzed by road type (city freeways, arterial roads, and collector roads) and by lane color (yellow, white, and blue) over a total length of 6790.34 km. The results indicate that the retroreflective performance deteriorates the most in the case of white lanes, regardless of the road classification, especially in the case of the first white lane. Additionally, the physical defects of lane markings were investigated over a total length of 502.82 km and categorized by road classification and lane color. Mask R-CNN and the Otsu Threshold method were used to automatically calculate the ratios of the defects. The results indicate that city freeways show a lower defect ratio than arterial and collector roads for all colors. Moreover, there is no significant difference between the white lanes for all types of roads. The distribution trends and relationship between retroreflectivity and the defect ratios were discussed according to the road type and lane color, and a method for selecting maintenance priority was suggested. The results show that the number of lanes requiring the restoration of retroreflectivity increases as the defect ratio increases. Therefore, we suggest prioritizing maintenance work on the lanes with a higher ratio of defects, covering a higher proportion of low-retroreflectivity sections. In addition, the unit length for data averaging can be adjusted to improve the work efficiency.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/rs15071812"
    },
    {
        "id": 28786,
        "title": "Advanced Deep Learning Techniques for High-Quality Synthetic Thermal Image Generation",
        "authors": "Vicente Pavez, Gabriel Hermosilla, Manuel Silva, Gonzalo Farias",
        "published": "2023-10-27",
        "citations": 1,
        "abstract": "In this paper, we introduce a cutting-edge system that leverages state-of-the-art deep learning methodologies to generate high-quality synthetic thermal face images. Our unique approach integrates a thermally fine-tuned Stable Diffusion Model with a Vision Transformer (ViT) classifier, augmented by a Prompt Designer and Prompt Database for precise image generation control. Through rigorous testing across various scenarios, the system demonstrates its capability in producing accurate and superior-quality thermal images. A key contribution of our work is the development of a synthetic thermal face image database, offering practical utility for training thermal detection models. The efficacy of our synthetic images was validated using a facial detection model, achieving results comparable to real thermal face images. Specifically, a detector fine-tuned with real thermal images achieved a 97% accuracy rate when tested with our synthetic images, while a detector trained exclusively on our synthetic data achieved an accuracy of 98%. This research marks a significant advancement in thermal image synthesis, paving the way for its broader application in diverse real-world scenarios.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math11214446"
    },
    {
        "id": 28787,
        "title": "Retraction notice – AI-driven techniques for controlling the metal melting production: a review, processes, enabling technologies, solutions, and research challenges (2022 Mater. Res. Express 9 072001)",
        "authors": "",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/2053-1591/ad1edc"
    },
    {
        "id": 28788,
        "title": "Harnessing the power of images in CALL: AI image generation for context specific visual aids in less commonly taught languages",
        "authors": "Liang Xu, Elaine Uí Dhonnchadha, Monica Ward",
        "published": "2023-8-15",
        "citations": 0,
        "abstract": "This paper explores the application of AI image generation in Computer-Assisted Language Learning (CALL) for Less Commonly Taught Languages (LCTLs). It delves into the potential of text to image generation models in creating context specific visual aids to enhance comprehension and engagement among learners. The integration of AI generated images in a language learning game, Cipher, is discussed, showcasing the benefits and challenges encountered. Learner feedback indicates positive inclinations towards the AI generated images, but also highlights the need for meticulous selection to address biases and stereotypes. Overall, this approach shows promise in creating culturally relevant CALL resources and improving language learning experiences for learners of LCTLs.",
        "keywords": "",
        "link": "http://dx.doi.org/10.4995/eurocall2023.2023.16950"
    },
    {
        "id": 28789,
        "title": "IMAGE GENERATION WITH STABLE DIFFUSION AI",
        "authors": "Sasirajan M, Guhan S, Mary Reni, Maheswari M, Roselin Mary S",
        "published": "2023-4-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17148/ijarcce.2023.125106"
    },
    {
        "id": 28790,
        "title": "AI-Driven Advanced Text Matching for Improved Information Capture and Retrieval",
        "authors": "Trapty Agrawal, Kuldeep Singh Kulhar, K. Ranjith Singh, G. Indira, Priya M. Shelke, A Kannagi",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smartgencon60755.2023.10442849"
    },
    {
        "id": 28791,
        "title": "Leveraging AI/ML Driven APC for Optimizing Beer Filtration A Data-Driven Approach",
        "authors": "",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1094/tq-60-4-0213-01"
    },
    {
        "id": 28792,
        "title": "Scene Graph Driven Text-Prompt Generation for Image Inpainting",
        "authors": "Tripti Shukla, Paridhi Maheshwari, Rajhans Singh, Ankita Shukla, Kuldeep Kulkarni, Pavan Turaga",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00083"
    },
    {
        "id": 28793,
        "title": "AI-driven designed protein epigenomics",
        "authors": "",
        "published": "2023-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.46439/oncology.1.01"
    },
    {
        "id": 28794,
        "title": "Scene recognition and image caption generation",
        "authors": "Shripad Bhatlawande, Neeraja Khire, Mahesh Kinge, Chinmay Kshirsagar, Parth Kudal, Swati Shilaskar, Jyoti Madake",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0166868"
    },
    {
        "id": 28795,
        "title": "AI Enhanced Resistance Training: Segmentation and Velocity Tracking Using Computer Vision",
        "authors": "Quang Dang Huynh, Joel Dedini, David Rowlands, Andrew Busch, Belinda Schwerin, Hugo Espinosa",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dicta60407.2023.00074"
    },
    {
        "id": 28796,
        "title": "AI-driven cybersecurity: Utilizing machine learning and deep learning techniques for real-time threat detection, analysis, and mitigation in complex IT networks",
        "authors": "Dabi Dabouabi Dalo Alionsi",
        "published": "2023-10-23",
        "citations": 0,
        "abstract": "With the escalating complexity of IT networks and the surge in cyber threats, the need for advanced, real-time security solutions has never been more paramount. Machine learning (ML) and deep learning (DL) present promising avenues for enhancing the detection, analysis, and mitigation of threats in these intricate networks. The paper delves into the confluence of ML and DL techniques in the realm of cybersecurity, focusing on their application for real-time threat detection within IT infrastructures. Drawing from recent research and developments, the study underscores the potential of these techniques in outmaneuvering conventional security models, while also shedding light on the inherent challenges and areas for future exploration.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2977-3903/3/2023036"
    },
    {
        "id": 28797,
        "title": "A COMPREHENSIVE REVIEW ON AI-DRIVEN OPTIMIZATION TECHNIQUES ENHANCING SUSTAINABILITY IN OIL AND GAS PRODUCTION PROCESSES",
        "authors": " Chuka Anthony Arinze,  Boma Sonimiteim Jacks",
        "published": "2024-3-24",
        "citations": 0,
        "abstract": "The oil and gas industry plays a pivotal role in global energy supply but faces increasing pressure to enhance sustainability amidst environmental concerns and economic constraints. This comprehensive review explores the integration of artificial intelligence (AI) in optimizing oil and gas production processes to achieve sustainability goals. The paper examines various AI-driven optimization techniques, including machine learning algorithms, genetic algorithms, and neural networks, and their application in different stages of oil and gas production, such as exploration, drilling, production, and distribution. By leveraging AI, operators can improve efficiency, reduce environmental impact, and maximize resource recovery. Furthermore, the review delves into specific case studies and implementations of AI-driven optimization in real-world oil and gas operations, highlighting their efficacy in minimizing greenhouse gas emissions, optimizing water usage, and mitigating operational risks. Additionally, the paper discusses challenges and limitations associated with AI adoption in the industry, such as data availability, model interpretability, and regulatory compliance. The integration of AI-driven optimization techniques not only enhances sustainability but also contributes to cost reduction and operational excellence in oil and gas production. By optimizing production processes, operators can achieve higher yields with fewer resources, leading to increased profitability and long-term viability in a rapidly evolving energy landscape. Overall, this review provides valuable insights into the transformative potential of AI-driven optimization techniques in fostering sustainability and resilience in oil and gas production processes, paving the way for a more efficient and environmentally responsible industry.\r\nKeywords: AL, Oil and Gas, Production, Optimization, Sustainability, Review, Process.",
        "keywords": "",
        "link": "http://dx.doi.org/10.51594/estj.v5i3.950"
    },
    {
        "id": 28798,
        "title": "Optimizing porosity detection in wire laser metal deposition processes through data-driven AI classification techniques",
        "authors": "Meritxell Gomez-Omella, Jon Flores, Basilio Sierra, Susana Ferreiro, Nicolas Hascoët, Francisco Chinesta",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.engfailanal.2023.107464"
    },
    {
        "id": 28799,
        "title": "An Approach to Spatial Design Visualization through Design Style Combinations Based on Image-Generation AI",
        "authors": "Hyun Jeong, Jin-Kook Lee",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.6107/jkha.2023.34.6.017"
    },
    {
        "id": 28800,
        "title": "AI-Driven Medical Imaging Platform: Advancements in Image Analysis and Healthcare Diagnosis",
        "authors": "Waleed Salah Eldin, Ahmed Kaboudan",
        "published": "2023-6-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21608/asc.2023.328064"
    },
    {
        "id": 28801,
        "title": "Self-Attention Driven Decoder for SAR Image-based Semantic Flood Zone Segmentation",
        "authors": "Girisha S, Hrishikesh Singh Yadav, Divyanshu Manawat, Savitha G, Shreesha S",
        "published": "2023-11-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3615886.3627736"
    },
    {
        "id": 28802,
        "title": "Designing a User-Friendly and Responsive AI based Image Generation Website and Performing Diversity Assessment of the Generated Images",
        "authors": "Harshil T. Kanakia, Suraj Prakkash Nair",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icesc57686.2023.10193269"
    },
    {
        "id": 28803,
        "title": "Efficient Generation of 3D Lumbar Spine Models: An Anatomy-Driven Approach with Limited Input Parameters",
        "authors": "Lara Blomenkamp, Ivanna Kramer, Sabine Bauer, Dietrich Paulus",
        "published": "2023-9-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ispa58351.2023.10278898"
    },
    {
        "id": 28804,
        "title": "Exploring AI for Creative Fashion Image Generation through HAIC",
        "authors": "Kyunghee Chung, Misuk Lee",
        "published": "2024-2-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.7233/jksc.2024.74.1.061"
    },
    {
        "id": 28805,
        "title": "AI-Driven Medical Imaging Platform: Advancements in Image Analysis and Healthcare Diagnosis",
        "authors": "Waleed Salah Eldin, Ahmed Kaboudan",
        "published": "2023-6-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21608/asc.2024.248278.1018"
    },
    {
        "id": 28806,
        "title": "Automated Generation of Chinese Text-Image Summaries Using Deep Learning Techniques",
        "authors": "Meiling Xu, Hayati Abd Rahman, Feng Li",
        "published": "2023-12-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18280/ts.400644"
    },
    {
        "id": 28807,
        "title": "Difficulties and possible mistakes in applying AI techniques in industrial control systems by new generation of engineers.",
        "authors": "Elena Raducan, Mihaita Argip, Sorin Guzu",
        "published": "2023-8-30",
        "citations": 0,
        "abstract": "Nowadays, Artificial Intelligence (AI) is making its entrance in absolutely all fields and only the economic level of the promoting states is responsible for the percentage of the insertion of this new technology. The economic aspect is not directly connected with the AI because there is already a wide range of open-source software’s and AI analysis models but is strictly connected with the digitalization level of the country and/or company that wants to follow this trend. This article proposes a subjective analysis of some situation that young engineers can face by early use of dedicated software’s for data analysis rise from different systems.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.47577/technium.v13i.9464"
    },
    {
        "id": 28808,
        "title": "Personalized Learning Paths: Adapting Education with AI-Driven Curriculum",
        "authors": "",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/eel.v14i1.993"
    },
    {
        "id": 28809,
        "title": "AI Driven Potholes Detection for Equitable Repair Prioritization: Human centred AI-driven methodology as support of road management system",
        "authors": "Alberto Moccardi",
        "published": "2023-12-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3633083.3633224"
    },
    {
        "id": 28810,
        "title": "AI-Driven Cybersecurity for Witness Data: Confidentiality Redefined",
        "authors": "Aishpreet Kaur Devgan",
        "published": "2023-12-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.55248/gengpi.4.1223.123428"
    },
    {
        "id": 28811,
        "title": "Multi-Scale Correspondence Learning for Person Image Generation",
        "authors": "Shi-Long SHEN, Ai-Guo WU, Yong XU",
        "published": "2023-5-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1587/transinf.2022dlp0058"
    },
    {
        "id": 28812,
        "title": "Assessing the Ability of AI-Driven Natural Language Processing to Accurately Analyze Unstructured Text Data",
        "authors": "M. Vigenesh, RaviKumar V, Vivek D. Patil, Sharma Sonu Kumar, Nyarik Geyi, Subir Chattopadhyay",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smartgencon60755.2023.10442594"
    },
    {
        "id": 28813,
        "title": "Exploring the Intersection of Language Processing and Image Generation in a Conversational AI Application",
        "authors": "Rahul Chauhan, Gurnain Singh Wadhwa, Deepak Kumar Verma, Krunal N. Vaghela, Chandradeep Bhatt",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/r10-htc57504.2023.10461849"
    },
    {
        "id": 28814,
        "title": "Appropriate Incongruity Driven Human-AI Collaborative Tool to Assist Novices in Humorous Content Generation",
        "authors": "Hasindu Kariyawasam, Amashi Niwarthana, Alister Palmer, Judy Kay, Anusha Withana",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3640543.3645161"
    },
    {
        "id": 28815,
        "title": "DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation",
        "authors": "Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, Kfir Aberman",
        "published": "2023-6",
        "citations": 206,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.02155"
    },
    {
        "id": 28816,
        "title": "Imagining the Unseen: Text-driven realism in artificial image generation",
        "authors": "Chinni Mohith, Jaya Venkatsh",
        "published": "2024-1-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.22271/27083969.2024.v5.i1a.36"
    },
    {
        "id": 28817,
        "title": "Intentional First Order Logic for Strong-AI Generation of Robots",
        "authors": "",
        "published": "2023-5-27",
        "citations": 0,
        "abstract": "Neuro-symbolic AI attempts to integrate neural and symbolic architectures in a manner that addresses strengths and weaknesses of each, in a complementary fashion, in order to support robust strong AI capable of reasoning, learning, and cognitive modeling. We consider the robot’s four-levels knowledge structure: The syntax level of particular natural language (Italian, French, etc..), two universal language levels: its semantic logic structure (based on virtual predicates of FOL and logic connectives), and its corresponding conceptual PRP structure level which universally represents the composite mining of FOL formulae grounded on the last robot’s neuro system level. Therefore, this paper we consider the intentional First Order Logic as a symbolic architecture of modern robots, able to use natural languages to communicate with humans and to reason about their own knowledge with self-reference and abstraction language property",
        "keywords": "",
        "link": "http://dx.doi.org/10.33140/amlai.04.01.03"
    },
    {
        "id": 28818,
        "title": "Using New AI-Driven Techniques to Ease Serious Games Authoring",
        "authors": "Iván J. Pérez Colado, Víctor M. Pérez Colado, Antonio Calvo Morata, Rubén Santa Cruz Píriz, Baltasar Fernández Manjón",
        "published": "2023-10-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/fie58773.2023.10343021"
    },
    {
        "id": 28819,
        "title": "AI Diffusion as Design Vocabulary - Investigating the use of AI image generation in early architectural design and education",
        "authors": "Mathias Bank Stigsen, Alexandra Moisi, Shervin Rasoulzadeh, Kristina Schinegger, Stefan Rutzinger",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.52842/conf.ecaade.2023.2.587"
    },
    {
        "id": 28820,
        "title": "Exploring the Effects of Various Generative Adversarial Networks Techniques on Image Generation",
        "authors": "Zian Shi, Junyi Teng, Shihao Zheng, Kaifeng Guo",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/itaic58329.2023.10409102"
    },
    {
        "id": 28821,
        "title": "Brain Tumor MRI Image Segmentation and Classification based on Deep Learning Techniques",
        "authors": "Ali Arafat, Dipesh Mamtani, K.R. Jansi",
        "published": "2023-4-21",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icstsn57873.2023.10151504"
    },
    {
        "id": 28822,
        "title": "AI tools vs AI text: Detecting AI-generated writing in foot and ankle surgery",
        "authors": "Steven R. Cooperman, Roberto A. Brandão",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.fastrc.2024.100367"
    },
    {
        "id": 28823,
        "title": "An Adaptive Event-Driven Condition Generation Circuit for Linear CMOS Image Sensors",
        "authors": "Hejiu Zhang, Haoran He, Ningmei Yu, Nan Lv, Zhongjie Guo",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icet58434.2023.10211351"
    },
    {
        "id": 28824,
        "title": "AI-Driven Customized Cyber Security Training and Awareness",
        "authors": "Shadi Jawhar, Jeremy Miller, Zeina Bitar",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaic60265.2024.10433829"
    },
    {
        "id": 28825,
        "title": "A design perspective on how to tackle gender biases when developing AI-driven systems",
        "authors": "Ana Santana González, Lucia Rampino",
        "published": "2024-1-15",
        "citations": 0,
        "abstract": "AbstractA growing awareness of bias in artificial intelligence (AI) systems has recently emerged, leading to an increased number of publications discussing ethics in AI. Nevertheless, the specific issue of gender bias remains under-discussed. How can design contribute to preventing the emergence of gender bias in AI-driven systems? To answer this question, we investigated the current state of AI ethical guidelines within the European Union. The results revealed that most guidelines do not acknowledge gender bias but address discrimination. This raised our concerns, as addressing multiple biases simultaneously might not effectively mitigate any of them due to their often-unconscious nature. Furthermore, our results revealed a lack of quantitative evidence supporting the effectiveness of bias prevention implementation methods and solutions. In conclusion, based on our analysis, we propose four recommendations for designing effective guidelines to tackle gender biases in AI. Moreover, we stress the central role of diversity in embedding the gender perspective from the beginning in any design activity.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00386-2"
    },
    {
        "id": 28826,
        "title": "A Realistic AI Avatar Generation Method Combining GAN, Unity and Kinect Techniques",
        "authors": "Weijia Zhang, Yuan Zheng, Feiyu Chen, Yulin Li, Yucheng Tian, Xuejing Cao, Jin Xie, Haiping Ma",
        "published": "2023-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bdai59165.2023.10256925"
    },
    {
        "id": 28827,
        "title": "An explainable AI framework for robust and transparent data-driven wind turbine power curve models",
        "authors": "Simon Letzgus, Klaus-Robert Müller",
        "published": "2024-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.egyai.2023.100328"
    },
    {
        "id": 28828,
        "title": "Synthetic Data Generation and Deep Learning for the Topological Analysis of 3D Data",
        "authors": "Dylan Peek, Matthew P. Skerritt, Stephan Chalup",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dicta60407.2023.00025"
    },
    {
        "id": 28829,
        "title": "Behind the AI Art Creation: A Study of Generative Models for Text-to-Image Generation",
        "authors": "Lege Zhao, Han Zhang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.4108/eai.15-9-2023.2340842"
    },
    {
        "id": 28830,
        "title": "AI-Accelerated Digitisation of Insect Collections: The next generation of Angled Label Image Capture Equipment (ALICE)",
        "authors": "Arianna Salili-James, Ben Scott, Laurence Livermore, Ben Price, Steen Dupont, Helen Hardy, Vincent Smith",
        "published": "2023-9-15",
        "citations": 0,
        "abstract": "The digitisation of natural science specimens is a shared ambition of many of the largest collections, but the scale of these collections, estimated at at least 1.1 billion specimens (Johnson et al. 2023), continues to challenge even the most resource-rich organisations.\nThe Natural History Museum, London (NHM) has been pioneering work to accelerate the digitisation of its 80 million specimens. Since the inception of the NHM Digital Collection Programme in 2014, more than 5.5 million specimen records have been made digitally accessible. This has enabled the museum to deliver a tenfold increase in digitisation, compared to when rates were first measured by the NHM in 2008. Even with this investment, it will take circa 150 years to digitise its remaining collections, leading the museum to pursue technology-led solutions alongside increased funding to deliver the next increase in digitisation rate. \nInsects comprise approximately half of all described species and, at the NHM, represent more than one-third (c. 30 million specimens) of the NHM’s overall collection. Their most common preservation method, attached to a pin alongside a series of labels with metadata, makes insect specimens challenging to digitise. Early Artificial Intelligence (AI)-led innovations (Price et al. 2018) resulted in the development of ALICE, the museum's Angled Label Image Capture Equipment, in which a pinned specimen is placed inside a multi-camera setup, which captures a series of partial views of a specimen and its labels. Centred around the pin, these images can be digitally combined and reconstructed, using the accompanying ALICE software, to provide a clean image of each label. To do this, a Convolutional Neural Network (CNN) model is incorporated, to locate all labels within the images. This is followed by various image processing tools to transform the labels into a two-dimensional viewpoint, align the associated label images together, and merge them into one label. This allows users to manually, or computationally (e.g., using Optical Character Recognition [OCR] tools) extract label data from the processed label images (Salili-James et al. 2022). \nWith the ALICE setup, a user might average imaging 800 digitised specimens per day, and exceptionally, up to 1,300. This compares with an average of 250 specimens or fewer daily, using more traditional methods involving separating the labels and photographing them off of the pin. Despite this, our original version of ALICE was only suited to a small subset of the collection. In situations when the specimen is very large, there are too many labels, or these labels are too close together, ALICE fails (Dupont and Price 2019).\nUsing a combination of updated AI processing tools, we hereby present ALICE version 2. This new version of ALICE provides faster rates, improved software accuracy, and a more streamlined pipeline. It includes the following updates:\n\n\n\nHardware: after conducting various tests, we have optimised the camera setup. Further hardware updates include a Light-Emitting Diode (LED) ring light, as well as modifications to the camera mounting.\n\n\nSoftware: our latest software incorporates machine learning and other computer vision tools to segment labels from ALICE images and stitch them together more quickly and with a higher level of accuracy, significantly reducing the image processing failure rate. These processed label images can be combined with the latest OCR tools for automatic transcription and data segmentation.\n\n\nBuildkit: we aim to provide a toolkit that any individual or institution can incorporate into their digitisation pipeline. This includes hardware instructions, an extensive guide detailing the pipeline, and new software code accessible via Github.\n\n\n\nHardware: after conducting various tests, we have optimised the camera setup. Further hardware updates include a Light-Emitting Diode (LED) ring light, as well as modifications to the camera mounting.\nSoftware: our latest software incorporates machine learning and other computer vision tools to segment labels from ALICE images and stitch them together more quickly and with a higher level of accuracy, significantly reducing the image processing failure rate. These processed label images can be combined with the latest OCR tools for automatic transcription and data segmentation.\nBuildkit: we aim to provide a toolkit that any individual or institution can incorporate into their digitisation pipeline. This includes hardware instructions, an extensive guide detailing the pipeline, and new software code accessible via Github.\nWe provide test data and workflows to demonstrate the potential of ALICE version 2 as an effective, accessible, and cost-saving solution to digitising pinned insect specimens. We also describe potential modifications, enabling it to work with other types of specimens.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3897/biss.7.112742"
    },
    {
        "id": 28831,
        "title": "Investigating the Use of Neural Networks for AI-Based Image Recognition Systems",
        "authors": "Nitin N. Sakhare, Dipannita Mondal, M. Vigenesh, Geetha. B, Dharmesh Dhabliya, Ashok Kumar Purohit",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smartgencon60755.2023.10442103"
    },
    {
        "id": 28832,
        "title": "Using AI Text-to-Image Generation to Create Novel Illustrations for Medical Education: Current Limitations as Illustrated by Hypothyroidism and Horner Syndrome",
        "authors": "Ajay Kumar, Pierce Burr, Tim Michael Young",
        "published": "2024-2-22",
        "citations": 1,
        "abstract": "Our research letter investigates the potential, as well as the current limitations, of widely available text-to-image tools in generating images for medical education. We focused on illustrations of important physical signs in the face (for which confidentiality issues in conventional patient photograph use may be a particular concern) that medics should know about, and we used facial images of hypothyroidism and Horner syndrome as examples.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2196/52155"
    },
    {
        "id": 28833,
        "title": "From Misuse to Mastery: Enhancing Code Generation with Knowledge-Driven AI Chaining",
        "authors": "Xiaoxue Ren, Xinyuan Ye, Dehai Zhao, Zhenchang Xing, Xiaohu Yang",
        "published": "2023-9-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ase56229.2023.00143"
    },
    {
        "id": 28834,
        "title": "Pattern Derivative Design of Black Copper Infused with Silver Using AI-based Pattern Generation and Image Style Transfer Algorithm",
        "authors": "Xinran Han, Yiyi Liu, Hanwen Zhang, Xin Huang, Xiaotang Sun",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aiac61660.2023.00048"
    },
    {
        "id": 28835,
        "title": "Data-driven framework for evaluating digitization and artificial intelligence risk: a comprehensive analysis",
        "authors": "Wael Badawy",
        "published": "2023-11-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00376-4"
    },
    {
        "id": 28836,
        "title": "Error-Driven Learning: Development of Vocabulary Learning Support System that Utilizes Suggestibility of Error by Image Generation",
        "authors": "kazuki sugita, Wen Gu, 長谷川 忍",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.52731/liir.v003.078"
    },
    {
        "id": 28837,
        "title": "AI-driven decision support systems and epistemic reliance: a qualitative study on obstetricians’ and midwives’ perspectives on integrating AI-driven CTG into clinical decision making",
        "authors": "Rachel Dlugatch, Antoniya Georgieva, Angeliki Kerasidou",
        "published": "2024-1-6",
        "citations": 0,
        "abstract": "Abstract\nBackground\nGiven that AI-driven decision support systems (AI-DSS) are intended to assist in medical decision making, it is essential that clinicians are willing to incorporate AI-DSS into their practice. This study takes as a case study the use of AI-driven cardiotography (CTG), a type of AI-DSS, in the context of intrapartum care. Focusing on the perspectives of obstetricians and midwives regarding the ethical and trust-related issues of incorporating AI-driven tools in their practice, this paper explores the conditions that AI-driven CTG must fulfill for clinicians to feel justified in incorporating this assistive technology into their decision-making processes regarding interventions in labor.\n\nMethods\nThis study is based on semi-structured interviews conducted online with eight obstetricians and five midwives based in England. Participants were asked about their current decision-making processes about when to intervene in labor, how AI-driven CTG might enhance or disrupt this process, and what it would take for them to trust this kind of technology. Interviews were transcribed verbatim and analyzed with thematic analysis. NVivo software was used to organize thematic codes that recurred in interviews to identify the issues that mattered most to participants. Topics and themes that were repeated across interviews were identified to form the basis of the analysis and conclusions of this paper.\n\nResults\nThere were four major themes that emerged from our interviews with obstetricians and midwives regarding the conditions that AI-driven CTG must fulfill: (1) the importance of accurate and efficient risk assessments; (2) the capacity for personalization and individualized medicine; (3) the lack of significance regarding the type of institution that develops technology; and (4) the need for transparency in the development process.\n\nConclusions\nAccuracy, efficiency, personalization abilities, transparency, and clear evidence that it can improve outcomes are conditions that clinicians deem necessary for AI-DSS to meet in order to be considered reliable and therefore worthy of being incorporated into the decision-making process. Importantly, healthcare professionals considered themselves as the epistemic authorities in the clinical context and the bearers of responsibility for delivering appropriate care. Therefore, what mattered to them was being able to evaluate the reliability of AI-DSS on their own terms, and have confidence in implementing them in their practice.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s12910-023-00990-1"
    },
    {
        "id": 28838,
        "title": "A Comprehensive Review of AI Techniques for Addressing Algorithmic Bias in Job Hiring",
        "authors": "Elham Albaroudi, Taha Mansouri, Ali Alameer",
        "published": "2024-2-7",
        "citations": 0,
        "abstract": "The study comprehensively reviews artificial intelligence (AI) techniques for addressing algorithmic bias in job hiring. More businesses are using AI in curriculum vitae (CV) screening. While the move improves efficiency in the recruitment process, it is vulnerable to biases, which have adverse effects on organizations and the broader society. This research aims to analyze case studies on AI hiring to demonstrate both successful implementations and instances of bias. It also seeks to evaluate the impact of algorithmic bias and the strategies to mitigate it. The basic design of the study entails undertaking a systematic review of existing literature and research studies that focus on artificial intelligence techniques employed to mitigate bias in hiring. The results demonstrate that the correction of the vector space and data augmentation are effective natural language processing (NLP) and deep learning techniques for mitigating algorithmic bias in hiring. The findings underscore the potential of artificial intelligence techniques in promoting fairness and diversity in the hiring process with the application of artificial intelligence techniques. The study contributes to human resource practice by enhancing hiring algorithms’ fairness. It recommends the need for collaboration between machines and humans to enhance the fairness of the hiring process. The results can help AI developers make algorithmic changes needed to enhance fairness in AI-driven tools. This will enable the development of ethical hiring tools, contributing to fairness in society.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ai5010019"
    },
    {
        "id": 28839,
        "title": "Improved Image Recognition for AI Based Various Scientific Applications",
        "authors": "Supriyo Karmakar, Sayantani Karmakar",
        "published": "2023-6-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aiiot58121.2023.10174451"
    },
    {
        "id": 28840,
        "title": "The AI Effect – Practical AI-driven Exploration as an Engine for Innovation",
        "authors": "K. Kurach, A. Zahreba",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3997/2214-4609.202377031"
    },
    {
        "id": 28841,
        "title": "An automated AI and video measurement techniques for monitoring social distancing, mask detection, and facial temperature screening for COVID-19",
        "authors": "Abdussalam Elhanashi, Sergio Saponara, Qinghe Zheng",
        "published": "2023-6-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2663754"
    },
    {
        "id": 28842,
        "title": "Innovative AI-based modelling and computing techniques for improving real-time search and rescue operations in impaired environments.",
        "authors": "Lennert Antson, Arthur Vandenhoeke, Guillem Ballesteros Garcia, Michal Shimoni",
        "published": "2023-6-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2663915"
    },
    {
        "id": 28843,
        "title": "AI-Driven Management of Dynamic Multi-Tenant Cloud Networks",
        "authors": "Nader F. Mir",
        "published": "2023-4-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/southeastcon51012.2023.10115110"
    },
    {
        "id": 28844,
        "title": "Paperpal  AI-driven solutions to revolutionise global research publishing",
        "authors": "",
        "published": "2023-3-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32907/ro-135-4229641455"
    },
    {
        "id": 28845,
        "title": "Weed Detection in Wheat Crops Using Image Analysis and Artificial Intelligence (AI)",
        "authors": "Syed Ijaz Ul Haq, Muhammad Naveed Tahir, Yubin Lan",
        "published": "2023-7-31",
        "citations": 6,
        "abstract": "In the present study, we used device visualization in tandem with deep learning to detect weeds in the wheat crop system in actual time. We selected the PMAS Arid Agriculture University research farm and wheat crop fields in diverse weather environments to collect the weed images. Some 6000 images were collected for the study. Throughout the season, tfhe databank was assembled to detect the weeds. For this study, we used two different frameworks, TensorFlow and PyTorch, to apply deep learning algorithms. PyTorch’s implementation of deep learning algorithms performed comparatively better than that of TensorFlow. We concluded that the neural network implemented through the PyTorch framework achieves a superior outcome in speed and accuracy compared to other networks, such as YOLO variants. This work implemented deep learning models for weed detection using different frameworks. While working on real-time detection models, it is very important to consider the inference time and detection accuracy. Therefore, we have compared the results in terms of execution time and prediction accuracy. In particular, the accuracy of weed removal from wheat crops was judged to be 0.89 and 0.91, respectively, with inference times of 9.43 ms and 12.38 ms on the NVIDIA RTX2070 GPU for each picture (640 × 640).",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app13158840"
    },
    {
        "id": 28846,
        "title": "Explainable AI is Dead, Long Live Explainable AI!",
        "authors": "Tim Miller",
        "published": "2023-6-12",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3593013.3594001"
    },
    {
        "id": 28847,
        "title": "Correntropy-Induced Wasserstein GCN: Learning Graph Embedding via Domain Adaptation",
        "authors": "Wei Wang, Gaowei Zhang, Hongyong Han, Chi Zhang",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tip.2023.3293774"
    },
    {
        "id": 28848,
        "title": "AI-driven Automation as a Pre-condition for Eudaimonia",
        "authors": "Anastasia Siapka",
        "published": "2023-8-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3600211.3604743"
    },
    {
        "id": 28849,
        "title": "TrackSafe: A comparative study of data-driven techniques for automated railway track fault detection using image datasets",
        "authors": "Marta Garcia Minguell, Ravi Pandit",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.engappai.2023.106622"
    },
    {
        "id": 28850,
        "title": "AI-driven molecular generation of not-patented pharmaceutical compounds using world open patent data",
        "authors": "Yugo Shimizu, Masateru Ohta, Shoichi Ishida, Kei Terayama, Masanori Osawa, Teruki Honma, Kazuyoshi Ikeda",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "AbstractDeveloping compounds with novel structures is important for the production of new drugs. From an intellectual perspective, confirming the patent status of newly developed compounds is essential, particularly for pharmaceutical companies. The generation of a large number of compounds has been made possible because of the recent advances in artificial intelligence (AI). However, confirming the patent status of these generated molecules has been a challenge because there are no free and easy-to-use tools that can be used to determine the novelty of the generated compounds in terms of patents in a timely manner; additionally, there are no appropriate reference databases for pharmaceutical patents in the world. In this study, two public databases, SureChEMBL and Google Patents Public Datasets, were used to create a reference database of drug-related patented compounds using international patent classification. An exact structure search system was constructed using InChIKey and a relational database system to rapidly search for compounds in the reference database. Because drug-related patented compounds are a good source for generative AI to learn useful chemical structures, they were used as the training data. Furthermore, molecule generation was successfully directed by increasing and decreasing the number of generated patented compounds through incorporation of patent status (i.e., patented or not) into learning. The use of patent status enabled generation of novel molecules with high drug-likeness. The generation using generative AI with patent information would help efficiently propose novel compounds in terms of pharmaceutical patents. Scientific contribution: In this study, a new molecule-generation method that takes into account the patent status of molecules, which has rarely been considered but is an important feature in drug discovery, was developed. The method enables the generation of novel molecules based on pharmaceutical patents with high drug-likeness and will help in the efficient development of effective drug compounds.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s13321-023-00791-z"
    },
    {
        "id": 28851,
        "title": "Integrating aesthetics and efficiency: AI-driven diffusion models for visually pleasing interior design generation",
        "authors": "Junming Chen, Zichun Shao, Xiaodong Zheng, Kai Zhang, Jun Yin",
        "published": "2024-2-12",
        "citations": 0,
        "abstract": "AbstractThe interior design suffers from inefficiency and a lack of aesthetic appeal. With the development of artificial intelligence diffusion models, using text descriptions to generate aesthetically pleasing designs has emerged as a new approach to address these issues. In this study, we propose a novel method based on the aesthetic diffusion model, which can quickly generate visually appealing interior design based on input text descriptions while allowing for the specification of decorative styles and spatial functions. The method proposed in this study creates creative designs and drawings by computer instead of from designers, thus improving the design efficiency and aesthetic appeal. We demonstrate the potential of this approach in the field of interior design through our research. The results indicate that: (1) The method efficiently provides designers with aesthetically pleasing interior design solutions; (2) By modifying the text descriptions, the method allows for the rapid regeneration of design solutions; (3) Designers can apply this highly flexible method to other design fields through fine-tuning. (4) The method optimizes the workflow of interior design.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-024-53318-3"
    },
    {
        "id": 28852,
        "title": "Leveraging Deep Learning Model for Image Caption Generation for Scenes Description",
        "authors": "Vidyadevi G. Biradar, Mukund G, Suyush Agarwal, Saurabh Kumar Singh, R Ujwal Bharadwaj",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/easct59475.2023.10393602"
    },
    {
        "id": 28853,
        "title": "Picture This: AI-Assisted Image Generation as a Resource for Problem Construction in Creative Problem-Solving",
        "authors": "Janet Rafner, Blanka Zana, Peter Dalsgaard, Michael Mose Biskjaer, Jacob Sherson",
        "published": "2023-6-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3591196.3596823"
    },
    {
        "id": 28854,
        "title": "Athlete Perspectives on AI-Driven Coaching Technologies: A Qualitative Inquiry",
        "authors": "Hamidreza Ghezelseflou, Ali Choori",
        "published": "2023",
        "citations": 0,
        "abstract": "This article seeks to understand athletes' perceptions and experiences with AI-driven coaching technologies. The objective is to identify the major themes associated with the adoption, perceived benefits, challenges, and impact of these technologies on motivation and performance, alongside suggestions for future enhancements. Eighteen athletes across various sports disciplines participated in semi-structured interviews. The study employed a thematic analysis approach to identify key themes and sub-themes related to athletes' experiences with AI-driven coaching technologies. Ethical approval was obtained from the Institutional Review Board, and informed consent was secured from all participants. Five major themes were identified: Adoption and Adaptation, Perceived Benefits, Challenges and Limitations, Impact on Motivation and Performance, and Suggestions for Improvement. Athletes expressed initial skepticism followed by appreciation for the personalized training and efficiency offered by AI technologies. However, concerns regarding technical issues, lack of personal touch, and data privacy were noted. The impact on motivation and performance was predominantly positive, with athletes acknowledging the role of AI in enhancing training outcomes. Suggestions for improvement emphasized the need for more intuitive user interfaces, enhanced data security, and better integration of human coaching elements. Athletes recognize the transformative potential of AI-driven coaching technologies in enhancing training efficiency, personalization, and injury prevention. Nonetheless, the successful adoption of these technologies hinges on addressing technical challenges, ensuring data privacy, and maintaining the human element in coaching. Future developments in AI-driven coaching technologies should consider athletes' feedback to refine and tailor these tools, ensuring they meet the unique needs of individuals and foster a productive coach-athlete relationship. Suggestions for future research include expanding the participant pool across a wider range of sports and incorporating longitudinal studies to explore the evolution of athlete perspectives over time.",
        "keywords": "",
        "link": "http://dx.doi.org/10.61838/kman.aitech.1.1.2"
    },
    {
        "id": 28855,
        "title": "Collaborative Generative AI: Integrating GPT-k for Efficient Editing in Text-to-Image Generation",
        "authors": "Wanrong Zhu, Xinyi Wang, Yujie Lu, Tsu-Jui Fu, Xin Wang, Miguel Eckstein, William Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.emnlp-main.685"
    },
    {
        "id": 28856,
        "title": "Synthetic aperture radar ground target image generation based on improved Wasserstein generative adversarial networks with gradient penalty",
        "authors": "Zheng Qu, Gaowei Fan, Zhicheng Zhao, Lu Jia, Jun Shi, Jiaqiu Ai",
        "published": "2023-7-22",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/1.jrs.17.036501"
    },
    {
        "id": 28857,
        "title": "Retracted: A New Generation of ResNet Model Based on Artificial Intelligence and Few Data Driven and Its Construction in Image Recognition Model",
        "authors": "",
        "published": "2023-7-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9890364"
    },
    {
        "id": 28858,
        "title": "Design and implementation of an AI-controlled spraying drone for agricultural applications using advanced image preprocessing techniques",
        "authors": "Cemalettin Akdoğan, Tolga Özer, Yüksel Oğuz",
        "published": "2024-3-29",
        "citations": 0,
        "abstract": "\nPurpose\nNowadays, food problems are likely to arise because of the increasing global population and decreasing arable land. Therefore, it is necessary to increase the yield of agricultural products. Pesticides can be used to improve agricultural land products. This study aims to make the spraying of cherry trees more effective and efficient with the designed artificial intelligence (AI)-based agricultural unmanned aerial vehicle (UAV).\n\n\nDesign/methodology/approach\nTwo approaches have been adopted for the AI-based detection of cherry trees: In approach 1, YOLOv5, YOLOv7 and YOLOv8 models are trained with 70, 100 and 150 epochs. In Approach 2, a new method is proposed to improve the performance metrics obtained in Approach 1. Gaussian, wavelet transform (WT) and Histogram Equalization (HE) preprocessing techniques were applied to the generated data set in Approach 2. The best-performing models in Approach 1 and Approach 2 were used in the real-time test application with the developed agricultural UAV.\n\n\nFindings\nIn Approach 1, the best F1 score was 98% in 100 epochs with the YOLOv5s model. In Approach 2, the best F1 score and mAP values were obtained as 98.6% and 98.9% in 150 epochs, with the YOLOv5m model with an improvement of 0.6% in the F1 score. In real-time tests, the AI-based spraying drone system detected and sprayed cherry trees with an accuracy of 66% in Approach 1 and 77% in Approach 2. It was revealed that the use of pesticides could be reduced by 53% and the energy consumption of the spraying system by 47%.\n\n\nOriginality/value\nAn original data set was created by designing an agricultural drone to detect and spray cherry trees using AI. YOLOv5, YOLOv7 and YOLOv8 models were used to detect and classify cherry trees. The results of the performance metrics of the models are compared. In Approach 2, a method including HE, Gaussian and WT is proposed, and the performance metrics are improved. The effect of the proposed method in a real-time experimental application is thoroughly analyzed.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.1108/ria-05-2023-0068"
    },
    {
        "id": 28859,
        "title": "Advances in AI-Driven Retention Prediction for Different Chromatographic Techniques: Unraveling the Complexity",
        "authors": "Yash Raj Singh, Darshil B. Shah, Dilip G. Maheshwari, Jignesh S. Shah, Shreeraj Shah",
        "published": "2023-9-6",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/10408347.2023.2254379"
    },
    {
        "id": 28860,
        "title": "“Threatened and empty selves following AI-based virtual influencers”: comparison between followers and non-followers of virtual influencers in AI-driven digital marketing",
        "authors": "S. Venus Jin, Vijay Viswanathan",
        "published": "2024-1-18",
        "citations": 1,
        "abstract": "AbstractArtificial intelligence (AI)-based virtual influencers are now frequently used by brands in various categories to engage customers. However, little is known about who the followers of these AI-based virtual influencers are and more importantly, what drives the followers to use AI-based virtual influencers. The results from a survey support the notion that compensatory mechanisms and the need to belong play important roles in affecting usage intentions of AI-based virtual influencers. Specifically, the study finds that usage intentions are mediated and moderated by compensatory mechanisms that arise from the perception of AI-based virtual influencers’ functional benefits and existential threats to human identity. Furthermore, the need for belonging moderates the effects of the following status (following versus non-following) on perceived personalization benefits of AI-based virtual influencers and behavioral intentions to use AI-based virtual influencers. This study provides important implications for academia delving into the social, cultural, and philosophical implications of AI-based virtual influencers for human societies as well as for brands that plan to use AI-based virtual influencers and gain a better understanding of their customers in AI-driven digital marketing.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00146-023-01832-9"
    },
    {
        "id": 28861,
        "title": "AI-Based Computer Vision Techniques and Expert Systems",
        "authors": "Yasunari Matsuzaka, Ryu Yashiro",
        "published": "2023-2-23",
        "citations": 8,
        "abstract": "Computer vision is a branch of computer science that studies how computers can ‘see’. It is a field that provides significant value for advancements in academia and artificial intelligence by processing images captured with a camera. In other words, the purpose of computer vision is to impart computers with the functions of human eyes and realise ‘vision’ among computers. Deep learning is a method of realising computer vision using image recognition and object detection technologies. Since its emergence, computer vision has evolved rapidly with the development of deep learning and has significantly improved image recognition accuracy. Moreover, an expert system can imitate and reproduce the flow of reasoning and decision making executed in human experts’ brains to derive optimal solutions. Machine learning, including deep learning, has made it possible to ‘acquire the tacit knowledge of experts’, which was not previously achievable with conventional expert systems. Machine learning ‘systematises tacit knowledge’ based on big data and measures phenomena from multiple angles and in large quantities. In this review, we discuss some knowledge-based computer vision techniques that employ deep learning.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ai4010013"
    },
    {
        "id": 28862,
        "title": "Development of data labeling techniques for terahertz image-based AI cancer diagnosis",
        "authors": "Myeong Suk Yim, Yun Heung Kim, Byeong Cheol Yoo, Hyun Ju Choi, Seung Jae Oh, Young Bin Ji",
        "published": "2023-9-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/irmmw-thz57677.2023.10299285"
    },
    {
        "id": 28863,
        "title": "Multilevel Spatial–Temporal Excited Graph Network for Skeleton-Based Action Recognition",
        "authors": "Yisheng Zhu, Hui Shuai, Guangcan Liu, Qingshan Liu",
        "published": "2023",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tip.2022.3230249"
    },
    {
        "id": 28864,
        "title": "Using structured ethical techniques to facilitate reasoning in technology ethics",
        "authors": "Matt A. Murphy",
        "published": "2023-11-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-023-00371-9"
    },
    {
        "id": 28865,
        "title": "SubmergeStyleGAN: Synthetic Underwater Data Generation with Style Transfer for Domain Adaptation",
        "authors": "Mohamed E. Fathy, Samer A. Mohamed, Mohammed I. Awad, Hossam E. Abd El Munim",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/dicta60407.2023.00081"
    },
    {
        "id": 28866,
        "title": "CLIP-guided StyleGAN Inversion for Text-driven Real Image Editing",
        "authors": "Ahmet Canberk Baykal, Abdul Basit Anees, Duygu Ceylan, Erkut Erdem, Aykut Erdem, Deniz Yuret",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "Researchers have recently begun exploring the use of StyleGAN-based models for real image editing. One particularly interesting application is using natural language descriptions to guide the editing process. Existing approaches for editing images using language either resort to instance-level latent code optimization or map predefined text prompts to some editing directions in the latent space. However, these approaches have inherent limitations. The former is not very efficient, while the latter often struggles to effectively handle multi-attribute changes. To address these weaknesses, we present CLIPInverter, a new text-driven image editing approach that is able to efficiently and reliably perform multi-attribute changes. The core of our method is the use of novel, lightweight text-conditioned adapter layers integrated into pretrained GAN-inversion networks. We demonstrate that by conditioning the initial inversion step on the Contrastive Language-Image Pre-training (CLIP) embedding of the target description, we are able to obtain more successful edit directions. Additionally, we use a CLIP-guided refinement step to make corrections in the resulting residual latent codes, which further improves the alignment with the text prompt. Our method outperforms competing approaches in terms of manipulation accuracy and photo-realism on various domains including human faces, cats, and birds, as shown by our qualitative and quantitative results.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3610287"
    },
    {
        "id": 28867,
        "title": "Bridging the Explanation Gap in AI Security: A Task-Driven Approach to XAI Methods Evaluation",
        "authors": "Ondrej Lukas, Sebastian Garcia",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012475200003636"
    },
    {
        "id": 28868,
        "title": "Video Frame-wise Explanation Driven Contrastive Learning for Procedural Text Generation",
        "authors": "Zhihao Wang, Lin Li, Zhongwei Xie, Chuanbo Liu",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2024.103954"
    },
    {
        "id": 28869,
        "title": "AI-Driven Digital Twins for Smart Cities",
        "authors": "Sergey Goncharov, Andrey Nechesov",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ecsa-10-16223"
    },
    {
        "id": 28870,
        "title": "Empowering Employees: Unlocking the Benefits of Employee Self - Service by AI Driven HCM Platforms",
        "authors": "Ramesh Nyathani",
        "published": "2023-9-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21275/sr231030131808"
    },
    {
        "id": 28871,
        "title": "On inscription and bias: data, actor network theory, and the social problems of text-to-image AI models",
        "authors": "Jorge Luis Morton",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43681-024-00431-8"
    },
    {
        "id": 28872,
        "title": "Proofig AI: An AI tool to ensure image integrity in scientific publications",
        "authors": "Dror Kolodkin-Gal",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32907/ro-139-5873464896"
    },
    {
        "id": 28873,
        "title": "AI-Based Scenario Generation for Future Planning: An Exploratory Study Using GPT-3",
        "authors": "",
        "published": "2023-4-15",
        "citations": 0,
        "abstract": "Artificial Intelligence (AI) is a rapidly developing technology that allows machines to process large amounts of data and make predictions. OpenAI's GPT-3 AI is one such example, which has been trained on data available up until June 2021, and had no access to more recent data nor was connected to the internet. The objective of this exploratory study was to investigate the potential of AI in forecasting the escalation of the 2022 Ukrainian war and to determine whether such contribution justifies co-authorship. In a stage-gate methodology, GPT-3's capability for generating future scenarios with estimated probabilities was used to check their consistency and define drivers for evaluating their presence before deciding on AI co-authorship in this publication. The results showed that GPT-3 accurately described the open war as one of the scenarios; however, its capability for predicting the future was limited, and internal consistency of generated scenarios could be improved. Overall, this study demonstrated that GPT-3 has proved itself as powerful for generating future scenarios and re-writing abstracts, like this one. According to our stage-gate approach, GPT-3 did not qualify for co-authorship in this publication. We recommend further scientific discussion and updating best practices and journal guidelines with clear guidelines on AI contributions for future scientific papers.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33140/jctcsr.02.02.02"
    },
    {
        "id": 28874,
        "title": "Data-driven Innovation or Innovation-driven Data Generation?",
        "authors": "Youshan Yu",
        "published": "2023-6-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ice/itmc58018.2023.10332261"
    },
    {
        "id": 28875,
        "title": "A Data-Driven Approach Based on Artificial Neural Networks for the Detection and Classification of Bearing Anomalies in Power Generation Plants",
        "authors": "S. I. Senarathna, L. A. U. Prasanshi, S. D. W. Senanayake, Dhammike Wimalarathne, S. Kumarawadu, V. Logeeshan, C. Wanigasekara",
        "published": "2023-6-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aiiot58121.2023.10174441"
    },
    {
        "id": 28876,
        "title": "Talkin’ ‘Bout AI Generation: Copyright and the Generative AI Supply Chain",
        "authors": "Katherine Lee, A. Feder Cooper, James Grimmelmann",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4523551"
    },
    {
        "id": 28877,
        "title": "“Journey of Finding the Best Query”: Understanding the User Experience of AI Image Generation System",
        "authors": "Soomin Kim, Jinsu Eun, Changhoon Oh, Joonhwan Lee",
        "published": "2024-2-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/10447318.2024.2307670"
    },
    {
        "id": 28878,
        "title": "Manifesto for Artist-Driven AI Art",
        "authors": "Atte Oksanen, Jussi Lahtinen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4536742"
    },
    {
        "id": 28879,
        "title": "AI DRIVEN - INVENTORY MANAGEMENT",
        "authors": "",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets43375"
    },
    {
        "id": 28880,
        "title": "Breeding 5.0 AI-Driven Revolution in Designed Plant Breeding",
        "authors": "Jim Fang",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5376/mpb.2024.15.0004"
    },
    {
        "id": 28881,
        "title": "Managerial Hierarchy in AI-driven Organizations",
        "authors": "Oliver Baumann, Brian Wu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4590443"
    },
    {
        "id": 28882,
        "title": "AI Driven Data Governance for the Enterprise Intelligence",
        "authors": "atul anand",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4767837"
    },
    {
        "id": 28883,
        "title": "Tutorial 1 - Explainable AI in the Problems of Image Clarification",
        "authors": "",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ipta59101.2023.10320026"
    },
    {
        "id": 28884,
        "title": "AI Institute in Dynamic Systems: Developing machine learning and AI tools for scientific discovery, engineering design, and data‐driven control",
        "authors": "J. Nathan Kutz, Steven L. Brunton, Krithika Manohar, Hod Lipson, Na Li",
        "published": "2024-3",
        "citations": 0,
        "abstract": "AbstractThe mission of the AI Institute in Dynamic Systems is to develop the next generation of advanced machine learning (ML) and AI tools for controlling complex physical systems by discovering physically interpretable and physics‐constrained data‐driven models through optimal sensor selection and placement. The research effort is anchored by a common task framework (CTF) that evaluates the performance of ML algorithms, architectures, and optimization schemes for the diverse tasks required in engineering applications. The aim is to push beyond the boundaries of modern techniques by closing the loop between data collection, control, and modeling, creating a unique and cross‐disciplinary architecture for learning physically interpretable and physics constrained models of complex dynamic systems from time series data. The CTF further supports sustainable and open‐source challenge datasets, which are foundational for developing interpretable, ethical, and inclusive tools to solve problems fundamental to human safety, society, and the environment.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/aaai.12159"
    },
    {
        "id": 28885,
        "title": "Automation Bias and Assistive AI",
        "authors": "Rohan Khera, Melissa A. Simon, Joseph S. Ross",
        "published": "2023-12-19",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1001/jama.2023.22557"
    },
    {
        "id": 28886,
        "title": "An Innovative Approach to Electrical Motor Geometry Generation Using Machine Learning and Image Processing Techniques",
        "authors": "Ugur Demir, Gazi Akgun, Mustafa Caner Akuner, Majid Pourkarimi, Omer Akgun, Tahir Cetin Akinci",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3276885"
    },
    {
        "id": 28887,
        "title": "Explainable Image Classification: The Journey So Far and the Road Ahead",
        "authors": "Vidhya Kamakshi, Narayanan C. Krishnan",
        "published": "2023-8-1",
        "citations": 1,
        "abstract": "Explainable Artificial Intelligence (XAI) has emerged as a crucial research area to address the interpretability challenges posed by complex machine learning models. In this survey paper, we provide a comprehensive analysis of existing approaches in the field of XAI, focusing on the tradeoff between model accuracy and interpretability. Motivated by the need to address this tradeoff, we conduct an extensive review of the literature, presenting a multi-view taxonomy that offers a new perspective on XAI methodologies. We analyze various sub-categories of XAI methods, considering their strengths, weaknesses, and practical challenges. Moreover, we explore causal relationships in model explanations and discuss approaches dedicated to explaining cross-domain classifiers. The latter is particularly important in scenarios where training and test data are sampled from different distributions. Drawing insights from our analysis, we propose future research directions, including exploring explainable allied learning paradigms, developing evaluation metrics for both traditionally trained and allied learning-based classifiers, and applying neural architectural search techniques to minimize the accuracy–interpretability tradeoff. This survey paper provides a comprehensive overview of the state-of-the-art in XAI, serving as a valuable resource for researchers and practitioners interested in understanding and advancing the field.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ai4030033"
    },
    {
        "id": 28888,
        "title": "ODP-Transformer: Interpretation of pest classification results using image caption generation techniques",
        "authors": "Shansong Wang, Qingtian Zeng, Weijian Ni, Cheng Cheng, Yanxue Wang",
        "published": "2023-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compag.2023.107863"
    },
    {
        "id": 28889,
        "title": "The growth of image-related three dimensional reconstruction techniques in deep learning-driven era：a critical summary",
        "authors": "Yang Hang,  , Chen Rui, An Shipeng, Wei Hao, Zhang Heng",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.11834/jig.220376"
    },
    {
        "id": 28890,
        "title": "Comparative Analysis of Generative AI Techniques for Addressing the Tabular Data Generation Problem in Medical Records",
        "authors": "S. S. Aravinth, S. Srithar, K. Pranay Joseph, U. Gopala Anil Varma, G. Madhu Kiran, Venkatesh Jonna",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icraset59632.2023.10419886"
    },
    {
        "id": 28891,
        "title": "Orchestrating Efficiency: AI-Driven Cloud Resource Optimization for Enhanced Performance and Cost Reduction",
        "authors": "Prof. Dr. Angajala Srinivasa Rao",
        "published": "2023-12-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.55248/gengpi.4.1223.123430"
    },
    {
        "id": 28892,
        "title": "Comparing Gab’s AI Image Generator to Microsoft Bing’s Image Maker: An Experimental Study",
        "authors": "Robert W. McGee",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4679640"
    },
    {
        "id": 28893,
        "title": "​AI-Driven Anomaly Detection in Brewing for Enhanced Quality and Efficiency",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1094/tq-60-4-1214-01"
    },
    {
        "id": 28894,
        "title": "AI-Driven Clinical Decision Support Systems: An Ongoing Pursuit of Potential",
        "authors": "Malek Elhaddad, Sara Hamam",
        "published": "2024-4-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.7759/cureus.57728"
    },
    {
        "id": 28895,
        "title": "Smart Classrooms, Smarter Teachers: A Deep Dive into AI-Driven Educational Enhancement",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/jier.v3i2.479"
    },
    {
        "id": 28896,
        "title": "Collaborative Edge-Cloud AI for IoT Driven Secure Healthcare System",
        "authors": "Lav Gupta",
        "published": "2023-4-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/syscon53073.2023.10131082"
    },
    {
        "id": 28897,
        "title": "Adapting the Finance Curriculum for an AI-Driven Future",
        "authors": "David Krause",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4448143"
    },
    {
        "id": 28898,
        "title": "Yolov5 AI Deep Learning model driven Nuclear Pleomorphism Grading on Breast Cancer Pathology WSI for Nottingham Cancer Grading",
        "authors": "Et al. Rajasekaran Subramanian",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "Breast cancer is the second largest cancer caused in the world due to the uncontrollable growth in breast cells. Nottingham Grading is the internationally acceptable system to grade breast cancer. Nuclear pleomorphism is one of the breast cancer biomarkers for computing Nottingham grading. Pathologists grade nuclear pleomorphism on breast cancer glass tissue slides using a conventional microscope which is time consuming and has considerable inter-observer variability between pathologists. The paper proposed an Artificial Intelligence (AI) deep learning model to grade grade1, grade2, grade3 nuclear pleomorphism on breast cancer whole slide images (WSI). The proposed Yolov5 model is trained and tested on 1,30,000 WSI tiles having around two lakh annotations. The accuracy of the model is mAP 0.89. The proposed model saves the time and reduces the workload of the pathologist and also helps them  to produce accurate results.",
        "keywords": "",
        "link": "http://dx.doi.org/10.17762/ijritcc.v11i10.8465"
    },
    {
        "id": 28899,
        "title": "A Survey of AI Text-to-Image and AI Text-to-Video Generators",
        "authors": "Aditi Singh",
        "published": "2023-5-9",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/airc57904.2023.10303174"
    },
    {
        "id": 28900,
        "title": "AI-DRIVEN ENVIRONMENTAL HEALTH DISEASE MODELING: A REVIEW OF TECHNIQUES AND THEIR IMPACT ON PUBLIC HEALTH IN THE USA AND AFRICAN CONTEXTS",
        "authors": " Nzubechukwu Chukwudum Ohalete,  Oluwatoyin Ayo-Farai,  Tolulope O Olorunsogo,  Paschal Maduka,  Temidayo Olorunsogo",
        "published": "2024-1-23",
        "citations": 0,
        "abstract": "This scholarly paper embarks on an exploratory journey into the realm of AI-driven environmental health disease modeling, with a keen focus on its implications in the diverse healthcare landscapes of the USA and Africa. The study's background delves into the historical evolution of disease modeling techniques, emphasizing the revolutionary role of AI in modern public health strategies. It meticulously examines the comparative effectiveness of AI models in these distinct regions, addressing the challenges and opportunities inherent in AI-driven health models. Aiming to unravel the multifaceted impact of AI in disease prediction and public health policy, the paper navigates through various thematic corridors. It critically analyzes the significance of data sources and quality, ethical considerations in AI health modeling, and the integration of AI models into public health policies. The scope of the paper encompasses a comprehensive review of AI's efficacy in predicting environmental diseases, its role in enhancing disease surveillance systems, and the geographic and socioeconomic variations affecting model accuracy. The main findings reveal that AI models, while effective in disease prediction and surveillance, encounter challenges related to data integrity and ethical complexities. The study concludes that the integration of AI in healthcare necessitates a balanced approach, advocating for policies that support the development of context-specific AI models and address ethical concerns. Recommendations include fostering interdisciplinary collaboration and continuous evaluation of AI models to align them with evolving healthcare needs and ethical standards. This paper serves as a beacon for understanding AI's transformative potential in environmental health disease modeling, offering insights that are crucial for shaping future public health strategies and interventions.\r\nKeywords:  AI in Healthcare, Disease Modeling, Public Health Policy, Data Quality, Ethical Considerations, Geographic Variations.",
        "keywords": "",
        "link": "http://dx.doi.org/10.51594/imsrj.v4i1.737"
    },
    {
        "id": 28901,
        "title": "A systematic literature review: deep learning techniques for synthetic medical image generation and their applications in radiotherapy",
        "authors": "Moiz Khan Sherwani, Shyam Gopalakrishnan",
        "published": "2024-3-27",
        "citations": 0,
        "abstract": "The aim of this systematic review is to determine whether Deep Learning (DL) algorithms can provide a clinically feasible alternative to classic algorithms for synthetic Computer Tomography (sCT). The following categories are presented in this study: ∙ MR-based treatment planning and synthetic CT generation techniques. ∙ Generation of synthetic CT images based on Cone Beam CT images. ∙ Low-dose CT to High-dose CT generation. ∙ Attenuation correction for PET images. To perform appropriate database searches, we reviewed journal articles published between January 2018 and June 2023. Current methodology, study strategies, and results with relevant clinical applications were analyzed as we outlined the state-of-the-art of deep learning based approaches to inter-modality and intra-modality image synthesis. This was accomplished by contrasting the provided methodologies with traditional research approaches. The key contributions of each category were highlighted, specific challenges were identified, and accomplishments were summarized. As a final step, the statistics of all the cited works from various aspects were analyzed, which revealed that DL-based sCTs have achieved considerable popularity, while also showing the potential of this technology. In order to assess the clinical readiness of the presented methods, we examined the current status of DL-based sCT generation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fradi.2024.1385742"
    },
    {
        "id": 28902,
        "title": "A crowd-AI dynamic neural network hyperparameter optimization approach for image-driven social sensing applications",
        "authors": "Yang Zhang, Ruohan Zong, Lanyu Shang, Dong Wang",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2023.110864"
    },
    {
        "id": 28903,
        "title": "Locomotion characteristics of a wheeled vibration-driven robot with an enhanced pantograph-type suspension",
        "authors": "Vitaliy Korendiy, Oleksandr Kachur",
        "published": "2023-8-11",
        "citations": 3,
        "abstract": "Introduction: The paper considers the improved design of the wheeled vibration-driven robot equipped with an inertial exciter (unbalanced rotor) and enhanced pantograph-type suspension. The primary purpose and objectives of the study are focused on mathematical modeling, computer simulation, and experimental testing of locomotion conditions of the novel robot prototype. The primary scientific novelty of the present research consists in substantiating the possibilities of implementing the enhanced pantograph-type suspension in order to improve the robot’s kinematic characteristics, particularly the average translational speed.Methods: The simplified dynamic diagram of the robot’s oscillatory system is developed, and the mathematical model describing its locomotion conditions is derived using the Euler-Lagrange differential equations. The numerical modeling is carried out in the Mathematica software with the help of the Runge-Kutta methods. Computer simulation of the robot motion is performed in the SolidWorks Motion software using the variable step integration method (Gear’s method). The experimental investigations of the robot prototype operating conditions are conducted at the Vibroengineering Laboratory of Lviv Polytechnic National University using the WitMotion accelerometers and software. The experimental data is processed in the MathCad software.Results and discussion: The obtained results show the time dependencies of the robot body’s basic kinematic parameters (accelerations, velocities, displacements) under different operating conditions, particularly the angular frequencies of the unbalanced rotor. The numerical modeling, computer simulation, and experimental investigations present almost similar results: the smallest horizontal speed of about 1 mm/s is observed at the supplied voltage of 3.47 V when the forced frequency is equal to 500 rpm; the largest locomotion speed is approximately 40 mm/s at the supplied voltage of 10 V and forced frequency of 1,500 rpm. The paper may be interesting for designers and researchers of similar vibration-driven robotic systems based on wheeled chassis, and the results may be used while implementing the experimental and industrial prototypes of vibration-driven robots for various purposes, particularly, for inspecting and cleaning the pipelines. Further investigation on the subject of the paper should be focused on analyzing the relations between the power consumption, average translational speed, and working efficiency of the considerer robot under various operating conditions.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/frobt.2023.1239137"
    },
    {
        "id": 28904,
        "title": "A Requirements-Driven Conceptual Modeling Framework for Responsible AI",
        "authors": "Rohith Sothilingam",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/re57278.2023.00061"
    }
]