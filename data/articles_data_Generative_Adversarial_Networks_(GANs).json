[
    {
        "id": 1601,
        "title": "Generative Adversarial Networks (GANs) for Images",
        "authors": "Mehdi Ghayoumi",
        "published": "2023-11-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003281344-14"
    },
    {
        "id": 1602,
        "title": "Generative Adversarial Networks (GANs) Fundamentals and Architectures",
        "authors": "Mehdi Ghayoumi",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003281344-7"
    },
    {
        "id": 1603,
        "title": "Generative Adversarial Networks (GANs) for Voice, Music, and Song",
        "authors": "Mehdi Ghayoumi",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003281344-15"
    },
    {
        "id": 1604,
        "title": "Generative Adversarial Networks (GANs)",
        "authors": "Xudong Mao, Qing Li",
        "published": "2021",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-33-6048-8_1"
    },
    {
        "id": 1605,
        "title": "Generation of druglike molecules with generative adversarial networks (GANs)",
        "authors": "Beihong Ji, Matthew Brock",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1021/scimeetings.0c04751"
    },
    {
        "id": 1606,
        "title": "Generation of druglike molecules with generative adversarial networks (GANs)",
        "authors": "Beihong Ji, Matthew Brock",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1021/scimeetings.0c04750"
    },
    {
        "id": 1607,
        "title": "The Research Landscape on Generative Artificial Intelligence: A Bibliometric Analysis of Generative Adversarial Networks (Gans)",
        "authors": "Giulio Marchena, Ivan De La Vega",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4768716"
    },
    {
        "id": 1608,
        "title": "Speech Enhancement with Topology-Enhanced Generative Adversarial Networks (GANs)",
        "authors": "Xudong Zhang, Liang Zhao, Feng Gu",
        "published": "2021-8-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-1411"
    },
    {
        "id": 1609,
        "title": "Latent Deep Space: Generative Adversarial Networks (GANs) in the Sciences",
        "authors": "Fabian Offert",
        "published": "2021-12-22",
        "citations": 12,
        "abstract": "The recent spectacular success of machine learning in the sciences points to the emergence of a new artificial intelligence trading zone. The epistemological implications of this trading zone, however, have so far not been studied in depth. Critical research on machine learning systems, in media studies, visual studies, and “critical AI studies,” in the past five years, has focused almost exclusively on the social use of machine learning, producing an almost insurmountable backlog of deeply flawed technical reality. Among this backlog, one machine learning technique warrants particular attention from the perspective of media studies and visual studies: the generative adversarial network (GAN), a type of deep convolutional neural network that operates primarily on image data. In this paper, I argue that GANs are not only technically but also epistemically opaque systems: where GANs seem to enhance our view of an object under investigation, they actually present us with a technically and historically predetermined space of visual possibilities. I discuss this hypothesis in relation to established theories of images in the sciences and recent applications of GANs to problems in astronomy and medicine. I conclude by proposing that contemporary artistic uses of GANs point to their true potential as engines of scientific speculation.",
        "link": "http://dx.doi.org/10.1525/001c.29905"
    },
    {
        "id": 1610,
        "title": "GANs for Image Generation",
        "authors": "Xudong Mao, Qing Li",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-33-6048-8_2"
    },
    {
        "id": 1611,
        "title": "Understanding the Mathematical Background of Generative Adversarial Neural Networks (GANs)",
        "authors": "Bilgi Yilmaz",
        "published": "No Date",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3981773"
    },
    {
        "id": 1612,
        "title": "Creating Synthetic Data for Replication &amp; Privacy Protection using Generative Adversarial Networks",
        "authors": "",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4135/9781526496300"
    },
    {
        "id": 1613,
        "title": "Current Use of Generative Adversarial Networks (GANs) in Cardio-Imaging and Future Applications as Educational Tools in Cardiology",
        "authors": "Banu Bilen",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26226/morressier.5d19cfb257558b317a10dd99"
    },
    {
        "id": 1614,
        "title": "More Key Applications of GANs",
        "authors": "Xudong Mao, Qing Li",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-33-6048-8_3"
    },
    {
        "id": 1615,
        "title": "On Evaluating Video-based Generative Adversarial Networks (GANs)",
        "authors": "Nancy Ronquillo, Josh Harguess",
        "published": "2018-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aipr.2018.8707431"
    },
    {
        "id": 1616,
        "title": "Chapter 13: Generative Adversarial Networks (GANs)",
        "authors": "",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1137/1.9781611977905.ch13"
    },
    {
        "id": 1617,
        "title": "Generative Adversarial Networks (GANs): A Survey on Network Traffic Generation",
        "authors": "",
        "published": "2022-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18178/ijmlc.2022.12.6.1120"
    },
    {
        "id": 1618,
        "title": "Application of Generative Adversarial Networks (GANs) for Generating Synthetic Data and in Cybersecurity",
        "authors": "Sankalp Chenna",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4305711"
    },
    {
        "id": 1619,
        "title": "Bridging the gap between geophysics and geology with Generative Adversarial Networks (GANs)",
        "authors": "Suihong Song, Tapan Mukerji, Jiagen Hou",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31223/osf.io/ch8xf"
    },
    {
        "id": 1620,
        "title": "Geological Facies Modeling Based on Progressive Growing of Generative Adversarial Networks (GANs)",
        "authors": "Suihong Song, Tapan Mukerji, Jiagen Hou",
        "published": "No Date",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31223/osf.io/ycufs"
    },
    {
        "id": 1621,
        "title": "True 2D-to-3D Reconstruction of Heterogeneous Porous Media via Deep Generative Adversarial Networks (GANs)",
        "authors": "Hamed Amiri, Hannah Vogel, Oliver Plümper",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22541/essoar.170965049.96322870/v1"
    },
    {
        "id": 1622,
        "title": "Generative Adversarial Networks (GANs)",
        "authors": "",
        "published": "2022-11-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/9781119884170.ch12"
    },
    {
        "id": 1623,
        "title": "Improving Prediction Accuracy in Building Performance Models Using Generative Adversarial Networks (GANs)",
        "authors": "Chanachok Chokwitthaya, Edward Collier, Yimin Zhu, Supratik Mukhopadhyay",
        "published": "2019-7",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn.2019.8852411"
    },
    {
        "id": 1624,
        "title": "Circuit Synthesis Using Generative Adversarial Networks (GANs)",
        "authors": "Tinghao Guo, Daniel Herber, James T. Allison",
        "published": "2019-1-7",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2514/6.2019-2350"
    },
    {
        "id": 1625,
        "title": "Medical Image Synthesis Using Generative Adversarial Networks",
        "authors": "Vishal Raner, Amit Joshi, Suraj Sawant",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-43205-7_3"
    },
    {
        "id": 1626,
        "title": "GANSim: Conditional Facies Simulation Using an Improved Progressive Growing of Generative Adversarial Networks (GANs)",
        "authors": "Suihong Song, Tapan Mukerji, Jiagen Hou",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31223/osf.io/fm24b"
    },
    {
        "id": 1627,
        "title": "A Survey of Modern Deep Learning based Generative Adversarial Networks (GANs)",
        "authors": "P. Pradhyumna,  Mohana",
        "published": "2022-3-29",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccmc53470.2022.9753782"
    },
    {
        "id": 1628,
        "title": "Using Generative Adversarial Networks (GANs) to downscale tropical cyclone precipitation.&amp;#160;",
        "authors": "Emily Vosper, Dann Mitchell, Peter Watson, Laurence Aitchison, Raul Santos-Rodriguez",
        "published": "No Date",
        "citations": 1,
        "abstract": "&lt;div&gt;\n&lt;p&gt;&lt;span&gt;Fluvial flood hazards from tropical cyclones (TCs) are frequently the leading cause of mortality and damages (Rezapour and Baldock, 2014).&amp;#160;Accurately modeling TC precipitation is vital for studying the current and future impacts of TCs.&amp;#160;However, general circulation models at typical resolution&amp;#160;struggle to accurately reproduce TC&amp;#160;rainfall,&amp;#160;especially for the most&amp;#160;extreme storms&amp;#160;(Murakami et al., 2015).&amp;#160;Increasing horizontal resolution can&amp;#160;improve&amp;#160;precipitation estimates&amp;#160;(Roberts et al., 2020;&amp;#160;Zhang et al., 2021), but as these methods are computationally expensive there is a trade-off between accuracy and&amp;#160;generating enough ensemble members&amp;#160;to generate sufficient&amp;#160;high impact, low probability events.&amp;#160;Often, downscaling models are used as a computationally cheaper alternative.&lt;/span&gt;&lt;span&gt;&amp;#160;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div&gt;\n&lt;p&gt;&lt;span&gt;Here, we downscale TC precipitation data from 100 km to 10 km resolution using a generative adversarial network (GAN). Generative approaches have the potential to well reproduce &lt;/span&gt;&lt;span&gt;the fine spatial detail&lt;/span&gt;&lt;span&gt;&amp;#160;and stochastic nature of precipitation (Ravuri et al., 2021).&amp;#160;Using&amp;#160;observational products for tracking&amp;#160;(IBTrACS) and rainfall&amp;#160;(MSWEP), we train our GAN over the historical period 1979 - 2020.&amp;#160;We are interested in&amp;#160;how well&amp;#160;our model reproduces precipitation intensity and structure&amp;#160;with a focus on the most extreme events, where models have traditionally struggled.&lt;/span&gt;&lt;span&gt;&amp;#160;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div&gt;\n&lt;p&gt;&lt;strong&gt;&lt;span&gt;Bibliography&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&amp;#160;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div&gt;\n&lt;p&gt;&lt;span&gt;Murakami, H., et al., 2015. Simulation and Prediction of Category 4 and 5 Hurricanes in the High-Resolution GFDL HiFLOR Coupled Climate Model*.&amp;#160;&lt;/span&gt;&lt;em&gt;&lt;span&gt;Journal of Climate&lt;/span&gt;&lt;/em&gt;&lt;span&gt;, 28(23), pp.9058-9079.&lt;/span&gt;&lt;span&gt;&amp;#160;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div&gt;\n&lt;p&gt;&lt;span&gt;Ravuri, S., et al., 2021. Skilful precipitation nowcasting using deep generative models of radar.&amp;#160;&lt;/span&gt;&lt;em&gt;&lt;span&gt;Nature&lt;/span&gt;&lt;/em&gt;&lt;span&gt;, 597(7878), pp.672-677.&lt;/span&gt;&lt;span&gt;&amp;#160;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div&gt;\n&lt;p&gt;&lt;span&gt;Rezapour, M. and Baldock, T., 2014. Classification of Hurricane Hazards: The Importance of Rainfall.&amp;#160;&lt;/span&gt;&lt;em&gt;&lt;span&gt;Weather and Forecasting&lt;/span&gt;&lt;/em&gt;&lt;span&gt;, 29(6), pp.1319-1331.&lt;/span&gt;&lt;span&gt;&amp;#160;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div&gt;\n&lt;p&gt;&lt;span&gt;Roberts, M., et al., 2020. Impact of Model Resolution on Tropical Cyclone Simulation Using the HighResMIP&amp;#8211;PRIMAVERA Multimodel Ensemble.&amp;#160;&lt;/span&gt;&lt;em&gt;&lt;span&gt;Journal of Climate,&lt;/span&gt;&lt;/em&gt;&lt;span&gt; 33(7), pp.2557-2583.&lt;/span&gt;&lt;span&gt;&amp;#160;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;div&gt;\n&lt;p&gt;&lt;span&gt;Zhang, W., et al., 2021. Tropical cyclone precipitation in the HighResMIP atmosphere-only experiments of the PRIMAVERA Project.&amp;#160;&lt;/span&gt;&lt;em&gt;&lt;span&gt;Climate Dynamics&lt;/span&gt;&lt;/em&gt;&lt;span&gt;, 57(1-2), pp.253-273.&lt;/span&gt;&lt;span&gt;&amp;#160;&lt;/span&gt;&lt;/p&gt;\n&lt;/div&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu22-8454"
    },
    {
        "id": 1629,
        "title": "GIU-GANs: Global Information Utilization for Generative Adversarial Networks",
        "authors": "Yongqi Tian, Xueyuan Gong, Jialin Tang, Binghua Su, Xiaoxiang Liu, Xinyuan Zhang",
        "published": "2022-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neunet.2022.05.014"
    },
    {
        "id": 1630,
        "title": "Ubaldo Ramón: LDDMM Meets GANs: Generative Adversarial   Networks for Diffeomorphic Registration",
        "authors": "Ubaldo Ramón",
        "published": "2021-11-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26754/jjii3a.20216118"
    },
    {
        "id": 1631,
        "title": "On the photographic status of images produced by generative adversarial networks (GANs)",
        "authors": "Antonio Somaini",
        "published": "2022-4-1",
        "citations": 1,
        "abstract": "The text analyses the new images produced by artificial neural networks such as Generative Adversarial Networks (GANs) from the perspective of photography and, more specifically, cameraless photography. The images produced by GANs are located within the wider framework of the impact of machine learning technologies on contemporary visual culture and contemporary artistic practices. In the final section, the article focuses on the work of two artists who have explicity tackled the relations between GAN-generated images and the traditions of photography and cameraless photography, with their multiple intertwinings of human and non-human agencies: Mario Klingemann and Grégory Chatonsky.",
        "link": "http://dx.doi.org/10.1386/pop_00044_1"
    },
    {
        "id": 1632,
        "title": "Generative Adversarial Networks (GANs)",
        "authors": "Umberto Michelucci",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-8020-1_11"
    },
    {
        "id": 1633,
        "title": "Image Synthesis and Editing with Generative Adversarial Networks (GANs): A Review",
        "authors": "Wanwan Li",
        "published": "2021-7-29",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/worlds451998.2021.9514052"
    },
    {
        "id": 1634,
        "title": "3-D Reconstructions of Porous Media from 2-D input via Generative Adversarial Networks (GANs)",
        "authors": "Hannah Vogel, Hamed Amiri, Austin Arias, Oliver Plümper, Markus Ohl",
        "published": "No Date",
        "citations": 0,
        "abstract": "Many macroscopic transport properties and physical processes, such as the flow of fluids through a porous medium, are directly controlled by its microstructure, specifically the presence and connectivity of individual pore spaces at micron and submicron scales. Reconstructing and evaluating the material properties of porous media plays a key role across many engineering disciplines from subsurface storage (e.g., CO2 and hydrogen) to geothermal energy and reservoir characterization. As such, the rapid and reliable characterization, evaluation, and simulation of complex pore microstructures is required not only to enhance our understanding of the fundamental processes occurring at the pore scale, but to also better estimate their material behavior on a larger scale.These material behaviors are inherently volumetric and therefore cannot be accurately modelled using two-dimensional (2D) data alone. As a result, the accuracy of reconstruction techniques used to extract these morphological properties and spatial distributions is in part determined by the quality of available three-dimensional (3D) microstructural datasets. However, in comparison to their 3D counterparts, 2D imaging techniques are typically more cost efficient, easier to collect, and higher resolution. Our goal of generating statistically accurate 3D reconstructions of complex pore microstructural distributions based on high resolution 2D datasets is essential to bridging this dimensionality gap.Newly explored 2D-to-3D reconstruction techniques based on deep-learning (DL) algorithms offer an alternative means of generating robust and statistically representative digital 3D rock reconstructions by measuring some spatial morphological properties and statistical microstructural descriptors (SMDs) of porous media samples from high-resolution 2D datasets. These DL models are highly flexible and capable of capturing a variety of complex microstructural features given representative 2D training datasets. In this paper, we implement a newly developed deep Generative Adversarial Network (GAN), known as SliceGAN, to synthesize novel binary digital 3D reconstructions using high-resolution 2D back-scattered electron (BSE) images obtained from thin-sections oriented in the x-, y- & z-direction.Our trained model is capable of accurately reconstructing complex 3D microstructural features of porous media through capturing the underlying (micro-)structural and morphological properties contained in the original sample (2D) thin-sections. To demonstrate the effectiveness of our trained model, we conducted a comparative analysis between the generated 3D reconstructions and real sample datasets by evaluating morphological properties (volume fraction, surface area, equivalent diameter, pore orientations, etc.) as well as the widely popular SMD the two-point correlation function (S2 (r) ). The resulting reconstructions are virtually indistinguishable, both visually and statistically, from the real sample. Our research paves the way for quickly and accurately describing complex heterogenous media for the prediction of transport processes, for example, carbon and hydrogen storage and extraction.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-15241"
    },
    {
        "id": 1635,
        "title": "Minimal Walking Technicolor Simulation using Generative Adversarial Networks (GANs)",
        "authors": "Essam Al Daoud",
        "published": "2020-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.30534/ijeter/2020/24832020"
    },
    {
        "id": 1636,
        "title": "Deep Convolutional Generative Adversarial Networks (DCGANs)",
        "authors": "Mehdi Ghayoumi",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003281344-8"
    },
    {
        "id": 1637,
        "title": "Reviving Black and White Images: Enhancing Colorization with Generative Adversarial Networks (GANs)",
        "authors": "Rahul Rahul, Devanshu Walecha",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10306534"
    },
    {
        "id": 1638,
        "title": "Scope of generative adversarial networks (GANs) in image processing",
        "authors": "Sudesh Kumari, Karan Aggarwal",
        "published": "2022-6-24",
        "citations": 0,
        "abstract": "Generative Adversarial Network is the topic of interest in today’s research in the field of image processing and computer vision. A basic GAN model was introduced by Ian Goodfellow et al. in 2014. After that advancement in the field of research in GAN models has been application specific. In computer vision and image to image translation GANs are playing very effective role either in the case of face detection and recognition or in image resolution enhancement and image augmentation. This paper represents a concise overview of various GAN models along with their features and applications. Pix2Pix and conditional GAN models work upon paired datasets while other models like cycle GAN, discover GAN, dual GAN, info GAN, deep convolutional GAN etc. work upon unpaired datasets. Various image datasets which are commonly used for training of generator and discriminator networks are also discussed in this paper. Since partial mode collapse is a common problem to occur during training process for all models, therefore various normalization techniques are also preferred during the training of generator and discriminator networks. As the advancements in GAN models are increasing at a very fast rate, soon these models will also be preferred in commercial applications.",
        "link": "http://dx.doi.org/10.53730/ijhs.v6ns6.9664"
    },
    {
        "id": 1639,
        "title": "Attention-Aware Generative Adversarial Networks (ATA-GANs)",
        "authors": "Dimitris Kastaniotis, Ioanna Ntinou, Dimitrios Tsourounis, George Economou, Spiros Fotopoulos",
        "published": "2018-6",
        "citations": 23,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ivmspw.2018.8448850"
    },
    {
        "id": 1640,
        "title": "Games of GANs: Game-Theoretical Models for Generative Adversarial Networks",
        "authors": "Monireh Mohebbi Moghadam, Bahar Boroomand, Mohammad Jalali, Arman Zareian, Alireza Daeijavad, Mohammad Hossein Manshaei, Marwan Krunz",
        "published": "No Date",
        "citations": 1,
        "abstract": "Abstract\nGenerative Adversarial Networks (GANs) have recently attracted considerable attention in the AI community due to their ability to generate high-quality data of significant statistical resemblance to real data. Fundamentally, GAN is a game between two neural networks trained in an adversarial manner to reach a zero-sum Nash equilibrium profile. Despite the improvement accomplished in GANs in the last few years, several issues remain to be solved. This paper reviews the literature on the game-theoretic aspects of GANs and addresses how game theory models can address specific challenges of generative models and improve the GAN's performance. We first present some preliminaries, including the basic GAN model and some game theory background. We then present taxonomy to classify state-of-the-art solutions into three main categories: modified game models, modified architectures, and modified learning methods. The classification is based on modifications made to the basic GAN model by proposed game-theoretic approaches in the literature. We then explore the objectives of each category and discuss recent works in each class. Finally, we discuss the remaining challenges in this field and present future research directions.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1766445/v1"
    },
    {
        "id": 1641,
        "title": "Distributionally robust chance constrained programming with generative adversarial networks (GANs)",
        "authors": "Shipu Zhao, Fengqi You",
        "published": "2020-6",
        "citations": 16,
        "abstract": "AbstractThis paper presents a novel deep learning based data‐driven optimization method. A novel generative adversarial network (GAN) based data‐driven distributionally robust chance constrained programming framework is proposed. GAN is applied to fully extract distributional information from historical data in a nonparametric and unsupervised way without a priori approximation or assumption. Since GAN utilizes deep neural networks, complicated data distributions and modes can be learned, and it can model uncertainty efficiently and accurately. Distributionally robust chance constrained programming takes into consideration ambiguous probability distributions of uncertain parameters. To tackle the computational challenges, sample average approximation method is adopted, and the required data samples are generated by GAN in an end‐to‐end way through the differentiable networks. The proposed framework is then applied to supply chain optimization under demand uncertainty. The applicability of the proposed approach is illustrated through a county‐level case study of a spatially explicit biofuel supply chain in Illinois.",
        "link": "http://dx.doi.org/10.1002/aic.16963"
    },
    {
        "id": 1642,
        "title": "EEG Anomaly Detection using Generative Adversarial Networks (GANs)",
        "authors": "Niloofar Sedighian Bidgoli, Saeed Reza Kheradpisheh, Hadi Farahani",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/aisp61396.2024.10475243"
    },
    {
        "id": 1643,
        "title": "Using Generative Adversarial Networks (GANs) to Generate Facial Attributes",
        "authors": "Mustafa Radif",
        "published": "2019-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36478/jeasci.2019.9073.9085"
    },
    {
        "id": 1644,
        "title": "Generative Adversarial Networks (GANs) for Audio-Visual Speech Recognition in Artificial Intelligence IoT",
        "authors": "Yibo He, Kah Phooi Seng, Li Minn Ang",
        "published": "2023-10-19",
        "citations": 1,
        "abstract": "This paper proposes a novel multimodal generative adversarial network AVSR (multimodal AVSR GAN) architecture, to improve both the energy efficiency and the AVSR classification accuracy of artificial intelligence Internet of things (IoT) applications. The audio-visual speech recognition (AVSR) modality is a classical multimodal modality, which is commonly used in IoT and embedded systems. Examples of suitable IoT applications include in-cabin speech recognition systems for driving systems, AVSR in augmented reality environments, and interactive applications such as virtual aquariums. The application of multimodal sensor data for IoT applications requires efficient information processing, to meet the hardware constraints of IoT devices. The proposed multimodal AVSR GAN architecture is composed of a discriminator and a generator, each of which is a two-stream network, corresponding to the audio stream information and the visual stream information, respectively. To validate this approach, we used augmented data from well-known datasets (LRS2-Lip Reading Sentences 2 and LRS3) in the training process, and testing was performed using the original data. The research and experimental results showed that the proposed multimodal AVSR GAN architecture improved the AVSR classification accuracy. Furthermore, in this study, we discuss the domain of GANs and provide a concise summary of the proposed GANs.",
        "link": "http://dx.doi.org/10.3390/info14100575"
    },
    {
        "id": 1645,
        "title": "Generative Adversarial Networks (GANs) for spatial upward fluxes radiation estimation",
        "authors": "Mohamed Eltahan, Nour Daoud, Karim Moharm",
        "published": "2021-2-19",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icaect49130.2021.9392477"
    },
    {
        "id": 1646,
        "title": "Generative adversarial networks and their variants",
        "authors": "Er. Aarti",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-823519-5.00003-8"
    },
    {
        "id": 1647,
        "title": "Data Augmentation Using Generative Adversarial Networks (GANs) For GAN-Based Detection Of Pneumonia And COVID-19 In Chest X-Ray Images",
        "authors": "Saman Motamed, Patrik Rogalla, Farzad Khalvati",
        "published": "No Date",
        "citations": 6,
        "abstract": "Abstract\nSuccessful training of convolutional neural networks (CNNs) requires a substantial amount of data. With small datasets networks generalize poorly. Data Augmentation techniques improve the generalizability of neural networks by using existing training data more effectively. Standard data augmentation methods, however, produce limited plausible alternative data. Generative Adversarial Networks (GANs) have been utilized to generate new data and improve the performance of CNNs. Nevertheless, data augmentation techniques for training GANs are under-explored compared to CNNs. In this work, we propose a new GAN architecture for augmentation of chest X-rays for semi-supervised detection of pneumonia and COVID-19 using generative models. We show that the proposed GAN can be used to effectively augment data and improve classification accuracy of disease in chest X-rays for pneumonia and COVID-19. We compare our augmentation GAN model with Deep Convolutional GAN and traditional augmentation methods (rotate, zoom, etc) on two different X-ray datasets and show our GAN-based augmentation method surpasses other augmentation methods for training a GAN in detecting anomalies in X-ray images.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-146161/v1"
    },
    {
        "id": 1648,
        "title": "Generating OCT B-Scan DME images using optimized Generative Adversarial Networks (GANs)",
        "authors": "Aditya Tripathi, Preetham Kumar, Veena Mayya, Akshat Tulsani",
        "published": "2023-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.heliyon.2023.e18773"
    },
    {
        "id": 1649,
        "title": "Augmentation von Kameradaten mit Generative Adversarial Networks (GANs) zur Absicherung automatisierter Fahrfunktionen",
        "authors": "P. Rigoll, P. Petersen, L. Ries, J. Langner, E. Sax",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.51202/9783181023945-41"
    },
    {
        "id": 1650,
        "title": "On the Fairness of Generative Adversarial Networks (GANs)",
        "authors": "Patrik Joslin Kenfack, Daniil Dmitrievich Arapov, Rasheed Hussain, S.M. Ahsan Kazmi, Adil Khan",
        "published": "2021-8-26",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/nir52917.2021.9666131"
    },
    {
        "id": 1651,
        "title": "A Study on Customized Face generator using Generative Adversarial Networks (GANs)",
        "authors": "Priya Yadav, Ramandeep Kaur, U. Hariharan",
        "published": "2023-12-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iementech60402.2023.10423429"
    },
    {
        "id": 1652,
        "title": "GPR-GANs: Generation of Synthetic Ground Penetrating Radargrams Using Generative Adversarial Networks",
        "authors": "Ahtisham Fazeel, Jan Rottmayer, Rajat Mehta, Naim Bajcinca",
        "published": "2021-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iwagpr50767.2021.9843171"
    },
    {
        "id": 1653,
        "title": "Image generation using generative adversarial networks",
        "authors": "Omkar Metri, H.R Mamatha",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-823519-5.00007-5"
    },
    {
        "id": 1654,
        "title": "Conditional Generative Adversarial Network (cGAN)",
        "authors": "Mehdi Ghayoumi",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003281344-9"
    },
    {
        "id": 1655,
        "title": "Cycle Generative Adversarial Network (CycleGAN)",
        "authors": "Mehdi Ghayoumi",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003281344-10"
    },
    {
        "id": 1656,
        "title": "Wasserstein Generative Adversarial Network (WGAN)",
        "authors": "Mehdi Ghayoumi",
        "published": "2023-11-14",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003281344-13"
    },
    {
        "id": 1657,
        "title": "Exploring Generative Adversarial Networks (GANs) for Deepfake Detection: A Systematic Literature Review",
        "authors": "Jerico Asan, Ivana Ekaputri, Catherine Natalie, Kartika Purwandari",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iwaiip58158.2023.10462832"
    },
    {
        "id": 1658,
        "title": "Least Squares Generative Adversarial Network (LSGAN)",
        "authors": "Mehdi Ghayoumi",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003281344-12"
    },
    {
        "id": 1659,
        "title": "Semi-Supervised Generative Adversarial Network (SGAN)",
        "authors": "Mehdi Ghayoumi",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003281344-11"
    },
    {
        "id": 1660,
        "title": "Generative Adversarial Networks-aided Intrusion Detection System",
        "authors": "V. Kumar",
        "published": "2023-3-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003203964-6"
    },
    {
        "id": 1661,
        "title": "License Plate Image Analysis Empowered by Generative Adversarial Neural Networks (GANs)",
        "authors": "Ibrahim H. El-Shal, Omar M. Fahmy, Mustafa A. Elattar",
        "published": "2022",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2022.3157714"
    },
    {
        "id": 1662,
        "title": "Generative adversarial networks for histopathology staining",
        "authors": "Aashutosh Ganesh, Koshy George",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-823519-5.00010-5"
    },
    {
        "id": 1663,
        "title": "Generative Adversarial Networks (GANs) in networking: A comprehensive survey &amp; evaluation",
        "authors": "Hojjat Navidan, Parisa Fard Moshiri, Mohammad Nabati, Reza Shahbazian, Seyed Ali Ghorashi, Vahid Shah-Mansouri, David Windridge",
        "published": "2021-7",
        "citations": 40,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.comnet.2021.108149"
    },
    {
        "id": 1664,
        "title": "LDDMM Meets GANs: Generative Adversarial Networks for Diffeomorphic Registration",
        "authors": "Ubaldo Ramon Julvez, Mónica Hernández Giménez, Elvira Mayordomo Cámara",
        "published": "2021-11-12",
        "citations": 0,
        "abstract": "In this work, we propose an unsupervised adversarial learning LDDMM method for 3D mono-modal images based on Generative Adversarial Networks. We have successfully implemented two models with stationary and EPDiff constrained non-stationary parameterizations of diffeomorphisms. Our approach has shown a competitive performance with respect to benchmark supervised and model-based methods.",
        "link": "http://dx.doi.org/10.26754/jjii3a.20216002"
    },
    {
        "id": 1665,
        "title": "Stock Market Prediction Using Generative Adversarial Networks (GANs): Hybrid Intelligent Model",
        "authors": "Fares Abdulhafidh Dael, Ömer Çağrı Yavuz, Uğur Yavuz",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32604/csse.2023.037903"
    },
    {
        "id": 1666,
        "title": "Applications of generative adversarial networks (GANs) in radiotherapy: narrative review",
        "authors": "Zhixiang Wang, Glauco Lorenzut, Zhen Zhang, Andre Dekker, Alberto Traverso",
        "published": "2022-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21037/pcm-22-28"
    },
    {
        "id": 1667,
        "title": "Method for Exploring Generative Adversarial Networks (GANs) via Automatically Generated Image Galleries",
        "authors": "Enhao Zhang, Nikola Banovic",
        "published": "2021-5-6",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3411764.3445714"
    },
    {
        "id": 1668,
        "title": "Challenges and Corresponding Solutions of Generative Adversarial Networks (GANs): A Survey Study",
        "authors": "Haiyang Chen",
        "published": "2021-3-1",
        "citations": 16,
        "abstract": "Abstract\nGenerative Adversarial Networks (GANs) are an innovative class of deep learning generative model that has been popular among academics recently. GANs are able to learn distributions on complex high-dimensional data which made it efficient in images and audio processing. Nevertheless, in the training of GANs, some major challenges exist namely mode collapse, non-convergence, and instability. In recent years, in order to overcome these challenges, researchers have proposed many variants of GANs by redesigning network architecture, changing the form of objective functions, and altering optimization algorithms. In this research, we conducted a comprehensive investigation on the progress of GANs design and optimization solutions. Finally, according to the classification method, we provided a problem-solving structure to solve conquer the GANs training challenges.",
        "link": "http://dx.doi.org/10.1088/1742-6596/1827/1/012066"
    },
    {
        "id": 1669,
        "title": "Understanding the mathematical background of Generative Adversarial Networks (GANs)",
        "authors": "Bilgi YILMAZ, Ralf KORN",
        "published": "2023-9-30",
        "citations": 0,
        "abstract": "Generative Adversarial Networks (GANs) have gained widespread attention since their introduction, leading to numerous extensions and applications of the original GAN idea. A thorough understanding of GANs' mathematical foundations is necessary to use and build upon these techniques. However, most studies on GANs are presented from a computer science or engineering perspective, which can be challenging for beginners to understand fully. Therefore, this paper aims to provide an overview of the mathematical background of GANs, including detailed proofs of optimal solutions for vanilla GANs and boundaries for $f$-GANs that minimize a variational approximation of the $f$-divergence between two distributions. These contributions will enhance the understanding of GANs for those with a mathematical background and pave the way for future research.",
        "link": "http://dx.doi.org/10.53391/mmnsa.1327485"
    },
    {
        "id": 1670,
        "title": "Generative Adversarial Networks for Video-to-Video Translation",
        "authors": "Yogini Borole, Roshani Raut",
        "published": "2023-3-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003203964-4"
    },
    {
        "id": 1671,
        "title": "Enhancing Population Diversity by Integrating Iterative Local Search with Deep Convolutional Generative Adversarial Networks (GANs)",
        "authors": "Ruiran Yu, Yuhan Xu, Haowei Peng, Meng-Hui Chen",
        "published": "2022-8-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icpr56361.2022.9956322"
    },
    {
        "id": 1672,
        "title": "Chest X-Ray Data Augmentation with Generative Adversarial Networks for Pneumonia and COVID-19 Diagnosis",
        "authors": "Beena Godbin A, Graceline Jasmine S",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-43205-7_4"
    },
    {
        "id": 1673,
        "title": "Ultrasound breast images denoising using generative adversarial networks (GANs)",
        "authors": "Yuliana Jiménez-Gaona, María José Rodríguez-Alvarez, Líder Escudero, Carlos Sandoval, Vasudevan Lakshminarayanan",
        "published": "2024-1-31",
        "citations": 0,
        "abstract": "INTRODUCTION: Ultrasound in conjunction with mammography imaging, plays a vital role in the early detection and diagnosis of breast cancer. However, speckle noise affects medical ultrasound images and degrades visual radiological interpretation. Speckle carries information about the interactions of the ultrasound pulse with the tissue microstructure, which generally causes several difficulties in identifying malignant and benign regions. The application of deep learning in image denoising has gained more attention in recent years. OBJECTIVES: The main objective of this work is to reduce speckle noise while preserving features and details in breast ultrasound images using GAN models. METHODS: We proposed two GANs models (Conditional GAN and Wasserstein GAN) for speckle-denoising public breast ultrasound databases: BUSI, DATASET A, AND UDIAT (DATASET B). The Conditional GAN model was trained using the Unet architecture, and the WGAN model was trained using the Resnet architecture. The image quality results in both algorithms were measured by Peak Signal to Noise Ratio (PSNR, 35–40 dB) and Structural Similarity Index (SSIM, 0.90–0.95) standard values. RESULTS: The experimental analysis clearly shows that the Conditional GAN model achieves better breast ultrasound despeckling performance over the datasets in terms of PSNR = 38.18 dB and SSIM = 0.96 with respect to the WGAN model (PSNR = 33.0068 dB and SSIM = 0.91) on the small ultrasound training datasets. CONCLUSIONS: The observed performance differences between CGAN and WGAN will help to better implement new tasks in a computer-aided detection/diagnosis (CAD) system. In future work, these data can be used as CAD input training for image classification, reducing overfitting and improving the performance and accuracy of deep convolutional algorithms.",
        "link": "http://dx.doi.org/10.3233/ida-230631"
    },
    {
        "id": 1674,
        "title": "Generic image application using GANs (Generative Adversarial Networks): A Review",
        "authors": "S. P. Porkodi, V. Sarada, Vivek Maik, K. Gurushankar",
        "published": "2023-10",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s12530-022-09464-y"
    },
    {
        "id": 1675,
        "title": "A Review of Generative Adversarial Networks (GANs) for Technology-Assisted Learning: Solving Teaching and Learning Challenges",
        "authors": "K. Dinesh Kumar, Sarot Srang, Dona Valy",
        "published": "2022-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icacrs55517.2022.10029021"
    },
    {
        "id": 1676,
        "title": "GANs, GANs, and More GANs",
        "authors": "Micheal Lanham",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-7092-9_4"
    },
    {
        "id": 1677,
        "title": "Generative adversarial networks (GANs): Introduction, Taxonomy, Variants, Limitations, and Applications",
        "authors": "Preeti Sharma, Manoj Kumar, Hitesh Kumar Sharma, Soly Mathew Biju",
        "published": "2024-3-26",
        "citations": 0,
        "abstract": "AbstractThe growing demand for applications based on Generative Adversarial Networks (GANs) has prompted substantial study and analysis in a variety of fields. GAN models have applications in NLP, architectural design, text-to-image, image-to-image, 3D object production, audio-to-image, and prediction. This technique is an important tool for both production and prediction, notably in identifying falsely created pictures, particularly in the context of face forgeries, to ensure visual integrity and security. GANs are critical in determining visual credibility in social media by identifying and assessing forgeries. As the field progresses, a variety of GAN variations arise, along with the development of diverse assessment techniques for assessing model efficacy and scope. The article provides a complete and exhaustive overview of the most recent advances in GAN model designs, the efficacy and breadth of GAN variations, GAN limits and potential solutions, and the blooming ecosystem of upcoming GAN tool domains. Additionally, it investigates key measures like as Inception Score (IS) and Fréchet Inception Distance (FID) as critical benchmarks for improving GAN performance in contrast to existing approaches.",
        "link": "http://dx.doi.org/10.1007/s11042-024-18767-y"
    },
    {
        "id": 1678,
        "title": "Synthetic demand data generation for individual electricity consumers : Generative Adversarial Networks (GANs)",
        "authors": "Bilgi Yilmaz, Ralf Korn",
        "published": "2022-8",
        "citations": 20,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.egyai.2022.100161"
    },
    {
        "id": 1679,
        "title": "Capturing multiscale temporal dynamics in synthetic residential load profiles through Generative Adversarial Networks (GANs)",
        "authors": "Robbert Claeys, Rémy Cleenwerck, Jos Knockaert, Jan Desmet",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.apenergy.2024.122831"
    },
    {
        "id": 1680,
        "title": "Elderly Care Using Generative Adversarial Networks (GANs) on Deep Video Analysis",
        "authors": "S. Rajasekaran, G. Kousalya",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-8721-1_6"
    },
    {
        "id": 1681,
        "title": "Agricultural Image Augmentation with Generative Adversarial Networks GANs",
        "authors": "Sayan De, Ishita Bhakta, Santanu Phadikar, Koushik Majumder",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-3089-8_32"
    },
    {
        "id": 1682,
        "title": "Generation And Detection of Deepfakes using Generative Adversarial Networks (GANs) and Affine Transformation",
        "authors": "J. Vijaya, Amaan A. Kazi, Kishan G. Mishra, Avala Praveen",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10307811"
    },
    {
        "id": 1683,
        "title": "Visual Storytelling: A Generative Adversarial Networks (GANs) and Graph Embedding Framework",
        "authors": "Et al. K. Dinesh Kumar",
        "published": "2023-11-5",
        "citations": 0,
        "abstract": "Visual storytelling is a powerful educational tool, using image sequences to convey complex ideas and establish emotional connections with the audience. A study at the Chinese University of Hong Kong found that 92.7% of students prefer visual storytelling through animation over text alone [21]. Our approach integrates dual coding and propositional theory to generate visual representations of text, such as graphs and images, thereby enhancing students' memory retention and visualization skills. We use Generative Adversarial Networks (GANs) with graph data to generate images while preserving semantic consistency across objects, encompassing their attributes and relationships. By incorporating graph embedding, which includes node and relation embedding, we further enhance the semantic consistency of the generated high-quality images, improving the effectiveness of visual storytelling in education.",
        "link": "http://dx.doi.org/10.17762/ijritcc.v11i9.9184"
    },
    {
        "id": 1684,
        "title": "Generative Adversarial Networks (GANs) in Computer-Generated Imagery",
        "authors": "Sannan Ahmad Shah, Shahhab Hasin Drabu, Murtaza Mahdi Khan, Dawar Bin Qayoom Kirmani, Shailendra Narayan Singh",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iccsai59793.2023.10421513"
    },
    {
        "id": 1685,
        "title": "What are GANs?: Introducing Generative Adversarial Networks to Middle School Students",
        "authors": "Safinah Ali, Daniella DiPaola, Cynthia Breazeal",
        "published": "2021-5-18",
        "citations": 10,
        "abstract": "Applications of Generative Machine Learning techniques such as Generative Adversarial Networks (GANs) are used to generate new instances of images, music, text, and videos. While GANs have now become commonplace on social media, a part of children’s lives, and have considerable ethical implications, existing K-12 AI education curricula do not include generative AI. We present a new module, “What are GANs?”, that teaches middle school students how GANs work and how they can create media using GANs. We developed an online, team-based game to simulate how GANs work. Students also interacted with up to four web tools that apply GANs to generate media. This module was piloted with 72 middle school students in a series of online workshops. We provide insight into student usage, understanding, and attitudes towards this lesson. Finally, we give suggestions for integrating this lesson into AI education curricula.",
        "link": "http://dx.doi.org/10.1609/aaai.v35i17.17821"
    },
    {
        "id": 1686,
        "title": "Creating Artificial Images for Radiology Applications Using Generative Adversarial Networks (GANs) – A Systematic Review",
        "authors": "Vera Sorin, Yiftach Barash, Eli Konen, Eyal Klang",
        "published": "2020-8",
        "citations": 92,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.acra.2019.12.024"
    },
    {
        "id": 1687,
        "title": "Security of Generative Adversarial Networks",
        "authors": "Kyrylo Rudavskyy",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The overarching goal of this work is to explore the security landscape of Generative Adversarial Networks (GANs). In recent years, their adoption started to gain traction, and they are now used in many critical domains. Security is paramount in many of these domains. Since GANs are a system of two or more neural networks, security weaknesses in one of its components can be exploited against the system. This is the attack vector considered in this work. Specifically, this research evaluated the threat potential of an adversarial attack against the discriminator part of the system. Such an attack aims to distort the output by injecting maliciously modified input during training. The attack was empirically evaluated against four types of GANs, injections of 10% and 20% malicious data, and two datasets. The targets were CGAN, ACGAN, WGAN, and WGAN-GP. The datasets were MNIST and F-MNIST. The attack was created by improving an existing attack on GANs. The lower bound for the injection size turned out to be 10% for the improvement and 10-20% for the baseline attack. It was shown that the attack on WGAN-GP can overcome a filtering-based defence for F-MNIST. Furthermore, it was demonstrated that differentially private GANs are likely impossible to defend using current countermeasures.</p>",
        "link": "http://dx.doi.org/10.32920/25412851"
    },
    {
        "id": 1688,
        "title": "Quality assessment of residential layout designs generated by relational Generative Adversarial Networks (GANs)",
        "authors": "Keundeok Park, Semiha Ergan, Chen Feng",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.autcon.2023.105243"
    },
    {
        "id": 1689,
        "title": "Security of Generative Adversarial Networks",
        "authors": "Kyrylo Rudavskyy",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>The overarching goal of this work is to explore the security landscape of Generative Adversarial Networks (GANs). In recent years, their adoption started to gain traction, and they are now used in many critical domains. Security is paramount in many of these domains. Since GANs are a system of two or more neural networks, security weaknesses in one of its components can be exploited against the system. This is the attack vector considered in this work. Specifically, this research evaluated the threat potential of an adversarial attack against the discriminator part of the system. Such an attack aims to distort the output by injecting maliciously modified input during training. The attack was empirically evaluated against four types of GANs, injections of 10% and 20% malicious data, and two datasets. The targets were CGAN, ACGAN, WGAN, and WGAN-GP. The datasets were MNIST and F-MNIST. The attack was created by improving an existing attack on GANs. The lower bound for the injection size turned out to be 10% for the improvement and 10-20% for the baseline attack. It was shown that the attack on WGAN-GP can overcome a filtering-based defence for F-MNIST. Furthermore, it was demonstrated that differentially private GANs are likely impossible to defend using current countermeasures.</p>",
        "link": "http://dx.doi.org/10.32920/25412851.v1"
    },
    {
        "id": 1690,
        "title": "Generative adversarial network for video anomaly detection",
        "authors": "Thittaporn Ganokratanaa, Supavadee Aramvith",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-823519-5.00011-7"
    },
    {
        "id": 1691,
        "title": "Generative Adversarial Networks and Its Use Cases",
        "authors": "Chaitrali Sorde, Anuja Jadhav, Swati Jaiswal, Hirkani Padwad, Roshani Raut",
        "published": "2023-3-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003203964-1"
    },
    {
        "id": 1692,
        "title": "Applications of Generative Adversarial Networks (GANs): An Updated Review",
        "authors": "Hamed Alqahtani, Manolya Kavakli-Thorne, Gulshan Kumar",
        "published": "2021-3",
        "citations": 144,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11831-019-09388-y"
    },
    {
        "id": 1693,
        "title": "Emotion Detection Using Generative Adversarial Network",
        "authors": "Sima Das, Ahona Ghosh",
        "published": "2023-3-8",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003203964-11"
    },
    {
        "id": 1694,
        "title": "Brief History of Generative Adversarial Networks",
        "authors": "Parth Sharma",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31224/2637"
    },
    {
        "id": 1695,
        "title": "Enhancing the resolution of Brain MRI images using Generative Adversarial Networks (GANs)",
        "authors": "B. Ankitha, Ch. Srikanth, D. Venkatesh, D. Badrinath, G. Aditya, S. Akila Agnes",
        "published": "2023-4-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cises58720.2023.10183400"
    },
    {
        "id": 1696,
        "title": "Generative Adversarial Networks (GANs) Video Framework: A Systematic Literature Review",
        "authors": "Muhammad Hamza, Sibghat Ullah Bazai, Muhammad Imran Ghafoor, Shafi Ullah, Saira Akram, Muhammad Shahzeb Khan",
        "published": "2023-3-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icepecc57281.2023.10209475"
    },
    {
        "id": 1697,
        "title": "Generative Adversarial Networks in Practice",
        "authors": "Mehdi Ghayoumi",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003281344"
    },
    {
        "id": 1698,
        "title": "Generative Adversarial Networks (GANs) Based Synthetic Sampling for Predictive Modeling",
        "authors": "Stephen J. Barigye, José M. García de la Vega, Yunierkis Perez‐Castillo",
        "published": "2020-10",
        "citations": 8,
        "abstract": "AbstractIn the present report we evaluate the possible utility of the Generative Adversarial Networks (GANs) in mapping the chemical structural space for molecular property profiles, with the goal of subsequently yielding synthetic (artificial) samples for ligand‐based molecular modeling. Two case studies are considered: BACE‐1 (β‐Secretase 1) and DENV (Dengue Virus) inhibitory activities, with the former focused on data populating and the latter on data balancing tasks. We train GANs using subsamples extracted from datasets for each bioactivity endpoint, and apply the trained networks in generating synthetic examples from the respective bioactivity chemical spaces. Original and synthetic samples are pooled together and employed to build BACE‐1 and DENV inhibitory activity classifiers and their performance evaluated over tenfold external validation sets. In both case studies, the obtained classifiers demonstrate satisfactory predictivity with the former yielding accuracy (ACC) and Mathew's correlation coefficient (MCC) values of 0.80 and 0.59, while the latter produces balanced accuracy(BACC) and MCC values of 0.81 and 0.70, respectively. Moreover, the statistics of these classifiers are compared with those of other models in the literature demonstrating comparable to better performance. These results suggest that GANs may be useful in mapping the chemical space for molecular property profiles of interest, and thus allow for the extraction of synthetic examples for computational modeling.",
        "link": "http://dx.doi.org/10.1002/minf.202000086"
    },
    {
        "id": 1699,
        "title": "Generative adversarial networks (GANs) and object tracking (OT) for vehicle accident detection",
        "authors": "Taraka Rama Krishna Kanth Kannuri, Kirsnaragavan Arudpiragasam, Klaus Schwarz, Michael Hartmann, Reiner Creutzburg",
        "published": "2023-1-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2352/ei.2023.35.3.mobmu-364"
    },
    {
        "id": 1700,
        "title": "AI-Driven Drug Discovery: Unravelling the Potential of Generative Adversarial Networks (GANs) in Pharmaceutical Research",
        "authors": "Srinivasa Rao Burri, Mamadou Yero Diallo, Lakshay Sharma, Vishal Dutt",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ictacs59847.2023.10390116"
    }
]