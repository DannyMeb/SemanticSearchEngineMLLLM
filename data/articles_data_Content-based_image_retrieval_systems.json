[
    {
        "id": 29505,
        "title": "Content Based Image Retrieval Using Depth Maps for Colonoscopy Images",
        "authors": "Md Rahman, JungHwan Oh, Wallapak Tavanapong, Piet C. de Groen",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011749100003414"
    },
    {
        "id": 29506,
        "title": "Class Anchor Margin Loss for Content-Based Image Retrieval",
        "authors": "Alexandru Ghita, Radu Ionescu",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012400500003636"
    },
    {
        "id": 29507,
        "title": "Deep Learning-Based Image Retrieval: Addressing the Semantic Gap for Accurate Content-Based Image Retrieval",
        "authors": "Aditya Soni,  Anju, Amit Kumar",
        "published": "2023-8-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccpct58313.2023.10245342"
    },
    {
        "id": 29508,
        "title": "Progressive detail-content-based similarity retrieval over large lung CT image database based on WSLN model",
        "authors": "Yi Zhuang, Nan Jiang",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.120209"
    },
    {
        "id": 29509,
        "title": "A Secure Search For Outsourced Image Collection Based Content-Based Image Retrieval",
        "authors": "Israa Kadhem Abady Hamady",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.54633/2333-022-047-023"
    },
    {
        "id": 29510,
        "title": "Unsupervised Content Based Image Retrieval Using Pre-Trained CNN and PCNN Features Extractors",
        "authors": "",
        "published": "2023-2-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.22266/ijies2023.0228.50"
    },
    {
        "id": 29511,
        "title": "Deep Representation-Based Fuzzy Graph Model for Content-Based Image Retrieval",
        "authors": "Jiao Liu, Mingbo Zhao, Choujun Zhan",
        "published": "2024-3-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s40815-024-01682-7"
    },
    {
        "id": 29512,
        "title": "An Effective Deep Learning Model for Content-Based Gastric Image Retrieval",
        "authors": "Mona Singh, Manoj Kumar Singh",
        "published": "2023-3-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iscon57294.2023.10112189"
    },
    {
        "id": 29513,
        "title": "A Study on Content based Image Retrieval Using Knowledge Extraction Technique",
        "authors": "",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/jier.v4i1.670"
    },
    {
        "id": 29514,
        "title": "A Model for Content-Based Image Retrieval Using Machine Learning",
        "authors": "Yash Mahajan, Priya Batta, Muskan Sharma, Devansh Saxena",
        "published": "2023-9-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ccpis59145.2023.10291361"
    },
    {
        "id": 29515,
        "title": "Simulation of content based on image retrieval for financial institutions",
        "authors": "Amogh Shukla, Nitin Lodha, V. Vijayarajan, Surya Prasath",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0180219"
    },
    {
        "id": 29516,
        "title": "Deep learning for content-based image retrieval in FHE algorithms",
        "authors": "Sura Mahmood Abdullah, Mustafa Musa Jaber",
        "published": "2023-2-15",
        "citations": 0,
        "abstract": "AbstractContent-based image retrieval (CBIR) is a technique used to retrieve image from an image database. However, the CBIR process suffers from less accuracy to retrieve many images from an extensive image database and prove the privacy of images. The aim of this article is to address the issues of accuracy utilizing deep learning techniques such as the CNN method. Also, it provides the necessary privacy for images using fully homomorphic encryption methods by Cheon–Kim–Kim–Song (CKKS). The system has been proposed, namely RCNN_CKKS, which includes two parts. The first part (offline processing) extracts automated high-level features based on a flatting layer in a convolutional neural network (CNN) and then stores these features in a new dataset. In the second part (online processing), the client sends the encrypted image to the server, which depends on the CNN model trained to extract features of the sent image. Next, the extracted features are compared with the stored features using a Hamming distance method to retrieve all similar images. Finally, the server encrypts all retrieved images and sends them to the client. Deep-learning results on plain images were 97.87% for classification and 98.94% for retriever images. At the same time, the NIST test was used to check the security of CKKS when applied to Canadian Institute for Advanced Research (CIFAR-10) dataset. Through these results, researchers conclude that deep learning is an effective method for image retrieval and that a CKKS method is appropriate for image privacy protection.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1515/jisys-2022-0222"
    },
    {
        "id": 29517,
        "title": "Content Based Image Retrieval on Satellite Imagery",
        "authors": "Zeynep GÖKCE",
        "published": "2023-7-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/siu59756.2023.10223878"
    },
    {
        "id": 29518,
        "title": "Energetic Content based Image Retrieval Scheme using Improved Deep Learning Strategy with Image Analysis Technique",
        "authors": "S. Karkuzhali, P. Malathi, A Thenmozhi, Velu Aiyyasamy, Keerthika A, G.S. Uthayakumar",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsss58085.2023.10407057"
    },
    {
        "id": 29519,
        "title": "Secure Content-Based Image Retrieval with Image Ambiguation",
        "authors": "Shreesh Shankar Bhat, Padmashree Desai, C Sujata",
        "published": "2023-4-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/i2ct57861.2023.10126466"
    },
    {
        "id": 29520,
        "title": "A novel hash based feature descriptors for content based image retrieval in large database",
        "authors": "K. Lalitha, S. Murugavalli, A. Ameelia Roseline",
        "published": "2023-12-2",
        "citations": 0,
        "abstract": "For retrieving the relevant images from the internet, CBIRs (content based image retrievals) techniques are most globally utilized. However, the traditional image retrieval techniques are unable to represent the image features semantically. The CNNs (convolutional neural networks) and DL has made the retrieval task simpler. But, it is not adequate to consider only the finalized aspect vectors from the completely linked layers to fill the semantic gap. In order to alleviate this problem, a novel Hash Based Feature Descriptors (HBFD) method is proposed. In this method, the most significant feature vectors from each block are considered. To reduce the number of descriptors, pyramid pooling is used. To improve the performance in huge databases, the hash code like function is introduced in each block to represent the descriptors. The proposed method has been evaluated in Oxford 5k, Paris 6k, and UKBench datasets with the accuracy level of 80.6%, 83.9% and 92.14% respectively and demonstrated better recall value than the existing methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/jifs-233891"
    },
    {
        "id": 29521,
        "title": "Multimedia information retrieval using content-based image retrieval and context link for Chinese cultural artifacts",
        "authors": "Chung-Ming Lo",
        "published": "2024-1-24",
        "citations": 1,
        "abstract": "PurposeAn increasing number of images are generated daily, and images are gradually becoming a search target. Content-based image retrieval (CBIR) is helpful for users to express their requirements using an image query. Nevertheless, determining whether the retrieval system can provide convenient operation and relevant retrieval results is challenging. A CBIR system based on deep learning features was proposed in this study to effectively search and navigate images in digital articles.Design/methodology/approachConvolutional neural networks (CNNs) were used as the feature extractors in the author's experiments. Using pretrained parameters, the training time and retrieval time were reduced. Different CNN features were extracted from the constructed image databases consisting of images taken from the National Palace Museum Journals Archive and were compared in the CBIR system.FindingsDenseNet201 achieved the best performance, with a top-10 mAP of 89% and a query time of 0.14 s.Practical implicationsThe CBIR homepage displayed image categories showing the content of the database and provided the default query images. After retrieval, the result showed the metadata of the retrieved images and links back to the original pages.Originality/valueWith the interface and retrieval demonstration, a novel image-based reading mode can be established via the CBIR and links to the original images and contextual descriptions.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1108/lht-10-2022-0500"
    },
    {
        "id": 29522,
        "title": "Content-based image retrieval",
        "authors": "",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-17074-2"
    },
    {
        "id": 29523,
        "title": "Class-Specific Variational Auto-Encoder for Content-Based Image Retrieval",
        "authors": "Mehdi Rafiei, Alexandros Iosifidis",
        "published": "2023-6-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191068"
    },
    {
        "id": 29524,
        "title": "Content-based image retrieval via transfer learning",
        "authors": "Iqra Toheed Chughtai, Asma Naseer, Maria Tamoor, Saara Asif, Mamoona Jabbar, Rabia Shahid",
        "published": "2023-5-4",
        "citations": 0,
        "abstract": "In the past few years, due to the increased usage of internet, smartphones, sensors and digital cameras, more than a million images are generated and uploaded daily on social media platforms. The massive generation of such multimedia contents has resulted in an exponential growth in the stored and shared data. Certain ever-growing image repositories, consisting of medical images, satellites images, surveillance footages, military reconnaissance, fingerprints and scientific data etc., has increased the motivation for developing robust and efficient search methods for image retrieval as per user requirements. Hence, it is need of the hour to search and retrieve relevant images efficiently and with good accuracy. The current research focuses on Content-based Image Retrieval (CBIR) and explores well-known transfer learning-based classifiers such as VGG16, VGG19, EfficientNetB0, ResNet50 and their variants. These deep transfer leaners are trained on three benchmark image datasets i.e., CIFAR-10, CIFAR-100 and CINIC-10 containing 10, 100, and 10 classes respectively. In total 16 customized models are evaluated on these benchmark datasets and 96% accuracy is achieved for CIFAR-10 while 83% accuracy is achieved for CIFAR-100.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/jifs-223449"
    },
    {
        "id": 29525,
        "title": "Efficient content-based image retrieval using integrated dual deep convolutional neural network",
        "authors": "Feroza D. Mirajkar, Ruksar Fatima, Shaik A. Qadeer",
        "published": "2023-7-1",
        "citations": 0,
        "abstract": "<p>Content-based image retrieval (CBIR) uses the content features for retrieving and searching the images in a given large database. Earlier, different hand feature descriptor designs are researched based on cues that are visual such as shape, colour, and texture used to represent these images. Although, deep learning technologies have widely been applied as an alternative to designing engineering that is dominant for over a decade. The features are automatically learnt through the data. This research work proposes integrated dual deep convolutional neural network (IDD-CNN), IDD-CNN comprises two distinctive CNN, first CNN exploits the features and further custom CNN is designed for exploiting the custom features. Moreover, a novel directed graph is designed that comprises the two blocks i.e. learning block and memory block which helps in finding the similarity among images; since this research considers the large dataset, an optimal strategy is introduced for compact features. Moreover, IDD-CNN is evaluated considering the two distinctive benchmark datasets the oxford dataset considering mean average precision (mAP) metrics and comparative analysis shows IDD-CNN outperforms the other existing model.</p>",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijres.v12.i2.pp297-304"
    },
    {
        "id": 29526,
        "title": "Co-attention enabled content-based image retrieval",
        "authors": "Zechao Hu, Adrian G. Bors",
        "published": "2023-7",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.04.009"
    },
    {
        "id": 29527,
        "title": "Deep Learning Model for Retrieving Color Logo Images in Content Based Image Retrieval",
        "authors": "Latika Pinjarkar, Jaspal Bagga, Poorva Agrawal, Gagandeep Kaur, Vedant Pinjarkar, Rutuja Rajendra",
        "published": "2024-3-31",
        "citations": 0,
        "abstract": "Content-Based Image retrieval (CBIR) has gained a magnificent deal of consideration because of the digital image data's epidemic growth. The advancement of deep learning has enabled Convolutional Neural Networks to become an influential technique for extraction of discriminative image features. In recent years, convolutional neural networks (CNNs) have proven extremely effective at extracting unique information from images. In contrast to text-based image retrieval, CBIR gathers comparable images based primarily on their visual content. The use of deep learning, especially CNNs, for feature extraction and image processing has been shown to perform better than other techniques. In the proposed study, we investigate CNNs for CBIR focusing on how well they extract discriminative visual features and facilitate accurate image retrieval.  Also Principal Component Analysis and Linear Discriminant Analysis are combined for optimization of features resulting in boosting the retrieval results.  Using hierarchical representations learned by CNNs, we aim to improve retrieval accuracy and efficiency. In comparison with conventional retrieval techniques, our proposed CBIR system shows superior performance on a benchmark dataset.",
        "keywords": "",
        "link": "http://dx.doi.org/10.52783/jes.1773"
    },
    {
        "id": 29528,
        "title": "Novel Method for Detecting Content Based Image Retrieval Using OCR Tools",
        "authors": "Mariyan Richard A, Prasad N. Hamsavath",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4461929"
    },
    {
        "id": 29529,
        "title": "Certified Defense for Content Based Image Retrieval",
        "authors": "Kazuya Kakizaki, Kazuto Fukuchi, Jun Sakuma",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00454"
    },
    {
        "id": 29530,
        "title": "Feature Vector Generation for Content Based Image Retrieval",
        "authors": "M N Nachappa, Ajay Rastogi",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaiccit60255.2023.10465890"
    },
    {
        "id": 29531,
        "title": "Enhancing Document Image Retrieval in Education: Leveraging Ensemble-Based Document Image Retrieval Systems for Improved Precision",
        "authors": "Yehia Ibrahim Alzoubi, Ahmet Ercan Topcu, Erdem Ozdemir",
        "published": "2024-1-16",
        "citations": 1,
        "abstract": "Document image retrieval (DIR) systems simplify access to digital data within printed documents by capturing images. These systems act as bridges between print and digital realms, with demand in organizations handling both formats. In education, students use DIR to access online materials, clarify topics, and find solutions in printed textbooks by photographing content with their phones. DIR excels in handling complex figures and formulas. We propose using ensembles of DIR systems instead of single-feature models to enhance DIR’s efficacy. We introduce “Vote-Based DIR” and “The Strong Decision-Based DIR”. These ensembles combine various techniques, like optical code reading, spatial analysis, and image features, improving document retrieval. Our study, using a dataset of university exam preparation materials, shows that ensemble DIR systems outperform individual ones, promising better accuracy and efficiency in digitizing printed content, which is especially beneficial in education.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app14020751"
    },
    {
        "id": 29532,
        "title": "Deep internally connected transformer hashing for image retrieval",
        "authors": "Zijian Chao, Shuli Cheng, Yongming Li",
        "published": "2023-11",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2023.110953"
    },
    {
        "id": 29533,
        "title": "Learning Local Similarity with Spatial Interrelations on Content-Based Image Retrieval",
        "authors": "Longjiao ZHAO, Yu WANG, Jien KATO, Yoshiharu ISHIKAWA",
        "published": "2023-5-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1587/transinf.2022edp7163"
    },
    {
        "id": 29534,
        "title": "Content based word image retrieval using multi-layer perception based convolutional neural networks",
        "authors": "Anandbabu Gopatoti",
        "published": "2023",
        "citations": 0,
        "abstract": "Content based image retrieval (CBIR) plays the major role in real time applications likes search engines, libraries. The conventional CBIR systems are implemented by using basic image processing and machine learning models. So, they resulted in the poor performance against various situations. Therefore, this article is focused on implementation of CBIR system using multi-layer perception based convolutional neural network (MLP-CNN). Initially, principal component analysis (PCA) applied on images to perform the dimensionality reduction operation, which also extracts the content specific features. Further, MLP-CNN model is used to train the system and generates the trained features. Finally, the testing operation is performed using MLP-CNN, which generates the output as content specific images. The simulation results shows that the proposed method resulted in superior performance as compared to state of art approaches.",
        "keywords": "",
        "link": "http://dx.doi.org/10.58599/ijsmem.2023.1101"
    },
    {
        "id": 29535,
        "title": "A Review on Content Based Image Retrieval Techniques",
        "authors": "Suresh Kumar J S, Maria Celestin Vigila S",
        "published": "2023-8-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccpct58313.2023.10245360"
    },
    {
        "id": 29536,
        "title": "Re-ranking Image Retrieval in Challenging Geographical Iconographic Heritage Collections",
        "authors": "Emile Blettery, Valérie Gouet-Brunet",
        "published": "2023-9-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3617233.3617259"
    },
    {
        "id": 29537,
        "title": "Content-based image retrieval using handcraft feature fusion in semantic pyramid",
        "authors": "Fatemeh Taheri, Kambiz Rahbar, Ziaeddin Beheshtifard",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13735-023-00292-7"
    },
    {
        "id": 29538,
        "title": "A DCT probability histogram-based ROI features for content-based natural and medical image retrieval applications",
        "authors": "Jitesh Pradhan",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.dsp.2023.104152"
    },
    {
        "id": 29539,
        "title": "A Machine Learning Model for Content-Based Image Retrieval",
        "authors": " Kunal, Baljap Singh, Er. Kanwaldeep Kaur, Chahil Choudhary",
        "published": "2023-3-3",
        "citations": 17,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/inocon57975.2023.10101215"
    },
    {
        "id": 29540,
        "title": "Content-Based remote sensing image retrieval method using adaptive tetrolet transform based GLCM features",
        "authors": "Naushad Varish, Mohammad Kamrul Hasan, Asif Khan, Abu Taha Zamani, Vadivel Ayyasamy, Shayla Islam, Rizwan Alam",
        "published": "2023-6-1",
        "citations": 3,
        "abstract": "This paper proposed a novel texture feature extraction technique for radar remote sensing image retrieval application using adaptive tetrolet transform and Gray level co-occurrence matrix. Tetrolets have provided fine texture information in the radar image. Tetrominoes have been employed on each decomposed radar image and best pattern of tetrominoes has been chosen which represents the better radar image geometry at each decomposition level. All three high pass components of the decomposed radar image at each level and low pass component at the last level are considered as input values for Gray level co-occurrence matrix (GLCM), where GLCM provides the spatial relationship among the pixel values of decomposed components in different directions at certain distances. The GLCMs of decomposed components are computed in (1). (0, π/2, π, 3π/2), (2). (π/4, 3π/4, 5π/4, 7π/4) (3). (0, π/4, π/2, 3π/4, π, 3π/2, 5π/4, 7π/4) directions individually and subsequently a texture feature descriptor is constructed by computing statistical parameters from the corresponding GLCMs. The retrieval performance is validated on two standard radar remote sensing image databases: 20-class satellite remote sensing dataset and 21-class land-cover dataset. The average metrices i.e., precision, recall and F-score are 61.43%, 12.29% and 20.47% for 20-class satellite remote sensing dataset while 21-class land-cover dataset have achieved 67.75%, 9.03% and 15.94% average metrices. The retrieved results show the better accuracy as compared to the other related state of arts radar remote sensing image retrieval methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/jifs-224083"
    },
    {
        "id": 29541,
        "title": "Innovative local texture descriptor in joint of human-based color features for content-based image retrieval",
        "authors": "Morteza Karimian Kelishadrokhi, Mohammad Ghattaei, Shervan Fekri-Ershad",
        "published": "2023-11",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11760-023-02631-x"
    },
    {
        "id": 29542,
        "title": "A Content Based Image Retrieval System for Biodiversity System",
        "authors": "Jyoti Madake, Rohit Agrawal, Vineet Pawar, Shripad Bhatlawande",
        "published": "2023-10-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/gcat59970.2023.10353428"
    },
    {
        "id": 29543,
        "title": "Privacy preserving content based image retrieval",
        "authors": "Maemoona Kayani, M Mohsin Riaz, Abdul Ghafoor, Fawad Khan",
        "published": "2023-10-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-17168-x"
    },
    {
        "id": 29544,
        "title": "Enhancing Content-Based Histopathology Image Retrieval Using QR Code Representation",
        "authors": "Hamidreza Rouzegar, Shahryar Rahnamayan, Azam Asilian Bidgoli, Masoud Makrehchi",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ssci52147.2023.10371928"
    },
    {
        "id": 29545,
        "title": "Content-based medical image retrieval with opponent class adaptive margin loss",
        "authors": "Şaban Öztürk, Emin Çelik, Tolga Çukur",
        "published": "2023-8",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ins.2023.118938"
    },
    {
        "id": 29546,
        "title": "Feature Extraction Method using HoG with LTP for Content-Based Medical Image Retrieval",
        "authors": "NV Shamna, B. Aziz Musthafa",
        "published": "2023-3-28",
        "citations": 0,
        "abstract": "An accurate diagnosis is significant for the treatment of any disease in its early stage. Content-Based Medical Image Retrieval (CBMIR) is used to find similar medical images in a huge database to help radiologists in diagnosis. The main difficulty in CBMIR is semantic gaps between the lower-level visual details, captured by computer-aided tools and higher-level semantic details captured by humans. Many existing methods such as Manhattan Distance, Triplet Deep Hashing, and Transfer Learning techniques for CBMIR were developed but showed lower efficiency and the computational cost was high. To solve such issues, a new feature extraction approach is proposed using Histogram of Gradient (HoG) with Local Ternary Pattern (LTP) to automatically retrieve medical images from the Contrast-Enhanced Magnetic Resonance Imaging (CE-MRI) database. Adam optimization algorithm is utilized to select features and the Euclidean measure calculates the similarity for query images. From the experimental analysis, it is clearly showing that the proposed HoG-LTP method achieves higher accuracy of 98.8%, a sensitivity of 98.5%, and a specificity of 99.416%, which is better when compared to the existing Random Forest (RF) method which displayed an accuracy, sensitivity, and specificity of 81.1%, 81.7% and 90.5% respectively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.32985/ijeces.14.3.4"
    },
    {
        "id": 29547,
        "title": "Using fuzzy similarity measure in content-based video retrieval based on image query",
        "authors": "Kambiz Rahbar, Fatemeh Taheri",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijcvr.2024.10062185"
    },
    {
        "id": 29548,
        "title": "Research and Application of Content-based Image Hash Retrieval Algorithm",
        "authors": "Xinqun Luo, Xingyu Tan",
        "published": "2023-5-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sera57763.2023.10197838"
    },
    {
        "id": 29549,
        "title": "Fusion of CNN-QCSO for Content Based Image Retrieval",
        "authors": "Sarva Naveen Kumar, Ch. Sumanth Kumar",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.12720/jait.14.4.668-673"
    },
    {
        "id": 29550,
        "title": "Fuzzy-Based Solar Magnetogram Image Retrieval",
        "authors": "Rafal Grycuk, Marcin Korytkowski, Rafal Scherer",
        "published": "2023-8-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/fuzz52849.2023.10309721"
    },
    {
        "id": 29551,
        "title": "A Hybrid Approach of Semantic Weight Based Re-Propagation For Convolutional Neural Networks in Content Based Medical Image Retrieval",
        "authors": "Gourav Sood",
        "published": "2023-4-29",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icdcece57866.2023.10151427"
    },
    {
        "id": 29552,
        "title": "Fuzzy adaptive learning control network (FALCN) for image clustering and content-based image retrieval on noisy dataset",
        "authors": "S. Neelakandan, Sathishkumar Veerappampalayam Easwaramoorthy, A. Chinnasamy, Jaehyuk Cho",
        "published": "2023",
        "citations": 0,
        "abstract": "<abstract>\n\t\t\t<p>It has been demonstrated that fuzzy systems are beneficial for classification and regression. However, they have been mainly utilized in controlled settings. An image clustering technique essential for content-based picture retrieval in big image datasets is developed using the contents of color, texture and shape. Currently, it is challenging to label a huge number of photos. The issue of unlabeled data has been addressed. Unsupervised learning is used. K-means is the most often used unsupervised learning algorithm. In comparison to fuzzy c-means clustering, K-means clustering has lower-dimensional space resilience and initialization resistance. The dominating triple HSV space was shown to be a perceptual color space made of three modules, S (saturation), H (hue) and V (value), referring to color qualities that are significantly connected to how human eyes perceive colors. A deep learning technique for segmentation (RBNN) is built on the Gaussian function, fuzzy adaptive learning control network (FALCN), clustering and the radial basis neural network. The segmented image and critical information are fed into a radial basis neural network classifier. The suggested fuzzy adaptive learning control network (FALCN) fuzzy system, also known as the unsupervised fuzzy neural network, is very good at clustering images and can extract image properties. When a conventional fuzzy network system receives a noisy input, the number of output neurons grows needlessly. Finally, random convolutional weights extract features from data without labels. Furthermore, the state-of-the-art uniting the proposed FALCN with the RBNN classifier, the proposed descriptor also achieves comparable performance, such as improved accuracy is 96.547 and reduced mean squared error of 36.028 values for the JAFE, ORL, and UMIT datasets.</p>\n\t\t</abstract>",
        "keywords": "",
        "link": "http://dx.doi.org/10.3934/math.2023931"
    },
    {
        "id": 29553,
        "title": "Content-based face image retrieval using quaternion based local diagonal extreme value pattern",
        "authors": "Komal Nain Sukhia, M. Mohsin Riaz, Benish Amin, Abdul Ghafoor",
        "published": "2024-1-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-15234-y"
    },
    {
        "id": 29554,
        "title": "A Content-Based Medical Image Retrieval Method Using Relative Difference-Based Similarity Measure",
        "authors": "Ali Ahmed, Alaa Omran Almagrabi, Omar M. Barukab",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/iasc.2023.039847"
    },
    {
        "id": 29555,
        "title": "Shuffled-Xception-DarkNet-53: A content-based image retrieval model based on deep learning algorithm",
        "authors": "Debanjan Pathak, U.S.N. Raju",
        "published": "2023-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compeleceng.2023.108647"
    },
    {
        "id": 29556,
        "title": "CBIR-ANR: A content-based image retrieval with accuracy noise reduction",
        "authors": "Gabriel S. Vieira, Afonso U. Fonseca, Fabrizzio Soares",
        "published": "2023-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.simpa.2023.100486"
    },
    {
        "id": 29557,
        "title": "Position Mapping using Content Based Image Retrieval and Annoy",
        "authors": "Riya Dalal, Simrat Kaur Randhawa, Shrey Modi, Rahul Vishwakarma",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mosicom59118.2023.10458815"
    },
    {
        "id": 29558,
        "title": "Stacked Siamese Neural Network (SSiNN) on Neural Codes for Content-Based Image Retrieval",
        "authors": "Gopu V. R. Muni Kumar, D. Madhavi",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3298216"
    },
    {
        "id": 29559,
        "title": "Special issue on content-based image retrieval",
        "authors": "Gianluigi Ciocca, Raimondo Schettini, Simone Santini, Marco Bertini",
        "published": "2023-11-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-17646-2"
    },
    {
        "id": 29560,
        "title": "Experimental Comparison of Autoencoder Variants in Content-Based Image Retrieval",
        "authors": "Juhi Janjua, Archana Patankar, Mohit Shetty, Sainath Poojary",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10308062"
    },
    {
        "id": 29561,
        "title": "Content-based image retrieval using multi-scale averaging local binary patterns",
        "authors": "Sadegh Fadaei, Abbas Dehghani, Bahman Ravaei",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.dsp.2024.104391"
    },
    {
        "id": 29562,
        "title": "Gaze-Dependent Image Re-Ranking Technique for Enhancing Content-Based Image Retrieval",
        "authors": "Yuhu Feng, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama",
        "published": "2023-5-11",
        "citations": 1,
        "abstract": "Content-based image retrieval (CBIR) aims to find desired images similar to the image input by the user, and it is extensively used in the real world. Conventional CBIR methods do not consider user preferences since they only determine retrieval results by referring to the degree of resemblance or likeness between the query and potential candidate images. Because of the above reason, a “semantic gap” appears, as the model may not accurately understand the potential intention that a user has included in the query image. In this article, we propose a re-ranking method for CBIR that considers a user’s gaze trace as interactive information to help the model predict the user’s inherent attention. The proposed method uses the user’s gaze trace corresponding to the image obtained from the initial retrieval as the user’s preference information. We introduce image captioning to effectively express the relationship between images and gaze information by generating image captions based on the gaze trace. As a result, we can transform the coordinate data into a text format and explicitly express the semantic information of the images. Finally, image retrieval is performed again using the generated gaze-dependent image captions to obtain images that align more accurately with the user’s preferences or interests. The experimental results on an open image dataset with corresponding gaze traces and human-generated descriptions demonstrate the efficacy or efficiency of the proposed method. Our method considers visual information as the user’s feedback to achieve user-oriented image retrieval.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app13105948"
    },
    {
        "id": 29563,
        "title": "Image Retrieval based on Deep Learning",
        "authors": "Yuru Gao",
        "published": "2023-11-5",
        "citations": 0,
        "abstract": "With the rapid growth of image data, how to efficiently and accurately extract useful features from massive image data and perform fast image retrieval has become an important research direction. This study focuses on the design and training of deep learning-based image feature extraction networks to improve the robustness and generalization of image features by optimizing the network structure and loss function. In order to evaluate the performance of the system, this study also designs appropriate evaluation indicators and conducts corresponding experiments. Through experimental verification, the results show that these methods can effectively improve the performance of image feature extraction and image retrieval, and have broad potential in practical applications.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/fcis.v5i3.14054"
    },
    {
        "id": 29564,
        "title": "Content-Based Music-Image Retrieval Using Self- and Cross-Modal Feature Embedding Memory",
        "authors": "Takayuki Nakatsuka, Masahiro Hamasaki, Masataka Goto",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00221"
    },
    {
        "id": 29565,
        "title": "Implementation of Content-Based Image Retrieval Using Artificial Neural Networks",
        "authors": "Sarath Yenigalla, Karumuri Srinivasa Rao, Phalguni Ngangbam",
        "published": "2023-3-13",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/hmam2-14161"
    },
    {
        "id": 29566,
        "title": "Content-Based Image Retrieval for Remote Sensing Images using Hybrid Firefly and Grey Wolf Optimization Algorithm",
        "authors": "Nijaguna G S",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/easct59475.2023.10392764"
    },
    {
        "id": 29567,
        "title": "Secure Content Based Image Retrieval Scheme Based on Deep Hashing and Searchable Encryption",
        "authors": "Zhen Wang, Qiu-yu Zhang, Ling-tao Meng, Yi-lin Liu",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/cmc.2023.037134"
    },
    {
        "id": 29568,
        "title": "Medical image retrieval via nearest neighbor search on pre-trained image features",
        "authors": "Deepak Gupta, Russell Loane, Soumya Gayen, Dina Demner-Fushman",
        "published": "2023-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2023.110907"
    },
    {
        "id": 29569,
        "title": "An Efficient CNN-Based Method for Content-Based Image Retrieval",
        "authors": " A Mukul Kumar Patro,  Dr. J Bhuvana",
        "published": "2023-3-15",
        "citations": 0,
        "abstract": "Image recovery has been one of the most fascinating and active study fields in the field of computer vision. The use of content-based image retrieval (CBIR) systems allows for the automatic indexing, searching, retrieval, and exploration of picture datasets. Important characteristics in content-based picture retrieval systems include colour - texture elements. As a result, content-based image retrieval (CBIR) is attractive as a source of precise and speedy retrieval in the modern era. The (CBIR) system uses a feature-based approach to retrieve images from image databases. Low grade characteristics and high grade characteristics are the two categories that image features fall under. Low level aspects of an image include colour, texture, and shape, whereas high level features define the image's semantic content. CBIR is a rapidly developing technology, and as datasets grow as a result of recent advancements in multimedia, it is crucial to enhance this technology to suit user needs.",
        "keywords": "",
        "link": "http://dx.doi.org/10.32628/cseit239024"
    },
    {
        "id": 29570,
        "title": "Isometric Feature Embedding for Content-Based Image Retrieval",
        "authors": "Hayato Muraki, Kei Nishimaki, Shuya Tobari, Kenichi Oishi, Hitoshi Iyatomi",
        "published": "2024-3-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ciss59072.2024.10480174"
    },
    {
        "id": 29571,
        "title": "EDBC Algorithm used for Content-Based Image Retrieval",
        "authors": " Vishma Kumar Karna,  Shatendra Dubey",
        "published": "2023-5-7",
        "citations": 0,
        "abstract": "The tremendous increase and om- nipresent accessibility of graphic documents on the network led to the high interest in research on content-based image retrieval (CBIR). This has ce- mented the approach for a massive sum of innovative procedures and schemes, and growing curiosity in allied fields to upkeep such projects. Existing associ- ated theories include efficient Content-based Image Retrieval (CBIR) frame by enacting the content- based image, K-means and hybrid clustering is func- tional over combined lineament vector of information images, texture features. In similar cases it is tight in expressing the user’s semantic Intention knowledge to permit information distribution and reuse, models ought to be managed within repositories, where they might be retrieved upon users’ queries. There is still a lack of adequate tools for incisive/handling visual content. In this paper, a novel algorithm Efficient Density-based Clustering Algorithm (EDBC) is sug- gested for content-based image retrieval technique that will enhance scalability and lower maintenance costs significantly, enhance the efficacy of software development.",
        "keywords": "",
        "link": "http://dx.doi.org/10.32628/cseit2390291"
    },
    {
        "id": 29572,
        "title": "Ensemble learning framework for image retrieval via deep hash ranking",
        "authors": "Donggen Li, Dawei Dai, Jiancu Chen, Shuyin Xia, Guoyin Wang",
        "published": "2023-1",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2022.110128"
    },
    {
        "id": 29573,
        "title": "Deep hashing image retrieval based on hybrid neural network and optimized metric learning",
        "authors": "Xingming Xiao, Shu Cao, Liejun Wang, Shuli Cheng, Erdong Yuan",
        "published": "2024-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2023.111336"
    },
    {
        "id": 29574,
        "title": "A framework for privacy preserving medical content based image retrieval",
        "authors": "Abdelhalim Kamrani, Khalid Zenkouar, Said Najah",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0149473"
    },
    {
        "id": 29575,
        "title": "MLMQ-IR: Multi-label multi-query image retrieval based on the variance of Hamming distance",
        "authors": "Enver Akbacak, Abdurrahim Toktas, Uğur Erkan, Suo Gao",
        "published": "2024-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2023.111193"
    },
    {
        "id": 29576,
        "title": "RbQE: An Efficient Method for Content-Based Medical Image Retrieval Based on Query Expansion",
        "authors": "Metwally Rashad, Ibrahem Afifi, Mohammed Abdelfatah",
        "published": "2023-1-26",
        "citations": 3,
        "abstract": "AbstractSystems for retrieving and managing content-based medical images are becoming more important, especially as medical imaging technology advances and the medical image database grows. In addition, these systems can also use medical images to better grasp and gain a deeper understanding of the causes and treatments of different diseases, not just for diagnostic purposes. For achieving all these purposes, there is a critical need for an efficient and accurate content-based medical image retrieval (CBMIR) method. This paper proposes an efficient method (RbQE) for the retrieval of computed tomography (CT) and magnetic resonance (MR) images. RbQE is based on expanding the features of querying and exploiting the pre-trained learning models AlexNet and VGG-19 to extract compact, deep, and high-level features from medical images. There are two searching procedures in RbQE: a rapid search and a final search. In the rapid search, the original query is expanded by retrieving the top-ranked images from each class and is used to reformulate the query by calculating the mean values for deep features of the top-ranked images, resulting in a new query for each class. In the final search, the new query that is most similar to the original query will be used for retrieval from the database. The performance of the proposed method has been compared to state-of-the-art methods on four publicly available standard databases, namely, TCIA-CT, EXACT09-CT, NEMA-CT, and OASIS-MRI. Experimental results show that the proposed method exceeds the compared methods by 0.84%, 4.86%, 1.24%, and 14.34% in average retrieval precision (ARP) for the TCIA-CT, EXACT09-CT, NEMA-CT, and OASIS-MRI databases, respectively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10278-022-00769-7"
    },
    {
        "id": 29577,
        "title": "Towards Content-Based Image Retrieval for Encrypted Images over Cloud Computing: Review of Recent Trends",
        "authors": "Rowayda A. Elsayd, Metwally Rashad, Noha E. El-Attar, Ahmed Elsawy",
        "published": "2023-7-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/itc-egypt58155.2023.10206394"
    },
    {
        "id": 29578,
        "title": "Content-based image retrieval through fusion of deep features extracted from segmented neutrosophic using depth map",
        "authors": "Fatemeh Taheri, Kambiz Rahbar, Ziaeddin Beheshtifard",
        "published": "2024-4-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00371-024-03335-0"
    },
    {
        "id": 29579,
        "title": "Content-based image retrieval based on corel dataset using deep learning",
        "authors": "Rasha Qassim Hassan, Zainab N. Sultani, Ban N. Dhannoon",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "A popular technique for retrieving images from huge and unlabeled image databases are content-based-image-retrieval (CBIR). However, the traditional information retrieval techniques do not satisfy users in terms of time consumption and accuracy. Additionally, the number of images accessible to users are growing due to web development and transmission networks. As the result, huge digital image creation occurs in many places. Therefore, quick access to these huge image databases and retrieving images like a query image from these huge image collections provides significant challenges and the need for an effective technique. Feature extraction and similarity measurement are important for the performance of a CBIR technique. This work proposes a simple but efficient deep-learning framework based on convolutional-neural networks (CNN) for the feature extraction phase in CBIR. The proposed CNN aims to reduce the semantic gap between low-level and high-level features. The similarity measurements are used to compute the distance between the query and database image features. When retrieving the first 10 pictures, an experiment on the Corel-1K dataset showed that the average precision was 0.88 with Euclidean distance, which was a big step up from the state-of-the-art approaches.",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijai.v12.i4.pp1854-1863"
    },
    {
        "id": 29580,
        "title": "Research on tax knowledge automatic retrieval based on ASDPQ image retrieval",
        "authors": "C. Li",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/icp.2023.3296"
    },
    {
        "id": 29581,
        "title": "Content-based medical image retrieval using deep learning-based features and hybrid meta-heuristic optimization",
        "authors": "Rani Shetty, Vandana S. Bhat, Jagadeesh Pujari",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.bspc.2024.106069"
    },
    {
        "id": 29582,
        "title": "Designing a new deep convolutional neural network for content-based image retrieval with relevance feedback",
        "authors": "Homayoun Rastegar, Davar Giveki",
        "published": "2023-3",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compeleceng.2023.108593"
    },
    {
        "id": 29583,
        "title": "Content-Based Image Retrieval Using DNA Transcription and Translation",
        "authors": "Jitesh Pradhan, Chiranjeev Bhaya, Arup Kumar Pal, Arpit Dhuriya",
        "published": "2023-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnb.2022.3169701"
    },
    {
        "id": 29584,
        "title": "Content based image retrieval using hybrid feature extraction and HWBMMBO feature selection method",
        "authors": "K. Vijila Rani",
        "published": "2023-12",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-15716-z"
    },
    {
        "id": 29585,
        "title": "Object Recognition to Content Based Image Retrieval: A Study of the Developments and Applications of Computer Vision",
        "authors": "Udula Mangalika",
        "published": "2024-1-5",
        "citations": 0,
        "abstract": "Natural Language Processing (NLP) and Computer Vision (CV) are interconnected fields within the domain of Artificial Intelligence (AI). CV is tasked with the process of engaging with computer systems to effectively interpret and recognize visual data, while NLP is responsible for comprehending and processing the human voice. The two fields have practical applicability in various tasks such as image description generation, object recognition, and question-based answering after a visual input. Deep learning algorithms such as word input are typically employed in enhancing the performance of Content-Based Image Processing (CBIR) techniques. Generally, NLP and CV play a vital role in enhancing computer comprehension and engagements with both visual and written information. This paper seeks to review various major elements of computer vision, such as CBIR, visual effects, image documentation, video documentation, visual learning, and inquiry to explore various databases, techniques, and methods employed in this field. The authors focus on the challenges and progress in each area and offer new strategies for improving the performance of CV systems.",
        "keywords": "",
        "link": "http://dx.doi.org/10.53759/181x/jcns202404005"
    },
    {
        "id": 29586,
        "title": "CBIR-ACHS: compressed domain content-based image retrieval through auto-correloblock in HEVC standard",
        "authors": "Yaghoub Saberi, Mohammadreza Ramezanpour, Shervan Fekri-Ershad, Behrang Barekatain",
        "published": "2024-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-024-18488-2"
    },
    {
        "id": 29587,
        "title": "Retracted: Content-Based Image Retrieval Using Gamma Distribution and Mixture Model",
        "authors": "Journal of Function Spaces",
        "published": "2024-1-24",
        "citations": 0,
        "abstract": "",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2024/9819768"
    },
    {
        "id": 29588,
        "title": "A Comparative Study about Content-Based Image Retrieval using Features from Deep Convolutional Neural Networks",
        "authors": "Budi Srikrushna Pinaki, Meka Dheeraj Reddy, Srisatya Kapardi",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccsai59793.2023.10421161"
    },
    {
        "id": 29589,
        "title": "An efficient content based image retrieval and classification based on hybrid texture feature extraction",
        "authors": "P. Nirmala Devi, K. Manoj Senthil, M. Pavithra",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0178562"
    },
    {
        "id": 29590,
        "title": "An Effective Hybrid Framework Based on Combination of Color and Texture Features for Content-Based Image Retrieval",
        "authors": "Fahad A. Alghamdi",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13369-023-08087-y"
    },
    {
        "id": 29591,
        "title": "Comparison of State Vector Machine and Decision Tree - Content Based Image Retrieval Algorithms to Perceive Accuracy",
        "authors": "Gagandeep Kaur, Satish Saini",
        "published": "2023-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ihcsp56702.2023.10127132"
    },
    {
        "id": 29592,
        "title": "CONTENT-BASED IMAGE RETRIEVAL UNTUK MENGIDENTIFIKASI JENIS KAYU BERDASARKAN CITRA DIGITAL MENGGUNAKAN ALGORITMA EIGENIMAGE",
        "authors": "Wahyu Widodo, Rofiq Muhdan Siregar",
        "published": "2023-11-20",
        "citations": 0,
        "abstract": "Indonesia is a tropical country that has no less than 4,000 types of trees. Potential tree species estimated 400 botanical species (species), included in 198 genera (genus) of the 68 tribes (families). Anatomical features include composition, shape, and size of cell or tissue intruders, which can only be observed clearly by using the aid of a magnifying glass like a magnifying glass or microscope. Along with the development of computerized technology, pattern recognition has much to do with a variety of applications and algorithms. One technique to identify an image is to distinguish the texture are the basic components forming the image. This study developed a computer-based technologies to perform pattern recognition (image). The system uses image recognition wood type pore structure of the wood. The introduction of wood types to apply the concept of content-based image retrieval (CBIR) using the algorithm Eigenimage. Identification is done by pattern matching. The test results by using 129 sample, showed the percentage of the system's ability to identify the image timber correctly by 97% (sensitivity), the percentage of the system's ability to recognize the type of wood does not match the sample, 58% (specificity), positive predictive value of 90% (PPV), a negative predictive value of 83% (NPV), and accuracy rate of 89%  with an error rate of 11%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.61805/fahma.v17i1.80"
    },
    {
        "id": 29593,
        "title": "Learning image representations for content-based image retrieval of radiotherapy treatment plans",
        "authors": "Charles Huang, Varun Vasudevan, Oscar Pastor-Serrano, Md Tauhidul Islam, Yusuke Nomura, Piotr Dubrowski, Jen-Yeu Wang, Joseph B Schulz, Yong Yang, Lei Xing",
        "published": "2023-5-7",
        "citations": 1,
        "abstract": "Abstract\n\nObjective. In this work, we propose a content-based image retrieval (CBIR) method for retrieving dose distributions of previously planned patients based on anatomical similarity. Retrieved dose distributions from this method can be incorporated into automated treatment planning workflows in order to streamline the iterative planning process. As CBIR has not yet been applied to treatment planning, our work seeks to understand which current machine learning models are most viable in this context. Approach. Our proposed CBIR method trains a representation model that produces latent space embeddings of a patient’s anatomical information. The latent space embeddings of new patients are then compared against those of previous patients in a database for image retrieval of dose distributions. All source code for this project is available on github. Main results. The retrieval performance of various CBIR methods is evaluated on a dataset consisting of both publicly available image sets and clinical image sets from our institution. This study compares various encoding methods, ranging from simple autoencoders to more recent Siamese networks like SimSiam, and the best performance was observed for the multitask Siamese network. Significance. Our current results demonstrate that excellent image retrieval performance can be obtained through slight changes to previously developed Siamese networks. We hope to integrate CBIR into automated planning workflow in future works.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1361-6560/accdb0"
    },
    {
        "id": 29594,
        "title": "Two-layer content-based image retrieval technique for improving effectiveness",
        "authors": "Fawzi Abdul Azeez Salih, Alan Anwer Abdulla",
        "published": "2023-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-14678-6"
    },
    {
        "id": 29595,
        "title": "Latent Representation Generation for Efficient Content-Based Image Retrieval in Weather Satellite Images Using Self-Supervised Segmentation",
        "authors": "Abdulhakin Mohamud Ismail, Ha-Myung Park",
        "published": "2024-2-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bigcomp60711.2024.00078"
    },
    {
        "id": 29596,
        "title": "A novel image recognition using Fuzzy C-Means and content-based fabric image retrieval",
        "authors": "A. Meenakshi, A. P. Janani, S. Devi Mahalakshmi, S. Vanitha Sivagami",
        "published": "2023-7-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/13682199.2023.2183316"
    },
    {
        "id": 29597,
        "title": "Content based Image Retrieval using Fine-tuned Deep Features with Transfer Learning",
        "authors": "Meqdam A. Mohammed, Zakariya A. Oraibi, Mohammed Abdulridha Hussain",
        "published": "2023-8-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cosite60233.2023.10249430"
    },
    {
        "id": 29598,
        "title": "Exploring deep learning-based content-based video retrieval with Hierarchical Navigable Small World index and ResNet-50 features for anomaly detection",
        "authors": "Muthurasu Nallappan, Rajasekar Velswamy",
        "published": "2024-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2024.123197"
    },
    {
        "id": 29599,
        "title": "An Overview of Content-Based Image Retrieval Methods and Techniques",
        "authors": "M.H Hadid, Qasim Mohammed Hussein, Z.T. Al-Qaysi, M.A. Ahmed, Mahmood M. Salih",
        "published": "2023-7-30",
        "citations": 0,
        "abstract": "With the development of Internet technology and the popularity of digital devices, Content-Based Image Retrieval (CBIR) has been quickly developed and applied in various fields related to computer vision and artificial intelligence. Currently, it is possible to retrieve related images effectively and efficiently from a large-scale database with an input image. In the past ten years, great efforts have been made for new theories and models of CBIR, and many effective CBIR algorithms have been established. Content-based image retrieval helps to discover identical images in a big dataset that match a query image. The query image's representative feature similarities to the dataset images typically assist in ranking the images for retrieval. There are various past studies on different handicraft feature descriptors according to the visual features that describe the images: color, texture, and shape. However, deep learning has been the dominant alternative to manually planned feature engineering; it automatically takes the features from the data. The current work reviews recent advancements in content-based image retrieval. For a deeper understanding of the advancement, the explanation of current state-of-the-art approaches from various vantage points is also conducted. This review employs a taxonomy encompassing various retrieval networks, classification types, and descriptors and this study will help researchers make more progress in image retrieval",
        "keywords": "",
        "link": "http://dx.doi.org/10.52866/ijcsm.2023.02.03.006"
    },
    {
        "id": 29600,
        "title": "Content-based image retrieval using integrated dual deep  convolutional neural network",
        "authors": "Feroza D. Mirajkar, Ruksar Fatima, Shaik A. Qadeer",
        "published": "2023-7-1",
        "citations": 0,
        "abstract": "The image retrieval focuses on finding images that are similar from a dataset that is of a large scale against an image of a query. Earlier, different hand feature descriptor designs are researched based on cues that are visual such as their shape, colour, and texture. used to represent these images. Although, deep learning technologies have widely been applied as an alternative to designing engineering that is dominant for over a decade. The features are automatically learnt through the data. This research work proposes integrated dual deepconvolutional neural networks (IDD-CNN), IDD-CNN comprises two distinctive CNN, first CNN exploits the features and further custom CNN is designed for exploiting the custom features. Moreover, a novel directed graph is designed that comprises the two blocks i.e., learning block and memory block which helps in finding the similarity among images; since this research considers the large dataset, an optimal strategy is introduced for compact features. Moreover, IDD-CNN is evaluated considering the two distinctive benchmark datasets of Paris and the oxford dataset considering metrics; also, image retrieval and re-ranking is carried out against the given query. Comparative analysis of various difficulty levels against the different CNN models suggests that IDD-CNN simply outperforms the existing model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijeecs.v31.i1.pp77-87"
    },
    {
        "id": 29601,
        "title": "PCBIR-CV: A privacy-preserved content-based image retrieval using combined visual descriptors for cloud",
        "authors": "Anju J., Shreelekshmi R.",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.simpa.2023.100529"
    },
    {
        "id": 29602,
        "title": "Content-based product image retrieval using squared-hinge loss trained convolutional neural networks",
        "authors": "Arif Rahman, Edi Winarko, Khabis Mustofa",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "<p><span lang=\"EN-US\">Convolutional neural networks (CNN) have proven to be highly effective in large-scale object detection and image classification, as well as in serving as feature extractors for content-based image retrieval. While CNN models are typically trained with category label supervision and softmax loss for product image retrieval, we propose a different approach for feature extraction using the squared-hinge loss, an alternative multiclass classification loss function. First, transfer learning is performed on a pre-trained model, followed by fine-tuning the model. Then, image features are extracted based on the fine-tuned model and indexed using the nearest-neighbor indexing technique. Experiments are conducted on VGG19, InceptionV3, MobileNetV2, and ResNet18 CNN models. The model training results indicate that training the models with squared-hinge loss reduces the loss values in each epoch and reaches stability in less epoch than softmax loss. Retrieval results show that using features from squared-hinge trained models improves the retrieval accuracy by up to 3.7% compared to features from softmax-trained models. Moreover, the squared-hinge trained MobileNetV2 features outperformed others, while the ResNet18 feature gives the advantage of having the lowest dimensionality with competitive accuracy.</span></p>",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijece.v13i5.pp5804-5812"
    },
    {
        "id": 29603,
        "title": "Data Mining Techniques for Content-Based Image Retrieval",
        "authors": "Jyotsana Thakur, Rajesh Premjibhai Vansdadiya, Kapil Joshi, Devesh Pratap Singh, Guptnath Trivedi, R. Manickam",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icacite57410.2023.10182411"
    },
    {
        "id": 29604,
        "title": "Jumping particle swarm optimization algorithm framework for content-based image retrieval system",
        "authors": "Atheer Bassel, Mohammed Jameel, Mohammed Ayad Saad",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "Content-based image retrieval (CBIR) has been studied well in the last decades in numerous research fields such as medicine, journalism, and private life. Applications of CBIR have been widely employed in medical images due to their direct impact on human life. With continues growing of digital libraries, there is a need for an efficient method to retrieve images from large datasets. In this paper, a new method was developed for CBIR based on the jumping particle swarm optimization (JPSO) algorithm. The proposed algorithm represents a developed instant of particle swarm optimization (PSO). However, JPSO the approach does not consider the velocity components to guide particle movements in the problem space. Instead of relying on inertia and velocity, intermittently random jumps (moves) occur from one solution to another within the discrete search space. To test the performance of the proposed algorithm, three types of medical image databases were used in the experiment which are the endoscopy 100, dental 100, and 50 skull image databases. The results show that the proposed algorithm could achieve high accuracy in image extraction and retrieve the accurate image category compared with other research works.",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/eei.v12i6.5024"
    },
    {
        "id": 29605,
        "title": "A powerful method for interactive content-based image retrieval by variable compressed convolutional info neural networks",
        "authors": "Vishwanath S. Mahalle, Narendra M. Kandoi, Santosh B. Patil",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00371-023-03104-5"
    },
    {
        "id": 29606,
        "title": "Multimorbidity Content-Based Medical Image Retrieval and Disease Recognition Using Multi-Label Proxy Metric Learning",
        "authors": "Yunyan Xing, Benjamin J. Meyer, Mehrtash Harandi, Tom Drummond, Zongyuan Ge",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3278376"
    },
    {
        "id": 29607,
        "title": "An effective and efficient framework of content-based similarity retrieval of large CT image sequences based on WSLEN model",
        "authors": "Bo Xie, Yi Zhuang, Nan Jiang, Jingkun Liu",
        "published": "2023-9-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-16226-8"
    },
    {
        "id": 29608,
        "title": "Content-Based Image Retrieval (CBIR): Using Combined Color and Texture Features (TriCLR and HistLBP)",
        "authors": "P. John Bosco, S. Janakiraman",
        "published": "2023-9-26",
        "citations": 0,
        "abstract": " Content-Based Image Retrieval (CBIR) is a broad research field in the current digital world. This paper focuses on content-based image retrieval based on visual properties, consisting of high-level semantic information. The variation between low-level and high-level features is identified as a semantic gap. The semantic gap is the biggest problem in CBIR. The visual characteristics are extracted from low-level features such as color, texture and shape. The low-level feature increases CBIRs performance level. The paper mainly focuses on an image retrieval system called combined color (TriCLR) (RGB, YCbCr, and [Formula: see text]) with the histogram of texture features in LBP (HistLBP), which, is known as a hybrid of three colors (TriCLR) with Histogram of LBP (TriCLR and HistLBP). The study also discusses the hybrid method in light of low-level features. Finally, the hybrid approach uses the (TriCLR and HistLBP) algorithm, which provides a new solution to the CBIR system that is better than the existing methods. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1142/s0219467825500214"
    },
    {
        "id": 29609,
        "title": "Content-Based Image Retrieval Using Adaptive CIE Color Feature Fusion",
        "authors": "Charulata Palai, Pradeep Kumar Jena, Bonomali Khuntia, Tapas Kumar Mishra, Satya Ranjan Pattanaik",
        "published": "2023-2-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18280/ria.370109"
    },
    {
        "id": 29610,
        "title": "An Extended Canberra Similarity Measure Method for Content-Based Image Retrieval",
        "authors": "K R N Aswini, S. P. Prakash, Gobinath Ravindran, T Jagadesh, Ashitha V Naik",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/easct59475.2023.10392995"
    },
    {
        "id": 29611,
        "title": "Notice of Retraction: Comparison of deep learning techniques on content based image retrieval",
        "authors": "Meenakshi Garg, Manisha Malhotra, Harpal Singh",
        "published": "2023-3-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1142/s021773232393001x"
    },
    {
        "id": 29612,
        "title": "Annotation Cost Efficient Active Learning for Content Based Image Retrieval",
        "authors": "Julia Henkel, Genc Hoxha, Gencer Sumbul, Lars Möllenbrok, Begüm Demir",
        "published": "2023-7-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/igarss52108.2023.10281811"
    },
    {
        "id": 29613,
        "title": "An Effective Clustering Using Moth Flame Optimization for Content-Based Image Retrieval",
        "authors": "Srinivas Aluvala, Zainab Abed Almoussawi, Muntather Almusawi, Zamen Latef Naser, S. Meenakshi Sundaram",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmnwc60182.2023.10435658"
    },
    {
        "id": 29614,
        "title": "Triplet Label Based Image Retrieval Using Deep Learning in Large Database",
        "authors": "K. Nithya, V. Rajamani",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/csse.2023.027275"
    },
    {
        "id": 29615,
        "title": "A novel content-based image retrieval system with feature descriptor integration and accuracy noise reduction",
        "authors": "Gabriel S. Vieira, Afonso U. Fonseca, Naiane M. Sousa, Juliana P. Felix, Fabrizzio Soares",
        "published": "2023-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.120774"
    },
    {
        "id": 29616,
        "title": "Content-based Retrieval of Tiles and Ceramics Images based on Grouping of\n                        Images and Minimal Feature Extraction",
        "authors": "Simin RajaeeNejad, Farahnaz Mohanna",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.61186/jist.34084.11.43.241"
    },
    {
        "id": 29617,
        "title": "Combined query image retrieval based on hybrid coding of CNN and Mix-Transformer",
        "authors": "Zhiwei Zhang, Shuli Cheng, Liejun Wang",
        "published": "2023-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.121060"
    },
    {
        "id": 29618,
        "title": "Multiview adaptive attention pooling for image–text retrieval",
        "authors": "Yunlai Ding, Jiaao Yu, Qingxuan Lv, Haoran Zhao, Junyu Dong, Yuezun Li",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2024.111550"
    },
    {
        "id": 29619,
        "title": "Content-based image retrieval for medical diagnosis using fuzzy clustering and deep learning",
        "authors": "Dhanya K. Sudhish, Latha R. Nair, Shailesh S",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.bspc.2023.105620"
    },
    {
        "id": 29620,
        "title": "Deep transfer learning enabled DenseNet model for content based image retrieval in agricultural plant disease images",
        "authors": "M. Karthikeyan, D. Raja",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-14992-z"
    },
    {
        "id": 29621,
        "title": "A Novel Approach for Content-based Image Retrieval System using Logical AND and OR Operations",
        "authors": "Ranjana Battur, Jagadisha Narayana",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14569/ijacsa.2023.0140955"
    },
    {
        "id": 29622,
        "title": "Content-Based Image Retrieval using Encoder based RGB and Texture Feature Fusion",
        "authors": "Charulata Palai, Pradeep Kumar Jena, Satya Ranjan Pattanaik, Trilochan Panigrahi, Tapas Kumar Mishra",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14569/ijacsa.2023.0140328"
    },
    {
        "id": 29623,
        "title": "Orthogonal opponent colour local binary patterns: a new colour-texture descriptor for content based-image retrieval",
        "authors": "Salah Bougueroua, Bachir Boucheham, Rahima Boukerma",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijcvr.2024.10062221"
    },
    {
        "id": 29624,
        "title": "SSVMEF: Design of a high-efficiency content-based image retrieval model using selective sampling with variance maximization of ensemble features",
        "authors": "Milind Vijayrao Lande, Sonali Ridhorkar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0127761"
    },
    {
        "id": 29625,
        "title": "Secure Content Based Image Retrieval System Using Deep Learning",
        "authors": "Meqdam A. Mohammed, Mohammed A. Hussain, Zakariya A. Oraibi, Zaid A. Abduljabbar, Vincent O. Nyangaresi",
        "published": "2023-12-30",
        "citations": 0,
        "abstract": "This paper investigates Content-Based Image Retrieval (CBIR) using an ensemble of three cutting-edge deep learning architectures: Xception, MobileNet, and Inception. This ensemble approach demonstrated exceptional retrieval accuracy, with Xception and Inception models achieving an accuracy of 92.375%, precision and recall of 93% and 92% respectively, and an F1-score of 92%. The MobileNet model also showed strong performance, with an accuracy of 87.125%, precision and recall of 88% and 87%, and an F1-score of 87%.Beyond mere retrieval accuracy, the study places a significant emphasis on the security of the image database. A dual-layer encryption method was employed, integrating visual cryptography with the Advanced Encryption Standard (AES) to ensure robust protection of sensitive data. This approach guarantees efficient image retrieval based on content while securing the data against potential breaches.The results underscore the efficiency of the ensemble model in balancing high retrieval accuracy with stringent security measures. This balance is particularly relevant for applications in digital libraries, historical research, fingerprint identification, and crime prevention. The paper’s findings advocate for the critical need to integrate strong security protocols in future CBIR systems, ensuring optimal performance without compromising data security.",
        "keywords": "",
        "link": "http://dx.doi.org/10.56714/bjrs.49.2.9"
    },
    {
        "id": 29626,
        "title": "An Effective Content Based Image Retrieval System Using Deep Learning Based Inception Model",
        "authors": "E. Ranjith, Latha Parthiban, T. P. Latchoumi, S. Ananda Kumar, Darshika G. Perera, Sangeetha Ramaswamy",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11277-023-10792-8"
    },
    {
        "id": 29627,
        "title": "Pooling-based Visual Transformer with low complexity attention hashing for image retrieval",
        "authors": "Huan Ren, Jiangtao Guo, Shuli Cheng, Yongming Li",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.122745"
    },
    {
        "id": 29628,
        "title": "Developing a model semantic‐based image retrieval by combining KD‐Tree structure with ontology",
        "authors": "Thanh Manh Le, Nguyen Thi Dinh, Thanh The Van",
        "published": "2023-7-13",
        "citations": 0,
        "abstract": "AbstractThe paper proposes an alternative approach to improve the performance of image retrieval. In this work, a framework for image retrieval based on machine learning and semantic retrieval is proposed. In the preprocessing phase, the image is segmented objects by using Graph‐cut, and the feature vectors of objects presented in the image and their visual relationships are extracted using R‐CNN. The feature vectors, visual relationships, and their symbolic labels are stored in KD‐Tree data structures which can be used to predict the label of objects and visual relationships later. To facilitate semantic query, the images use the RDF data model and create an ontology for the symbolic labels annotated. For each query image, after extracting their feature vectors, the KD‐Tree is used to classify the objects and predict their relationship. After that, a SPARQL query is built to extract a set of similar images. The SPARQL query consists of triple statements describing the objects and their relationship which were previously predicted. The evaluation of the framework with the MS‐COCO dataset and Flickr showed that the precision achieved scores of 0.9218 and 0.9370, respectively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1111/exsy.13396"
    },
    {
        "id": 29629,
        "title": "Content-Based Image Retrieval using Hard Voting Ensemble Method of Inception, Xception, and Mobilenet Architectures",
        "authors": "Meqdam Mohammed, Zakariya Oraibi, Mohammed Hussain",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "Advancements in internet accessibility and the affordability of digital picture sensors have led to the proliferation of extensive image databases utilized across a multitude of applications. Addressing the semantic gap between low-level attributes and human visual perception has become pivotal in refining Content-Based Image Retrieval (CBIR) methodologies, especially within this context. As this field is intensely researched, numerous efficient algorithms for CBIR systems have surfaced, precipitating significant progress in the artificial intelligence field. In this study, we propose employing a hard voting ensemble approach on features derived from three robust deep learning architectures: Inception, Exception, and Mobilenet. This is aimed at bridging the divide between low-level image features and human visual perception. The Euclidean method is adopted to determine the similarity metric between the query image and the features database. The outcome was a noticeable improvement in image retrieval accuracy. We applied our approach to a practical dataset named CBIR 50, which encompasses categories such as mobile phones, cars, cameras, and cats. The effectiveness of our method was thereby validated. Our approach outshone existing CBIR algorithms with superior accuracy (ACC), precision (PREC), recall (REC), and F1-score (F1-S), proving to be a noteworthy addition to the field of CBIR. Our proposed methodology could be potentially extended to various other sectors, including medical imaging and surveillance systems, where image retrieval accuracy is of paramount importance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.37917/ijeee.19.2.17"
    },
    {
        "id": 29630,
        "title": "A Novel Hybrid Approach for a Content-Based Image Retrieval Using Feature Fusion",
        "authors": "Shahbaz Sikandar, Rabbia Mahum, AbdulMalik Alsalman",
        "published": "2023-4-4",
        "citations": 6,
        "abstract": "The multimedia content generated by devices and image processing techniques requires high computation costs to retrieve images similar to the user’s query from the database. An annotation-based traditional system of image retrieval is not coherent because pixel-wise matching of images brings significant variations in terms of pattern, storage, and angle. The Content-Based Image Retrieval (CBIR) method is more commonly used in these cases. CBIR efficiently quantifies the likeness between the database images and the query image. CBIR collects images identical to the query image from a huge database and extracts more useful features from the image provided as a query image. Then, it relates and matches these features with the database images’ features and retakes them with similar features. In this study, we introduce a novel hybrid deep learning and machine learning-based CBIR system that uses a transfer learning technique and is implemented using two pre-trained deep learning models, ResNet50 and VGG16, and one machine learning model, KNN. We use the transfer learning technique to obtain the features from the images by using these two deep learning (DL) models. The image similarity is calculated using the machine learning (ML) model KNN and Euclidean distance. We build a web interface to show the result of similar images, and the Precision is used as the performance measure of the model that achieved 100%. Our proposed system outperforms other CBIR systems and can be used in many applications that need CBIR, such as digital libraries, historical research, fingerprint identification, and crime prevention.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app13074581"
    },
    {
        "id": 29631,
        "title": "CONTENT BASED IMAGE RETRIEVAL BERBASIS COLOR HISTOGRAM UNTUK PENGKLASIFIKASIAN IKAN KOI JENIS KOHAKU",
        "authors": "Hisyam Syarif, Pulung Nurtantio Andono",
        "published": "2023-5-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.29100/jipi.v8i2.3612"
    },
    {
        "id": 29632,
        "title": "Similarity Measurement on Logo Image Using CBIR (Content Base Image Retrieval) and CNN ResNet-18 Architecture",
        "authors": "Larissa Navia Rani, Yuhandri Yuhandri",
        "published": "2023-2-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccosite57641.2023.10127711"
    },
    {
        "id": 29633,
        "title": "Highly compressed image representation for classification and content retrieval",
        "authors": "Stanisław Łażewski, Bogusław Cyganek",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "In this paper, we propose a new method of representing images using highly compressed features for classification and image content retrieval – called PCA-ResFeats. They are obtained by fusing high- and low-level features from the outputs of ResNet-50 residual blocks and applying to them principal component analysis, which leads to a significant reduction in dimensionality. Further on, by applying a floating-point compression, we are able to reduce the memory required to store a single image by up to 1,200 times compared to jpg images and 220 times compared to features obtained by simple output fusion of ResNet-50. As a result, the representation of a single image from the dataset can be as low as 35 bytes on average. In comparison with the classification results on features from fusion of the last ResNet-50 residual block, we achieve a comparable accuracy (no worse than five percentage points), while preserving two orders of magnitude data compression. We also tested our method in the content-based image retrieval task, achieving better results than other known methods using sparse features. Moreover, our method enables the creation of concise summaries of image content, which can find numerous applications in databases.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/ica-230729"
    },
    {
        "id": 29634,
        "title": "Conceptional review of the Content-based Image retrieval",
        "authors": " Varsha Kiran Patil,  Shristi Manoj Dhamange,  Shraddha Anil Bhandurge,  Samruddhi Udaysinh Gaikwad",
        "published": "2023-9-30",
        "citations": 0,
        "abstract": "This article examines the process of the Content-based Image Retrieval (CBIR ) system , the features and steps involved, the methods employed, and the applications. CBIR aims to identify, sort, and manage images on the basis of the requirements posed to the system. The system cross checks the requirements using Machine learning processes against a given database and reduces the manual effort of sifting through all pictures individually. Incorporating references to the different methods of feature extraction, this article emphasizes understanding which features are considered important and the characteristics of features that are searched for. It argues the advantages of multiple methods while suggesting how each method is suitable when employed for a specific purpose. The process of indexing is also highlighted in this article. These processes are particularly useful in this advancing world where huge databases of images need to be handled on a daily basis in various applications and where manual methods are simply not feasible.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30574/ijsra.2023.10.1.0733"
    },
    {
        "id": 29635,
        "title": "WWFedCBMIR: World-Wide Federated Content-Based Medical Image Retrieval",
        "authors": "Zahra Tabatabaei, Yuandou Wang, Adrián Colomer, Javier Oliver Moll, Zhiming Zhao, Valery Naranjo",
        "published": "2023-9-28",
        "citations": 5,
        "abstract": "The paper proposes a federated content-based medical image retrieval (FedCBMIR) tool that utilizes federated learning (FL) to address the challenges of acquiring a diverse medical data set for training CBMIR models. CBMIR is a tool to find the most similar cases in the data set to assist pathologists. Training such a tool necessitates a pool of whole-slide images (WSIs) to train the feature extractor (FE) to extract an optimal embedding vector. The strict regulations surrounding data sharing in hospitals makes it difficult to collect a rich data set. FedCBMIR distributes an unsupervised FE to collaborative centers for training without sharing the data set, resulting in shorter training times and higher performance. FedCBMIR was evaluated by mimicking two experiments, including two clients with two different breast cancer data sets, namely BreaKHis and Camelyon17 (CAM17), and four clients with the BreaKHis data set at four different magnifications. FedCBMIR increases the F1 score (F1S) of each client from 96% to 98.1% in CAM17 and from 95% to 98.4% in BreaKHis, with 11.44 fewer hours in training time. FedCBMIR provides 98%, 96%, 94%, and 97% F1S in the BreaKHis experiment with a generalized model and accomplishes this in 25.53 fewer hours of training.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/bioengineering10101144"
    },
    {
        "id": 29636,
        "title": "Content‐based image retrieval using a fusion of global and local features",
        "authors": "Hee Hyung Bu, Nam Chul Kim, Sung Ho Kim",
        "published": "2023-6",
        "citations": 4,
        "abstract": "AbstractColor, texture, and shape act as important information for images in human recognition. For content‐based image retrieval, many studies have combined color, texture, and shape features to improve the retrieval performance. However, there have not been many powerful methods for combining all color, texture, and shape features. This study proposes a content‐based image retrieval method that uses the combined local and global features of color, texture, and shape. The color features are extracted from the color autocorrelogram; the texture features are extracted from the magnitude of a complete local binary pattern and the Gabor local correlation revealing local image characteristics; and the shape features are extracted from singular value decomposition that reflects global image characteristics. In this work, an experiment is performed to compare the proposed method with those that use our partial features and some existing techniques. The results show an average precision that is 19.60% higher than those of existing methods and 9.09% higher than those of recent ones. In conclusion, our proposed method is superior over other methods in terms of retrieval performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.4218/etrij.2022-0071"
    },
    {
        "id": 29637,
        "title": "(Retracted) Mimicking human vision systems: deep-learning-based feature fusion for semantic image retrieval",
        "authors": "Zhongzhe Chen, Luming Zhang",
        "published": "2023-2-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/1.jei.32.6.062509"
    },
    {
        "id": 29638,
        "title": "Securing Privacy: Encrypted Image Retrieval with CNNs and Chaos-Based Visual Cryptography on Cloud Computing",
        "authors": "",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.22266/ijies2023.1231.17"
    },
    {
        "id": 29639,
        "title": "Content-based image retrieval for industrial material images with deep learning and encoded physical properties",
        "authors": "Myung Seok Shim, Christopher Thiele, Jeremy Vila, Nishank Saxena, Detlef Hohl",
        "published": "2023",
        "citations": 0,
        "abstract": "Abstract\nIndustrial materials images are an important application domain for content-based image retrieval. Users need to quickly search databases for images that exhibit similar appearance, properties, and/or features to reduce analysis turnaround time and cost. The images in this study are 2D images of millimeter-scale rock samples acquired at micrometer resolution with light microscopy or extracted from 3D micro-CT scans. Labeled rock images are expensive and time-consuming to acquire and thus are typically only available in the tens of thousands. Training a high-capacity deep learning (DL) model from scratch is therefore not practicable due to data paucity. To overcome this “few-shot learning” challenge, we propose leveraging pretrained common DL models in conjunction with transfer learning. The “similarity” of industrial materials images is subjective and assessed by human experts based on both visual appearance and physical qualities. We have emulated this human-driven assessment process via a physics-informed neural network including metadata and physical measurements in the loss function. We present a novel DL architecture that combines Siamese neural networks with a loss function that integrates classification and regression terms. The networks are trained with both image and metadata similarity (classification), and with metadata prediction (regression). For efficient inference, we use a highly compressed image feature representation, computed offline once, to search the database for images similar to a query image. Numerical experiments demonstrate superior retrieval performance of our new architecture compared with other DL and custom-feature-based approaches.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1017/dce.2023.16"
    },
    {
        "id": 29640,
        "title": "An Improved and Efficient Content-Based Medical Image Retrieval Technique vs State-of-Art Texture Feature Extraction Techniques",
        "authors": "Samuel Kusi-Duah, Obed Appiah, Peter Appiahene",
        "published": "2023-6-1",
        "citations": 0,
        "abstract": "Areas in the health sector such as X-rays, Dermatology, High-resolution Computed Tomography – HRCT, Endoscopy, Radiology, Cardiology and Magnetic Resonance Imaging – MRI heavily depend on medical images for their activities hence it has become complex for managing and accessing these images from their repositories. As a matter of concern content-based medical image retrieval-CBMIR has been the system proposed by many researchers for handling access to similar medical image(s) as the input image, yet there is a caveat that has to be addressed with respect to which technique best suits CBMIR system with respect to a given performance metric. Medical images are mostly of grayscale and therefore color feature extraction techniques may not work effectively on them. Since there is no clear indication of which of the various texture feature extraction techniques is best suited for a given performance metric, this work seeks to comparatively evaluate the performance of the following state-of-the-art texture feature extraction techniques; Local Binary Pattern (LBP), Gabor Filter, Gray-Level Co-occurrence Matrix (GLCM), Haralick Descriptor, Features from Accelerated Segment Test (FAST) and a Proposed Technique using the metrics; Precision, Recall, F1-score, Mean Squared Error (MSE), Accuracy and Time. The results showed that the proposed technique is best suited for systems focusing on precision with an average precision score of 100% over 10.5k of raw medical images (dataset) using an appreciable minimum time with time complexity of 0(n).",
        "keywords": "",
        "link": "http://dx.doi.org/10.59657/2837-4681.brs.23.016"
    },
    {
        "id": 29641,
        "title": "OMCBIR: Offline mobile content-based image retrieval with lightweight CNN optimization",
        "authors": "Xiaoqing Zhang, Cong Bai, Kidiyo Kpalma",
        "published": "2023-1",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.displa.2022.102355"
    },
    {
        "id": 29642,
        "title": "Content-Based Image Retrieval Using BRISK and SURF as Bag-of-Visual-Words for Naïve Bayes Classifier",
        "authors": "Samy Bakheet, Mahmoud Mofaddel, Emadeldeen Soliman, Mohamed Heshmat",
        "published": "2023-9-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21608/sjsci.2023.212137.1081"
    },
    {
        "id": 29643,
        "title": "Hybrid Feature Extraction Improves Image Retrieval by Fusing Diverse Methods for Enhanced Content-Based Search",
        "authors": "B. Buvaneswari, Zainab Alassedi, Gotte Ranjith kumar, Mohammed I. Habelalmateen, Ghazi Mohamad Ramadan",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmnwc60182.2023.10435652"
    },
    {
        "id": 29644,
        "title": "Content-based image retrieval with fuzzy clustering for feature vector normalization",
        "authors": "Van-Hieu Vu",
        "published": "2024-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-15215-1"
    },
    {
        "id": 29645,
        "title": "Importance-aware 3D volume visualization for medical content-based image retrieval-a preliminary study",
        "authors": "Mingjian Li, Younhyun Jung, Michael Fulham, Jinman Kim",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.vrih.2023.08.005"
    },
    {
        "id": 29646,
        "title": "Content-Based Image Retrieval for Construction Site Images: Leveraging Deep Learning–Based Object Detection",
        "authors": "Yiheng Wang, Bo Xiao, Ahmed Bouferguene, Mohamed Al-Hussein, Heng Li",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1061/jccee5.cpeng-5473"
    },
    {
        "id": 29647,
        "title": "Weakly-supervised content-based video moment retrieval using low-rank video representation",
        "authors": "Shuwei Huo, Yuan Zhou, Wei Xiang, Sun-Yuan Kung",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2023.110776"
    },
    {
        "id": 29648,
        "title": "A Content-Based Image Retrieval Scheme for Encrypted Domain Using Feature Fusion Deep Supervised Hash",
        "authors": "Qiuyu Zhang, Zhen Wang, Xuewen Hu, Ruihong Chen",
        "published": "2023-8-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsece58870.2023.10263492"
    },
    {
        "id": 29649,
        "title": "Encrypted Image Retrieval Scheme Based on Neural Network and LBP Mapping",
        "authors": "Lan Wang, Tian Wang, Zheng Wang",
        "published": "2023-12-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icpads60453.2023.00288"
    },
    {
        "id": 29650,
        "title": "Content-based medical image retrieval using fractional Hartley transform with hybrid features",
        "authors": "K. Vijila Rani, M. Eugine Prince, P. Sujatha Therese, P. Josephin Shermila, E. Anna Devi",
        "published": "2023-8-30",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-16462-y"
    },
    {
        "id": 29651,
        "title": "A deep learning content-based image retrieval approach using cloud computing",
        "authors": "Mahmoud S. Sayed, Ahmed A. A. Gad-Elrab, Khaled A. Fathy, Kamal R. Raslan",
        "published": "2023-3-1",
        "citations": 0,
        "abstract": "Due to the rapid growth in multimedia content and its visual complexity, contentbased image retrieval (CBIR) has become a very challenging task. Existing works achieve high precision values at first retrieval levels such as top 10 and top 20 images, but low precision values at subsequent levels such as top 40, 50, and 70, so the goal of this paper is to propose a new CBIR approach that achieves high precision values at all retrieval levels. The proposed method combines features extracted from the pre-trained AlexNet model and discrete cosine transform (DCT). Then principal components analysis (PCA) is performed on AlexNet’s features and feeding these combination to multiclass support vector machine (SVM). The euclidean distance is used to measure the similarity between query and stored images features within the predicted class by SVM. Finally top similar images are ranked and retrieved. All above techniques require huge computational power which may not be available on client machine thus, the processing of these tasks is processed on cloud. Experimental results on the benchmark Corel-1k show that the proposed method achieves high precision value 97% along all retrieval levels top 10, 20 and 70 images and requiring less memory compared to other methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijeecs.v29.i3.pp1577-1589"
    },
    {
        "id": 29652,
        "title": "Automatic Weight of Color, Texture, and Shape Features in Content-Based Image Retrieval Using Artificial Neural Network",
        "authors": "Akmal Akmal, Rinaldi Munir, Judhi Santoso",
        "published": "2023-9-10",
        "citations": 0,
        "abstract": "Image retrieval is the process of finding images in the database that are similar to the query image by measuring how close the feature values of the query image are to other images. Image retrieval is currently dominated by approaches that combine several different representations or features. The optimal weight of each feature is needed in combining the image features such as color features, texture features, and shape features. In this study, we use a multi-layer perceptron artificial neural network (MLP) method to obtain feature weights automatically and simultaneously look for optimal weights. The color moment is used to find nine color features, Gray Level Co-occurrence Matrix (GLCM) to find four texture features, and Hu Moment to find seven shape features totaling 20 neurons and all of these features become the input layer in our MLP network. Three neurons in output layers become the automatic weight of each feature. These weights are used to combine each feature's role in obtaining the relevant image. Euclidean Distance is used to measure similarity. The average precision values obtained using automatic feature weights are 93.94% for the synthetic dataset, 91.19% for the Coil-100 dataset, and 54.31% for the Wang dataset. These results have an average difference of 5.06% with the target so automatic feature weighting works well. This value is obtained at a hidden layer size of 11 and a learning rate of 0.1. In addition, the use of automatic feature weighting gives more accurate results compared to manual feature weighting.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30630/joiv.7.3.1184"
    },
    {
        "id": 29653,
        "title": "Pseudo pairs based unsupervised deep hashing for image retrieval",
        "authors": "H. Zhang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/icp.2023.3294"
    },
    {
        "id": 29654,
        "title": "Content-Based Image Retrieval System using Color Moment and Bag of Visual Words with Local Binary Pattern",
        "authors": "Rasha Q. Hassan, Zainab N. Sultani, Ban N. Dhannoon",
        "published": "2023-1-17",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.33640/2405-609x.3274"
    },
    {
        "id": 29655,
        "title": "A novel hashing-inverted index for secure content-based retrieval with massive encrypted speeches",
        "authors": "Yingjie Hu, Qiuyu Zhang, Qiwen Zhang, Yugui Jia",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00530-023-01229-0"
    },
    {
        "id": 29656,
        "title": "Image-Text Correlation Based Remote Sensing Image Retrieval",
        "authors": "Prem Shanker Yadav, Sachin Dube",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/r10-htc57504.2023.10461864"
    },
    {
        "id": 29657,
        "title": "Building novel approach for context-based image retrieval in the area of healthcare",
        "authors": "Amogh Shukla, Nitin Lodha, V. Vijayarajan, Surya Prasath",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0180774"
    },
    {
        "id": 29658,
        "title": "Integrated Design of Building Environment Based on Image Segmentation and Retrieval Technology",
        "authors": "Zhou Li, Hanan Aljuaid",
        "published": "2024-3-19",
        "citations": 0,
        "abstract": "Existing models still exhibit a deficiency in capturing more detailed contextual information when processing architectural images. This paper introduces a model for architectural image segmentation and retrieval based on an image segmentation network. Primarily, spatial attention is incorporated into the U-Net segmentation network to enhance the extraction of image features. Subsequently, a dual-path attention mechanism is integrated into the U-Net backbone network, facilitating the seamless integration of information across different spaces and scales. Experimental results showcase the superior performance of the proposed model on the test set, with average dice coefficient, accuracy, and recall reaching 94.67%, 95.61%, and 97.88%, respectively, outperforming comparative models. The proposed model can enhance the U-Net network's capability to identify targets within feature maps. The amalgamation of image segmentation networks and attention mechanisms in artificial intelligence technology enables precise segmentation and retrieval of architectural images.",
        "keywords": "",
        "link": "http://dx.doi.org/10.4018/ijitsa.340774"
    },
    {
        "id": 29659,
        "title": "Toward Fine-grained Image Retrieval with Adaptive Deep Learning for Cultural Heritage Image",
        "authors": "Sathit Prasomphan",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/csse.2023.025293"
    },
    {
        "id": 29660,
        "title": "Interactive Indoor Localization Based on Image Retrieval and Question Response",
        "authors": "Xinyun Li, Ryosuke Furuta, Go Irie, Yota Yamamoto, Yukinobu Taniguchi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011624300003417"
    },
    {
        "id": 29661,
        "title": "Ancient Chinese Character Image Retrieval Based on Fusing Deep Features and Skeleton Features",
        "authors": "Xinhui Wang, Xuedong Tian",
        "published": "2023-12-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icpads60453.2023.00371"
    },
    {
        "id": 29662,
        "title": "Dual-Path Semantic Construction Network for Composed Query-Based Image Retrieval",
        "authors": "Shenshen Li",
        "published": "2023-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3591106.3592245"
    },
    {
        "id": 29663,
        "title": "Privacy-Preserving Image Retrieval Based on Additive Secret Sharing",
        "authors": "Qi Gu, Lizhi Xiong, Wenhao Zhou, Zhihua Xia",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijaacs.2024.10055815"
    },
    {
        "id": 29664,
        "title": "Generative Enhancement-based Similarity Prediction Hashing for Image Retrieval",
        "authors": "Yuan Cao, Fanlei Meng, Xiangyu Wu, Zijie Wang",
        "published": "2023-12-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icpads60453.2023.00204"
    },
    {
        "id": 29665,
        "title": "Modelling of Block Feature-Content Based Efficient Image Compression System Using DWT and Machine Learning",
        "authors": "",
        "published": "2024-4-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.22266/ijies2024.0430.42"
    },
    {
        "id": 29666,
        "title": "Mutual reconstruction-based linear discriminant hashing for image retrieval",
        "authors": "D. Huang, Z. Lai, H. Kong",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/icp.2023.3281"
    },
    {
        "id": 29667,
        "title": "Privacy-preserving image retrieval based on additive secret sharing",
        "authors": "Zhihua Xia, Qi Gu, Lizhi Xiong, Wenhao Zhou",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijaacs.2024.137065"
    },
    {
        "id": 29668,
        "title": "A SEMWORD based Semantic Secure Content Retrieval System in E-learning",
        "authors": "J I Christy Eunaicy,  , V Sundara Vadivelu",
        "published": "2023-8-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17485/ijst/v16i31.833"
    },
    {
        "id": 29669,
        "title": "diveXB: An Interactive Video Retrieval System for Beginners",
        "authors": "Klaus Schoeffmann",
        "published": "2023-9-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3617233.3617258"
    },
    {
        "id": 29670,
        "title": "Optoelectronic device based failure management using content based multispectral image retrieval and deep learning model",
        "authors": "Raghuram Bhukya, B. Arunsundar, Narendra Babu Tatini, Triveni Mohan Sadala, Hashim Elshafie, Shamimul Qamar",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11082-023-05793-7"
    },
    {
        "id": 29671,
        "title": "Module-based multiple feature integration descriptor for image retrieval",
        "authors": "Qiaoping He",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neucom.2023.127202"
    },
    {
        "id": 29672,
        "title": "Clothing Image retrieval method based on ConvNeXt",
        "authors": "xiujin shi, yiwei zhang",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3006006"
    },
    {
        "id": 29673,
        "title": "CNN-Based Pill Image Recognition for Retrieval Systems",
        "authors": "Khalil Al-Hussaeni, Ioannis Karamitsos, Ezekiel Adewumi, Rema M. Amawi",
        "published": "2023-4-18",
        "citations": 2,
        "abstract": "Medication should be consumed as prescribed with little to zero margins for errors, otherwise consequences could be fatal. Due to the pervasiveness of camera-equipped mobile devices, patients and practitioners can easily take photos of unidentified pills to avert erroneous prescriptions or consumption. This area of research goes under the umbrella of information retrieval and, more specifically, image retrieval or recognition. Several studies have been conducted in the area of image retrieval in order to propose accurate models, i.e., accurately matching an input image with stored ones. Recently, neural networks have been shown to be effective in identifying digital images. This study aims to provide an enhancement to image retrieval in terms of accuracy and efficiency through image segmentation and classification. This paper suggests three neural network (CNN) architectures: two models that are hybrid networks paired with a classification method (CNN+SVM and CNN+kNN) and one ResNet-50 network. We perform various preprocessing steps by using several detection techniques on the selected dataset. We conduct extensive experiments using a real-life dataset obtained from the National Library of Medicine database. The results demonstrate that our proposed model is capable of deriving an accuracy of 90.8%. We also provide a comparison of the above-mentioned three models with some existing methods, and we notice that our proposed CNN+kNN architecture improved the pill image retrieval accuracy by 10% compared to existing models.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app13085050"
    },
    {
        "id": 29674,
        "title": "RefinerHash: a new hashing-based re-ranking technique for image retrieval",
        "authors": "Farzad Sabahi, M. Omair Ahmad, M.N.S. Swamy",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00530-024-01296-x"
    },
    {
        "id": 29675,
        "title": "A Diagnostic Study of Content-Based Image Retrieval Technique for Studying the CT Images of Lung Nodules and Prediction of Lung Cancer as a Biometric Tool",
        "authors": "Rajeev Dixit, Dr. Pankaj Kumar, Dr. Shashank Ojha",
        "published": "2023-6-30",
        "citations": 0,
        "abstract": "Content Based Medical Image Retrieval (CBMIR) can be defined as a digital image search using the contents of the images. CBMIR plays a very important part in medical applications such as retrieving CT images and more accurately diagnosing aberrant lung tissues in CT images. The Content-Based Medical Image Retrieval (CBMIR) method might aid radiotherapists in examining a patient's CT image in order to retrieve comparable pulmonary nodes more precisely by utilizing query nodes. Intending a particular query node, the CBMIR system searches a large chest CT image database for comparable nodes. The prime aim of this research is to evaluate an end-to-end method for developing a CBIR system for lung cancer diagnosis.",
        "keywords": "",
        "link": "http://dx.doi.org/10.37391/ijeer.110234"
    },
    {
        "id": 29676,
        "title": "Evaluation of semantic relations impact in query expansion-based retrieval systems",
        "authors": "Lorenzo Massai",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2023.111183"
    },
    {
        "id": 29677,
        "title": "A clinically motivated self-supervised approach for content-based image retrieval of CT liver images",
        "authors": "Kristoffer Knutsen Wickstrøm, Eirik Agnalt Østmo, Keyur Radiya, Karl Øyvind Mikalsen, Michael Christian Kampffmeyer, Robert Jenssen",
        "published": "2023-7",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compmedimag.2023.102239"
    },
    {
        "id": 29678,
        "title": "Novel Topic Models for Content Based Recommender Systems",
        "authors": "Kamal Maanicshah, Manar Amayri, Nizar Bouguila",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011826700003467"
    },
    {
        "id": 29679,
        "title": "AToMiC: An Image/Text Retrieval Test Collection to Support Multimedia Content Creation",
        "authors": "Jheng-Hong Yang, Carlos Lassance, Rafael Sampaio De Rezende, Krishna Srinivasan, Miriam Redi, Stéphane Clinchant, Jimmy Lin",
        "published": "2023-7-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3539618.3591903"
    },
    {
        "id": 29680,
        "title": "An Efficient Anaglyph 3D Content based Video Retrieval using Watermarking Technique",
        "authors": "Dorra Dhaou, Saoussen Ben Jabra, Ezzeddine Zagrouba",
        "published": "2023-10-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cw58918.2023.00031"
    },
    {
        "id": 29681,
        "title": "A Privacy-preserving Image Retrieval Scheme in Edge Computing Environment",
        "authors": "",
        "published": "2023-2-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3837/tiis.2023.02.009"
    },
    {
        "id": 29682,
        "title": "Proactive Content Retrieval Based on Value of Popularity in Content-Centric Internet of Vehicles",
        "authors": "Muhammad Toaha Raza Khan, Yalew Zelalem Jembre, Malik Muhammad Saad, Safdar Hussain Bouk, Syed Hassan Ahmed, Dongkyun Kim",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tits.2024.3378669"
    },
    {
        "id": 29683,
        "title": "PCaSM: Text-Guided Composed Image Retrieval with Parallel Content and Style Modules",
        "authors": "Jiayan Zhang, Jie Zhang, Honghao Wu, Zongwei Zhao, Jinyu Hu, Mingyong Li",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmew59549.2023.00077"
    },
    {
        "id": 29684,
        "title": "A Symbolic Data Modeling and Similarity Based Approach to Audio-Query Based Image Retrieval",
        "authors": "S.  A. Angadi, Hemavati  C. Purad",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4364547"
    },
    {
        "id": 29685,
        "title": "Learning Noise-Assisted Robust Image Features for Fine-Grained Image Retrieval",
        "authors": "Vidit Kumar, Hemant Petwal, Ajay Krishan Gairola, Pareshwar Prasad Barmola",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/csse.2023.032047"
    },
    {
        "id": 29686,
        "title": "Octagonal lattice-based triangulated shape descriptor engaging second-order derivatives supplementing image retrieval",
        "authors": "M. Kanimozhi, M.S. Sudhakar",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jvcir.2023.104005"
    },
    {
        "id": 29687,
        "title": "Oppositional Jellyfish Search Optimizer With Deep Transfer Learning Enabled Secure Content-Based Biomedical Image Retrieval",
        "authors": "Ehab Bahaudien Ashary, Sahar Jambi, Rehab B. Ashari, Mahmoud Ragab",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3305368"
    },
    {
        "id": 29688,
        "title": "Interactive content-based image retrieval with deep learning for CT abdominal organ recognition",
        "authors": "Chung-Ming Lo, Chi-Cheng Wang, Peng-Hsiang Hung",
        "published": "2024-2-21",
        "citations": 0,
        "abstract": "Abstract\n\nObjective. Recognizing the most relevant seven organs in an abdominal computed tomography (CT) slice requires sophisticated knowledge. This study proposed automatically extracting relevant features and applying them in a content-based image retrieval (CBIR) system to provide similar evidence for clinical use. Approach. A total of 2827 abdominal CT slices, including 638 liver, 450 stomach, 229 pancreas, 442 spleen, 362 right kidney, 424 left kidney and 282 gallbladder tissues, were collected to evaluate the proposed CBIR in the present study. Upon fine-tuning, high-level features used to automatically interpret the differences among the seven organs were extracted via deep learning architectures, including DenseNet, Vision Transformer (ViT), and Swin Transformer v2 (SwinViT). Three images with different annotations were employed in the classification and query. Main results. The resulting performances included the classification accuracy (94%–99%) and retrieval result (0.98–0.99). Considering global features and multiple resolutions, SwinViT performed better than ViT. ViT also benefited from a better receptive field to outperform DenseNet. Additionally, the use of hole images can obtain almost perfect results regardless of which deep learning architectures are used. Significance. The experiment showed that using pretrained deep learning architectures and fine-tuning with enough data can achieve successful recognition of seven abdominal organs. The CBIR system can provide more convincing evidence for recognizing abdominal organs via similarity measurements, which could lead to additional possibilities in clinical practice.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1361-6560/ad1f86"
    },
    {
        "id": 29689,
        "title": "Nonlinear image encryption based on phase truncation and phase retrieval operation",
        "authors": "Gaurav Verma",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s12596-023-01499-x"
    },
    {
        "id": 29690,
        "title": "A Context-based Image Retrieval Method for Persian Databases",
        "authors": "Azadeh Fakhrzadeh, Mohammad Rabiei, Mohadese Rahnama",
        "published": "2023-5-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icwr57742.2023.10139001"
    },
    {
        "id": 29691,
        "title": "Prototypical Mixing and Retrieval-based Refinement for Label Noise-resistant Image Retrieval",
        "authors": "Xinlong Yang, Haixin Wang, Jinan Sun, Shikun Zhang, Chong Chen, Xian-Sheng Hua, Xiao Luo",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01032"
    },
    {
        "id": 29692,
        "title": "Image retrieval method based on k-means block",
        "authors": "GuanNan Deng, Lu Mu, Zhe Ma, Mei Zhang",
        "published": "2023-6-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2680938"
    },
    {
        "id": 29693,
        "title": "A CNN-based no reference image quality metric exploiting content saliency",
        "authors": "Kamal Lamichhane, Marco Carli, Federica Battisti",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.image.2022.116899"
    },
    {
        "id": 29694,
        "title": "Delving into the Depths of Image Retrieval Systems in the Light of Deep Learning: A Review",
        "authors": "Ovais Rashid Khan,  , Javaid Iqbal Bhat",
        "published": "2023-9-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17485/ijst/v16i34.1341"
    },
    {
        "id": 29695,
        "title": "Magnetic Resonance Image Reconstruction using Inception-based Convolutional Neural Network",
        "authors": "Elmira Vafay Eslahi, Amirali Baniasadi",
        "published": "2023-2-18",
        "citations": 0,
        "abstract": "Magnetic resonance imaging (MRI) is one of the best imaging techniques that produce highquality images of objects. The long scan time is one of the biggest challenges in MRI acquisitions. To address this challenge, many researchers have aimed at finding methods to speed up the process. Faster MRI can reduce patient discomfort and motion artifacts. Many reconstruction methods are used in this matter, like deep learning-based MRI reconstruction, parallel MRI, and compressive sensing. Among these techniques, the convolutional neural network (CNN) generates high-quality images with faster scan and reconstruction procedures compared to the other techniques. The Inception module proposed by Google inspires the algorithm of this study for MRI reconstruction. In other words, we introduce a new MRI U-Net modification by using the Inception module. Our method is more flexible and robust compared to the standard U-Net.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5121/csit.2023.130307"
    },
    {
        "id": 29696,
        "title": "A Retrieval Method in Heterogeneous Domains Based on Orthogonal Softmax",
        "authors": "Wei Yu",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icipca59209.2023.10257782"
    },
    {
        "id": 29697,
        "title": "Adapting Hierarchical Transformer for Scene-Level Sketch-Based Image Retrieval",
        "authors": "Jie Yang, Aihua Ke, Bo Cai",
        "published": "2023-12-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3595916.3626394"
    },
    {
        "id": 29698,
        "title": "Integrating listwise ranking into pairwise-based image-text retrieval",
        "authors": "Zheng Li, Caili Guo, Xin Wang, Hao Zhang, Yanjun Wang",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2024.111431"
    },
    {
        "id": 29699,
        "title": "Sketch-based 3D shape retrieval via teacher–student learning",
        "authors": "Shuang Liang, Weidong Dai, Yiyang Cai, Chi Xie",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103903"
    },
    {
        "id": 29700,
        "title": "An Operative Investigation of ML Methods for Image Retrieval with MPKDC-Based Brain Image Segmentation",
        "authors": "Manaswini R, Ganesh D, Ritesh Kumar",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ictbig59752.2023.10456186"
    },
    {
        "id": 29701,
        "title": "A novel Siamese deep hashing model for histopathology image retrieval",
        "authors": "Seyed Mohammad Alizadeh, Mohammad Sadegh Helfroush, Henning Müller",
        "published": "2023-9",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.120169"
    },
    {
        "id": 29702,
        "title": "Acquiring a Low-Dimensional, Environment-Independent Representation of Brain MR Images for Content-Based Image Retrieval",
        "authors": "Shuya Tobari, Kenichi Oishi, Hitoshi Iyatomi",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smc53992.2023.10394176"
    },
    {
        "id": 29703,
        "title": "AI co-pilot: content-based image retrieval for the reading of rare diseases in chest CT",
        "authors": "Johannes Haubold, Ke Zeng, Sepehr Farhand, Sarah Stalke, Hannah Steinberg, Denise Bos, Mathias Meetschen, Anisa Kureishi, Sebastian Zensen, Tim Goeser, Sandra Maier, Michael Forsting, Felix Nensa",
        "published": "2023-3-16",
        "citations": 0,
        "abstract": "AbstractThe aim of the study was to evaluate the impact of the newly developed Similar patient search (SPS) Web Service, which supports reading complex lung diseases in computed tomography (CT), on the diagnostic accuracy of residents. SPS is an image-based search engine for pre-diagnosed cases along with related clinical reference content (https://eref.thieme.de). The reference database was constructed using 13,658 annotated regions of interest (ROIs) from 621 patients, comprising 69 lung diseases. For validation, 50 CT scans were evaluated by five radiology residents without SPS, and three months later with SPS. The residents could give a maximum of three diagnoses per case. A maximum of 3 points was achieved if the correct diagnosis without any additional diagnoses was provided. The residents achieved an average score of 17.6 ± 5.0 points without SPS. By using SPS, the residents increased their score by 81.8% to 32.0 ± 9.5 points. The improvement of the score per case was highly significant (p = 0.0001). The residents required an average of 205.9 ± 350.6 s per case (21.9% increase) when SPS was used. However, in the second half of the cases, after the residents became more familiar with SPS, this increase dropped to 7%. Residents’ average score in reading complex chest CT scans improved by 81.8% when the AI-driven SPS with integrated clinical reference content was used. The increase in time per case due to the use of the SPS was minimal.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-023-29949-3"
    },
    {
        "id": 29704,
        "title": "Unsupervised Global and Local CNN Feature Extraction Using Multi-Scale Attention Aggregation for Fine-Grained Image Retrieval",
        "authors": "Chang-Hsing Lee, Jau-Ling Shih, Wen-Cheih Tsai, Cheng Chang Lien, Chin-Chuan Han",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.12792/icisip2023.028"
    }
]