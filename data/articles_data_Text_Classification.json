[
    {
        "id": 11871,
        "title": "Text Mining: Classification of Text Documents using Granular Hybrid Classification Technique",
        "authors": "Shiva Prasad KM, Dr.T Hanumantha Reddy",
        "published": "2019-7-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32622/ijrat.76201910"
    },
    {
        "id": 11872,
        "title": "Text Classification",
        "authors": "",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4135/9781483399782.n11"
    },
    {
        "id": 11873,
        "title": "Connecting Text Classification with Image Classification: A New Preprocessing Method for Implicit Sentiment Text Classification",
        "authors": "Meikang Chen, Kurban Ubul, Xuebin Xu, Alimjan Aysa, Mahpirat Muhammat",
        "published": "2022-2-28",
        "citations": 6,
        "abstract": "As a research hotspot in the field of natural language processing (NLP), sentiment analysis can be roughly divided into explicit sentiment analysis and implicit sentiment analysis. However, due to the lack of obvious emotion words in the implicit sentiment analysis task and because the sentiment polarity contained in implicit sentiment words is not easily accurately identified by existing text-processing methods, the implicit sentiment analysis task is one of the most difficult tasks in sentiment analysis. This paper proposes a new preprocessing method for implicit sentiment text classification; this method is named Text To Picture (TTP) in this paper. TTP highlights the sentiment differences between different sentiment polarities in Chinese implicit sentiment text with the help of deep learning by converting original text data into word frequency maps. The differences between sentiment polarities are used as sentiment clues to improve the performance of the Chinese implicit sentiment text classification task. It does this by transforming the original text data into a word frequency map in order to highlight the differences between the sentiment polarities expressed in the implicit sentiment text. We conducted experimental tests on two common datasets (SMP2019, EWECT), and the results show that the accuracy of our method is significantly improved compared with that of the competitor’s. On the SMP2019 dataset, the accuracy-improvement range was 4.55–7.06%. On the EWECT dataset, the accuracy was improved by 1.81–3.95%. In conclusion, the new preprocessing method for implicit sentiment text classification proposed in this paper can achieve better classification results.",
        "link": "http://dx.doi.org/10.3390/s22051899"
    },
    {
        "id": 11874,
        "title": "Computational Methods for Text Analysis and Text Classification",
        "authors": "Hercules Dalianis",
        "published": "2018",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-78503-5_8"
    },
    {
        "id": 11875,
        "title": "Framework for Thought to Text Classification",
        "authors": "Manasa R.",
        "published": "2020-3-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.37200/ijpr/v24i5/pr201707"
    },
    {
        "id": 11876,
        "title": "Text Classification",
        "authors": "Chengqing Zong, Rui Xia, Jiajun Zhang",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-0100-2_5"
    },
    {
        "id": 11877,
        "title": "Text Mining in Hotel Reviews: Impact of Words Restriction in Text Classification",
        "authors": "Diogo Campos, Rodrigo Silva, Jorge Bernardino",
        "published": "2019",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008346904420449"
    },
    {
        "id": 11878,
        "title": "Text Classification: Basic Models",
        "authors": "Charu C. Aggarwal",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-96623-2_5"
    },
    {
        "id": 11879,
        "title": "Text Classification: Basic Models",
        "authors": "Charu C. Aggarwal",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-73531-3_5"
    },
    {
        "id": 11880,
        "title": "Text Classification",
        "authors": "",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4135/9781506336985.n13"
    },
    {
        "id": 11881,
        "title": "A Study of Various Text Augmentation Techniques for Relation Classification in Free Text",
        "authors": "Praveen Giridhara, Chinmaya Mishra, Reddy Venkataramana, Syed Bukhari, Andreas Dengel",
        "published": "2019",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007311003600367"
    },
    {
        "id": 11882,
        "title": "A Distilbert-Based Hierarchical Text Classification",
        "authors": "Quang Tran",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4596434"
    },
    {
        "id": 11883,
        "title": "Linear Classification and Regression for Text",
        "authors": "Charu C. Aggarwal",
        "published": "2018",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-73531-3_6"
    },
    {
        "id": 11884,
        "title": "Review of \"Text Classification Algorithms: A Survey\"",
        "authors": "Ajit Singh",
        "published": "2021-2-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14293/s2199-1006.1.sor-uncat.am8qep.v1.rzgvyb"
    },
    {
        "id": 11885,
        "title": "News Text Classification Model Based on Topic Model",
        "authors": "",
        "published": "2017-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23883/ijrter.2017.3330.a9x5g"
    },
    {
        "id": 11886,
        "title": "CHALLENGES IN TEXT CLASSIFICATION USING MACHINE LEARNING TECHNIQUES",
        "authors": "",
        "published": "2018-2-27",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23883/ijrter.2018.4068.k3orb"
    },
    {
        "id": 11887,
        "title": "Co-Clustering based Classification Algorithm with Latent Semantic Relationship for Cross-Domain Text Classification throughWikipedia",
        "authors": "Pe ter, Max well",
        "published": "2017-5-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.9756/bijdm.8330"
    },
    {
        "id": 11888,
        "title": "Self-Refine Learning For Data-Centric Text Classification",
        "authors": "TechOnly Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<div>\n\t\t\t\t<div>\n\t\t\t\t\t<p>In industry NLP application, our manually labeled data has\na certain number of noisy data. We present a simple method to find the\nnoisy data and re-label their labels to the result of model prediction.\nWe select the noisy data whose human label is not contained in the\ntop-K model’s predictions. The model is trained on the origin dataset.\nThe experiment result shows that our method works. For industry deep\nlearning application, our method improve the text classification accuracy\nfrom 80.5% to 90.6% in dev dataset, and improve the human-evaluation\naccuracy from 83.2% to 90.5%.<br></p>\n\t\t\t\t</div>\n\t\t\t</div>",
        "link": "http://dx.doi.org/10.36227/techrxiv.16610629.v4"
    },
    {
        "id": 11889,
        "title": "Hybrid Quantum-Classical Neural Networks for Text Classification",
        "authors": "Dhruv Baronia",
        "published": "No Date",
        "citations": 0,
        "abstract": "Quantum Computing presents an interesting paradigm where it can possibly offer certain improvements and additions to a classical network while training. This method is particularly prevalent in the current Noisy Intermediate-Scale Quantum era, where we can test these theories using libraries such as Pennylane in conjunction with robust ML frameworks such as TensorFlow. This paper presents a proof-of-concept for the same, using a hybrid quantum-classical model to solve a text classification problem on the IMDB Movie Sentiment Dataset. These hybrid models utilize precalculated embeddings and dense layers alongside a variational quantum circuit layer. We created 4 such models, utilizing various kinds of embeddings, namely NNLM-128, NNLM-50, Swivel and USE, using TFHub and Pennylane. We also trained classical versions of these models, without the variational quantum layer to evaluate the performances. All models were trained on the same data, keeping the parameters constant.",
        "link": "http://dx.doi.org/10.36227/techrxiv.13488420"
    },
    {
        "id": 11890,
        "title": "Self-Refine Learning For Data-Centric Text Classification",
        "authors": "TechOnly Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<div>\n\t\t\t\t<div>\n\t\t\t\t\t<p>In industry NLP application, our manually labeled data has\na certain number of noisy data. We present a simple method to find the\nnoisy data and re-label their labels to the result of model prediction.\nWe select the noisy data whose human label is not contained in the\ntop-K model’s predictions. The model is trained on the origin dataset.\nThe experiment result shows that our method works. For industry deep\nlearning application, our method improve the text classification accuracy\nfrom 80.5% to 90.6% in dev dataset, and improve the human-evaluation\naccuracy from 83.2% to 90.5%.<br></p>\n\t\t\t\t</div>\n\t\t\t</div>",
        "link": "http://dx.doi.org/10.36227/techrxiv.16610629.v3"
    },
    {
        "id": 11891,
        "title": "Self-Refine Learning For Data-Centric Text Classification",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<div>\n\t\t\t\t<div>\n\t\t\t\t\t<p>In industry NLP application, our manually labeled data has\na certain number of noisy data. We present a simple method to find the\nnoisy data and re-label their labels to the result of model prediction.\nWe select the noisy data whose human label is not contained in the\ntop-K model’s predictions. The model is trained on the origin dataset.\nThe experiment result shows that our method works. For industry deep\nlearning application, our method improve the text classification accuracy\nfrom 80.5% to 90.6% in dev dataset, and improve the human-evaluation\naccuracy from 83.2% to 90.5%.<br></p>\n\t\t\t\t</div>\n\t\t\t</div>",
        "link": "http://dx.doi.org/10.36227/techrxiv.16610629.v1"
    },
    {
        "id": 11892,
        "title": "Self-Refine Learning For Data-Centric Text Classification",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In industry NLP application, our manually labeled data has a certain number of noise data. We present a simple method to find the noise data and remove them. We select the noise data whose human label is not contained in the top-K model's predictions. The experiment result shows that our method works. For industry deep learning application, our method improve the text classification accuracy from 80.5% to 90.6% in dev dataset, and improve the human-evaluation accuracy from 83.2% to 90.1%.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.16610629.v5"
    },
    {
        "id": 11893,
        "title": "Hybrid Tiled Convolutional Neural Networks (HTCNN) Text Sentiment Classification",
        "authors": "Maria Truşcǎ, Gerasimos Spanakis",
        "published": "2020",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008946505060513"
    },
    {
        "id": 11894,
        "title": "Self-Refine Learning For Data-Centric Text Classification",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<div>\n\t\t\t\t<div>\n\t\t\t\t\t<p>In industry NLP application, our manually labeled data has\na certain number of noisy data. We present a simple method to find the\nnoisy data and re-label their labels to the result of model prediction.\nWe select the noisy data whose human label is not contained in the\ntop-K model’s predictions. The model is trained on the origin dataset.\nThe experiment result shows that our method works. For industry deep\nlearning application, our method improve the text classification accuracy\nfrom 80.5% to 90.6% in dev dataset, and improve the human-evaluation\naccuracy from 83.2% to 90.5%.<br></p>\n\t\t\t\t</div>\n\t\t\t</div>",
        "link": "http://dx.doi.org/10.36227/techrxiv.16610629.v2"
    },
    {
        "id": 11895,
        "title": "Self-Refine Learning For Data-Centric Text Classification",
        "authors": "Tong Guo",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>In industry NLP application, our manually labeled data has a certain number of noise data. We present a simple method to find the noise data and remove them. We select the noise data whose human label is not contained in the top-K model's predictions. The experiment result shows that our method works. For industry deep learning application, our method improve the text classification accuracy from 80.5% to 90.6% in dev dataset, and improve the human-evaluation accuracy from 83.2% to 90.1%.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.16610629.v6"
    },
    {
        "id": 11896,
        "title": "Hybrid Quantum-Classical Neural Networks for Text Classification",
        "authors": "Dhruv Baronia",
        "published": "No Date",
        "citations": 0,
        "abstract": "Quantum Computing presents an interesting paradigm where it can possibly offer certain improvements and additions to a classical network while training. This method is particularly prevalent in the current Noisy Intermediate-Scale Quantum era, where we can test these theories using libraries such as Pennylane in conjunction with robust ML frameworks such as TensorFlow. This paper presents a proof-of-concept for the same, using a hybrid quantum-classical model to solve a text classification problem on the IMDB Movie Sentiment Dataset. These hybrid models utilize precalculated embeddings and dense layers alongside a variational quantum circuit layer. We created 4 such models, utilizing various kinds of embeddings, namely NNLM-128, NNLM-50, Swivel and USE, using TFHub and Pennylane. We also trained classical versions of these models, without the variational quantum layer to evaluate the performances. All models were trained on the same data, keeping the parameters constant.",
        "link": "http://dx.doi.org/10.36227/techrxiv.13488420.v1"
    },
    {
        "id": 11897,
        "title": "Quantitative Text Classification Based on POS-motifs",
        "authors": "Ruina Chen",
        "published": "2017-3-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110476637-005"
    },
    {
        "id": 11898,
        "title": "Exploring Text Classification Configurations - A Bottom-up Approach to Customize Text Classifiers based on the Visualization of Performance",
        "authors": "Alejandro Gabriel Villanueva Zacarias, Laura Kassner, Bernhard Mitschang",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006309705040511"
    },
    {
        "id": 11899,
        "title": "Text Classification",
        "authors": "Dipanjan Sarkar",
        "published": "2019",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-4354-1_5"
    },
    {
        "id": 11900,
        "title": "Text Classification via Compressive Sensing",
        "authors": "Dimitrios Milioris",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-66414-9_4"
    },
    {
        "id": 11901,
        "title": "Text Classification of English News Articles using Graph Mining Techniques",
        "authors": "Hasan Abdulla, Wasan Awad",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010954600003116"
    },
    {
        "id": 11902,
        "title": "Text Categorization and Affinities",
        "authors": "Jyotika Singh",
        "published": "2023-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003264774-8"
    },
    {
        "id": 11903,
        "title": "Open Text News Benchmark: A Novel ChineseNews Benchmark for Text Classification",
        "authors": "Guishen Wang, Xiaoxuan Guo, Junlin Wu, Xiaotang Zhou",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nWith the help of deep learning technology, related topics of natural language processing such as summarization, text classification, and sentiment analysis, are researched deeper and deeper. However, related benchmarks especially for Chinese language are in short. For this reason, we propose a novel Chinese news text benchmark called Open Text News benchmark (OTN) enhancing related research in natural language processing. OTNSTANDARD contains 90,000 Chinese news from April 2000 to June 2021 in nine categories, including finance, estate, education, technology, military, automobiles, sports, games, and entertainment. We employed several classical machine learning classifiers and several deep learning models to test our OTN benchmark to see how well it performed at text classification.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2126654/v1"
    },
    {
        "id": 11904,
        "title": "DAEPK:Domain-Adaptive Text Feature Enhancement Technology Integrating Prior Knowledge Domain In Text Classification",
        "authors": "Jie Yang, Tashi Nyima, Jindong Qi",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe scarcity of resources, lack of labeled texts, and insufficient corpora pose significant challenges to many specialized classification problems. It increases the difficulty of small language and domain-specific classification problems. In this paper, we propose a new approach to address this problem: by assigning multi-dimensional additional weights to words using external knowledge, thereby enhancing text features in low-resource domains. This is achieved by introducing the concepts of 'prior domains' and 'Adjusted Term Frequency Vectors (Adjust-TFs). Then, we propose a Domain Adaptive Text Feature Enhancement Method that combines prior domains and utilizes knowledge transfer to solve the classification problem. We conducted experiments across various data sizes on multilingual text categorization datasets. Experimental results demonstrate that our method notably enhances classification accuracy across diverse sample conditions, particularly in low-resource scenarios. This method still performs well in the few-shot setting, which, to some extent, alleviates the training problem of DNNs under this condition. Furthermore, we identify conditions that lead to improved performance in low-resource settings, providing valuable insights for future research.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-4004271/v1"
    },
    {
        "id": 11905,
        "title": "Supporting Trainset Annotation for Text Classification of Incoming Enterprise Documents",
        "authors": "Juris Rats, Inguna Pede",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011113000003269"
    },
    {
        "id": 11906,
        "title": "Concatenate text embeddings for text classification",
        "authors": "Hamid Machhour, Ismail Kassou",
        "published": "2017-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iintec.2017.8325940"
    },
    {
        "id": 11907,
        "title": "Text and Non-text Frame Classification in Video",
        "authors": "Palaiahnakote Shivakumara, Umapada Pal",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-7069-5_3"
    },
    {
        "id": 11908,
        "title": "Analyzing BERT’s Performance Compared to Traditional Text Classification Models",
        "authors": "Bihi Sabiri, Amal Khtira, Bouchra El Asri, Maryem Rhanoui",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011983100003467"
    },
    {
        "id": 11909,
        "title": "Hate Speech Detection and Bias in Supervised Text Classification",
        "authors": "Thomas Davidson",
        "published": "No Date",
        "citations": 0,
        "abstract": "This chapter introduces hate speech detection, describing the process of developing annotated datasets and training machine learning models and highlighting cutting-edge techniques used to improve these methods. The case of hate speech detection provides valuable insight into the promises and pitfalls of supervised text classification for sociological analyses.  A key theme running through the chapter is how ostensibly minor methodological decisions—particularly those related to the development of training datasets—can have profound downstream societal impacts. In particular, I examine racial bias in these systems, explaining why models intended to detect hate speech can discriminate against the groups they are designed to protect and discussing efforts to mitigate these problems. I argue that hate speech detection and other forms of content moderation should be an important topic of sociological inquiry as platforms increasingly use these tools to govern speech on a global scale.",
        "link": "http://dx.doi.org/10.31235/osf.io/23z78"
    },
    {
        "id": 11910,
        "title": "Text Data Labelling using Transformer based Sentence Embeddings and Text Similarity for Text Classification",
        "authors": "Amiya Amitabh Chakrabarty",
        "published": "2022-4-30",
        "citations": 0,
        "abstract": "This paper demonstrates that a lot of time, cost, and complexities can be saved and avoided that would otherwise be used to label the text data for classification purposes. The AI world realizes the importance of labelled data and its use for various NLP applications.  Here, we have labelled and categorized close to 6,000 unlabelled samples into five distinct classes. This labelled dataset was further used for multi-class text classification.  Data labelling task using transformer-based sentence embeddings and applying cosine-based text similarity threshold saved close to 20-30 days of human efforts and multiple human validations with 98.4% of classes correctly labelled as per business validation. Text classification results obtained using this AI labelled data fetched accuracy score and F1 score of 90%.",
        "link": "http://dx.doi.org/10.5121/ijnlc.2022.11201"
    },
    {
        "id": 11911,
        "title": "Information Extraction and Text Transforming Models",
        "authors": "Jyotika Singh",
        "published": "2023-5-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003264774-7"
    },
    {
        "id": 11912,
        "title": "Deep Convolution Neural Network for Extreme Multi-label Text Classification",
        "authors": "Francesco Gargiulo, Stefano Silvestri, Mario Ciampi",
        "published": "2018",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006730506410650"
    },
    {
        "id": 11913,
        "title": "Pre-Trained Prompt-Tuning Based on Adversarial Regularization for Text Classification",
        "authors": "Xiaoying Huang, Baihui Tang, Sanxing Cao",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011922200003612"
    },
    {
        "id": 11914,
        "title": "Hybrid Model of Data Augmentation Methods for Text Classification Task",
        "authors": "Jia Feng, Mahsa Mohaghegh",
        "published": "2021",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010688500003064"
    },
    {
        "id": 11915,
        "title": "Automatic Detection and Classification of Cognitive Distortions in Journaling Text",
        "authors": "Mai Mostafa, Alia El Bolock, Slim Abdennadher",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010713000003058"
    },
    {
        "id": 11916,
        "title": "A Graph-Based Text Classification Model for Web Text Documents",
        "authors": "Ankita Dhar, Niladri Sekhar Dash, Kaushik Roy",
        "published": "2019-11-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780429277573-5"
    },
    {
        "id": 11917,
        "title": "Decision Trees for Text Classification in CS2",
        "authors": "Kevin Lin",
        "published": "2023-3-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3519938"
    },
    {
        "id": 11918,
        "title": "Classification of Text and Non-Text from Bilingual Real-Time Document Using Deep Learning Approach",
        "authors": "SHIVAKUMAR G, Ravikumar M, Shivaprasad B J",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIn this work, we have presented an efficient approach for classification of text and non-text document information from real time office documents images which are bilingual using a deep learning approach i.e., U-net architecture for experimentation purpose. We have created our own dataset containing 2000 document images. Initially pre-processing is applied on the input document images proposed method is compared with other existing methods and obtained accuracy of 99.62% different performance measure i.e., (Specificity, Sensitivity, Precision, F1-Score) used in the experimentation.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2152190/v1"
    },
    {
        "id": 11919,
        "title": "Multi-label Text Classification and Text Adversarial Attack",
        "authors": "Yingxin Song, Zhenyan Liu, Chunxia Zhang",
        "published": "2021-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icaa53760.2021.00098"
    },
    {
        "id": 11920,
        "title": "Text-dominated multimodal text classification with quadruplet attention",
        "authors": "Yuanzhuo Li",
        "published": "2022-12-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1117/12.2665438"
    },
    {
        "id": 11921,
        "title": "An Improved Text Classification Model Based on Part of Speech Features",
        "authors": "",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe authors have requested that this preprint be removed from Research Square.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2627216/v2"
    },
    {
        "id": 11922,
        "title": "Text Classification in Python",
        "authors": "​Mamta Mittal, ​Gopi Battineni, ​Bhimavarapu Usharani, ​Lalit Mohan Goyal",
        "published": "2022-8-11",
        "citations": 1,
        "abstract": "Text classification is an ML technique that assigns a set of predefined tags to\nopen text, and text classifiers have been used to structure, organize, and categorize any\nsort of text data ranging from documents, files, medical studies, to the overall web.\nThis chapter will provide you with the text classification techniques in python. In\naddition, it focuses on training a supervised learning model to do text classification\nwith a real-time case study.",
        "link": "http://dx.doi.org/10.2174/9789815049602122010006"
    },
    {
        "id": 11923,
        "title": "Improving text classification using text summarization",
        "authors": "Abdelkader Kaddour, Nassim Zellal, Lamri Sayad",
        "published": "2022-12-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ntic55069.2022.10100492"
    },
    {
        "id": 11924,
        "title": "A Methodological Framework for Dictionary and Rule-based Text Classification",
        "authors": "Jennifer Abel, Birger Lantow",
        "published": "2019",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008121503300337"
    },
    {
        "id": 11925,
        "title": "Effectiveness of the News Text Classification Test Using the Naïve Bayes’ Classification Text Mining Method",
        "authors": "Yi Ying, T N Mursitama,  Shidarta,  Lohansen",
        "published": "2021-2-1",
        "citations": 7,
        "abstract": "Abstract\nThis study used a quantitative approach created by the author to describe the accuracy of the classification machine learning for news text. In this report we compare the results of the accuracy values obtained using the Naïve Bayes method with other methods to see the effectiveness of the method used. The resulting accuracy value has not reached its maximum and thus it could still be restructured and re-evaluated into a better model. In this case the writer tried to increase the precision value produced in order to make this machine able to predict news that contains sarcasm through modification of the set threshold value. After the threshold value was changed to 0.3, the accuracy value decreased to 61% but the precision value increased to 77% and the error value in the prediction of false positive headlines also increased significantly and only produced 89 errors in predicting sarcasm. The ROC Curve test showed that this machine learning model could still be improved by trying other text preprocessing methods such as the bigrams, tidytext, lemmatization methods, so that the machine will become smarter at predicting the resulting vectors and increase the value of precision and accuracy obtained.",
        "link": "http://dx.doi.org/10.1088/1742-6596/1764/1/012105"
    },
    {
        "id": 11926,
        "title": "Text Generation for Imbalanced Text Classification",
        "authors": "Suphamongkol Akkaradamrongrat, Pornpimon Kachamas, Sukree Sinthupinyo",
        "published": "2019-7",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/jcsse.2019.8864181"
    },
    {
        "id": 11927,
        "title": "Text Classification System",
        "authors": "Taeho Jo",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-32879-4_16"
    },
    {
        "id": 11928,
        "title": "Text Classification Method Based on PEGCN",
        "authors": "Zelin Guo, Ruidong Zhang, Hai Huan",
        "published": "No Date",
        "citations": 1,
        "abstract": "The purpose of text classification is to label the text with known\nlabels. In recent years, the method based on graph neural network (GNN)\nhas achieved good results. However, the existing methods based on GNN\nonly regard the text as the set of co-occurring words, without\nconsidering the position information of each word in the statement.\nMeanwhile, this method mainly extracts node features, but neglects the\nuse of edge features between nodes. To solve these problems, a new text\nclassification method, graph convolutional network using positions and\nedges (PEGCN), is proposed. In the word embedding section, a positional\nencoding input representation is employed to enable the neural network\nto learn the relative positional information among words. Meanwhile, the\ndimension of the adjacency matrix is increased to extract the\nmulti-dimensional edge features. Through experiments on multiple text\nclassification datasets, the proposed method is shown to be superior to\nthe traditional text classification method, and has achieved a maximum\nimprovement of more than 4%.",
        "link": "http://dx.doi.org/10.22541/au.168210369.91223406/v1"
    },
    {
        "id": 11929,
        "title": "Hierarchical Afaan Oromoo News Text Classification",
        "authors": "",
        "published": "2020-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7176/nmmc/88-01"
    },
    {
        "id": 11930,
        "title": "Benchmark Pathology Report Text Corpus with Cancer Type Classification",
        "authors": "Jenna Kefeli, Nicholas Tatonetti",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractIn cancer research, pathology report text is a largely un-tapped data source. Pathology reports are routinely generated, more nuanced than structured data, and contain added insight from pathologists. However, there are no publicly-available datasets for benchmarking report-based models. Two recent advances suggest the urgent need for a benchmark dataset. First, improved optical character recognition (OCR) techniques will make it possible to access older pathology reports in an automated way, increasing data available for analysis. Second, recent improvements in natural language processing (NLP) techniques using AI allow more accurate prediction of clinical targets from text. We apply state-of-the-art OCR and customized post- processing to publicly available report PDFs from The Cancer Genome Atlas, generating a machine-readable corpus of 9,523 reports. We perform a proof-of-principle cancer-type classification across 32 tissues, achieving 0.992 average AU-ROC. This dataset will be useful to researchers across specialties, including research clinicians, clinical trial investigators, and clinical NLP researchers.",
        "link": "http://dx.doi.org/10.1101/2023.08.03.23293618"
    },
    {
        "id": 11931,
        "title": "Development of a Text Classification Framework using Transformer-based Embeddings",
        "authors": "Sumona Yeasmin, Nazia Afrin, Kashfia Saif, Mohammad Huq",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011268000003269"
    },
    {
        "id": 11932,
        "title": "MAGNET: Multi-Label Text Classification using Attention-based Graph Neural Network",
        "authors": "Ankit Pal, Muru Selvakumar, Malaikannan Sankarasubbu",
        "published": "2020",
        "citations": 39,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008940304940505"
    },
    {
        "id": 11933,
        "title": "Image Classification System Not Affected by Background and Text Color",
        "authors": "Taku Akase, Hitoshi Nakao, Lifeng Zhang",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.12792/iciae2018.031"
    },
    {
        "id": 11934,
        "title": "Probabilistic Graphical Model based on BablNet for Arabic Text Classification",
        "authors": "Mounir Gouiouez",
        "published": "2020-7-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5373/jardcs/v12sp7/20202224"
    },
    {
        "id": 11935,
        "title": "Improving Text Classification with Vectors of Reduced Precision",
        "authors": "Krzysztof Wróbel, Maciej Wielgosz, Marcin Pietron, Michal Karwatowski, Jerzy Duda, Aleksander Smywinski-Pohl",
        "published": "2018",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006641505310538"
    },
    {
        "id": 11936,
        "title": "Using Automatic Features for Text-image Classification in Amharic Documents",
        "authors": "Birhanu Belay, Tewodros Habtegebrial, Gebeyehu Belay, Didier Stricker",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0008940704400445"
    },
    {
        "id": 11937,
        "title": "Data Scarcity: Methods to Improve the Quality of Text Classification",
        "authors": "Ingo Glaser, Shabnam Sadegharmaki, Basil Komboz, Florian Matthes",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010268005560564"
    },
    {
        "id": 11938,
        "title": "Multidimensional Text Warehousing for Automated Text Classification",
        "authors": "Jiyun Kim, Han-joon Kim",
        "published": "2018-4",
        "citations": 1,
        "abstract": "This article describes how, in the era of big data, a data warehouse is an integrated multidimensional database that provides the basis for the decision making required to establish crucial business strategies. Efficient, effective analysis requires a data organization system that integrates and manages data of various dimensions. However, conventional data warehousing techniques do not consider the various data manipulation operations required for data-mining activities. With the current explosion of text data, much research has examined text (or document) repositories to support text mining and document retrieval. Therefore, this article presents a method of developing a text warehouse that provides a machine-learning-based text classification service. The document is represented as a term-by-concept matrix using a 3rd-order tensor-based textual representation model, which emphasizes the meaning of words occurring in the document. As a result, the proposed text warehouse makes it possible to develop a semantic Naïve Bayes text classifier only by executing appropriate SQL statements.",
        "link": "http://dx.doi.org/10.4018/jitr.2018040110"
    },
    {
        "id": 11939,
        "title": "Text or Non-text Image Classification using Fully Convolution Network (FCN)",
        "authors": "Neeraj Gupta, Anand Singh Jalal",
        "published": "2020-2",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ic3a48958.2020.233287"
    },
    {
        "id": 11940,
        "title": "Long Text Truncation Algorithm Based on Label Embedding in Text Classification",
        "authors": "Jingang Chen, Shu Lv",
        "published": "2022-9-30",
        "citations": 1,
        "abstract": "The long text classification task has become a hot research topic in the field of text classification due to its long length and redundant information. At present, the common processing methods for long text data, such as the truncation method and pooling method, are prone to the problem of too many sentences or loss of contextual semantic information. To deal with these issues, we present LTTA-LE (Long Text Truncation Algorithm Based on Label Embedding in Text Classification), which consists of three key steps. Firstly, we build a pretraining prefix template and a label word mapping prefix template to obtain the label word embedding, and we realize the joint training of long text and label words. Secondly, we calculate the cosine similarity between the label word embedding and the long text embedding, and we filter the redundant information of the long text to reduce the text length. Finally, a three-stage model training architecture is introduced to effectively improve the classification performance and generalization ability of the model. We conduct comparative experiments on three public long text datasets, and the results show that LTTA-LE has an average F1 improvement of 1.0518% over other algorithms, which proves that our method can achieve satisfactory performance.",
        "link": "http://dx.doi.org/10.3390/app12199874"
    },
    {
        "id": 11941,
        "title": "Why Do We Need Domain-Experts for End-to-End Text Classification? An Overview",
        "authors": "Jakob Andersen",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011605900003393"
    },
    {
        "id": 11942,
        "title": "News Text Classification Using Machine Learning Algorithms",
        "authors": "",
        "published": "2021-6-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.17051/ilkonline.2021.02.282"
    },
    {
        "id": 11943,
        "title": "Algorithmic Assessment of Text based Data Classification in Big Data Sets",
        "authors": "Anjala N.J.",
        "published": "2020-3-31",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5373/jardcs/v12sp4/20201598"
    },
    {
        "id": 11944,
        "title": "Text Classification of Gender-Biased Language in Archival Documentation",
        "authors": "Lucy Havens",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4135/9781529692600"
    },
    {
        "id": 11945,
        "title": "A Supervised Term Relevance Weighting Method for Arabic Text Classification",
        "authors": "Ghassan Khazal Ali, Alexander Zamyatin",
        "published": "2019-11-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5373/jardcs/v11i11/20193189"
    },
    {
        "id": 11946,
        "title": "Methodology for Text Classification using Manually Created Corpora-based Sentiment Dictionary",
        "authors": "Nina Rizun, Wojciech Waloszek",
        "published": "2018",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006932602120220"
    },
    {
        "id": 11947,
        "title": "A Hybrid Approach for Product Classification based on Image and Text Matching",
        "authors": "Sebastian Bast, Christoph Brosch, Rolf Krieger",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011260200003269"
    },
    {
        "id": 11948,
        "title": "Mining M-Grams by a Granular Computing Approach for Text Classification",
        "authors": "Antonino Capillo, Enrico de Santis, Fabio Mascioli, Antonello Rizzi",
        "published": "2020",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010109803500360"
    },
    {
        "id": 11949,
        "title": "Text Classification",
        "authors": "Özgür Sahin",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-6421-8_3"
    },
    {
        "id": 11950,
        "title": "Video Text Type Classification",
        "authors": "Palaiahnakote Shivakumara, Umapada Pal",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-7069-5_7"
    },
    {
        "id": 11951,
        "title": "A Survey on Text Classification Algorithms: From Text to Predictions",
        "authors": "Andrea Gasparetto, Matteo Marcuzzo, Alessandro Zangari, Andrea Albarelli",
        "published": "2022-2-11",
        "citations": 46,
        "abstract": "In recent years, the exponential growth of digital documents has been met by rapid progress in text classification techniques. Newly proposed machine learning algorithms leverage the latest advancements in deep learning methods, allowing for the automatic extraction of expressive features. The swift development of these methods has led to a plethora of strategies to encode natural language into machine-interpretable data. The latest language modelling algorithms are used in conjunction with ad hoc preprocessing procedures, of which the description is often omitted in favour of a more detailed explanation of the classification step. This paper offers a concise review of recent text classification models, with emphasis on the flow of data, from raw text to output labels. We highlight the differences between earlier methods and more recent, deep learning-based methods in both their functioning and in how they transform input data. To give a better perspective on the text classification landscape, we provide an overview of datasets for the English language, as well as supplying instructions for the synthesis of two new multilabel datasets, which we found to be particularly scarce in this setting. Finally, we provide an outline of new experimental results and discuss the open research challenges posed by deep learning-based language models.",
        "link": "http://dx.doi.org/10.3390/info13020083"
    },
    {
        "id": 11952,
        "title": "Boosting Text Classification Performance on Sexist Tweets by Text Augmentation and Text Generation Using a Combination of Knowledge Graphs",
        "authors": "Sima Sharifirad, Borna Jafarpour, Stan Matwin",
        "published": "2018",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/w18-5114"
    },
    {
        "id": 11953,
        "title": "Text Classification Using Feature Extraction and Classification Model",
        "authors": "Anirudh Rana, Vishal Bharti",
        "published": "2022-12-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icac3n56670.2022.10074017"
    },
    {
        "id": 11954,
        "title": "Facebook text posts classification with TensorFlow",
        "authors": "О.О Druzhynin,  , V.V. Nekhai, O.A. Prila,  ,  ",
        "published": "2019-9-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.34121/1028-9763-2019-3-47-54"
    },
    {
        "id": 11955,
        "title": "An automated new approach in fast text classification (fastText)",
        "authors": "Birol Kuyumcu, Cuneyt Aksakalli, Selman Delil",
        "published": "2019-6-28",
        "citations": 19,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3342827.3342828"
    },
    {
        "id": 11956,
        "title": "Classification and Textual Function of Conclusions in Text and Paragraphs",
        "authors": "Biyu Wu, Jiayao Fan, Hui Sun",
        "published": "2023-4",
        "citations": 0,
        "abstract": "Text and paragraph are two forms of discourse. Their conclusions are similar in structure and semantics. There are three types of conclusion sentence in paragraphs: closing sentence, comment sentence, concluding sentence. The closing sentence is the restatement of the theme of the paragraph and generally has a discourse marker indicating a summary; The comment sentence is the remark on the topic of the paragraph; The concluding sentence is the ending of the paragraph with both summary and comment. When the conclusion sentence is in the thesis paragraph, it is also the thesis statement of the text. There are two types of paragraphs in the conclusion part of the text: the transitional paragraph and the conclusion paragraph. The latter is a summary and comment on the topic of the text. Usually, the topic sentence of the conclusion paragraph, often accompanied by discourse markers indicating the general conclusion, is the closing sentence of the text, which forms a circulation in viewpoint with the thesis statement of the text through lexical cohesion of keyword repetition. The conclusion sentence of the conclusion paragraph is the comment sentence of the text, which forms an emotional echo with the title of the text and realizes the sublimation of the theme.",
        "link": "http://dx.doi.org/10.18178/ijlll.2023.9.2.397"
    },
    {
        "id": 11957,
        "title": "Attention Based Encoder Architecture for Automatic Text Classification: A Case Study on Text-news Classification",
        "authors": "Joydeep Sinha Chowdhury,  , Tanmoy Roy",
        "published": "2022-4-3",
        "citations": 0,
        "abstract": "Text classification is a classical problem of natural language processing where given texts are classified into relevant classes. Text classification techniques are extensively used in finding news categories, search engine optimization, automated textual response and many more. With the exponential growth of digital data, it is inevitable that an automatic classification of documents is needed for efficient information retrieval and document archival. Over the years, text classification problems are approached by using classical machine learning techniques like naive bayes(NB), support vector machine(SVM), logistic regression(LR), random forest(RF) and others. In this article, an Attention based deep learning (DL) model is proposed and applied to the news corpus and then the results are compared with the results of classical machine learning models. A comparative analysis of classification accuracy of the DL model with prominent models like LR, RF and NB are presented in this work.",
        "link": "http://dx.doi.org/10.55041/ijsrem12107"
    },
    {
        "id": 11958,
        "title": "A comparative study of Naive Bayes Classifiers with improved technique on Text Classification",
        "authors": "Chingmuankim Naulak",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Experiment was carried out on imbalanced data having positive and negative labels as 0 and 1. These datasets after training were tested on Gaussian Naive Bayes, Bernoulli Naive Bayes and Multinomial Naive Bayes with improved technique using tf-idf and ngram. The results obtained were then compared with old model result that make use of BagofWords. On testing it is found that there is a 2-3% improvement in the model's performance.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.19918360.v1"
    },
    {
        "id": 11959,
        "title": "Fine-Grained and Coarse-Grained Contrastive Learning for Text Classification",
        "authors": "Shaokang Zhang, Ning Ran",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4691077"
    },
    {
        "id": 11960,
        "title": "Classification",
        "authors": "Emil Hvitfeldt, Julia Silge",
        "published": "2021-9-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003093459-10"
    },
    {
        "id": 11961,
        "title": "A comparative study of Naive Bayes Classifiers with improved technique on Text Classification",
        "authors": "Chingmuankim Naulak",
        "published": "No Date",
        "citations": 0,
        "abstract": "<p>Experiment was carried out on imbalanced data having positive and negative labels as 0 and 1. These datasets after training were tested on Gaussian Naive Bayes, Bernoulli Naive Bayes and Multinomial Naive Bayes with improved technique using tf-idf and ngram. The results obtained were then compared with old model result that make use of BagofWords. On testing it is found that there is a 2-3% improvement in the model's performance.</p>",
        "link": "http://dx.doi.org/10.36227/techrxiv.19918360"
    },
    {
        "id": 11962,
        "title": "Hybrid Classical-Quantum Transfer Learning for Text Classification",
        "authors": "Ebrahim Ardeshir-Larijani, Mehdi Nasiri",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nQuantum Machine Learning (QML) is a promising field that combines the power of quantum computing with machine learning. Variational quantum circuits, where parameters of circuits are learned classically, have been widely used in many recent applications of QML. This is an instance of a hybrid quantum-classical framework, where both classical and quantum components are present. However, applying these techniques to applications involving massive data is a challenging task. One way to overcome this, is using the concept of classical-quantum transfer learning with the help of dressed quantum circuit, introduced recently, where the underlying neural architecture is pre-trained classically, but at the final steps (decision layer), a quantum circuit is used, followed by quantum measurements and post-processing to classify images with high precision. In this paper, we applied hybrid classical-quantum transfer learning to another task of massive data processing, i.e. Natural Language Processing (NLP). We show how to (binary) classify short texts (e.g., SMS) with classical-quantum transfer learning, which was originally applied to image processing only. Our quantum network was pre-trained by Bidirectional Encoder Representations from the Transformers (BERT) model, and its variational quantum circuit is fine-tuned for text processing. We evaluated the performance of our hybrid neural architecture using the Receiver Operating Characteristic (ROC) curve, which is typically used in the evaluation of classification problems. The results indicate high precision as well as lower loss function. To our knowledge, our work is the first application of quantum transfer learning to the area of NLP. Finally a comparison with a tool that uses learning but in a different way than transfer learning is presented",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3094921/v1"
    },
    {
        "id": 11963,
        "title": "Text Classification in the Brazilian Legal Domain",
        "authors": "Gustavo Coelho, Alimed Celecia, Jefferson de Sousa, Melissa Cavaliere, Maria Lima, Ana Mangeth, Isabella Frajhof, Cesar Cury, Marco Casanova",
        "published": "2022",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011062000003179"
    },
    {
        "id": 11964,
        "title": "Towards More Reliable Text Classification on Edge Devices via a Human-in-the-Loop",
        "authors": "Jakob Andersen, Olaf Zukunft",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010980600003116"
    },
    {
        "id": 11965,
        "title": "User Interface for Text and Non-Text Classification",
        "authors": "Thanh Thi Xuan Lam, Anh Duc Le, Masaki Nakagawa",
        "published": "2019-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdarw.2019.20044"
    },
    {
        "id": 11966,
        "title": "Nanoscale Text Classification with Bi-LSTM: Enhancing Precision",
        "authors": "",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.17756/nwj.2023-s4-070"
    },
    {
        "id": 11967,
        "title": "Application Optimization of NLP System under Deep Learning Technology in Text Semantics and Text Classification",
        "authors": "Gang Jin",
        "published": "2022-9",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icenit57306.2022.00068"
    },
    {
        "id": 11968,
        "title": "Semantic Text Encoding for Text Classification Using Convolutional Neural Networks",
        "authors": "Ignazio Gallo, Shah Nawaz, Alessandro Calefati",
        "published": "2017-11",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icdar.2017.323"
    },
    {
        "id": 11969,
        "title": "Benchmark Pathology Report Text Corpus with Cancer Type Classification",
        "authors": "Jenna Kefeli, Nicholas P. Tatonetti",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4418621"
    },
    {
        "id": 11970,
        "title": "Text Analysis in Python for Social Scientists",
        "authors": "Dirk Hovy",
        "published": "2022-3-31",
        "citations": 0,
        "abstract": "Text contains a wealth of information about about a wide variety of sociocultural constructs. Automated prediction methods can infer these quantities (sentiment analysis is probably the most well-known application). However, there is virtually no limit to the kinds of things we can predict from text: power, trust, misogyny, are all signaled in language. These algorithms easily scale to corpus sizes infeasible for manual analysis. Prediction algorithms have become steadily more powerful, especially with the advent of neural network methods. However, applying these techniques usually requires profound programming knowledge and machine learning expertise. As a result, many social scientists do not apply them. This Element provides the working social scientist with an overview of the most common methods for text classification, an intuition of their applicability, and Python code to execute them. It covers both the ethical foundations of such work as well as the emerging potential of neural network methods.",
        "link": "http://dx.doi.org/10.1017/9781108960885"
    }
]