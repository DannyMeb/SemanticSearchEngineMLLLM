[
    {
        "id": 28505,
        "title": "Uni-NLX: Unifying Textual Explanations for Vision and Vision-Language Tasks",
        "authors": "Fawaz Sammani, Nikos Deligiannis",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00498"
    },
    {
        "id": 28506,
        "title": "Guest Editorial: Learning from limited annotations for computer vision tasks",
        "authors": "Yazhou Yao, Wenguan Wang, Qiang Wu, Dongfang Liu, Jin Zheng",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12229"
    },
    {
        "id": 28507,
        "title": "Difficulty Estimation with Action Scores for Computer Vision Tasks",
        "authors": "Octavio Arriaga, Sebastian Palacio, Matias Valdenegro-Toro",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00030"
    },
    {
        "id": 28508,
        "title": "Fully synthetic training for image restoration tasks",
        "authors": "Raphaël Achddou, Yann Gousseau, Saïd Ladjal",
        "published": "2023-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103723"
    },
    {
        "id": 28509,
        "title": "Patch-based Privacy Preserving Neural Network for Vision Tasks",
        "authors": "Mitsuhiro Mabuchi, Tetsuya Ishikawa",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00160"
    },
    {
        "id": 28510,
        "title": "Comparison of Large Language And Vision Models on Representative Downstream Tasks",
        "authors": "Huitong Chen",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icicml60161.2023.10424913"
    },
    {
        "id": 28511,
        "title": "Generating of synthetic datasets using diffusion models for solving computer vision tasks in urban applications",
        "authors": "Ilya Reutov",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.procs.2023.12.036"
    },
    {
        "id": 28512,
        "title": "Synthetic Driver Image Generation for Human Pose-Related Tasks",
        "authors": "Romain Guesdon, Carlos Crispim-Junior, Laure Rodet",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011780800003417"
    },
    {
        "id": 28513,
        "title": "ZiCo-BC: A Bias Corrected Zero-Shot NAS for Vision Tasks",
        "authors": "Kartikeya Bhardwaj, Hsin-Pai Cheng, Sweta Priyadarshi, Zhuojin Li",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00145"
    },
    {
        "id": 28514,
        "title": "Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding",
        "authors": "Joshua Feinglass, Yezhou Yang",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00434"
    },
    {
        "id": 28515,
        "title": "DONNAv2 - Lightweight Neural Architecture Search for Vision tasks",
        "authors": "Sweta Priyadarshi, Tianyu Jiang, Hsin-Pai Cheng, Sendil Krishna, Viswanath Ganapathy, Chirag Patel",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00149"
    },
    {
        "id": 28516,
        "title": "Hyneter:Hybrid Network Transformer for Multiple Computer Vision Tasks",
        "authors": "Dong Chen, Duoqian Miao, Xuerong Zhao",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tii.2024.3367043"
    },
    {
        "id": 28517,
        "title": "Vision-Language Models Performing Zero-Shot Tasks Exhibit Disparities Between Gender Groups",
        "authors": "Melissa Hall, Laura Gustafson, Aaron Adcock, Ishan Misra, Candace Ross",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00294"
    },
    {
        "id": 28518,
        "title": "Structure-Encoding Auxiliary Tasks for Improved Visual Representation in Vision-and-Language Navigation",
        "authors": "Chia-Wen Kuo, Chih-Yao Ma, Judy Hoffman, Zsolt Kira",
        "published": "2023-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00116"
    },
    {
        "id": 28519,
        "title": "How Close Are Other Computer Vision Tasks to Deepfake Detection?",
        "authors": "Huy H. Nguyen, Junichi Yamagishi, Isao Echizen",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcb57857.2023.10448744"
    },
    {
        "id": 28520,
        "title": "Box-based Refinement for Weakly Supervised and Unsupervised Localization Tasks",
        "authors": "Eyal Gomel, Tal Shaharbany, Lior Wolf",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01470"
    },
    {
        "id": 28521,
        "title": "FAME-ViL: Multi-Tasking Vision-Language Model for Heterogeneous Fashion Tasks",
        "authors": "Xiao Han, Xiatian Zhu, Licheng Yu, Li Zhang, Yi-Zhe Song, Tao Xiang",
        "published": "2023-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00262"
    },
    {
        "id": 28522,
        "title": "Finding and Navigating to Humans in Complex Environments for Assistive Tasks",
        "authors": "Asfand Yaar, Antonino Furnari, Marco Rosano, Aki Härmä, Giovanni Farinella",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012271700003660"
    },
    {
        "id": 28523,
        "title": "Video Anomaly Detection via Sequentially Learning Multiple Pretext Tasks",
        "authors": "Chenrui Shi, Che Sun, Yuwei Wu, Yunde Jia",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00948"
    },
    {
        "id": 28524,
        "title": "Distilling from Similar Tasks for Transfer Learning on a Budget",
        "authors": "Kenneth Borup, Cheng Perng Phoo, Bharath Hariharan",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01050"
    },
    {
        "id": 28525,
        "title": "Efficiency study of VGG networks in autonomous driving tasks",
        "authors": "Junhua Qi",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3021397"
    },
    {
        "id": 28526,
        "title": "Computer vision models application in the current system on object detection tasks",
        "authors": "Feilian Huang",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "The implementation of object detection algorithms would be helpful to the various fields of the current time. When object detection is applied to the surveillance camera system, it will be more efficient to locate crimes or find lost kids. This paper will investigate the performance of different object detection algorithms in a real-world scenario. With experimentation, CenterNet++ outperforms YOLO and MaskRCNN, two traditional and classic object detection algorithms, on the MS COCO dataset, which concludes that CenterNet++ can ensure both accuracy and speed.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/4/20230335"
    },
    {
        "id": 28527,
        "title": "The Dance of Logic and Unpredictability: Examining the Predictability of User Behavior on Visual Analytics Tasks",
        "authors": "Alvitta Ottley",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012671100003660"
    },
    {
        "id": 28528,
        "title": "Exploiting Proximity-Aware Tasks for Embodied Social Navigation",
        "authors": "Enrico Cancelli, Tommaso Campari, Luciano Serafini, Angel X. Chang, Lamberto Ballan",
        "published": "2023-10-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01006"
    },
    {
        "id": 28529,
        "title": "I can’t believe there’s no images! : Learning Visual Tasks Using Only Language Supervision",
        "authors": "Sophia Gu, Christopher Clark, Aniruddha Kembhavi",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00252"
    },
    {
        "id": 28530,
        "title": "3D visualization of HPC Tasks Scheduling Algorithm",
        "authors": "Pavel Alexandrovich Vasev",
        "published": "2023",
        "citations": 0,
        "abstract": "The paper is devoted to the issue of visualization of the algorithm for scheduling parallel tasks. Task planning is a key part of the online visualization and parallel programming environment developed by the author. When programming a parallel version of one application task, a suspicion arose that the scheduling algorithm does not optimally distribute the load between the performers. In this connection, it was decided to visualize its work in order to see the overall picture and possible problem areas of the algorithm. The display view works in three-dimensional space and visualizes the assignment of tasks with dots. The coordinates of the points are determined by the logical time, the sequence number of the core (performer), and the sequence number of the data block from the decomposition of the task. The color of the dots is set by the task type. Dependencies between data tasks are shown in segments. The constructed view of the display successfully coped with the task, and the planning algorithm was improved.",
        "keywords": "",
        "link": "http://dx.doi.org/10.20948/graphicon-2023-341-353"
    },
    {
        "id": 28531,
        "title": "Computer Vision Tasks for Ambient Intelligence in Children’s Health",
        "authors": "Danila Germanese, Sara Colantonio, Marco Del Coco, Pierluigi Carcagnì, Marco Leo",
        "published": "2023-10-6",
        "citations": 0,
        "abstract": "Computer vision is a powerful tool for healthcare applications since it can provide objective diagnosis and assessment of pathologies, not depending on clinicians’ skills and experiences. It can also help speed-up population screening, reducing health care costs and improving the quality of service. Several works summarise applications and systems in medical imaging, whereas less work is devoted to surveying approaches for healthcare goals using ambient intelligence, i.e., observing individuals in natural settings. Even more, there is a lack of papers providing a survey of works exhaustively covering computer vision applications for children’s health, which is a particularly challenging research area considering that most existing computer vision technologies have been trained and tested only on adults. The aim of this paper is then to survey, for the first time in the literature, the papers covering children’s health-related issues by ambient intelligence methods and systems relying on computer vision.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/info14100548"
    },
    {
        "id": 28532,
        "title": "SINC: Self-Supervised In-Context Learning for Vision-Language Tasks",
        "authors": "Yi-Syuan Chen, Yun-Zhu Song, Cheng Yu Yeo, Bei Liu, Jianlong Fu, Hong-Han Shuai",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01415"
    },
    {
        "id": 28533,
        "title": "Image as a Foreign Language: BEIT Pretraining for Vision and Vision-Language Tasks",
        "authors": "Wenhui Wang, Hangbo Bao, Li Dong, Johan Bjorck, Zhiliang Peng, Qiang Liu, Kriti Aggarwal, Owais Khan Mohammed, Saksham Singhal, Subhojit Som, Furu Wei",
        "published": "2023-6",
        "citations": 94,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01838"
    },
    {
        "id": 28534,
        "title": "Uni-Perceiver v2: A Generalist Model for Large-Scale Vision and Vision-Language Tasks",
        "authors": "Hao Li, Jinguo Zhu, Xiaohu Jiang, Xizhou Zhu, Hongsheng Li, Chun Yuan, Xiaohua Wang, Yu Qiao, Xiaogang Wang, Wenhai Wang, Jifeng Dai",
        "published": "2023-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00264"
    },
    {
        "id": 28535,
        "title": "Transfer Robustness to Downstream Tasks Through Sampling Adversarial Perturbations",
        "authors": "Ivan Reyes-Amezcua, Gilberto Ochoa-Ruiz, Andres Mendez-Vazquez",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "Due to the vulnerability of deep neural networks to adversarial attacks, adversarial robustness has grown to be a crucial problem in deep learning. Recent research has demonstrated that even small perturbations to the input data can have a large impact on the model’s output, exposing them susceptible to malicious attacks. In this work, we propose Delta Data Augmentation (DDA), a data augmentation method for enhancing transfer robustness by sampling extracted perturbations from trained models against adversarial attacks. The main idea of our work is to generate adversarial perturbations and to apply them to downstream datasets in a data augmentation fashion. Here we demonstrate, through extensive experimentation the advantages of our data augmentation method over the current State-of-the-Art in Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD) attacks for CIFAR10 dataset.",
        "keywords": "",
        "link": "http://dx.doi.org/10.52591/lxai2023061811"
    },
    {
        "id": 28536,
        "title": "Intelligent Execution of Computer Vision Tasks in Delay-Constrained UAV-Aided Networks",
        "authors": "Nancy Varshney, Corrado Puligheddu, Carla Fabiana Chiasserini, Claudio Casetti, Swades De",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/gcwkshps58843.2023.10464820"
    },
    {
        "id": 28537,
        "title": "Sense of Presence, Realism, and Simulation Sickness in Operational Tasks: A Comparative Analysis of Virtual and Mixed Reality",
        "authors": "Giorgio Ballestin, Heike Diepeveen",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012256300003660"
    },
    {
        "id": 28538,
        "title": "Beyond AI Exposure: Which Tasks are Cost-Effective to Automate with Computer Vision?",
        "authors": "Maja Svanberg, Wensu Li, Martin Fleming, Brian Goehring, Neil Thompson",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4700751"
    },
    {
        "id": 28539,
        "title": "SYENet: A Simple Yet Effective Network for Multiple Low-Level Vision Tasks with Real-time Performance on Mobile Device",
        "authors": "Weiran Gou, Ziyao Yi, Yan Xiang, Shaoqing Li, Zibin Liu, Dehui Kong, Ke Xu",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01119"
    },
    {
        "id": 28540,
        "title": "Neural Architecture Search for Dense Prediction Tasks in Computer Vision",
        "authors": "Rohit Mohan, Thomas Elsken, Arber Zela, Jan Hendrik Metzen, Benedikt Staffler, Thomas Brox, Abhinav Valada, Frank Hutter",
        "published": "2023-7",
        "citations": 2,
        "abstract": "AbstractThe success of deep learning in recent years has lead to a rising demand for neural network architecture engineering. As a consequence, neural architecture search (NAS), which aims at automatically designing neural network architectures in a data-driven manner rather than manually, has evolved as a popular field of research. With the advent of weight sharing strategies across architectures, NAS has become applicable to a much wider range of problems. In particular, there are now many publications for dense prediction tasks in computer vision that require pixel-level predictions, such as semantic segmentation or object detection. These tasks come with novel challenges, such as higher memory footprints due to high-resolution data, learning multi-scale representations, longer training times, and more complex and larger neural architectures. In this manuscript, we provide an overview of NAS for dense prediction tasks by elaborating on these novel challenges and surveying ways to address them to ease future research and application of existing methods to novel problems.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11263-023-01785-y"
    },
    {
        "id": 28541,
        "title": "EASUM: Enhancing Affective State Understanding through Joint Sentiment and Emotion Modeling for Multimodal Tasks",
        "authors": "Yewon Hwang, Jong-Hwan Kim",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00557"
    },
    {
        "id": 28542,
        "title": "Fast GraspNeXt: A Fast Self-Attention Neural Network Architecture for Multi-task Learning in Computer Vision Tasks for Robotic Grasping on the Edge",
        "authors": "Alexander Wong, Yifan Wu, Saad Abbasi, Saeejith Nair, Yuhao Chen, Mohammad Javad Shafiee",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00224"
    },
    {
        "id": 28543,
        "title": "Video Task Decathlon: Unifying Image and Video Tasks in Autonomous Driving",
        "authors": "Thomas E. Huang, Yifan Liu, Luc Van Gool, Fisher Yu",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00794"
    },
    {
        "id": 28544,
        "title": "Evaluation of the impact of lossy compression on event camera-based computer vision tasks",
        "authors": "Bowen Huang, Davi Lazzarotto, Touradj Ebrahimi",
        "published": "2023-10-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2676419"
    },
    {
        "id": 28545,
        "title": "Performance optimization and acceleration of convolutional neural networks in computer vision tasks",
        "authors": "Yongcong Chen, Yuhao Zeng, Yunqing Deng",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3026813"
    },
    {
        "id": 28546,
        "title": "Q: How to Specialize Large Vision-Language Models to Data-Scarce VQA Tasks? A: Self-Train on Unlabeled Images!",
        "authors": "Zaid Khan, BG Vijay Kumar, Samuel Schulter, Xiang Yu, Yun Fu, Manmohan Chandraker",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01441"
    },
    {
        "id": 28547,
        "title": "Global key knowledge distillation framework",
        "authors": "Junhuang Wang, Weiwei Zhang, Yufeng Guo, Peng Liang, Ming Ji, Chenghui Zhen, Hanmeng Wang",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103902"
    },
    {
        "id": 28548,
        "title": "Automated CNN Architectural Design: A Simple and Efficient Methodology for Computer Vision Tasks",
        "authors": "Ali Al Bataineh, Devinder Kaur, Mahmood Al-khassaweneh, Esraa Al-sharoa",
        "published": "2023-2-24",
        "citations": 6,
        "abstract": "Convolutional neural networks (CNN) have transformed the field of computer vision by enabling the automatic extraction of features, obviating the need for manual feature engineering. Despite their success, identifying an optimal architecture for a particular task can be a time-consuming and challenging process due to the vast space of possible network designs. To address this, we propose a novel neural architecture search (NAS) framework that utilizes the clonal selection algorithm (CSA) to automatically design high-quality CNN architectures for image classification problems. Our approach uses an integer vector representation to encode CNN architectures and hyperparameters, combined with a truncated Gaussian mutation scheme that enables efficient exploration of the search space. We evaluated the proposed method on six challenging EMNIST benchmark datasets for handwritten digit recognition, and our results demonstrate that it outperforms nearly all existing approaches. In addition, our approach produces state-of-the-art performance while having fewer trainable parameters than other methods, making it low-cost, simple, and reusable for application to multiple datasets.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math11051141"
    },
    {
        "id": 28549,
        "title": "Understanding How Different Visual Aids for Augmented Reality Influence Tool-Patient Alignment in Surgical Tasks: A Preliminary Study",
        "authors": "Stefano Stradiotti, Nicolas Emiliani, Emanuela Marcelli, Laura Cercenelli",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012611800003660"
    },
    {
        "id": 28550,
        "title": "Learning key lines for multi-object tracking",
        "authors": "Yi-Fan Li, Hong-Bing Ji, Xi Chen, Yong-Liang Yang, Yu-Kun Lai",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2024.103973"
    },
    {
        "id": 28551,
        "title": "Joint optical design for computer vision tasks: challenges and solutions",
        "authors": "Geoffroi Côté, Simon Thibault, Jean-Francois Lalonde, Felix Heide",
        "published": "2023-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2691993"
    },
    {
        "id": 28552,
        "title": "GMC: A general framework of multi-stage context learning and utilization for visual detection tasks",
        "authors": "Xuan Wang, Hao Tang, Zhigang Zhu",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2024.103944"
    },
    {
        "id": 28553,
        "title": "UnLoc: A Unified Framework for Video Localization Tasks",
        "authors": "Shen Yan, Xuehan Xiong, Arsha Nagrani, Anurag Arnab, Zhonghao Wang, Weina Ge, David Ross, Cordelia Schmid",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01253"
    },
    {
        "id": 28554,
        "title": "Causal reasoning in typical computer vision tasks",
        "authors": "KeXuan Zhang, QiYu Sun, ChaoQiang Zhao, Yang Tang",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11431-023-2502-9"
    },
    {
        "id": 28555,
        "title": "Auxiliary Tasks Benefit 3D Skeleton-based Human Motion Prediction",
        "authors": "Chenxin Xu, Robby T. Tan, Yuhong Tan, Siheng Chen, Xinchao Wang, Yanfeng Wang",
        "published": "2023-10-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00872"
    },
    {
        "id": 28556,
        "title": "DropMAE: Masked Autoencoders with Spatial-Attention Dropout for Tracking Tasks",
        "authors": "Qiangqiang Wu, Tianyu Yang, Ziquan Liu, Baoyuan Wu, Ying Shan, Antoni B. Chan",
        "published": "2023-6",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01399"
    },
    {
        "id": 28557,
        "title": "Tag‐inferring and tag‐guided Transformer for image captioning",
        "authors": "Yaohua Yi, Yinkai Liang, Dezhu Kong, Ziwei Tang, Jibing Peng",
        "published": "2024-3-22",
        "citations": 0,
        "abstract": "AbstractImage captioning is an important task for understanding images. Recently, many studies have used tags to build alignments between image information and language information. However, existing methods ignore the problem that simple semantic tags have difficulty expressing the detailed semantics for different image contents. Therefore, the authors propose a tag‐inferring and tag‐guided Transformer for image captioning to generate fine‐grained captions. First, a tag‐inferring encoder is proposed, which uses the tags extracted by the scene graph model to infer tags with deeper semantic information. Then, with the obtained deep tag information, a tag‐guided decoder that includes short‐term attention to improve the features of words in the sentence and gated cross‐modal attention to combine image features, tag features and language features to produce informative semantic features is proposed. Finally, the word probability distribution of all positions in the sequence is calculated to generate descriptions for the image. The experiments demonstrate that the authors’ method can combine tags to obtain precise captions and that it achieves competitive performance with a 40.6% BLEU‐4 score and 135.3% CIDEr score on the MSCOCO data set.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12280"
    },
    {
        "id": 28558,
        "title": "Vision Transformer-based recognition tasks: a critical review",
        "authors": "Zhou Lijuan,  , Mao Jianing",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.11834/jig.220895"
    },
    {
        "id": 28559,
        "title": "Content-Aware Image Color Editing with Auxiliary Color Restoration Tasks",
        "authors": "Yixuan Ren, Jing Shi, Zhifei Zhang, Yifei Fan, Zhe Lin, Bo He, Abhinav Shrivastava",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00511"
    },
    {
        "id": 28560,
        "title": "CO-Net: Learning Multiple Point Cloud Tasks at Once with A Cohesive Network",
        "authors": "Tao Xie, Ke Wang, Siyi Lu, Yukun Zhang, Kun Dai, Xiaoyu Li, Jie Xu, Li Wang, Lijun Zhao, Xinyu Zhang, Ruifeng Li",
        "published": "2023-10-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00326"
    },
    {
        "id": 28561,
        "title": "Research progress of computer vision tasks based on deep learning and SAE network",
        "authors": "Shijia Ling, Qiaoling Yi, Banru Lan, Liangfang Liu",
        "published": "2023-7-1",
        "citations": 0,
        "abstract": "Abstract\nIn recent years, artificial intelligence has gradually become the core driving force of a new round of scientific and technological revolution and industrial transformation, and is exerting a profound impact on all aspects of human life. With the rapid development of Internet big data and high-performance parallel computing, relevant research in computer vision has made significant progress in the past few years, becoming one of the important application branches in the field of artificial intelligence. The exercise of image classification forming part of computer vision tasks involves a large amount of computation, and training based on traditional deep learning (DL) classification models typically involves slow training and low accuracy in many parameters. Thus, in order to solve these problems, an image classification model based on DL and SAE network was proposed. Firstly, the main research of computer vision task-image classification is introduced in detail. Then, the combination framework of deep neural network and SAE network is built. At the same time, the deep neural network was used to carry out convolution operation of the parameters learned by SAE and extract each feature of the image with neurons, so as to improve the training accuracy of the deep neural network. Finally, the traditional deep neural network and SAE network were used for comparative experiment and analysis. Experimental results show that the proposed method has a certain degree of improvement in image classification accuracy compared with traditional deep neural network and SAE network, and the accuracy reaches 97.13%.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2478/amns.2021.2.00271"
    },
    {
        "id": 28562,
        "title": "Perceptual Artifacts Localization for Image Synthesis Tasks",
        "authors": "Lingzhi Zhang, Zhengjie Xu, Connelly Barnes, Yuqian Zhou, Qing Liu, He Zhang, Sohrab Amirghodsi, Zhe Lin, Eli Shechtman, Jianbo Shi",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00697"
    },
    {
        "id": 28563,
        "title": "fAIlureNotes: Supporting Designers in Understanding the Limits of AI Models for Computer Vision Tasks",
        "authors": "Steven Moore, Q. Vera Liao, Hariharan Subramonyam",
        "published": "2023-4-19",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3544548.3581242"
    },
    {
        "id": 28564,
        "title": "On the Importance of Accurate Geometry Data for Dense 3D Vision Tasks",
        "authors": "HyunJun Jung, Patrick Ruhkamp, Guangyao Zhai, Nikolas Brasch, Yitong Li, Yannick Verdie, Jifei Song, Yiren Zhou, Anil Armagan, Slobodan Ilic, Ales Leonardis, Nassir Navab, Benjamin Busam",
        "published": "2023-6",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00082"
    },
    {
        "id": 28565,
        "title": "A Review of Generative Adversarial Networks for Computer Vision Tasks",
        "authors": "Ana-Maria Simion, Șerban Radu, Adina Magda Florea",
        "published": "2024-2-9",
        "citations": 0,
        "abstract": "In recent years, computer vision tasks have gained a lot of popularity, accompanied by the development of numerous powerful architectures consistently delivering outstanding results when applied to well-annotated datasets. However, acquiring a high-quality dataset remains a challenge, particularly in sensitive domains like medical imaging, where expense and ethical concerns represent a challenge. Generative adversarial networks (GANs) offer a possible solution to artificially expand datasets, providing a basic resource for applications requiring large and diverse data. This work presents a thorough review and comparative analysis of the most promising GAN architectures. This review is intended to serve as a valuable reference for selecting the most suitable architecture for diverse projects, diminishing the challenges posed by limited and constrained datasets. Furthermore, we developed practical experimentation, focusing on the augmentation of a medical dataset derived from a colonoscopy video. We also applied one of the GAN architectures outlined in our work to a dataset consisting of histopathology images. The goal was to illustrate how GANs can enhance and augment datasets, showcasing their potential to improve overall data quality. Through this research, we aim to contribute to the broader understanding and application of GANs in scenarios where dataset scarcity poses a significant obstacle, particularly in medical imaging applications.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics13040713"
    },
    {
        "id": 28566,
        "title": "All in Tokens: Unifying Output Space of Visual Tasks via Soft Token",
        "authors": "Jia Ning, Chen Li, Zheng Zhang, Chunyu Wang, Zigang Geng, Qi Dai, Kun He, Han Hu",
        "published": "2023-10-1",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01822"
    },
    {
        "id": 28567,
        "title": "Diff attention: A novel attention scheme for person re-identification",
        "authors": "Xin Lin, Li Zhu, Shuyu Yang, Yaxiong Wang",
        "published": "2023-2",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103623"
    },
    {
        "id": 28568,
        "title": "Online object tracking based interactive attention",
        "authors": "Hongmei Wang, Fan Guo",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103809"
    },
    {
        "id": 28569,
        "title": "Optimal use of attention mechanisms: comparative study in U-Net for image segmentation tasks",
        "authors": "Zhou Qiangong, Su Guanzhang, Chen Jiayi, Chen Yuangen, Zhou Youyu",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3021498"
    },
    {
        "id": 28570,
        "title": "Application of Artificial Intelligence in Remote Monitoring Data Processing Tasks",
        "authors": "Yuri Yurievich Gromov, Igor Nikolaevich Ishchuk, V.V. Rodionov",
        "published": "2023",
        "citations": 0,
        "abstract": "This article presents a method for classifying multi-time multispectral images of the Earth's surface using the convolutional deep learning neural network U-net. Images of visible and infrared wavelengths were obtained using a multispectral optoelectronic system of an unmanned aerial vehicle and were used to construct orthophotoplanes of the terrain. Based on the data obtained, a neural network was trained to solve the problems of detecting man-made objects. The method of intelligent recognition of remote monitoring objects, based on deep learning and assessments of thermophysical parameters, allows you to create a phono-target environment using a genetic algorithm. This algorithm solves the coefficient inverse problem of thermal conductivity and provides estimates of the thermophysical parameters of materials. To train the model, 18 classes of objects were introduced, which were studied based on the difference in thermal contrast between man-made objects and the background (anthropogenic or natural landscape). The survey of the earth's surface was carried out 6 times during the day with an interval of 4 hours. The experiment was conducted in the summer of 2021, on specific dates of August 4-5. In the tasks of detecting and classifying man-made objects, it was found that the model demonstrates applicability with varying reliability. The conducted research shows that during the operation of the model, the desired classes of objects were discovered.",
        "keywords": "",
        "link": "http://dx.doi.org/10.20948/graphicon-2023-727-735"
    },
    {
        "id": 28571,
        "title": "Individual differences in patch leaving strategy in visual foraging tasks",
        "authors": "Walden Li, Mackenzie Siesel, Andrew Leber",
        "published": "2023-8-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.5917"
    },
    {
        "id": 28572,
        "title": "GAFNet: A Global Fourier Self Attention Based Novel Network for multi-modal downstream tasks",
        "authors": "Onkar Susladkar, Gayatri Deshmukh, Dhruv Makwana, Sparsh Mittal, R Sai Chandra Teja, Rekha Singhal",
        "published": "2023-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00521"
    },
    {
        "id": 28573,
        "title": "End-to-end dense video grounding via parallel regression",
        "authors": "Fengyuan Shi, Weilin Huang, Limin Wang",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2024.103980"
    },
    {
        "id": 28574,
        "title": "Visual Selection Interacts With Action Planning in Natural Foraging Tasks",
        "authors": "Danilo A. Kuhn, Jan Tünnermann, Anna Schubö",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.5394"
    },
    {
        "id": 28575,
        "title": "Context understanding in computer vision: A survey",
        "authors": "Xuan Wang, Zhigang Zhu",
        "published": "2023-3",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103646"
    },
    {
        "id": 28576,
        "title": "SlowFastFormer for 3D human pose estimation",
        "authors": "Lu Zhou, Yingying Chen, Jinqiao Wang",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2024.103992"
    },
    {
        "id": 28577,
        "title": "Beyond Appearance: A Semantic Controllable Self-Supervised Learning Framework for Human-Centric Visual Tasks",
        "authors": "Weihua Chen, Xianzhe Xu, Jian Jia, Hao Luo, Yaohua Wang, Fan Wang, Rong Jin, Xiuyu Sun",
        "published": "2023-6",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01445"
    },
    {
        "id": 28578,
        "title": "Motion duration is overestimated behind an occluder in action and perception tasks",
        "authors": "Melisa Menceloglu, Joo-Hyun Song",
        "published": "2023-5-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.5.11"
    },
    {
        "id": 28579,
        "title": "Convolutional Masked Image Modeling for Dense Prediction Tasks on Pathology Images",
        "authors": "Yan Yang, Liyuan Pan, Liu Liu, Eric A. Stone",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00762"
    },
    {
        "id": 28580,
        "title": "SEM-O-RAN: Semantic O-RAN Slicing for Mobile Edge Offloading of Computer Vision Tasks",
        "authors": "Corrado Puligheddu, Jonathan Ashdown, Carla Fabiana Chiasserini, Francesco Restuccia",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tmc.2023.3339056"
    },
    {
        "id": 28581,
        "title": "I-ViT: Integer-only Quantization for Efficient Vision Transformer Inference",
        "authors": "Zhikai Li, Qingyi Gu",
        "published": "2023-10-1",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01565"
    },
    {
        "id": 28582,
        "title": "Efficient 6-DoF camera pose tracking with circular edges",
        "authors": "Fulin Tang, Shaohuan Wu, Zhengda Qian, Yihong Wu",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103767"
    },
    {
        "id": 28583,
        "title": "Toward Building General Foundation Models for Language, Vision, and Vision-Language Understanding Tasks",
        "authors": "Xinsong Zhang, Yan Zeng, Jipeng Zhang, Hang Li",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-emnlp.40"
    },
    {
        "id": 28584,
        "title": "Occluders help estimate time-to-contact in motion prediction tasks",
        "authors": "Cristina de la Malla, Pamela Villavicencio, Joan López-Moliner",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.5106"
    },
    {
        "id": 28585,
        "title": "Privacy-preserving federated learning with various computer-vision tasks for security applications",
        "authors": "Sabina B. van Rooij, Muriel van der Spek, Arthur van Rooijen, Henri Bouma",
        "published": "2023-10-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2681921"
    },
    {
        "id": 28586,
        "title": "Corrections to: Feature similarity is non-linearly related to attentional selection: Evidence from visual search and sustained attention tasks",
        "authors": "",
        "published": "2023-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.3.5"
    },
    {
        "id": 28587,
        "title": "MP07-15 REAL-TIME KIDNEY STONE SEGMENTATION DURING DISTINCT URETEROSCOPIC TASKS USING A COMPUTER VISION MODEL",
        "authors": "Ekamjit S. Deol, Daiwei Lu, Ipek Oguz, Nicholas L. Kavoussi",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1097/01.ju.0001008728.41882.d7.15"
    },
    {
        "id": 28588,
        "title": "Global–local contrastive multiview representation learning for skeleton-based action recognition",
        "authors": "Cunling Bian, Wei Feng, Fanbo Meng, Song Wang",
        "published": "2023-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103655"
    },
    {
        "id": 28589,
        "title": "Oculomotor “laziness” constrains fixation selection in real-world tasks",
        "authors": "Charlie S. Burlingham, Naveen Sendhilnathan, T. Scott Murdison, Michael J. Proulx",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.4829"
    },
    {
        "id": 28590,
        "title": "X<sup>3</sup>KD: Knowledge Distillation Across Modalities, Tasks and Stages for Multi-Camera 3D Object Detection",
        "authors": "Marvin Klingner, Shubhankar Borse, Varun Ravi Kumar, Behnaz Rezaei, Venkatraman Narayanan, Senthil Yogamani, Fatih Porikli",
        "published": "2023-6",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01282"
    },
    {
        "id": 28591,
        "title": "Generalization in perceptual learning across stimuli and tasks in varied adaptation levels.",
        "authors": "Ravit Kahalani, Maria Lev, Dov Sagi, Uri Polat",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.4881"
    },
    {
        "id": 28592,
        "title": "Attentional priming in Go No-Go search tasks",
        "authors": "Árni Kristjánsson, Tómas Kristjánsson",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.visres.2023.108313"
    },
    {
        "id": 28593,
        "title": "Sketch RL: Interactive Sketch Generation for Long-Horizon Tasks via Vision-Based Skill Predictor",
        "authors": "Zhenyang Lin, Yurou Chen, Zhiyong Liu",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/lra.2023.3339400"
    },
    {
        "id": 28594,
        "title": "Exploring the neural correlates of naturalistic hybrid search tasks",
        "authors": "Matias Ison, Joaquin Gonzalez, Alessandra Barbosa, Damian Care, Anthony Ries, Juan Kamienkowski",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.5540"
    },
    {
        "id": 28595,
        "title": "Introducing ART: a new method of testing auditory memory with circular reproduction tasks",
        "authors": "Daryl Fougnie, Aytac Karabay, Rob Nijenkamp, Anastasios Sarampalis",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.5290"
    },
    {
        "id": 28596,
        "title": "Editorial Board",
        "authors": "",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(23)00007-3"
    },
    {
        "id": 28597,
        "title": "Editorial Board",
        "authors": "",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(23)00019-x"
    },
    {
        "id": 28598,
        "title": "Guest Editorial: Multi‐view representation learning for computer vision",
        "authors": "Xin Ning, Jun Zhou, Jian Cheng, Jing Wu, Chen Wang, Lin Gu",
        "published": "2023-2-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12176"
    },
    {
        "id": 28599,
        "title": "Editorial Board",
        "authors": "",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(23)00250-3"
    },
    {
        "id": 28600,
        "title": "Editorial Board",
        "authors": "",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(24)00044-4"
    },
    {
        "id": 28601,
        "title": "Editorial Board",
        "authors": "",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(24)00069-9"
    },
    {
        "id": 28602,
        "title": "Editorial Board",
        "authors": "",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(24)00085-7"
    },
    {
        "id": 28603,
        "title": "Video Frame-wise Explanation Driven Contrastive Learning for Procedural Text Generation",
        "authors": "Zhihao Wang, Lin Li, Zhongwei Xie, Chuanbo Liu",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2024.103954"
    },
    {
        "id": 28604,
        "title": "Editorial Board",
        "authors": "",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(23)00275-8"
    },
    {
        "id": 28605,
        "title": "Self-supervised multi-scale semantic consistency regularization for unsupervised image-to-image translation",
        "authors": "Heng Zhang, Yi-Jun Yang, Wei Zeng",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2024.103950"
    },
    {
        "id": 28606,
        "title": "Guest Editorial: Spectral imaging powered computer vision",
        "authors": "Jun Zhou, Fengchao Xiong, Lei Tong, Naoto Yokoya, Pedram Ghamisi",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12242"
    },
    {
        "id": 28607,
        "title": "Editorial Board",
        "authors": "",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(23)00227-8"
    },
    {
        "id": 28608,
        "title": "Editorial Board",
        "authors": "",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(23)00110-8"
    },
    {
        "id": 28609,
        "title": "Editorial Board",
        "authors": "",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(23)00079-6"
    },
    {
        "id": 28610,
        "title": "Editorial Board",
        "authors": "",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(23)00172-8"
    },
    {
        "id": 28611,
        "title": "Editorial Board",
        "authors": "",
        "published": "2023-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(23)00055-3"
    },
    {
        "id": 28612,
        "title": "Editorial Board",
        "authors": "",
        "published": "2023-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(23)00048-6"
    },
    {
        "id": 28613,
        "title": "Editorial Board",
        "authors": "",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(22)00185-0"
    },
    {
        "id": 28614,
        "title": "Editorial Board",
        "authors": "",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(23)00205-9"
    },
    {
        "id": 28615,
        "title": "Testing hemifield independence for divided attention in visual object tasks",
        "authors": "Dina V. Popovkina, John Palmer, Cathleen M. Moore, Geoffrey M. Boynton",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.13.3"
    },
    {
        "id": 28616,
        "title": "Editorial Board",
        "authors": "",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(23)00135-2"
    },
    {
        "id": 28617,
        "title": "Editorial Board",
        "authors": "",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/s1077-3142(24)00004-3"
    },
    {
        "id": 28618,
        "title": "CoCV: Heterogeneous Processors Collaboration Mechanism for End-to-End Execution of Intelligent Computer Vision Tasks on Mobile Devices",
        "authors": "Ye Wan, Mengyang Liu, Guangtong Li, Fang Dong",
        "published": "2023-12-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icpads60453.2023.00334"
    },
    {
        "id": 28619,
        "title": "SciOL and MuLMS-Img: Introducing A Large-Scale Multimodal Scientific Dataset and Models for Image-Text Tasks in the Scientific Domain",
        "authors": "Tim Tarsi, Heike Adel, Jan Hendrik Metzen, Dan Zhang, Matteo Finco, Annemarie Friedrich",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv57701.2024.00450"
    },
    {
        "id": 28620,
        "title": "Accelerating Computer Vision Tasks on GPUs using Ramanujan Graph Product Framework",
        "authors": "Furqan Ahmed Shaik, Thejasvi Konduru, Girish Varma, Kishore Kothapalli",
        "published": "2023-1-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3570991.3571044"
    },
    {
        "id": 28621,
        "title": "Strip-MLP: Efficient Token Interaction for Vision MLP",
        "authors": "Guiping Cao, Shengda Luo, Wenjian Huang, Xiangyuan Lan, Dongmei Jiang, Yaowei Wang, Jianguo Zhang",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00144"
    },
    {
        "id": 28622,
        "title": "Research on the Key Technology of Real-World 3D Model Refinement Reconstruction",
        "authors": "Jiang Wangyang, Qu Hui, Zhang Guangzhen",
        "published": "2023-9-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icrcv59470.2023.10329157"
    },
    {
        "id": 28623,
        "title": "Effect of 2D/3D Visual and Haptic Cues for Fine Operation Tasks With Varying Difficulties",
        "authors": "Zhenghang Hou, Weiping He, Shuxia Wang",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/10447318.2024.2329386"
    },
    {
        "id": 28624,
        "title": "Skill learning framework for human–robot interaction and manipulation tasks",
        "authors": "Gbenga Abiodun Odesanmi, Qining Wang, Jingeng Mai",
        "published": "2023-2",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.rcim.2022.102444"
    },
    {
        "id": 28625,
        "title": "Ordinal Label Distribution Learning",
        "authors": "Changsong Wen, Xin Zhang, Xingxu Yao, Jufeng Yang",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.02146"
    },
    {
        "id": 28626,
        "title": "Language guided 3D object detection in point clouds for MEP scenes",
        "authors": "Junjie Li, Shengli Du, Jianfeng Liu, Weibiao Chen, Manfu Tang, Lei Zheng, Lianfa Wang, Chunle Ji, Xiao Yu, Wanli Yu",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "AbstractIn recent years, contrastive language‐image pre‐training (CLIP) has gained popularity for processing 2D data. However, the application of cross‐modal transferable learning to 3D data remains a relatively unexplored area. In addition, high‐quality, labelled point cloud data for Mechanical, Electrical, and Plumbing (MEP) scenarios are in short supply. To address this issue, the authors introduce a novel object detection system that employs 3D point clouds and 2D camera images, as well as text descriptions as input, using image‐text matching knowledge to guide dense detection models for 3D point clouds in MEP environments. Specifically, the authors put forth the proposition of a language‐guided point cloud modelling (PCM) module, which leverages the shared image weights inherent in the CLIP backbone. This is done with the aim of generating pertinent category information for the target, thereby augmenting the efficacy of 3D point cloud target detection. After sufficient experiments, the proposed point cloud detection system with the PCM module is proven to have a comparable performance with current state‐of‐the‐art networks. The approach has 5.64% and 2.9% improvement in KITTI and SUN‐RGBD, respectively. In addition, the same good detection results are obtained in their proposed MEP scene dataset.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12261"
    },
    {
        "id": 28627,
        "title": "Causal inference predicts the effect of motion uncertainty in motion integration/segregation tasks.",
        "authors": "Boris Penaloza, Sabyasachi Shivkumar, Gabor Lengyel, Gregory DeAngelis, Ralf Haefner",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.5431"
    },
    {
        "id": 28628,
        "title": "STEPs: Self-Supervised Key Step Extraction and Localization from Unlabeled Procedural Videos",
        "authors": "Anshul Shah, Benjamin Lundell, Harpreet Sawhney, Rama Chellappa",
        "published": "2023-10-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00952"
    },
    {
        "id": 28629,
        "title": "Robust Teacher: Self-correcting pseudo-label-guided semi-supervised learning for object detection",
        "authors": "Shijie Li, Junmin Liu, Weilin Shen, Jianyong Sun, Chengli Tan",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103788"
    },
    {
        "id": 28630,
        "title": "A Computer Vision Approach to Compute Bubble Flow of Offshore Wells",
        "authors": "Rogerio Hart, Aura Conci",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012433500003660"
    },
    {
        "id": 28631,
        "title": "Study on extraction of key features of sugar orange phenotype",
        "authors": "Shilong Wang, Jinghuan Zhu",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2684489"
    },
    {
        "id": 28632,
        "title": "Multi-view cognition with path search for one-shot part labeling",
        "authors": "Shaowei Wang, Lingling Zhang, Tao Qin, Jun Liu, Yifei Li, Qianying Wang, Qinghua Zheng",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2024.104015"
    },
    {
        "id": 28633,
        "title": "NoisyQuant: Noisy Bias-Enhanced Post-Training Activation Quantization for Vision Transformers",
        "authors": "Yijiang Liu, Huanrui Yang, Zhen Dong, Kurt Keutzer, Li Du, Shanghang Zhang",
        "published": "2023-6",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01946"
    },
    {
        "id": 28634,
        "title": "Towards Generating 3D City Models with GAN and Computer Vision Methods",
        "authors": "Sarun Poolkrajang, Anand Bhojan",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012315000003660"
    },
    {
        "id": 28635,
        "title": "Top-down and within-layer recurrent connections in artificial networks are needed to solve challenging visual tasks",
        "authors": "Andrea Ivan Costantino, Hans Op de Beeck",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.5008"
    },
    {
        "id": 28636,
        "title": "Dynamic resource allocation in spatial working memory during full and partial report tasks",
        "authors": "Siobhan M. McAteer, Emma Ablott, Anthony McGregor, Daniel T. Smith",
        "published": "2023-2-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.2.10"
    },
    {
        "id": 28637,
        "title": "Layout similarity based key information extraction framework for structural images",
        "authors": "Maosheng Zhu, Ruijie Ni",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icicml60161.2023.10424746"
    },
    {
        "id": 28638,
        "title": "Evaluation of Computer Vision-Based Person Detection on Low-Cost Embedded Systems",
        "authors": "Francesco Pasti, Nicola Bellotto",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011797400003417"
    },
    {
        "id": 28639,
        "title": "OmDet: Large‐scale vision‐language multi‐dataset pre‐training with multimodal detection network",
        "authors": "Tiancheng Zhao, Peng Liu, Kyusong Lee",
        "published": "2024-1-24",
        "citations": 0,
        "abstract": "AbstractThe advancement of object detection (OD) in open‐vocabulary and open‐world scenarios is a critical challenge in computer vision. OmDet, a novel language‐aware object detection architecture and an innovative training mechanism that harnesses continual learning and multi‐dataset vision‐language pre‐training is introduced. Leveraging natural language as a universal knowledge representation, OmDet accumulates “visual vocabularies” from diverse datasets, unifying the task as a language‐conditioned detection framework. The multimodal detection network (MDN) overcomes the challenges of multi‐dataset joint training and generalizes to numerous training datasets without manual label taxonomy merging. The authors demonstrate superior performance of OmDet over strong baselines in object detection in the wild, open‐vocabulary detection, and phrase grounding, achieving state‐of‐the‐art results. Ablation studies reveal the impact of scaling the pre‐training visual vocabulary, indicating a promising direction for further expansion to larger datasets. The effectiveness of our deep fusion approach is underscored by its ability to learn jointly from multiple datasets, enhancing performance through knowledge sharing.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12268"
    },
    {
        "id": 28640,
        "title": "Scene- and object-based tasks performed on the same complex stimuli activate different regions in parietal and lateral occipital cortex.",
        "authors": "Mark D. Lescroart, Hunter Howe",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.5995"
    },
    {
        "id": 28641,
        "title": "One does not fit all! On the Complementarity of Vision Encoders for Vision and Language Tasks",
        "authors": "Gregor Geigle, Chen Liu, Jonas Pfeiffer, Iryna Gurevych",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.repl4nlp-1.9"
    },
    {
        "id": 28642,
        "title": "2023 IEEE International Conference on Computer Vision and Machine Intelligence (CVMI)",
        "authors": "",
        "published": "2023-12-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvmi59935.2023.10464399"
    },
    {
        "id": 28643,
        "title": "Building Vision Transformers with Hierarchy Aware Feature Aggregation",
        "authors": "Yongjie Chen, Hongmin Liu, Haoran Yin, Bin Fan",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00543"
    },
    {
        "id": 28644,
        "title": "Retracted: The Key Technologies of Marine Multiobjective Ship Monitoring and Tracking Based on Computer Vision",
        "authors": "",
        "published": "2023-7-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9867842"
    },
    {
        "id": 28645,
        "title": "Incremental Few-Shot Object Detection with scale- and centerness-aware weight generation",
        "authors": "Lu Zhang, Xu Yang, Lu Qi, Shaofeng Zeng, Zhiyong Liu",
        "published": "2023-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103774"
    },
    {
        "id": 28646,
        "title": "Slide-Transformer: Hierarchical Vision Transformer with Local Self-Attention",
        "authors": "Xuran Pan, Tianzhu Ye, Zhuofan Xia, Shiji Song, Gao Huang",
        "published": "2023-6",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00207"
    },
    {
        "id": 28647,
        "title": "A lightweight vision transformer with symmetric modules for vision tasks",
        "authors": "Shengjun Liang, Mingxin Yu, Wenshuai Lu, Xinglong Ji, Xiongxin Tang, Xiaolin Liu, Rui You",
        "published": "2023-11-20",
        "citations": 0,
        "abstract": "Transformer-based networks have demonstrated their powerful performance in various vision tasks. However, these transformer-based networks are heavyweight and cannot be applied to edge computing (mobile) devices. Despite that the lightweight transformer network has emerged, several problems remain, i.e., weak feature extraction ability, feature redundancy, and lack of convolutional inductive bias. To address these three problems, we propose a lightweight visual transformer (Symmetric Former, SFormer), which contains two novel modules (Symmetric Block and Symmetric FFN). Specifically, we design Symmetric Block to expand feature capacity inside the module and enhance the long-range modeling capability of attention mechanism. To increase the compactness of the model and introduce inductive bias, we introduce convolutional cheap operations to design Symmetric FFN. We compared the SFormer with existing lightweight transformers on several vision tasks. Remarkably, on the image recognition task of ImageNet [13], SFormer gains 1.2% and 1.6% accuracy improvements compared to PVTv2-b0 and Swin Transformer, respectively. On the semantic segmentation task of ADE20K [64], SFormer delivers performance improvements of 0.2% and 0.7% compared to PVTv2-b0 and Swin Transformer, respectively. On the cityscapes dataset [11], SFormer delivers performance improvements of 2.5% and 4.2% compared to PVTv2-b0 and Swin Transformer, respectively. The code is open-source and available at: https://github.com/ISCLab-Bistu/Symmetric_Former.git.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/ida-227205"
    },
    {
        "id": 28648,
        "title": "2024 IEEE Winter Conference on Applications of Computer Vision Workshops",
        "authors": "",
        "published": "2024-1-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacvw60836.2024.00002"
    },
    {
        "id": 28649,
        "title": "Research on Key Technologies for Deep Optimization of Unity Based Scenarios",
        "authors": "Yanping Wu, Xin Yang, Ping Xie, Jindong Liang",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icicml60161.2023.10424805"
    },
    {
        "id": 28650,
        "title": "Res-ViT: Residual Vision Transformers for Image Recognition Tasks.",
        "authors": "Sayda Elmi, Bell Morris",
        "published": "2023-11-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ictai59109.2023.00052"
    },
    {
        "id": 28651,
        "title": "Constituent Attention for Vision Transformers",
        "authors": "Haoling Li, Mengqi Xue, Jie Song, Haofei Zhang, Wenqi Huang, Lingyu Liang, Mingli Song",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103838"
    },
    {
        "id": 28652,
        "title": "SemiCVT: Semi-Supervised Convolutional Vision Transformer for Semantic Segmentation",
        "authors": "Huimin Huang, Shiao Xie, Lanfen Lin, Ruofeng Tong, Yen-Wei Chen, Yuexiang Li, Hong Wang, Yawen Huang, Yefeng Zheng",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01091"
    },
    {
        "id": 28653,
        "title": "FashionSAP: Symbols and Attributes Prompt for Fine-Grained Fashion Vision-Language Pre-Training",
        "authors": "Yunpeng Han, Lisai Zhang, Qingcai Chen, Zhijian Chen, Zhonghua Li, Jianxin Yang, Zhao Cao",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01443"
    },
    {
        "id": 28654,
        "title": "DropKey for Vision Transformer",
        "authors": "Bonan Li, Yinhan Hu, Xuecheng Nie, Congying Han, Xiangjian Jiang, Tiande Guo, Luoqi Liu",
        "published": "2023-6",
        "citations": 13,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.02174"
    },
    {
        "id": 28655,
        "title": "Towards Better User Studies in Computer Graphics and Vision",
        "authors": "Zoya Bylinskii, Laura Herman, Aaron Hertzmann, Stefanie Hutka, Yile Zhang",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1561/0600000106"
    },
    {
        "id": 28656,
        "title": "Microsaccades in head-free high-acuity tasks",
        "authors": "Paul Jolly, Yuanhao H. Li, Michele A. Cox, Ashley M. Clark, Bin Yang, Ruitao Lin, Zhetuo Zhao, Michele Rucci",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.5817"
    },
    {
        "id": 28657,
        "title": "A Motion-Simulation Platform to Generate Synthetic Motion Data for Computer Vision Tasks",
        "authors": "Andrew Chalmers, Junhong Zhao, Weng Khuan Hoh, James Drown, Simon Finnie, Richard Yao, James Lin, James Wilmott, Arindam Dey, Mark Billinghurst, Taehyun Rhee",
        "published": "2023-11-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3610543.3628795"
    },
    {
        "id": 28658,
        "title": "Is Meta-Learning Always Necessary?: A Practical ML Framework Solving Novel Tasks at Large-scale Car Sharing Platform",
        "authors": "Hyunhee Chung, Kyung Ho Park",
        "published": "2023-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacvw58289.2023.00046"
    },
    {
        "id": 28659,
        "title": "Enhancing Preservice Teachers' Professional Vision: Is There a Difference Between Providing Specific Tasks and Prompting?",
        "authors": "Sylvia Gabel",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3102/2006971"
    },
    {
        "id": 28660,
        "title": "Semi‐supervised domain adaptation via subspace exploration",
        "authors": "Zheng Han, Xiaobin Zhu, Chun Yang, Zhiyu Fang, Jingyan Qin, Xucheng Yin",
        "published": "2024-4",
        "citations": 0,
        "abstract": "AbstractRecent methods of learning latent representations in Domain Adaptation (DA) often entangle the learning of features and exploration of latent space into a unified process. However, these methods can cause a false alignment problem and do not generalise well to the alignment of distributions with large discrepancy. In this study, the authors propose to explore a robust subspace for Semi‐Supervised Domain Adaptation (SSDA) explicitly. To be concrete, for disentangling the intricate relationship between feature learning and subspace exploration, the authors iterate and optimise them in two steps: in the first step, the authors aim to learn well‐clustered latent representations by aggregating the target feature around the estimated class‐wise prototypes; in the second step, the authors adaptively explore a subspace of an autoencoder for robust SSDA. Specially, a novel denoising strategy via class‐agnostic disturbance to improve the discriminative ability of subspace is adopted. Extensive experiments on publicly available datasets verify the promising and competitive performance of our approach against state‐of‐the‐art methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12254"
    },
    {
        "id": 28661,
        "title": "Does Image Anonymization Impact Computer Vision Training?",
        "authors": "Håkon Hukkelås, Frank Lindseth",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvprw59228.2023.00019"
    },
    {
        "id": 28662,
        "title": "Hierarchical compositional representations for few-shot action recognition",
        "authors": "Changzhen Li, Jie Zhang, Shuzhe Wu, Xin Jin, Shiguang Shan",
        "published": "2024-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103911"
    },
    {
        "id": 28663,
        "title": "Adaptive Testing of Computer Vision Models",
        "authors": "Irena Gao, Gabriel Ilharco, Scott Lundberg, Marco Tulio Ribeiro",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00370"
    },
    {
        "id": 28664,
        "title": "Vision-Language Models for Vision Tasks: A Survey",
        "authors": "Jingyi Zhang, Jiaxing Huang, Sheng Jin, Shijian Lu",
        "published": "2024",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tpami.2024.3369699"
    },
    {
        "id": 28665,
        "title": "2024 IEEE Winter Conference on Applications of Computer Vision Workshops WACVW 2024",
        "authors": "",
        "published": "2024-1-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacvw60836.2024.00001"
    },
    {
        "id": 28666,
        "title": "Vision-Based Assessment of Low Back Load During Manual Material Handling Tasks",
        "authors": "Yusuke Asaka, Kazuyuki Kojima",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/gcce59613.2023.10315257"
    },
    {
        "id": 28667,
        "title": "Cross Contrasting Feature Perturbation for Domain Generalization",
        "authors": "Chenming Li, Daoan Zhang, Wenjian Huang, Jianguo Zhang",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00128"
    },
    {
        "id": 28668,
        "title": "An Optimal Transport View of Class-Imbalanced Visual Recognition",
        "authors": "Lianbao Jin, Dayu Lang, Na Lei",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11263-023-01831-9"
    },
    {
        "id": 28669,
        "title": "Application of Deep Learning in Computer Aided Vocal Tasks Learning",
        "authors": "Tianming Xu, Tianzhuo Gong",
        "published": "2023-1-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14733/cadaps.2023.s7.25-35"
    },
    {
        "id": 28670,
        "title": "Accelerating Vision-Language Pretraining with Free Language Modeling",
        "authors": "Teng Wang, Yixiao Ge, Feng Zheng, Ran Cheng, Ying Shan, Xiaohu Qie, Ping Luo",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.02218"
    },
    {
        "id": 28671,
        "title": "Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction",
        "authors": "Yuanhui Huang, Wenzhao Zheng, Yunpeng Zhang, Jie Zhou, Jiwen Lu",
        "published": "2023-6",
        "citations": 14,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00890"
    },
    {
        "id": 28672,
        "title": "3D Human Motion Data Compression Based on Computer Vision",
        "authors": "Peng Wang, Xiaolin Jiang",
        "published": "2023-11-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icicml60161.2023.10424871"
    },
    {
        "id": 28673,
        "title": "Attention-based multimodal image matching",
        "authors": "Aviad Moreshet, Yosi Keller",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2024.103949"
    },
    {
        "id": 28674,
        "title": "No evidence that attentionally demanding dual tasks disrupt visual processing capacity in a gamified orientation-averaging task",
        "authors": "Wing Hong Fu, Gabrielle Weidemann, Tijl Grootswagers, Larissa Cahill, John Cass",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.4985"
    },
    {
        "id": 28675,
        "title": "Analyzing lower half facial gestures for lip reading applications: Survey on vision techniques",
        "authors": "Preethi S.J., Niranjana Krupa B.",
        "published": "2023-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103738"
    },
    {
        "id": 28676,
        "title": "The effects of monocular and binocular retinal image minification during natural tasks",
        "authors": "Iona R. McLean, Ian M. Erkelens, Esther F. Sherbak, Loganne T. Mikkelsen, Robin Sharma, Emily A. Cooper",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.4700"
    },
    {
        "id": 28677,
        "title": "Proceedings of the 2023 IEEE International Conference on Computer Vision and Machine Intelligence (CVMI)",
        "authors": "",
        "published": "2023-12-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvmi59935.2023.10465136"
    },
    {
        "id": 28678,
        "title": "Brain settings across free-viewing tasks: from Exploration to Visual Search and Hybrid Search",
        "authors": "Juan Esteban Kamienkowski, Damian Care, Joaquin Ezequiel Gonzalez, Anthony J Ries, Matias J Ison",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.5527"
    },
    {
        "id": 28679,
        "title": "Inverse Compositional Learning for Weakly-supervised Relation Grounding",
        "authors": "Huan Li, Ping Wei, Zeyu Ma, Nanning Zheng",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.01419"
    },
    {
        "id": 28680,
        "title": "Understanding Masked Image Modeling via Learning Occlusion Invariant Feature",
        "authors": "Xiangwen Kong, Xiangyu Zhang",
        "published": "2023-6",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00604"
    },
    {
        "id": 28681,
        "title": "The Influence of Clutching Mechanism on Object Manipulation Tasks in Virtual Environments",
        "authors": "Zihan Gao, Xin Lyu, Anqi Ge, Huiqiang Wang",
        "published": "2023-6-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/10447318.2023.2227830"
    },
    {
        "id": 28682,
        "title": "Pointing Tasks Using Spatial Audio on Smartphones for People With Vision Impairments",
        "authors": "Abhijeet Singh Raina, Ronak R. Mohanty, Abhirath Bhuvanesh, Divya Prabha J, Manohar Swaminathan, Vinayak R. Krishnamurthy",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "Abstract\nWe present an experimental investigation of spatial audio feedback using smartphones to support direction localization in pointing tasks for people with visual impairments (PVIs). We do this using a mobile game based on a bow-and-arrow metaphor. Our game provides a combination of spatial and non-spatial (sound beacon) audio to help the user locate the direction of the target. Our experiments with sighted, sighted-blindfolded, and visually impaired users show that (a) the efficacy of spatial audio is relatively higher for PVIs than for blindfolded sighted users during the initial reaction time for direction localization, (b) the general behavior between PVIs and blindfolded individuals is statistically similar, and (c) the lack of spatial audio significantly reduces the localization performance even in sighted-blindfolded users. Based on our findings, we discuss the system and interaction design implications for making future mobile-based spatial interactions accessible to PVIs.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1115/1.4062426"
    },
    {
        "id": 28683,
        "title": "Learning Trajectory-Word Alignments for Video-Language Tasks",
        "authors": "Xu Yang, Zhangzikang Li, Haiyang Xu, Hanwang Zhang, Qinghao Ye, Chenliang Li, Ming Yan, Yu Zhang, Fei Huang, Songfang Huang",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00237"
    },
    {
        "id": 28684,
        "title": "EMT-NAS: Transferring architectural knowledge between tasks from different datasets",
        "authors": "Peng Liao, Yaochu Jin, Wenli Du",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00355"
    },
    {
        "id": 28685,
        "title": "Learnable fusion mechanisms for multimodal object detection in autonomous vehicles",
        "authors": "Yahya Massoud, Robert Laganiere",
        "published": "2024-3-15",
        "citations": 0,
        "abstract": "AbstractPerception systems in autonomous vehicles need to accurately detect and classify objects within their surrounding environments. Numerous types of sensors are deployed on these vehicles, and the combination of such multimodal data streams can significantly boost performance. The authors introduce a novel sensor fusion framework using deep convolutional neural networks. The framework employs both camera and LiDAR sensors in a multimodal, multiview configuration. The authors leverage both data types by introducing two new innovative fusion mechanisms: element‐wise multiplication and multimodal factorised bilinear pooling. The methods improve the bird's eye view moderate average precision score by +4.97% and +8.35% on the KITTI dataset when compared to traditional fusion operators like element‐wise addition and feature map concatenation. An in‐depth analysis of key design choices impacting performance, such as data augmentation, multi‐task learning, and convolutional architecture design is offered. The study aims to pave the way for the development of more robust multimodal machine vision systems. The authors conclude the paper with qualitative results, discussing both successful and problematic cases, along with potential ways to mitigate the latter.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12259"
    },
    {
        "id": 28686,
        "title": "Weakly-supervised Single-view Image Relighting",
        "authors": "Renjiao Yi, Chenyang Zhu, Kai Xu",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00812"
    },
    {
        "id": 28687,
        "title": "Unsupervised image blind super resolution via real degradation feature learning",
        "authors": "Cheng Yang, Guanming Lu",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "AbstractIn recent years, many methods for image super‐resolution (SR) have relied on pairs of low‐resolution (LR) and high‐resolution (HR) images for training, where the degradation process is predefined by bicubic downsampling. While such approaches perform well in standard benchmark tests, they often fail to accurately replicate the complexity of real‐world image degradation. To address this challenge, researchers have proposed the use of unpaired image training to implicitly model the degradation process. However, there is a significant domain gap between the real‐world LR and the synthetic LR images from HR, which severely degrades the SR performance. A novel unsupervised image‐blind super‐resolution method that exploits degradation feature‐based learning for real‐image super‐resolution reconstruction (RDFL) is proposed. Their approach learns the degradation process from HR to LR using a generative adversarial network (GAN) and constrains the data distribution of the synthetic LR with real degraded images. The authors then encode the degraded features into a Transformer‐based SR network for image super‐resolution reconstruction through degradation representation learning. Extensive experiments on both synthetic and real datasets demonstrate the effectiveness and superiority of the RDFL method, which achieves visually pleasing reconstruction results.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12262"
    },
    {
        "id": 28688,
        "title": "An efficient mixed attention module",
        "authors": "Kuang Sheng, Pinghua Chen",
        "published": "2023-6",
        "citations": 1,
        "abstract": "AbstractRecently, the application of attention mechanisms in convolutional neural networks (CNNs) has become a hot area in computer vision. Most existing methods focus on channel attention or spatial attention. Some mixed attention usually achieves better performance than channel attention or spatial attention with the help of a complex model structure, which increases the complexity of the model. This article proposes an efficient mixed attention that combines channel information with spatial information using learnable broadcast addition to reduce this complexity. In particular, this module can simplify learning and improve performance with fewer parameters. Furthermore, our method uses an excitation method based on the Tanh function to reduce computational resources while maintaining model performance, and it is a lightweight attention module that can be used in arbitrary CNNs to improve performance. Experiments on ImageNet and Cifar confirm the effectiveness of the proposed method. Besides, our method remains highly competitive for object detection tasks and image segmentation tasks.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12184"
    },
    {
        "id": 28689,
        "title": "The Computer Vision Simulation of Athlete’s Wrong Actions Recognition Model Based on Artificial Intelligence",
        "authors": "Wenxin Du",
        "published": "2024",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3349020"
    },
    {
        "id": 28690,
        "title": "Transformer-based computer vision technology empowers drones",
        "authors": "Mingzheng Lai, PengJie Wang, YiFan Zeng, Wei Lv",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10166286"
    },
    {
        "id": 28691,
        "title": "Lmser-pix2seq: Learning stable sketch representations for sketch healing",
        "authors": "Tengjie Li, Sicong Zang, Shikui Tu, Lei Xu",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2024.103931"
    },
    {
        "id": 28692,
        "title": "FAM: Improving columnar vision transformer with feature attention mechanism",
        "authors": "Lan Huang, Xingyu Bai, Jia Zeng, Mengqiang Yu, Wei Pang, Kangping Wang",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2024.103981"
    },
    {
        "id": 28693,
        "title": "Differential development of object and location processing is a critical factor to a child’s passing or failing explicit false-belief tasks",
        "authors": "Rebecca J. Rennert, Virginia J. Chambers, Daniel D. Dilks",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1167/jov.23.9.4953"
    },
    {
        "id": 28694,
        "title": "Editor’s Note: Special Issue on 3D Computer Vision",
        "authors": "",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11263-023-01751-8"
    },
    {
        "id": 28695,
        "title": "A temporal shift reconstruction network for compressive video sensing",
        "authors": "Zhenfei Gu, Chao Zhou, Guofeng Lin",
        "published": "2023-9-9",
        "citations": 0,
        "abstract": "AbstractCompressive sensing provides a promising sampling paradigm for video acquisition for resource‐limited sensor applications. However, the reconstruction of original video signals from sub‐sampled measurements is still a great challenge. To exploit the temporal redundancies within videos during the recovery, previous works tend to perform alignment on initial reconstructions, which are too coarse to provide accurate motion estimations. To solve this problem, the authors propose a novel reconstruction network, named TSRN, for compressive video sensing. Specifically, the authors utilise a number of stacked temporal shift reconstruction blocks (TSRBs) to enhance the initial reconstruction progressively. Each TSRB could learn the temporal structures by exchanging information with last and next time step, and no additional computations is imposed on the network compared to regular 2D convolutions due to the high efficiency of temporal shift operations. After the enhancement, a bidirectional alignment module to build accurate temporal dependencies directly with the help of optical flows is employed. Different from previous methods that only extract supplementary information from the key frames, the proposed alignment module can receive temporal information from the whole video sequence via bidirectional propagations, thus yielding better performance. Experimental results verify the superiority of the proposed method over other state‐of‐the‐art approaches quantitatively and qualitatively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12234"
    },
    {
        "id": 28696,
        "title": "Pollinators as Data Collectors: Estimating Floral Diversity with Bees and Computer Vision",
        "authors": "Frederic Tausch, Jan Wagner, Simon Klaus",
        "published": "2023-10-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccvw60793.2023.00071"
    },
    {
        "id": 28697,
        "title": "Computer Vision for Ocean Eddy Detection in Infrared Imagery",
        "authors": "Evangelos Moschos, Alisa Kugusheva, Paul Coste, Alexandre Stegner",
        "published": "2023-1",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00633"
    },
    {
        "id": 28698,
        "title": "Soft-Landing Strategy for Alleviating the Task Discrepancy Problem in Temporal Action Localization Tasks",
        "authors": "Hyolim Kang, Hanjung Kim, Joungbin An, Minsu Cho, Seon Joo Kim",
        "published": "2023-6",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00630"
    },
    {
        "id": 28699,
        "title": "ParCNetV2: Oversized Kernel with Enhanced Attention<sup>*</sup>",
        "authors": "Ruihan Xu, Haokui Zhang, Wenze Hu, Shiliang Zhang, Xiaoyu Wang",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00529"
    },
    {
        "id": 28700,
        "title": "Single and multiple illuminant estimation using convex functions",
        "authors": "Zeinab Abedini, Mansour Jamzad",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103711"
    },
    {
        "id": 28701,
        "title": "Network Expansion For Practical Training Acceleration",
        "authors": "Ning Ding, Yehui Tang, Kai Han, Chao Xu, Yunhe Wang",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01941"
    },
    {
        "id": 28702,
        "title": "Image amodal completion: A survey",
        "authors": "Jiayang Ao, Qiuhong Ke, Krista A. Ehinger",
        "published": "2023-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103661"
    },
    {
        "id": 28703,
        "title": "Concept Study for Dynamic Vision Sensor Based Insect Monitoring",
        "authors": "Regina Pohle-Fröhlich, Tobias Bolten",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011775500003417"
    },
    {
        "id": 28704,
        "title": "Eulerian Single-Photon Vision",
        "authors": "Shantanu Gupta, Mohit Gupta",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccv51070.2023.00960"
    }
]