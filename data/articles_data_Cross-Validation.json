[
    {
        "id": 5401,
        "title": "Procrustes Cross-Validation—A Bridge between Cross-Validation and Independent Validation Sets",
        "authors": "Sergey Kucheryavskiy, Sergei Zhilin, Oxana Rodionova, Alexey Pomerantsev",
        "published": "2020-9-1",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1021/acs.analchem.0c02175"
    },
    {
        "id": 5402,
        "title": "Procrustes Cross-Validation — a Bridge Between Cross-Validation and Independent Validation Set",
        "authors": "Sergey Kucheryavskiy, Sergei Zhilin, Oxana Ye. Rodionova, Alexey L. Pomerantsev",
        "published": "No Date",
        "citations": 1,
        "abstract": "<div><div><div><p>In this paper we propose a new approach for validation of chemometric models. It is based on k-fold cross-validation algorithm, but, in contrast to conventional cross-validation, our approach makes possible to create a new dataset, which carries sampling uncertainty estimated by the cross-validation procedure. This dataset, called <i>pseudo-validation set</i>, can be used similar to independent test set, giving a possibility to compute residual distances, explained variance, scores and other results, which can not be obtained in the conventional cross-validation. The paper describes theoretical details of the proposed approach and its implementation as well as presents experimental results obtained using simulated and real chemical datasets.</p></div></div></div>",
        "link": "http://dx.doi.org/10.26434/chemrxiv.12327803"
    },
    {
        "id": 5403,
        "title": "Procrustes Cross-Validation — a Bridge Between Cross-Validation and Independent Validation Set",
        "authors": "Sergey Kucheryavskiy, Sergei Zhilin, Oxana Ye. Rodionova, Alexey L. Pomerantsev",
        "published": "No Date",
        "citations": 0,
        "abstract": "In this paper we propose a new approach for validation of chemometric models. It is based on k-fold cross-validation algorithm, but, in contrast to conventional cross-validation, our approach makes possible to create a new dataset, which carries sampling uncertainty estimated by the cross-validation procedure. This dataset, called pseudo-validation set, can be used similar to independent test set, giving a possibility to compute residual distances, explained variance, scores and other results, which can not be obtained in the conventional cross-validation. The paper describes theoretical details of the proposed approach and its implementation as well as presents experimental results obtained using simulated and real chemical datasets.",
        "link": "http://dx.doi.org/10.26434/chemrxiv.12327803.v1"
    },
    {
        "id": 5404,
        "title": "Cross-validation coordinate analysis (CVCA): performing coordinate based meta-analysis using cross-validation",
        "authors": "C.R. Tench",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractCoordinate based meta-analysis (CBMA) can be used to estimate where a future neuroimaging study testing a particular hypothesis might report summary results (activation foci, for example). However, current methods cannot be validated for all possible analyses, and use empirical features that might not always be ideal. Indeed, the various algorithms that perform CBMA tend to produce somewhat different results even on the same data. Furthermore, the use of null hypothesis significance testing (NHST) in the algorithms is not strictly in keeping with meta-analysis, where the aim is usually effect estimation rather than statistical significance.Given the limitations of current CBMA algorithms, a new algorithm has been developed that will perform its analysis using cross validation: cross-validation coordinate analysis (CVCA). Although a full validation cannot be performed, CVCA optimises its parameters in such a way as to make the analysis results most similar to the held-out data. The algorithm can be used as a stand-alone meta-analysis method, or to provide confidence in results from other algorithms where no validation is performed.Software to perform CVCA is freely available.",
        "link": "http://dx.doi.org/10.1101/2024.03.13.24304212"
    },
    {
        "id": 5405,
        "title": "Cross validation",
        "authors": "Candace Moore",
        "published": "2020-3-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.53347/rid-74964"
    },
    {
        "id": 5406,
        "title": "Book Chapter Submission Validation Test",
        "authors": "Cross Ref",
        "published": "2019",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5555/bookchaptervalidation/test002"
    },
    {
        "id": 5407,
        "title": "Cross-validation, Symbolic Regression, Pareto include",
        "authors": "",
        "published": "2024-2-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5194/egusphere-2023-2969-cc1"
    },
    {
        "id": 5408,
        "title": "PERBANDINGAN METODE CROSS VALIDATION DAN GENERALIZED CROSS VALIDATION DALAM REGRESI NONPARAMETRIK BIRESPON SPLINE",
        "authors": "Luh Putu Safitri Pratiwi",
        "published": "2017-9-28",
        "citations": 2,
        "abstract": "AbstrakAnalisis regresi merupakan salah satu metode yang sangat populer dalam statistika untuk menjelaskan hubungan sebab akibat antara satu/beberapa variabel prediktor terhadap satu variabel respon. Pada umumnya, pemodelan yang dapat dilakukan dengan menggunakan analisis regresi. Kurva regresi dapat diduga dengan pendekatan regresi parametrik dan pendekatan regresi nonparametrik. Namun, tidak semua data yang diperoleh mengikuti pola tertentu sehingga jenis data ini menggunakan pendekatan regresi nonparametrik. Pendekatan regresi nonparametrik tidak terkait dengan asumsi bentuk kurva regresi seperti halnya pada regresi parametrik, dan lebih fleksibel. Ada beberapa teknik yang dilakukan untuk estimasi dalam regresi nonparametrik yaitu Spline. Beberapa kasus dalam analisis regresi banyak dijumpai permasalahan yang tidak dapat diselesaikan dengan analisis regresi sederhana satu respon karena jika menggunakan dua variabel respon pada penelitian, maka harus dilihat nilai korelasi antar variabel. Akibatnya, persoalan regresi harus diselesaikan dengan model regresi birespon. Penelitian ini bertujuan untuk mendeskripsikan AKB dan status gizi buruk balita dan mendapatkan model Spline dalam regresi nonparametrik birespon terbaik melalui hubungan antara variabel yang diduga berpengaruh dengan menggunakan metode Cross Validation (CV) dan Generalized Cross Validation (GCV). Hasil yang didapat yaitu model terbaik yang sesuai untuk derajat kesehatan di Indonesia pada tahun 2015 yaitu dengan menggunakan metode CV dengan  nilai CV minimum yang terletak  pada model Spline linier satu knot yakni sebesar 77.37831 dengan MSE sebesar 76.75449. ",
        "link": "http://dx.doi.org/10.30812/varian.v1i1.49"
    },
    {
        "id": 5409,
        "title": "Cross Validation",
        "authors": " ",
        "published": "2020-2-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/fnrqkb"
    },
    {
        "id": 5410,
        "title": "Empirical Validation of cross-version and 10-fold cross-validation for Defect Prediction",
        "authors": "Ruchika Malhotra, Shweta Meena",
        "published": "2021-8-4",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icesc51422.2021.9533030"
    },
    {
        "id": 5411,
        "title": "Cross validation",
        "authors": "J.S. Urban Hjorth",
        "published": "2017-10-19",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781315140056-3"
    },
    {
        "id": 5412,
        "title": "A Comparative Study of the Use of Stratified Cross-Validation and Distribution-Balanced Stratified Cross-Validation in Imbalanced Learning",
        "authors": "Szilvia Szeghalmy, Attila Fazekas",
        "published": "2023-2-20",
        "citations": 18,
        "abstract": "Nowadays, the solution to many practical problems relies on machine learning tools. However, compiling the appropriate training data set for real-world classification problems is challenging because collecting the right amount of data for each class is often difficult or even impossible. In such cases, we can easily face the problem of imbalanced learning. There are many methods in the literature for solving the imbalanced learning problem, so it has become a serious question how to compare the performance of the imbalanced learning methods. Inadequate validation techniques can provide misleading results (e.g., due to data shift), which leads to the development of methods designed for imbalanced data sets, such as stratified cross-validation (SCV) and distribution optimally balanced SCV (DOB-SCV). Previous studies have shown that higher classification performance scores (AUC) can be achieved on imbalanced data sets using DOB-SCV instead of SCV. We investigated the effect of the oversamplers on this difference. The study was conducted on 420 data sets, involving several sampling methods and the DTree, kNN, SVM, and MLP classifiers. We point out that DOB-SCV often provides a little higher F1 and AUC values for classification combined with sampling. However, the results also prove that the selection of the sampler–classifier pair is more important for the classification performance than the choice between the DOB-SCV and the SCV techniques.",
        "link": "http://dx.doi.org/10.3390/s23042333"
    },
    {
        "id": 5413,
        "title": "Estimator Nadaraya-Watson dengan Pendekatan Cross Validation dan Generalized Cross Validation untuk Mengestimasi Produksi Jagung",
        "authors": "Febriolah Lamusu, Tedy Machmud, Resmawan Resmawan",
        "published": "2021-1-23",
        "citations": 0,
        "abstract": "<p>Nadaraya-Watson Estimator with kernel approach depends on two-parameter, those are kernel function and bandwidth choice. However, between the two of them, bandwidth choice gave a huge impact on the result of the estimation. By minimizing the value of Mean Square Error (MSE), Cross-Validation (CV) and Generalized Cross-Validation (GCV) gave the optimal bandwidth value. In this research, corn production was considered as the dependent variable, while the planted area, harvested area, and the fertilizer as the independent variable. The result of this research showed that Nadaraya-Watson Estimator with Generalized Cross-Validation gives a better corn production estimation with optimal bandwidth value 742392,2, with and  with MSE 202583,9.</p><p><strong>Keywords</strong>: kernel, estimator Nadaraya-Watson, cross validation, generalized cross validation.</p>",
        "link": "http://dx.doi.org/10.13057/ijas.v3i2.42125"
    },
    {
        "id": 5414,
        "title": "A Note on Time Series Cross Validation",
        "authors": "Ai Deng",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4366573"
    },
    {
        "id": 5415,
        "title": "Cross-Validation",
        "authors": "",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4135/9781071812082.n138"
    },
    {
        "id": 5416,
        "title": "Review for \"Nearest Neighbour Distance Matching &lt;scp&gt;Leave‐One‐Out Cross‐Validation&lt;/scp&gt; for map validation\"",
        "authors": "",
        "published": "2021-10-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/2041-210x.13851/v1/review1"
    },
    {
        "id": 5417,
        "title": "Purposeful cross-validation: a novel cross-validation strategy for improved surrogate optimizability",
        "authors": "Daniel Correia, Daniel N. Wilke",
        "published": "2021-9-2",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1080/0305215x.2020.1807017"
    },
    {
        "id": 5418,
        "title": "Review for \"Nearest Neighbour Distance Matching &lt;scp&gt;Leave‐One‐Out Cross‐Validation&lt;/scp&gt; for map validation\"",
        "authors": "",
        "published": "2021-12-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/2041-210x.13851/v1/review3"
    },
    {
        "id": 5419,
        "title": "Excuse Validation: A Cross-cultural Study",
        "authors": "John Turri",
        "published": "No Date",
        "citations": 0,
        "abstract": "If someone unintentionally breaks the rules, do they break the rules? In the abstract, the answer is obviously “yes.” But, surprisingly, when considering specific examples of unintentional, blameless rule-breaking, approximately half of people judge that no rule was broken. This effect, known as excuse validation, has previously been observed in American adults. Outstanding questions concern what causes excuse validation, and whether it is peculiar to American moral psychology or cross-culturally robust. The present paper studies the phenomenon cross-culturally, focusing on Korean and American adults, and proposes a new explanation of why people engage in excuse validation, in terms of competing forces in human norm-psychology. The principal findings are that Americans and Koreans engaged in excuse validation at similar levels, and older adults were more likely to engage in excuse validation.",
        "link": "http://dx.doi.org/10.31219/osf.io/w89sm"
    },
    {
        "id": 5420,
        "title": "Cross Validation",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4135/9781483381411.n115"
    },
    {
        "id": 5421,
        "title": "Review for \"Nearest Neighbour Distance Matching &lt;scp&gt;Leave‐One‐Out Cross‐Validation&lt;/scp&gt; for map validation\"",
        "authors": "Carsten Dormann",
        "published": "2021-11-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/2041-210x.13851/v1/review2"
    },
    {
        "id": 5422,
        "title": "Cross-Validation",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_190"
    },
    {
        "id": 5423,
        "title": "Cross-validation and permutations in MVPA: Validity of permutation strategies and power of cross-validation schemes",
        "authors": "Giancarlo Valente, Agustin Lage Castellanos, Lars Hausfeld, Federico De Martino, Elia Formisano",
        "published": "2021-9",
        "citations": 33,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neuroimage.2021.118145"
    },
    {
        "id": 5424,
        "title": "Decision letter for \"Nearest Neighbour Distance Matching &lt;scp&gt;Leave‐One‐Out Cross‐Validation&lt;/scp&gt; for map validation\"",
        "authors": "",
        "published": "2022-3-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/2041-210x.13851/v2/decision1"
    },
    {
        "id": 5425,
        "title": "Decision letter for \"Nearest Neighbour Distance Matching &lt;scp&gt;Leave‐One‐Out Cross‐Validation&lt;/scp&gt; for map validation\"",
        "authors": "",
        "published": "2021-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/2041-210x.13851/v1/decision1"
    },
    {
        "id": 5426,
        "title": "Modify Leave-One-Out Cross Validation by Moving Validation Samples around Random Normal Distributions: Move-One-Away Cross Validation",
        "authors": "Liye Lv, Xueguan Song, Wei Sun",
        "published": "2020-4-3",
        "citations": 2,
        "abstract": "The leave-one-out cross validation (LOO-CV), which is a model-independent evaluate method, cannot always select the best of several models when the sample size is small. We modify the LOO-CV method by moving a validation point around random normal distributions—rather than leaving it out—naming it the move-one-away cross validation (MOA-CV), which is a model-dependent method. The key point of this method is to improve the accuracy rate of model selection that is unreliable in LOO-CV without enough samples. Errors from LOO-CV and MOA-CV, i.e., LOO-CVerror and MOA-CVerror, respectively, are employed to select the best one of four typical surrogate models through four standard mathematical functions and one engineering problem. The coefficient of determination (R-square, R2) is used to be a calibration of MOA-CVerror and LOO-CVerror. Results show that: (i) in terms of selecting the best models, MOA-CV and LOO-CV become better as sample size increases; (ii) MOA-CV has a better performance in selecting best models than LOO-CV; (iii) in the engineering problem, both the MOA-CV and LOO-CV can choose the worst models, and in most cases, MOA-CV has a higher probability to select the best model than LOO-CV.",
        "link": "http://dx.doi.org/10.3390/app10072448"
    },
    {
        "id": 5427,
        "title": "Cross-Validation",
        "authors": "Daniel Berrar",
        "published": "2019",
        "citations": 419,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-809633-8.20349-x"
    },
    {
        "id": 5428,
        "title": "Cross-validation and cross-study validation of kidney cancer with machine learning and whole exome sequences from the National Cancer Institute",
        "authors": "Abdulrhman Aljouie, Nihir Patel, Usman Roshan",
        "published": "2018-5",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cibcb.2018.8404967"
    },
    {
        "id": 5429,
        "title": "Stratified Cross Validation",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_788"
    },
    {
        "id": 5430,
        "title": "Response_to_Reviewers",
        "authors": "Eben Cross",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5194/amt-2017-138-ac1"
    },
    {
        "id": 5431,
        "title": "Validation of nonlinear physics in cross-beam energy transfer [Slides]",
        "authors": "Lin Yin",
        "published": "2021-5-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2172/1781350"
    },
    {
        "id": 5432,
        "title": "Estimation of Large Financial Covariances: A Cross-Validation Approach",
        "authors": "Vincent Tan, Stefan Zohren",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4418630"
    },
    {
        "id": 5433,
        "title": "Genetic Algorithm Based Critical Experiment Design for Uranium Cross Section Validation",
        "authors": "Dominik Fritz",
        "published": "2018-8-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2172/1463589"
    },
    {
        "id": 5434,
        "title": "Cross-Validation",
        "authors": "Payam Refaeilzadeh, Lei Tang, Huan Liu",
        "published": "2018",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4614-8265-9_565"
    },
    {
        "id": 5435,
        "title": "Targeted cross-validation",
        "authors": "Jiawei Zhang, Jie Ding, Yuhong Yang",
        "published": "2023-2-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3150/22-bej1461"
    },
    {
        "id": 5436,
        "title": "Evaluating the accuracy of equivalent-source predictions using cross-validation",
        "authors": "Leonardo Uieda, Santiago Soler",
        "published": "No Date",
        "citations": 0,
        "abstract": "\n        &lt;p&gt;We investigate the use of cross-validation (CV) techniques to estimate the accuracy of equivalent-source (also known as equivalent-layer) models for interpolation and processing of potential-field data. Our preliminary results indicate that some common CV algorithms (e.g., random permutations and k-folds) tend to overestimate the accuracy. We have found that blocked CV methods, where the data are split along spatial blocks instead of randomly, provide more conservative and realistic accuracy estimates. Beyond evaluating an equivalent-source model's performance, cross-validation can be used to automatically determine configuration parameters, like source depth and amount of regularization, that maximize prediction accuracy and avoid over-fitting.&lt;/p&gt;&lt;p&gt;Widely used in gravity and magnetic data processing, the equivalent-source technique consists of a linear model (usually point sources) used to predict the observed field at arbitrary locations. Upward-continuation, interpolation, gradient calculations, leveling, and reduction-to-the-pole can be performed simultaneously by using the model to make predictions (i.e., forward modelling). Likewise, the use of linear models to make predictions is the backbone of many machine learning (ML) applications. The predictive performance of ML models is usually evaluated through cross-validation, in which the data are split (usually randomly) into a training set and a validation set. Models are fit on the training set and their predictions are evaluated using the validation set using a goodness-of-fit metric, like the mean square error or the R&amp;#178; coefficient of determination. Many cross-validation methods exist in the literature, varying in how the data are split and how this process is repeated. Prior research from the statistical modelling of ecological data suggests that prediction accuracy is usually overestimated by traditional CV methods when the data are spatially auto-correlated. This issue can be mitigated by splitting the data along spatial blocks rather than randomly. We conducted experiments on synthetic gravity data to investigate the use of traditional and blocked CV methods in equivalent-source interpolation. We found that the overestimation problem also occurs and that more conservative accuracy estimates are obtained when applying blocked versions of random permutations and k-fold. Further studies need to be conducted to generalize these findings to upward-continuation, reduction-to-the-pole, and derivative calculation.&lt;/p&gt;&lt;p&gt;Open-source software implementations of the equivalent-source and blocked cross-validation (in progress) methods are available in the Python libraries Harmonica and Verde, which are part of the Fatiando a Terra project (www.fatiando.org).&lt;/p&gt;\n        ",
        "link": "http://dx.doi.org/10.5194/egusphere-egu2020-15729"
    },
    {
        "id": 5437,
        "title": "Molecular Cross-Validation for Single-Cell RNA-seq",
        "authors": "Joshua Batson, Loïc Royer, James Webber",
        "published": "No Date",
        "citations": 17,
        "abstract": "Single-cell RNA sequencing enables researchers to study the gene expression of individual cells. However, in high-throughput methods the portrait of each individual cell is noisy, representing thousands of the hundreds of thousands of mRNA molecules originally present. While many methods for denoising single-cell data have been proposed, a principled procedure for selecting and calibrating the best method for a given dataset has been lacking. We present “molecular cross-validation,” a statistically principled and data-driven approach for estimating the accuracy of any denoising method without the need for ground-truth. We validate this approach for three denoising methods—principal component analysis, network diffusion, and a deep autoencoder—on a dataset of deeply-sequenced neurons. We show that molecular cross-validation correctly selects the optimal parameters for each method and identifies the best method for the dataset.",
        "link": "http://dx.doi.org/10.1101/786269"
    },
    {
        "id": 5438,
        "title": "Leave-One-Out Cross-Validation",
        "authors": "",
        "published": "2017",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_469"
    },
    {
        "id": 5439,
        "title": "Early Lung Cancer Prediction Using Neural Network with Cross-Validation",
        "authors": "Samir Bandyopadhyay, Shawni Dutta",
        "published": "No Date",
        "citations": 3,
        "abstract": "Lung cancer is known as lung carcinoma. It is a disease which is malignant tumor leading to the uncontrolled cell growth in the lung tissue. Lung Cancer disease is one of the most prominent cause of death in all over world. Early detection of this disease can assist medical care unit as well as physicians to provide counter measures to the patients. The objective of this paper is to approach an automated tool that takes influential causes of lung cancer as input and detect patients with higher probabilities of being affected by this disease. A neural network classifier accompanied by cross-validation technique is proposed in this paper as a predictive tool. Later, this proposed method is compared with another baseline classifier Gradient Boosting Classifier in order to justify the prediction performance.",
        "link": "http://dx.doi.org/10.20944/preprints202006.0333.v1"
    },
    {
        "id": 5440,
        "title": "The Cross-Track Infrared Sounder Overview and Validation",
        "authors": "Y. Han",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-409548-9.10392-6"
    },
    {
        "id": 5441,
        "title": "Blocked Cross–Validation: A Precise and Efficient Method for Hyperparameter Tuning",
        "authors": "Giovanni Maria Merola",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nHyperparameter tuning plays a crucial role in optimizing the performance of predictive learners. Cross--validation (CV) is a widely adopted technique for estimating the error of different hyperparameter settings. Repeated cross--validation (RCV) has been commonly employed to reduce the variability of CV errors. In this paper, we introduce a novel approach called blocked cross--validation (BCV), where the repetitions are blocked with respect to both CV partition and the random behavior of the learner. Theoretical analysis and empirical experiments demonstrate that BCV provides more precise error estimates compared to RCV, even with a significantly reduced number of runs. We present extensive examples using real--world data sets to showcase the effectiveness and efficiency of BCV in hyperparameter tuning. Our results indicate that BCV outperforms RCV in hyperparameter tuning, achieving greater precision with fewer computations.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3221138/v1"
    },
    {
        "id": 5442,
        "title": "Cross-site validation of the diagnostic accuracy of a ncRNA biomarker panel in ALS",
        "authors": "Greig Joilin",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26226/morressier.5ebd45acffea6f735881b03e"
    },
    {
        "id": 5443,
        "title": "Analytic and bootstrap-after-cross-validation methods for selecting penalty parameters of high-dimensional M-estimators",
        "authors": "",
        "published": "2022-1-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47004/wp.cem.2022.0322"
    },
    {
        "id": 5444,
        "title": "Cross-validation of bias-corrected climate simulations is misleading",
        "authors": "Douglas Maraun, Martin Widmann",
        "published": "No Date",
        "citations": 2,
        "abstract": "Abstract. We demonstrate both analytically and with a modelling example that cross-validation of free running bias-corrected climate change simulations against observations is misleading. The underlying reasoning is as follows: a cross-validation can have in principle two outcomes. A negative (in the sense of not rejecting a Null hypothesis), if the residual bias in the validation period after bias correction vanishes; and a positive, if the residual bias in the validation period after bias correction is large. It can be shown analytically that the residual bias depends solely on the difference between the simulated and observed change between calibration and validation period. These changes, however, depend mainly on the realisations of internal variability in the observations and climate model. As a consequence, also the outcome of a cross-validation is dominated by internal variability, and does not allow for any conclusion about the sensibility of a bias correction. In particular, a sensible bias correction may be rejected (false positive) and a non-sensible bias correction may be accepted (false negative). We therefore propose to avoid cross-validation when evaluating bias correction of free running bias-corrected climate change simulations against observations. Instead, one should evaluate temporal, spatial and process-based aspects.\n                        ",
        "link": "http://dx.doi.org/10.5194/hess-2018-151"
    },
    {
        "id": 5445,
        "title": "Variability Evaluation of CNNs using Cross-validation on Viruses Images",
        "authors": "André R. de Geus, André Backes, Jefferson Souza",
        "published": "2020",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009352106260632"
    },
    {
        "id": 5446,
        "title": "A relation between log-likelihood and cross-validation log-scores",
        "authors": "PierGianLuca Porta Mana",
        "published": "No Date",
        "citations": 0,
        "abstract": "It is shown that the log-likelihood of a hypothesis or model given some data is equal to an average of all leave-one-out cross-validation log-scores that can be calculated from all subsets of the data. This relation can be generalized to any k-fold cross-validation log-scores.",
        "link": "http://dx.doi.org/10.31219/osf.io/k8mj3"
    },
    {
        "id": 5447,
        "title": "Analytic and bootstrap-after-cross-validation methods for selecting penalty parameters of high-dimensional M-estimators",
        "authors": "",
        "published": "2021-4-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.47004/wp.cem.2021.2021"
    },
    {
        "id": 5448,
        "title": "Evolutionary cross validation",
        "authors": "Thineswaran Gunasegaran, Yu-N Cheah",
        "published": "2017-5",
        "citations": 21,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icitech.2017.8079960"
    },
    {
        "id": 5449,
        "title": "Author response for \"Nearest Neighbour Distance Matching &lt;scp&gt;Leave‐One‐Out Cross‐Validation&lt;/scp&gt; for map validation\"",
        "authors": " Carles Milà,  Jorge Mateu,  Edzer Pebesma,  Hanna Meyer",
        "published": "2022-2-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1111/2041-210x.13851/v2/response1"
    },
    {
        "id": 5450,
        "title": "Performance of Nested vs. Non-Nested SVM Cross-Validation Methods in Visual BCI: Validation Study",
        "authors": "Mohammed J. Abdulaal, Alexander J. Casson, Patrick Gaydecki",
        "published": "2018-9",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23919/eusipco.2018.8553102"
    },
    {
        "id": 5451,
        "title": "Pitfalls and Remedies for Cross Validation with Multi-trait Genomic Prediction Methods",
        "authors": "Daniel Runcie, Hao Cheng",
        "published": "No Date",
        "citations": 0,
        "abstract": "ABSTRACTIncorporating measurements on correlated traits into genomic prediction models can increase prediction accuracy and selection gain. However, multi-trait genomic prediction models are complex and prone to overfitting which may result in a loss of prediction accuracy relative to single-trait genomic prediction. Cross-validation is considered the gold standard method for selecting and tuning models for genomic prediction in both plant and animal breeding. When used appropriately, cross-validation gives an accurate estimate of the prediction accuracy of a genomic prediction model, and can effectively choose among disparate models based on their expected performance in real data. However, we show that a naive cross-validation strategy applied to the multi-trait prediction problem can be severely biased and lead to sub-optimal choices between single and multi-trait models when secondary traits are used to aid in the prediction of focal traits and these secondary traits are measured on the individuals to be tested. We use simulations to demonstrate the extent of the problem and propose three partial solutions: 1) a parametric solution from selection index theory, 2) a semi-parametric method for correcting the cross-validation estimates of prediction accuracy, and 3) a fully non-parametric method which we call CV2*: validating model predictions against focal trait measurements from genetically related individuals. The current excitement over high-throughput phenotyping suggests that more comprehensive phenotype measurements will be useful for accelerating breeding programs. Using an appropriate cross-validation strategy should more reliably determine if and when combining information across multiple traits is useful.",
        "link": "http://dx.doi.org/10.1101/595397"
    },
    {
        "id": 5452,
        "title": "Consensus Features Nested Cross-Validation",
        "authors": "Saeid Parvandeh, Hung-Wen Yeh, Martin P. Paulus, Brett A. McKinney",
        "published": "No Date",
        "citations": 4,
        "abstract": "AbstractMotivationFeature selection can improve the accuracy of machine learning models, but appropriate steps must be taken to avoid overfitting. Nested cross-validation (nCV) is a common approach that chooses the classification model and features to represent a given outer fold based on features that give the maximum inner-fold accuracy. Differential privacy is a related technique to avoid overfitting that uses a privacy preserving noise mechanism to identify features that are stable between training and holdout sets.MethodsWe develop consensus nested CV (cnCV) that combines the idea of feature stability from differential privacy with nested CV. Feature selection is applied in each inner fold and the consensus of top features across folds is a used as a measure of feature stability or reliability instead of classification accuracy, which is used in standard nCV. We use simulated data with main effects, correlation, and interactions to compare the classification accuracy and feature selection performance of the new cnCV with standard nCV, Elastic Net optimized by CV, differential privacy, and private Evaporative Cooling (pEC). We also compare these methods using real RNA-Seq data from a study of major depressive disorder.ResultsThe cnCV method has similar training and validation accuracy to nCV, but cnCV has much shorter run times because it does not construct classifiers in the inner folds. The cnCV method chooses a more parsimonious set of features with fewer false positives than nCV. The cnCV method has similar accuracy to pEC and cnCV selects stable features between folds without the need to specify a privacy threshold. We show that cnCV is an effective and efficient approach for combining feature selection with classification.AvailabilityCode available at https://github.com/insilico/cncv.Contactbrett.mckinney@utulsa.eduSupplementary information:",
        "link": "http://dx.doi.org/10.1101/2019.12.31.891895"
    },
    {
        "id": 5453,
        "title": "Identifying the best approximating model in Bayesian phylogenetics: Bayes factors, cross-validation or wAIC?",
        "authors": "Nicolas Lartillot",
        "published": "No Date",
        "citations": 1,
        "abstract": "AbstractThere is still no consensus as to how to select models in Bayesian phylogenetics, and more generally in applied Bayesian statistics. Bayes factors are often presented as the method of choice, yet other approaches have been proposed, such as cross-validation or information criteria. Each of these paradigms raises specific computational challenges, but they also differ in their statistical meaning, being motivated by different objectives: either testing hypotheses or finding the best-approximating model. These alternative goals entail different compromises, and as a result, Bayes factors, cross-validation and information criteria may be valid for addressing different questions. Here, the question of Bayesian model selection is revisited, with a focus on the problem of finding the best-approximating model. Several model selection approaches were re-implemented, numerically assessed and compared: Bayes factors, cross-validation (CV), in its different forms (k-fold or leave-one-out), and the widely applicable information criterion (wAIC), which is asymptotically equivalent to leave-one-out cross validation (LOO-CV). Using a combination of analytical results and empirical and simulation analyses, it is shown that Bayes factors are unduly conservative. In contrast, cross-validation represents a more adequate formalism for selecting the model returning the best approximation of the data-generating process and the most accurate estimates of the parameters of interest. Among alternative CV schemes, LOO-CV and its asymptotic equivalent represented by the wAIC, stand out as the best choices, conceptually and computationally, given that both can be simultaneously computed based on standard MCMC runs under the posterior distribution.",
        "link": "http://dx.doi.org/10.1101/2022.04.22.489153"
    },
    {
        "id": 5454,
        "title": "Computational Modeling and Experiment Validation of a Microchannel Cross-Flow Heat Exchanger",
        "authors": "Mahdi Ghorbani, Hailei Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4461967"
    },
    {
        "id": 5455,
        "title": "Peer Review #2 of \"Discrete natural neighbour interpolation with uncertainty using cross-validation error-distance fields (v0.1)\"",
        "authors": "",
        "published": "2020-7-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.282v0.1/reviews/2"
    },
    {
        "id": 5456,
        "title": "Peer Review #1 of \"Discrete natural neighbour interpolation with uncertainty using cross-validation error-distance fields (v0.1)\"",
        "authors": "",
        "published": "2020-7-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.282v0.1/reviews/1"
    },
    {
        "id": 5457,
        "title": "Enhancing Disease Classification in Paddy Fields: A Stratified Cross-Validation Approach",
        "authors": "Elakya R, T. Manoranjitham",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nIn India rice (Oryza sativa) is an important food staple. It is the third highest production among worldwide. Rice is highly rich in calorie so morethan one-fifth of the population in world consumed Rice. Abiotic and Biotic factors plays a vital role in production of Rice as it affects and causes more damage. Biotic factors like diseases and pests leads to 70% of loss in crop production. Identifying diseases in early stage is a tedious concern for every farmer. Once the disease is predicted in early stage, solution or necessary steps can be taken to reduce the damage. Agricultural officers or External experts have to check manually and give the remedial solutions for this issue. But, due to lack of available resource external experts cannot visit field for every time. So identifying the correct disease is very difficult. One solution for this concern is by using latest advancement in technology. Convolutional Neural network is mainly used for classifying images. We have taken 10,407 labelled images for training the model and 3,469 images for testing the model. We used transfer learning model namely InceptionV3, ResNet50, VGG16, MobileNetV2, and EfficientNetB0 to obtain the result. Finally CNN model ResNet is applied with Stratified Cross-validation fastai techniques. K-fold cross validation strategy obtained an highest accuracy of 98.81% which is more accurate than traditional Transfer learning models.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3376908/v1"
    },
    {
        "id": 5458,
        "title": "Rejoinder: More Limitations of Bayesian Leave-One-Out Cross-Validation",
        "authors": "Quentin Frederik Gronau, Eric-Jan Wagenmakers",
        "published": "No Date",
        "citations": 0,
        "abstract": "We recently discussed several limitations of Bayesian leave-one-out cross-validation (LOO) for model selection. Our contribution attracted three thought-provoking commentaries. In this rejoinder, we address each of the commentaries and identify several additional limitations of LOO-based methods such as Bayesian stacking. We focus on differences between LOO-based methods versus approaches that consistently use Bayes' rule for both parameter estimation and model comparison. We conclude that LOO-based methods do not align satisfactorily with the epistemic goal of mathematical psychology.",
        "link": "http://dx.doi.org/10.31234/osf.io/38zxu"
    },
    {
        "id": 5459,
        "title": "Computational Modeling and Experiment Validation of a Microchannel Cross-Flow Heat Exchanger",
        "authors": "Mahdi Ghorbani, Hailei Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4540690"
    },
    {
        "id": 5460,
        "title": "Using K-Fold Cross Validation and ResNet Ensembles to Predict Cooking States",
        "authors": "Fred Mubang",
        "published": "2019-4-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32555/2019.dl.017"
    },
    {
        "id": 5461,
        "title": "Time Series Cross Validation: Theoretical Properties and Empirical Performance",
        "authors": "Ai Deng",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3996529"
    },
    {
        "id": 5462,
        "title": "Translation into Spanish, Cross-cultural Adaptation and Validation of an Advance Care Planning Self-efficacy Scale",
        "authors": "Cristina Lasmarías",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26226/morressier.5c76c8bce2ea5a7237612695"
    },
    {
        "id": 5463,
        "title": "Limitations of Bayesian Leave-One-Out Cross-Validation for Model Selection",
        "authors": "Quentin Frederik Gronau, Eric-Jan Wagenmakers",
        "published": "No Date",
        "citations": 6,
        "abstract": "Cross-validation (CV) is increasingly popular as a generic method to adjudicate between mathematical models of cognition and behavior. In order to measure model generalizability, CV quantifies out-of-sample predictive performance, and the CV preference goes to the model that predicted the out-of-sample data best. The advantages of CV include theoretic simplicity and practical feasibility. Despite its prominence, however, the limitations of CV are often underappreciated. Here we demonstrate the limitations of a particular form of CV --Bayesian leave-one-out cross-validation or LOO-- with three concrete examples. In each example, a data set of infinite size is perfectly in line with the predictions of a simple model (i.e., a general law or invariance). Nevertheless, LOO shows bounded and relatively modest support for the simple model. We conclude that CV is not a panacea for model selection.",
        "link": "http://dx.doi.org/10.31234/osf.io/at7cx"
    },
    {
        "id": 5464,
        "title": "GPT-Neo-CRV: Elevating Information Accuracy in GPT-Neo with Cross-Referential Validation",
        "authors": "Xingyu Xiong, Mingliang Zheng",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.36227/techrxiv.170473976.61241065/v1"
    },
    {
        "id": 5465,
        "title": "Nonparametric Regression Mixed Estimators of Truncated Spline and Gaussian Kernel based on Cross-Validation (CV), Generalized Cross-Validation (GCV), and Unbiased Risk (UBR) Methods",
        "authors": "Vita Ratnasari, I Nyoman Budiantara, Andrea Tri Rian Dani",
        "published": "2021-12-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18517/ijaseit.11.6.14464"
    },
    {
        "id": 5466,
        "title": "Possibly Nonstationary Cross-Validation",
        "authors": "Federico M. Bandi, Valentina Corradi, Daniel Wilhelm",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.2748510"
    },
    {
        "id": 5467,
        "title": "APLIKASI CROSS VALIDATION  PADA  MODEL SKILL SISWA",
        "authors": "Wahyu Hartono",
        "published": "2020-7-15",
        "citations": 0,
        "abstract": "One of the activities in the educational test is making a diagnosis to determine whether or not a person's skills are present. This study specifically aims to design student skill models in basic mathematics courses and perform validation using a leave-one-out cross validation to select an accurate model. The diagnostic test questions used in this study ranged from moderate to difficult. The findings of this study indicate that the method of fixed test questions in order of questions from easy to difficult is better than the method of design of the initial fixed test questions. Keywords: Bayes Network, Cross Validation, Student Skill Model, Diagnostic test",
        "link": "http://dx.doi.org/10.33603/e.v7i2.4220"
    },
    {
        "id": 5468,
        "title": "K-fold Cross-validation of Multiple-point Statistical Simulations",
        "authors": "P. Juda, P. Renard, J. Straubhaar",
        "published": "2019",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.3997/2214-4609.201902239"
    },
    {
        "id": 5469,
        "title": "Peer Review #2 of Cross-validation of conserved osteoblast-specific enhancers illuminates bone diseases and early skeletal evolution",
        "authors": "",
        "published": "2024-1-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15252/rc.2024661223"
    },
    {
        "id": 5470,
        "title": "Peer Review #1 of Cross-validation of conserved osteoblast-specific enhancers illuminates bone diseases and early skeletal evolution",
        "authors": "",
        "published": "2024-1-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15252/rc.2024924651"
    },
    {
        "id": 5471,
        "title": "Peer Review #3 of Cross-validation of conserved osteoblast-specific enhancers illuminates bone diseases and early skeletal evolution",
        "authors": "",
        "published": "2024-1-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15252/rc.2024979099"
    },
    {
        "id": 5472,
        "title": "Maneuver-Based Cross-Validation Approach for Angle-of-Attack Estimation",
        "authors": "A. Brandl, M. Battipede",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23967/wccm-eccomas.2020.192"
    },
    {
        "id": 5473,
        "title": "Coronary artery disease classification with support vector machines tuned via randomized search cross-validation",
        "authors": "Kemal Akyol",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nCoronary artery disease outstands health problem that causes high mortality in the world population. This disease brings with it fateful problems such as heart attack and heart failure in patients with cardiovascular problems. Early diagnosis of coronary artery disease is essential for timely administration of the right treatment and reduction of mortality. Angiography is the most preferred method for CAD detection. However, the complications and costs of this method have led researchers to forage alternative methods through machine learning algorithms. By developing a machine learning model with high generalization ability, prediction errors can be minimized. Thus, these models could potentially be useful for specialist physicians in the effective detection of coronary artery disease. The main focus of this study is to perform coronary artery disease detection with improved support vector machines. k-fold cross-validation experiments were performed on the Z-Alizadeh Sani dataset to evaluate the performance of the models. According to the results obtained, support vector machines with randomize search cross validation provided best performance when compared to other models. 87.102% average accuracy, 91.176% average sensitivity, 90.852% average precision, 76.996% average specificity, and also 8.824% average false negative rate obtained by 5-fold cross validation competes with the known approaches in the literature.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1551634/v1"
    },
    {
        "id": 5474,
        "title": "Evaluation of Analysis by Cross-Validation. Part I: Using Verification Metrics",
        "authors": "Richard Menard, Martin Deshaies-Jacques",
        "published": "No Date",
        "citations": 3,
        "abstract": "We examine how observations can be used to evaluate an air quality analysis by verifying against passive observations (i.e. cross-validation) that are not used to create the analysis and we compare these verifications to those made against the same set of (active) observations that were used to generate the analysis. The results show that both active and passive observations can be used to evaluate of first moment metrics (e.g. bias) but only passive observations are useful to evaluate second moment metrics such as variance of observed-minus-analysis and correlation between observations and analysis. We derive a set of diagnostics based on passive observation&ndash;minus-analysis residuals and we show that the true analysis error variance can be estimated, without relying on any statistical optimality assumption. This diagnostic is used to obtain near optimal analyses that are then used to evaluate the analysis error using several different methods. We compare the estimates according to the method of Hollingsworth Lonnberg, Desroziers, a diagnostic we introduce, and the perceived analysis error computed from the analysis scheme, to conclude that as long as the analysis is optimal, all estimates agrees within a certain error margin. The analysis error variance at passive observation sites is also obtained.",
        "link": "http://dx.doi.org/10.20944/preprints201801.0217.v1"
    },
    {
        "id": 5475,
        "title": "İnşaat Maliyet Endeksi Tahmininde Holt-Winters Üstel Düzeltme Parametrelerinin PSO ve İleri Walk-Forward Cross-Validation ile Optimizasyonu",
        "authors": "Özlem TÜZ EBESEK, Şafak EBESEK",
        "published": "2023-12-16",
        "citations": 0,
        "abstract": "This research aims to enhance the accuracy of Construction Cost Index (CCI) forecasting using Holt-Winters exponential smoothing (ES) by optimizing its parameters, focusing on minimizing the Mean Absolute Percentage Error (MAPE) for precise CCI forecasts. To reach this aim, The Holt-Winters model parameters are optimized through Particle Swarm Optimization (PSO) and Walk-Forward Cross-Validation (WFCV). PSO, a metaheuristic optimization algorithm, is being applied to search for optimal values of the smoothing parameters (alpha, beta, and gamma) that determine the weightage of past observations, trends, and seasonality, respectively. WFCV is assessed the model's performance and ensures robustness. Reduced MAPEs of 22 for CCI forecasts and 2 for training data are the findings of the optimized Holt-Winters model. The obtained alpha, beta, and gamma values are 0.99, 0.77, and 0, respectively, highlighting the importance of while neglecting seasonality. Convergence graphs demonstrate the superiority of the optimization approach over conventional parameter values or random selections. By employing PSO and WFCV, the study efficiently fine-tunes the Holt-Winters model for precise CCI forecasting. Optimized parameter values enable data driven decision-making in construction project cost estimation and budget management. This research contributes a reliable and robust optimization methodology for CCI forecasting, supporting advancements in the field.",
        "link": "http://dx.doi.org/10.35674/kent.1343590"
    },
    {
        "id": 5476,
        "title": "Cross-validation of correlation networks using modular structure",
        "authors": "Magnus Neuman, Viktor Jonsson, Joaquín Calatayud, Martin Rosvall",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nCorrelation networks derived from multivariate data appear in many applications across the sciences. These networks are usually dense and require sparsification to detect meaningful structure. However, current methods for sparsifying correlation networks struggle with balancing overfitting and underfitting. We propose a module-based cross-validation procedure to threshold these networks, making modular structure an integral part of the thresholding. We illustrate our approach using synthetic and real data and find that its ability to recover a planted partition has a step-like dependence on the number of data samples. The reward for sampling more varies non-linearly with the number of samples, with minimal gains after a critical point. A comparison with the well-established WGCNA method shows that our approach allows for revealing more modular structure in the data used here.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2069260/v1"
    },
    {
        "id": 5477,
        "title": "Coronary artery disease classification using support vector machines tuned via randomized search cross-validation",
        "authors": "Kemal Akyol",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nCoronary artery disease outstands health problem that causes high mortality in the world population. This disease brings with it fateful problems such as heart attack and heart failure in patients with cardiovascular problems. Early diagnosis of coronary artery disease is essential for the timely administration of the right treatment and reduction of mortality. Angiography is the most preferred method for CAD detection. However, the complications and costs of this method have led researchers to forage alternative methods through machine learning algorithms. By developing a machine learning model with high generalization ability, prediction errors can be minimized. Thus, these models could potentially be useful for specialist physicians in the effective detection of coronary artery disease. The main focus of this study is to perform coronary artery disease detection with improved support vector machines. k-fold cross-validation experiments were performed on the Z-Alizadeh Sani dataset to evaluate the performance of the models. According to the results obtained, support vector machines with randomized search cross-validation provided the best performance when compared to other models. 87.102% average accuracy, 91.176% average sensitivity, 90.852% average precision, 76.996% average specificity, and also 8.824% average false negative rate obtained by 5-fold cross-validation competes with the known approaches in the literature.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2459099/v1"
    },
    {
        "id": 5478,
        "title": "Validation of a Mathematical Model of Ultrasonic Cross-Correlation Flow Meters Based on Industrial Experience",
        "authors": "vi ton",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4470069"
    },
    {
        "id": 5479,
        "title": "Validation of machine learning ridge regression models using Monte Carlo, bootstrap, and variations in cross-validation",
        "authors": "Robbie T. Nakatsu",
        "published": "2023-7-19",
        "citations": 1,
        "abstract": "Abstract\nIn recent years, there have been several calls by practitioners of machine learning to provide more guidelines on how to use its methods and techniques. For example, the current literature on resampling methods is confusing and sometimes contradictory; worse, there are sometimes no practical guidelines offered at all. To address this shortcoming, a simulation study was conducted that evaluated ridge regression models fitted on five real-world datasets. The study compared the performance of four resampling methods, namely, Monte Carlo resampling, bootstrap, k-fold cross-validation, and repeated k-fold cross-validation. The goal was to find the best-fitting λ (regularization) parameter that would minimize mean squared error, by using nine variations of these resampling methods. For each of the nine resampling variations, 1,000 runs were performed to see how often a good fit, average fit, and poor fit λ value would be chosen. The resampling method that chose good fit values the greatest number of times was deemed the best method. Based on the results of the investigation, three general recommendations are made: (1) repeated k-fold cross-validation is the best method to select as a general-purpose resampling method; (2) k = 10 folds is a good choice in k-fold cross-validation; (3) Monte Carlo and bootstrap are underperformers, so they are not recommended as general-purpose resampling methods. At the same time, no resampling method was found to be uniformly better than the others.",
        "link": "http://dx.doi.org/10.1515/jisys-2022-0224"
    },
    {
        "id": 5480,
        "title": "Translation, cross-cultural adaptation, and validation of the Duke Activity Status Index (DASI) to Sinhala language: Translation, cross-cultural adaptation, and validation study",
        "authors": "C. Ranasinghe, K. Kariyawasam, J. Liyanage, Y. Walpita, U. Rajasinghe, A. Abayadeera, P. Chandrasinghe, M. Gunasekara, S. Kumarage, M. Silva, K. Ranathunga, K. Deen, H. Ismail",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nBackground\n Duke Activity Status Index (DASI) is a widely used tool to assess functional capacity among patients, but there is no Sri Lankan version validated for patients in Sri Lanka. This study aimed to cross culturally adapt and test validity and reliability of Sinhala version of DASI (DASI-SL).\nMethods\n The questionnaire was translated using forward and backward translation methods and cultural adaptation was conducted. It was pretested on ten preoperative patients and further modified. Construct validity and reliability of DASI-SL was assessed by administering the modified final DASI-SL on eighty-one patients who were awaiting non-cardiac surgeries at university surgical wards, National Hospital of Sri Lanka, and Colombo North Teaching Hospital Sri Lanka.\nResults\n The Cronbach's α coefficient for the internal consistency of DASI-SL was 0.861. The concurrent validity of DASI-SL was substantiated by positively correlating (p < 0.01, rs = 0.466) with the physical subscale of SF-36. There was a significant difference (p < 0.01) in the total score of DASI-SL between two age groups.\nConclusions\n The Sri Lankan version of the DASI appears to be a valid, reliable and easy to administer tool to assess functional capacity among patients who are awaiting non-cardiac surgeries.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3874874/v1"
    },
    {
        "id": 5481,
        "title": "Cross Validation",
        "authors": "David B. Hibbert",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/iupac.88.0065"
    },
    {
        "id": 5482,
        "title": "Cross-Layer Inference in WSN: From Methods to Experimental Validation",
        "authors": "Indrakshi Dey",
        "published": "2021-9-15",
        "citations": 0,
        "abstract": "In this chapter, the fundamentals of distributed inference problem in wireless sensor networks (WSN) is addressed and the statistical theoretical foundations to several applications is provided. The chapter adopts a statistical signal processing perspective and focusses on distributed version of the binary-hypothesis test for detecting an event as correctly as possible. The fusion center is assumed to be equipped with multiple antennas collecting and processing the information. The inference problem that is solved, primarily concerns the robust detection of a phenomenon of interest (for example, environmental hazard, oil/gas leakage, forest fire). The presence of multiple antennas at both transmit and receive sides resembles a multiple-input-multiple-output (MIMO) system and allows for utilization of array processing techniques providing spectral efficiency, fading mitigation and low energy sensor adoption. The problem is referred to as MIMO decision fusion. Subsequently, both design and evaluation (simulated and experimental) of these fusion approaches is presented for this futuristic WSN set-up.",
        "link": "http://dx.doi.org/10.5772/intechopen.93848"
    },
    {
        "id": 5483,
        "title": "Validation of the Positive and Negative Affect Scale (PANAS) for Use with Cross-National Older Adults",
        "authors": "Sofia von Humboldt",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26226/morressier.5a7070e6d462b80290b56e9b"
    },
    {
        "id": 5484,
        "title": "Validation of Maneuvering Target RCS by Computation based on Feature Selective Validation(FSV)",
        "authors": "Zhou Bo, Dai Huanyao, Zhang Yang, Qiao Huidong",
        "published": "2018-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/csqrwc.2018.8455648"
    },
    {
        "id": 5485,
        "title": "Validation of a Measure of Positive and Negative Affect for Use with Cross-National Older Adults",
        "authors": "Sofia von Humboldt",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26226/morressier.5885d714d462b8028d89162a"
    },
    {
        "id": 5486,
        "title": "The adaptation of the cross validation aproach for RBF-based collocation methods",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4467/2353737xct.17.115.6656"
    },
    {
        "id": 5487,
        "title": "Review of Cross et al. from CMU",
        "authors": "Naomi Zimmerman",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5194/amt-2017-138-sc1"
    },
    {
        "id": 5488,
        "title": "Cross-cultural adaptation in French and validation of Functional Assessment Scale for acute Hamstring injuries (FASH)",
        "authors": "Jean-François Kaux",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.26226/morressier.5ab4d4f0d462b80296ca4f6b"
    },
    {
        "id": 5489,
        "title": "Cross-validation of quality-adjustment methods for price indexes",
        "authors": "Brian Adams, Alexander Klayman",
        "published": "2018-6-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21916/mlr.2018.18"
    },
    {
        "id": 5490,
        "title": "An Evaluation of Risk Preferences Using Cross Validation",
        "authors": "Hyoeun Park, John Rehbeck",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4102042"
    },
    {
        "id": 5491,
        "title": "Non-Invasive Blood Test Cross-Validation Study",
        "authors": " ",
        "published": "2019-6-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31525/ct1-nct03991637"
    },
    {
        "id": 5492,
        "title": "Asymptotics of K-Fold Cross Validation",
        "authors": "Jessie Li",
        "published": "2023-11-14",
        "citations": 0,
        "abstract": "This paper investigates the asymptotic distribution of the K-fold cross validation error in an i.i.d. setting. As the number of observations n goes to infinity while keeping the number of folds K fixed, the K-fold cross validation error is √ n-consistent for the expected out-of-sample error and has an asymptotically normal distribution. A consistent estimate of the asymptotic variance is derived and used to construct asymptotically valid confidence intervals for the expected out-of-sample error. A hypothesis test is developed for comparing two estimators’ expected out-of-sample errors and a subsampling procedure is used to obtain critical values. Monte Carlo simulations demonstrate the asymptotic validity of our confidence intervals for the expected out-of-sample error and investigate the size and power properties of our test. In our empirical application, we use our estimator selection test to compare the out-of-sample predictive performance of OLS, Neural Networks, and Random Forests for predicting the sale price of a domain name in a GoDaddy expiry auction.",
        "link": "http://dx.doi.org/10.1613/jair.1.13974"
    },
    {
        "id": 5493,
        "title": "Learning (I) Cross-validation &amp; OOB",
        "authors": "Shuai Huang, Houtao Deng",
        "published": "2021-4-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003102656-ch5"
    },
    {
        "id": 5494,
        "title": "Cross-National Validation of Opportunity to Learn School Experience",
        "authors": "Liuhan Cai, Hui Yang",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1037/e511112017-001"
    },
    {
        "id": 5495,
        "title": "Cross validation",
        "authors": "Rafael A. Irizarry",
        "published": "2019-11-12",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780429341830-29"
    },
    {
        "id": 5496,
        "title": "Peer Review #3 of \"Discrete natural neighbour interpolation with uncertainty using cross-validation error-distance fields (v0.1)\"",
        "authors": "A Crawford",
        "published": "2020-7-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7287/peerj-cs.282v0.1/reviews/3"
    },
    {
        "id": 5497,
        "title": "Method validation studies and an inter-laboratory cross validation study of lenvatinib assay in human plasma using LC-MS/MS",
        "authors": "Yuji Mano",
        "published": "2018-11",
        "citations": 10,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.plabm.2018.e00103"
    },
    {
        "id": 5498,
        "title": "Revealing pathway cross-talk related to diabetes mellitus by Monte Carlo Cross-Validation analysis",
        "authors": "Han-Qing Cai, Shi-Hong Lv, Chun-Jing Shi",
        "published": "2017-12-29",
        "citations": 0,
        "abstract": "AbstractObjectiveTo explore potential functional biomarkers in diabetes mellitus (DM) by utilizing gene pathway cross-talk.MethodsFirstly, potential disrupted pathways that were enriched by differentially expressed genes (DEGs) were identified based on biological pathways downloaded from the Ingenuity Pathways Analysis (IPA) database. In addition, we quantified the pathway crosstalk for each pair of pathways based on Discriminating Score (DS). Random forest (RF) classification was then employed to find the top 10 pairs of pathways with a high area under the curve (AUC) value between DM samples versus normal samples based on 10-fold cross-validation. Finally, a Monte Carlo Cross-Validation was applied to demonstrate the identified pairs of pathways by a mutual information analysis.ResultsA total of 247 DEGs in normal and disease samples were identified. Based on the F-test, 50 disrupted pathways were obtained with false discovery rate (FDR) < 0.01. Simultaneously, after calculating the DS, the top 10 pairs of pathways were selected based on a higher AUC value as measured by RF classification. From the Monte Carlo Cross-Validation, we considered the top 10 pairs of pathways with higher AUC values ranked for all 50 bootstraps as the most frequently detected ones.ConclusionThe pairs of pathways identified in our study might be key regulators in DM.",
        "link": "http://dx.doi.org/10.1515/biol-2017-0056"
    },
    {
        "id": 5499,
        "title": "Metric Learning via Cross-Validation",
        "authors": "Linlin Dai, Kani Chen, Gang Li, Yuanyuan Lin",
        "published": "2022",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5705/ss.202020.0398"
    },
    {
        "id": 5500,
        "title": "Political bullshit receptivity and its correlates: a cross-country validation of the concept",
        "authors": "Vukašin Gligorić, Allard Feddes, Bertjan Doosje",
        "published": "No Date",
        "citations": 2,
        "abstract": "Frankfurt defined persuasive communication that has no regard for truth, knowledge, or evidence as bullshit. Although there has been a lot of psychological research on pseudo-profound bullshit, no study examined this type of communication in politics. In the present research, we operationalize political bullshit receptivity as endorsing vague political statements, slogans, and political bullshit programs. We investigated the relationship of these three measures with pseudo-profound bullshit, ideology (political ideology, support for neoliberalism), populism, and voting behavior. Three pre-registered studies in different cultural settings (the United States, Serbia, The Netherlands; total N = 534) yielded medium to high intercorrelations between political bullshit measures and pseudo-profound bullshit, and good construct validity (hypothesized one-factor solution). A Bayesian meta-analysis showed that all political bullshit measures positively correlated with support for the free market, while only some positively correlated with social (political statements and programs) and economic conservatism (programs), and populism (programs). In the U.S., higher receptivity to political bullshit was associated with a higher probability that one voted for Trump (vs Clinton) in the past and higher intentions to vote for Trump (vs Biden and Sanders). In the Netherlands, higher receptivity to political bullshit predicted the intention to vote for the conservative-liberal People's Party for Freedom and Democracy. Exploratory analyses on merged datasets showed that higher receptivity to political bullshit was associated with a higher probability to vote for right-wing candidates/parties and lower probability for the left-wing ones. Overall, political bullshit endorsement showed good validity, opening avenues for research in political communication, especially when this communication is broad and meaningless.",
        "link": "http://dx.doi.org/10.31234/osf.io/u9pe3"
    }
]