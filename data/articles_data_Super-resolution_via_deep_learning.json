[
    {
        "id": 29305,
        "title": "Recovering JPEG Compression Loss via Deep Learning-Based Super Resolution Techniques",
        "authors": "Muhammet Bolat, Nurullah Çalık, Lütfiye Durak Ata",
        "published": "2023-7-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/siu59756.2023.10223843"
    },
    {
        "id": 29306,
        "title": "Deep learning-based computed tomographic image super-resolution via wavelet embedding",
        "authors": "Hyeongsub Kim, Haenghwa Lee, Donghoon Lee",
        "published": "2023-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.radphyschem.2022.110718"
    },
    {
        "id": 29307,
        "title": "Magnetic Resonance Image Super-Resolution via Multi-Resolution Learning",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23977/phpm.2023.030307"
    },
    {
        "id": 29308,
        "title": "DeepSR: A deep learning tool for image super resolution",
        "authors": "Hakan Temiz",
        "published": "2023-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.softx.2022.101261"
    },
    {
        "id": 29309,
        "title": "Deep-Learning Based Super-Resolution of Aeolianite Images on the Purpose of Edge Detection and Pattern Extraction",
        "authors": "Antigoni Panagiotopoulou, Lemonia Ragia, Niki Evelpidou",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012038600003473"
    },
    {
        "id": 29310,
        "title": "Super-Resolution Using Deep Learning Focusing on Local Reproducibility",
        "authors": "Mizuki Ishikawa, Masataka Seo",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/gcce59613.2023.10315493"
    },
    {
        "id": 29311,
        "title": "Image Super-Resolution Processing Method Based on Deep Learning",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25236/ajcis.2023.061310"
    },
    {
        "id": 29312,
        "title": "Enhancing the Resolution of Historical Ottoman Texts Using Deep Learning-Based Super-Resolution Techniques",
        "authors": "Hakan Temiz",
        "published": "2023-6-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18280/ts.400323"
    },
    {
        "id": 29313,
        "title": "Super-Resolution of Lightweight Images Based on Deep Learning",
        "authors": "Haozhe Wu",
        "published": "2024-1-26",
        "citations": 0,
        "abstract": "As digital imaging technology advances, a significant breakthrough is the emergence of super-resolution technology, a method to enhance the quality of low-resolution images to high-resolution. When there are some developing of the newest digital camera's skills, the super-resolution technology is appearing and getting more and more importance. In the simplest terms, the image super-resolution skill is the technology of which one cover the process from low resolution images to high resolution images skills. This technology differs from the traditional approach in that it is attracting more and more attention from researchers and practitioners. This method is important in the future. With the passage of time, it will be more and more mature. In this paper, we focus on how to improve image resolution by using various technologies, and summarise the results obtained in recent years. Then, we briefly introduce the background and development of super resolution, then briefly introduce the technology. Finally, we come to a few conclusions regarding Deep Learning.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/f8y87181"
    },
    {
        "id": 29314,
        "title": "Ultrasound Super Resolution Using Deep Learning Based on Attention Mechanism",
        "authors": "Xilun Liu, Mohamed Almekkawy",
        "published": "2023-4-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isbi53787.2023.10230812"
    },
    {
        "id": 29315,
        "title": "AnimeTransGAN: Animation Image Super-Resolution Transformer via Deep Generative Adversarial Network",
        "authors": "Chang-De Peng, Li-Wei Kang",
        "published": "2023-10-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/gcce59613.2023.10315278"
    },
    {
        "id": 29316,
        "title": "HoloSR: Deep Learning-based Super-Resolution for Real-Time High-Resolution Computer-Generated Holograms",
        "authors": "Siwoo Lee, Seung-Woo Nam, Juhyun Lee, Yoonchan Jeong, Byoungho lee",
        "published": "2024-3-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1364/oe.516564"
    },
    {
        "id": 29317,
        "title": "Enhancing Facial Image Resolution: Leveraging UNET++ for Super-Resolution using Deep Learning",
        "authors": "Asef Jamil Ajwad, Sk Tahmed Salim Rafid, Saurov Podder",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccit60459.2023.10441095"
    },
    {
        "id": 29318,
        "title": "Super-Resolution via Deep Enhanced Residual Generative Network with Adversarial Attentive Mechanism",
        "authors": "Allen Patnaik, Narendra Chaudhary, M. K. Bhuyan",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ocit59427.2023.10431332"
    },
    {
        "id": 29319,
        "title": "Research on Super-resolution Image Processing Based on Deep Learning",
        "authors": "Yuyan Lu, Yubian Wang",
        "published": "2023-9-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccnea60107.2023.00052"
    },
    {
        "id": 29320,
        "title": "Application of Deep Learning in Super-resolution Processing of Face Images",
        "authors": "Zhichao Zhang",
        "published": "2023-7-14",
        "citations": 0,
        "abstract": "The resolution of an image is generally defined as the number of pixels contained in a unit size. The higher the resolution, the more details it contains and the clearer the image is. Because the results of reconstructing high-resolution images from low-resolution images are not unique, the super-resolution of images is a morbid inverse problem, and it is also a challenging and open research topic in the field of computer vision. With the development of machine learning and deep neural network, this paper studies the application of DL (Deep Learning) in face image super-resolution processing. The results show that the algorithm in this paper combines detail enhancement module and synthesizes fine-grained structure from high-resolution example image, which can generate low-frequency details of the image and transmit high-frequency details from the example image to the basic image for enhancement. It can be seen that the algorithm in this paper is better than other methods in evaluation index and visual effect. However, there are still some shortcomings in this algorithm and experiment, which need further research and improvement. The two image super-resolution algorithms proposed in this paper are both aimed at improving the perceptual quality of reconstructed images.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v56i.9815"
    },
    {
        "id": 29321,
        "title": "Studies Advanced in Image Super-resolution Reconstruction based on Deep Learning",
        "authors": "Hongjie Cao",
        "published": "2023-4-1",
        "citations": 1,
        "abstract": "Image super-resolution reconstruction (SR) has always been a research hotspot in the computer vision community, whose purpose is to convert low-resolution (LR) images into high-resolution (HR) images by algorithms without changing the hardware. Early SR works were mainly based on manual features and mathematical statistical models, relying on interpolation to achieve high-resolution image reconstruction. Thanks to the rapid development of convolutional neural networks, SR based on deep learning has achieved breakthroughs in both accuracy and speed. This paper first introduces the basic principles of image super-resolution reconstruction, including the basic framework and loss function of SR. Then, we introduce the representative super-resolution reconstruction methods such as SRCNN, SRGAN, and TTSR. We also introduce the common public datasets and evaluation indexes, and compare the performance of several SR methods to analyze their advantages and disadvantages. Finally, we summarize the existing challenges in the image super-resolution reconstruction, and give a look out for the future development direction of SR.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v39i.6759"
    },
    {
        "id": 29322,
        "title": "Computational efficient deep learning-based super resolution approach",
        "authors": "Asfa Jamil, Alessandro Artusi",
        "published": "2023-6-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2665645"
    },
    {
        "id": 29323,
        "title": "Uncertainty-Supervised Super-Resolution Deep Learning Network in Diffusion MRI",
        "authors": "Chun Wang, Jiquan Ma",
        "published": "2023-4-18",
        "citations": 0,
        "abstract": "The research of uncertainty has shown great potential in the field of medical image processing. However, most of the research in the field of medical image is aimed at quantifying uncertainty. In this paper, we introduce an uncertainty supervised learning method. Specifically, we integrate the dropout variable reference and heterostatic noise model to estimate uncertainty and then guide super-resolution processing. Finally, we evaluate the enhancement effect of uncertainty supervised learning on super-resolution processing under the demonstration of DIQT model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/hset.v45i.7288"
    },
    {
        "id": 29324,
        "title": "Deep learning based denoising of super-resolution images of protein aggregates",
        "authors": "Zhongsheng Cheng",
        "published": "2023-12-20",
        "citations": 0,
        "abstract": "Neurodegenerative diseases (NDs) are closely associated with the amyloid aggregation of proteins like Amyloid-, -synuclein, and tau. Understanding the pathogenesis of NDs requires studying the structures and morphological features of these aggregates, which are typically below 100 nm in size. Traditional fluorescence microscopy is limited by the diffraction limit of light (~250 nm). Single-molecule localization microscopy (SMLM) offers a resolution down to ~20 nm, enabling the visualization of these aggregates. However, issues such as non-specific binding (NSB) of fluorophores and background noise degrade the quality of SMLM images. This study presents a U-net-based convolutional neural network (CNN) to denoise SMLM images of protein aggregates. The training dataset includes noise-free super-resolution images of aggregates and their noisy counterparts with non-specific binding signals. Various imaging conditions are simulated to mimic real-world scenarios. The U-net's output is evaluated against ground-truth images for denoising performance. Post-processing techniques further enhance denoised images. The fine-tuned U-net model achieves a validation loss of 0.0042 and low prediction errors of 0.32% and 3.71% in the area and number of aggregates, respectively. This research offers a powerful tool for denoising SMLM images, facilitating accurate characterization of protein aggregate structures and morphological features.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2753-8818/23/20231050"
    },
    {
        "id": 29325,
        "title": "Deep Learning-enabled Autofocusing and Pixel Super-Resolution in Holographic Imaging",
        "authors": "Hanlong Chen, Luzhe Huang, Tairan Liu, Aydogan Ozcan",
        "published": "2023",
        "citations": 0,
        "abstract": "We introduce the enhanced Fourier Imager Network (eFIN), a deep learning framework for generalizable holographic image reconstruction, offering adaptive pixel super-resolution and autofocusing. Tested on new sample types, eFIN demonstrates superior generalizability and robustness.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1364/fio.2023.ftu6d.2"
    },
    {
        "id": 29326,
        "title": "Single-Molecule Super-Resolution Microscopy with Light Field and Deep Learning",
        "authors": "Keyi Han, Xuanwen Hua, Xiaopeng Wang, Shu Jia",
        "published": "2023",
        "citations": 0,
        "abstract": "We propose a 3D single-molecule super-resolution imaging method with light-field microscopy and deep learning network that significantly loosen the computational burden of volumetric reconstruction while maintaining large field of view and extended depth of focus.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1364/fio.2023.fm1e.6"
    },
    {
        "id": 29327,
        "title": "Unsupervised image blind super resolution via real degradation feature learning",
        "authors": "Cheng Yang, Guanming Lu",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "AbstractIn recent years, many methods for image super‐resolution (SR) have relied on pairs of low‐resolution (LR) and high‐resolution (HR) images for training, where the degradation process is predefined by bicubic downsampling. While such approaches perform well in standard benchmark tests, they often fail to accurately replicate the complexity of real‐world image degradation. To address this challenge, researchers have proposed the use of unpaired image training to implicitly model the degradation process. However, there is a significant domain gap between the real‐world LR and the synthetic LR images from HR, which severely degrades the SR performance. A novel unsupervised image‐blind super‐resolution method that exploits degradation feature‐based learning for real‐image super‐resolution reconstruction (RDFL) is proposed. Their approach learns the degradation process from HR to LR using a generative adversarial network (GAN) and constrains the data distribution of the synthetic LR with real degraded images. The authors then encode the degraded features into a Transformer‐based SR network for image super‐resolution reconstruction through degradation representation learning. Extensive experiments on both synthetic and real datasets demonstrate the effectiveness and superiority of the RDFL method, which achieves visually pleasing reconstruction results.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cvi2.12262"
    },
    {
        "id": 29328,
        "title": "Super-Resolution of BVOC Maps by Adapting Deep Learning Methods",
        "authors": "Antonio Giganti, Sara Mandelli, Paolo Bestagini, Marco Marcon, Stefano Tubaro",
        "published": "2023-10-8",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10223169"
    },
    {
        "id": 29329,
        "title": "Deep Learning in Medical Image Super-Resolution: A Survey",
        "authors": "Vaishali Patel, Anand Mankodia",
        "published": "2023-8-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14445/22315381/ijett-v71i8p201"
    },
    {
        "id": 29330,
        "title": "A review of research on super-resolution image reconstruction based on deep learning",
        "authors": "Yu Wanjun, Liang XiaYan",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciibms60103.2023.10347780"
    },
    {
        "id": 29331,
        "title": "A Deep Learning-based Joint Image Super-resolution and Deblurring Framework",
        "authors": "Trishna Barman, Bhabesh Deka",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tai.2023.3343319"
    },
    {
        "id": 29332,
        "title": "Advancements in Image Super-Resolution: A Deep Learning Approach",
        "authors": "K.G.S. Venkatesan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.58599/ijsmien.2023.1801"
    },
    {
        "id": 29333,
        "title": "Improving deep learning-based image super-resolution with residual learning and perceptual loss using SRGAN model",
        "authors": "Rehman Abbas, Naijie Gu",
        "published": "2023-11",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00500-023-09126-4"
    },
    {
        "id": 29334,
        "title": "Real-world abnormal event detection via super-resolution and few-shot learning",
        "authors": "Limin Xia, Changhong Wei",
        "published": "2023-5-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/1.jei.32.3.033005"
    },
    {
        "id": 29335,
        "title": "A Comparative Study of Deep Learning Approaches for Amyotrophic Lateral Sclerosis Super-Resolution Image Classification",
        "authors": "Hui Miao, Mathew Horrocks, Marta Vallejo",
        "published": "2023-10-22",
        "citations": 0,
        "abstract": "Amyotrophic lateral sclerosis is a fatal degenerative neurological disease known as motor neuron disease. According to research, amyotrophic lateral sclerosis affects nerve cells related to movement in the brain and spinal cord, leading to the death of motor neurons, making the brain unable to control muscle movement, and resulting in a significant loss of motor nerve cells, leading to muscle atrophy. In the early stages of ALS, symptoms are mild, often go unnoticed, and can easily be confused with other diseases. Patients may only feel symptoms such as weakness, convulsions, and fatigue, gradually develop muscle atrophy all over the body, difficulty swallowing, and finally die of respiratory failure. TDP-43 is a DNA/RNA binding protein typically located in the nucleus regulating various steps of RNA metabolism. Meanwhile, TDP-43 is the most prominent pathological protein in the characteristics of ALS patients.[1] TDP-43 is depleted in the nucleus in nearly all ALS cases but accumulates in the cytoplasm.Deep learning is learning the internal laws and representation levels of sample data. The information obtained from these learning processes can significantly help interpret data such as text, images, and sounds. Its goal is to enable machines to analyze and learn like humans and recognize data. Additionally, super-resolution microscopy can be used to observe the conformation of proteins in biological samples, thereby gaining insight into the structure and assembly mechanism of TDP-43 aggregates.This project aims to use super-resolution images for machine learning to build a model for classifying ALS patients from non-ALS patients. At the same time, multiple neural network models are used for training and then compared to select the model with the highest accuracy.",
        "keywords": "",
        "link": "http://dx.doi.org/10.61173/nc7fkr37"
    },
    {
        "id": 29336,
        "title": "Generative Texture Super-Resolution via Differential Rendering",
        "authors": "Milena Bagdasarian, Peter Eisert, Anna Hilsmann",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012303300003660"
    },
    {
        "id": 29337,
        "title": "Tchebichef Transform Domain-Based Deep Learning Architecture for Image Super-Resolution",
        "authors": "Ahlad Kumar, Harsh Vardhan Singh, Vijeta Khare",
        "published": "2024-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2022.3188452"
    },
    {
        "id": 29338,
        "title": "Super-Resolution Infrared Imaging via Degraded Information Distillation Network",
        "authors": "Yulong Zhuang, Quan Chen",
        "published": "2023-2-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3587716.3587773"
    },
    {
        "id": 29339,
        "title": "Use of Attention Mechanism for Decoder in Deep Learning-based Image Super Resolution",
        "authors": "Hyeongyu Kim, Byungchan Choi, Haewoon Nam",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ictc58733.2023.10393268"
    },
    {
        "id": 29340,
        "title": "Deep Regression Network for the Single Image Super Resolution of Multimedia Text Image",
        "authors": "S Karthick, N Muthukumaran",
        "published": "2023-10-7",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccmla58983.2023.10346975"
    },
    {
        "id": 29341,
        "title": "Deep Learning Based Lightweight Approach to Thermal Super Resolution",
        "authors": "Basant Kumar, Darshika Sharma, Shashwat Pandey, Himanshu Singh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijbm.2023.10048267"
    },
    {
        "id": 29342,
        "title": "Deep Learning based Super-Resolution for Accurate COVID-19 diagnosis in Chest CT Images",
        "authors": "Rajeshwari P, Shyamala K",
        "published": "2023-7-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsses58299.2023.10200155"
    },
    {
        "id": 29343,
        "title": "Deep Learning Super-Resolution Network Facilitating Fiducial Tangibles on Capacitive Touchscreens",
        "authors": "Marius Rusu, Sven Mayer",
        "published": "2023-4-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3544548.3580987"
    },
    {
        "id": 29344,
        "title": "Deep learning super resolution for high-speed excitation emission matrix measurements",
        "authors": "Umberto Michelucci, Silvan Fluri, Michael Baumgartner, Francesca Venturini",
        "published": "2023-3-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2647589"
    },
    {
        "id": 29345,
        "title": "Evaluating Deep Learning Techniques for Blind Image Super-Resolution within a High-Scale Multi-Domain Perspective",
        "authors": "Valdivino Alexandre de Santiago Júnior",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "Despite several solutions and experiments have been conducted recently addressing image super-resolution (SR), boosted by deep learning (DL), they do not usually design evaluations with high scaling factors. Moreover, the datasets are generally benchmarks which do not truly encompass significant diversity of domains to proper evaluate the techniques. It is also interesting to remark that blind SR is attractive for real-world scenarios since it is based on the idea that the degradation process is unknown, and, hence, techniques in this context rely basically on low-resolution (LR) images. In this article, we present a high-scale (8×) experiment which evaluates five recent DL techniques tailored for blind image SR: Adaptive Pseudo Augmentation (APA), Blind Image SR with Spatially Variant Degradations (BlindSR), Deep Alternating Network (DAN), FastGAN, and Mixture of Experts Super-Resolution (MoESR). We consider 14 datasets from five different broader domains (Aerial, Fauna, Flora, Medical, and Satellite), and another remark is that some of the DL approaches were designed for single-image SR but others not. Based on two no-reference metrics, NIQE and the transformer-based MANIQA score, MoESR can be regarded as the best solution although the perceptual quality of the created high-resolution (HR) images of all the techniques still needs to improve.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ai4030032"
    },
    {
        "id": 29346,
        "title": "SSRNet: A Deep Learning Network via Spatial‐Based Super‐resolution Reconstruction for Cell Counting and Segmentation",
        "authors": "Lijia Deng, Qinghua Zhou, Shuihua Wang, Yudong Zhang",
        "published": "2023-10",
        "citations": 0,
        "abstract": "Cell counting and segmentation are critical tasks in biology and medicine. The traditional methods for cell counting are labor‐intensive, time‐consuming, and prone to human errors. Recently, deep learning‐based cell counting methods have become a trend, including point‐based counting methods, such as cell detection and cell density prediction, and non‐point‐based counting, such as cell number regression prediction. However, the point‐based counting method heavily relies on well‐annotated datasets, which are scarce and difficult to obtain. On the other hand, nonpoint‐based counting is less interpretable. The task of cell counting by dividing it into two subtasks is approached: cell number prediction and cell distribution prediction. To accomplish this, a deep learning network for spatial‐based super‐resolution reconstruction (SSRNet) is proposed that predicts the cell count and segments the cell distribution contour. To effectively train the model, an optimized multitask loss function (OM loss) is proposed that coordinates the training of multiple tasks. In SSRNet, a spatial‐based super‐resolution fast upsampling module (SSR‐upsampling) is proposed for feature map enhancement and one‐step upsampling, which can enlarge the deep feature map by 32 times without blurring and achieves fine‐grained detail and fast processing. SSRNet uses an optimized encoder network. Compared with the classic U‐Net, SSRNet's running memory read and write consumption is only 1/10 of that of U‐Net, and the total number of multiply and add calculations is 1/20 of that of U‐Net. Compared with the traditional sampling method, SSR‐upsampling can complete the upsampling of the entire decoder stage at one time, reducing the complexity of the network and achieving better performance. Experiments demonstrate that the method achieves state‐of‐the‐art performance in cell counting and segmentation tasks. The method achieves nonpoint‐based counting, eliminating the need for exact position annotation of each cell in the image during training. As a result, it has demonstrated excellent performance on cell counting and segmentation tasks. The code is public on GitHub (https://github.com/Roin626/SSRnet).",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/aisy.202300185"
    },
    {
        "id": 29347,
        "title": "Single Image Super-resolution Method for Electrical Equipment Images Based on Deep Learning",
        "authors": "Xinbiao Lu, Xupeng Xie, Chunlin Ye, Hao Xing, Mingxuan Tang",
        "published": "2023-5-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ccdc58219.2023.10326490"
    },
    {
        "id": 29348,
        "title": "A Review of Hyperspectral Image Super-Resolution Based on Deep Learning",
        "authors": "Chi Chen, Yongcheng Wang, Ning Zhang, Yuxi Zhang, Zhikang Zhao",
        "published": "2023-5-31",
        "citations": 4,
        "abstract": "Hyperspectral image (HSI) super-resolution (SR) is a classical computer vision task that aims to accomplish the conversion of images from lower to higher resolutions. With the booming development of deep learning (DL) technology, more and more researchers are dedicated to the research of image SR techniques based on DL and have made remarkable progress. However, no scholar has provided a comprehensive review of the field. As a response, in this paper we aim to supply a comprehensive summary of the DL-based SR techniques for HSI, including upsampling frameworks, upsampling methods, network design, loss functions, representative works with different strategies, and future directions, in which we design several sets of comparative experiments for the advantages and limitations of two-dimensional convolution and three-dimensional convolution in the field of HSI SR and analyze the experimental results in depth. In addition, the paper also briefly discusses the secondary foci such as common datasets, evaluation metrics, and traditional SR algorithms. To the best of our knowledge, this paper is the first review on DL-based HSI SR.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/rs15112853"
    },
    {
        "id": 29349,
        "title": "Deep learning-based lightweight approach to thermal super resolution",
        "authors": "Shashwat Pandey, Darshika Sharma, Basant Kumar, Himanshu Singh",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijbm.2023.130650"
    },
    {
        "id": 29350,
        "title": "Cloud-Mobile Video Super-Resolution Method Based on Deep Learning",
        "authors": "Jing Zhou, Yang Zheng, Songbin Yu, Zhijun Yan, Huishen Yuan",
        "published": "2023-12-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceace60673.2023.10442906"
    },
    {
        "id": 29351,
        "title": "Multiple-image super-resolution of cryo-electron micrographs based on deep internal learning",
        "authors": "Qinwen Huang, Ye Zhou, Hsuan-Fu Liu, Alberto Bartesaghi",
        "published": "2023",
        "citations": 2,
        "abstract": "Abstract\nSingle-particle cryo-electron microscopy (cryo-EM) is a powerful imaging modality capable of visualizing proteins and macromolecular complexes at near-atomic resolution. The low electron-doses used to prevent radiation damage to the biological samples, however, result in images where the power of the noise is 100 times greater than the power of the signal. To overcome these low signal-to-noise ratios (SNRs), hundreds of thousands of particle projections are averaged to determine the three-dimensional structure of the molecule of interest. The sampling requirements of high-resolution imaging impose limitations on the pixel sizes that can be used for acquisition, limiting the size of the field of view and requiring data collection sessions of several days to accumulate sufficient numbers of particles. Meanwhile, recent image super-resolution (SR) techniques based on neural networks have shown state-of-the-art performance on natural images. Building on these advances, here, we present a multiple-image SR algorithm based on deep internal learning designed specifically to work under low-SNR conditions. Our approach leverages the internal image statistics of cryo-EM movies and does not require training on ground-truth data. When applied to single-particle datasets of apoferritin and T20S proteasome, we show that the resolution of the 3D structure obtained from SR micrographs can surpass the limits imposed by the imaging system. Our results indicate that the combination of low magnification imaging with in silico image SR has the potential to accelerate cryo-EM data collection by virtue of including more particles in each exposure and doing so without sacrificing resolution.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1017/s2633903x2300003x"
    },
    {
        "id": 29352,
        "title": "Deep learning method for super-resolution reconstruction of the spatio-temporal flow field",
        "authors": "Kairui Bao, Xiaoya Zhang, Wei Peng, Wen Yao",
        "published": "2023-6-1",
        "citations": 3,
        "abstract": "AbstractThe high-resolution (HR) spatio-temporal flow field plays a decisive role in describing the details of the flow field. In the acquisition of the HR flow field, traditional direct numerical simulation (DNS) and other methods face a seriously high computational burden. To address this deficiency, we propose a novel multi-scale temporal path UNet (MST-UNet) model to reconstruct temporal and spatial HR flow fields from low-resolution (LR) flow field data. Different from the previous super-resolution (SR) model, which only takes advantage of LR flow field data at instantaneous (SLR) or in a time-series (MTLR), MST-UNet introduces multi-scale information in both time and space. MST-UNet takes the LR data at the current frame and the predicted HR result at the previous moment as the model input to complete the spatial SR reconstruction. On this basis, a temporal model is introduced as the inbetweening model to obtain HR flow field data in space and time to complete spatio-temporal SR reconstruction. Finally, the proposed model is validated by the spatio-temporal SR task of the flow field around two-dimensional cylinders. Experimental results show that the outcome of the MST-UNet model in spatial SR tasks is much better than those of SLR and MTLR, which can greatly improve prediction accuracy. In addition, for the spatio-temporal SR task, the spatio-temporal HR flow field predicted by the MST-UNet model has higher accuracy either.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s42774-023-00148-y"
    },
    {
        "id": 29353,
        "title": "Joint depth map super-resolution method via deep hybrid-cross guidance filter",
        "authors": "Ke Wang, Lijun Zhao, Jinjing Zhang, Jialong Zhang, Anhong Wang, Huihui Bai",
        "published": "2023-4",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2022.109260"
    },
    {
        "id": 29354,
        "title": "On Training Model Bias of Deep Learning based Super-resolution Frameworks for Magnetic Resonance Imaging",
        "authors": "Mamata Shrestha, Nian Wang, Ukash Nakarmi",
        "published": "2023-10-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bhi58575.2023.10313380"
    },
    {
        "id": 29355,
        "title": "Efficient Attention Fusion Feature Extraction Network for Image Super-Resolution",
        "authors": "Tuoran Wang, Na Cheng, Shijia Ding, Hongyu Wang",
        "published": "2023-7-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3613330.3613336"
    },
    {
        "id": 29356,
        "title": "\"ENHANCING IMAGE SUPER-RESOLUTION USING DEEP  LEARNING AND MATHEMATICAL OPTIMIZATION  TECHNIQUES\"",
        "authors": "Kashish Parwani, Sandeep Das, Ruchi Mathur, Sunil Kumar Srivastava",
        "published": "2023-6-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.30696/jac.xvii.1.2023.239-247"
    },
    {
        "id": 29357,
        "title": "Deep learning-driven super-resolution reconstruction of two-dimensional explosion pressure fields",
        "authors": "Yang Huang, Shaojun Zhu, Suwen Chen",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jobe.2023.107620"
    },
    {
        "id": 29358,
        "title": "Deep Learning-based Super-Resolution on the Cloud: Focus on Face and Text Enhancement",
        "authors": "Michael Nguyen, Kanika Sood, Kenytt Avery, Doina Bein",
        "published": "2023-9-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icrcv59470.2023.10329061"
    },
    {
        "id": 29359,
        "title": "Localization with deep learning networks for super-resolution ultrasound imaging",
        "authors": "Katherine Brown, Arthur D. Redfern",
        "published": "2023-3-1",
        "citations": 0,
        "abstract": "OBJECTIVE: The objective was to optimize an acquisition methodology and deep learning network to localize a microbubble (MB) contrast agent on a preclinical ultrasound (US) platform with the goal of moving super-resolution ultrasound (SRUS) imaging towards clinical adoption. METHODS: A deep learning network was optimized based on the latest advances in computer vision, convolutional neural networks, and transformer architectures. Synthetic data were produced in an US simulation of tissue with MB at various concentrations flowing in a vascular model. The network was programmed in PyTorch and trained on 12 000 synthetic images. US data were collected with a Vevo 3100 (FUJIFILM VisualSonics Inc) using an MX201 linear transducer. In vivo testing images were obtained from hepatocellular carcinoma (HCC) rat liver tumors. After MB injection (Definity), 3000 frames were collected at 90 Hz. RESULTS: The SRUS in vivo results reveal a high level of detail. The smallest vessel measured 34 μm in diameter. Compared to conventional methods, the network improved performance by 10x on a CPU. A GPU platform could give an additional boost, by as much 100x. CONCLUSIONS: Deep networks for localization show potential for improving performance of SR-US towards a real-time imaging modality. The use of a pre-clinical focused US platform demonstrates that localization can improve the visualization of vascular detail and aid clinical understanding.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1121/10.0018773"
    },
    {
        "id": 29360,
        "title": "Mouse brain MR super-resolution using a deep learning network trained with optical imaging data",
        "authors": "Zifei Liang, Jiangyang Zhang",
        "published": "2023-5-15",
        "citations": 2,
        "abstract": "IntroductionThe resolution of magnetic resonance imaging is often limited at the millimeter level due to its inherent signal-to-noise disadvantage compared to other imaging modalities. Super-resolution (SR) of MRI data aims to enhance its resolution and diagnostic value. While deep learning-based SR has shown potential, its applications in MRI remain limited, especially for preclinical MRI, where large high-resolution MRI datasets for training are often lacking.MethodsIn this study, we first used high-resolution mouse brain auto-fluorescence (AF) data acquired using serial two-photon tomography (STPT) to examine the performance of deep learning-based SR for mouse brain images.ResultsWe found that the best SR performance was obtained when the resolutions of training and target data were matched. We then applied the network trained using AF data to MRI data of the mouse brain, and found that the performance of the SR network depended on the tissue contrast presented in the MRI data. Using transfer learning and a limited set of high-resolution mouse brain MRI data, we were able to fine-tune the initial network trained using AF to enhance the resolution of MRI data.DiscussionOur results suggest that deep learning SR networks trained using high-resolution data of a different modality can be applied to MRI data after transfer learning.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fradi.2023.1155866"
    },
    {
        "id": 29361,
        "title": "Texture-driven super-resolution of ultrasound images using optimized deep learning model",
        "authors": "M. Markco, S. Kannan",
        "published": "2023-6-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/13682199.2023.2218224"
    },
    {
        "id": 29362,
        "title": "Super-resolution of Ray-tracing Channel Simulation via Attention Mechanism based Deep Learning Model",
        "authors": "Haoyang Zhang, Danping He, Xiping Wang, Wenbin Wang, Yunhao Cheng, Ke Guan",
        "published": "2023-8-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/ursigass57860.2023.10265505"
    },
    {
        "id": 29363,
        "title": "Retracted: Deep Learning-Based Leaf Region Segmentation Using High-Resolution Super HAD CCD and ISOCELL GW1 Sensors",
        "authors": "",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9862849"
    },
    {
        "id": 29364,
        "title": "Deep learning enables super-resolution hydrodynamic flooding process modeling under spatiotemporally varying rainstorms",
        "authors": "Jian He, Limin Zhang, Te Xiao, Haojie Wang, Hongyu Luo",
        "published": "2023-7",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.watres.2023.120057"
    },
    {
        "id": 29365,
        "title": "Improved SNR and super-resolution reconstruction of multi-scale digital holography based on deep learning",
        "authors": "Shuo Wang, Xianan Jiang, Haijun Guo, Huaying Wang",
        "published": "2023-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.optcom.2023.129634"
    },
    {
        "id": 29366,
        "title": "A Review of Image Super Resolution using Deep Learning",
        "authors": "Sneha R. Mhatre, Jagdish W. Bakal",
        "published": "2023-5-17",
        "citations": 0,
        "abstract": "The image processing methods collectively known as super-resolution have proven useful in creating high-quality images from a group of low-resolution photographic images. Single image super resolution (SISR) has been applied in a variety of fields. The paper offers an in-depth analysis of a few current picture super resolution works created in various domains. In order to comprehend the most current developments in the development of Image super resolution systems, these recent publications have been examined with particular emphasis paid to the domain for which these systems have been designed, image enhancement used or not, among other factors. To improve the accuracy of the image super resolution, a different deep learning techniques might be explored. In fact, greater research into the image super resolution in medical imaging is possible to improve the data's suitability for future analysis. In light of this, it can be said that there is a lot of scope for research in the field of medical imaging.",
        "keywords": "",
        "link": "http://dx.doi.org/10.17762/ijritcc.v11i5s.6638"
    },
    {
        "id": 29367,
        "title": "Deep Learning-Based Scene Text Image Super-Resolution Methods: A Survey",
        "authors": "Shuo Jiang, Bo Ning, Yunpeng Wang, Haocheng Zhang, Yingying Diao, Peize Yang",
        "published": "2023-7-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icivc58118.2023.10270461"
    },
    {
        "id": 29368,
        "title": "Deep Learning for Super Resolution and Applications",
        "authors": "Zahraa Hasan,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "High-resolution technologies are aimed at obtaining a high-resolution image from a low-resolution image, and the importance of this field has increased due to the emergence of the need to have high-resolution images in many important applications such as medical, security, and other images. Methods for obtaining ultra-high-resolution images have developed after the advent of Deep Learning Technologies, which have shown good results in this task, Due to the importance of the field of ultra-high-resolution images and deep learning, In this article we will explain one of the deep learning models used to obtain a high-resolution image from a low-resolution image and how to build and train it based on one of the famous deep learning offices and using one of the google platforms used in training, namely Google Laboratory",
        "keywords": "",
        "link": "http://dx.doi.org/10.54216/gjmsa.080204"
    },
    {
        "id": 29369,
        "title": "Single Image Super Resolution Using Deep Residual Learning",
        "authors": "Moiz Hassan, Kandasamy Illanko, Xavier N. Fernando",
        "published": "2024-3-21",
        "citations": 0,
        "abstract": "Single Image Super Resolution (SSIR) is an intriguing research topic in computer vision where the goal is to create high-resolution images from low-resolution ones using innovative techniques. SSIR has numerous applications in fields such as medical/satellite imaging, remote target identification and autonomous vehicles. Compared to interpolation based traditional approaches, deep learning techniques have recently gained attention in SISR due to their superior performance and computational efficiency. This article proposes an Autoencoder based Deep Learning Model for SSIR. The down-sampling part of the Autoencoder mainly uses 3 by 3 convolution and has no subsampling layers. The up-sampling part uses transpose convolution and residual connections from the down sampling part. The model is trained using a subset of the VILRC ImageNet database as well as the RealSR database. Quantitative metrics such as PSNR and SSIM are found to be as high as 76.06 and 0.93 in our testing. We also used qualitative measures such as perceptual quality.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/ai5010021"
    },
    {
        "id": 29370,
        "title": "A Deep Learning Based Super-Resolution Approach for the Reconstruction of Full Wavefields of Lamb Waves",
        "authors": "Saeed Ullah, Pawel Kudela, Wieslaw Ostachowicz",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "Abstract\nScanning laser Doppler vibrometer (SLDV) is widely used to obtain the full wavefields of propagating guided waves, particularly Lamb waves. Signal processing is applied on such full wavefields in order to reveal the defects in the inspected structure. However, obtaining the full wavefields of guided Lamb waves is very time-consuming.\nTo tackle this problem, one possible solution is to acquire the guided Lamb waves in a low-resolution form and then apply a compressive sensing (CS) or a deep learning-based super-resolution approach to that low-resolution form of full wavefields data.\nIn this research, we applied a deep learning-based super-resolution technique on a large synthetic dataset of full wavefields of propagating Lamb waves in low-resolution format on a carbon fibre-reinforced polymer (CFRP) plate. The developed deep learning approach is elaborated, and the results acquired from the deep learning-based process are compared with the conventional CS approach. The developed deep learning-based super-resolution approach is evaluated with two evaluation metrics namely peak signal-to-noise ratio (PSNR) and Pearson correlation coefficient (Pearson CC) and has achieved promising results. It is concluded that the developed deep learning-based method outperforms the traditional CS approach, and the deep learning-based approach for super-resolution can improve the speed of data acquisition by SLDV.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1115/qnde2023-109860"
    },
    {
        "id": 29371,
        "title": "FSRSI: New Deep Learning-Based Approach for Super-Resolution of Multispectral Satellite Images",
        "authors": "Omar Soufi, Fatima Zahra Belouadha",
        "published": "2023-2-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18280/isi.280112"
    },
    {
        "id": 29372,
        "title": "Deep learning architecture for 3D image super-resolution of late gadolinium enhanced cardiac MRI",
        "authors": "Roshan Reddy Upendra, Richard Simon, Cristian A. Linte",
        "published": "2023-5-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/1.jmi.10.5.051808"
    },
    {
        "id": 29373,
        "title": "Target Image Processing Based on Super-resolution Reconstruction and Deep Machine Learning Algorithm",
        "authors": "Yang Lin, Ping Zhang, He Zhang, Guoping Song",
        "published": "2024-2-24",
        "citations": 0,
        "abstract": "In dictionary-based single-frame image reconstruction algorithms, dictionaries rely on the design of artificial shallow features and are limited in their ability to represent image features. Therefore, this paper proposes a high-accuracy reconstruction method based on deep learning feature dictionary. This algorithm first uses a deep network to learn high-resolution and low-resolution training example images with deep features; Then co-train the feature dictionary under the super dense framework of the sparse dictionary; Finally, a single low-resolution image can be input and a super-resolution reconstruction can be performed using a dictionary. From the theoretical analysis, the introduction of deep network to extract the deep-level features of the image and its use in dictionary training is more beneficial to complement the high-frequency information in the low-resolution image. Experiments show that the proposed method achieves the best results in terms of both the peak signal-to-noise ratio and the gradient energy function of the reconstructed images. This shows that compared with traditional interpolation methods and some deep learning methods, the proposed method can recover image details to a high degree while preserving the original image damage information. This proves that the subjective visual and objective evaluation indicators of the algorithm presented in this article are higher than those of the comparative algorithm.",
        "keywords": "",
        "link": "http://dx.doi.org/10.12694/scpe.v25i2.2656"
    },
    {
        "id": 29374,
        "title": "Enhancing Image Quality through Deep Learning-based Super-Resolution Techniques",
        "authors": "Sreenivas Mekala, Sushant Bhushan, Puja Shashi, J. Ananda Lavanya, Mohit Tiwari, Shilpa Narlagiri",
        "published": "2023-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ic3i59117.2023.10397725"
    },
    {
        "id": 29375,
        "title": "Enhancing Side-Scan Sonar Imaging: A Comparative Study of Deep Learning Super-Resolution Techniques",
        "authors": "Jaebeom Park, Seongmin Lee, Youngseo Ryu, Dasol Jeong, Joonki Paik",
        "published": "2024-1-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iceic61013.2024.10457238"
    },
    {
        "id": 29376,
        "title": "Geologic stratigraphic scenario testing via deep learning: towards imaging beyond seismic resolution",
        "authors": "A. Karimzadanzabi, A. Cuesta Cano, E.J. Verschuur",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3997/2214-4609.2023101151"
    },
    {
        "id": 29377,
        "title": "Modal adaptive super-resolution for medical images via continual learning",
        "authors": "Zheng Wu, Feihong Zhu, Kehua Guo, Ren Sheng, Liu Chao, Hui Fang",
        "published": "2024-4",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.sigpro.2023.109342"
    },
    {
        "id": 29378,
        "title": "A Review of Deep Learning-Based Super-Resolution",
        "authors": "Chen Weiqin, Chen Bo, Deng Yuandan, Tian Yi, Mao Yanling, Zeng Juntao",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccwamtip60502.2023.10387044"
    },
    {
        "id": 29379,
        "title": "Hybrid Approach for Handwritten Digit Recognition using Deep Learning and ESRGAN-based Image Super-Resolution",
        "authors": "Mohan Sai Srujan Mekapothula, Phanindra Pullagura, Jhansi Lakshmi Potharlanka",
        "published": "2023-7-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icecaa58104.2023.10212325"
    },
    {
        "id": 29380,
        "title": "Research on Super-resolution Image Based on Deep Learning",
        "authors": "Tong Han, Li Zhao, Chuang Wang",
        "published": "2023-1-1",
        "citations": 1,
        "abstract": "Abstract\nImage super-resolution is a kind of important image processing technology in computer vision and image processing. It refers to the process of recovering high-resolution image from low-resolution image. It has a wide range of real-world applications, such as medical imaging, security and others. In addition to improving image perception quality, it also helps improve other computer vision tasks. Compared with traditional methods, deep learning methods show better reconstruction results in the field of image super-resolution reconstruction, and have gradually developed into the mainstream technology. This article will study the depth in the super resolution direction is important method of types of introduction, combed the main image super-resolution reconstruction method, expounds the depth study of several important super-resolution network model, the advantages and disadvantages of different algorithms and adaptive application scenarios are analyzed and compared, this paper expounds the different ways in the super resolution to liquidate, Finally, the potential problems of current image super-resolution reconstruction techniques are discussed, and the future development direction is prospected.",
        "keywords": "",
        "link": "http://dx.doi.org/10.2478/ijanmc-2023-0046"
    },
    {
        "id": 29381,
        "title": "Comparison and analysis of various deep learning models for super-resolution reconstruction of turbulent flows",
        "authors": "Hang Yin",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "Abstract\nSingle image super-resolution (SR) has become a promising research topic, with many deep learning-based models invented to reconstruct high-fidelity high-resolution (HR) images from low-resolution (LR) images. Motivated by a large amount of turbulent flow field data collected by experimental measurements and numerical simulation, researchers begin investigating the application of these data-driven deep learning models to conduct SR reconstruction of LR flow field data. Due to the limitations of experimental equipment and computing power, sometimes researchers can only obtain LR data. However, deep learning models can quickly reconstruct HR spatial-temporal turbulent data from LR data so that researchers can easily conduct further qualitative and quantitative analyses. This article reviews the development of flow field data SR reconstruction models and the problems encountered from the two aspects of network structure and loss function definition. Finally, we propose the research direction of applying the conditional generative adversarial network (cGAN) to turbulent flow SR reconstruction since seldom study has been conducted in this field.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1742-6596/2634/1/012046"
    },
    {
        "id": 29382,
        "title": "Image Quality Enhancement via Machine Learning: A Unified Approach to Super-Resolution, Denoising, and Low-Density Enhancement",
        "authors": "Woochan Jung, John Blofeld-Watson",
        "published": "2023-11-30",
        "citations": 0,
        "abstract": "Problem: The escalating demand for high-quality images across various applications has underscored the necessity for advanced image enhancement techniques. Traditionally, denoising, super-resolution, and low-density enhancement, the three key image enhancement techniques, have been approached independently, resulting in separate developments for each. Unfortunately, a unified framework that seamlessly combines all three techniques and surpasses individual method performance has been lacking.\nProposed Idea: The objective of this research is to develop a unified image enhancement framework that not only unites these techniques but also substantiates its superiority over existing individual methods through an extensive series of experiments. The proposed method utilizes cascade autoencoder architectures to generate high-quality enhanced images. In addition, an auxiliary artifact type prediction module has been introduced to enhance the noise-awareness, resulting in improved accuracy.\nResult: The proposed method demonstrates superior performance in achieving state-of-the-art accuracy when evaluated against three image quality metrics on various public datasets. Additionally, the practical application of the proposed method showcases its efficacy in effectively solving real-world problems.",
        "keywords": "",
        "link": "http://dx.doi.org/10.47611/jsrhs.v12i4.5541"
    },
    {
        "id": 29383,
        "title": "A review of image super-resolution approaches based on deep learning methods",
        "authors": "T. Pathrabe, K. K. Joy, S. S. Lal, S. Tewary, J. Sengupta",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/icp.2023.1472"
    },
    {
        "id": 29384,
        "title": "Deep Learning-based MRI Super-Resolution Using Non-uniform Segmented Phase-Scrambling Fourier Transform Signals",
        "authors": "Kazuki Yamato, Shuntaro Fujisawa, Satoshi Ito",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/apsipaasc58517.2023.10317545"
    },
    {
        "id": 29385,
        "title": "Deep learning-based super-resolution holographic data storage",
        "authors": "Jianying Hao, Xiao Lin, Ryushi Fujimura, Soki Hirayama, Yoshito Tanaka, Xiaodi Tan, Tsutomu Shimura",
        "published": "2023-9-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3008355"
    },
    {
        "id": 29386,
        "title": "YOLOSR-IST: A deep learning method for small target detection in infrared remote sensing images based on super-resolution and YOLO",
        "authors": "Ronghao Li, Ying Shen",
        "published": "2023-7",
        "citations": 26,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.sigpro.2023.108962"
    },
    {
        "id": 29387,
        "title": "Deep Unpaired Blind Image Super-Resolution Using Self-supervised Learning and Exemplar Distillation",
        "authors": "Jiangxin Dong, Haoran Bai, Jinhui Tang, Jinshan Pan",
        "published": "2023-12-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11263-023-01957-w"
    },
    {
        "id": 29388,
        "title": "Single-image super-resolution via dynamic multi-task learning and multi-level mutual feature fusion",
        "authors": "Yaofang Zhang, Yuchun Fang, Qicai Ran, Jiahua Wu",
        "published": "2023-5-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/1.jei.32.3.033011"
    },
    {
        "id": 29389,
        "title": "Arbitrary-scale Super-resolution via Deep Learning: A Comprehensive Survey",
        "authors": "Hongying Liu, Zekun Li, Fanhua Shang, Yuanyuan Liu, Liang Wan, Wei Feng, Radu Timofte",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.inffus.2023.102015"
    },
    {
        "id": 29390,
        "title": "Single-Photon Image Super-Resolution via Self-Supervised Learning",
        "authors": "Yiwei Chen, Chen Jiang, Yu Pan",
        "published": "2023-6-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10096804"
    },
    {
        "id": 29391,
        "title": "Fast Super-Resolution Network via Dynamic Path Selection",
        "authors": "Longfei Jia, Yuguo Hu, Xianlong Tian, Wenwei Luo",
        "published": "2023-11-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icicml60161.2023.10424923"
    },
    {
        "id": 29392,
        "title": "Deep learning-based microbubble localization towards improved super-resolution ultrasound",
        "authors": "Scott J. Schoen, Ali K. Tehrani, Anthony E. Samir",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "Ultrasound (US) is an indispensable tool for visualizing the microvasculature noninvasively. Over the last decade, US localization microscopy (ULM), which exploits microbubble contrast agents as effective point scatterers, has dramatically improved the spatial resolution attainable with US subject to the so-called diffraction limit (millimeter scale), and enabled mapping of vessels on the order of 10 μm. However, microbubble localization, a principal component of ULM, typically relies on bubble sparsity and compounding of many (102 to 104) frames. Thus, to enable sensitivity to more transient phenomena at the smallest scales, optimally sensitive and specific means of localization are required. Drawing on newly available ground truth data (ULTRA-SR Challenge, IUS 2022), we apply convolutional neural network (DeepLabv3) to perform localization via segmentation of the microbubble regions and identification of their centroids. Following training on 80% of the available simulated US frames, the network demonstrated localization precision 0.88 and recall 0.50 (tolerance of 0.5λ) on the test frames, with bias on the order of 0.1λ, and inference time of 40 ms on Nvidia RTX3090. Such accurate and sensitive localizations have significant promise toward elucidating hemodynamics at still finer spatial and temporal resolutions.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1121/10.0023049"
    },
    {
        "id": 29393,
        "title": "TSDSR: Temporal–Spatial Domain Denoise Super-Resolution Photon-Efficient 3D Reconstruction by Deep Learning",
        "authors": "Ziyi Tong, Xinding Jiang, Jiemin Hu, Lu Xu, Long Wu, Xu Yang, Bo Zou",
        "published": "2023-6-28",
        "citations": 0,
        "abstract": "The combination of a single-photon avalanche diode detector with a high-sensitivity and photon-efficient reconstruction algorithm can realize the reconstruction of target range image from weak light signal conditions. The limited spatial resolution of the detector and the substantial background noise remain significant challenges in the actual detection process, hindering the accuracy of 3D reconstruction techniques. To address this challenge, this paper proposes a denoising super-resolution reconstruction network based on generative adversarial network (GAN) design. Soft thresholding is incorporated into the deep architecture as a nonlinear transformation layer to effectively filter out noise. Moreover, the Unet-based discriminator is introduced to complete the high-precision detail reconstruction. The experimental results show that the proposed network can achieve high-quality super-resolution range imaging. This approach has the potential to enhance the accuracy and quality of long-range imaging in weak light signal conditions, with broad applications in fields such as robotics, autonomous vehicles, and biomedical imaging.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/photonics10070744"
    },
    {
        "id": 29394,
        "title": "Super-Resolution of Dental Panoramic Radiographs Using Deep Learning: A Pilot Study",
        "authors": "Hossein Mohammad-Rahimi, Shankeeth Vinayahalingam, Erfan Mahmoudinia, Parisa Soltani, Stefaan J. Bergé, Joachim Krois, Falk Schwendicke",
        "published": "2023-3-6",
        "citations": 6,
        "abstract": "Using super-resolution (SR) algorithms, an image with a low resolution can be converted into a high-quality image. Our objective was to compare deep learning-based SR models to a conventional approach for improving the resolution of dental panoramic radiographs. A total of 888 dental panoramic radiographs were obtained. Our study involved five state-of-the-art deep learning-based SR approaches, including SR convolutional neural networks (SRCNN), SR generative adversarial network (SRGAN), U-Net, Swin for image restoration (SwinIr), and local texture estimator (LTE). Their results were compared with one another and with conventional bicubic interpolation. The performance of each model was evaluated using the metrics of mean squared error (MSE), peak signal-to-noise ratio (PNSR), structural similarity index (SSIM), and mean opinion score by four experts (MOS). Among all the models evaluated, the LTE model presented the highest performance, with MSE, SSIM, PSNR, and MOS results of 7.42 ± 0.44, 39.74 ± 0.17, 0.919 ± 0.003, and 3.59 ± 0.54, respectively. Additionally, compared with low-resolution images, the output of all the used approaches showed significant improvements in MOS evaluation. A significant enhancement in the quality of panoramic radiographs can be achieved by SR. The LTE model outperformed the other models.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/diagnostics13050996"
    },
    {
        "id": 29395,
        "title": "Re-Learning ShiftIR for Super-Resolution of Carbon Nanotube Images",
        "authors": "Yoshiki Kakamu, Takahiro Maruyama, Kazuhiro Hotta",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011708200003417"
    },
    {
        "id": 29396,
        "title": "Multiscale Super-Resolution Remote Imaging via Deep Conditional Normalizing Flows",
        "authors": "Aneesh M. Heintz, Mason Peck, Ian Mackey",
        "published": "2023-8",
        "citations": 0,
        "abstract": " Many onboard vision tasks for spacecraft navigation require high-quality remote-sensing images with clearly decipherable features. However, design constraints and the operational and environmental conditions limit their quality. Enhancing images through postprocessing is a cost-efficient solution. Current deep learning methods that enhance low-resolution images through super-resolution do not quantify network uncertainty of predictions and are trained at a single scale, which hinders practical integration in image-acquisition pipelines. This work proposes performing multiscale super-resolution using a deep normalizing flow network for uncertainty-quantified and Monte Carlo estimates so that image enhancement for spacecraft vision tasks may be more robust and predictable. The proposed network architecture outperforms state-of-the-art super-resolution models on in-orbit lunar imagery data. Simulations demonstrate its viability on task-based evaluations for landmark identification. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.2514/1.i011089"
    },
    {
        "id": 29397,
        "title": "Polarized image super-resolution via a deep convolutional neural network",
        "authors": "Haofeng Hu, Shiyao Yang, Xiaobo Li, Zhenzhou Cheng, Tiegen Liu, Jingsheng Zhai",
        "published": "2023-2-27",
        "citations": 12,
        "abstract": "Reduced resolution of polarized images makes it difficult to distinguish detailed polarization information and limits the ability to identify small targets and weak signals. A possible way to handle this problem is the polarization super-resolution (SR), which aims to obtain a high-resolution polarized image from a low-resolution one. However, compared with the traditional intensity-mode image SR, the polarization SR is more challenging because more channels and their nonlinear cross-links need to be considered as well as the polarization and intensity information need to be reconstructed simultaneously. This paper analyzes the polarized image degradation and proposes a deep convolutional neural network for polarization SR reconstruction based on two degradation models. The network structure and the well-designed loss function have been verified to effectively balance the restoration of intensity and polarization information, and can realize the SR with a maximum scaling factor of four. Experimental results show that the proposed method outperforms other SR methods in terms of both quantitative evaluation and visual effect evaluation for two degradation models with different scaling factors.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1364/oe.479700"
    },
    {
        "id": 29398,
        "title": "Semantic Super-Resolution via Self-Distillation and Adversarial Learning",
        "authors": "Hanhoon Park",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3349023"
    },
    {
        "id": 29399,
        "title": "SIT-SR 3D: Self-supervised slice interpolation via transfer learning for 3D volume super-resolution",
        "authors": "Muhammad Sarmad, Leonardo Carlos Ruspini, Frank Lindseth",
        "published": "2023-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patrec.2023.01.008"
    },
    {
        "id": 29400,
        "title": "A Systematic Survey of Deep Learning-based Single-Image Super-Resolution",
        "authors": "Juncheng Li, Zehua Pei, Wenjie Li, Guangwei Gao, Longguang Wang, Yingqian Wang, Tieyong Zeng",
        "published": "2024-4-13",
        "citations": 0,
        "abstract": "Single-image super-resolution (SISR) is an important task in image processing, which aims to enhance the resolution of imaging systems. Recently, SISR has made a huge leap and has achieved promising results with the help of deep learning (DL). In this survey, we give an overview of DL-based SISR methods and group them according to their design targets. Specifically, we first introduce the problem definition, research background, and the significance of SISR. Secondly, we introduce some related works, including benchmark datasets, upsampling methods, optimization objectives, and image quality assessment methods. Thirdly, we provide a detailed investigation of SISR and give some domain-specific applications of it. Fourthly, we present the reconstruction results of some classic SISR methods to intuitively know their performance. Finally, we discuss some issues that still exist in SISR and summarize some new trends and future directions. This is an exhaustive survey of SISR, which can help researchers better understand SISR and inspire more exciting research in this field. An investigation project for SISR is provided at https://github.com/CV-JunchengLi/SISR-Survey.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3659100"
    },
    {
        "id": 29401,
        "title": "A deep learning framework for electrocardiogram (ECG) super resolution and arrhythmia classification",
        "authors": "Christina Perinbam Kaniraja, Vani Devi M, Deepak Mishra",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42600-024-00343-w"
    },
    {
        "id": 29402,
        "title": "Correction to: Deep Unpaired Blind Image Super-Resolution Using Self-supervised Learning and Exemplar Distillation",
        "authors": "Jiangxin Dong, Haoran Bai, Jinhui Tang, Jinshan Pan",
        "published": "2024-2-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11263-023-01980-x"
    },
    {
        "id": 29403,
        "title": "Automated phase reconstruction and super-resolution with deep learning in digital holography",
        "authors": "Seonghwan Park, Youhyun Kim, Inkyu Moon",
        "published": "2024-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.optlastec.2024.111030"
    },
    {
        "id": 29404,
        "title": "Super-resolution Deep Learning Reconstruction For Improvement Of Image Quality In Coronary Computed Tomography Angiography: Comparison With Conventional Deep Learning Reconstruction",
        "authors": "M. Takafuji, K. Kitagawa, S. Mizutani, A. Hamaguchi, R. Kisou, K. Iio, K. Ichikawa, D. Izumi, H. Sakuma",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jcct.2023.05.229"
    },
    {
        "id": 29405,
        "title": "Contrastive Learning for Blind Super-Resolution via A Distortion-Specific Network",
        "authors": "Xinya Wang, Jiayi Ma, Junjun Jiang",
        "published": "2023-1",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/jas.2022.105914"
    },
    {
        "id": 29406,
        "title": "Deep Learning-Based Single-Image Super-Resolution: A Comprehensive Review",
        "authors": "Karansingh Chauhan, Shail Nimish Patel, Malaram Kumhar, Jitendra Bhatia, Sudeep Tanwar, Innocent Ewean Davidson, Thokozile F. Mazibuko, Ravi Sharma",
        "published": "2023",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3251396"
    },
    {
        "id": 29407,
        "title": "Multi-scale ultrasound image denoising algorithm based on deep learning model for super-resolution reconstruction",
        "authors": "Jianhong Gan, Liping Wang, Zhiming Liu, Jiayun Wang",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3622896.3622898"
    },
    {
        "id": 29408,
        "title": "Deep learning-based image super-resolution restoration for mobile infrared imaging system",
        "authors": "Heng Wu, Xinyue Hao, Jibiao Wu, Huapan Xiao, Chunhua He, Shenxin Yin",
        "published": "2023-8",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.infrared.2023.104762"
    },
    {
        "id": 29409,
        "title": "A Review on Deep Learning based Algorithms for Video Super Resolution",
        "authors": "Deekshitha Arasa, S Sivaramakrishnan, Sneha Sharma",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "Abstract\nA HR (High Resolution) video frame may be created from a set of LR (Low Resolution) video frames using a process called Video Super Resolution (VSR). Deep Learning (DL) techniques have surpassed conventional techniques in terms of efficiency. To achieve video super-resolution, the inter-frame information must be extracted. The numerous categories for possible deep learning techniques include methods with alignment and methods without alignment, for example. Details about the different approaches’ architecture designs and implementation are provided in this review paper. Lastly, a comparison and summary are given for the various methods based on some standard datasets is provided.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1757-899x/1295/1/012009"
    },
    {
        "id": 29410,
        "title": "Evaluating Deep Neural Network Models on Ultrasound Single Image Super Resolution",
        "authors": "Mahsa Mikaeili, Hasan Şakir Bilge",
        "published": "2023-11-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tiptekno59875.2023.10359188"
    },
    {
        "id": 29411,
        "title": "Encoding-Aware Deep Video Super-Resolution Framework",
        "authors": "Sijung Kim, Ungwon Lee, Minyong Jeon",
        "published": "2023-10-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10223143"
    },
    {
        "id": 29412,
        "title": "A Lightweight Deep Residual Attention Network for Single Image Super Resolution",
        "authors": " Inderjeet, J. S. Sahambi",
        "published": "2023-2-23",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ncc56989.2023.10067881"
    },
    {
        "id": 29413,
        "title": "Noise robust face super-resolution via learning of spatial attentive features",
        "authors": "Anurag Singh Tomar, K. V. Arya, Shyam Singh Rajput",
        "published": "2023-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-14472-4"
    },
    {
        "id": 29414,
        "title": "DBlink: dynamic localization microscopy in super spatiotemporal resolution via deep learning",
        "authors": "Alon Saguy, Onit Alalouf, Nadav Opatovski, Soohyen Jang, Mike Heilemann, Yoav Shechtman",
        "published": "2023-12",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41592-023-01966-0"
    },
    {
        "id": 29415,
        "title": "Deep Learning-Based Leaf Region Segmentation Using High-Resolution Super HAD CCD and ISOCELL GW1 Sensors",
        "authors": "Srinivas Talasila, Kirti Rawal, Gaurav Sethi",
        "published": "2023-7-4",
        "citations": 4,
        "abstract": "Super HAD CCD and ISOCELL GW1 imaging sensors are used for capturing images in high-resolution cameras nowadays. These high-resolution camera sensors were used in this work to acquire black gram plant leaf diseased images in natural cultivation fields. Segmenting plant leaf regions from the black gram cultivation field images is a preliminary step for disease identification and classification. It is also helpful for the farmers to assess the plants’ health and identify the diseases in their early stages. Even though plant leaf region segmentation has been effectively handled in many contributions, no universally applicable solution exists to solve all issues. Therefore, an approach for extracting leaf region from black gram plant leaf images is presented in this article. The novelty of the proposed method is that MobileNetV2 has been utilized as a backbone network for DeepLabv3+ layers to segment plant leaf regions. The DeepLabv3+ with MobileNetV2 segmentation model exhibited superior performance compared to the other models (SegNet, U-Net, DeepLabv3+ with ResNet18, ResNet50, Xception, and InceptionResNetV2) in terms of accuracy of 99.71%, Dice of 98.72%, and Jaccard/IoU of 97.47% when data augmentation was applied. The algorithms were developed and trained using MATLAB software. Each of the experimental trials reported in this article surpasses the prior findings.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/1085735"
    },
    {
        "id": 29416,
        "title": "ANALYTICAL STUDY OF DEEP LEARNING MODELS FOR THE PROBLEM OF REMOTE SENSING SINGLE IMAGE SUPER RESOLUTION",
        "authors": "Н. ФАВОРСКАЯ М",
        "published": "2023-8-25",
        "citations": 0,
        "abstract": "Глубокие нейронные сети оказали существенное влияние на развитие методов создания снимков ДЗЗ сверхвысокого разрешения, позволяя находить приближенные решения некорректной задачи реконструкции по одному исходному снимку малого разрешения. Существуют два основных подхода - на основе сверточных нейронных сетей и генеративно-состязательных нейронных сетей, причем последние демонстрируют лучшие результаты восстановления. В докладе представлен аналитический обзор решений на основе глубоких моделей, предложенных в последние годы, приведена краткая характеристика наборов снимков ДЗЗ, а также сформулированы основные тенденции в данной области.\nDeep neural networks have had a significant impact on the development of methods for creating super-resolution remote sensing images, making it possible to find approximate solutions to an ill-posed reconstruction problem from a single low-resolution image. There are two main approaches - based on convolutional neural networks and generative adversarial neural networks, the latter ones show the best recovery results. The report presents an analytical study of solutions based on deep models proposed in recent years, provides a brief description of remote sensing datasets, and also formulates the main trends in this field.",
        "keywords": "",
        "link": "http://dx.doi.org/10.25743/sdm.2023.73.37.004"
    },
    {
        "id": 29417,
        "title": "A deep learning super-resolution model to speed up computations of coastal sea states",
        "authors": "J. Kuehn, S. Abadie, B. Liquet, V. Roeber",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.apor.2023.103776"
    },
    {
        "id": 29418,
        "title": "Blind Video Quality Assessment for Ultra-High-Definition Video Based on Super-Resolution and Deep Reinforcement Learning",
        "authors": "Zefeng Ying, Da Pan, Ping Shi",
        "published": "2023-1-29",
        "citations": 2,
        "abstract": "Ultra-high-definition (UHD) video has brought new challenges to objective video quality assessment (VQA) due to its high resolution and high frame rate. Most existing VQA methods are designed for non-UHD videos—when they are employed to deal with UHD videos, the processing speed will be slow and the global spatial features cannot be fully extracted. In addition, these VQA methods usually segment the video into multiple segments, predict the quality score of each segment, and then average the quality score of each segment to obtain the quality score of the whole video. This breaks the temporal correlation of the video sequences and is inconsistent with the characteristics of human visual perception. In this paper, we present a no-reference VQA method, aiming to effectively and efficiently predict quality scores for UHD videos. First, we construct a spatial distortion feature network based on a super-resolution model (SR-SDFNet), which can quickly extract the global spatial distortion features of UHD videos. Then, to aggregate the spatial distortion features of each UHD frame, we propose a time fusion network based on a reinforcement learning model (RL-TFNet), in which the actor network continuously combines multiple frame features extracted by SR-SDFNet and outputs an action to adjust the current quality score to approximate the subjective score, and the critic network outputs action values to optimize the quality perception of the actor network. Finally, we conduct large-scale experiments on UHD VQA databases and the results reveal that, compared to other state-of-the-art VQA methods, our method achieves competitive quality prediction performance with a shorter runtime and fewer model parameters.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23031511"
    },
    {
        "id": 29419,
        "title": "Deep learning-based super-resolution ultrasound imaging for a wide range of microbubble density",
        "authors": "Qiyang Chen, Kayhan Batmanghelich, Roderick Tan, Kang Kim",
        "published": "2023-3-1",
        "citations": 0,
        "abstract": "Super-resolution ultrasound (SRU) imaging that can identify the vasculature with a high spatial resolution has a great potential for assessing and monitoring the progression of diseases associated with microvascular changes. One limitation of the conventional SRU is that the image quality is highly sensitive to the microbubbles (MBs) concentration at the imaging site, an aspect that is difficult to control in vivo due to the varying local perfusion and vessel sizes in the different organs. Deep learning (DL) techniques have been explored in the field of medical ultrasound for various applications, including image reconstruction, segmentation, and disease classifications. In this study, we developed a DL-based SRU imaging that works in end-to-end fashion without parameter tuning and is robust over a wide range of MB density while preserving the spatial resolution. The DL network containing U-net and interpolation layers was trained by the simulated MB images to replace the conventional MB center localization algorithms. The developed algorithm was evaluated in vivo on the mouse kidney for different MB injection doses and shown consistent performance, which support the robustness of this approach to varying MB density. The end-to-end operation that requires minimum parameter tuning would also potentially benefit the clinical applications.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1121/10.0018041"
    },
    {
        "id": 29420,
        "title": "Super-Resolution of Synthetic Aperture Radar Complex Data by Deep-Learning",
        "authors": "Pia Addabbo, Mario Luca Bernardi, Filippo Biondi, Marta Cimitile, Carmine Clemente, Nicomino Fiscante, Gaetano Giunta, Danilo Orlando, Linjie Yan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3251565"
    },
    {
        "id": 29421,
        "title": "Deep-learning-based image super-resolution for enhanced root hair visualization and root traits analysis",
        "authors": "Divya Mishra, Sharon Chemweno, Ofer Hadar, Naftali Lazarovitch, Jonathan E. Ephrath",
        "published": "2023-10-17",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2687786"
    },
    {
        "id": 29422,
        "title": "Hyperspectral Image Super-Resolution via Learning an Undercomplete Dictionary and Intra-Algorithmic Postprocessing",
        "authors": "Milad Rostami, Ali Asghar Beheshti Shirazi",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tgrs.2023.3260030"
    },
    {
        "id": 29423,
        "title": "Improvement of Spatial Resolution on Coronary CT Angiography by Using Super-Resolution Deep Learning Reconstruction",
        "authors": "Fuminari Tatsugami, Toru Higaki, Ikuo Kawashita, Wataru Fukumoto, Yuko Nakamura, Masakazu Matsuura, Tzu-Cheng Lee, Jian Zhou, Liang Cai, Toshiro Kitagawa, Yukiko Nakano, Kazuo Awai",
        "published": "2023-11",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.acra.2022.12.044"
    },
    {
        "id": 29424,
        "title": "Comparative Study of Implementation of Very Deep Super Resolution Neural Network and Bicubic Interpolation for Single Image Super Resolution Quality Enhancement",
        "authors": "Ganesan P, M. Ravichandran, B.S. Sathish, L.M.I.Leo Joseph, G. Sajiv, R. Murugesan",
        "published": "2023-11-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aespc59761.2023.10389860"
    },
    {
        "id": 29425,
        "title": "Improving the Spatial Resolution of Drone Images Using a Deep Learning-Based Super-Resolution",
        "authors": "Suhong Yoo, Phillip Kim, Junhee Youn",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.7848/ksgpc.2023.41.6.651"
    },
    {
        "id": 29426,
        "title": "Two-Dimensional Super-Resolution Imaging For Scanning Radar Using Sparse Learning Via Iterative Minimization",
        "authors": "Jiawei Luo, Yongchao Zhang, Deqing Mao, Yin Zhang, Yulin Huang, Jianyu Yang",
        "published": "2023-7-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/igarss52108.2023.10282232"
    },
    {
        "id": 29427,
        "title": "Accelerating topology optimization using deep learning-based image super-resolution",
        "authors": "Jaekyung Lim, Kyusoon Jung, Youngsuk Jung, Do-Nyun Kim",
        "published": "2024-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.engappai.2024.108370"
    },
    {
        "id": 29428,
        "title": "A Ray-tracing and Deep Learning Fusion Super-resolution Modeling Method for Wireless Mobile Channel",
        "authors": "Zhao Zhang, Danping He, Xiping Wang, Ke Guan, Zhangdui Zhong, Jianwu Dou",
        "published": "2023-3-26",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/eucap57121.2023.10133327"
    },
    {
        "id": 29429,
        "title": "Omnidirectional Video Super-Resolution Using Deep Learning",
        "authors": "Arbind Agrahari Baniya, Tsz-Kwan Lee, Peter W. Eklund, Sunil Aryal",
        "published": "2024",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tmm.2023.3267294"
    },
    {
        "id": 29430,
        "title": "Deep learning in computed tomography super resolution using multi‐modality data training",
        "authors": "Wai Yan Ryana Fok, Andreas Fieselmann, Magdalena Herbst, Ludwig Ritschl, Steffen Kappler, Sylvia Saalfeld",
        "published": "2024-4",
        "citations": 0,
        "abstract": "AbstractBackgroundOne of the limitations in leveraging the potential of artificial intelligence in X‐ray imaging is the limited availability of annotated training data. As X‐ray and CT shares similar imaging physics, one could achieve cross‐domain data sharing, so to generate labeled synthetic X‐ray images from annotated CT volumes as digitally reconstructed radiographs (DRRs). To account for the lower resolution of CT and the CT‐generated DRRs as compared to the real X‐ray images, we propose the use of super‐resolution (SR) techniques to enhance the CT resolution before DRR generation.PurposeAs spatial resolution can be defined by the modulation transfer function kernel in CT physics, we propose to train a SR network using paired low‐resolution (LR) and high‐resolution (HR) images by varying the kernel's shape and cutoff frequency. This is different to previous deep learning‐based SR techniques on RGB and medical images which focused on refining the sampling grid. Instead of generating LR images by bicubic interpolation, we aim to create realistic multi‐detector CT (MDCT) like LR images from HR cone‐beam CT (CBCT) scans.MethodsWe propose and evaluate the use of a SR U‐Net for the mapping between LR and HR CBCT image slices. We reconstructed paired LR and HR training volumes from the same CT scans with small in‐plane sampling grid size of . We used the residual U‐Net architecture to train two models. SRUN: trained with kernel‐based LR images, and SRUN: trained with bicubic downsampled data as baseline. Both models are trained on one CBCT dataset (n = 13 391). The performance of both models was then evaluated on unseen kernel‐based and interpolation‐based LR CBCT images (n = 10 950), and also on MDCT images (n = 1392).ResultsFive‐fold cross validation and ablation study were performed to find the optimal hyperparameters. Both SRUN and SRUN models show significant improvements (p‐value  0.05) in mean absolute error (MAE), peak signal‐to‐noise ratio (PSNR) and structural similarity index measures (SSIMs) on unseen CBCT images. Also, the improvement percentages in MAE, PSNR, and SSIM by SRUN is larger than SRUN. For SRUN, MAE is reduced by 14%, and PSNR and SSIMs increased by 6 and 8%, respectively. To conclude, SRUN outperforms SRUN, which the former generates sharper images when tested with kernel‐based LR CBCT images as well as cross‐modality LR MDCT data.ConclusionsOur proposed method showed better performance than the baseline interpolation approach on unseen LR CBCT. We showed that the frequency behavior of the used data is important for learning the SR features. Additionally, we showed cross‐modality resolution improvements to LR MDCT images. Our approach is, therefore, a first and essential step in enabling realistic high spatial resolution CT‐generated DRRs for deep learning training.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/mp.16825"
    },
    {
        "id": 29431,
        "title": "Super-Resolution Deep Learning Reconstruction At Coronary Computed Tomography Angiography To Evaluate The Coronary Arteries",
        "authors": "M. Orii, M. Sone, J. Fujiwara, K. Yoshioka",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jcct.2023.05.228"
    },
    {
        "id": 29432,
        "title": "A deep-learning super-resolution reconstruction model of turbulent reacting flow",
        "authors": "Zhentao Pang, Kai Liu, Hualin Xiao, Tai Jin, Kun Luo, Jianren Fan",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compfluid.2024.106249"
    },
    {
        "id": 29433,
        "title": "Spectral super-resolution meets deep learning: Achievements and challenges",
        "authors": "Jiang He, Qiangqiang Yuan, Jie Li, Yi Xiao, Denghong Liu, Huanfeng Shen, Liangpei Zhang",
        "published": "2023-9",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.inffus.2023.101812"
    },
    {
        "id": 29434,
        "title": "Deep Learning-based Super Resolution for 3D Whole-heart Coronary MR Angiography",
        "authors": "Marie González-Inostroza, Simon Littlewood, Reza Hajhosseiny, Anastasia Fotaki, Claudia Prieto, Rene Botnar",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jocmr.2024.100979"
    },
    {
        "id": 29435,
        "title": "Super-Resolution Tomographic SAR Imaging with Deep LISTA Network",
        "authors": "Hong Li, Xiao Wang",
        "published": "2023-7-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsip57908.2023.10271006"
    },
    {
        "id": 29436,
        "title": "Image super-resolution techniques using deep neural networks",
        "authors": "Meilin Guo",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "Super-resolution (SR) based on deep convolutional neural networks is a rapidly developing field with many real-world applications. In this paper, we examine cutting-edge super-resolution neural networks in-depth using freshly released difficult datasets to test single-image SR. We present a taxonomy that divides existing techniques into six categories, including upsampling, residual, recursive, dense connection, attention-based, and loss function designs. This taxonomy is applicable to deep learning-based SR networks. The comprehensive analysis shows that in the past few years, the accuracy has increased steadily and rapidly, while the complexity of the model and the accessibility of large-scale information have also increased accordingly. It has been noted that the present techniques have greatly outperformed the past techniques that were indicated as benchmarks. On this basis, this paper will put forward some suggestions for future research.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/5/20230567"
    },
    {
        "id": 29437,
        "title": "Correlative super‐resolution microscopy with deep UV reactivation",
        "authors": "Kirti Prakash",
        "published": "2024-1-3",
        "citations": 0,
        "abstract": "AbstractCorrelative super‐resolution microscopy has the potential to accurately visualize and validate new biological structures past the diffraction limit. However, combining different super‐resolution modalities, such as deterministic stimulated emission depletion (STED) and stochastic single‐molecule localization microscopy (SMLM), is a challenging endeavour. For correlative STED and SMLM, the following poses a significant challenge: (1) the photobleaching of the fluorophores in STED; (2) the subsequent reactivation of the fluorophores for SMLM and (3) finding the right fluorochrome and imaging buffer for both imaging modalities. Here, we highlight how the deep ultraviolet (DBUE) wavelengths of the Mercury (Hg) arc lamp can help recover STED bleaching and allow for the reactivation of single molecules for SMLM imaging. We also show that Alexa Fluor 594 and the commercially available Prolong Diamond to be excellent fluorophores and imaging media for correlative STED and SMLM.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1111/jmi.13258"
    },
    {
        "id": 29438,
        "title": "Super resolution label-free dark-field microscopy by deep learning",
        "authors": "Ming Lei, Junxiang Zhao, Junxiao Zhou, Hongki Lee, Qianyi Wu, Zachary Burns, Guanghao Chen, Zhaowei Liu",
        "published": "2024",
        "citations": 0,
        "abstract": "In this work, we propose a deep learning based framework which doubles the resolution in traditional dark field imaging after being trained on a dataset simulated with the forward imaging model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1039/d3nr04294d"
    },
    {
        "id": 29439,
        "title": "Super‐resolution reconstruction of vertebrate microfossil computed tomography images based on deep learning",
        "authors": "Yemao Hou, Mario Canul‐Ku, Xindong Cui, Min Zhu",
        "published": "2023-8-2",
        "citations": 0,
        "abstract": "AbstractMicropaleontologists use the fine structures of microfossils to extract evolutionary information. These structures could not be directly observed with the naked eye. Recently, paleontologists resort to computed tomography (CT) images to mine the information, and pursue higher resolution CT images with in‐depth research. Therefore, we propose a new model, weighted super‐resolution generative adversarial network (WSRGAN), for the super‐resolution reconstruction of CT images. The model proposed herein (WSRGAN) obtained higher LPIPS (0.0757) on the experimental dataset, compared with Bilinear (0.4289), Bicubic (0.4166), EDSR (0.2281), WDSR (0.2640), and SRGAN (0.0815). WSRGAN meets the requirements of paleontologists for reconstructing fish microfossils. We hope that more super‐resolution reconstruction methods based on deep learning could be applied to paleontology and achieve better performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/xrs.3389"
    },
    {
        "id": 29440,
        "title": "Batch and Lossless Image Hiding Via Super Resolution",
        "authors": "Tingchu Wei, Rui Fan",
        "published": "2023-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/scset58950.2023.00077"
    },
    {
        "id": 29441,
        "title": "Super-resolution reconstruction of ultrasonic Lamb wave TFM image via deep learning",
        "authors": "Wenjing Zhang, Xiaodong Chai, Wenfa Zhu, Shubin Zheng, Guopeng Fan, Zaiwei Li, Hui Zhang, Hanfei Zhang",
        "published": "2023-5-1",
        "citations": 4,
        "abstract": "Abstract\nUnder the same detection frequency and depth, when the center spacing of multiple defects is less than the resolution threshold determined by the Rayleigh criterion, it is challenging to achieve super-resolution imaging of multiple defects using the ultrasonic total focusing method (TFM). A multilevel deep learning network is proposed as a super-resolution reconstruction method for ultrasonic Lamb wave TFM images. The first-level network is a detection network that uses a Resnet50 with more convolutional layers to improve the linear expression capabilities of the neural network. It introduces residual structure to solve low accuracy issues of multi-convolutional layers so that the Resnet50 can accurately detect defects from TFM images. The second-level network is a super-resolution reconstruction network that uses a Deeplab v3+ with a dilated convolutional layer. It controls the receptive field without changing the image feature size of the TFM image. With this model, a super-resolution reconstruction of multiple defects with a center spacing less than the resolution threshold is realized by extracting the detailed features of defects in the TFM image. Experimental results show that when the defect center spacing is greater than the resolution threshold determined by the Rayleigh criterion, the super-resolution reconstruction method improves the calculation accuracy of the defect center spacing by 4.7% and the calculation accuracy of the defect area by 93.7% compared with TFM. When the defect spacing is less than the resolution threshold, the method can still identify and accurately calculate the center spacing of multiple defects.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1361-6501/acb166"
    },
    {
        "id": 29442,
        "title": "Deep Arbitrary-Scale Image Super-Resolution via Scale-Equivariance Pursuit",
        "authors": "Xiaohang Wang, Xuanhong Chen, Bingbing Ni, Hang Wang, Zhengyan Tong, Yutian Liu",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00178"
    },
    {
        "id": 29443,
        "title": "Single-image super-resolution via a lightweight convolutional neural network with improved shuffle learning",
        "authors": "Xinbiao Lu, Xupeng Xie, Chunlin Ye, Hao Xing, Zecheng Liu, Yudan Chen",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11760-023-02730-9"
    },
    {
        "id": 29444,
        "title": "Improving Robotic Tactile Localization Super-resolution via Spatiotemporal Continuity Learning and Overlapping Air Chambers",
        "authors": "Xuyang Li, Yipu Zhang, Xuemei Xie, Jiawei Li, Guangming Shi",
        "published": "2023-6-26",
        "citations": 3,
        "abstract": "Human hand has amazing super-resolution ability in sensing the force and position of contact and this ability can be strengthened by practice. Inspired by this, we propose a method for robotic tactile super-resolution enhancement by learning spatiotemporal continuity of contact position and a tactile sensor composed of overlapping air chambers. Each overlapping air chamber is constructed of soft material and seals the barometer inside to mimic adapting receptors of human skin. Each barometer obtains the global receptive field of the contact surface with the pressure propagation in the hyperelastic seal overlapping air chambers. \nNeural networks with causal convolution are employed to resolve the pressure data sampled by barometers and to predict the contact position. The temporal consistency of spatial position contributes to the accuracy and stability of positioning. We obtain an average super-resolution (SR) factor of over 2500 with only four physical sensing nodes on the rubber surface (0.1 mm in the best case on 38 × 26 mm²), which outperforms the state-of-the-art. The effect of time series length on the location prediction accuracy of causal convolution is quantitatively analyzed in this article. \nWe show that robots can accomplish challenging tasks such as haptic trajectory following, adaptive grasping, and human-robot interaction with the tactile sensor. This research provides new insight into tactile super-resolution sensing and could be beneficial to various applications in the robotics field.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1609/aaai.v37i5.25763"
    },
    {
        "id": 29445,
        "title": "Deep Learning-Based Point Cloud Coding and Super-Resolution: a Joint Geometry and Color Approach",
        "authors": "André F. R. Guarda, Manuel Ruivo, Luís Coelho, Abdelrahman Seleem, Nuno M. M. Rodrigues, Fernando Pereira",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tmm.2023.3338081"
    },
    {
        "id": 29446,
        "title": "Deep Learning-Based Super Resolution Applied to Finite Element Analysis of Fused Deposition Modeling 3D Printing",
        "authors": "Yi Zhang, Elton L. Freeman, James T. Stinson, Guillermo A. Riveros",
        "published": "2024-3-26",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1089/3dp.2023.0191"
    },
    {
        "id": 29447,
        "title": "Enhanced Compressed Sensing Based Deep Learning Neural Network for Single Image Super Resolution of COVID-19 Using X-Ray Images",
        "authors": "Hossam M. Kasem, Samar Atef, Mohamed E. Nasr",
        "published": "2023-9-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21608/dusj.2023.318654"
    },
    {
        "id": 29448,
        "title": "Analysis of the Effect of Deep-learning Super-resolution for Fragments Detection Performance Enhancement",
        "authors": "Yuseok Lee",
        "published": "2023-6-5",
        "citations": 0,
        "abstract": "The Arena Fragmentation Test(AFT) is designed to analyze warhead performance by measuring fragmentation data. In order to evaluate the results of the AFT, a set of AFT images are captured by high-speed cameras. To detect objects in the AFT image set, ResNet-50 based Faster R-CNN is used as a detection model. However, because of the low resolution of the AFT image set, a detection model has shown low performance. To enhance the performance of the detection model, Super-resolution(SR) methods are used to increase the AFT image set resolution. To this end, The Bicubic method and three SR models: ZSSR, EDSR, and SwinIR are used. The use of SR images results in an increase in the performance of the detection model. While the increase in the number of pixels representing a fragment flame in the AFT images improves the Recall performance of the detection model, the number of pixels representing noise also increases, leading to a slight decreases in Precision performance. Consequently, the F1 score is increased by up to 9 %, demonstrating the effectiveness of SR in enhancing the performance of the detection model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.9766/kimst.2023.26.3.234"
    },
    {
        "id": 29449,
        "title": "Medical image super-resolution reconstruction algorithms based on deep learning: A survey",
        "authors": "Defu Qiu, Yuhu Cheng, Xuesong Wang",
        "published": "2023-8",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cmpb.2023.107590"
    },
    {
        "id": 29450,
        "title": "Underwater Image Super-Resolution via Dual-aware Integrated Network",
        "authors": "Aiye Shi, Haimin Ding",
        "published": "2023-12-5",
        "citations": 1,
        "abstract": "Underwater scenes are often affected by issues such as blurred details, color distortion, and low contrast, which are primarily caused by wavelength-dependent light scattering; these factors significantly impact human visual perception. Convolutional neural networks (CNNs) have recently displayed very promising performance in underwater super-resolution (SR). However, the nature of CNN-based methods is local operations, making it difficult to reconstruct rich features. To solve these problems, we present an efficient and lightweight dual-aware integrated network (DAIN) comprising a series of dual-aware enhancement modules (DAEMs) for underwater SR tasks. In particular, DAEMs primarily consist of a multi-scale color correction block (MCCB) and a swin transformer layer (STL). These components work together to incorporate both local and global features, thereby enhancing the quality of image reconstruction. MCCBs can use multiple channels to process the different colors of underwater images to restore the uneven underwater light decay-affected real color and details of the images. The STL captures long-range dependencies and global contextual information, enabling the extraction of neglected features in underwater images. Experimental results demonstrate significant enhancements with a DAIN over conventional SR methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app132412985"
    },
    {
        "id": 29451,
        "title": "Super-resolution reconstruction of sea surface pollutant diffusion images based on deep learning models: a case study of thermal discharge from a coastal power plant",
        "authors": "Yafei Duan, Zhaowei Liu, Manjie Li",
        "published": "2023-6-9",
        "citations": 0,
        "abstract": "While remote sensing images could convey essential information of surface water environment, the low spatial resolution limits their application. This study carried out a series of experiment tests of thermal discharge from a coastal power plant and constructed an image dataset HY_IRS, representing the transport and diffusion of discharged heated water in tidal waters. Two image super-resolution (SR) reconstruction models based on deep learning (DL), ESPCN and ESRGAN, were trained based on this dataset and then used to reconstruct high-resolution remote sensing images. It shows that the two DL models can markedly improve the spatial resolution of the surface diffusion image of thermal discharging, with the PSNR improved by 8.3% on average. The trained two models were successfully used to improve the spatial resolution of thermal infrared remote sensing SST images from Landsat8 TIRS, indicating that the SR model based on DL has a good effect and a crucial application prospect in the field of improving the resolution of pollutant diffusion remote sensing images.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fmars.2023.1211981"
    },
    {
        "id": 29452,
        "title": "City scene super-resolution via geometric error minimization",
        "authors": "Zhengyang Lu, Feng Wang",
        "published": "2024-1-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/1.jei.33.1.013014"
    },
    {
        "id": 29453,
        "title": "Spatial-Spectral Deep Residual Network for Hyperspectral Image Super-Resolution",
        "authors": "WeiFa Zheng, ZiXin Xie",
        "published": "2023-6-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42979-023-01868-0"
    },
    {
        "id": 29454,
        "title": "Spectral Super-Resolution via Deep Low-Rank Tensor Representation",
        "authors": "Renwei Dian, Yuanye Liu, Shutao Li",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2024.3359852"
    },
    {
        "id": 29455,
        "title": "Low-resolution object detection via a lightweight super-resolution network",
        "authors": "Jian Tang, Yang Liu, Haoyue Fu, Hegui Zhu, Wuming Jiang, Lianping Yang",
        "published": "2023-9-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/1.jei.32.5.053022"
    },
    {
        "id": 29456,
        "title": "High-Resolution 3D MRI With Deep Generative Networks via Novel Slice-Profile Transformation Super-Resolution",
        "authors": "Jiahao Lin, Qi Miao, Chuthaporn Surawech, Steven S. Raman, Kai Zhao, Holden H. Wu, Kyunghyun Sung",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3307577"
    },
    {
        "id": 29457,
        "title": "An Efficient Deep Unrolling Super-Resolution Network for Lidar Automotive Scenes",
        "authors": "Alexandros Gkillas, Aris S. Lalos, Dimitris Ampeliotis",
        "published": "2023-10-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icip49359.2023.10222856"
    },
    {
        "id": 29458,
        "title": "Deep Model-Based Super-Resolution with Non-uniform Blur",
        "authors": "Charles Laroche, Andres Almansa, Matias Tassano",
        "published": "2023-1",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/wacv56688.2023.00184"
    },
    {
        "id": 29459,
        "title": "MAML-SR: Self-adaptive super-resolution networks via multi-scale optimized attention-aware meta-learning",
        "authors": "Debabrata Pal, Shirsha Bose, Deeptej More, Ankit Jha, Biplab Banerjee, Yogananda Jeppu",
        "published": "2023-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patrec.2023.08.004"
    },
    {
        "id": 29460,
        "title": "Guided Depth Super-Resolution by Deep Anisotropic Diffusion",
        "authors": "Nando Metzger, Rodrigo Caye Daudt, Konrad Schindler",
        "published": "2023-6",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01749"
    },
    {
        "id": 29461,
        "title": "Spatial frequency shift super-resolution imaging based on quasiperiodic grating and deep learning",
        "authors": "Xingyu Liu, Jiang Yu, Fubin Liu, Yong Liu, HongMei Guo, Yong-Hong Ye",
        "published": "2024-1-1",
        "citations": 0,
        "abstract": "In this study, we propose a pioneering spatially frequency-shifted super-resolution microscopy technique that utilizes the synergy of quasiperiodic gratings and deep learning. First, a quasiperiodic grating capable of converting evanescent waves into propagating waves is designed. The grating is positioned between the object under investigation and the objective lens, and the high-frequency information carried by the evanescent waves in the near-field region of the object is shifted into the detection window and becomes accessible in the far field for imaging. Subsequently, we provide two deep learning models for image and video reconstructions to achieve the reconstruction of static and dynamic samples respectively. Simulation results demonstrate the high feasibility of the proposed method, and both static and dynamic objects with sub-wavelength features can be resolved. The developed method paves the way to the realization of super-resolution imaging by using a traditional bright-field microscope without the need for an extensive optical system design.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1364/ol.510735"
    },
    {
        "id": 29462,
        "title": "Deep learning based video-related super-resolution technique: a survey",
        "authors": "Jiang Junjun,  , Cheng Hao, Li Zhenyu, Liu Xianming, Wang Zhongyuan",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.11834/jig.220130"
    },
    {
        "id": 29463,
        "title": "Super-Resolution of Radargrams With a Generative Deep Learning Model",
        "authors": "Elena Donini, Lorenzo Bruzzone, Francesca Bovolo",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tgrs.2024.3378576"
    },
    {
        "id": 29464,
        "title": "Hyperspectral Image Super-Resolution Meets Deep Learning: A Survey and Perspective",
        "authors": "Xinya Wang, Qian Hu, Yingsong Cheng, Jiayi Ma",
        "published": "2023-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/jas.2023.123681"
    },
    {
        "id": 29465,
        "title": "Video Super-Resolution Reconstruction Based on Deep Learning and Spatio-Temporal Feature Self-similarity (Extended abstract)",
        "authors": "Meiyu Liang, Junping Du, Linghui Li, Zhe Xue, Xiaoxiao Wang, Feifei Kou, Xu Wang",
        "published": "2023-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icde55515.2023.00365"
    },
    {
        "id": 29466,
        "title": "YOLOLens: A Deep Learning Model Based on Super-Resolution to Enhance the Crater Detection of the Planetary Surfaces",
        "authors": "Riccardo La Grassa, Gabriele Cremonese, Ignazio Gallo, Cristina Re, Elena Martellato",
        "published": "2023-2-21",
        "citations": 4,
        "abstract": "The impact crater detection offers a great scientific contribution in analyzing the geological processes, morphologies and physical properties of the celestial bodies and plays a crucial role in potential future landing sites. The huge amount of craters requires automated detection algorithms, and considering the low spatial resolution provided by the satellite jointly with, the solar illuminance/incidence variety, these methods lack their performance in the recognition tasks. Furthermore, small craters are harder to recognize also by human experts and the need to have a sophisticated detection algorithm becomes mandatory. To address these problems, we propose a deep learning architecture refers as “YOLOLens5x”, for impact crater detection based on super-resolution in a unique end-to-end design. We introduce the entire workflow useful to link the Robbins Lunar catalogue with the tiles orthoprojected from the Lunar mosaic LROC mission in order to train our proposed model as a supervised paradigm and, the various optimization due to provide a clear dataset in the training step. We prove by experimental results a boost in terms of precision and recall than the other state-of-the-art crater detection models, reporting the lowest error estimated craters diameter using the same scale factor given by LROC WAC Camera. To simulate the camera satellite at the lowest spatial resolution, we carried out experiments at different scale factors (200 m/px, 400 m/px) by interpolating the source image of 100 m/px, bringing to light remarkable results across all metrics under consideration compared with the baseline used.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/rs15051171"
    },
    {
        "id": 29467,
        "title": "Deep-learning-based super-resolution and classification framework for skin disease detection applications",
        "authors": "Ibrahim Abd El-Fattah, Anas M. Ali, Walid El-Shafai, Taha E. Taha, Fathi E. Abd El-Samie",
        "published": "2023-5",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11082-022-04432-x"
    },
    {
        "id": 29468,
        "title": "Super-Resolution Deep Learning Reconstruction for Improved Image                     Quality of Coronary CT Angiography",
        "authors": "Masafumi Takafuji, Kakuya Kitagawa, Sachio Mizutani, Akane Hamaguchi, Ryosuke Kisou, Kotaro Iio, Kazuhide Ichikawa, Daisuke Izumi, Hajime Sakuma",
        "published": "2023-8-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1148/ryct.230085"
    },
    {
        "id": 29469,
        "title": "Super-resolution reconstruction of structured illumination microscopy using deep-learning and sparse deconvolution",
        "authors": "Liangfeng Song, Xin Liu, Zihan Xiong, Mostak Ahamed, Sha An, Juanjuan Zheng, Ying Ma, Peng Gao",
        "published": "2024-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.optlaseng.2023.107968"
    },
    {
        "id": 29470,
        "title": "Evaluation of Resampling Techniques to Provide Better Synthesized Input Data to Super-Resolution Deep Learning Model Training",
        "authors": "Vinicius Sales, Ademir Marques, Graciela Racolte, Anderson Nunes, Tainá Guimaraes, Daniel Zanotta, André Spigolon, Luiz Gonzaga, Mauricio Roberto Veronez",
        "published": "2023-7-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/igarss52108.2023.10281470"
    },
    {
        "id": 29471,
        "title": "Uncertainty quantification in super-resolution guided wave array imaging using a variational Bayesian deep learning approach",
        "authors": "Homin Song, Yongchao Yang",
        "published": "2023-1",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ndteint.2022.102753"
    },
    {
        "id": 29472,
        "title": "Deep learning super-resolution for the reconstruction of full wavefield of Lamb waves",
        "authors": "Abdalraheem Ijjeh, Saeed Ullah, Maciej Radzienski, Pawel Kudela",
        "published": "2023-3",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ymssp.2022.109878"
    },
    {
        "id": 29473,
        "title": "Hyperspectral image super resolution using deep internal and self‐supervised learning",
        "authors": "Zhe Liu, Xian‐Hua Han",
        "published": "2024-2",
        "citations": 0,
        "abstract": "AbstractBy automatically learning the priors embedded in images with powerful modelling capabilities, deep learning‐based algorithms have recently made considerable progress in reconstructing the high‐resolution hyperspectral (HR‐HS) image. With previously collected large‐amount of external data, these methods are intuitively realised under the full supervision of the ground‐truth data. Thus, the database construction in merging the low‐resolution (LR) HS (LR‐HS) and HR multispectral (MS) or RGB image research paradigm, commonly named as HSI SR, requires collecting corresponding training triplets: HR‐MS (RGB), LR‐HS and HR‐HS image simultaneously, and often faces difficulties in reality. The learned models with the training datasets collected simultaneously under controlled conditions may significantly degrade the HSI super‐resolved performance to the real images captured under diverse environments. To handle the above‐mentioned limitations, the authors propose to leverage the deep internal and self‐supervised learning to solve the HSI SR problem. The authors advocate that it is possible to train a specific CNN model at test time, called as deep internal learning (DIL), by on‐line preparing the training triplet samples from the observed LR‐HS/HR‐MS (or RGB) images and the down‐sampled LR‐HS version. However, the number of the training triplets extracted solely from the transformed data of the observation itself is extremely few particularly for the HSI SR tasks with large spatial upscale factors, which would result in limited reconstruction performance. To solve this problem, the authors further exploit deep self‐supervised learning (DSL) by considering the observations as the unlabelled training samples. Specifically, the degradation modules inside the network were elaborated to realise the spatial and spectral down‐sampling procedures for transforming the generated HR‐HS estimation to the high‐resolution RGB/LR‐HS approximation, and then the reconstruction errors of the observations were formulated for measuring the network modelling performance. By consolidating the DIL and DSL into a unified deep framework, the authors construct a more robust HSI SR method without any prior training and have great potential of flexible adaptation to different settings per observation. To verify the effectiveness of the proposed approach, extensive experiments have been conducted on two benchmark HS datasets, including the CAVE and Harvard datasets, and demonstrate the great performance gain of the proposed method over the state‐of‐the‐art methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cit2.12285"
    },
    {
        "id": 29474,
        "title": "Deep learning-based blind image super-resolution with iterative kernel reconstruction and noise estimation",
        "authors": "Hasan F. Ates, Suleyman Yildirim, Bahadir K. Gunturk",
        "published": "2023-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cviu.2023.103718"
    },
    {
        "id": 29475,
        "title": "Learning the Frequency Domain Aliasing for Real-World Super-Resolution",
        "authors": "Yukun Hao, Feihong Yu",
        "published": "2024-1-5",
        "citations": 0,
        "abstract": "Most real-world super-resolution methods require synthetic image pairs for training. However, the frequency domain gap between synthetic images and real-world images leads to artifacts and blurred reconstructions. This work points out that the main reason for the frequency domain gap is that aliasing exists in real-world images, but the degradation model used to generate synthetic images ignores the impact of aliasing on images. Therefore, a method is proposed in this work to assess aliasing in images undergoing unknown degradation by measuring the distance to their alias-free counterparts. Leveraging this assessment, a domain-translation framework is introduced to learn degradation from high-resolution to low-resolution images. The proposed framework employs a frequency-domain branch and loss function to generate synthetic images with aliasing features. Experiments validate that the proposed domain-translation framework enhances the visual quality and quantitative results compared to existing super-resolution models across diverse real-world image benchmarks. In summary, this work offers a practical solution to the real-world super-resolution problem by minimizing the frequency domain gap between synthetic and real-world images.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics13020250"
    },
    {
        "id": 29476,
        "title": "Medical Image Super-Resolution via Diagnosis-Guided Attention",
        "authors": "Jingwei Wang, Peng Zhou, Xianjun Han, Yanming Chen",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icme55011.2023.00086"
    },
    {
        "id": 29477,
        "title": "Physics-Informed Super-Resolution of Turbulent Channel Flows via Three-Dimensional Generative Adversarial Networks",
        "authors": "Nicholas J. Ward",
        "published": "2023-6-29",
        "citations": 1,
        "abstract": "For a few decades, machine learning has been extensively utilized for turbulence research. The goal of this work is to investigate the reconstruction of turbulence from minimal or lower-resolution datasets as inputs using reduced-order models. This work seeks to effectively reconstruct high-resolution 3D turbulent flow fields using unsupervised physics-informed deep learning. The first objective of this study is to reconstruct turbulent channel flow fields and verify these with respect to the statistics. The second objective is to compare the turbulent flow structures generated from a GAN with a DNS. The proposed deep learning algorithm effectively replicated the first- and second-order statistics of turbulent channel flows of Reτ= 180 within a 2% and 5% error, respectively. Additionally, by incorporating physics-based corrections to the loss functions, the proposed algorithm was also able to reconstruct λ2 structures. The results suggest that the proposed algorithm can be useful for reconstructing a range of 3D turbulent flows given computational and experimental efforts.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/fluids8070195"
    },
    {
        "id": 29478,
        "title": "USR: Unrolled Super-Resolution with Deep Priors for Structured Illumination Microscopy",
        "authors": "S. Parisa Dajkhosh, Mazharul Hossain, Chrysanthe Preza",
        "published": "2023",
        "citations": 0,
        "abstract": "We introduce a method for enhancing the resolution of Structured Illumination Microscopy images. It uses a deep prior network, unrolled with a model-based analytical process to improve performance, maintain structural details, and guarantee the theory.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1364/3d.2023.jtu4a.42"
    },
    {
        "id": 29479,
        "title": "MrSARP: A Hierarchical Deep Generative Prior for SAR Image Super-resolution",
        "authors": "Tushar Agarwal, Nithin Sugavanam, Emre Ertin",
        "published": "2023-5-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/radarconf2351548.2023.10149659"
    },
    {
        "id": 29480,
        "title": "Image super resolution via multi-regularization combining hybrid Tikhonov-TV prior and deep denoiser prior",
        "authors": "Jiahao Zhang, Shengrong Zhao, Hu Liang, Changchun Wen, Chen Liang",
        "published": "2023-11-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ictai59109.2023.00126"
    },
    {
        "id": 29481,
        "title": "An Efficient Multi-Scale Learning Method for Image Super-Resolution",
        "authors": "Wenyuan Ying, Tianyang Dong, Jing Fan",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4399142"
    },
    {
        "id": 29482,
        "title": "Asymptotic Behavior of Super-Resolution Sparse Bayesian Learning",
        "authors": "Dmitriy Shutin",
        "published": "2024-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp48485.2024.10445954"
    },
    {
        "id": 29483,
        "title": "SINGLE IMAGE SUPER RESOLUTION VIA COUPLED SPARSE AND LOW RANK DICTIONARY LEARNING",
        "authors": "S. Sahebkheir, A. Esmaeily, M. Saba",
        "published": "2023-1-14",
        "citations": 0,
        "abstract": "Abstract. Limitations in imaging systems and the effects of changes in sensing have caused limitation in acquiring high resolution images such as satellite images and magnetic resonance imaging (MRI). Sparsity can reduce the noises and improve the resolution. Super resolution in medical and satellite imagery is essential because low resolution image analysis is very difficult. Sparsity techniques have significant influence on computer vision specially when the main objective is extracting the meaningful information. The success of sparsity is related to the nature of signals such as image and sound which are naturally sparse because they were founded based on Wavelet and Fourier equations. In this research, we proposed a method for restoring a clear image from the related low-resolution parts of both MRI and satellite images. First, we proposed a widespread structure for learning the couple low rank and sparse main characteristic representation. Combined optimization of the nuclear and L1 norms extracts the total low rank formation and the local patterns lodged in the image. In that case the reconstructed image will be more informative and matrix decomposition problem can recover a noisy observation matrix into an approximation of low rank matrix and a second matrix which contains some low dimensional structure. We assumed that by removing the blur and noise from these images, they would be reconstructed in the highest quality. The proposed method was compared with a variety dictionary learning approaches which addressed super resolution problem, such as tensor sparsity, Generative Bayesian and TV based methods. We demonstrated the results of applied method on MRI and satellite images, showing both visual and psnr improvements. Dealing with complex data in best manner shows the robustness of the proposed method.\n                    ",
        "keywords": "",
        "link": "http://dx.doi.org/10.5194/isprs-annals-x-4-w1-2022-661-2023"
    },
    {
        "id": 29484,
        "title": "Single image super-resolution approaches in medical images based-deep learning: a survey",
        "authors": "Walid El-Shafai, Anas M. Ali, Samy Abd El-Nabi, El-Sayed M. El-Rabaie, Fathi E. Abd El-Samie",
        "published": "2023-9-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-16197-w"
    },
    {
        "id": 29485,
        "title": "Exploring the impact of super-resolution deep learning on MR angiography image quality",
        "authors": "Masamichi Hokamura, Hiroyuki Uetani, Takeshi Nakaura, Kensei Matsuo, Kosuke Morita, Yasunori Nagayama, Masafumi Kidoh, Yuichi Yamashita, Mitsuharu Ueda, Akitake Mukasa, Toshinori Hirai",
        "published": "2024-2",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00234-023-03271-1"
    },
    {
        "id": 29486,
        "title": "Comparative analysis of the deep-learning-based super-resolution\n                        methods for generating high-resolution texture maps",
        "authors": "Hyeju Kim, Jah-Ho Nah",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.15701/kcgs.2023.29.5.31"
    },
    {
        "id": 29487,
        "title": "Cerebrovascular super-resolution 4D Flow MRI – Sequential combination of resolution enhancement by deep learning and physics-informed image processing to non-invasively quantify intracranial velocity, flow, and relative pressure",
        "authors": "E. Ferdian, D. Marlevi, J. Schollenberger, M. Aristova, E.R. Edelman, S. Schnell, C.A. Figueroa, D.A. Nordsletten, A.A. Young",
        "published": "2023-8",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.media.2023.102831"
    },
    {
        "id": 29488,
        "title": "Application of deep learning-based super-resolution to T1-weighted postcontrast gradient echo imaging of the chest",
        "authors": "Simon Maennlin, Daniel Wessling, Judith Herrmann, Haidara Almansour, Dominik Nickel, Stephan Kannengiesser, Saif Afat, Sebastian Gassenmaier",
        "published": "2023-1-7",
        "citations": 3,
        "abstract": "AbstractObjectivesA deep learning-based super-resolution for postcontrast volume-interpolated breath-hold examination (VIBE) of the chest was investigated in this study. Aim was to improve image quality, noise, artifacts and diagnostic confidence without change of acquisition parameters.Materials and methodsFifty patients who received VIBE postcontrast imaging of the chest at 1.5 T were included in this retrospective study. After acquisition of the standard VIBE (VIBES), a novel deep learning-based algorithm and a denoising algorithm were applied, resulting in enhanced images (VIBEDL). Two radiologists qualitatively evaluated both datasets independently, rating sharpness of soft tissue, vessels, bronchial structures, lymph nodes, artifacts, cardiac motion artifacts, noise levels and overall diagnostic confidence, using a Likert scale ranging from 1 to 4. In the presence of lung lesions, the largest lesion was rated regarding sharpness and diagnostic confidence using the same Likert scale as mentioned above. Additionally, the largest diameter of the lesion was measured.ResultsThe sharpness of soft tissue, vessels, bronchial structures and lymph nodes as well as the diagnostic confidence, the extent of artifacts, the extent of cardiac motion artifacts and noise levels were rated superior in VIBEDL(allP < 0.001).There was no significant difference in the diameter or the localization of the largest lung lesion in VIBEDLcompared to VIBES. Lesion sharpness as well as detectability was rated significantly better by both readers with VIBEDL(bothP < 0.001).ConclusionThe application of a novel deep learning-based super-resolution approach in T1-weighted VIBE postcontrast imaging resulted in an improvement in image quality, noise levels and diagnostic confidence as well as in a shortened acquisition time.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11547-022-01587-1"
    },
    {
        "id": 29489,
        "title": "RGB‐guided hyperspectral image super‐resolution with deep progressive learning",
        "authors": "Tao Zhang, Ying Fu, Liwei Huang, Siyuan Li, Shaodi You, Chenggang Yan",
        "published": "2023-7-17",
        "citations": 0,
        "abstract": "AbstractDue to hardware limitations, existing hyperspectral (HS) camera often suffer from low spatial/temporal resolution. Recently, it has been prevalent to super‐resolve a low resolution (LR) HS image into a high resolution (HR) HS image with a HR RGB (or multispectral) image guidance. Previous approaches for this guided super‐resolution task often model the intrinsic characteristic of the desired HR HS image using hand‐crafted priors. Recently, researchers pay more attention to deep learning methods with direct supervised or unsupervised learning, which exploit deep prior only from training dataset or testing data. In this article, an efficient convolutional neural network‐based method is presented to progressively super‐resolve HS image with RGB image guidance. Specifically, a progressive HS image super‐resolution network is proposed, which progressively super‐resolve the LR HS image with pixel shuffled HR RGB image guidance. Then, the super‐resolution network is progressively trained with supervised pre‐training and unsupervised adaption, where supervised pre‐training learns the general prior on training data and unsupervised adaptation generalises the general prior to specific prior for variant testing scenes. The proposed method can effectively exploit prior from training dataset and testing HS and RGB images with spectral‐spatial constraint. It has a good generalisation capability, especially for blind HS image super‐resolution. Comprehensive experimental results show that the proposed deep progressive learning method outperforms the existing state‐of‐the‐art methods for HS image super‐resolution in non‐blind and blind cases.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/cit2.12256"
    },
    {
        "id": 29490,
        "title": "Validation Of New Super Resolution Deep Learning Reconstruction For Coronary Artery Calcium Scoring",
        "authors": "J. Schuzer, C. Steveson, S. Rollison, K. Bronson, J. Zhou, L. Cai, Z. Yu, M. Chen",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jcct.2023.05.187"
    },
    {
        "id": 29491,
        "title": "Deep-learning-based image super-resolution of an end-expandable optical fiber probe for application in esophageal cancer diagnostics",
        "authors": "Xiaohui Zhang, Mimi Tan, Mansour Nabil, Richa Shukla, Shaleen Vasavada, Sharmila Anandasabapathy, Mark A. Anastasio, Elena V. Petrova",
        "published": "2024-4-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/1.jbo.29.4.046001"
    },
    {
        "id": 29492,
        "title": "A COMPARISON OF DEEP LEARNING-BASED SUPER-RESOLUTION FRAMEWORKS FOR SENTINEL-2 IMAGERY IN URBAN AREAS",
        "authors": "S. T. Seydi, H. Arefi",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "Abstract. The high-resolution images are in demand for many applications in the monitoring of urban areas. The advent of remote sensing satellites such as Sentinel-2 has made data more accessible as it provides free multispectral imagery. However, the spatial resolution of these images is not sufficient for many of the tasks. With the advent of deep learning techniques, significant progress has been made in the field of super-resolution, which has shown promising results in the improvement of the spatial resolution of satellite images. In this study, we compare four the most common deep learning-based models for the super-resolution of Sentinel-2 imagery in dense urban areas using aerial images. These methods are including enhanced deep super-resolution network (EDSR), super-resolution generative adversarial networks (ESRGAN), residual feature distillation network (RFDN), and Super-Resolution Convolutional Neural Network (SRCNN). To determine the effectiveness of the models in improving image resolution, they were evaluated using visual quality and quantitative metrics. The super-resolution results show that deep learning-based models have high potential for the generation of the high-resolution dataset from Sentinel-2 imagery in urban areas. The RFDN outperformed other deep learning-based models that achieved the peak signal-to-noise ratio (PSNR) more than 17.8.\n                    ",
        "keywords": "",
        "link": "http://dx.doi.org/10.5194/isprs-annals-x-1-w1-2023-1021-2023"
    },
    {
        "id": 29493,
        "title": "Deep Learning Accelerated Brain Diffusion-Weighted MRI with Super Resolution Processing",
        "authors": "Sebastian Altmann, Nils F. Grauhan, Mario Alberto Abello Mercado, Sebastian Steinmetz, Andrea Kronfeld, Roman Paul, Thomas Benkert, Timo Uphaus, Sergiu Groppa, Yaroslav Winter, Marc A. Brockmann, Ahmed E. Othman",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.acra.2024.02.049"
    },
    {
        "id": 29494,
        "title": "A Comparative Study of Deep Learning-Based Super-Resolution Techniques on Sentinel-2 and CAS500-1 Satellites",
        "authors": "Jonggu Kang, Yang-Won Lee, Daesun Kim",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.22905/kaopqj.2023.57.4.13"
    },
    {
        "id": 29495,
        "title": "Super-resolution deep learning reconstruction at coronary computed tomography angiography to evaluate the coronary arteries and in-stent lumen: an initial experience",
        "authors": "Makoto Orii, Misato Sone, Takeshi Osaki, Yuta Ueyama, Takuya Chiba, Tadashi Sasaki, Kunihiro Yoshioka",
        "published": "2023-10-30",
        "citations": 1,
        "abstract": "AbstractA super-resolution deep learning reconstruction (SR-DLR) algorithm trained using data acquired on the ultrahigh spatial resolution computed tomography (UHRCT) has the potential to provide better image quality of coronary arteries on the whole-heart, single-rotation cardiac coverage on a 320-detector row CT scanner. However, the advantages of SR-DLR at coronary computed tomography angiography (CCTA) have not been fully investigated. The present study aimed to compare the image quality of the coronary arteries and in-stent lumen between SR-DLR and model-based iterative reconstruction (MBIR). We prospectively enrolled 70 patients (median age, 69 years; interquartile range [IQR], 59–75 years; 50 men) who underwent CCTA using a 320-detector row CT scanner between January and August 2022. The image noise in the ascending aorta, left atrium, and septal wall of the ventricle was measured, and the signal-to-noise ratio (SNR) and contrast-to-noise ratio (CNR) in the proximal coronary arteries were calculated. Of the twenty stents, stent strut thickness and luminal diameter were quantitatively evaluated. The image noise on SR-DLR was significantly lower than that on MBIR (median 22.1 HU; IQR, 19.3–24.9 HU vs. 27.4 HU; IQR, 24.2–31.2 HU, p < 0.01), whereas the SNR (median 16.3; IQR, 11.8–21.8 vs. 13.7; IQR, 9.9–18.4, p = 0.01) and CNR (median 24.4; IQR, 15.5–30.2 vs. 19.2; IQR, 14.1–23.2, p < 0.01) on SR-DLR were significantly higher than that on MBIR. Stent struts were significantly thinner (median, 0.68 mm; IQR, 0.61–0.78 mm vs. 0.81 mm; IQR, 0.72–0.96 mm, p < 0.01) and in-stent lumens were significantly larger (median, 1.84 mm; IQR, 1.65–2.26 mm vs. 1.52 mm; IQR, 1.28–2.25 mm, p < 0.01) on SR-DLR than on MBIR. Although further large-scale studies using invasive coronary angiography as the reference standard, comparative studies with UHRCT, and studies in more challenging population for CCTA are needed, this study’s initial experience with SR-DLR would improve the utility of CCTA in daily clinical practice due to the better image quality of the coronary arteries and in-stent lumen at CCTA compared with conventional MBIR.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s12880-023-01139-7"
    },
    {
        "id": 29496,
        "title": "Super-coding resolution single-pixel imaging based on unpaired data-driven deep learning",
        "authors": "Shoupei Liu, Huazheng Wu, Qi Li, Xiangfeng Meng, Yongkai Yin",
        "published": "2023-11",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.optlaseng.2023.107786"
    },
    {
        "id": 29497,
        "title": "Lightweight image super-resolution based on deep learning: State-of-the-art and future directions",
        "authors": "Garas Gendy, Guanghui He, Nabil Sabor",
        "published": "2023-6",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.inffus.2023.01.024"
    },
    {
        "id": 29498,
        "title": "Learning-based and quality preserving super-resolution of noisy images",
        "authors": "Simone Cammarasana, Giuseppe Patanè",
        "published": "2024-4-16",
        "citations": 0,
        "abstract": "AbstractPurpose: Several applications require the super-resolution of noisy images and the preservation of geometrical and texture features. State-of-the-art super-resolution methods do not account for noise and generally enhance the output image’s artefacts (e.g., aliasing, blurring). Methods: We propose a learning-based method that accounts for the presence of noise and preserves the properties of the input image, as measured by quantitative metrics, e.g., normalised crossed correlation, normalised mean squared error, peak-signal-to-noise-ration, structural similarity feature-based similarity, universal image quality. We train our network to up-sample a low-resolution noisy image while preserving its properties. We perform our tests on the Cineca Marconi100 cluster, at the 26th position in the “top500” list. Results: The experimental results show that our method outperforms learning-based methods, has comparable results with standard methods, preserves the properties of the input image as contours, brightness, and textures, and reduces the artefacts. As average quantitative metrics, our approach has a PSNR value of 23.81 on the super-resolution of Gaussian noise images with a 2X up-sampling factor. In contrast, previous work has a PSNR value of 23.09 (standard method) and 21.78 (learning-based method). Conclusion: Our learning-based and quality-preserving super-resolution improves the high-resolution prediction of noisy images with respect to state-of-the-art methods with different noise types and up-sampling factors.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-024-19202-y"
    },
    {
        "id": 29499,
        "title": "Multi-step reinforcement learning for medical image super-resolution",
        "authors": "Alix Bouffard, Mihaela Pop, Mehran Ebrahimi",
        "published": "2023-4-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2653655"
    },
    {
        "id": 29500,
        "title": "Learning Super-Resolution Ultrasound Localization Microscopy from Radio-Frequency Data",
        "authors": "Christopher Hahne, Georges Chabouh, Olivier Couture, Raphael Sznitman",
        "published": "2023-9-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ius51837.2023.10307592"
    },
    {
        "id": 29501,
        "title": "Audio super-resolution via vision transformer",
        "authors": "Simona Nisticò, Luigi Palopoli, Adele Pia Romano",
        "published": "2023-12-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10844-023-00833-w"
    },
    {
        "id": 29502,
        "title": "A super-resolution network for medical imaging via transformation analysis of wavelet multi-resolution",
        "authors": "Yue Yu, Kun She, Jinhua Liu, Xiao Cai, Kaibo Shi, O.M. Kwon",
        "published": "2023-9",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neunet.2023.07.005"
    },
    {
        "id": 29503,
        "title": "Deep Successive Convex Approximation for Image Super-Resolution",
        "authors": "Xiaohui Li, Jinpeng Wang, Xinbo Liu",
        "published": "2023-1-27",
        "citations": 0,
        "abstract": "Image super-resolution (SR), as one of the classic image processing issues, has attracted increasing attention from researchers. As a highly ill-conditioned, non-convex optimization issue, it is difficult for image SR to restore a high-resolution (HR) image from a given low-resolution (LR) instance. Recent researchers have tended to regard image SR as a regression task and to design an end-to-end convolutional neural network (CNN) to predict the pixels directly, which lacks inherent theoretical analysis and limits the effectiveness of the restoration. In this paper, we analyze image SR from an optimization perspective and develop a deep successive convex approximation network (SCANet) for generating HR images. Specifically, we divide non-convex optimization into several convex LASSO sub-problems and use CNN to adaptively learn the parameters. To boost network representation, we use residual feature aggregation (RFA) blocks and devise a spatial and channel attention (SACA) mechanism to improve the restoration capacity. The experimental results show that the proposed SCANet can restore HR images more effectively than other works. Specifically, SCANet achieves higher PSNR/SSIM results and generates more satisfying textures.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math11030651"
    },
    {
        "id": 29504,
        "title": "Noise modelling using Deep CNN for Terahertz Super-Resolution Imaging",
        "authors": "Rejeena R Sebastian, Léo Guiramand, François Blanchard",
        "published": "2023-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/pn58661.2023.10223028"
    }
]