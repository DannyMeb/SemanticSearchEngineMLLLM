[
    {
        "id": 4801,
        "title": "Biased Dropout and Crossmap Dropout: Learning towards effective Dropout regularization in convolutional neural network",
        "authors": "Alvin Poernomo, Dae-Ki Kang",
        "published": "2018-8",
        "citations": 89,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neunet.2018.03.016"
    },
    {
        "id": 4802,
        "title": "Regularization of Deep Neural Networks with Average Pooling Dropout",
        "authors": "El Houssaine HSSAYNI",
        "published": "2020-3-31",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5373/jardcs/v12sp4/20201654"
    },
    {
        "id": 4803,
        "title": "Unsupervised Adaptation with Adversarial Dropout Regularization for Robust Speech Recognition",
        "authors": "Pengcheng Guo, Sining Sun, Lei Xie",
        "published": "2019-9-15",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2019-2544"
    },
    {
        "id": 4804,
        "title": "Dropout regularization in Deep learning for Internet traffic classification",
        "authors": "Ahmed Krobba, Mohamed Debyeche, Rania KOUIDER, Boutheina Hocine",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nNowadays, the Internet has become the global means of communication for transmitting all kinds of traffic data; this is what makes it develop rapidly, which means the network traffic data increases greatly. In order to manage the data circulating in the networks it is necessary to establish an analysis of the network traffic which makes it possible to provide detailed and explainable data on this traffic and the consumption of the bandwidth, generally by applications and their protocols. In this paper, we analyse and classify internet traffic using the «Deep Neurale Network » method and compare their performance to that of the artificial neural network. The results show that the proposed method is able to accurately and stably classify the content types of network traffic compared with to the RNN.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1583026/v1"
    },
    {
        "id": 4805,
        "title": "Dropout regularization in hierarchical mixture of experts",
        "authors": "Ozan İrsoy, Ethem Alpaydın",
        "published": "2021-1",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neucom.2020.08.052"
    },
    {
        "id": 4806,
        "title": "Dropout Regularization for Self-Supervised Learning of Transformer Encoder Speech Representation",
        "authors": "Jian Luo, Jianzong Wang, Ning Cheng, Jing Xiao",
        "published": "2021-8-30",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2021-1066"
    },
    {
        "id": 4807,
        "title": "Employing dropout regularization to classify recurring drifted data streams",
        "authors": "Filip Guzy, Michal Wozniak",
        "published": "2020-7",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/ijcnn48605.2020.9207266"
    },
    {
        "id": 4808,
        "title": "Integrating Dropout and Kullback-Leibler Regularization in Bayesian Neural Networks for Improved Uncertainty Estimation in Regression",
        "authors": "Raghavendra Devadas, Dr Vani Hiremani",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4727556"
    },
    {
        "id": 4809,
        "title": "Data Dropout in Arbitrary Basis for Deep Network Regularization",
        "authors": "Mostafa Rahmani, George K. Atia",
        "published": "2018-10",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/acssc.2018.8645094"
    },
    {
        "id": 4810,
        "title": "Combining Regularization and Dropout Techniques for Deep Convolutional Neural Network",
        "authors": "Zari Farhadi, Hossein Bevrani, Mohammad-Reza Feizi-Derakhshi",
        "published": "2022-10-26",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/gec55014.2022.9986657"
    },
    {
        "id": 4811,
        "title": "Exploiting Semi-Supervised Training Through a Dropout Regularization in End-to-End Speech Recognition",
        "authors": "Subhadeep Dey, Petr Motlicek, Trung Bui, Franck Dernoncourt",
        "published": "2019-9-15",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21437/interspeech.2019-3246"
    },
    {
        "id": 4812,
        "title": "Dropout Regularization in Deep Neural Networks Used in Atomic Simulations",
        "authors": "Ljubinka Sandjakoska",
        "published": "2018-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.20544/aiit2018.p11"
    },
    {
        "id": 4813,
        "title": "BPE-Dropout: Simple and Effective Subword Regularization",
        "authors": "Ivan Provilkov, Dmitrii Emelianenko, Elena Voita",
        "published": "2020",
        "citations": 45,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18653/v1/2020.acl-main.170"
    },
    {
        "id": 4814,
        "title": "Acceleration of DNN Training Regularization: Dropout Accelerator",
        "authors": "Gunhee Lee, Hanmin Park, Soojung Ryu, Hyuk-Jae Lee",
        "published": "2020-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/iceic49074.2020.9051194"
    },
    {
        "id": 4815,
        "title": "Regularization of deep neural networks with spectral dropout",
        "authors": "Salman H. Khan, Munawar Hayat, Fatih Porikli",
        "published": "2019-2",
        "citations": 75,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.neunet.2018.09.009"
    },
    {
        "id": 4816,
        "title": "Node Classification Using Graph Convolutional Network with Dropout Regularization",
        "authors": "Bing-Yu Xiao, Chien-Cheng Tseng, Su-Ling Lee",
        "published": "2021-12-7",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tencon54134.2021.9707262"
    },
    {
        "id": 4817,
        "title": "On the Regularization Properties of Structured Dropout",
        "authors": "Ambar Pal, Connor Lane, Rene Vidal, Benjamin D. Haeffele",
        "published": "2020-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/cvpr42600.2020.00769"
    },
    {
        "id": 4818,
        "title": "Lung Cancer Detection by Employing Adaptive Entropy Variance Dropout Regularization in GAN Variants",
        "authors": "E. Thirumagal, K. Saruladha",
        "published": "2024-3-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s42979-024-02662-2"
    },
    {
        "id": 4819,
        "title": "Integrating Dropout and Kullback-Leibler Regularization in Bayesian Neural Networks for improved uncertainty estimation in Regression",
        "authors": "Raghavendra M. Devadas, Vani Hiremani",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.mex.2024.102659"
    },
    {
        "id": 4820,
        "title": "Macro-Block Dropout for Improved Regularization in Training End-to-End Speech Recognition Models",
        "authors": "Chanwoo Kim, Sathish Indurti, Jinhwan Park, Wonyong Sung",
        "published": "2023-1-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/slt54892.2023.10023451"
    },
    {
        "id": 4821,
        "title": "An Unsupervised Regularization and Dropout based Deep Neural Network and Its Application for Thermal Error Prediction",
        "authors": "Yang Tian, Guangyuan Pan",
        "published": "2020-4-21",
        "citations": 12,
        "abstract": "Due to the large size of the heavy duty machine tool-foundation systems, space temperature difference is high related to thermal error, which affects to system’s accuracy greatly. The recent highly focused deep learning technology could be an alternative in thermal error prediction. In this paper, a thermal prediction model based on a self-organizing deep neural network (DNN) is developed to facilitate accurate-based training for thermal error modeling of heavy-duty machine tool-foundation systems. The proposed model is improved in two ways. Firstly, a dropout self-organizing mechanism for unsupervised training is developed to prevent co-adaptation of the feature detectors. In addition, a regularization enhanced transfer function is proposed to further reduce the less important weights of the process and improve the network feature extraction capability and generalization ability. Furthermore, temperature sensors are used to acquire temperature data from the heavy-duty machine tool and concrete foundation. In this way, sample data of thermal error predictive model are repeatedly collected from the same locations at different times. Finally, accuracy of the thermal error prediction model was validated by thermal error experiments, thus laying the foundation for subsequent studies on thermal error compensation.",
        "link": "http://dx.doi.org/10.3390/app10082870"
    },
    {
        "id": 4822,
        "title": "Ising-dropout: A Regularization Method for Training and Compression of Deep Neural Networks",
        "authors": "Hojjat Salehinejad, Shahrokh Valaee",
        "published": "2019-5",
        "citations": 22,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp.2019.8682914"
    },
    {
        "id": 4823,
        "title": "Weighted Channel Dropout for Regularization of Deep Convolutional Neural Network",
        "authors": "Saihui Hou, Zilei Wang",
        "published": "2019-7-17",
        "citations": 37,
        "abstract": "In this work, we propose a novel method named Weighted Channel Dropout (WCD) for the regularization of deep Convolutional Neural Network (CNN). Different from Dropout which randomly selects the neurons to set to zero in the fully-connected layers, WCD operates on the channels in the stack of convolutional layers. Specifically, WCD consists of two steps, i.e., Rating Channels and Selecting Channels, and three modules, i.e., Global Average Pooling, Weighted Random Selection and Random Number Generator. It filters the channels according to their activation status and can be plugged into any two consecutive layers, which unifies the original Dropout and Channel-Wise Dropout. WCD is totally parameter-free and deployed only in training phase with very slight computation cost. The network in test phase remains unchanged and thus the inference cost is not added at all. Besides, when combining with the existing networks, it requires no re-pretraining on ImageNet and thus is well-suited for the application on small datasets. Finally, WCD with VGGNet-16, ResNet-101, Inception-V3 are experimentally evaluated on multiple datasets. The extensive results demonstrate that WCD can bring consistent improvements over the baselines.",
        "link": "http://dx.doi.org/10.1609/aaai.v33i01.33018425"
    },
    {
        "id": 4824,
        "title": "Implicit Regularization of Dropout",
        "authors": "Zhongwang Zhang, Zhi-Qin John Xu",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/tpami.2024.3357172"
    },
    {
        "id": 4825,
        "title": "A Review on Dropout Regularization Approaches for Deep Neural Networks within the Scholarly Domain",
        "authors": "Imrus Salehin, Dae-Ki Kang",
        "published": "2023-7-17",
        "citations": 10,
        "abstract": "Dropout is one of the most popular regularization methods in the scholarly domain for preventing a neural network model from overfitting in the training phase. Developing an effective dropout regularization technique that complies with the model architecture is crucial in deep learning-related tasks because various neural network architectures have been proposed, including convolutional neural networks (CNNs) and recurrent neural networks (RNNs), and they have exhibited reasonable performance in their specialized areas. In this paper, we provide a comprehensive and novel review of the state-of-the-art (SOTA) in dropout regularization. We explain various dropout methods, from standard random dropout to AutoDrop dropout (from the original to the advanced), and also discuss their performance and experimental capabilities. This paper provides a summary of the latest research on various dropout regularization techniques for achieving improved performance through “Internal Structure Changes”, “Data Augmentation”, and “Input Information”. We can see that proper regularization with respect to structural constraints of network architecture is a critical factor to facilitate overfitting avoidance. We discuss the strengths and limitations of the methods presented in this work, which can serve as valuable references for future research and the development of new approaches. We also pay attention to the scholarly domain in the discussion in order to meet the overwhelming increase of scientific research outcomes by providing an analysis of several important academic scholarly issues of neural networks.",
        "link": "http://dx.doi.org/10.3390/electronics12143106"
    },
    {
        "id": 4826,
        "title": "Quality of randomness and node dropout regularization for fitting neural networks",
        "authors": "Aki Koivu, Joona-Pekko Kakko, Santeri Mäntyniemi, Mikko Sairanen",
        "published": "2022-11",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.eswa.2022.117938"
    },
    {
        "id": 4827,
        "title": "Dropout, a basic and effective regularization method for a deep learning model: a case study",
        "authors": "Brahim Jabir, Noureddine Falih",
        "published": "2021-11-1",
        "citations": 4,
        "abstract": "Deep learning is based on a network of artificial neurons inspired by the human brain. This network is made up of tens or even hundreds of \"layers\" of neurons. The fields of application of deep learning are indeed multiple; Agriculture is one of those fields in which deep learning is used in various agricultural problems (disease detection, pest detection, and weed identification). A major problem with deep learning is how to create a model that works well, not only on the learning set but also on the validation set. Many approaches used in neural networks are explicitly designed to reduce overfit, possibly at the expense of increasing validation accuracy and training accuracy. In this paper, a basic technique (dropout) is proposed to minimize overfit, we integrated it into a convolutional neural network model to classify weed species and see how it impacts performance, a complementary solution (exponential linear units) are proposed to optimize the obtained results. The results showed that these proposed solutions are practical and highly accurate, enabling us to adopt them in deep learning models.",
        "link": "http://dx.doi.org/10.11591/ijeecs.v24.i2.pp1009-1016"
    },
    {
        "id": 4828,
        "title": "Assessment of data augmentation, dropout with L2 Regularization and differential privacy against membership inference attacks",
        "authors": "Sana Ben Hamida, Hichem Mrabet, Faten Chaieb, Abderrazak Jemai",
        "published": "2023-10-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/s11042-023-17394-3"
    },
    {
        "id": 4829,
        "title": "Robust Audio-visual Speech Recognition Using Bimodal Dfsmn with Multi-condition Training and Dropout Regularization",
        "authors": "Shiliang Zhang, Ming Lei, Bin Ma, Lei Xie",
        "published": "2019-5",
        "citations": 15,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp.2019.8682566"
    },
    {
        "id": 4830,
        "title": "Analysis on the Effect of Dropout as a Regularization Technique in Deep Averaging Network",
        "authors": "Lovelyn Rose S, Rashmi M",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4108/eai.7-12-2021.2314492"
    },
    {
        "id": 4831,
        "title": "Heuristic Dropout: An Efficient Regularization Method for Medical Image Segmentation Models",
        "authors": "Dachuan Shi, Ruiyang Liu, Linmi Tao, Chun Yuan",
        "published": "2022-5-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/icassp43922.2022.9747409"
    },
    {
        "id": 4832,
        "title": "Integrating Dropout Regularization Technique at Different Layers to Improve the Performance of Neural Networks",
        "authors": "B. H. Pansambal, A. B. Nandgaokar",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.14569/ijacsa.2023.0140478"
    },
    {
        "id": 4833,
        "title": "Analysis on Dropout Regularization",
        "authors": "John Sum, Chi-Sing Leung",
        "published": "2019",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-36802-9_28"
    },
    {
        "id": 4834,
        "title": "Frequency Dropout: Feature-Level Regularization via Randomized Filtering",
        "authors": "Mobarakol Islam, Ben Glocker",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-25066-8_14"
    },
    {
        "id": 4835,
        "title": "Mitigating Overfitting in Extreme Learning Machine Classifier Through Dropout Regularization",
        "authors": " Fateh Alrahman Kamal Qasem Alnagashi,  Norasmadi Abdul Rahim,  Shazmin Aniza Abdul Shukor,  Mohamad Hanif Ab. Hamid",
        "published": "2024-2-14",
        "citations": 0,
        "abstract": "Achieving optimal machine learning model performance is often hindered by the limited availability of diverse datasets, a challenge exacerbated by small sample sizes in real-world scenarios. In this study, we address this critical issue in classification tasks by integrating the Dropout technique into the Extreme Learning Machine (ELM) classifier. Our research underscores the effectiveness of Dropout-ELM in mitigating overfitting, especially when data is scarce, leading to enhanced generalization capabilities. Through extensive experiments on synthetic and real-world datasets, our findings consistently demonstrate that Dropout-ELM outperforms traditional ELM, yielding significant accuracy improvements ranging from 0.19% to 16.20%. By strategically implementing dropout during training, we promote the development of robust models that reduce reliance on specific features or neurons, resulting in increased adaptability and resilience across diverse datasets. Ultimately, Dropout-ELM emerges as a potent tool to counter overfitting and bolster the performance of ELM-based classifiers, particularly in scenarios with limited data. Its established efficacy positions it as a valuable asset for enhancing the reliability and generalization of machine learning models, providing a robust solution to the challenges posed by constrained training data. ",
        "link": "http://dx.doi.org/10.58915/amci.v13ino.1.561"
    },
    {
        "id": 4836,
        "title": "Mixed-pooling-dropout for convolutional neural network regularization",
        "authors": "Brahim Ait Skourt, Abdelhamid El Hassani, Aicha Majda",
        "published": "2022-9",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.jksuci.2021.05.001"
    },
    {
        "id": 4837,
        "title": "Dropout Regularization for Automatic Segmented Dental Images",
        "authors": "Vincent Majanga, Serestina Viriri",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-16-1685-3_21"
    },
    {
        "id": 4838,
        "title": "Sine Cosine Algorithm with Tangent Search for Neural Networks Dropout Regularization",
        "authors": "Luka Jovanovic, Milos Antonijevic, Miodrag Zivkovic, Dijana Jovanovic, Marina Marjanovic, Nebojsa Bacanin",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-19-6004-8_59"
    },
    {
        "id": 4839,
        "title": "Revisiting Dropout Regularization for Cross-Modality Person Re-Identification",
        "authors": "Reza Fuad Rachmadi, Supeno Mardi Susiki Nugroho, I. Ketut Eddy Purnama",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/access.2022.3208562"
    },
    {
        "id": 4840,
        "title": "Batch Normalization and Dropout Regularization in Training Deep Neural Networks with Label Noise",
        "authors": "Andrzej Rusiecki",
        "published": "2022",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-96308-8_6"
    },
    {
        "id": 4841,
        "title": "Modeling and implementation of a novel active voltage balancing circuit using deep recurrent neural network with dropout regularization",
        "authors": "Mostafa Noohi, Amin Faraji, Sayed Alireza Sadrossadat, Ali Mirvakili, Ali Moftakharzadeh",
        "published": "2023-5",
        "citations": 3,
        "abstract": "SummaryRecurrent neural networks (RNN) emerged as powerful tools to model and analyze the nonlinear behavior of electronic circuits accurately and quickly. Efforts to improve the accuracy of RNN will lead to the design of better‐quality products, which is essential in various fields such as the design of energy harvesting (EH) systems. EH techniques can provide the electrical energy needed for low‐power electronics without the need for a battery or with minimal dependency. Due to the importance of the active voltage balancing circuit in EH systems, we have proposed a new macromodeling method called dropout local‐feedback deep recurrent neural network (Dropout‐LFDRNN) to model and analyze this circuit along with two other nonlinear circuits as examples. This technique is an advance over the LFDRNN macromodeling method, and based on the obtained results from the measurements, we were able to build a fast macromodel for the active balancing circuit, which outperforms conventional deep recurrent neural network modeling method in terms of accuracy without sacrificing speed. It is worth mentioning that this proposed technique in this paper can be considered a viable approach for modeling and analysis of nonlinear electronic components and circuits. In addition to the advantage of generating a more accurate model, the model based on the Dropout‐LFDRNN approach is much faster than the existing transistor‐level models.",
        "link": "http://dx.doi.org/10.1002/cta.3485"
    },
    {
        "id": 4842,
        "title": "Building Comprehensive Dropout Prevention and Recovery/Re-Entry Programs",
        "authors": "Howard M. Blonsky",
        "published": "2020-1-6",
        "citations": 0,
        "abstract": "This chapter looks at effective strategies and programs that have proved successful in addressing and preventing students dropping out of school. It cites the findings of the What Works Clearinghouse with regard to various programs and whether they were found to show evidence of effectiveness.",
        "link": "http://dx.doi.org/10.1093/oso/9780190090845.003.0012"
    },
    {
        "id": 4843,
        "title": "School Climate and Culture and Its Relationship to Dropout Prevention",
        "authors": "Howard M. Blonsky",
        "published": "2020-1-6",
        "citations": 0,
        "abstract": "This chapter describes how a positive school climate can contribute to students bonding with and staying in the school. It also describes how a negative or “toxic” school climate can contribute to the dropout problem. The chapter looks at the important role of teacher(s) and how they contribute to students staying in or leaving school prior to graduation. The chapter also looks at school climate as a “therapeutic intervention.”",
        "link": "http://dx.doi.org/10.1093/oso/9780190090845.003.0005"
    },
    {
        "id": 4844,
        "title": "A Hybrid Improved Neural Networks Algorithm Based on L2 and Dropout Regularization",
        "authors": "Xiaoyun Xie, Ming Xie, Ata Jahangir Moshayedi, Mohammad Hadi Noori Skandari",
        "published": "2022-11-3",
        "citations": 3,
        "abstract": "Small samples are prone to overfitting in the neural network training process. This paper proposes an optimization approach based on L2 and dropout regularization called a hybrid improved neural network algorithm to overcome this issue. The proposed model was evaluated based on the Modified National Institute of Standards and Technology (MNIST, grayscale-28 × 28 × 1) and Canadian Institute for Advanced Research 10 (CIFAR10, RGB - 32 × 32 × 3) as the training data sets and data applied to the LeNet-5 and Autoencoder neural network architectures. The evaluation is conducted based on cross-validation; the result of the model prediction is used as the final measure to evaluate the quality of the model. The results show that the proposed hybrid algorithm can perform more effectively, avoid overfitting, improve the accuracy of network model prediction in classification tasks, and reduce the reconstruction error in the unsupervised domain. In addition, employing the proposed algorithm without increasing the time complexity can reduce the effect of noisy data and bias and improve the training time of neural network models. Quantitative and qualitative experimental results show that the accuracy of using the proposed algorithm in this paper with the MNIST test set has an improvement of 2.3% and 0.9% compared to L2 regularization and dropout regularization, respectively, and based on the CIFAR10 data set, the accuracy improvement of 0.92% compared with L2 regularization and 1.31% concerning dropout regularization. The reconstruction error of using the proposed algorithm in this paper with the MNIST data set has an improvement of 0.00174 and 0.00398 compared to L2 regularization and dropout regularization, respectively, and based on the CIFAR10 data set, the accuracy improvement of 0.00078 compared with L2 regularization and 0.00174 concerning dropout regularization.",
        "link": "http://dx.doi.org/10.1155/2022/8220453"
    },
    {
        "id": 4845,
        "title": "Hybrid Approach Based on Grey Wolf Optimizer for Dropout Regularization in Deep Learning",
        "authors": "Selma Kali Ali, Dalila Boughaci",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-18516-8_9"
    },
    {
        "id": 4846,
        "title": "Hybridized sine cosine algorithm with convolutional neural networks dropout regularization application",
        "authors": "Nebojsa Bacanin, Miodrag Zivkovic, Fadi Al-Turjman, K. Venkatachalam, Pavel Trojovský, Ivana Strumberger, Timea Bezdan",
        "published": "2022-4-15",
        "citations": 49,
        "abstract": "AbstractDeep learning has recently been utilized with great success in a large number of diverse application domains, such as visual and face recognition, natural language processing, speech recognition, and handwriting identification. Convolutional neural networks, that belong to the deep learning models, are a subtype of artificial neural networks, which are inspired by the complex structure of the human brain and are often used for image classification tasks. One of the biggest challenges in all deep neural networks is the overfitting issue, which happens when the model performs well on the training data, but fails to make accurate predictions for the new data that is fed into the model. Several regularization methods have been introduced to prevent the overfitting problem. In the research presented in this manuscript, the overfitting challenge was tackled by selecting a proper value for the regularization parameter dropout by utilizing a swarm intelligence approach. Notwithstanding that the swarm algorithms have already been successfully applied to this domain, according to the available literature survey, their potential is still not fully investigated. Finding the optimal value of dropout is a challenging and time-consuming task if it is performed manually. Therefore, this research proposes an automated framework based on the hybridized sine cosine algorithm for tackling this major deep learning issue. The first experiment was conducted over four benchmark datasets: MNIST, CIFAR10, Semeion, and UPS, while the second experiment was performed on the brain tumor magnetic resonance imaging classification task. The obtained experimental results are compared to those generated by several similar approaches. The overall experimental results indicate that the proposed method outperforms other state-of-the-art methods included in the comparative analysis in terms of classification error and accuracy.",
        "link": "http://dx.doi.org/10.1038/s41598-022-09744-2"
    },
    {
        "id": 4847,
        "title": "Driving Intention Inference Based on a Deep Neural Network with Dropout Regularization from Adhesion Coefficients in Active Collision Avoidance Control Systems",
        "authors": "Yufeng Lian, Jianan Huang, Shuaishi Liu, Zhongbo Sun, Binglin Li, Zhigen Nie",
        "published": "2022-7-22",
        "citations": 1,
        "abstract": "Driving intention, which can assist drivers to avoid dangerous emergence for the advanced driver assistant systems (ADAS), can be hardly described accurately for complex traffic environments. At present, driving intention can be mainly obtained by deep neural networks with neuromuscular dynamics and electromyography (EMG) signals of drivers. This method needs numerous drivers’ signals and neural networks with a complex structure. This paper proposes a driving intention direct inference method, namely direct inference from the road surface condition. A driving intention safety distance model based on a deep neural network with dropout regularization was built in an active collision avoidance control system of electric vehicles. Driving intention can be inferred by a deep neural network with dropout regularization from adhesion coefficients between the tire and road. Simulations using rapid control prototyping (RCP) and a hardware-in-the-loop (HIL) simulator were performed to demonstrate the effectiveness of the proposed driving intention safety distance model based on a deep neural network with dropout regularization. The proposed driving intention safety distance model can guarantee the safe driving of electric vehicles.",
        "link": "http://dx.doi.org/10.3390/electronics11152284"
    },
    {
        "id": 4848,
        "title": "Regularization in CNN: A Mathematical Study for $$L_1$$, $$L_2$$ and Dropout Regularizers",
        "authors": "Chrifi Alaoui Mehdi, Joudar Nour-Eddine, Ettaouil Mohamed",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-26384-2_38"
    },
    {
        "id": 4849,
        "title": "Fine-Tuning Dropout Regularization in Energy-Based Deep Learning",
        "authors": "Gustavo H. de Rosa, Mateus Roder, João P. Papa",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-93420-0_10"
    },
    {
        "id": 4850,
        "title": "Sparse Dropout: a dropout layer specialized for attention mechanism",
        "authors": "Peng Liu, Guowei Deng, Shuai Zhao, Yanli Shi, Xiaoli Liu",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nRecently, the Transformer-architecture-based model takes an absolute predominance in natural language processing. Attention is a critical component of the Transformer. Attention allows the model to focus on different parts of the input sequence selectively. Dropout regularization is widely adopted and plays an active role by decoupling the hidden units in the model, preventing dependency on only several hidden units and finally making the model over-fitting. Though powerful and effective, the randomness introduced in attention may cause substantial information loss because of its completely random nature. In this paper, we present a simple but effective method named Sparse Dropout dedicated, which no longer randomly sets some values of attention scores to 0. A manually designated threshold super-parameter called $\\alpha$ was introduced in Sparse Dropout. All scores lower than this threshold will be set to 0 to suppress unwanted randomness and help the model to pay more attention to high attention scores parts of sequences. We verify our method on three mainstream tasks, including Chinese Named Entity Recognition, Text Summarization, and Text Classification. We achieve apparent improvements on the condition that we only substitute the Dropout layer during attention scores calculation with our Sparse Dropout. It demonstrates that our Sparse Dropout is effective and universal for all attention mechanisms entailed deep learning models with an elegant form.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-2840311/v1"
    },
    {
        "id": 4851,
        "title": "Regularization",
        "authors": "",
        "published": "2018",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.7551/mitpress/4175.003.0007"
    },
    {
        "id": 4852,
        "title": "dropout, n.",
        "authors": "",
        "published": "2023-3-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/oed/1402950681"
    },
    {
        "id": 4853,
        "title": "Adaptive Tabu Dropout for Regularization of Deep Neural Networks",
        "authors": "Md. Tarek Hasan, Arifa Akter, Mohammad Nazmush Shamael, Md Al Emran Hossain, H. M. Mutasim Billah, Sumayra Islam, Swakkhar Shatabda",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-30105-6_30"
    },
    {
        "id": 4854,
        "title": "Theoretical Underpinnings of Regularization Methods",
        "authors": "Holmes Finch",
        "published": "2022-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780367809645-2"
    },
    {
        "id": 4855,
        "title": "Regularization Methods for Linear Models",
        "authors": "Holmes Finch",
        "published": "2022-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780367809645-3"
    },
    {
        "id": 4856,
        "title": "Regularization Methods for Multilevel Models",
        "authors": "Holmes Finch",
        "published": "2022-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780367809645-8"
    },
    {
        "id": 4857,
        "title": "Reducing community college dropout through comprehensive supports",
        "authors": "",
        "published": "2020-2",
        "citations": 0,
        "abstract": "Providing community college students with a wide range of comprehensive supports, such as counseling, tutoring, and financial assistance, can improve low rates of persistence and graduation. These support programs address many simultaneous barriers that students face, which may be a key driver behind their effectiveness.",
        "link": "http://dx.doi.org/10.31485/pi.2593.2020"
    },
    {
        "id": 4858,
        "title": "The Dropout Prevention Specialist Workbook",
        "authors": "Howard M. Blonsky",
        "published": "2020-1-6",
        "citations": 0,
        "abstract": "This workbook is intended for school social workers and others who find themselves in positions either in a school or school district, working in the area of attendance improvement and dropout prevention and recovery. It is intended as a practical guide to going about actually doing this complex, multifaceted, and very important job. Many books and articles have been written regarding why students drop out of school, along with numerous suggestions for how to address this nationwide problem, but none has provided detailed directions for actually going into a school and beginning the task of tackling this challenging problem.",
        "link": "http://dx.doi.org/10.1093/oso/9780190090845.001.0001"
    },
    {
        "id": 4859,
        "title": "Clinical Trial Dropout",
        "authors": " ",
        "published": "2020-2-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.32388/shd3le"
    },
    {
        "id": 4860,
        "title": "Educational quality and dropout risk: a causal analysis of the university dropout phenomenon",
        "authors": "Inmaculada Pedraza-Navarro, Teresa González-Ramírez",
        "published": "2021-6-22",
        "citations": 0,
        "abstract": "University dropout is one of the main problems of the Spanish university system due to its high rates. The latest report issued by the Ministry of Science and Innovation (MICINN, 2020) shows that more than 30% of students drop out of an undergraduate degree program. In order to explore the phenomenon, in line with the scientific literature, we have focused on identifying personal and family variables associated with university dropout. Using an ex post facto, quantitative, descriptive and causal design methodology, we observed significant relationships between the dependent variable “completion of university degree” and the independent variables “age”, “marital status” and “number of siblings”. In agreement with other researches (Belloc et al, 2010; Diaz Peralta, 2008; Lizarte Simon, 2017) we conclude that university dropout is a multicausal phenomenon that needs to be fully understood. This will allow to maximize the use of resources allocated to higher education and optimize university access, permanence and quality policies.",
        "link": "http://dx.doi.org/10.4995/head21.2021.12910"
    },
    {
        "id": 4861,
        "title": "Regularization Methods for Latent Variable Models",
        "authors": "Holmes Finch",
        "published": "2022-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780367809645-7"
    },
    {
        "id": 4862,
        "title": "Regularization Methods for Multivariate Linear Models",
        "authors": "Holmes Finch",
        "published": "2022-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780367809645-5"
    },
    {
        "id": 4863,
        "title": "Regularization Methods for Generalized Linear Models",
        "authors": "Holmes Finch",
        "published": "2022-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780367809645-4"
    },
    {
        "id": 4864,
        "title": "Performance of a Novel Chaotic Firefly Algorithm with Enhanced Exploration for Tackling Global Optimization Problems: Application for Dropout Regularization",
        "authors": "Nebojsa Bacanin, Ruxandra Stoean, Miodrag Zivkovic, Aleksandar Petrovic, Tarik A. Rashid, Timea Bezdan",
        "published": "2021-10-25",
        "citations": 95,
        "abstract": "Swarm intelligence techniques have been created to respond to theoretical and practical global optimization problems. This paper puts forward an enhanced version of the firefly algorithm that corrects the acknowledged drawbacks of the original method, by an explicit exploration mechanism and a chaotic local search strategy. The resulting augmented approach was theoretically tested on two sets of bound-constrained benchmark functions from the CEC suites and practically validated for automatically selecting the optimal dropout rate for the regularization of deep neural networks. Despite their successful applications in a wide spectrum of different fields, one important problem that deep learning algorithms face is overfitting. The traditional way of preventing overfitting is to apply regularization; the first option in this sense is the choice of an adequate value for the dropout parameter. In order to demonstrate its ability in finding an optimal dropout rate, the boosted version of the firefly algorithm has been validated for the deep learning subfield of convolutional neural networks, with respect to five standard benchmark datasets for image processing: MNIST, Fashion-MNIST, Semeion, USPS and CIFAR-10. The performance of the proposed approach in both types of experiments was compared with other recent state-of-the-art methods. To prove that there are significant improvements in results, statistical tests were conducted. Based on the experimental data, it can be concluded that the proposed algorithm clearly outperforms other approaches.",
        "link": "http://dx.doi.org/10.3390/math9212705"
    },
    {
        "id": 4865,
        "title": "A Mixed Methods Research Study on School Dropout and Mathematics-Related School Dropout",
        "authors": "Hatice Cetin, Hakan Cite",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "School dropout is a persistent problem in educational sciences, and sample research has been conducted on this issue. Research has associated school dropout with various reasons, including academic failure. The current study aims to investigate the reasons of mathematics-related school dropout, as a sub-area of academic failure. The study adopted a mixed methods research design. In the quantitative phase, 955 adults completed a questionnaire regarding their school dropout and not continuing to a further school level. The quantitative data were analyzed using SPSS 25.0 program. The descriptive statistics revealed the reasons of general school dropout as family-related reasons, academic failure, environmental conditions, personal reasons, social reasons, teacher factor, health problems, and financial reasons. The inferential statistics (the chi-square test of independence) confirmed that adults’ school dropout was not independent of mathematics failure. The qualitative data analysis program, MAXQDA 2020, was used to account for the reasons of mathematics-related middle school and high school dropout in detail. To this end, interviews were held with two participants who dropped out of middle and high school, and their statements revealed that the reasons of mathematicsrelated school dropout or not continuing to a further school level were mathematics attitude, test anxiety, mathematics anxiety, teacher’s attitude, social factors, and main shortcomings. The qualitative data were analyzed through the singlecase model and two-cases model and presented with MAXmaps. The results demonstrated that the qualitative findings explained and confirmed the quantitative findings. The study offers several recommendations for various disciplines based on the findings.",
        "link": "http://dx.doi.org/10.59455/jomes.35"
    },
    {
        "id": 4866,
        "title": "Dropout and its Impact on the Household Economy",
        "authors": "Nirdosh Kumar",
        "published": "2018-4-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.29070/27/57481"
    },
    {
        "id": 4867,
        "title": "CamDrop",
        "authors": "Hongjun Wang, Guangrun Wang, Guanbin Li, Liang Lin",
        "published": "2019-11-3",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1145/3357384.3357999"
    },
    {
        "id": 4868,
        "title": "Introduction",
        "authors": "Howard M. Blonsky",
        "published": "2020-1-6",
        "citations": 0,
        "abstract": "This chapter includes the reasons that students drop out of school, a proposed job description for the social worker working as a dropout prevention specialist (DPS), thoughts on going into the school and developing working relationships with staff and students, an explanation of school data and finances and how to use them, and the importance of persevering on behalf of students.",
        "link": "http://dx.doi.org/10.1093/oso/9780190090845.003.0001"
    },
    {
        "id": 4869,
        "title": "2. Theoretical aspects of regularization",
        "authors": "",
        "published": "2017-9-25",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110559125-002"
    },
    {
        "id": 4870,
        "title": "2 Regularization Methods For Linear Equations",
        "authors": "",
        "published": "2018-2-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110557350-002"
    },
    {
        "id": 4871,
        "title": "Dropout rates and reasons for dropout among patients receiving clozapine",
        "authors": "Sandeep Grover, Eepsita Mishra, Subho Chakrabarti",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.4103/indianjpsychiatry.indianjpsychiatry_819_22"
    },
    {
        "id": 4872,
        "title": "Conclusion",
        "authors": "Howard M. Blonsky",
        "published": "2020-1-6",
        "citations": 0,
        "abstract": "I sincerely hope that the material presented in these pages will assist you, as a dropout prevention specialist, to be a catalyst in your school and/or district, in identifying those students, either individually or in groups, who are at risk for dropping out of school. By helping to craft and implement opportunities, services, and supports to address the issues and needs identified in the student body, you are helping tremendously to lower the potential for more students dropping out....",
        "link": "http://dx.doi.org/10.1093/oso/9780190090845.003.0013"
    },
    {
        "id": 4873,
        "title": "With music: Education against university dropout? On the connection between experiential group music sessions and the university dropout process.",
        "authors": "Agáta Csehi",
        "published": "2021-3-10",
        "citations": 0,
        "abstract": "'Dropout' is a phenomenon in practice and a defined concept in the literature, one of the most actual issues in education. It is a complex and multifaceted process. The Ratio research group, established at J. Selye University in Slovakia, also launched its research to study this phenomenon based on various objective and subjective aspects. The present study introduces a particular part of this research process. Music education is a crucial part of (pre-school and elementary) teacher training, which includes a unity of theoretical and practical knowledge. It is one of the most demanding subjects, which has been proven to cause difficulties in passing exams, in the successful fulfilment of the study conditions of teacher trainees and university studies. According to this facts, the study aims to assess the opinions of first-year (pre-school and elementary) teacher trainees and the objective and subjective circumstances (defined by them) that have helped or hindered them in meeting the study requirements for the subject of music education. Further, the paper aims to map out students' experiences during the study and exam period, which finally provided reinforcement in their university studies' relationship.",
        "link": "http://dx.doi.org/10.3311/ope.418"
    },
    {
        "id": 4874,
        "title": "The Machine Learning-Based Dropout Early Warning System for Improving the Performance of Dropout Prediction",
        "authors": "Sunbok Lee, Jae Young Chung",
        "published": "2019-7-31",
        "citations": 67,
        "abstract": "A dropout early warning system enables schools to preemptively identify students who are at risk of dropping out of school, to promptly react to them, and eventually to help potential dropout students to continue their learning for a better future. However, the inherent class imbalance between dropout and non-dropout students could pose difficulty in building accurate predictive modeling for a dropout early warning system. The present study aimed to improve the performance of a dropout early warning system: (a) by addressing the class imbalance issue using the synthetic minority oversampling techniques (SMOTE) and the ensemble methods in machine learning; and (b) by evaluating the trained classifiers with both receiver operating characteristic (ROC) and precision–recall (PR) curves. To that end, we trained random forest, boosted decision tree, random forest with SMOTE, and boosted decision tree with SMOTE using the big data samples of the 165,715 high school students from the National Education Information System (NEIS) in South Korea. According to our ROC and PR curve analysis, boosted decision tree showed the optimal performance.",
        "link": "http://dx.doi.org/10.3390/app9153093"
    },
    {
        "id": 4875,
        "title": "4 Iterative Regularization Methods For Nonlinear Equations",
        "authors": "",
        "published": "2018-2-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110557350-004"
    },
    {
        "id": 4876,
        "title": "Regularization, Definitions: Cut-off, Pauli–Villars, Dimensional Regularization, and General Feynman Parametrization",
        "authors": "",
        "published": "2019-10-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108624992.035"
    },
    {
        "id": 4877,
        "title": "The Academic Dropout Wheel Analyzing the Antecedents of Higher Education Dropout in Education Studies",
        "authors": "Hind Naaman",
        "published": "2021-6-15",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31757/euer.421"
    },
    {
        "id": 4878,
        "title": "Controlled dropout: A different dropout for improving training speed on deep neural network",
        "authors": "ByungSoo Ko, Han-Gyu Kim, Ho-Jin Choi",
        "published": "2017-10",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/smc.2017.8122736"
    },
    {
        "id": 4879,
        "title": "Dropout reasons and associated factors with active dropout in Chinese healthy participants of bioequivalence studies",
        "authors": "",
        "published": "2021-9-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5246/jcps.2021.09.063"
    },
    {
        "id": 4880,
        "title": "Hidden Dropout, Actual Dropout, and Preserving Tradition and Language among Israeli Youth of Ethiopian Origin",
        "authors": "Wovite Worko Mangasto",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "Dropping out from school is a serious problem affecting education systems. This study aims to examine the importance of preserving Ethiopian culture among Israeli high school students of Ethiopian origin and the relationship between preserving this culture and perseverance in formal schooling. Keeping ethnic tradition was examined using two indices: keeping the language and preserving tradition. Although hidden dropout is very common, the related literature is insufficient. Moreover, there are hardly any studies examining dropout among immigrant students in general, and among Israeli immigrants of Ethiopian origin in particular. This study is a pioneering investigation, in both the phenomenon being studied and the target population—the relationship between preserving culture of origin and hidden dropout and actual dropout among adolescent immigrants and children of immigrants of Ethiopian origin in Israel. The current study follows qualitative interviews with members of three research groups: learners, hidden dropouts, and disengaged. The analysis revealed a relationship between the importance assigned to preserving tradition and hidden dropout. In the measures of assigned importance to preserving tradition and language of origin, both hidden dropouts and learners assigned high importance to these variables, as opposed to the disengaged group that assigned less importance to preserving ethnic tradition.",
        "link": "http://dx.doi.org/10.22158/elsr.v4n5p20"
    },
    {
        "id": 4881,
        "title": "Regularization Methods for Cluster Analysis and Principal Components Analysis",
        "authors": "Holmes Finch",
        "published": "2022-2-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9780367809645-6"
    },
    {
        "id": 4882,
        "title": "Developing a definition of early ECT dropout and exploring correlates of dropout",
        "authors": "Yassir Mahgoub, Dallas Hamlin, Andrew Francis",
        "published": "2023-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/j.genhosppsych.2023.08.007"
    },
    {
        "id": 4883,
        "title": "Fairness of In-session Dropout Prediction",
        "authors": "Nathalie Rzepka, Katharina Simbeck, Hans-Georg Müller, Niels Pinkwart",
        "published": "2022",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010962100003182"
    },
    {
        "id": 4884,
        "title": "6 Regularization of Nonlinear Variational Inequalities and Optimization Problems",
        "authors": "",
        "published": "2018-2-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110557350-006"
    },
    {
        "id": 4885,
        "title": "Factors Affecting Female Student Dropout Rates in Hargeisa, Somaliland High Schools",
        "authors": "",
        "published": "2023-8-8",
        "citations": 0,
        "abstract": "Every society's economic development has been based on education. Female student abandonment, on the other hand, constitute a considerable drain and loss on a country's education budget, especially as high school possibilities are predicted to grow. This study investigated various variables that influence the dropout rate of girls from high school in Hargeisa, Somaliland. The study was directed by the following precise goals such as to examine the effects of domestic labor, to assess the influence of parents’ attitudes and to determine the influence community’s perception on girl child education in Hargeisa. The study was carried out using a descriptive research approach. The demographic being targeted included Principles, female students, educators, and parents. Purposive sampling was used to choose respondents from the designated high schools. The sample size was 68 respondents. Questionnaires were chosen as collecting data instruments. Descriptive methods of statistical analysis such as percent and frequencies were used to analyze quantitative data. The data was presented using tables and charts. According to The study results, domestic labor, parent’s attitudes, and community perceptions are resulting in a higher percentage of female high school dropouts. According to findings, 50% the respondents identified working as house helps as a reason for girls dropping out of school. Additionally, 79% of the respondents believed that parents have a responsibility in their daughter's education and dropout, while 63% of the respondents stated that their communities do not prioritize or encourage girls' education. The study suggested that it is essential for girls to have access to basic education as it is their fundamental right as stated in the Somaliland constitution. Additionally, the study recommended conducting further research in secondary schools to identify other challenges that girls face and find effective strategies to help them stay in school and continue their education.",
        "link": "http://dx.doi.org/10.33140/crvv.02.03.02"
    },
    {
        "id": 4886,
        "title": "Dropout",
        "authors": "Ekkehard Nuissl",
        "published": "2023-4-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.35468/wbeb2022-070"
    },
    {
        "id": 4887,
        "title": "A Study on School Dropout Experience of Adolescents -For Dropout Adolescents in H Alternative Education Center",
        "authors": " Eunja Lee,  Song, Jung-Ah",
        "published": "2017-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.15703/kjc.18.5.201710.213"
    },
    {
        "id": 4888,
        "title": "Regularization methodologies in geotechnology",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1090/surv/274/07"
    },
    {
        "id": 4889,
        "title": "Reconstruction and regularization methods",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1090/surv/274/06"
    },
    {
        "id": 4890,
        "title": "REDUCED POWER CONSUMPTION DESIGN IN LOW VOLTAGE DROPOUT REGULATOR",
        "authors": "",
        "published": "2017-3-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.23883/ijrter.2017.3054.y4lxp"
    },
    {
        "id": 4891,
        "title": "Handling Misbehavior",
        "authors": "Howard M. Blonsky",
        "published": "2020-1-6",
        "citations": 0,
        "abstract": "This chapter looks at how punitive disciplinary practices contribute to students dropping out and how positive relationships, rules, and consequences that are fairly, consistently, and equitably enforced have a positive effect on keeping students in school.",
        "link": "http://dx.doi.org/10.1093/oso/9780190090845.003.0006"
    },
    {
        "id": 4892,
        "title": "Grade Repetition and School Dropout",
        "authors": "Sarah Kabay",
        "published": "2021-8-26",
        "citations": 0,
        "abstract": "The issue of grade repetition is relevant for policy and practice in every education system around the world—and yet it is rarely the topic of research in low-income countries. Typically, grade repetition is coupled with a second concern: early school dropout. Together, they are believed represent a constraint upon access to education—preventing children from progressing through school. On the other hand, repetition often intends to emphasize standards and enforce the quality of education. In this way, the issue of grade repetition represents the possible tension between access and quality, but methodological challenges associated with the study of repetition make it difficult to draw any definitive conclusions. This chapter investigates the association between repeating a grade and dropping out of school, the defining theme of existing literature on repetition in low-income countries. Empirical analysis in the sample of Ugandan schools brings to light two other concerns: age of entry into primary school and language of instruction.",
        "link": "http://dx.doi.org/10.1093/oso/9780192896865.003.0005"
    },
    {
        "id": 4893,
        "title": "100% Attendance",
        "authors": "Howard M. Blonsky",
        "published": "2020-1-6",
        "citations": 0,
        "abstract": "This chapter describes how an effective attendance program must be at the forefront of any school’s program if it is to survive as a school, and what the components of an effective attendance program is. It goes back to the first chapter and lists various interventions for each of the six categories of reasons why students drop out of school.",
        "link": "http://dx.doi.org/10.1093/oso/9780190090845.003.0007"
    },
    {
        "id": 4894,
        "title": "Controlled dropout: A different approach to using dropout on deep neural network",
        "authors": " ByungSoo Ko, Han-Gyu Kim,  Kyo-Joong Oh, Ho-Jin Choi",
        "published": "2017-2",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1109/bigcomp.2017.7881693"
    },
    {
        "id": 4895,
        "title": "regularization, n.",
        "authors": "",
        "published": "2023-3-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1093/oed/1001802870"
    },
    {
        "id": 4896,
        "title": "3 Regularization of Ill-Posed Cauchy Problems by Finite Difference Methods",
        "authors": "",
        "published": "2018-2-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1515/9783110557350-003"
    },
    {
        "id": 4897,
        "title": "Variational Regularization for Systems of Inverse Problems",
        "authors": "Richard Huber",
        "published": "2019",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-658-25390-5"
    },
    {
        "id": 4898,
        "title": "Therapeuteneffekte auf Outcome, Sitzungsanzahl und Dropout",
        "authors": "Brian Schwartz",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-658-16472-0"
    },
    {
        "id": 4899,
        "title": "Client Dropout Measure",
        "authors": "Carsten C. Schermuly",
        "published": "2018-5-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1037/t66984-000"
    },
    {
        "id": 4900,
        "title": "Main reasons for dropout for different age groups, 2016",
        "authors": " ",
        "published": "2018-11-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1787/9789264306202-graph51-en"
    }
]