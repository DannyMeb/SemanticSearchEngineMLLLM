[
    {
        "id": 6105,
        "title": "Graph Representation Learning with Graph Transformers in Neural Combinatorial Optimization",
        "authors": "Tianze Wang, Amir H. Payberah, Vladimir Vlassov",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00074"
    },
    {
        "id": 6106,
        "title": "Autoregressive transformers for data-driven spatiotemporal learning of turbulent flows",
        "authors": "Aakash Patil, Jonathan Viquerat, Elie Hachem",
        "published": "2023-12-1",
        "citations": 2,
        "abstract": "A convolutional encoder–decoder-based transformer model is proposed for autoregressively training on spatiotemporal data of turbulent flows. The prediction of future fluid flow fields is based on the previously predicted fluid flow field to ensure long-term predictions without diverging. A combination of convolutional neural networks and transformer architecture is utilized to handle both the spatial and temporal dimensions of the data. To assess the performance of the model, a priori assessments are conducted, and significant agreements are found with the ground truth data. The a posteriori predictions, which are generated after a considerable number of simulation steps, exhibit predicted variances. The autoregressive training and prediction of a posteriori states are deemed crucial steps toward the development of more complex data-driven turbulence models and simulations. The highly nonlinear and chaotic dynamics of turbulent flows can be handled by the proposed model, and accurate predictions over long time horizons can be generated. Overall, the potential of using deep learning techniques to improve the accuracy and efficiency of turbulence modeling and simulation is demonstrated by this approach. The proposed model can be further optimized and extended to incorporate additional physics and boundary conditions, paving the way for more realistic simulations of complex fluid dynamics.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0152212"
    },
    {
        "id": 6107,
        "title": "Offensive Language Detection in Social Media Using Transformers and Importance of Pre-training",
        "authors": "",
        "published": "2023-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18178/ijml.2023.13.2.1133"
    },
    {
        "id": 6108,
        "title": "Sequentia12D: Organizing Center of Skip Connections for Transformers",
        "authors": "Harsh Nilesh Pathak, Randy Paffenroth, Quincy Hershey",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00057"
    },
    {
        "id": 6109,
        "title": "Correcting Wide-Range of Arabic Spelling Mistakes Using Machine Learning and Transformers",
        "authors": "Raghda Diab Hasan, Gheith Ali Abandah",
        "published": "2023-8-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icit58056.2023.10225830"
    },
    {
        "id": 6110,
        "title": "Research on Machine Learning Based Fault Diagnosis Methods for Power Transformers",
        "authors": "Xiaoyu Sun",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccasit58768.2023.10351584"
    },
    {
        "id": 6111,
        "title": "Dynamic Patch Sampling for Efficient Training and Dynamic Inference in Vision Transformers",
        "authors": "Bradley McDanel, Chi Phuong Ngoc Huynh",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00020"
    },
    {
        "id": 6112,
        "title": "INSTRAS: INfrared Spectroscopic imaging-based TRAnsformers for medical image Segmentation",
        "authors": "Hangzheng Lin, Kianoush Falahkheirkhah, Volodymyr Kindratenko, Rohit Bhargava",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2024.100549"
    },
    {
        "id": 6113,
        "title": "Intersection of Machine Learning, Deep Learning and Transformers to Combat Fake News in Kannada Language",
        "authors": "Sanjana S, Shubhankar Kuranagatti, Jayendra Ganesh Devisetti, Richa Sharma, Arti Arya",
        "published": "2023-9-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ic3i59117.2023.10398034"
    },
    {
        "id": 6114,
        "title": "Focused Decoding Enables 3D Anatomical Detection by Transformers",
        "authors": "Bastian Wittmann, Fernando Navarro, Suprosanna Shit, Bjoern Menze",
        "published": "2023-2-27",
        "citations": 3,
        "abstract": "Detection Transformers represent end-to-end object detection approaches based on a Transformer encoder-decoder architecture, exploiting the attention mechanism for global relation modeling. Although Detection Transformers deliver results on par with or even superior to their highly optimized CNN-based counterparts operating on 2D natural images, their success is closely coupled to access to a vast amount of training data. This, however, restricts the feasibility of employing Detection Transformers in the medical domain, as access to annotated data is typically limited. To tackle this issue and facilitate the advent of medical Detection Transformers, we propose a novel Detection Transformer for 3D anatomical structure detection, dubbed Focused Decoder. Focused Decoder leverages information from an anatomical region atlas to simultaneously deploy query anchors and restrict the crossattention’s field of view to regions of interest, which allows for a precise focus on relevant anatomical structures. We evaluate our proposed approach on two publicly available CT datasets and demonstrate that Focused Decoder not only provides strong detection results and thus alleviates the need for a vast amount of annotated data but also exhibits exceptional and highly intuitive explainability of results via attention weights. Our code is available at <a href='https://github.com/bwittmann/transoar'>https://github.com/bwittmann/transoar</a>",
        "keywords": "",
        "link": "http://dx.doi.org/10.59275/j.melba.2023-35e6"
    },
    {
        "id": 6115,
        "title": "AraSentiment: Arabic Sentiment Analysis on Data using Machine Learning, and Transformers",
        "authors": "Diaa Salama AbdElminaam, Abdelrahman Shorim, Mina Antoun, Habiba Mohamed",
        "published": "2023-9-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/miucc58832.2023.10278359"
    },
    {
        "id": 6116,
        "title": "Improving Credibility Detection with Combined Transformers-Based with Machine Learning and Deep Learning Techniques",
        "authors": "Mostafa Saeed, Rana Reda Waly, Mena Hany, Abdelrahman Ezzeldin Nagib, Wael H. Gomaa",
        "published": "2023-10-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/niles59815.2023.10296792"
    },
    {
        "id": 6117,
        "title": "Transformers Faults Prediction Using Machine Learning Approach",
        "authors": "Hanane Hadiki, Fouad Slaoui Hasnaoui, Semaan Georges",
        "published": "2023-7-5",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/actea58025.2023.10194101"
    },
    {
        "id": 6118,
        "title": "BEVTransFusion: LiDAR-Camera Fusion Under Bird’s-Eye-View for 3D Object Detection with Transformers",
        "authors": "Kaiqi Feng, Yu Zhang",
        "published": "2023-8-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/prml59573.2023.10348338"
    },
    {
        "id": 6119,
        "title": "Raw Packet Data Ingestion with Transformers for Malicious Activity Classifications",
        "authors": "Nitin Sharan, Thomas Quig, Eric Goodman, Yung Ryn Choe, Dalton Brucker-Hahn",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00330"
    },
    {
        "id": 6120,
        "title": "A Light Recipe to Train Robust Vision Transformers",
        "authors": "Edoardo Debenedetti, Vikash Sehwag, Prateek Mittal",
        "published": "2023-2",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/satml54575.2023.00024"
    },
    {
        "id": 6121,
        "title": "IoT Edge-based Machine Learning Approach for Detection of Partial Discharge in Power Transformers",
        "authors": "Atish Bagchi, Siva Chandrasekaran",
        "published": "2023-9-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aibthings58340.2023.10292493"
    },
    {
        "id": 6122,
        "title": "Retracted: Software solution for text summarisation using machine learning based Bidirectional Encoder Representations from Transformers algorithm",
        "authors": "Abdulwahid Al Abdulwahid",
        "published": "2023-8",
        "citations": 2,
        "abstract": "AbstractRetraction: [Abdulwahid Al Abdulwahid, Software solution for text summarisation using machine learning based Bidirectional Encoder Representations from Transformers algorithm, IET Software 2023 (https://doi.org/10.1049/sfw2.12098)].The above article from IET Software, published online on 2 February 2023 in Wiley Online Library (wileyonlinelibrary.com), has been retracted by agreement between the Editor‐in‐Chief, Hana Chockler, the Institution of Engineering and Technology (the IET) and John Wiley and Sons Ltd. This article was published as part of a Guest Edited special issue. Following an investigation, the IET and the journal have determined that the article was not reviewed in line with the journal’s peer review standards and there is evidence that the peer review process of the special issue underwent systematic manipulation. Accordingly, we cannot vouch for the integrity or reliability of the content. As such we have taken the decision to retract the article. The authors have been informed of the decision to retract.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/sfw2.12098"
    },
    {
        "id": 6123,
        "title": "Transformers as strong lens detectors - From simulation to surveys",
        "authors": "Hareesh Thuruthipilly, Margherita Grespan, Adam Zadrożny",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0203317"
    },
    {
        "id": 6124,
        "title": "Enhancing Textual Relatedness Assessment with Combined Transformers-Embedding Similarity Techniques and Machine Learning Regressors",
        "authors": "Mena Hany, Mostafa Mohamed Saeed, Rana Reda Waly, Abdelrahman Ezzeldin Nagib, Wael H. Gomaa",
        "published": "2023-7-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/imsa58542.2023.10217726"
    },
    {
        "id": 6125,
        "title": "Power Transformers' Health Index Determination: A Machine Learning Approach Using Clustering Algorithms and Industry-Specific Parameters",
        "authors": "Farhan Hamid, Md Arif Hossen, Mohammed Imamul Hassan Bhuiyan",
        "published": "2023-10-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/r10-htc57504.2023.10461745"
    },
    {
        "id": 6126,
        "title": "Deep Machine Learning-Based Asset Management Approach for Oil- Immersed Power Transformers Using Dissolved Gas Analysis",
        "authors": "Lan Jin, Dowon Kim, Kit Yan Chan, Ahmed Abu-Siada",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2024.3366905"
    },
    {
        "id": 6127,
        "title": "Power transformers fault diagnosis based on a meta-learning approach to kernel extreme learning machine with opposition-based learning sparrow search algorithm",
        "authors": "Song Yu, Weimin Tan, Chengming Zhang, Chao Tang, Lihong Cai, Dong Hu",
        "published": "2023-1-5",
        "citations": 2,
        "abstract": "Considering the power transformers fault diagnosis model has unstable performance and prone to over-fitting, we propose a transformers fault diagnosis model based on a meta-learning approach to kernel extreme learning machine with opposition-based learning sparrow search algorithm optimization (Meta-OSSA-KELM) in this paper. Its learning proceeds in two steps. Firstly, the base-learner KELMs is trained on the disjoint training subset. Then, meta-learner KELM is trained with the hidden codes of training set in base-learner KELMs that have been trained. In this paper, chaotic mapping and opposition-based learning are integrated into Sparrow search algorithm(SSA) and used it to optimize each learner. We simulate this model with measured dissolved gas analysis(DGA) data, the results show that compared with PSO and SSA, opposition-based learning sparrow search algorithm(OSSA) has better global search-ability on the optimization for the proposed model. In addition, compared with Adaboost.M1, BPNN, SVM and KELM, Meta-OSSA-KELM has a higher average accuracy (90.9% vs 78.5%, 74.0%, 76.9%, 76.9%) and a lower standard deviation (1.56×10–2 vs 4.21×10–2, 10.5×10–2, 3.7×10–2, 2.18×10–2) in simulation tests for 30 times. It is shown that the proposed model is a stable and better performance transformers fault diagnosis method.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/jifs-211862"
    },
    {
        "id": 6128,
        "title": "Multimodal Learning With Transformers: A Survey",
        "authors": "Peng Xu, Xiatian Zhu, David A. Clifton",
        "published": "2023",
        "citations": 51,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tpami.2023.3275156"
    },
    {
        "id": 6129,
        "title": "Hyperparameter Tuning On Machine Learning Transformers For Mood Classification In Indonesian Music",
        "authors": "Neny Rosmawarni, Thoyyibah. T, Imam Ahmad, Eka Ardhianto, Dede Handayani, Willis Puspita Sari",
        "published": "2023-11-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icimcis60089.2023.10349008"
    },
    {
        "id": 6130,
        "title": "A Survey of Deep Learning: From Activations to Transformers",
        "authors": "Johannes Schneider, Michalis Vlachos",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012404300003636"
    },
    {
        "id": 6131,
        "title": "Correction to: IntelPVT: intelligent patch-based pyramid vision transformers for object detection and classification",
        "authors": "Divya Nimma, Zhaoxian Zhou",
        "published": "2023-12-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13042-023-02052-9"
    },
    {
        "id": 6132,
        "title": "Patient Phenotyping for Atopic Dermatitis With Transformers and Machine Learning: Algorithm Development and Validation Study",
        "authors": "Andrew Wang, Rachel Fulton, Sy Hwang, David J Margolis, Danielle Mowery",
        "published": "2024-1-26",
        "citations": 0,
        "abstract": "\nBackground\nAtopic dermatitis (AD) is a chronic skin condition that millions of people around the world live with each day. Performing research into identifying the causes and treatment for this disease has great potential to provide benefits for these individuals. However, AD clinical trial recruitment is not a trivial task due to the variance in diagnostic precision and phenotypic definitions leveraged by different clinicians, as well as the time spent finding, recruiting, and enrolling patients by clinicians to become study participants. Thus, there is a need for automatic and effective patient phenotyping for cohort recruitment.\n\n\nObjective\nThis study aims to present an approach for identifying patients whose electronic health records suggest that they may have AD.\n\n\nMethods\nWe created a vectorized representation of each patient and trained various supervised machine learning methods to classify when a patient has AD. Each patient is represented by a vector of either probabilities or binary values, where each value indicates whether they meet a different criteria for AD diagnosis.\n\n\nResults\nThe most accurate AD classifier performed with a class-balanced accuracy of 0.8036, a precision of 0.8400, and a recall of 0.7500 when using XGBoost (Extreme Gradient Boosting).\n\n\nConclusions\nCreating an automated approach for identifying patient cohorts has the potential to accelerate, standardize, and automate the process of patient recruitment for AD studies; therefore, reducing clinician burden and informing the discovery of better treatment options for AD.\n",
        "keywords": "",
        "link": "http://dx.doi.org/10.2196/52200"
    },
    {
        "id": 6133,
        "title": "Machine Learning Applications for Online Partial Discharge Detection, Classification, and Localization in Power Transformers: A Review",
        "authors": "Ameera Tag, Shady S. Refaat, Sayed Mohammad Kameli, Mohammad AlShaikh Saleh",
        "published": "2024-1-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/sgre59715.2024.10428725"
    },
    {
        "id": 6134,
        "title": "IntelPVT: intelligent patch-based pyramid vision transformers for object detection and classification",
        "authors": "Divya Nimma, Zhaoxian Zhou",
        "published": "2024-5",
        "citations": 0,
        "abstract": "AbstractSince the advent of Transformers followed by Vision Transformers (ViTs), enormous success has been achieved by researchers in the field of computer vision and object detection. The difficulty mechanism of splitting images into fixed patches posed a serious challenge in this arena and resulted in loss of useful information at the time of object detection and classification. To overcome the challengers, we propose an innovative Intelligent-based patching mechanism and integrated it seamlessly into the conventional Patch-based ViT framework. The proposed method enables the utilization of patches with flexible sizes to capture and retain essential semantic content from input images and therefore increases the performance compared with conventional methods. Our method was evaluated with three renowned datasets Microsoft Common Objects in Context (MSCOCO-2017), Pascal VOC (Visual Object Classes Challenge) and Cityscapes upon object detection and classification. The experimental results showed promising improvements in specific metrics, particularly in higher confidence thresholds, making it a notable performer in object detection and classification tasks.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13042-023-01996-2"
    },
    {
        "id": 6135,
        "title": "VisFormers—Combining Vision and Transformers for Enhanced Complex Document Classification",
        "authors": "Subhayu Dutta, Subhrangshu Adhikary, Ashutosh Dhar Dwivedi",
        "published": "2024-2-16",
        "citations": 0,
        "abstract": "Complex documents have text, figures, tables, and other elements. The classification of scanned copies of different categories of complex documents like memos, newspapers, letters, and more is essential for rapid digitization. However, this task is very challenging as most scanned complex documents look similar. This is because all documents have similar colors of the page and letters, similar textures for all papers, and very few contrasting features. Several attempts have been made in the state of the art to classify complex documents; however, only a few of these works have addressed the classification of complex documents with similar features, and among these, the performances could be more satisfactory. To overcome this, this paper presents a method to use an optical character reader to extract the texts. It proposes a multi-headed model to combine vision-based transfer learning and natural-language-based Transformers within the same network for simultaneous training for different inputs and optimizers in specific parts of the network. A subset of the Ryers Vision Lab Complex Document Information Processing dataset containing 16 different document classes was used to evaluate the performances. The proposed multi-headed VisFormers network classified the documents with up to 94.2% accuracy, while a regular natural-language-processing-based Transformer network achieved 83%, and vision-based VGG19 transfer learning could achieve only up to 90% accuracy. The model deployment can help sort the scanned copies of various documents into different categories.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/make6010023"
    },
    {
        "id": 6136,
        "title": "On the use of Machine Learning for predictive maintenance of power transformers",
        "authors": "Carla Pacheco, Vagner Paes, Marcelo Carvalho, Felipe Lopes, Gabriel Machado, Alex Garcia, Edmilson Neto, Jefferson Santos, Edward Haeusler, Ana Marotti",
        "published": "2023-12-31",
        "citations": 0,
        "abstract": "This paper focuses on the use of machine learning algorithms to assist predictive maintenance aiming at reducing downtime and maintenance costs associated with power transformers. The paper presents two ML predictive indicators, Chromatographic Assay Indicator (CAI) and Electrical Failure Risk Indicator (EFRI), which use chromatographic and sensors data, respectively. The CAI evaluation showed a significant improvement in predicting failures compared with classical methods, whereas the EFRI tests showed it can be helpful to help maintenance team in identifying potential problems. The proposed solution integrates classical chromatographic analysis techniques with these ML indicators and aims at supporting maintenance specialists in decision-making processes, leading to more efficient maintenance management and reduced costs associated with equipment downtime.",
        "keywords": "",
        "link": "http://dx.doi.org/10.21528/cbic2023-031"
    },
    {
        "id": 6137,
        "title": "Transformers in Machine Learning: Literature Review",
        "authors": "Thoyyibah T, Wasis Haryono, Achmad Udin Zailani, Yan Mitha Djaksana, Neny Rosmawarni, Nunik Destria Arianti",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "In this study, the researcher presents an approach regarding methods in Transformer Machine Learning. Initially, transformers are neural network architectures that are considered as inputs. Transformers are widely used in various studies with various objects. The transformer is one of the deep learning architectures that can be modified. Transformers are also mechanisms that study contextual relationships between words. Transformers are used for text compression in readings. Transformers are used to recognize chemical images with an accuracy rate of 96%. Transformers are used to detect a person's emotions. Transformer to detect emotions in social media conversations, for example, on Facebook with happy, sad, and angry categories. Figure 1 illustrates the encoder and decoder process through the input process and produces output. the purpose of this study is to only review literature from various journals that discuss transformers. This explanation is also done by presenting the subject or dataset, data analysis method, year, and accuracy achieved. By using the methods presented, researchers can conclude results in search of the highest accuracy and opportunities for further research.",
        "keywords": "",
        "link": "http://dx.doi.org/10.29303/jppipa.v9i9.5040"
    },
    {
        "id": 6138,
        "title": "MULTI-DOMAIN MACHINE LEARNING APPROACH OF NAMED ENTITY RECOGNITION FOR ARABIC BOOKING CHATBOT ENGINES USING PRE-TRAINED BIDIRECTIONAL TRANSFORMERS",
        "authors": "Boshra Sadder, Rahma Sadder, Gheith Abandah, Iyad Jafar",
        "published": "2023",
        "citations": 0,
        "abstract": "Chatbots have recently become essential in various fields, ranging from customer service and information acquisition to entertainment. The use of chatbots reduces operational costs and human errors while providing services at any time. This work presents a Named Entity Recognition (NER) model for the Arabic booking chatbot, focusing on booking tickets and appointments across multiple domains. This research paves the way for the development of chatbots that can support multiple booking domains, contributing to the advancement of the Arabic language in this field. We adopt deep machine learning and transfer learning approaches to solve this task. Specifically, we utilized and fine-tuned the AraBERTv0.2 base model to develop the Named Entity Recognition for Booking Queries (NERB) model. Furthermore, we extended it to the Domain-Aware Named Entity Recognition for Booking Queries (DA-NERB) model by adding an additional input for domain type and an embedding layer. The input to our proposed model consists of text sequences of reservation requests, while the output includes sequences of tags representing entities within the input sequences. For training and testing, we synthesized the Arabic Booking Chatbot-Synthetic Dataset (ABC-S Dataset), comprising 76,117 reservation samples that span seven different domains and encompassing 26 categories of named entities.  Additionally, we collected the Arabic Booking Chatbot-Collected Dataset (ABC-C Dataset) from volunteers to evaluate our model using various samples. It's worth noting that these datasets are written in informal Arabic, specifically the Levantine dialect. The proposed model achieves 100% and 96.9% accuracy scores on ABC-S (test set) and ABC-C, respectively. Both the datasets and the code for our model are publicly available to support research in the field of Arabic chatbots.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5455/jjcit.71-1694435791"
    },
    {
        "id": 6139,
        "title": "GA-based weighted ensemble learning for multi-label aerial image classification using convolutional neural networks and vision transformers",
        "authors": "Ming-Hseng Tseng",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "Abstract\nMulti-label classification (MLC) of aerial images is a crucial task in remote sensing image analysis. Traditional image classification methods have limitations in image feature extraction, leading to an increasing use of deep learning models, such as convolutional neural networks (CNN) and vision transformers (ViT). However, the standalone use of these models may have limitations when dealing with MLC. To enhance the generalization performance of MLC of aerial images, this paper combines two CNN and two ViT models, comparing four single deep learning models, a manually weighted ensemble learning method, and a GA-based weighted ensemble method. The experimental results using two public multi-label aerial image datasets show that the classification performance of ViT models is better than CNN models, the traditional weighted ensemble learning model performs better than a single deep learning model, and the GA-based weighted ensemble method performs better than the manually weighted ensemble learning method. The GA-based weighted ensemble method proposed in this study can achieve better MLC performance of aerial images than previous results.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/2632-2153/ad10cf"
    },
    {
        "id": 6140,
        "title": "Cross Attention Transformers for Multi-modal Unsupervised Whole-Body PET Anomaly Detection",
        "authors": "Ashay Patel, Petru-Danial Tudiosu, Walter H.L. Pinaya, Gary Cook, Vicky Goh, Sebastien Ourselin, M. Jorge Cardoso",
        "published": "2023-4-19",
        "citations": 1,
        "abstract": "Cancer is a highly heterogeneous condition that can occur almost anywhere in the human body. [<sup>18</sup>F]fluorodeoxyglucose Positron Emission Tomography (<sup>18</sup>F-FDG PET) is a imaging modality commonly used to detect cancer due to its high sensitivity and clear visualisation of the pattern of metabolic activity. Nonetheless, as cancer is highly heterogeneous, it is challenging to train general-purpose discriminative cancer detection models, with data availability and disease complexity often cited as a limiting factor. Unsupervised learning methods, more specifically anomaly detection models, have been suggested as a putative solution. These models learn a healthy representation of tissue and detect cancer by predicting deviations from the healthy norm, which requires models capable of accurately learning long-range interactions between organs, their imaging patterns, and other abstract features with high levels of expressivity. Such characteristics are suitably satisfied by transformers, which have been shown to generate state-of-the-art results in unsupervised anomaly detection by training on normal data. This work expands upon such approaches by introducing multi-modal conditioning of the transformer via cross-attention i.e. supplying anatomical reference information from paired CT images to aid the PET anomaly detection task. Furthermore, we show the importance and impact of codebook sizing within a Vector Quantized Variational Autoencoder, on the ability of the transformer network to fulfill the task of anomaly detection. Using 294 whole-body PET/CT samples containing various cancer types, we show that our anomaly detection method is robust and capable of achieving accurate cancer localization results even in cases where normal training data is unavailable. In addition, we show the efficacy of this approach on out-of-sample data showcasing the generalizability of this approach even with limited training data. Lastly, we propose to combine model uncertainty with a new kernel density estimation approach, and show that it provides clinically and statistically significant improvements in accuracy and robustness, when compared to the classic residual-based anomaly maps. Overall, a superior performance is demonstrated against leading state-of-the-art alternatives, drawing attention to the potential of these approaches.",
        "keywords": "",
        "link": "http://dx.doi.org/10.59275/j.melba.2023-18c1"
    },
    {
        "id": 6141,
        "title": "Use of Machine Learning Models of the ”Transformers” Type in the Construction of Services in a Gamified Web app.",
        "authors": "C Saavedra Escalante, D Alava Santana, F Moreira Moreira, R Moreira Pico",
        "published": "2023-11-9",
        "citations": 0,
        "abstract": "The purpose of this document is to describe the use of a natural language processing model in the multiplatform system ”Gamivity” by means of a sentence similarity algorithm to offer a personalized experience module based on the conceptual relationship between questions. For the selection process, certain criteria were chosen that will allow several pre-trained models under the “Transformers” architecture for evaluation, later. These criteria were the language with which the model was altered; Python was the programming language used for the implementation. Regarding the evaluation phase of the selected models, the ”Sentence Transformers” library of the Python programming language was used. In addition, a work environment analogous to the module present in the ”Gamivity” system was built, in which the development platform ”Google Colab” was used to test these models. The criteria for choosing the candidate model were based on its effectiveness in relation to questions as well as the computational cost involved while performing the operations in the said model Based on the applied methodology, the model that yielded the best results was ”paraphrase-multilingual- MiniLM-L12-v2,” modified with a large corpus of text in Spanish and 50 other languages, which showed a degree of precision. When it comes to conceptually relating the questions provided it was found to be optimal, having relatively low computational cost when performing these operations.\r\nKeywords: sentence transformers, sentence similarity, relate questions, personalized learning.\r\nResumen\r\nEl presente documento, tiene como propósito el de describir la utilización de un modelo de procesamiento de lenguaje natural en el sistema multiplataforma “Gamivity”, por medio de un algoritmo de similitud de oraciones para ofrecer un módulo de experiencia personalizada a partir de la relación conceptual entre preguntas. Para el proceso de selección, se establecieron ciertos criterios que permitieron elegir varios modelos pre entrenados bajo la arquitectura “Transformers” para su posterior evaluación. Dichos criterios, fueron el idioma con el que fue entrenado el modelo, así como que el lenguaje de programación utilizado para la implementación fuese Python. En lo que concierne a la fase de evaluación de los modelos seleccionados, se hizo uso de la biblioteca “Sentence Transformers” del lenguaje de programación Python, además se construyó un entorno de trabajo análogo al módulo presente en el sistema “Gamivity”, en la plataforma de desarrollo “Google Colab” para poner a prueba dichos modelos, los criterios para la elección del modelo candidato, se resumen en la eficacia a la hora de relacionar preguntas, así como el coste computacional a la hora de realizar las operaciones involucradas en dicho proceso. A partir de la metodología aplicada, el modelo que mejor resultados generó fue “paraphrase-multilingual-MiniLM L12-v2”, entrenado con un gran corpus de texto en español, así como de otros 50 idiomas, el cual mostró un grado de precisión óptimo a la hora de relacionar conceptualmente las preguntas proporcionadas, así como su relativo bajo coste computacional a la hora de efectuar dichas operaciones.\r\nPalabras Clave: sentence transformers, sentence similarity, relacionar preguntas, aprendizaje personalizado.",
        "keywords": "",
        "link": "http://dx.doi.org/10.18502/espoch.v3i1.14466"
    },
    {
        "id": 6142,
        "title": "Machine Learning Based Predictive Maintenance Solution for Transformers",
        "authors": "子祥 王",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.12677/jee.2023.112014"
    },
    {
        "id": 6143,
        "title": "Ubiquitous vision of transformers for person re-identification",
        "authors": "N. Perwaiz, M. Shahzad, M. M. Fraz",
        "published": "2023-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00138-023-01376-4"
    },
    {
        "id": 6144,
        "title": "Machine-learning Love: classifying the equation of state of neutron stars with transformers",
        "authors": "Gonçalo Gonçalves, Márcio Ferreira, João Aveiro, Antonio Onofre, Felipe F. Freitas, Constança Providência, José A. Font",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "Abstract\nThe use of the Audio Spectrogram Transformer (AST) model for gravitational-wave data\n  analysis is investigated. The AST machine-learning model is a convolution-free classifier that\n  captures long-range global dependencies through a purely attention-based mechanism. In this paper\n  a model is applied to a simulated dataset of inspiral gravitational wave signals from binary\n  neutron star coalescences, built from five distinct, cold equations of state (EOS) of nuclear\n  matter. From the analysis of the mass dependence of the tidal deformability parameter for each EOS\n  class it is shown that the AST model achieves a promising performance in correctly classifying the\n  EOS purely from the gravitational wave signals, especially when the component masses of the binary\n  system are in the range [1,1.5]M\n⊙. Furthermore, the generalization ability of the model\n  is investigated by using gravitational-wave signals from a new EOS not used during the training of\n  the model, achieving fairly satisfactory results. Overall, the results, obtained using the\n  simplified setup of noise-free waveforms, show that the AST model, once trained, might allow for\n  the instantaneous inference of the cold nuclear matter EOS directly from the inspiral\n  gravitational-wave signals produced in binary neutron star coalescences",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1475-7516/2023/12/001"
    },
    {
        "id": 6145,
        "title": "Annotating metabolite mass spectra with domain-inspired chemical formula transformers",
        "authors": "Samuel Goldman, Jeremy Wohlwend, Martin Stražar, Guy Haroush, Ramnik J. Xavier, Connor W. Coley",
        "published": "2023-8-17",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s42256-023-00708-3"
    },
    {
        "id": 6146,
        "title": "Variational Mode Decomposition-Based Processing for Detection of Short-Circuited Turns in Transformers Using Vibration Signals and Machine Learning",
        "authors": "David Camarena-Martinez, Jose R. Huerta-Rosales, Juan P. Amezquita-Sanchez, David Granados-Lieberman, Juan C. Olivares-Galvan, Martin Valtierra-Rodriguez",
        "published": "2024-3-26",
        "citations": 0,
        "abstract": "Transformers are key elements in electrical systems. Although they are robust machines, different faults can appear due to their inherent operating conditions, e.g., the presence of different electrical and mechanical stresses. Among the different elements that compound a transformer, the winding is one of the most vulnerable parts, where the damage of turn-to-turn short circuits is one of the most studied faults since low-level damage (i.e., a low number of short-circuited turns—SCTs) can lead to the overall fault of the transformer; therefore, early fault detection has become a fundamental task. In this regard, this paper presents a machine learning-based method to diagnose SCTs in the transformer windings by using their vibrational response. In general, the vibration signals are firstly decomposed by means of the variational mode decomposition method, where a comparison with the empirical mode decomposition (EMD) method and the ensemble empirical mode decomposition (EEMD) method is also carried out. Then, entropy, energy, and kurtosis indices are obtained from each decomposition as fault indicators, where both the combination of features and the dimensionality reduction by using the principal component analysis (PCA) method are analyzed for the global effectiveness improvement and the computational burden reduction. Finally, a pattern recognition algorithm based on artificial neural networks (ANNs) is used for automatic fault detection. The obtained results show 100% effectiveness in detecting seven fault conditions, i.e., 0 (healthy), 5, 10, 15, 20, 25, and 30 SCTs.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics13071215"
    },
    {
        "id": 6147,
        "title": "Material transformers: deep learning language models for generative materials design",
        "authors": "Nihang Fu, Lai Wei, Yuqi Song, Qinyang Li, Rui Xin, Sadman Sadeed Omee, Rongzhi Dong, Edirisuriya M Dilanga Siriwardane, Jianjun Hu",
        "published": "2023-3-1",
        "citations": 3,
        "abstract": "Abstract\nPre-trained transformer language models (LMs) on large unlabeled corpus have produced state-of-the-art results in natural language processing, organic molecule design, and protein sequence generation. However, no such models have been applied to learn the composition patterns for the generative design of material compositions. Here we train a series of seven modern transformer models (GPT, GPT-2, GPT-Neo, GPT-J, BLMM, BART, and RoBERTa) for materials design using the expanded formulas of the ICSD, OQMD, and Materials Projects databases. Six different datasets with/out non-charge-neutral or EB samples are used to benchmark the generative design performances and uncover the biases of modern transformer models for the generative design of materials compositions. Our experiments show that the materials transformers based on causal LMs can generate chemically valid material compositions with as high as 97.61% to be charge neutral and 91.22% to be electronegativity balanced, which has more than six times higher enrichment compared to the baseline pseudo-random sampling algorithm. Our LMs also demonstrate high generation novelty and their potential in new materials discovery is proved by their capability to recover the leave-out materials. We also find that the properties of the generated compositions can be tailored by training the models with selected training sets such as high-bandgap samples. Our experiments also show that different models each have their own preference in terms of the properties of the generated samples and their running time complexity varies a lot. We have applied our materials transformers to discover a set of new materials as validated using density functional theory calculations. All our trained materials transformer models and code can be accessed freely at http://www.github.com/usccolumbia/MTransformer.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/2632-2153/acadcd"
    },
    {
        "id": 6148,
        "title": "How to Use Transformers for Transfer Learning?",
        "authors": "Maryam Ebrahimzadeh, Hamidreza Asadi",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4461376"
    },
    {
        "id": 6149,
        "title": "Review on Machine Learning Strategies for Real-World Engineering Applications",
        "authors": "Abdulazeez Alsajri",
        "published": "2023-1-15",
        "citations": 0,
        "abstract": "As we enter the Industry 5.0 era, enormous volumes of data are being created across digital systems. Machine learning techniques have recently achieved immense success in areas such as intelligent control, decision-making, speech recognition, natural language processing, computer graphics, and computer vision. This despite the significant challenge of analyzing and interpreting massive datasets. Owing to their strong performance, deep learning and machine learning algorithms have become widely deployed across various real-time engineering applications. Developing working knowledge of machine learning is now critical for building automated, smart systems that can process data in domains like healthcare, cybersecurity, and intelligent transportation. There exist multiple strategies in machine learning, including reinforcement learning, semi-supervised learning, unsupervised learning, and supervised learning algorithms. This research provides a comprehensive examination of leveraging machine learning for managing real-time engineering systems, with the goal of augmenting their capabilities and intelligence. It contributes to the understanding of how different machine learning approaches can be applied in real-world use cases like cybersecurity, healthcare, and intelligent transportation. Additionally, it highlights ongoing research objectives and difficulties that machine learning techniques encounter while tackling real-world systems. This research serves both industry professionals and academics as a reference, while technically benchmarking decision-making across different application areas and real-world scenarios.",
        "keywords": "",
        "link": "http://dx.doi.org/10.58496/bjml/2023/001"
    },
    {
        "id": 6150,
        "title": "Federated Machine Learning for Systems Medicine",
        "authors": "Richard Röttger",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14293/gof.23.06"
    },
    {
        "id": 6151,
        "title": "Efficient machine learning-assisted failure analysis method for circuit-level defect prediction",
        "authors": "Joydeep Ghosh",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2024.100537"
    },
    {
        "id": 6152,
        "title": "A machine learning approach for hierarchical classification of software requirements",
        "authors": "Manal Binkhonain, Liping Zhao",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100457"
    },
    {
        "id": 6153,
        "title": "Machine learning for an explainable cost prediction of medical insurance",
        "authors": "Ugochukwu Orji, Elochukwu Ukwandu",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100516"
    },
    {
        "id": 6154,
        "title": "Using machine learning for detecting liquidity risk in banks",
        "authors": "Rweyemamu Ignatius Barongo, Jimmy Tibangayuka Mbelwa",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100511"
    },
    {
        "id": 6155,
        "title": "Machine Learning Operations for Accelerator Control",
        "authors": "Tia Miceli",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2172/1973632"
    },
    {
        "id": 6156,
        "title": "Survey of transformers and towards ensemble learning using transformers for natural language processing",
        "authors": "Hongzhi Zhang, M. Omair Shafiq",
        "published": "2024-2-4",
        "citations": 0,
        "abstract": "AbstractThe transformer model is a famous natural language processing model proposed by Google in 2017. Now, with the extensive development of deep learning, many natural language processing tasks can be solved by deep learning methods. After the BERT model was proposed, many pre-trained models such as the XLNet model, the RoBERTa model, and the ALBERT model were also proposed in the research community. These models perform very well in various natural language processing tasks. In this paper, we describe and compare these well-known models. In addition, we also apply several types of existing and well-known models which are the BERT model, the XLNet model, the RoBERTa model, the GPT2 model, and the ALBERT model to different existing and well-known natural language processing tasks, and analyze each model based on their performance. There are a few papers that comprehensively compare various transformer models. In our paper, we use six types of well-known tasks, such as sentiment analysis, question answering, text generation, text summarization, name entity recognition, and topic modeling tasks to compare the performance of various transformer models. In addition, using the existing models, we also propose ensemble learning models for the different natural language processing tasks. The results show that our ensemble learning models  perform better than a single classifier on specific tasks.\nGraphical Abstract",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s40537-023-00842-0"
    },
    {
        "id": 6157,
        "title": "Editorial: Welcome to APL Machine Learning",
        "authors": "Adnan Mehonic",
        "published": "2023-3-1",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0143646"
    },
    {
        "id": 6158,
        "title": "Tractable Executable Binary Provenance Signalling through Vision Transformers",
        "authors": "Mohammad Nauman",
        "published": "2024-1-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/lt60077.2024.10469044"
    },
    {
        "id": 6159,
        "title": "Reducing MEG interference using machine learning",
        "authors": "Sammi Hamdan, Kyle DuBray, Jordan Treutel, Rajendra Paudyal, Khem Poudel",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100462"
    },
    {
        "id": 6160,
        "title": "Temporal teacher with masked transformers for semi-supervised action proposal generation",
        "authors": "Selen Pehlivan, Jorma Laaksonen",
        "published": "2024-5",
        "citations": 0,
        "abstract": "AbstractBy conditioning on unit-level predictions, anchor-free models for action proposal generation have displayed impressive capabilities, such as having a lightweight architecture. However, task performance depends significantly on the quality of data used in training, and most effective models have relied on human-annotated data. Semi-supervised learning, i.e., jointly training deep neural networks with a labeled dataset as well as an unlabeled dataset, has made significant progress recently. Existing works have either primarily focused on classification tasks, which may require less annotation effort, or considered anchor-based detection models. Inspired by recent advances in semi-supervised methods on anchor-free object detectors, we propose a teacher-student framework for a two-stage action detection pipeline, named Temporal Teacher with Masked Transformers (TTMT), to generate high-quality action proposals based on an anchor-free transformer model. Leveraging consistency learning as one self-training technique, the model jointly trains an anchor-free student model and a gradually progressing teacher counterpart in a mutually beneficial manner. As the core model, we design a Transformer-based anchor-free model to improve effectiveness for temporal evaluation. We integrate bi-directional masks and devise encoder-only Masked Transformers for sequences. Jointly training on boundary locations and various local snippet-based features, our model predicts via the proposed scoring function for generating proposal candidates. Experiments on the THUMOS14 and ActivityNet-1.3 benchmarks demonstrate the effectiveness of our model for temporal proposal generation task.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00138-024-01521-7"
    },
    {
        "id": 6161,
        "title": "Interpretable trading pattern designed for machine learning applications",
        "authors": "Artur Sokolovsky, Luca Arnaboldi, Jaume Bacardit, Thomas Gross",
        "published": "2023-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100448"
    },
    {
        "id": 6162,
        "title": "Erratum to “New interpretation of GNRVⓇ knee arthrometer results for ACL injury diagnosis support using machine learning” [Machine Learning with Applications 13 (2023) 100480]",
        "authors": "Jean Mouchotte, Matthieu LeBerre, Théo Cojean, Henri Robert",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2024.100540"
    },
    {
        "id": 6163,
        "title": "Intrusion Detection System Based on Machine Learning Algorithms:( SVM and Genetic Algorithm)",
        "authors": "Abdulazeez Alsajri, Amani Steiti",
        "published": "2023-1-18",
        "citations": 0,
        "abstract": "The widespread utilization of the internet and computer systems has resulted in notable security concerns, characterized by a surge in intrusions and vulnerabilities. Malicious users manipulate internal systems, resulting in the exploitation of software flaws and default setups.   With the integration of the internet into society, there is an emergence of new risks such as viruses and worms, which highlights the importance of implementing robust security measures.   Intrusion detection systems (IDS) are security technologies utilized to monitor and analyze network traffic or system activity with the purpose of identifying hostile behavior.   This article presents a proposed method for detecting intrusion in network traffic using a hybrid approach, which combines a genetic algorithm and an SVM algorithm.   The model underwent training and testing on the KDDCup99 dataset, with a reduction in features from 42 to 29 using the hybrid approach.   The results demonstrated that throughout the system testing, it exhibited a remarkable accuracy of 0.999. Additionally, it achieved a true positive value of 0.9987 and a false negative rate of 0.012.",
        "keywords": "",
        "link": "http://dx.doi.org/10.58496/bjml/2024/002"
    },
    {
        "id": 6164,
        "title": "Predictive Analysis of NBA Game Outcomes through Machine Learning",
        "authors": "Junwen Wang",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3635638.3635646"
    },
    {
        "id": 6165,
        "title": "Spam detection for Youtube video comments using machine learning approaches",
        "authors": "Andrew S. Xiao, Qilian Liang",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2024.100550"
    },
    {
        "id": 6166,
        "title": "Acknowledgment to the Reviewers of Machine Learning and Knowledge Extraction in 2022",
        "authors": " ",
        "published": "2023-1-18",
        "citations": 0,
        "abstract": "High-quality academic publishing is built on rigorous peer review [...]",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/make5010011"
    },
    {
        "id": 6167,
        "title": "Re-targeting self-supervised transformers for semantic segmentation without training",
        "authors": "Zeyu Yan, Yacheng Tan, Bin Zhu",
        "published": "2023-4-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2678616"
    },
    {
        "id": 6168,
        "title": "Machine learning for sports betting: Should model selection be based on accuracy or calibration?",
        "authors": "Conor Walsh, Alok Joshi",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2024.100539"
    },
    {
        "id": 6169,
        "title": "Higgs event classification using Machine Learning",
        "authors": "Mysha Khan, Pushpa Bhat",
        "published": "2023-8-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2172/1997111"
    },
    {
        "id": 6170,
        "title": "Predicting firm performance and size using machine learning with a Bayesian perspective",
        "authors": "Debdatta Saha, Timothy M. Young, Jessica Thacker",
        "published": "2023-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100453"
    },
    {
        "id": 6171,
        "title": "Research on Diabetes Prediction Based on Machine Learning",
        "authors": "Kaina Zhao, Zhiping Wang",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3635638.3635643"
    },
    {
        "id": 6172,
        "title": "Causal Fairness Analysis: A Causal Toolkit for Fair Machine Learning",
        "authors": "Drago Plečko, Elias Bareinboim",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1561/2200000106"
    },
    {
        "id": 6173,
        "title": "A model-based approach to meta-Reinforcement Learning: Transformers and tree search",
        "authors": "Brieuc Pinon, Raphaël Jungers, Jean-Charles Delvenne",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.14428/esann/2023.es2023-117"
    },
    {
        "id": 6174,
        "title": "Reusability report: Learning the transcriptional grammar in single-cell RNA-sequencing data using transformers",
        "authors": "Sumeer Ahmad Khan, Alberto Maillo, Vincenzo Lagani, Robert Lehmann, Narsis A. Kiani, David Gomez-Cabrero, Jesper Tegner",
        "published": "2023-11-16",
        "citations": 2,
        "abstract": "AbstractThe rise of single-cell genomics is an attractive opportunity for data-hungry machine learning algorithms. The scBERT method, inspired by the success of BERT (‘bidirectional encoder representations from transformers’) in natural language processing, was recently introduced by Yang et al. as a data-driven tool to annotate cell types in single-cell genomics data. Analogous to contextual embedding in BERT, scBERT leverages pretraining and self-attention mechanisms to learn the ‘transcriptional grammar’ of cells. Here we investigate the reusability beyond the original datasets, assessing the generalizability of natural language techniques in single-cell genomics. The degree of imbalance in the cell-type distribution substantially influences the performance of scBERT. Anticipating an increased utilization of transformers, we highlight the necessity to consider data distribution carefully and introduce a subsampling technique to mitigate the influence of an imbalanced distribution. Our analysis serves as a stepping stone towards understanding and optimizing the use of transformers in single-cell genomics.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s42256-023-00757-8"
    },
    {
        "id": 6175,
        "title": "AutonoML: Towards an Integrated Framework for Autonomous Machine Learning",
        "authors": "David Jacob Kedziora, Katarzyna Musial, Bogdan Gabrys",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1561/2200000093"
    },
    {
        "id": 6176,
        "title": "Adapter Incremental Continual Learning of Efficient Audio Spectrogram Transformers",
        "authors": "Nithish Muthuchamy Selvaraj, Xiaobao Guo, Adams Kong, Bingquan Shen, Alex Kot",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-1189"
    },
    {
        "id": 6177,
        "title": "Few-Shot Multimodal Learning for Social Relation Understanding With Supervised Bi-Transformers",
        "authors": "Hanqing Li, Niannian Chen",
        "published": "2023-8-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/swc57546.2023.10448819"
    },
    {
        "id": 6178,
        "title": "Proceedings of 2023 International Conference on Machine Learning and Cybernetics",
        "authors": "",
        "published": "2023-7-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmlc58545.2023.10328008"
    },
    {
        "id": 6179,
        "title": "Automatic Text Classification Model Based on Machine Learning",
        "authors": "",
        "published": "2023-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.38007/ml.2023.040106"
    },
    {
        "id": 6180,
        "title": "Extremely randomised trees machine learning model for electricity theft detection",
        "authors": "Stanley Yaw Appiah, Emmanuel Kofi Akowuah, Valentine Chibueze Ikpo, Albert Dede",
        "published": "2023-6",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100458"
    },
    {
        "id": 6181,
        "title": "DiMS: Distilling Multiple Steps of Iterative Non-Autoregressive Transformers for Machine Translation",
        "authors": "Sajad Norouzi, Rasa Hosseinzadeh, Felipe Perez, Maksims Volkovs",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.542"
    },
    {
        "id": 6182,
        "title": "Optimizing vision transformers for CPU platforms via human-machine collaborative design",
        "authors": "Dong Chen, Hao Shen, Ping Li",
        "published": "2024-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2024.111611"
    },
    {
        "id": 6183,
        "title": "Augmenting roadway safety with machine learning and deep learning: Pothole detection and dimension estimation using in-vehicle technologies",
        "authors": "Cuthbert Ruseruka, Judith Mwakalonge, Gurcan Comert, Saidi Siuhi, Frank Ngeni, Quincy Anderson",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2024.100547"
    },
    {
        "id": 6184,
        "title": "Business Application of Machine Learning Technology in Data Mining",
        "authors": "",
        "published": "2023-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.38007/ml.2023.040104"
    },
    {
        "id": 6185,
        "title": "Machine learning – A new kind of cultural tool? A “recontextualisation” perspective on machine learning + interprofessional learning",
        "authors": "David Guile",
        "published": "2023-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.lcsi.2023.100738"
    },
    {
        "id": 6186,
        "title": "Deepfake Detection with Deep Learning: Convolutional Neural Networks versus Transformers",
        "authors": "Vrizlynn L.L. Thing",
        "published": "2023-7-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/csr57506.2023.10225004"
    },
    {
        "id": 6187,
        "title": "Reviews research on applying machine learning techniques to reduce false positives for network intrusion detection systems",
        "authors": "Kavita Rajora, Nazar salih Abdulhussein",
        "published": "2023-5-28",
        "citations": 0,
        "abstract": "High false positive rates impede the adoption of anomaly detection methods, which have promise for detecting novel cyber threats. Techniques reviewed include Extreme Learning Machine (ELM), Hidden Markov Models (HMM), situation awareness frameworks, ensemble methods, and feature selection algorithms when applied to contemporary benchmark datasets. Findings show combinations of ELM, HMMs, and ensemble classifiers can achieve reduced false positive rates. However, gaps still exist in research using current representative data.",
        "keywords": "",
        "link": "http://dx.doi.org/10.58496/bjml/2023/005"
    },
    {
        "id": 6188,
        "title": "Learned image compression with transformers",
        "authors": "Tianma Shen, Ying Liu",
        "published": "2023-6-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2656516"
    },
    {
        "id": 6189,
        "title": "PSST! Prosodic Speech Segmentation with Transformers",
        "authors": "Nathan Roll, Calbert Graham, Simon Todd",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-1.31"
    },
    {
        "id": 6190,
        "title": "Explainable Machine Learning",
        "authors": "Jochen Garcke, Ribana Roscher",
        "published": "2023-1-17",
        "citations": 1,
        "abstract": "Machine learning methods are widely used in commercial applications and in many scientific areas [...]",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/make5010010"
    },
    {
        "id": 6191,
        "title": "Performance Analysis of Machine Learning Models in Solar Energy Forecasting",
        "authors": "",
        "published": "2023-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18178/ijml.2023.13.3.1140"
    },
    {
        "id": 6192,
        "title": "Exploring Transformers as Compact, Data-efficient Language Models",
        "authors": "Clayton Fields, Casey Kennington",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.conll-1.35"
    },
    {
        "id": 6193,
        "title": "Credit Card Fraud Detection Using Machine Learning",
        "authors": "Vishal Vishal Kumar",
        "published": "2023-4-14",
        "citations": 0,
        "abstract": "To make life better, many mechanisms in modern environment are carried out via the Internet. The economy is expanding yet on the other side, there is a lot of illegal and unauthorised activity carried throughout the country that is seriously hampering that progress. Scam instances, which mislead individuals while also causing economic losses, are just one of them. In realistic conditions, fraud involving credit cards surveillance is the main emphasis of this research. Contrary to earlier eras, the number of credit card scammers is drastically increasing right now. Criminals use various forms of innovation, fake documents, and deception to con others and take their cash. Therefore, it is extremely crucial to discover a solution to these frauds. As technology advances, it becomes harder to keep up with the behaviour and trends of illegal activities. Ai technology, machine learning, as well as other relevant data technology fields have advanced to the point that it is currently feasible to expedite this process and reduce the volume of labour-intensive effort needed in recognizing credit card scams. The user-submitted utilization of credit cards database might be collected initially, then using machine learning approach; it would be split into databases for testing and training purposes. This methodical technique could be utilized by researchers once they have evaluated both the larger information collection and the user-provided available data collection. Enhance the accuracy of the outcome statistics after that. Depending on its exactness and precision, a technology's efficiency is assessed. The results show that XG-Boost and Random Forest techniques have the greatest performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36647/ciml/04.01.a009"
    },
    {
        "id": 6194,
        "title": "Machine Learning in EDA: When and How",
        "authors": "Bei Yu",
        "published": "2023-9-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mlcad58807.2023.10299822"
    },
    {
        "id": 6195,
        "title": "Wind Power Prediction Based on Machine Learning",
        "authors": "Song Liu, Jing Lv",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaml60083.2023.00021"
    },
    {
        "id": 6196,
        "title": "Traditional Machine Learning Models for Building Energy Performance Prediction: A Comparative Research",
        "authors": "Zeyu Wu, Hongyang He",
        "published": "2023-5-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.11648/j.mlr.20230801.11"
    },
    {
        "id": 6197,
        "title": "A big data-handling machine learning model for membrane-based absorber reactors in sorption heat transformers",
        "authors": "Mahyar Ashouri, Naghme Kheyrikoochaksarayee, Callum Chhokar, Amir Shabani, Majid Bahrami",
        "published": "2023-9",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.enconman.2023.117376"
    },
    {
        "id": 6198,
        "title": "Practice and Application of Fusion Machine Learning in Data Analysis",
        "authors": "",
        "published": "2023-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.38007/ml.2023.040101"
    },
    {
        "id": 6199,
        "title": "A Dropout Optimization Algorithm to Prevent Overfitting in Machine Learning",
        "authors": "",
        "published": "2023-3-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.38007/ml.2023.040103"
    },
    {
        "id": 6200,
        "title": "Calibration in machine learning uncertainty quantification: Beyond consistency to target adaptivity",
        "authors": "Pascal Pernot",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "Reliable uncertainty quantification (UQ) in machine learning (ML) regression tasks is becoming the focus of many studies in materials and chemical science. It is now well understood that average calibration is insufficient, and most studies implement additional methods for testing the conditional calibration with respect to uncertainty, i.e., consistency. Consistency is assessed mostly by so-called reliability diagrams. There exists, however, another way beyond average calibration, which is conditional calibration with respect to input features, i.e., adaptivity. In practice, adaptivity is the main concern of the final users of the ML-UQ method, seeking the reliability of predictions and uncertainties for any point in the feature space. This article aims to show that consistency and adaptivity are complementary validation targets and that good consistency does not imply good adaptivity. An integrated validation framework is proposed and illustrated with a representative example.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0174943"
    },
    {
        "id": 6201,
        "title": "Vector Representation of Amharic Idioms for Natural Language Processing Applications Using Machine Learning Approach",
        "authors": "Anduamlak Abebe Fenta",
        "published": "2023-12-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.11648/j.mlr.20230802.11"
    },
    {
        "id": 6202,
        "title": "New interpretation of GNRB® knee arthrometer results for ACL injury diagnosis support using machine learning",
        "authors": "Jean Mouchotte, Matthieu LeBerre, Théo Cojean, Henri Robert",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100480"
    },
    {
        "id": 6203,
        "title": "Application of improved support vector machine model in fault diagnosis and prediction of power transformers",
        "authors": "Yanming Wang",
        "published": "2023-11-9",
        "citations": 0,
        "abstract": "AbstractPower transformers undertake the task of transforming voltage and transmitting electrical energy. Its operating status is directly connected with the stability and safety of the whole power system, and it is very important to judge the operating conditions of power transformers and diagnose fault types. The use of dissolved gas analysis technology in oil can provide preliminary fault diagnosis for transformers. However, with the increasing demand for fault diagnosis accuracy in modern electrical equipment, relying only on dissolved gas analysis technology in oil cannot satisfy the demands. To lift the transformer fault diagnosis accuracy, this study introduces the K‐means algorithm into the model and constructs a high‐precision and fast convergence diagnosis method and a power transformer fault location recognition model. In the example analysis, kernel functions were selected for training five typical gases to obtain the optimal parameters, and their prediction curves and errors were analyzed. Its diagnostic accuracy is 98.4%, and the error in all five gases is within 1 (uL/L). The average error of the improved support vector machine intelligent algorithm is lower than that of the previous model and other prediction methods. By testing the same sample data, the correctness of this method was verified. The significance of improving support vector machines lies in further improving the performance and applicability of the original support vector machine algorithm, providing a basis for future transformer maintenance and contributing to social development and continuous improvement of economic benefits.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/adc2.170"
    },
    {
        "id": 6204,
        "title": "Machine Learning-based Analysis and Prediction of Telecoms Customer Churn",
        "authors": "Liwei Chen",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaml60083.2023.00032"
    },
    {
        "id": 6205,
        "title": "Recession Prediction Using Multiple Machine Learning Methods and Historical Economic Data",
        "authors": "",
        "published": "2023-12-26",
        "citations": 0,
        "abstract": "This study explores the application of machine learning methods to enhance economic recession prediction in the UK and USA, considering the limitations of traditional methods. Various models, including Logistic Regression, Linear Discriminant Analysis, K Nearest Neighbors, Decision Tree Classifier, Gaussian Naive Bayes, Support Vector Classifier, Neural Network, RTC, Long Short-Term Memory, Convolutional Neural Network, and XGBoost, were assessed using economic data since 1900. The UK data encompassed GDP, unemployment rate, inflation, FTSE 100 index, yield curve, and debt levels, while the USA utilized the 50-day simple moving average of 10-year treasury rates minus the 50-day simple moving average of 3-month treasury rates. Performance evaluation involved averaged F1, recall, and accuracy over 100 iterations, with confusion matrices illustrating model predictions against actual events. Long Short-Term Memory excelled with recall and F1 values of 0.96 and 0.97, accurately identifying 11 in 12 Positive USA events. K Nearest Neighbours, Decision Tree Classifier, Random Forest Classifier, and XGBoost demonstrated good results, with recall ranging from 0.99 to 0.75, F1 from 1.0 to 0.69, and correctly identifying 2 in 3 Positive events. Conversely, Logistic Regression, Gaussian Naive Bayes, and Neural Network exhibited less reliable predictions. Linear Discriminant Analysis, Support Vector Classifier, and Convolutional Neural Network were completely inadequate. Using recent data, most models predicted the USA avoiding recession in 2023-24, but the probability increased to 0.5 by mid-2023, then decreased. Logistical Regression, Linear Discriminant Analysis, and Long Short-Term Memory initially predicted no recession, but the probability rapidly increased to between 0.83 and 0.97 by April 2024. While recession avoidance is plausible, modelling indicates an escalating risk. The results underscore the utility of machine learning in recession prediction, emphasizing the importance of diverse training datasets. Algorithmic performance varied, with neural network models, particularly Long Short-Term Memory and XGBoost, proving most accurate. Further enhancements in performance necessitate refining training datasets and leveraging advanced models like Long Short-Term Memory.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33140/amlai.04.02.08"
    },
    {
        "id": 6206,
        "title": "Applying Machine Learning to Vertex Recognition for Neutrino Interactions",
        "authors": "Moreno Eduardo",
        "published": "2023-9-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2172/1998906"
    },
    {
        "id": 6207,
        "title": "Machine Learning for Detecting Malware in PE Files",
        "authors": "Collin Connors, Dilip Sarkar",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00331"
    },
    {
        "id": 6208,
        "title": "Development of Property Prediction Model for Hot Strip Mill Using Machine Learning Algorithms",
        "authors": "Rushikesh Muley, Shanti Priya",
        "published": "2024-1-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.11648/j.mlr.20240901.11"
    },
    {
        "id": 6209,
        "title": "Detecting face masks through embedded machine learning algorithms: A transfer learning approach for affordable microcontrollers",
        "authors": "Mariana B. Azevedo, Thaís de A. de Medeiros, Morsinaldo de A. Medeiros, Ivanovitch Silva, Daniel G. Costa",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100498"
    },
    {
        "id": 6210,
        "title": "A Short Review on Supervised Machine Learning and Deep Learning Techniques in Computer Vision",
        "authors": "Ahmed Adil Nafea, Saeed Amer Alameri, Russel R Majeed, Meaad Ali Khalaf, Mohammed M AL-Ani",
        "published": "2024-2-11",
        "citations": 0,
        "abstract": "In last years, computer vision has shown important advances, mainly using the application of supervised machine learning (ML) and deep learning (DL) techniques. The objective of this review is to show a brief review of the current state of the field of supervised ML and DL techniques, especially on computer vision tasks. This study focuses on the main ideas, advantages, and applications of DL in computer vision and highlights their main concepts and advantages. This study showed the strengths, limitations, and effects of computer vision supervised ML and DL techniques.",
        "keywords": "",
        "link": "http://dx.doi.org/10.58496/bjml/2024/004"
    },
    {
        "id": 6211,
        "title": "Learning Curves Prediction for a Transformers-Based Model",
        "authors": "Francisco Cruz, Mauro Castelli",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "One of the main challenges when training or fine-tuning a machine learning model concerns the number of observations necessary to achieve satisfactory performance. While, in general, more training observations result in a better-performing model, collecting more data can be time-consuming, expensive, or even impossible. For this reason, investigating the relationship between the dataset's size and the performance of a machine learning model is fundamental to deciding, with a certain likelihood, the minimum number of observations that are necessary to ensure a satisfactory-performing model is obtained as a result of the training process. The learning curve represents the relationship between the dataset’s size and the performance of the model and is especially useful when choosing a model for a specific task or planning the annotation work of a dataset. Thus, the purpose of this paper is to find the functions that best fit the learning curves of a Transformers-based model (LayoutLM) when fine-tuned to extract information from invoices. Two new datasets of invoices are made available for such a task. Combined with a third dataset already available online, 22 sub-datasets are defined, and their learning curves are plotted based on cross-validation results. The functions are fit using a non-linear least squares technique. The results show that both a bi-asymptotic and a Morgan-Mercer-Flodin function fit the learning curves extremely well. Also, an empirical relation is presented to predict the learning curve from a single parameter that may be easily obtained in the early stage of the annotation process. Doi: 10.28991/ESJ-2023-07-05-03 Full Text: PDF",
        "keywords": "",
        "link": "http://dx.doi.org/10.28991/esj-2023-07-05-03"
    },
    {
        "id": 6212,
        "title": "Machine Learning in Drug Discovery",
        "authors": "Deepak B",
        "published": "2023-3-21",
        "citations": 0,
        "abstract": "A drug is a substance that when put into the body can change the way the body works and a person's mental state. Discovering the accurate drug plays a vital role in saving precious lives. In traditional drug creation, scientists identify a target in the body and test a large range of chemical compounds on it until they obtain the results. The process gets quicker and more effective with the role of machine learning techniques. This is done by using the huge amount of biological data, medical data, algorithms and statistical models available today. This automation of the drug development process is a key to the current issue of low productivity rate that pharmaceutical companies currently face and helps eliminate the side effects. Machine learning might be a useful tool to further enhance the drug development process.",
        "keywords": "",
        "link": "http://dx.doi.org/10.55529/jaimlnn.32.53.60"
    },
    {
        "id": 6213,
        "title": "BERT Transformers Multitask Learning Sarcasm and Sentiment Classification (BMSS)",
        "authors": "Fateme Molavi, Jamshid Bagherzadeh Mohasefi",
        "published": "2023-11-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccke60553.2023.10326244"
    },
    {
        "id": 6214,
        "title": "A survey of malware detection using deep learning",
        "authors": "Ahmed Bensaoud, Jugal Kalita, Mahmoud Bensaoud",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2024.100546"
    },
    {
        "id": 6215,
        "title": "Using Machine Learning to Classify Information Related to Child Rearing of Infants from Twitter",
        "authors": "",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "It is difficult to obtain necessary information accurately from Social Networking Service (SNS) while raising children, and it is thought that there is a certain demand for the development of a system that presents appropriate information to users according to the child's developmental stage. There are still few examples of research on knowledge extraction that focuses on childcare. This research aims to develop a system that extracts and presents useful knowledge for people who are actually raising children, using texts about childcare posted on Twitter. In many systems, numbers in text data are just strings like words and are normalized to zero or simply ignored. In this paper, we created a set of tweet texts and a set of profiles created according to the developmental stages of infants from \"0-year-old child\" to \"6-year-old child\". For each set, we used ML algorithms such as NB (Naive Bayes), LR (Logistic Regression), ANN (Approximate Nearest Neighbor algorithms search), XGboost, RF (random forest), decision trees, and SVM (Support Vector Machine) to compare with BERT (Bidirectional Encoder Representations from Transformers), a neural language model, to construct a classification model that predicts numbers from \"0\" to \"6\" from sentences. The accuracy rate predicted by the BERT classifier was slightly higher than that of the NB, LR, and ANN, XGboost, and RF, decision trees and SVM classifiers, indicating that the BERT classification method was better.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33140/amlai.04.02.01"
    },
    {
        "id": 6216,
        "title": "Learning stochastic dynamics and predicting emergent behavior using transformers",
        "authors": "Corneel Casert, Isaac Tamblyn, Stephen Whitelam",
        "published": "2024-2-29",
        "citations": 0,
        "abstract": "AbstractWe show that a neural network originally designed for language processing can learn the dynamical rules of a stochastic system by observation of a single dynamical trajectory of the system, and can accurately predict its emergent behavior under conditions not observed during training. We consider a lattice model of active matter undergoing continuous-time Monte Carlo dynamics, simulated at a density at which its steady state comprises small, dispersed clusters. We train a neural network called a transformer on a single trajectory of the model. The transformer, which we show has the capacity to represent dynamical rules that are numerous and nonlocal, learns that the dynamics of this model consists of a small number of processes. Forward-propagated trajectories of the trained transformer, at densities not encountered during training, exhibit motility-induced phase separation and so predict the existence of a nonequilibrium phase transition. Transformers have the flexibility to learn dynamical rules from observation without explicit enumeration of rates or coarse-graining of configuration space, and so the procedure used here can be applied to a wide range of physical systems, including those with large and complex dynamical generators.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41467-024-45629-w"
    },
    {
        "id": 6217,
        "title": "Identification of IoT Devices Using A Multiple Transformers Single Estimator (MTSE) Learning Pipeline",
        "authors": "Gwen Xiao, Rasha Kashef",
        "published": "2023-6-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/aiiot58121.2023.10174596"
    },
    {
        "id": 6218,
        "title": "Erratum to “A BCI system for imagined Bengali speech recognition” [Machine Learning with Applications 13 (2023) 100486]",
        "authors": "Arman Hossain, Kathak Das, Protima Khan, Md. Fazlul Kader",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2024.100532"
    },
    {
        "id": 6219,
        "title": "Our Vision for JGR: Machine Learning and Computation",
        "authors": "E. Camporeale, R. Marino,  ",
        "published": "2024-3",
        "citations": 0,
        "abstract": "AbstractThis editorial introduces the inaugural issue of the Journal of Geophysical Research: Machine Learning and Computation to the scientific community, elucidating the motivations and vision behind its establishment. The landscape of computational tools for geoscientists has undergone a rapid transformation in the last decade, akin to a new scientific revolution challenging the traditional scientific method. The paradigm shift emphasizes the integration of data‐driven methods and the possibility of predicting and/or reproducing the evolution of natural phenomena with computers as the fourth pillar of scientific discovery, sparking debates on trustworthiness, and ethical implications. The data science revolution is fueled by the convergence of advancements, including the big‐data revolution, GPU market expansion, and significant investments in Artificial Intelligence and high performance computing by both institutional and private players. This transformation has given rise to a trans‐disciplinary community that has investigated a wide range of questions under the lens of machine learning (ML) approaches and has generally advanced the field of computational methods within the broader geosciences community, the core of the American Geophysical Union (AGU) membership. Responding to an unmet demand in the existing worldwide editorial offer, the Journal of Geophysical Research: Machine Learning and Computation aims to serve as an intellectual crucible, fostering collaborations across multiple geophysical disciplines and data scientists. The journal welcomes papers with strong methodological developments that allow for geoscience advancements grounded in specific computational and data‐driven methods, leveraging ML as well as innovative computational strategies, and leading to breakthrough discoveries and original scientific outcomes. Authors are encouraged to balance succinctness in introducing methods with a thorough exploration of the novelty of the work proposed and its future applications placing special emphasis on the connection between the data science approach and the scientific outcome, considering a broad readership. Emphasis on result reproducibility aligns with AGU guidance, inviting active participation from the community in shaping geophysical research in the era of machine learning and computation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1029/2024jh000184"
    },
    {
        "id": 6220,
        "title": "Machine Learning in Modern World",
        "authors": "Archana V",
        "published": "2023-1-11",
        "citations": 0,
        "abstract": "Today the world is totally dependent on technology. Machine learning is one of the game changing technologies which is used in our day to day life. Everyday in machine learning technology there are  developed a variety of new products and applications using various machine learning algorithms. Mainly of three types of algorithm. A few applications of machine learning are Product recommendations, Speech recognition etc… The machine learning outcome of the product is perfectly excellent and more accurate. Machine learning is otherwise a subset of Artificial inteligence,it implements several tasks left out any changes. There are many more trending  technologies depending on machine learning, in machine learning the process is more effective and quick and faster than human work efficiency. These trends are done by using huge amounts of  biological data, medical data,algorithms and numerical models available today. It is also becoming very useful in the upcoming future generation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.55529/jaimlnn.31.39.46"
    },
    {
        "id": 6221,
        "title": "Code2Drive: A Code-based Interactive and Educational Driving Environment for Improving the Youth Driving Learning and Training using Machine Learning",
        "authors": "Zihao Lin, Jonathan Sahagun",
        "published": "2023-6-17",
        "citations": 0,
        "abstract": "Serious games are video games designed for more than just pure entertainment purposes [1]. Serious games developers combine traditional game mechanics and the ideas to educate, inform and facilitate social change [2]. These games can be used in many occasions, such as education, healthcare and more. Serious games use simulations and scenarios to provide an immersive and interactive learning experience. They offer an environment to experiment with a variety of solutions to real-world problems, promoting critical thinking and decision making skills. These games can also improve knowledge retention, motivation, and engagement, as they provide instant feedback, rewards, and challenges. This application is like one of the many serious games, it provides a simulation of a highway, its primary purpose is to help to train juvenile’s knowledge on driving and logical thinking, and relax during the playthrough [3].",
        "keywords": "",
        "link": "http://dx.doi.org/10.5121/csit.2023.131014"
    },
    {
        "id": 6222,
        "title": "Relative attributes classification via transformers and rank SVM loss",
        "authors": "Sara Atito Ali Ahmed, Berrin Yanikoglu",
        "published": "2023-6-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2680623"
    },
    {
        "id": 6223,
        "title": "Optimization Algorithm of Big Data Mining Based on Machine Learning Model",
        "authors": "",
        "published": "2023-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.38007/ml.2023.040108"
    },
    {
        "id": 6224,
        "title": "Fall Detection using Machine Learning Techniques and Frequency-Driven Riemannian Manifolds",
        "authors": "Shan Suthaharan",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00035"
    },
    {
        "id": 6225,
        "title": "Deep Ensemble Transformers for Dimensionality Reduction",
        "authors": "Maria Nareklishvili, Marius Geitle",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tnnls.2024.3357621"
    },
    {
        "id": 6226,
        "title": "A comparison of machine learning surrogate models of street-scale flooding in Norfolk, Virginia",
        "authors": "Diana McSpadden, Steven Goldenberg, Binata Roy, Malachi Schram, Jonathan L. Goodall, Heather Richter",
        "published": "2024-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100518"
    },
    {
        "id": 6227,
        "title": "An inpatient fall risk assessment tool: Application of machine learning models on intrinsic and extrinsic risk factors",
        "authors": "Sonia Jahangiri, Masoud Abdollahi, Rasika Patil, Ehsan Rashedi, Nasibeh Azadeh-Fard",
        "published": "2024-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100519"
    },
    {
        "id": 6228,
        "title": "Identifying Michel Electrons in Liquid Argon TPCs Using Machine Learning",
        "authors": "Riya Shah",
        "published": "2023-8-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2172/1996940"
    },
    {
        "id": 6229,
        "title": "Research on Edge Network Topology Optimization Based on Machine Learning",
        "authors": "Boyi Wang, Wei Zhang",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaml60083.2023.00018"
    },
    {
        "id": 6230,
        "title": "Scanning probe microscopy in the age of machine learning",
        "authors": "Md Ashiqur Rahman Laskar, Umberto Celano",
        "published": "2023-12-1",
        "citations": 2,
        "abstract": "Scanning probe microscopy (SPM) has revolutionized our ability to explore the nanoscale world, enabling the imaging, manipulation, and characterization of materials at the atomic and molecular level. However, conventional SPM techniques suffer from limitations, such as slow data acquisition, low signal-to-noise ratio, and complex data analysis. In recent years, the field of machine learning (ML) has emerged as a powerful tool for analyzing complex datasets and extracting meaningful patterns and features in multiple fields. The combination of ML with SPM techniques has the potential to overcome many of the limitations of conventional SPM methods and unlock new opportunities for nanoscale research. In this review article, we will provide an overview of the recent developments in ML-based SPM, including its applications in topography imaging, surface characterization, and secondary imaging modes, such as electrical, spectroscopic, and mechanical datasets. We will also discuss the challenges and opportunities of integrating ML with SPM techniques and highlight the potential impact of this interdisciplinary field on various fields of science and engineering.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0160568"
    },
    {
        "id": 6231,
        "title": "Hybrid deep learning and GARCH-family models for forecasting volatility of cryptocurrencies",
        "authors": "Bahareh Amirshahi, Salim Lahmiri",
        "published": "2023-6",
        "citations": 9,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100465"
    },
    {
        "id": 6232,
        "title": "A novel approach to tele-rehabilitation: Implementing a biofeedback system using machine learning algorithms",
        "authors": "Ali Barzegar Khanghah, Geoff Fernie, Atena Roshan Fekr",
        "published": "2023-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100499"
    },
    {
        "id": 6233,
        "title": "Transfer Learning for Sentiment Classification Using Bidirectional Encoder Representations from Transformers (BERT) Model",
        "authors": "Ali Areshey, Hassan Mathkour",
        "published": "2023-5-31",
        "citations": 3,
        "abstract": "Sentiment is currently one of the most emerging areas of research due to the large amount of web content coming from social networking websites. Sentiment analysis is a crucial process for recommending systems for most people. Generally, the purpose of sentiment analysis is to determine an author’s attitude toward a subject or the overall tone of a document. There is a huge collection of studies that make an effort to predict how useful online reviews will be and have produced conflicting results on the efficacy of different methodologies. Furthermore, many of the current solutions employ manual feature generation and conventional shallow learning methods, which restrict generalization. As a result, the goal of this research is to develop a general approach using transfer learning by applying the “BERT (Bidirectional Encoder Representations from Transformers)”-based model. The efficiency of BERT classification is then evaluated by comparing it with similar machine learning techniques. In the experimental evaluation, the proposed model demonstrated superior performance in terms of outstanding prediction and high accuracy compared to earlier research. Comparative tests conducted on positive and negative Yelp reviews reveal that fine-tuned BERT classification performs better than other approaches. In addition, it is observed that BERT classifiers using batch size and sequence length significantly affect classification performance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23115232"
    },
    {
        "id": 6234,
        "title": "Big Data Analytics Using Machine Learning Techniques for Prediction on Datasets",
        "authors": "Ankit Verma",
        "published": "2023-4-14",
        "citations": 0,
        "abstract": "Data analytics is the process of performing scientific and statistical analysis on raw data in order to transform it into information that can be used for gaining knowledge. A recently emerging trend in feature abstraction is the combination of computational techniques and big data analysis. This requires gaining knowledge from trustworthy data sources, being able to digest information quickly, and making accurate predictions about the future. The primary objective of this study is to locate the machine learning strategies that produce the most accurate prediction by utilising the model that has been proposed. The supervised and unsupervised strategies have been implemented in a variety of different ways using the MapReduce methodology; however, the suggested model makes use of the Apache Spark framework in order to compare the many existing methods. In this study, the emphasis is placed on elucidating the characteristics of datasets in order to conduct the most accurate analysis possible using machine learning techniques. For the purpose of conducting an analysis of the data sets, machine learning methods such as linear regression, decision trees, random forests, and gradient boosting tree algorithms are utilised. In light of the findings of this research, it is possible to draw the conclusion that when the Spark framework is applied on top of Machine Learning methods, the efficiency of the model is improved by a factor of seventy percent in comparison to the MapReduce paradigm.  Keyword : Apache Spark Framework, Big Data Analytics, Machine Learning Algorithms, MapReduce Paradigm.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36647/ciml/04.01.a002"
    },
    {
        "id": 6235,
        "title": "A comprehensive survey on machine learning applications for drilling and blasting in surface mining",
        "authors": "Venkat Munagala, Srikanth Thudumu, Irini Logothetis, Sushil Bhandari, Rajesh Vasa, Kon Mouzakis",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100517"
    },
    {
        "id": 6236,
        "title": "Deep echo state networks in data marketplaces",
        "authors": "Will Serrano",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100456"
    },
    {
        "id": 6237,
        "title": "Fake Review Detection using Machine Learning",
        "authors": "Gayathri M, Y.S.N Siva Teja, K.Ajay Sharma",
        "published": "2023-10-14",
        "citations": 0,
        "abstract": "Online reviews have become increasingly important in the world of e-commerce, serving as a powerful tool to establish a business's reputation and attract new customers. However, the rise of fake reviews has become a growing concern as they can skew the reputation of a business and deceive potential customers. As a result, detecting fake reviews has become a key area of research in recent years.",
        "keywords": "",
        "link": "http://dx.doi.org/10.36647/ciml/04.02.a002"
    },
    {
        "id": 6238,
        "title": "On Dataset Transferability in Active Learning for Transformers",
        "authors": "Fran Jelenić, Josip Jukić, Nina Drobac, Jan Snajder",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18653/v1/2023.findings-acl.144"
    },
    {
        "id": 6239,
        "title": "Erratum to “Automated recognition of individual performers from de-identified video sequences” [Machine Learning with Applications 11 (2023) 100450]",
        "authors": "Zizui Chen, Stephen Czarnuch, Erica Dove, Arlene Astell",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2024.100533"
    },
    {
        "id": 6240,
        "title": "Voice spoofing detection for multiclass attack classification using deep learning",
        "authors": "Jason Boyd, Muhammad Fahim, Oluwafemi Olukoya",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100503"
    },
    {
        "id": 6241,
        "title": "Unsupervised machine learning to analyze corneal tissue surfaces",
        "authors": "Carolin A. Rickert, Fabio Henkel, Oliver Lieleg",
        "published": "2023-12-1",
        "citations": 0,
        "abstract": "Identifying/classifying damage features on soft materials, such as tissues, is much more challenging than on classical, hard materials—but nevertheless important, especially in the field of bio-tribology. For instance, cartilage samples from osteoarthritic patients exhibit surface damage even at early stages of tissue degeneration, and corneal tissues can be damaged by contact lenses when the ocular lubrication system fails. Here, we employ unsupervised machine learning (ML) methods to assess the surface condition of a soft tissue by detecting and classifying different wear morphologies as well as the severity of surface damage they represent. We show that different clustering methods, especially a k-means clustering algorithm, can indeed achieve a—from a material science point of view—meaningful classification of those tissue samples. Our study pinpoints the ability of unsupervised ML models to guide or even replace human decision processes for the analysis of complex surfaces and topographical datasets that—either owing to their complexity or the sample size—exceed the capability of the human brain.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0159502"
    },
    {
        "id": 6242,
        "title": "Design of Computer Complex Spam Filtering System Based on Machine Learning Algorithm",
        "authors": "Yong Yang",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaml60083.2023.00033"
    },
    {
        "id": 6243,
        "title": "Energy-Efficient Predictive Control and Reinforcement Learning Agent for Power Transformers Cooling Systems",
        "authors": "Therence Houngbadji",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/pree57903.2023.10370417"
    },
    {
        "id": 6244,
        "title": "Semi-supervised visual anomaly detection based on convolutional autoencoder and transfer learning",
        "authors": "Jamal Saeedi, Alessandro Giusti",
        "published": "2023-3",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100451"
    },
    {
        "id": 6245,
        "title": "Multilinear multitask learning by transformed tensor singular value decomposition",
        "authors": "Xiongjun Zhang, Jin Wu, Michael K. Ng",
        "published": "2023-9",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100479"
    },
    {
        "id": 6246,
        "title": "A reinforcement learning algorithm for scheduling parallel processors with identical speedup functions",
        "authors": "Farid Ziaei, Mohammad Ranjbar",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100485"
    },
    {
        "id": 6247,
        "title": "Practical Charts for Sizing Neutral Grounding Elements for Machine-Based Distributed Energy Source Step-Up Transformers",
        "authors": "Alexandre Nassif, Julio Romero Aguero, Ming Dong",
        "published": "2023-7-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/pesgm52003.2023.10252969"
    },
    {
        "id": 6248,
        "title": "Advancing magnetic material discovery through machine learning: Unveiling new manganese-based materials",
        "authors": "Yogesh Khatri, Arti Kashyap",
        "published": "2023-12-1",
        "citations": 1,
        "abstract": "Magnetic materials are used in a variety of applications, such as electric generators, speakers, hard drives, MRI machines, etc. Discovery of new magnetic materials with desirable properties is essential for advancement in these applications. In this research article, we describe the development and validation of a machine-learning model to discover new manganese-based stable magnetic materials. The machine learning model is trained on the input data from the Materials Project database to predict the magnetization and formation energy of the materials. New hypothetical structures are made using the substitution method, and the properties are predicted using the machine learning model to select the materials with desired properties. Harnessing the power of machine learning allows us to intelligently narrow down the vast pool of potential candidates. By doing so, we deftly reduce the number of materials that warrant in-depth examination using density functional theory, rendering the task more manageable and efficient. The selected materials, seemingly promising with their magnetic potential, undergo a meticulous validation process using the Vienna Ab initio Simulation Package, grounded in density functional theory. Our results underscore the paramount significance of input data in the efficacy of the machine learning model. Particularly in the realm of magnetic materials, the proper initialization of atomic magnetic spins holds the key to converging upon the true magnetic state of each material.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0171320"
    },
    {
        "id": 6249,
        "title": "Relationship between Risk Factors of Water Conservancy Project Based on Machine Learning Algorithm",
        "authors": "",
        "published": "2023-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.38007/ml.2023.040105"
    },
    {
        "id": 6250,
        "title": "Research on advanced manufacturing process monitoring and fault prediction method based on machine learning",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23977/autml.2023.040311"
    },
    {
        "id": 6251,
        "title": "ANALIZA OPRAVDANOSTI INVESTICIONIH TROŠKOVA NOVIH EFIKASNIH ENERGETSKIH TRANSFROMATORA TOKOM PERIODA NJIHOVE EKSPLOATACIJE",
        "authors": "Petar Marković,  , Ana Pastor, Milan Ćelović, Jelena Ćelović, Miroslav Bosančić,  ,  ,  ,  ",
        "published": "2023",
        "citations": 0,
        "abstract": "Due to the goal of increasing energy efficiency in the power system, engineering solutions are required to reduce power losses. Although the efficiency of power transformers is high, considering that they are one of the most expensive components of the power system and are designed to operate for many years, increasing the efficiency and cost-effectiveness of transformers is necessary. This paper provides a theoretical overview of the types and causes of power losses in power transformers, as well as a review of engineering solutions for their reduction. The analysis focuses on high-voltage power transformers rated at 110 kV, with an overview of energy savings over the average life of a power transformer designed to traditional and modern requirements. The conclusions drawn in this paper can be useful for defining power loss requirements in transformers and for calculating the cost-effectiveness of replacing old, less efficient power transformers with new ones.",
        "keywords": "",
        "link": "http://dx.doi.org/10.46793/cigre36.0241m"
    },
    {
        "id": 6252,
        "title": "Semmeldetector: Application of Machine Learning in Commercial Bakeries",
        "authors": "Thomas H. Schmitt, Maximilian Bundscherer, Tobias Bocklet",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00129"
    },
    {
        "id": 6253,
        "title": "Comparing deep reinforcement learning architectures for autonomous racing",
        "authors": "Benjamin David Evans, Hendrik Willem Jordaan, Herman Arnold Engelbrecht",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100496"
    },
    {
        "id": 6254,
        "title": "2023 IEEE 33rd International Workshop on Machine Learning for Signal Processing (MLSP)",
        "authors": "",
        "published": "2023-9-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/mlsp55844.2023.10285990"
    },
    {
        "id": 6255,
        "title": "A Novel Machine Learning-Based Heart Murmur Detection and Classification using Sound Feature Analysis",
        "authors": "Ram Sivaraman, Joe Xiao",
        "published": "2024-1-27",
        "citations": 0,
        "abstract": "An electrocardiogram (ECG) is a common method used for diagnosis of heart diseases. ECG is not sufficient to detect heart abnormalities early. Heart sound monitoring or phonocardiogram (PCG) is a non-invasive assessment that can be performed during routine exams. PCG can provide valuable details for both heart disorder diagnosis as well as any perioperative cardiac monitoring. Further, heart murmurs are abnormal signals generated by turbulent blood flow in the heart and are closely associated with specific heart diseases.  This paper presents a new machine learning-based heart sounds evaluation for murmurs with high accuracy. A random forest classifier is built using the statistical moments of the coefficients extracted from the heart sounds. The classifier can predict the location of the heart sounds with over 90% accuracy. The random forest classifier has a murmur detection accuracy of over 70% for test dataset and detects with over 98% accuracy for the full dataset.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5121/csit.2024.140206"
    },
    {
        "id": 6256,
        "title": "Optimization Scheme of Accurate Calculation Algorithm of Electric Charge Based on Machine Learning",
        "authors": "",
        "published": "2023-3-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.38007/ml.2023.040102"
    },
    {
        "id": 6257,
        "title": "Simulation of Spectrum Big Data Analysis and Processing Model Based on Machine Learning",
        "authors": "Yanfei Zou",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaml60083.2023.00098"
    },
    {
        "id": 6258,
        "title": "Analyze Organizational Internal Threats Using Machine Learning",
        "authors": "Yinluo Jing, Chunyuan Jiang, Wenhua Chen, Yong Xu",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaml60083.2023.00013"
    },
    {
        "id": 6259,
        "title": "Mathematical Formulation of Learning and Its Computational Complexity for Transformers’ Layers",
        "authors": "Danilo Pietro Pau, Fabrizio Maria Aymone",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "Transformers are the cornerstone of natural language processing and other much more complicated sequential modelling tasks. The training of these models, however, requires an enormous number of computations, with substantial economic and environmental impacts. An accurate estimation of the computational complexity of training would allow us to be aware in advance about the associated latency and energy consumption. Furthermore, with the advent of forward learning workloads, an estimation of the computational complexity of such neural network topologies is required in order to reliably compare backpropagation with these advanced learning procedures. This work describes a mathematical approach, independent from the deployment on a specific target, for estimating the complexity of training a transformer model. Hence, the equations used during backpropagation and forward learning algorithms are derived for each layer and their complexity is expressed in the form of MACCs and FLOPs. By adding all of these together accordingly to their embodiment into a complete topology and the learning rule taken into account, the total complexity of the desired transformer workload can be estimated.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/eng5010003"
    },
    {
        "id": 6260,
        "title": "Molecule generation using transformers and policy gradient reinforcement learning",
        "authors": "Eyal Mazuz, Guy Shtar, Bracha Shapira, Lior Rokach",
        "published": "2023-5-31",
        "citations": 11,
        "abstract": "AbstractGenerating novel valid molecules is often a difficult task, because the vast chemical space relies on the intuition of experienced chemists. In recent years, deep learning models have helped accelerate this process. These advanced models can also help identify suitable molecules for disease treatment. In this paper, we propose Taiga, a transformer-based architecture for the generation of molecules with desired properties. Using a two-stage approach, we first treat the problem as a language modeling task of predicting the next token, using SMILES strings. Then, we use reinforcement learning to optimize molecular properties such as QED. This approach allows our model to learn the underlying rules of chemistry and more easily optimize for molecules with desired properties. Our evaluation of Taiga, which was performed with multiple datasets and tasks, shows that Taiga is comparable to, or even outperforms, state-of-the-art baselines for molecule optimization, with improvements in the QED ranging from 2 to over 20 percent. The improvement was demonstrated both on datasets containing lead molecules and random molecules. We also show that with its two stages, Taiga is capable of generating molecules with higher biological property scores than the same model without reinforcement learning.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-023-35648-w"
    },
    {
        "id": 6261,
        "title": "Monitoring and Diagnostic System for Dry-Type Transformers Using Machine Learning Techniques",
        "authors": "F. G. R. Martins, Y. Lopes, B. W. França, V. H. Ferreira, G. G. Sotelo, A. A. Augusto, A. C. Colombini, A. C. Pinho, M. Mello, M. C. Costa, C. S. C. Nogueira, N. da Silva, A. Melo, A. Soares, D. Fernandes",
        "published": "2023-10-17",
        "citations": 0,
        "abstract": "Power transformers are recognized as high-value assets in substation design, but their susceptibility to various failure modes poses a significant risk of damage and power supply disruptions. Consequently, extensive research has been conducted to develop diagnostic techniques and monitoring methodologies for these devices. This project aims to develop a comprehensive solution comprising hardware and software components for the online diagnosis of dry-type transformers, primarily focusing on the detection of Inter-Turn Short Circuits (ITSC) in conjunction with Partial Discharge (PD) signatures.\nDry-type transformers utilize ambient air as both a cooling and insulating medium. Among its advantages, the most relevant for the oil and gas industry are the lower maintenance costs and the absence of flammable oil, ensuring lower fire risks, which is a critical factor in facilities. As offshore electrical plants grow in complexity, there is an increasing demand for dry-type transformers with higher power ratings. Effectively monitoring the operational condition of such transformers serves as a strategic tool to enhance the reliability, robustness and safety of the electrical system, while potentially reducing overall maintenance expenditures.\nSuch transformers offer notable advantages in terms of safety and reliability [1]. However, they come with higher costs and have lower power and voltage limits. Similar to any other equipment, transformers experience aging as a natural consequence of their operation. Its most significant consequence is the gradual degradation of insulation due to thermal effects and mechanical stresses resulting from electromagnetic interactions between windings turns. Additionally, transformers are susceptible to short-circuits, which induce intense electromechanical stresses in the windings, as well as overvoltages stemming from maneuvers such as line energization or the presence of inductive or capacitive loads. These factors elevate the dielectric stress on insulating materials and connections, potentially surpassing their design limits.",
        "keywords": "",
        "link": "http://dx.doi.org/10.4043/32700-ms"
    },
    {
        "id": 6262,
        "title": "Narrow Band Frequency Response Analysis of Power Transformers with Deep Learning",
        "authors": "Micah Phillip, Arvind Singh, Craig J. Ramlal",
        "published": "2023-9-1",
        "citations": 0,
        "abstract": "Frequency response analysis (FRA) is a standard technique for monitoring the integrity of the mechanical structure of power transformer windings. To date, however, there remains no suitable method for online testing using this technique. One of the main issues that persists is that any hardware designed to measure the frequencies in the range of interest would filter out frequency bands used for assessment by humans. The growth of pattern recognition capabilities in deep learning networks, however, now offers the possibility of detecting different types of faults in a narrow frequency band, which is simply not possible for human experts. This paper explores the ability of a selection of typical networks to classify common faults within different bands. The results show that networks are able to identify faults in bands where humans are unable to find them, which has implications for signal processing and electronics design in developing a system for online monitoring.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/en16176347"
    },
    {
        "id": 6263,
        "title": "CLASSIFICAÇÃO DE TEXTOS: UMA ABORDAGEM COM USO DE MACHINE LEARNING",
        "authors": "Fábio Eder Cardoso, Edberto Ferneda, Leonardo Botega",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "La clasificación de textos ha sido utilizada como base para la organización del conocimiento en las más diversas áreas, ya que permite organizar grupos de categorías para guiar el corte de estos dominios. En la era de la información digital, donde existe una gran cantidad de datos diseminados en entornos de computación en la nube, es necesario el uso de tecnologías informacionales para ayudar en el proceso de clasificación de estos datos. En este contexto, la Ciencia de la Información contribuye en el proceso de producción, organización, transmisión y uso de la información en las más variadas áreas, entre ellas, la ciencia de la computación, matemáticas, inteligencia artificial, entre otras. A través de la tecnología, cuando la información está adecuadamente clasificada, puede ser puesta a disposición de la sociedad de manera más eficaz. El objetivo principal de este artículo es abordar contextos sobre la clasificación de textos con el uso de Machine Learning. Esta investigación es de tipo exploratoria, con un método experimental, y utiliza un enfoque cuantitativo como técnica de análisis de datos. Como resultado, después de utilizar el algoritmo de distancia euclidiana, se estableció una matriz de distancias y un agrupamiento jerárquico, además de una nube de palabras, resaltando expresiones con términos relevantes de los documentos.",
        "keywords": "",
        "link": "http://dx.doi.org/10.62758/re.v3i3.212"
    },
    {
        "id": 6264,
        "title": "Applied machine learning to the determination of biochar hydrogen sulfide adsorption capacity",
        "authors": "Abolhassan Banisheikholeslami, Farhad Qaderi",
        "published": "2023-12-20",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10994-023-06446-2"
    },
    {
        "id": 6265,
        "title": "Design of intelligent dustbin based on machine learning",
        "authors": "xin feng",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2675548"
    },
    {
        "id": 6266,
        "title": "Wind Power Prediction using Transformers: A Federated Learning Approach",
        "authors": "S Shivkumar, Rimjhim Padam Singh, Priyanka Kumar",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icsc60394.2023.10441057"
    },
    {
        "id": 6267,
        "title": "Prediksi Sisa Umur Layan dan Analisa Resiko pada Power Transformer Menggunakan pendekatan Distribusi Weibull dan Risk Priority Number",
        "authors": "Krisnandha Rahardian, Rini Riastuti, Ahmad Zakiyuddin",
        "published": "2024-1-30",
        "citations": 0,
        "abstract": "Transformator adalah peralatan mahal dan krusial dalam sistem transmisi dan distribusi tenaga listrik. Berperan penting dalam menjaga keandalan dan efisiensi pasokan listrik, transformator terus menerima tekanan termal, listrik, mekanik, dan kimia selama operasinya. Oleh karena itu, penilaian penuaan transformator memerlukan parameter komprehensif, terutama karena panas terbuang menjadi faktor pembatas untuk beban maksimum. Kelangsungan operasional transformator menjadi isu penting, dan kegiatan pemantauan, inspeksi, dan pemeliharaan rutin diperlukan untuk mencegah pemadaman yang tidak diinginkan. Dalam penelitian ini, pendekatan dilakukan dengan mendekomposisi transformator menjadi bagian-bagian dan melakukan analisis risiko kuantitatif serta evaluasi prioritas. Lowest Replacable Unit (LRU) dievaluasi menggunakan Weibull++, Life Data Analisis, dan software reliasoft. Hasil analisis menunjukkan bahwa Power Transformer (TR-01) milik PT ABC di Area Integrated Terminal berada dalam kondisi baik dan layak beroperasi. Simulasi Weibull++ menunjukkan umur sisa 275 bulan (22.9 tahun), dengan reliabilitas 86% untuk 4 tahun ke depan dan nilai risk priority number Medium High (3D). Kesimpulan dari analisis ini memberikan keyakinan bahwa transformator berfungsi dengan baik dan dapat diandalkan dalam operasionalnya.",
        "keywords": "",
        "link": "http://dx.doi.org/10.57152/malcom.v4i1.1068"
    },
    {
        "id": 6268,
        "title": "PeptideBERT: A Language Model Based on Transformers for Peptide Property Prediction",
        "authors": "Chakradhar Guntuboina, Adrita Das, Parisa Mollaei, Seongwon Kim, Amir Barati Farimani",
        "published": "2023-11-23",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1021/acs.jpclett.3c02398"
    },
    {
        "id": 6269,
        "title": "Machine Learning and Deep Learning Approaches for Cybersecurity: A Review",
        "authors": "Migul Jain",
        "published": "2023-10-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21275/sr231023115126"
    },
    {
        "id": 6270,
        "title": "Learning Résumé Embeddings with Search Data and Transformers",
        "authors": "Jonathan Hourany, Aaron Zira, Ignacio Avas, Nicolas Thiebaut",
        "published": "2023-10-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/smc53992.2023.10394109"
    },
    {
        "id": 6271,
        "title": "ADA_ViT: Adaptive Drawer Algorithm for Vision Transformers to Detect the Severity of Diabetic Retinopathy",
        "authors": "Prameela M.,  , Kamala Kumari M.,  ",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.37285/bsp.aimlsnlpc2023.08"
    },
    {
        "id": 6272,
        "title": "Effect of Dimensionality Reduction on Uncertainty Quantification in Trustworthy Machine Learning",
        "authors": "Yen-Chen Li, Justin Zhan",
        "published": "2023-7-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmlc58545.2023.10327953"
    },
    {
        "id": 6273,
        "title": "Detecting Arabic Cyberbullying Tweets Using Machine Learning",
        "authors": "Alanoud Mohammed Alduailaj, Aymen Belghith",
        "published": "2023-1-5",
        "citations": 17,
        "abstract": "The advancement of technology has paved the way for a new type of bullying, which often leads to negative stigma in the social setting. Cyberbullying is a cybercrime wherein one individual becomes the target of harassment and hatred. It has recently become more prevalent due to a rise in the usage of social media platforms, and, in some severe situations, it has even led to victims’ suicides. In the literature, several cyberbullying detection methods are proposed, but they are mainly focused on word-based data and user account attributes. Furthermore, most of them are related to the English language. Meanwhile, only a few papers have studied cyberbullying detection in Arabic social media platforms. This paper, therefore, aims to use machine learning in the Arabic language for automatic cyberbullying detection. The proposed mechanism identifies cyberbullying using the Support Vector Machine (SVM) classifier algorithm by using a real dataset obtained from YouTube and Twitter to train and test the classifier. Moreover, we include the Farasa tool to overcome text limitations and improve the detection of bullying attacks.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/make5010003"
    },
    {
        "id": 6274,
        "title": "Deep learning for anomaly detection in log data: A survey",
        "authors": "Max Landauer, Sebastian Onder, Florian Skopik, Markus Wurzenberger",
        "published": "2023-6",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100470"
    },
    {
        "id": 6275,
        "title": "A deep learning knowledge graph neural network for recommender systems",
        "authors": "Gurinder Kaur, Fei Liu, Yi-Ping Phoebe Chen",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.mlwa.2023.100507"
    },
    {
        "id": 6276,
        "title": "Seven Epileptic Seizure Type Classification in Pre-Ictal, Ictal and Inter-Ictal Stages using Machine Learning Techniques",
        "authors": "",
        "published": "2023-1-27",
        "citations": 0,
        "abstract": "Background: Epileptic Seizure type diagnosis is done by clinician based on the symptoms during the episode and the Electroencephalograph (EEG) recording taken during inter-ictal period. But main challenge is, most of the time with the absence of any attendee, the patients are unable to explain the symptoms and not possible to find signature in inter-ictal EEG signal. Aims: This paper aims to analyze epileptic seizure Electro-encephalograph (EEG) signals to diagnose seizure in pre-ictal, ictal and inter-ictal stages and to classify into seven different classes. Methods: Temple University Hospital licensed dataset is used for study. From the seizure corpus, seven seizure types are pre- processed and segregated into pre-ictal, ictal and inter-ictal stages. The multi class classification performed using different machine and deep learning techniques such as K- Nearest Neighbor (KNN) and Random Forest, etc. Results: Multiclass classification of seven type of epileptic seizure with 20 channels, with 80-20 train-test ratio, is achieved 94.7%, 94.7%, 69.0% training accuracy and 94.46%, 94.46% 71.11% test accuracy by weighted KNN for pre-ictal, ictal and inter-ictal stages respectively. Conclusion: Seven epileptic seizure type classification using machine learning techniques carried out with MATLAB software and weighted KNN shows better accuracy comparatively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33140/amlai.04.01.01"
    },
    {
        "id": 6277,
        "title": "Analisis Perbandingan Algoritma Machine Learning untuk Prediksi Stunting pada Anak",
        "authors": "Indah Pratiwi Putri, Terttiaavini Terttiaavini, Nur Arminarahmah",
        "published": "2024-1-15",
        "citations": 0,
        "abstract": "Penelitian ini menyoroti permasalahan serius stunting pada anak-anak, terutama dalam pendataan yang tidak konsisten dan kurangnya informasi akurat dalam evaluasi kondisi tersebut. Tujuannya adalah mengembangkan model Machine Learning (ML)  untuk memprediksi kasus stunting dengan lebih baik. Metode penelitian melibatkan tiga algoritma ML: Naive Bayes, K-Nearest Neighbors, dan Random Forest, dievaluasi berdasarkan Accuracy, Precision, dan recall. Penelitian ini memanfaatkan platform KNIME untuk membantu pengelolaan data yang lebih efisien dan akurat. Hasil evaluasi menunjukkan bahwa Random Forest memiliki akurasi tertinggi (87.75%) dan F1-score (0.922), menunjukkan keseimbangan yang baik antara Precision dan recall. Meskipun demikian, K-Nearest Neighbors menonjol dalam menemukan sebagian besar kasus stunting yang sebenarnya. Kesimpulannya, model Random Forest mungkin menjadi pilihan terbaik untuk mendiagnosis stunting pada anak-anak, karena kombinasi akurasi tinggi dan kemampuan menemukan kasus stunting yang lebih baik dari model lainnya. Penelitian ini memberikan wawasan tentang penerapan ML dalam mendukung deteksi dini stunting, memungkinkan intervensi yang lebih tepat dan cepat bagi anak-anak yang membutuhkan perhatian kesehatan yang lebih intensif.",
        "keywords": "",
        "link": "http://dx.doi.org/10.57152/malcom.v4i1.1078"
    },
    {
        "id": 6278,
        "title": "Impact of High-Dimensional Feature Selection Strategies Based on Machine Learning on Malicious Document Detection",
        "authors": "",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23977/autml.2024.050105"
    },
    {
        "id": 6279,
        "title": "Utilizing Machine Learning Techniques in Predicting Job Viability of Information Technology Program Graduates",
        "authors": "Caesar Jude Clemente",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00253"
    },
    {
        "id": 6280,
        "title": "Analysis and Type Identification of Ancient Glass Relics Based on Machine Learning",
        "authors": "Hongjin Mi, Zijun Guo",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaml60083.2023.00062"
    },
    {
        "id": 6281,
        "title": "Tutorial on Amortized Optimization",
        "authors": "Brandon Amos",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1561/2200000102"
    },
    {
        "id": 6282,
        "title": "Machine Learning based Cryptocurrency Price Prediction using Historical Data and Social Media Sentiment",
        "authors": "Saachin Bhatt, Mustansar Ghazanfar, Mohammad Hossein Amirhosseini",
        "published": "2023-6-17",
        "citations": 2,
        "abstract": "The purpose of this research is to investigate the impact of social media sentiments on predicting the Bitcoin price using machine learning models, with a focus on integrating onchain data and employing a Multi Modal Fusion Model. For conducting the experiments, the crypto market data, on-chain data, and corresponding social media data (Twitter) has been collected from 2014 to 2022 containing over 2000 samples. We trained various models over historical data including K-Nearest Neighbors, Logistic Regression, Gaussian Naive Bayes, Support Vector Machine, Extreme Gradient Boosting and a Multi Modal Fusion. Next, we added Twitter sentiment data to the models, using the Twitter-roBERTa and VADAR models to analyse the sentiments expressed in social media about Bitcoin. We then compared the performance of these models with and without the Twitter sentiment data and found that the inclusion of sentiment feature resulted in consistently better performance, with TwitterRoBERTa-based sentiment giving an average F1 scores of 0.79. The best performing model was an optimised Multi Modal Fusion classifier using Twitter-RoBERTa based sentiment, producing an F1 score of 0.85. This study represents a significant contribution to the field of financial forecasting by demonstrating the potential of social media sentiment analysis, onchain data integration, and the application of a Multi Modal Fusion model to improve the accuracy and robustness of machine learning models for predicting market trends, providing a valuable tool for investors, brokers, and traders seeking to make informed decisions",
        "keywords": "",
        "link": "http://dx.doi.org/10.5121/csit.2023.131001"
    },
    {
        "id": 6283,
        "title": "Truth Seeker of the Largest Social Media Content using Machine Learning Algorithms",
        "authors": "Maysa Khalil, Mohammad Azzeh",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00243"
    },
    {
        "id": 6284,
        "title": "Fourier Series Weight in Quantum Machine Learning",
        "authors": "Parfait Atchade-Adelomou",
        "published": "2024",
        "citations": 0,
        "abstract": "In this work, we aim to confirm the impact of the Fourier series on the quantum machine learning model. We will propose models, tests, and demonstrations to achieve this objective. We designed a quantum machine learning leveraged on the Hamiltonian encoding. With a subtle change, we performed the trigonometric interpolation, binary and multiclass classifier, and a quantum signal processing application. We also proposed a block diagram of determining approximately the Fourier coefficient based on quantum machine learning. We performed and tested all the proposed models using the Pennylane framework.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54364/aaiml.2024.41108"
    },
    {
        "id": 6285,
        "title": "Comment on ‘Physics-based representations for machine learning properties of chemical reactions’",
        "authors": "Kevin A Spiekermann, Thijs Stuyver, Lagnajit Pattanaik, William H Green",
        "published": "2023-12-1",
        "citations": 2,
        "abstract": "Abstract\nIn a recent article in this journal, van Gerwen et al (2022 Mach. Learn.: Sci. Technol.\n3 045005) presented a kernel ridge regression model to predict reaction barrier heights. Here, we comment on the utility of that model and present references and results that contradict several statements made in that article. Our primary interest is to offer a broader perspective by presenting three aspects that are essential for researchers to consider when creating models for chemical kinetics: (1) are the model’s prediction targets and associated errors sufficient for practical applications? (2) Does the model prioritize user-friendly inputs so it is practical for others to integrate into prediction workflows? (3) Does the analysis report performance on both interpolative and more challenging extrapolative data splits so users have a realistic idea of the likely errors in the model’s predictions?",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/2632-2153/acee42"
    },
    {
        "id": 6286,
        "title": "Time-Drift Aware RF Optimization with Machine Learning Techniques",
        "authors": "Ralitsa Sharankova, Kiyomi Seiya, Matilda Mwaniki",
        "published": "2023-5-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2172/1983803"
    },
    {
        "id": 6287,
        "title": "Injury Risk Prediction in Soccer Using Machine Learning",
        "authors": "Brendan Shen, Mikhail Y. Shalaginov, Tingying Helen Zeng",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00317"
    },
    {
        "id": 6288,
        "title": "Identification of defects in a software using machine learning",
        "authors": " Nishthaa, Ruchika Malhotra",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0179183"
    },
    {
        "id": 6289,
        "title": "Machine learning from casual conversation",
        "authors": "Awrad E. Mohammed Ali, Avelino J. Gonzalez",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10994-023-06383-0"
    },
    {
        "id": 6290,
        "title": "Learning Imbalanced Data with Vision Transformers",
        "authors": "Zhengzhuo Xu, Ruikang Liu, Shuo Yang, Zenghao Chai, Chun Yuan",
        "published": "2023-6",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01516"
    },
    {
        "id": 6291,
        "title": "On a machine learning based analysis of online transaction",
        "authors": "Kailai Chen",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2675229"
    },
    {
        "id": 6292,
        "title": "Machine-Learning Prediction of the Computed Band Gaps of Double Perovskite Materials",
        "authors": "Junfei Zhang, Yueqi Li, Xinbo Zhou",
        "published": "2023-1-2",
        "citations": 0,
        "abstract": "Prediction of the electronic structure of functional materials is essential for the engineering of new devices. Conventional electronic structure prediction methods based on density functional theory (DFT) suffer from not only high computational cost, but also limited accuracy arising from the approximations of the exchange-correlation functional. Surrogate methods based on machine learning have garnered much attention as a viable alternative to bypass these limitations, especially in the prediction of solid-state band gaps, which motivated this research study. Herein, we construct a random forest regression model for band gaps of double perovskite materials, using a dataset of 1306 band gaps computed with the GLLBSC (Gritsenko, van Leeuwen, van Lenthe, and Baerends solid correlation) functional. Among the 20 physical features employed, we find that the bulk modulus, superconductivity temperature, and cation electronegativity exhibit the highest importance scores, consistent with the physics of the underlying electronic structure. Using the top 10 features, a model accuracy of 85.6% with a root mean square error of 0.64 eV is obtained, comparable to previous studies. Our results are significant in the sense that they attest to the potential of machine learning regressions for the rapid screening of promising candidate functional materials.",
        "keywords": "",
        "link": "http://dx.doi.org/10.5121/csit.2023.130102"
    },
    {
        "id": 6293,
        "title": "Preface: 3rd International Conference on Machine Learning and Information Processing (ICMLIP-2023)",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/12.0021946"
    },
    {
        "id": 6294,
        "title": "Image Enhancement using Convolution Neural Networks",
        "authors": "Hasan Ahmed Salman, Ali Kalakech",
        "published": "2024-1-25",
        "citations": 0,
        "abstract": "The research presents a comprehensive exploration of the topic of image enhancement using convolutional neural networks (CNN).The research goes deeper into the advanced field of image processing based on the use of neural networks to automatically and efficiently improve the quality and detail of images. The thesis shows that convolutional neural networks are one of the types of deep neural networks, which are specially designed to gain knowledge from big data and extract complex features and patterns found in images. The different layers of the grid are discussed in detail, dealing with images incrementally and extracting different attributes in each layer. The research also highlights CNN's ability to detect, learn and improve important details found in images through convolutions, filtering and data aggregation processes. The proposed CNN image enhancement model was developed and tested on both medical and normal images. The images were optimized using the proposed model and compared with other models. Various quality measures were used to evaluate the results. The results showed that the proposed model can significantly improve the quality of images.",
        "keywords": "",
        "link": "http://dx.doi.org/10.58496/bjml/2024/003"
    },
    {
        "id": 6295,
        "title": "FastDTI: Drug-Target Interaction Prediction using Multimodality and Transformers",
        "authors": "Mathijs Boezer, Maryam Tavakol, Zahra Sajadi",
        "published": "2023-1-23",
        "citations": 4,
        "abstract": "Recent advances in machine learning have proved effective in the application of drug discovery by predicting the drugs that are likely to interact with a protein target of a certain disease, leading to prioritizing drug development and re-purposing efforts. State-of-the-art techniques in Drug-Target Interaction (DTI) prediction are often computationally expensive and can only be trained on small specialized datasets. In this paper, we propose a novel architecture, called FastDTI, utilizing pretrained transformers and graph neural networks in a self-supervised manner on large-scale (unlabeled) data, which additionally allows for embedding of multimodal input representations, for both drug and protein properties. Extensive empirical study demonstrates that our approach outperforms state-of-the-art DTI methods on the KIBA benchmark dataset, while greatly improving the computational complexity of training, about 200 times faster, leading to excellent performance results.",
        "keywords": "",
        "link": "http://dx.doi.org/10.7557/18.6788"
    },
    {
        "id": 6296,
        "title": "Leveraging Business Data Analytics Using Machine Learning Techniques",
        "authors": "",
        "published": "2023-11-15",
        "citations": 0,
        "abstract": "This research explores the utilization of machine learning and deep learning methods for analyzing business data in the context of internal s. With the exponential growth of data in businesses, the extraction of insights and informed decisionmaking based on data has become crucial. Machine learning algorithms offer effective tools for identifying patterns and trends within large datasets. This article delves into various machine learning techniques, including supervised and unsupervised learning, reinforcement learning, and deep learning, and investigates their applications in business data analytics. Notably, machine and deep learning models such as Support Vector Machine (SVM) and Decision Tree (DT) prove highly valuable in analyzing complex datasets such as text and images. Moreover, the paper evaluates the challenges associated with implementing machine learning models, such as data preprocessing, model selection, and performance evaluation. Lastly, the paper concludes by discussing potential future research directions in the field of business data analytics, emphasizing the utilization of machine learning and deep learning techniques within the realm of internal.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33140/ann.07.01.05"
    },
    {
        "id": 6297,
        "title": "Tutorials at <i>APL Machine Learning</i>: To share, to envision, and to help others learn",
        "authors": "Shijing Sun",
        "published": "2023-9-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1063/5.0175787"
    },
    {
        "id": 6298,
        "title": "Offline handwritten mathematical recognition using adversarial learning and transformers",
        "authors": "Ujjwal Thakur, Anuj Sharma",
        "published": "2023-9-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10032-023-00451-w"
    },
    {
        "id": 6299,
        "title": "Learning Expressive Prompting With Residuals for Vision Transformers",
        "authors": "Rajshekhar Das, Yonatan Dukler, Avinash Ravichandran, Ashwin Swaminathan",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.00328"
    },
    {
        "id": 6300,
        "title": "Vision Transformers and Transfer Learning Approaches for Arabic Sign Language Recognition",
        "authors": "Nojood M. Alharthi, Salha M. Alzahrani",
        "published": "2023-10-24",
        "citations": 2,
        "abstract": "Sign languages are complex, but there are ongoing research efforts in engineering and data science to recognize, understand, and utilize them in real-time applications. Arabic sign language recognition (ArSL) has been examined and applied using various traditional and intelligent methods. However, there have been limited attempts to enhance this process by utilizing pretrained models and large-sized vision transformers designed for image classification tasks. This study aimed to create robust transfer learning models trained on a dataset of 54,049 images depicting 32 alphabets from an ArSL dataset. The goal was to accurately classify these images into their corresponding Arabic alphabets. This study included two methodological parts. The first one was the transfer learning approach, wherein we utilized various pretrained models namely MobileNet, Xception, Inception, InceptionResNet, DenseNet, and BiT, and two vision transformers namely ViT, and Swin. We evaluated different variants from base-sized to large-sized pretrained models and vision transformers with weights initialized from the ImageNet dataset or otherwise randomly. The second part was the deep learning approach using convolutional neural networks (CNNs), wherein several CNN architectures were trained from scratch to be compared with the transfer learning approach. The proposed methods were evaluated using the accuracy, AUC, precision, recall, F1 and loss metrics. The transfer learning approach consistently performed well on the ArSL dataset and outperformed other CNN models. ResNet and InceptionResNet obtained a comparably high performance of 98%. By combining the concepts of transformer-based architecture and pretraining, ViT and Swin leveraged the strengths of both architectures and reduced the number of parameters required for training, making them more efficient and stable than other models and existing studies for ArSL classification. This demonstrates the effectiveness and robustness of using transfer learning with vision transformers for sign language recognition for other low-resourced languages.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app132111625"
    },
    {
        "id": 6301,
        "title": "Emotion Classification using Generative Pre-trained Embedding and Machine Learning",
        "authors": "Geeta Pattun, Pradeep Kumar",
        "published": "2023-12-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmlant59547.2023.10372980"
    },
    {
        "id": 6302,
        "title": "Overview of Neural Networks",
        "authors": "Maad M. Mijwel, Adam Esen, Aysar Shamil",
        "published": "2023-8-11",
        "citations": 0,
        "abstract": "Since it was confirmed and verified that the human nervous system consists of individual cells, which were later called neurons, and it was discovered that these cells connect with each other to form an extensive communication network, a large number of possibilities have been opened for application in multiple disciplines in areas of knowledge. Neural Networks are created to perform tasks such as pattern recognition, classification, regression, and many other functions that serve humans and are an essential component in the field of machine learning and artificial intelligence. In computer science, progress has been made, and computers are supposed to learn how to solve problems like that of the human brain. Through pre-established examples, the computer must be able to provide solutions to issues that are like those presented during training. This article overviews neural networks and their application in developing computer systems.",
        "keywords": "",
        "link": "http://dx.doi.org/10.58496/bjml/2023/008"
    },
    {
        "id": 6303,
        "title": "An application of machine learning in real estate economics: What extra benefits could machine learning techniques provide?",
        "authors": "",
        "published": "2023-8-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.36334/modsim.2023.chan39"
    },
    {
        "id": 6304,
        "title": "Security for Distributed Machine Learning",
        "authors": "Laurent Gomez, Tianchi Yu, Patrick Duverger",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0012137700003555"
    }
]