[
    {
        "id": 5801,
        "title": "Ensemble Learning",
        "authors": "Yun Yang",
        "published": "2017",
        "citations": 25,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811654-8.00004-x"
    },
    {
        "id": 5802,
        "title": "Unsupervised Learning via an Iteratively Constructed Clustering Ensemble",
        "authors": "Yun Yang",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811654-8.00006-3"
    },
    {
        "id": 5803,
        "title": "Introduction to Ensemble Learning",
        "authors": "",
        "published": "2019-3",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811201967_0003"
    },
    {
        "id": 5804,
        "title": "Fraud Classification on Bank Accounts using Ensemble Learning Approach",
        "authors": "Alfiah Maghfiroh, Yulian Findawati",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21070/ups.733"
    },
    {
        "id": 5805,
        "title": "Ensemble Machine Learning Model for Software Defect Prediction",
        "authors": "",
        "published": "2021-3-25",
        "citations": 3,
        "abstract": "Software defect prediction is a significant activity in every software firm. It helps in producing quality software by reliable defect prediction, defect elimination, and prediction of modules that are susceptible to defect. Several researchers have proposed different software prediction approaches in the past. However, these conventional software defect predictions are prone to low classification accuracy, time-consuming, and tasking. This paper aims to develop a novel multi-model ensemble machine-learning for software defect prediction. The ensemble technique can reduce inconsistency among training and test datasets and eliminate bias in the training and testing phase of the model, thereby overcoming the downsides that have characterized the existing techniques used for the prediction of a software defect. To address these shortcomings, this paper proposes a new ensemble machine-learning model for software defect prediction using k Nearest Neighbour (kNN), Generalized Linear Model with Elastic Net Regularization (GLMNet), and Linear Discriminant Analysis (LDA) with Random Forest as base learner. Experiments were conducted using the proposed model on CM1, JM1, KC3, and PC3 datasets from the NASA PROMISE repository using the RStudio simulation tool. The ensemble technique achieved 87.69% for CM1 dataset, 81.11% for JM1 dataset, 90.70% for PC3 dataset, and 94.74% for KC3 dataset. The performance of the proposed system was compared with that of other existing techniques in literature in terms of AUC. The ensemble technique achieved 87%, which is better than the other seven state-of-the-art techniques under consideration. On average, the proposed model achieved an overall prediction accuracy of 88.56% for all datasets used for experiments. The results demonstrated that the ensemble model succeeded in effectively predicting the defects in PROMISE datasets that are notorious for their noisy features and high dimensions. This shows that ensemble machine learning is promising and the future of software defect prediction.",
        "link": "http://dx.doi.org/10.33140/amlai.02.01.03"
    },
    {
        "id": 5806,
        "title": "Modeling Early-stage Diabetes Mellitus using an Ensemble Learning Approach",
        "authors": "Syaikhina Usabili, Uce Indahyanti",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21070/ups.4219"
    },
    {
        "id": 5807,
        "title": "Ensemble Learning",
        "authors": "",
        "published": "2021-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1017/9781108938051.012"
    },
    {
        "id": 5808,
        "title": "Ensemble Learning",
        "authors": "Taeho Jo",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-32879-4_4"
    },
    {
        "id": 5809,
        "title": "Ensemble Learning",
        "authors": "Zhi-Hua Zhou",
        "published": "2021",
        "citations": 115,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-981-15-1967-3_8"
    },
    {
        "id": 5810,
        "title": "Using Ensemble Learning Libraries",
        "authors": "Alok Kumar, Mayank Jain",
        "published": "2020",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4842-5940-5_5"
    },
    {
        "id": 5811,
        "title": "Multistrategy Ensemble Learning",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_574"
    },
    {
        "id": 5812,
        "title": "Ensemble Diversity",
        "authors": "",
        "published": "2019-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811201967_0006"
    },
    {
        "id": 5813,
        "title": "Ensemble Classification",
        "authors": "",
        "published": "2019-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811201967_0004"
    },
    {
        "id": 5814,
        "title": "Deep Learning Stack Ensemble to Detect Sarcasm in News Headline Dataset",
        "authors": "Siti Nur Haliza, Mochammad Alfan Rosid",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.21070/ups.689"
    },
    {
        "id": 5815,
        "title": "Ensemble Selection",
        "authors": "",
        "published": "2019-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811201967_0007"
    },
    {
        "id": 5816,
        "title": "Mathematical Foundation for Ensemble Machine Learning and Ensemble Portfolio Analysis",
        "authors": "eugene pinsky",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.3243974"
    },
    {
        "id": 5817,
        "title": "Ensemble Learning",
        "authors": "Taeho Jo",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-030-65900-4_13"
    },
    {
        "id": 5818,
        "title": "Introduction to Machine Learning",
        "authors": "",
        "published": "2019-3",
        "citations": 4,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811201967_0001"
    },
    {
        "id": 5819,
        "title": "Ensemble Learning",
        "authors": "Gavin Brown",
        "published": "2017",
        "citations": 16,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-1-4899-7687-1_252"
    },
    {
        "id": 5820,
        "title": "High-Dimensional Ensemble Learning Classification: An Ensemble Learning Classification Algorithm Based on High-Dimensional Feature Space Reconstruction",
        "authors": "Miao Zhao, Ning Ye",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "When performing classification tasks on high-dimensional data, traditional machine learning algorithms often fail to filter out valid information in the features adequately, leading to low levels of classification accuracy. Therefore, this paper explores the high-dimensional data from both the data feature dimension and the model ensemble dimension. We propose a high-dimensional ensemble learning classification algorithm focusing on feature space reconstruction and classifier ensemble, called the HDELC algorithm. First, the algorithm considers feature space reconstruction and then generates a feature space reconstruction matrix. It effectively achieves feature selection and reconstruction for high-dimensional data. An optimal feature space is generated for the subsequent ensemble of the classifier, which enhances the representativeness of the feature space. Second, we recursively determine the number of classifiers and the number of feature subspaces in the ensemble model. Different classifiers in the ensemble system are assigned mutually exclusive non-intersecting feature subspaces for model training. The experimental results show that the HDELC algorithm has advantages compared with most high-dimensional datasets due to its more efficient feature space ensemble capability and relatively reliable ensemble operation performance. The HDELC algorithm makes it possible to solve the classification problem for high-dimensional data effectively and has vital research and application value.",
        "link": "http://dx.doi.org/10.3390/app14051956"
    },
    {
        "id": 5821,
        "title": "Temporal Data Mining Via Unsupervised Ensemble Learning",
        "authors": "",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/c2016-0-01428-6"
    },
    {
        "id": 5822,
        "title": "Deep Ensemble Learning-based Smart Teaching",
        "authors": "Rajdeep Chatterjee",
        "published": "No Date",
        "citations": 1,
        "abstract": "In the traditional system, a teacher observes its students' attention levels from his/her experience. To date, there is no system that automatically tracks the attention level of the students in a class in real-time (that is while the lecturer delivering his/her lectures or student watching tutorials). This paper aims at improving the lecture delivery mechanism in real-time in a classroom. On the other hand, our proposed system periodically will not only monitor the learning behaviour of the whole class but also track the attentiveness of each student. The proposed system is not meant to identify the non-attentive students and punish them. Rather contrary to the punishment based mechanism, it introduces a  counseling based mechanism. This deep learning-based real-time face monitoring system will allow lecturers to improvise his/her delivery either through bringing diversity in the class contents or personal care to those non-attentive students. The concept of deep ensemble learning has been used with convolutional neural networks to predict the percentage of openness of eyes. Separately, the positive facial postures of a student are also recognized using our model of convolutional neural network. Finally, the net learning behaviour of the student has been computed by a weighted average of these two features (that are, eyes openness and facial postures).",
        "link": "http://dx.doi.org/10.35543/osf.io/re94u"
    },
    {
        "id": 5823,
        "title": "HMM-Based Hybrid Meta-Clustering in Association With Ensemble Technique",
        "authors": "Yun Yang",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811654-8.00005-1"
    },
    {
        "id": 5824,
        "title": "Numerical Weather Forecast Post-processing with Ensemble Learning and Transfer Learning",
        "authors": "Yuwen Chen, Xiaomeng Huang",
        "published": "No Date",
        "citations": 1,
        "abstract": "\n        &lt;p&gt;Statistical approaches have been used for decades to augment and interpret numerical weather forecasts. The emergence of artificial intelligence algorithms has provided new perspectives in this field, but the extension of algorithms developed for station networks with rich historical records to include newly-built stations remains a challenge. To address this, we design a framework that combines two machine learning methods: temperature prediction based on ensemble of multiple machine learning models and transfer learning for newly-built stations. We then evaluate this framework by post-processing temperature forecasts provided by a leading weather forecast center and observations from 301 weather stations in China. Station clustering reduces forecast errors by 24.4% averagely, while transfer learning improves predictions by 13.4% for recently-built sites with only one year of data available. This work demonstrates how ensemble learning and transfer learning can be used to supplement weather forecasting.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;\n        ",
        "link": "http://dx.doi.org/10.5194/egusphere-egu2020-3885"
    },
    {
        "id": 5825,
        "title": "Copyright",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811654-8.12001-9"
    },
    {
        "id": 5826,
        "title": "Review for \"An interpretable ensemble method for deep representation learning\"",
        "authors": "",
        "published": "2023-4-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/eng2.12725/v1/review1"
    },
    {
        "id": 5827,
        "title": "Ensemble Learning",
        "authors": "Amin Zollanvari",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-33342-2_8"
    },
    {
        "id": 5828,
        "title": "Ensemble learning from ensemble docking: revisiting the optimum ensemble size problem",
        "authors": "Sara Mohammadi, Zahra Narimani, Mitra Ashouri, Rohoullah Firouzi, Mohammad Hossein Karimi‐Jafari",
        "published": "2022-1-10",
        "citations": 16,
        "abstract": "AbstractDespite considerable advances obtained by applying machine learning approaches in protein–ligand affinity predictions, the incorporation of receptor flexibility has remained an important bottleneck. While ensemble docking has been used widely as a solution to this problem, the optimum choice of receptor conformations is still an open question considering the issues related to the computational cost and false positive pose predictions. Here, a combination of ensemble learning and ensemble docking is suggested to rank different conformations of the target protein in light of their importance for the final accuracy of the model. Available X-ray structures of cyclin-dependent kinase 2 (CDK2) in complex with different ligands are used as an initial receptor ensemble, and its redundancy is removed through a graph-based redundancy removal, which is shown to be more efficient and less subjective than clustering-based representative selection methods. A set of ligands with available experimental affinity are docked to this nonredundant receptor ensemble, and the energetic features of the best scored poses are used in an ensemble learning procedure based on the random forest method. The importance of receptors is obtained through feature selection measures, and it is shown that a few of the most important conformations are sufficient to reach 1 kcal/mol accuracy in affinity prediction with considerable improvement of the early enrichment power of the models compared to the different ensemble docking without learning strategies. A clear strategy has been provided in which machine learning selects the most important experimental conformers of the receptor among a large set of protein–ligand complexes while simultaneously maintaining the final accuracy of affinity predictions at the highest level possible for available data. Our results could be informative for future attempts to design receptor-specific docking-rescoring strategies.",
        "link": "http://dx.doi.org/10.1038/s41598-021-04448-5"
    },
    {
        "id": 5829,
        "title": "Acknowledgments",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811654-8.04001-x"
    },
    {
        "id": 5830,
        "title": "Deep learning for ensemble forecasting",
        "authors": "Rüdiger Brecht, Alexander Bihlo",
        "published": "No Date",
        "citations": 0,
        "abstract": "&lt;div&gt;Ensemble prediction systems are an invaluable tool for weather prediction. Practically, ensemble predictions are obtained by&amp;#160;running several&amp;#160;perturbed numerical simulations. However, these systems are associated with a high computational cost and often involve statistical post-processing steps to improve their qualities.&lt;/div&gt;&lt;div&gt;Here we propose to use a deep-learning-based algorithm to learn the statistical properties of a given ensemble prediction system, such that this&amp;#160;system will not be needed&amp;#160;to simulate&amp;#160;future ensemble forecasts. This way, the high computational costs of the ensemble prediction&amp;#160;system can be avoided&amp;#160;while still obtaining&amp;#160;the statistical properties from a single deterministic forecast.&amp;#160;&lt;span&gt;We show preliminary results where we demonstrate the ensemble &lt;/span&gt;&lt;span&gt;prediction&lt;/span&gt;&lt;span&gt; properties for a shallow water unstable jet simulation on the sphere.&amp;#160;&lt;/span&gt;&lt;/div&gt;",
        "link": "http://dx.doi.org/10.5194/egusphere-egu22-2058"
    },
    {
        "id": 5831,
        "title": "Review for \"An interpretable ensemble method for deep representation learning\"",
        "authors": "",
        "published": "2023-6-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/eng2.12725/v2/review1"
    },
    {
        "id": 5832,
        "title": "Temporal Data Clustering via a Weighted Clustering Ensemble With Different Representations",
        "authors": "Yun Yang",
        "published": "2017",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811654-8.00007-5"
    },
    {
        "id": 5833,
        "title": "Uncertainty research of landslide susceptibility mapping based deep ensemble learning: different basic classifier and ensemble strategy",
        "authors": "Taorui Zeng, Kunlong Yin, Liyang Wu",
        "published": "No Date",
        "citations": 0,
        "abstract": "The Jurassic red-strata of the Three Gorges Reservoir Area in China is interbedded of thick siltstone and thin sandy-mudstone and contains many clay minerals, such as montmorillonite and illite, which is water sensitive, weak and expansive, and easy to decompose by water weathering. In particular, due to the seasonal rainfall, development of settlements, and large-scale reservoir impoundment, many slow-moving landslides (e.g., deep rotation and planar landslides) often occur. Notwithstanding, the reconnaissance, updating, and mapping of kinematic features of township area landslides lack the appropriate attention of the government and researchers. Landslide susceptibility mapping is necessary prerequisites for landslide hazard and risk assessment. But a certain proportion of unpredictability is always closely related to modeling. The main objective of this work is to introduce deep ensemble learning into landslide susceptibility assessment to improve the performance of maximum likelihood models. Therefore, the current model construction has focused on three basic classifiers: decision tree, support vector machine, multi-layer perceptron neural network model, and two homogeneous ensemble models: random forest and extreme gradient boosting. Two prominent ensemble techniques&#8212;homogeneous/heterogeneous model ensemble and bagging, boosting, stacking ensemble strategy&#8212;were applied to implement the deep ensemble learning. Then, thirteen influencing factors were prepared as predictors and dependent variables. The landslide susceptibility maps were validated by the area under the receiver operating characteristic curve. The results of validation showed that the ensemble model shows that the ROC/AUC value is higher than 0.9, which is improved compared with the basic classifiers. Deep ensemble learning focuses more on detecting the landslide susceptibility area with the highest probability of occurrence. The Stacking based RF-XGBoost model obtained the best verification score (AUC=0.955). The comparison between the susceptibility map and landslide inventory data is encouraging as most of the recorded landslide pixels (about 83.3%) are at a high susceptibility level. Besides, from the information gain rate, we found that the Yangtze River and human engineering activities mainly affect the results, which is consistent with the current situation in the study area. The research results in the township-level landslide susceptibility map can also be extended to other urban and rural areas affected by landslides to reduce the landslide disaster risk and formulate further development strategies.",
        "link": "http://dx.doi.org/10.5194/egusphere-egu23-2445"
    },
    {
        "id": 5834,
        "title": "Network Intrusion Detection System Using Ensemble Learning Approaches",
        "authors": "Salam Allawi Hussein, Alyaa Abduljawad Mahmood, Emaan Oudah Oraby",
        "published": "2021-10-30",
        "citations": 1,
        "abstract": "To mitigate modern network intruders in a rapidly growing and fast pattern changing network traffic data, single classifier is not sufficient. In this study Chi-Square feature selection technique is used to select the most important features of network traffic data, then AdaBoost, Random Forest (RF), and XGBoost ensemble classifiers were used to classify data based on binary-classes and multi-classes. The aim of this study is to improve detection rate accuracy for every individual attack types and all types of attacks, which will help us to identify attacks and particular category of attacks. The proposed method is evaluated using k-fold cross validation, and the experimental results of all the three classifiers with and without feature selection are compared together. We used two different datasets in our experiments to evaluate the model performance. The used datasets are NSL-KDD and UNSW-NB15.",
        "link": "http://dx.doi.org/10.14704/web/v18si05/web18274"
    },
    {
        "id": 5835,
        "title": "Predicting Behavior with Ensemble Learning",
        "authors": "Enrique Garcia Ceja",
        "published": "2021-10-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003203469-3"
    },
    {
        "id": 5836,
        "title": "Comparative Analysis of Ensemble Learning and Non-Ensemble Machine Learning Algorithms for Phishing URL Detection",
        "authors": "Chiamaka M. Igwilo, Victor T. Odumuyiwa",
        "published": "2022-9-14",
        "citations": 1,
        "abstract": "Phishing is a social engineering attack that has been perpetuated for long and is still a prominent attack with an attending high number of victims. Through phishing, attackers can gain easy access to sensitive information about a company or an individual. This research compares the import of features such as lexical features, Domain Named Based features, HTML Features, and tokenization of URLs in detecting phishing URLs. Experimental procedures were designed to compare the efficiency of the four categories of features used separately on three machine learning models (K-Nearest Neighbour, Decision Tree, Logistic Regression) and five ensemble learning classifiers (Random Forest, Bagging, Stacking, Ada Boost, Gradient Boost). Results obtained show higher accuracy for experiments done using URL tokenization with stacking classifier with accuracy scores of 96% and 99.3% respectively for the two datasets used. Future study would be based on more dataset with larger sample size to provide a basis for generalisation.",
        "link": "http://dx.doi.org/10.46792/fuoyejet.v7i3.807"
    },
    {
        "id": 5837,
        "title": "Ensemble Learning",
        "authors": "Lior Rokach",
        "published": "2019-3",
        "citations": 34,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/11325"
    },
    {
        "id": 5838,
        "title": "A Powerful Plant Disease Classification based on Ensemble Learning",
        "authors": "Noura Ouled Sihamman, Assia Ennouni, My Abdelouahed Sabri, Abdellah Aarab",
        "published": "2021",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010733500003101"
    },
    {
        "id": 5839,
        "title": "Can Ensemble Learning Approaches for Offside Detection Work?",
        "authors": "Kurt Buttigieg, David Suda, Mark Caruana",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012159800003587"
    },
    {
        "id": 5840,
        "title": "Front Matter",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811654-8.01001-0"
    },
    {
        "id": 5841,
        "title": "Appendix",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811654-8.15001-8"
    },
    {
        "id": 5842,
        "title": "Temporal patterns and ensemble learning for environmental sound recognition",
        "authors": "Wenjun Yang",
        "published": "No Date",
        "citations": 0,
        "abstract": "This thesis explores features characterizing the temporal dynamics and the use of ensemble techniques to\nimprove the performances of environmental sound recognition (ESR) system. Firstly, for acoustic scene\nclassification (ASC), local binary pattern (LBP) technique is applied to extract the temporal evolution\nof Mel-frequency cepstral coefficients (MFCC) features, and the D3C ensemble classifier is adopted to\noptimize the system performance. The results show that the proposed method achieved a classification\nimprovement of 8% compared to the baseline system.\n\nSecondly, a new approach for sound event detection (SED) using Nonnegative Matrix Factor 2-\nD Deconvolution (NMF2D) and RUSBoost techniques is presented. The idea is to capture the two dimensional\njoint spectral and temporal information from the time-frequency representation (TFR) while\npossibly separating the sound mixture into several sources. Besides, the RUSBoost ensemble technique\nis utilized in the event detection process to alleviate class imbalance in the training data. This method\nreduced the total error rate by 5% compared to the baseline method.",
        "link": "http://dx.doi.org/10.32920/ryerson.14653065.v1"
    },
    {
        "id": 5843,
        "title": "References",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811654-8.16001-4"
    },
    {
        "id": 5844,
        "title": "Index",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811654-8.18001-7"
    },
    {
        "id": 5845,
        "title": "Ensemble Methods",
        "authors": "Poornachandra Sarang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-031-45633-6_6"
    },
    {
        "id": 5846,
        "title": "BGP Anomaly Prediction Using Ensemble Learning",
        "authors": "Marijana Cosovic,  , Emina Junuz",
        "published": "2019-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.18178/ijmlc.2019.9.4.825"
    },
    {
        "id": 5847,
        "title": "Diagnosis of atherosclerosis based on pulse wave and ensemble learning method: Weighted-Ensemble model",
        "authors": "Rongbin Chen, Wenjun Liu, Hui Huang, Songtao Bai",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nPurpose: Atherosclerosis (AS) is closely related to cardiovascular disease (CVD). Nowadays, many scholars have conducted research on CVD, but the diagnosis of AS can only be diagnosed based on traditional medical methods. Pulse wave velocity (PWV) can evaluate potential AS. As a new technology, ultrafast pulse wave velocity (ufPWV) can accurately evaluate PWV. This research aims to screen out relevant features through feature engineering methods and build a Weighted-Ensemble model based on these features to predict AS, which can assist doctors in making more effective diagnosis of atherosclerosis. Methods: In this paper, the traditional statistical analysis method and Random forests (RF) are used to ensemble selection characteristics. This paper improves the ensemble model and applies it to the prediction of AS. Based on the idea of bagging, the base model of RF is changed, and all decision trees in RF are replaced with prediction models with better generalization ability. In order to make full use of models with high generalization ability, this study will also introduce a boosting strategy to weight each base model to form a Weighted-Ensemble model with high generalization ability. The accuracy (ACC), sensitivity (TPR), specificity (TNR) and AUC are four evaluation criteria to evaluate the model.Results: There are 37 features in the data set. Based on the statistical analysis of the data set, a total of 16 characteristics affect the diagnosis of AS. According to the importance of the features obtained by RF model, the 10 most important features are used to construct a Weighted-Ensemble model. The results show that the ACC, TPR, TNR and AUC of the Weighted-Ensemble model are 0.91, 0.93, 0.89 and 0.91 respectively. Compared with each model, the ACC, TPR and AUC of the Weighted-Ensemble model are better than other models. The analysis shows that the Weighted-Ensemble model is superior to traditional machine learning methods in distinguishing patients as normal or atherosclerosis. Conclusions: The accuracy of the algorithm based on the Weighted-Ensemble model in predicting AS has been confirmed in this paper, which implicates that the Weighted-Ensemble model can be successfully used in the atherosclerosis diagnosis and decision-making system.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-1517698/v1"
    },
    {
        "id": 5848,
        "title": "Temporal patterns and ensemble learning for environmental sound recognition",
        "authors": "Wenjun Yang",
        "published": "No Date",
        "citations": 0,
        "abstract": "This thesis explores features characterizing the temporal dynamics and the use of ensemble techniques to\nimprove the performances of environmental sound recognition (ESR) system. Firstly, for acoustic scene\nclassification (ASC), local binary pattern (LBP) technique is applied to extract the temporal evolution\nof Mel-frequency cepstral coefficients (MFCC) features, and the D3C ensemble classifier is adopted to\noptimize the system performance. The results show that the proposed method achieved a classification\nimprovement of 8% compared to the baseline system.\n\nSecondly, a new approach for sound event detection (SED) using Nonnegative Matrix Factor 2-\nD Deconvolution (NMF2D) and RUSBoost techniques is presented. The idea is to capture the two dimensional\njoint spectral and temporal information from the time-frequency representation (TFR) while\npossibly separating the sound mixture into several sources. Besides, the RUSBoost ensemble technique\nis utilized in the event detection process to alleviate class imbalance in the training data. This method\nreduced the total error rate by 5% compared to the baseline method.",
        "link": "http://dx.doi.org/10.32920/ryerson.14653065"
    },
    {
        "id": 5849,
        "title": "Ensemble Learning",
        "authors": "Jitendra Kumar, Ashutosh Kumar Singh, Anand Mohan, Rajkumar Buyya",
        "published": "2021-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003110101-7"
    },
    {
        "id": 5850,
        "title": "Factoid vs. Non-factoid Question Identification: An Ensemble Learning Approach",
        "authors": "Alaa Mohasseb, Andreas Kanavos",
        "published": "2022",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011525900003318"
    },
    {
        "id": 5851,
        "title": "Predicting Lung Cancer Survivability: A Machine Learning Ensemble Method On Seer Data",
        "authors": "",
        "published": "2023-10-11",
        "citations": 1,
        "abstract": "Ensemble methods are powerful techniques used in machine learning to improve the prediction accuracy of classifier learning systems. In this study, different ensemble learning methods for lung cancer survival prediction were evaluated on the Surveillance, Epidemiology and End Results (SEER) dataset. Data were preprocessed in several steps before applying classification models. The popular ensemble methods Bagging, Adaboost and three classification algorithms, K-Nearest Neighbours, Decision Tree and Neural Networks as base classifiers were evaluated for lung cancer survival prediction. The results empirically showed that ensemble methods are able to evaluate the performance of their base classifiers and they are appropriate methods for analysis of cancer survival.",
        "link": "http://dx.doi.org/10.33140/ijcrt.08.04.03"
    },
    {
        "id": 5852,
        "title": "Ensemble Learning",
        "authors": "Yigit Aydede",
        "published": "2023-8-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003381501-17"
    },
    {
        "id": 5853,
        "title": "Extreme Learning Machine based Linear Homogeneous Ensemble for Software Fault Prediction",
        "authors": "Pravas Ranjan Bal, Sandeep Kumar",
        "published": "2018",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006839500690078"
    },
    {
        "id": 5854,
        "title": "Extreme Learning Machine based Linear Homogeneous Ensemble for Software Fault Prediction",
        "authors": "Pravas Ranjan Bal, Sandeep Kumar",
        "published": "2018",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006839501030112"
    },
    {
        "id": 5855,
        "title": "Ensemble Learning for Cough-Based Subject-Independent COVID-19 Detection",
        "authors": "Vincenzo Conversano, Stavros Ntalampiras",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011651700003411"
    },
    {
        "id": 5856,
        "title": "Machine Learning-based Lung and Colon Cancer Detection using Deep Feature Extraction and Ensemble Learning",
        "authors": "Md. Alamin Talukder",
        "published": "No Date",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.31224/2731"
    },
    {
        "id": 5857,
        "title": "ABPET: An AutomaticSoftware Bug Prediction Using Ensemble Learning Technique",
        "authors": "",
        "published": "2023-9-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.48047/nq.2022.20.16.nq880461"
    },
    {
        "id": 5858,
        "title": "WITHDRAWN: Deep Ensemble Learning Method to Forecast COVID-19 Outbreak",
        "authors": "",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThe authors have requested that this preprint be withdrawn due to erroneous posting.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-27216/v2"
    },
    {
        "id": 5859,
        "title": "Learning (II) SVM &amp; Ensemble Learning",
        "authors": "Shuai Huang, Houtao Deng",
        "published": "2021-4-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1201/9781003102656-ch7"
    },
    {
        "id": 5860,
        "title": "An R package for ensemble learning stacking",
        "authors": "Taichi Nukui, Akio Onogi",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractSummaryWe developed an R package for stacking, which is an ensemble approach to supervised learning. Using this package, training and prediction of stacking can be conducted using one-row scripts.Availability and implementationThe R package stacking is available at the GitHub (https://github.com/Onogi/stacking).Contactonogiakio@gmail.comSupplementary informationThis manuscript has no supplementary information.",
        "link": "http://dx.doi.org/10.1101/2023.06.06.543970"
    },
    {
        "id": 5861,
        "title": "List of Tables",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811654-8.27002-4"
    },
    {
        "id": 5862,
        "title": "Review for \"An interpretable ensemble method for deep representation learning\"",
        "authors": " Ammar  Mohammed",
        "published": "2023-4-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/eng2.12725/v1/review2"
    },
    {
        "id": 5863,
        "title": "Crime Status Prediction Using Ensemble Learning",
        "authors": "Sanjay Jain, Prashant Singh",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nThis work focuses on crime status prediction through an ensemble methodology applied to extensive datasets obtained from catalog.data.gov, specifically targeting Los Angeles crime incidents since 2020. The research methodology comprises meticulous data collection, rigorous preprocessing, exploratory data analysis, model selection, and comprehensive model evaluation. Initial challenges included data inaccuracies and privacy-preserving measures in location data, necessitating thorough cleaning and transformation processes. Exploratory data analysis revealed crucial insights, including the 'Status' attribute's limited correlation, crime code distributions, areawise crime counts, and temporal patterns. To address class imbalance within 'Status', the synthetic minority oversampling technique (SMOTE) was applied to balance the dataset. Model evaluation highlighted the superiority of random forest models employing 10 and 20 decision trees, alongside KNN, which demonstrated consistent high accuracy, balanced precision-recall trade-offs, and notable F1 scores in crime status prediction.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3978276/v1"
    },
    {
        "id": 5864,
        "title": "Decision trees and ensemble learning",
        "authors": "Maria Deprez, Emma C. Robinson",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-822904-0.00012-1"
    },
    {
        "id": 5865,
        "title": "Hybrid Ensemble Learning Methods for Classification of Microarray Data",
        "authors": "Sujata Dash",
        "published": "2020",
        "citations": 0,
        "abstract": "Efficient classification and feature extraction techniques pave an effective way for diagnosing cancers from microarray datasets. It has been observed that the conventional classification techniques have major limitations in discriminating the genes accurately. However, such kind of problems can be addressed by an ensemble technique to a great extent. In this paper, a hybrid RotBagg ensemble framework has been proposed to address the problem specified above. This technique is an integration of Rotation Forest and Bagging ensemble which in turn preserves the basic characteristics of ensemble architecture i.e., diversity and accuracy. Three different feature selection techniques are employed to select subsets of genes to improve the effectiveness and generalization of the RotBagg ensemble. The efficiency is validated through five microarray datasets and also compared with the results of base learners. The experimental results show that the correlation based FRFR with PCA-based RotBagg ensemble form a highly efficient classification model. ",
        "link": "http://dx.doi.org/10.4018/978-1-7998-1204-3.ch038"
    },
    {
        "id": 5866,
        "title": "A Game Theoretic Approach Based on Differential Evolution to Ensemble Learning for Classification",
        "authors": "Rodica Lung",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012192700003595"
    },
    {
        "id": 5867,
        "title": "Cross Project Software Defect Prediction using Extreme Learning Machine: An Ensemble based Study",
        "authors": "Pravas Ranjan Bal",
        "published": "2018",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006886503200327"
    },
    {
        "id": 5868,
        "title": "Ensemble Machine Learning Methods to Predict the Balancing of Ayurvedic Constituents in the Human Body",
        "authors": "Vani Rajasekar, Sathya Krishnamoorthi, Muzafer Saračević, Janani A",
        "published": "2022-3-24",
        "citations": 7,
        "abstract": "Ayurvedic medicines are categorized into seven constitutional forms ‘Prakriti’ which is a constituent in the Ayurvedic system of medicine to determine drought tolerance and drug responsiveness. Prakriti assessment entails a thorough physical examination as well as queries about physiological or behavioral characteristics. The prevalence of certain \"doshas\" is attributed by Ayurveda to the fundamental constituent of a person. Vata, pitta, and Kapha are the three main doshas mentioned. Ayurveda-dosha studies have been used for a long time, but the quantitative reliability measurement of these diagnostic methods still lags. The careful and appropriate analysis leads to an effective treatment. In this paper, we demonstrate the result of certain machine learning methods like Support Vector Machine (SVM), Naive Bayes (NB), Decision Tree (DT), K-Nearest Neighbour (KNN), Artificial Neural Network (ANN), and Adaboost algorithm for various performance characteristics to predict human body constituencies. From the observations of results it is shown that the AdaBoost algorithm with hyperparameter tuning provides enhanced accuracy and recall of 0.97, precision and F-score of 0.96, the lower RSME value obtained is 0.64. The experimental results reveal that the improved model, which is based on ensemble learning methods, outperforms traditional methods significantly. According to the findings, advancements in the proposed algorithms could give machine learning a promising future.",
        "link": "http://dx.doi.org/10.7494/csci.2022.23.1.4315"
    },
    {
        "id": 5869,
        "title": "Cross Project Software Defect Prediction using Extreme Learning Machine: An Ensemble based Study",
        "authors": "Pravas Ranjan Bal",
        "published": "2018",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0006886503540361"
    },
    {
        "id": 5870,
        "title": "Melanoma Classification Through Deep Ensemble Learning and Explainable AI",
        "authors": "Wadduwage Perera, Abm Islam, Van Pham, Min An",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0012575400003657"
    },
    {
        "id": 5871,
        "title": "Efficient Deep Learning Ensemble for Skin Lesion Classification",
        "authors": "David Gaviria, Md Saker, Petia Radeva",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011816100003417"
    },
    {
        "id": 5872,
        "title": "Simulation Runtime Prediction Approach based on Stacking Ensemble Learning",
        "authors": "Yuhao Xiao, Yiping Yao, Feng Zhu, Kai Chen",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010517600002995"
    },
    {
        "id": 5873,
        "title": "Predicting gross domestic product using the ensemble machine learning method.    ",
        "authors": "MD Adewale",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.22541/au.168494153.35626048/v1"
    },
    {
        "id": 5874,
        "title": "An Ensemble Learning Approach for Cancer Drug Prediction",
        "authors": "Darsh Mandera, Anna Ritz",
        "published": "No Date",
        "citations": 0,
        "abstract": "AbstractPredicting the response to a particular drug for specific cancer, despite known genetic mutations, still remains a huge challenge in modern oncology and precision medicine. Today, prescribing a drug for a cancer patient is based on a doctor’s analysis of various articles and previous clinical trials; it is an extremely time-consuming process. We developed a machine learning classifier to automatically predict a drug given a carcinogenic gene mutation profile. Using the Breast Invasive Carcinoma Dataset from The Cancer Genome Atlas (TCGA), the method first selects features from mutated genes and then applies K-Fold, Decision Tree, Random Forest and Ensemble Learning classifiers to predict best drugs. Ensemble Learning yielded prediction accuracy of 66% on the test set in predicting the correct drug. To validate that the model is general-purpose, Lung Adenocarcinoma (LUAD) data and Colorectal Adenocarcinoma (COADREAD) data from TCGA was trained and tested, yielding prediction accuracies 50% and 66% respectively. The resulting accuracy indicates a direct correlation between prediction accuracy and cancer data size. More importantly, the results of LUAD and COADREAD show that the implemented model is general purpose as it is able to achieve similar results across multiple cancer types. We further verified the validity of the model by implementing it on patients with unclear recovery status from the COADREAD dataset. In every case, the model predicted a drug that was administered to each patient. This method will offer oncologists significant time-saving compared to their current approach of extensive background research, and offers personalized patient care for cancer patients.",
        "link": "http://dx.doi.org/10.1101/2020.08.10.245142"
    },
    {
        "id": 5875,
        "title": "Traffic Accident Severity Prediction with Ensemble Learning Methods",
        "authors": "Süleyman ÇEVEN, AHMET ALBAYRAK",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4659523"
    },
    {
        "id": 5876,
        "title": "List of Figures",
        "authors": "",
        "published": "2017",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811654-8.27001-2"
    },
    {
        "id": 5877,
        "title": "Ensemble Machine Learning to “Boost” Ubiquitination-sites Prediction",
        "authors": "Xiaoye Mo, Xia Jiang",
        "published": "No Date",
        "citations": 0,
        "abstract": "ABSTRACTUbiquitination-site prediction is an important task because ubiquitination is a critical regulatory function for many biological processes such as proteasome degradation, DNA repair and transcription, signal transduction, endocytoses, and sorting. However, the highly dynamic and reversible nature of ubiquitination makes it difficult to experimentally identify specific ubiquitination sites. In this paper, we explore the possibility of improving the prediction of ubiquitination sites using ensemble machine learning methods including Random Forrest (RF), Adaptive Boosting (ADB), Gradient Boosting (GB), and eXtreme Gradient Boosting (XGB). By doing grid search with the four ensemble methods and six comparison non-ensemble learning methods including Naïve Base (NB), Logistic Regression (LR), Decision Trees (DT), Support Vector Machine (SVM), LASSO, and K-Nearest Neighbor (KNN), we find that all the four ensemble methods significantly outperform one or more non-ensemble methods included in this study. XGB outperforms three out of the six non-ensemble methods that we included; ADB and RF both outperform two of the six non-ensemble methods; GB outperforms one non-ensemble method. Comparing the four ensemble methods among themselves. GB performs the worst; XGB and ADB are very comparable in terms of prediction, but ADB beats XGB by far in terms of both the unit model training time and total running time. Both XGB and ADB tend to do better than RF in terms of prediction, but RF has the shortest unit model training time out of the three. In addition, we notice that ADB tends to outperform XGB when dealing with small-scale datasets, and RF can outperform either ADB or XGB when data are less balanced. Interestingly, we find that SVM, LR, and LASSO, three of the six non-ensemble methods included, perform comparably with all the ensemble methods. Based on this study, ensemble learning is a promising approach to ignificantly improving ubiquitination-site prediction using protein segment data.",
        "link": "http://dx.doi.org/10.1101/2022.09.11.507485"
    },
    {
        "id": 5878,
        "title": "Decision letter for \"An interpretable ensemble method for deep representation learning\"",
        "authors": "",
        "published": "2023-4-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/eng2.12725/v1/decision1"
    },
    {
        "id": 5879,
        "title": "ENSEMBLE-BASED INSTANCE RELEVANCE ESTIMATION IN MULTIPLE-INSTANCE LEARNING",
        "authors": "Muhammad Waqas, Rizwan Qureshi",
        "published": "No Date",
        "citations": 0,
        "abstract": "The Contribution to the  9th European Workshop on Visual Information Processing. The work is focuses on instance relevance estimation process in domain of multiple instance learning. <br>",
        "link": "http://dx.doi.org/10.36227/techrxiv.14945712"
    },
    {
        "id": 5880,
        "title": "Malignant Melanoma Classification using Ensemble Machine Learning Techniques",
        "authors": "",
        "published": "2023-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.48047/nq.2019.17.03.2011"
    },
    {
        "id": 5881,
        "title": "Brain Tumor Detection based on Ensemble Learning",
        "authors": "Donghyun Kim",
        "published": "No Date",
        "citations": 3,
        "abstract": "In this paper, we propose methods for brain tumor detection in MRI images based on ensemble learning. We build upon prior research on ensemble methods by testing the concatenation of pre-trained models: features extracted via transfer learning are merged and segmented by classification algorithms or a stacked ensemble of those algorithms. The proposed approach achieved accuracy scores of 0.98 , outperforming a benchmark VGG-16 model. Considerations to granular computing are given in the paper as well.",
        "link": "http://dx.doi.org/10.20944/preprints202008.0641.v2"
    },
    {
        "id": 5882,
        "title": "An Ensemble Learning Interpretation of Geometric Semantic Genetic Programming",
        "authors": "Grant Dick",
        "published": "No Date",
        "citations": 0,
        "abstract": "Abstract\nGeometric semantic genetic programming (GSGP) is a variant of genetic programming (GP) that directly searches the semantic space of programs to produce candidate solutions. GSGP has shown considerable success in improving the performance of GP in terms of program correctness, however this comes at the expense of exponential program growth. Subsequent attempts to address this growth have not fully-exploited the fact that GSGP searches by producing linear combinations of existing solutions. This paper examines this property of GSGP and frames the method as an ensemble learning defining mutation and crossover as examples of boosting and stacking, respectively. The ensemble interpretation allows for simple integration of regularisation techniques that significantly reduce the size of the resultant programs. Additionally, this paper examines the quality of parse tree base learners within this ensemble interpretation of GSGP and suggests that future research could substantially improve the quality of GSGP by examining more effective initialisation techniques. The resulting ensemble learning interpretation leads to variants of GSGP that substantially improve upon the performance of traditional GSGP in regression contexts, and produce a method that frequently outperforms gradient boosting.",
        "link": "http://dx.doi.org/10.21203/rs.3.rs-3096521/v1"
    },
    {
        "id": 5883,
        "title": "BACK MATTER",
        "authors": "",
        "published": "2019-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811201967_bmatter"
    },
    {
        "id": 5884,
        "title": "Ensemble Learning based on Regressor Chains: A Case on Quality Prediction",
        "authors": "Kenan Demirel, Ahmet Şahin, Erinc Albey",
        "published": "2019",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0007932802670274"
    },
    {
        "id": 5885,
        "title": "LSTM-Based Ensemble Learning for Time-Dependent Reliability Analysis",
        "authors": "Zequn Wang, Mingyang Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1115/1.0001758v"
    },
    {
        "id": 5886,
        "title": "Introduction",
        "authors": "Yun Yang",
        "published": "2017",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1016/b978-0-12-811654-8.00001-4"
    },
    {
        "id": 5887,
        "title": "Ensemble Learning for Accurate Heart Sound Multi-Labeling",
        "authors": "Arjun Dash",
        "published": "No Date",
        "citations": 0,
        "abstract": "Ensemble Learning for Accurate Heart Sound Multi-Labeling",
        "link": "http://dx.doi.org/10.31219/osf.io/ty3ha"
    },
    {
        "id": 5888,
        "title": "Preliminary application of machine learning in ensemble forecasting",
        "authors": "Junjie Ma, Wansuo Duan",
        "published": "No Date",
        "citations": 0,
        "abstract": "\n        &lt;p&gt;The optimal&amp;#160;perturbation method is a beneficial way to generate ensemble members to be used in ensemble forecasting. With orthogonal optimal perturbation, orthogonal conditional nonlinear optimal perturbations (O-CNOPs) generating initial perturbations and orthogonal nonlinear forcing singular vectors (O-NFSVs) generating model perturbations are two kinds of skillful ensemble forecasting methods. There is main disadvantage that O-CNOPs and O-NFSVs generate optimal perturbation members may need a lot of time, but in practical weather prediction, the ensemble members usually need to be generated quickly. In order to benefit from O-CNOPs and O-NFSVs, as well as considering the cost of calculation, therefore, we present a way with the big data and machine learning thinking to simplify the process of the optimal perturbation ensemble methods. Using the historical samples and their optimal perturbations to establish a database, we look for the historical sample which is analogous to what need to be forecasted currently from the database by using the convolutional neural network (CNN). In comparison with using optimization algorithm to get O-CNOPs and O-NFSVs directly, this way gets O-CNOPs and O-NFSVs faster which still obtain acceptable prediction performance. In addition, once the CNN model is trained completely, the cost of time for prediction will be saved. We illustrate the advantage by numerical simulations of a Lorenz 96 model.&lt;/p&gt;&lt;p&gt;Further more, based on above study, some comparison of the ensemble forecasting skill of O-CNOPs and O-NFSVs has been done, and there are three results for the reference: (1) in the early stage (1-6 days), the O-CNOPs method perform more skillfully, and in the later stage (6-12 days), the O-NFSVs method perform more skillfully; (2) within 1-5 days, if the development of analysis error is bigger than or close to the average value of the analysis error development of historical samples, the O-CNOPs method is preferred, else the O-NFSVs method is preferred; (3) within 0-3 days, if the development of energy is bigger than or close to the average value of the energy development of the historical samples, the O-CNOPs method is preferred, else the O-NFVS method is preferred. Next, further work is required to examine and explore more and deeper research using machine learning in ensemble forecasting studies of atmosphere and other systems.&lt;/p&gt;\n        ",
        "link": "http://dx.doi.org/10.5194/egusphere-egu2020-4017"
    },
    {
        "id": 5889,
        "title": "LSTM-Based Ensemble Learning for Time-Dependent Reliability Analysis",
        "authors": "Zequn Wang, Mingyang Li",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1115/1.0005322v"
    },
    {
        "id": 5890,
        "title": "Decision letter for \"An interpretable ensemble method for deep representation learning\"",
        "authors": "",
        "published": "2023-6-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1002/eng2.12725/v2/decision1"
    },
    {
        "id": 5891,
        "title": "ENSEMBLE-BASED INSTANCE RELEVANCE ESTIMATION IN MULTIPLE-INSTANCE LEARNING",
        "authors": "Muhammad Waqas, Rizwan Qureshi",
        "published": "No Date",
        "citations": 0,
        "abstract": "The Contribution to the  9th European Workshop on Visual Information Processing. The work is focuses on instance relevance estimation process in domain of multiple instance learning. <br>",
        "link": "http://dx.doi.org/10.36227/techrxiv.14945712.v1"
    },
    {
        "id": 5892,
        "title": "Robust Model Discovery with SINDy and Ensemble Learning",
        "authors": "Urban Fasel",
        "published": "No Date",
        "citations": 0,
        "abstract": "The sparse identification of nonlinear dynamics (SINDy) algorithm can identify dynamical system models purely from data. In this talk, I will present recent work on extending the SINDy algorithm using ensemble learning to identify interpretable and generalizable models in the low-data and high-noise limit. We apply the ensemble-SINDy (E-SINDy) algorithm to a range of challenging synthetic and real-world data sets and demonstrate substantial improvements to the accuracy and robustness of model discovery from noisy and limited data. E-SINDy is computationally efficient, with similar scaling as standard SINDy. We show that E-SINDy can perform efficient uncertainty estimation and probabilistic forecasts, compared to expensive Bayesian uncertainty quantification methods via MCMC. Finally, we show that ensemble statistics from E-SINDy can be used for active learning and improved model predictive control.",
        "link": "http://dx.doi.org/10.52843/cassyni.430yw2"
    },
    {
        "id": 5893,
        "title": "Unfrozen Water Content Estimation: A Comparison between Ensemble and Non-ensemble Machine Learning Models",
        "authors": "Jiaxian Li, Pengcheng Zhou, Junping Ren, Yiqing Pu, Fanyu Zhang, Chong Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Unfrozen water content (UWC) is a key parameter affecting a variety of\nsoil physical-mechanical properties and processes in frozen soil\nsystems. However, traditional estimation models suffer limitations due\nto oversimplified assumptions or limited applicable conditions. Given\nthat, there is a compelling need to explore alternative modeling\napproaches that leverage machine learning (ML) algorithms, which have\nshown increasing potential in engineering fields. To this end, this\nstudy evaluated and compared six widely known ML algorithms (i.e., three\nensemble models: RF, LightGBM and XGBoost; and three non-ensemble\nmodels: KNN, SVR and BPNN) for modeling UWC based on collected\nexperimental datasets. These algorithms were optimized and evaluated\nusing a framework combining Bayesian optimization and cross-validation\nto ensure model stability and generalization. The results demonstrated\nthat the ensemble tree-based methods, particularly LightGBM and XGBoost,\nachieved the highest predictive accuracy and superior overall\nperformance. On the other hand, the nonensemble methods exhibited poorer\ngeneralization abilities. Interestingly, during 10-fold\ncross-validation, consistent underperformance was observed for a\nparticular fold, possibly stemming from the challenges of the data\ndistribution in that fold after random shuffling. The present study\nhighlights the effectiveness of ensemble learning approaches, importance\nof proper hyperparameter tuning and validation strategies, and intrinsic\nmodeling challenges arising from the difference between the freezing and\nthawing phase change behaviors. This comprehensive ML model comparison\nand robust training framework provide valuable guidance on selecting\nsuitable data-driven techniques for modeling frozen soil properties for\ncold regions hydrogeology and engineering practices.",
        "link": "http://dx.doi.org/10.22541/essoar.170758242.26616387/v1"
    },
    {
        "id": 5894,
        "title": "Unfrozen Water Content Estimation: A Comparison between Ensemble and Non-ensemble Machine Learning Models",
        "authors": "Jiaxian Li, Pengcheng Zhou, Junping Ren, Yiqing Pu, Fanyu Zhang, Chong Wang",
        "published": "No Date",
        "citations": 0,
        "abstract": "Unfrozen water content (UWC) is a key parameter affecting a variety of\nsoil physical-mechanical properties and processes in frozen soil\nsystems. However, traditional estimation models suffer limitations due\nto oversimplified assumptions or limited applicable conditions. Given\nthat, there is a compelling need to explore alternative modeling\napproaches that leverage machine learning (ML) algorithms, which have\nshown increasing potential in engineering fields. To this end, this\nstudy evaluated and compared six widely known ML algorithms (i.e., three\nensemble models: RF, LightGBM and XGBoost; and three non-ensemble\nmodels: KNN, SVR and BPNN) for modeling UWC based on collected\nexperimental datasets. These algorithms were optimized and evaluated\nusing a framework combining Bayesian optimization and cross-validation\nto ensure model stability and generalization. The results demonstrated\nthat the ensemble tree-based methods, particularly LightGBM and XGBoost,\nachieved the highest predictive accuracy and superior overall\nperformance. On the other hand, the nonensemble methods exhibited poorer\ngeneralization abilities. Interestingly, during 10-fold\ncross-validation, consistent underperformance was observed for a\nparticular fold, possibly stemming from the challenges of the data\ndistribution in that fold after random shuffling. The present study\nhighlights the effectiveness of ensemble learning approaches, importance\nof proper hyperparameter tuning and validation strategies, and intrinsic\nmodeling challenges arising from the difference between the freezing and\nthawing phase change behaviors. This comprehensive ML model comparison\nand robust training framework provide valuable guidance on selecting\nsuitable data-driven techniques for modeling frozen soil properties for\ncold regions hydrogeology and engineering practices.",
        "link": "http://dx.doi.org/10.22541/essoar.170688777.71505940/v1"
    },
    {
        "id": 5895,
        "title": "FRONT MATTER",
        "authors": "",
        "published": "2019-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1142/9789811201967_fmatter"
    },
    {
        "id": 5896,
        "title": "Ensemble Methods",
        "authors": "Jan Kozak",
        "published": "2019",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.1007/978-3-319-93752-6_6"
    },
    {
        "id": 5897,
        "title": "Integrated Deep Learning and Ensemble Learning Model for Deep Feature-Based Wheat Disease Detection",
        "authors": "Hatice Catal Reis, Veysel Turk",
        "published": "No Date",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.2139/ssrn.4593652"
    },
    {
        "id": 5898,
        "title": "Cost-Aware Ensemble Learning Approach for Overcoming Noise in Labeled Data",
        "authors": "Abdulrahman Gharawi, Jumana Alsubhi, Lakshmish Ramaswamy",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0011675200003393"
    },
    {
        "id": 5899,
        "title": "Simulation Runtime Prediction Approach based on Stacking Ensemble Learning",
        "authors": "Yuhao Xiao, Yiping Yao, Feng Zhu, Kai Chen",
        "published": "2021",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0010517600420049"
    },
    {
        "id": 5900,
        "title": "Ensemble Clustering based Semi-supervised Learning for Revenue Accounting Workflow Management",
        "authors": "Tianshu Yang, Nicolas Pasquier, Frederic Precioso",
        "published": "2020",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "link": "http://dx.doi.org/10.5220/0009883802830293"
    }
]