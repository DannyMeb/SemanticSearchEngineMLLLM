[
    {
        "id": 22305,
        "title": "Advancements in End-to-End Speech Recognition: A Comparative Study of Deep Learning Architectures and Attention Mechanisms",
        "authors": "",
        "published": "2024-1-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets48033"
    },
    {
        "id": 22306,
        "title": "A short-term energy consumption forecasting method for attention mechanisms based on spatio-temporal deep learning",
        "authors": "Mingdong Han, Lingyan Fan",
        "published": "2024-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.compeleceng.2023.109063"
    },
    {
        "id": 22307,
        "title": "A General Survey on Attention Mechanisms in Deep Learning",
        "authors": "Gianni Brauwers, Flavius Frasincar",
        "published": "2023-4-1",
        "citations": 110,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tkde.2021.3126456"
    },
    {
        "id": 22308,
        "title": "Machine Fault Diagnosis Based on a Multi-Input Multi- Branch Deep Learning Network with Attention Mechanisms",
        "authors": "Lianghui Zou, Haoxin Qin, Qidong Lu, Zhiliang Qin",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.18178/ijfcc.2024.13.1.612"
    },
    {
        "id": 22309,
        "title": "Harnessing edge-enhanced attention mechanisms for supernova detection in deep learning frameworks",
        "authors": "K. Yin, J. Jia, F. Li, X. Gao, T. Sun",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ascom.2023.100784"
    },
    {
        "id": 22310,
        "title": "Data-Driven Techniques for Short-Term Electricity Price Forecasting through Novel Deep Learning Approaches with Attention Mechanisms",
        "authors": "Vasileios Laitsos, Georgios Vontzos, Dimitrios Bargiotas, Aspassia Daskalopulu, Lefteri H. Tsoukalas",
        "published": "2024-3-28",
        "citations": 0,
        "abstract": "The electricity market is constantly evolving, being driven by factors such as market liberalization, the increasing use of renewable energy sources (RESs), and various economic and political influences. These dynamics make it challenging to predict wholesale electricity prices. Accurate short-term forecasting is crucial to maintaining system balance and addressing anomalies such as negative prices and deviations from predictions. This paper investigates short-term electricity price forecasting using historical time series data and employs advanced deep learning algorithms. First, four deep learning models are implemented and proposed, which are a convolutional neural network (CNN) with an integrated attention mechanism, a hybrid CNN followed by a gated recurrent unit model (CNN-GRU) with an attention mechanism, and two ensemble learning models, which are a soft voting ensemble and a stacking ensemble model. Also, the optimized version of a transformer model, the Multi-Head Attention model, is introduced. Finally, the perceptron model is used as a benchmark for comparison. Our results show excellent prediction accuracy, particularly in the hybrid CNN-GRU model with attention, thereby achieving a mean absolute percentage error (MAPE) of 6.333%. The soft voting ensemble model and the Multi-Head Attention model also performed well, with MAPEs of 6.125% and 6.889%, respectively. These findings are significant, as previous studies have not shown high performance with transformer models and attention mechanisms. The presented results offer promising insights for future research in this field.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/en17071625"
    },
    {
        "id": 22311,
        "title": "Using Deep Learning with Attention to Detect Data Exfiltration by POS Malware",
        "authors": "Gabriele Martino, Federico Galatolo, Mario Cimino, Christian Callegari",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.5220/0011993900003467"
    },
    {
        "id": 22312,
        "title": "Enhancing Breast Cancer Diagnosis with Channel-Wise Attention Mechanisms in Deep Learning",
        "authors": "Muhammad Mumtaz Ali, Faiqa Maqsood, Shiqi Liu, Weiyan Hou, Liying Zhang, Zhenfei Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/cmc.2023.045310"
    },
    {
        "id": 22313,
        "title": "Attention-Guided Deep Learning Texture Feature for Object Recognition Applications",
        "authors": "Sachinkumar Veerashetty",
        "published": "2023-12-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/engproc2023059051"
    },
    {
        "id": 22314,
        "title": "Ensemble deep learning modeling for Chlorophyll-a concentration prediction based on two-layer decomposition and attention mechanisms",
        "authors": "Can Zhang, Zhuoqun Zou, Zhaocai Wang, Jing Wang",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11600-023-01240-z"
    },
    {
        "id": 22315,
        "title": "Deep Learning with Attention Mechanisms for Road Weather Detection",
        "authors": "Madiha Samo, Jimiama Mosima Mafeni Mase, Grazziela Figueredo",
        "published": "2023-1-10",
        "citations": 5,
        "abstract": "There is great interest in automatically detecting road weather and understanding its impacts on the overall safety of the transport network. This can, for example, support road condition-based maintenance or even serve as detection systems that assist safe driving during adverse climate conditions. In computer vision, previous work has demonstrated the effectiveness of deep learning in predicting weather conditions from outdoor images. However, training deep learning models to accurately predict weather conditions using real-world road-facing images is difficult due to: (1) the simultaneous occurrence of multiple weather conditions; (2) imbalanced occurrence of weather conditions throughout the year; and (3) road idiosyncrasies, such as road layouts, illumination, and road objects, etc. In this paper, we explore the use of a focal loss function to force the learning process to focus on weather instances that are hard to learn with the objective of helping address data imbalances. In addition, we explore the attention mechanism for pixel-based dynamic weight adjustment to handle road idiosyncrasies using state-of-the-art vision transformer models. Experiments with a novel multi-label road weather dataset show that focal loss significantly increases the accuracy of computer vision approaches for imbalanced weather conditions. Furthermore, vision transformers outperform current state-of-the-art convolutional neural networks in predicting weather conditions with a validation accuracy of 92% and an F1-score of 81.22%, which is impressive considering the imbalanced nature of the dataset.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23020798"
    },
    {
        "id": 22316,
        "title": "Contrast-Enhanced Ultrasound with Deep Learning with Attention Mechanisms for Predicting Microvascular Invasion in Single Hepatocellular Carcinoma",
        "authors": "Xiachuan Qin, Jianhui Zhu, Zhengzheng Tu, Qianqing Ma, Jin Tang, Chaoxue Zhang",
        "published": "2023-9",
        "citations": 6,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.acra.2022.12.005"
    },
    {
        "id": 22317,
        "title": "Deep Learning-Based Medical Image Registration Algorithm: Enhancing Accuracy with Dense Connections and Channel Attention Mechanisms",
        "authors": "Yulu Gong, Houze Liu, Lianwei Li, Jingxiao Tian, Hanzhe Li",
        "published": "2024-2-28",
        "citations": 0,
        "abstract": "In critical clinical medical image analysis applications, such as surgical navigation and tumor monitoring, image registration is crucial. Recognizing the potential for enhanced accuracy in existing unsupervised image registration techniques for single-modal imagery, this research introduces an innovative deep learning-based image registration algorithm. Its novelty resides in integrating short and long connections to create a densely connected structure, markedly refining the feature map interconnectivity within the U-Net architecture. This advancement addresses the significant semantic gap issues arising from disparities in feature map sampling depths. Moreover, the algorithm incorporates a channel attention mechanism within the U-shaped network's decoder, significantly mitigating image noise and facilitating the generation of smoother deformation fields. This enhancement not only boosts the model's detail sensitivity but also markedly increases image registration precision, particularly evident when processing single-modal brain MRI datasets, thereby proving the algorithm's efficacy and utility. Extensive clinical application-based training and testing have underscored this algorithm's substantial contributions to medical image registration accuracy enhancement. Overall, by leveraging deep learning technologies and innovative algorithmic structures, this study addresses pivotal challenges in medical image registration, offering more precise and dependable support for clinical applications like surgical navigation and tumor surveillance.",
        "keywords": "",
        "link": "http://dx.doi.org/10.53469/jtpes.2024.04(02).01"
    },
    {
        "id": 22318,
        "title": "Integrating Multiple Visual Attention Mechanisms in Deep Neural Networks",
        "authors": "Fernando Martinez, Yijun Zhao",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/compsac57700.2023.00180"
    },
    {
        "id": 22319,
        "title": "Personalized Federated Learning with Attention Mechanisms",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.25236/ajcis.2023.061113"
    },
    {
        "id": 22320,
        "title": "NOVEL TRANSFORMER-BASED APPROACH ENHANCED BY REINFORCEMENT LEARNING AND ATTENTION MECHANISMS",
        "authors": "",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.35741/issn.0258-2724.58.6.5"
    },
    {
        "id": 22321,
        "title": "Deep Neural Network Based Spam Email Classification Using Attention Mechanisms",
        "authors": "Md. Tofael Ahmed, Mariam Akter, Md. Saifur Rahman, Maqsudur Rahman, Pintu Chandra Paul, Miss. Nargis Parvin, Almas Hossain Antar",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.4236/jilsa.2023.154010"
    },
    {
        "id": 22322,
        "title": "Differential attention net: Multi-directed differential attention based hybrid deep learning model for solar power forecasting",
        "authors": "Amit Rai, Ashish Shrivastava, Kartick C. Jana",
        "published": "2023-1",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.energy.2022.125746"
    },
    {
        "id": 22323,
        "title": "Complementary Attention-Based Deep Learning Detection of Fake Faces",
        "authors": "Supriyo Sadhya, Xiaojun Qi",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bigdata59044.2023.10386483"
    },
    {
        "id": 22324,
        "title": "Cyberbullying Detection on Twitter Using Deep Learning-Based Attention Mechanisms and Continuous Bag of Words Feature Extraction",
        "authors": "Suliman Mohamed Fati, Amgad Muneer, Ayed Alwadain, Abdullateef O. Balogun",
        "published": "2023-8-17",
        "citations": 6,
        "abstract": "Since social media platforms are widely used and popular, they have given us more opportunities than we can even imagine. Despite all of the known benefits, some users may abuse these opportunities to humiliate, insult, bully, and harass other people. This issue explains why there is a need to reduce such negative activities and create a safe cyberspace for innocent people by detecting cyberbullying activity. This study provides a comparative analysis of deep learning methods used to test and evaluate their effectiveness regarding a well-known global Twitter dataset. To recognize abusive tweets and overcome existing challenges, attention-based deep learning methods are introduced. The word2vec with CBOW concatenated formed the weights included in the embedding layer and was used to extract the features. The feature vector was input into a convolution and pooling mechanism, reducing the feature dimensionality while learning the position-invariant of the offensive words. A SoftMax function predicts feature classification. Using benchmark experimental datasets and well-known evaluation measures, the convolutional neural network model with attention-based long- and short-term memory was found to outperform other DL methods. The proposed cyberbullying detection methods were evaluated using benchmark experimental datasets and well-known evaluation measures. Finally, the results demonstrated the superiority of the attention-based 1D convolutional long short-term memory (Conv1DLSTM) classifier over the other implemented methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math11163567"
    },
    {
        "id": 22325,
        "title": "Simultaneous Pipe Leak Detection and Localization Using Attention-Based Deep Learning Autoencoder",
        "authors": "Divas Karimanzira",
        "published": "2023-11-16",
        "citations": 0,
        "abstract": "Water distribution networks are often susceptible to pipeline leaks caused by mechanical damages, natural hazards, corrosion, and other factors. This paper focuses on the detection of leaks in water distribution networks (WDN) using a data-driven approach based on machine learning. A hybrid autoencoder neural network (AE) is developed, which utilizes unsupervised learning to address the issue of unbalanced data (as anomalies are rare events). The AE consists of a 3DCNN encoder, a ConvLSTM decoder, and a ConvLSTM future predictor, making the anomaly detection robust. Additionally, spatial and temporal attention mechanisms are employed to enhance leak localization. The AE first learns the expected behavior and subsequently detects leaks by identifying deviations from this expected behavior. To evaluate the performance of the proposed method, the Water Network Tool for Resilience (WNTR) simulator is utilized to generate water pressure and flow rate data in a water supply network. Various conditions, such as fluctuating water demands, data noise, and the presence of leaks, are considered using the pressure-driven demand (PDD) method. Datasets with and without pipe leaks are obtained, where the AE is trained using the dataset without leaks and tested using the dataset with simulated pipe leaks. The results, based on a benchmark WDN and a confusion matrix analysis, demonstrate that the proposed method successfully identifies leaks in 96% of cases and a false positive rate of 4% compared to two baselines: a multichannel CNN encoder with LSTM decoder (MC-CNN-LSTM) and a random forest and model based on supervised learning with a false positive rate of 8% and 15%, respectively. Furthermore, a real case study demonstrates the applicability of the developed model for leak detection in the operational conditions of water supply networks using inline sensor data.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics12224665"
    },
    {
        "id": 22326,
        "title": "Visual Tracking with Temporal Contextual Attention",
        "authors": "Qin Li, Wenjie Zou",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10166053"
    },
    {
        "id": 22327,
        "title": "Bengali Text Summarization with Attention-Based Deep Learning",
        "authors": "Anupam Singha, N R Rajalakshmi",
        "published": "2023-8-25",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/asiancon58793.2023.10270772"
    },
    {
        "id": 22328,
        "title": "Automatic Postoperative Brain Tumor Segmentation with Limited Data using Transfer Learning and Triplet Attention",
        "authors": "Jingpeng Li, Atle Bjørnerud",
        "published": "2023-1-23",
        "citations": 0,
        "abstract": "Accurate brain tumor segmentation is clinically important for diagnosis and treatment planning. Convolutional neural networks (CNNs) have achieved promising performance in various visual recognition tasks. Training such networks usually requires large amount of labeled data, which is often challenging for medical applications. In this work, we address the segmentation problem by applying transfer learning to downstream segmentation tasks. Specifically, we explore how knowledge acquired from a large preoperative dataset can be transferred to postoperative tumor segmentation on a smaller dataset. To this end, we have developed a 3D CNN for brain tumor segmentation, and fine-tuned the pretrained models on the target domain data. To better exploit the inter-channel and spatial information, triplet attention has been incorporated and extended into existing segmentation network. Extensive experiments on our dataset demonstrate the effectiveness of transfer learning and attention modules for improved postoperative tumor segmentation performance when only limited amount of annotated data is available.",
        "keywords": "",
        "link": "http://dx.doi.org/10.7557/18.6826"
    },
    {
        "id": 22329,
        "title": "Ultrasound Super Resolution Using Deep Learning Based on Attention Mechanism",
        "authors": "Xilun Liu, Mohamed Almekkawy",
        "published": "2023-4-18",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/isbi53787.2023.10230812"
    },
    {
        "id": 22330,
        "title": "Attention Balanced Multi-Dimension Multi-Task Deep Learning for Alopecia Recognition",
        "authors": "C Saraswathi,  , B Pushpa",
        "published": "2023-5-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17485/ijst/v16i18.29"
    },
    {
        "id": 22331,
        "title": "Breast Cancer Diagnosis in Thermography Using Pre-Trained VGG16 with Deep Attention Mechanisms",
        "authors": "Alia Alshehri, Duaa AlSaeed",
        "published": "2023-2-23",
        "citations": 2,
        "abstract": "One of the most prevalent cancers in women is breast cancer. The mortality rate related to this disease can be decreased by early, accurate diagnosis to increase the chance of survival. Infrared thermal imaging is one of the breast imaging modalities in which the temperature of the breast tissue is measured using a screening tool. The previous studies did not use pre-trained deep learning (DL) with deep attention mechanisms (AMs) on thermographic images for breast cancer diagnosis. Using thermal images from the Database for Research Mastology with Infrared Image (DMR-IR), the study investigates the use of a pre-trained Visual Geometry Group with 16 layers (VGG16) with AMs that can produce good diagnosis performance utilizing the thermal images of breast cancer. The symmetry of the three models resulting from the combination of VGG16 with three types of AMs is evident in all its stages in methodology. The models were compared to state-of-art breast cancer diagnosis approaches and tested for accuracy, sensitivity, specificity, precision, F1-score, AUC score, and Cohen’s kappa. The test accuracy rates for the AMs using the VGG16 model on the breast thermal dataset were encouraging, at 99.80%, 99.49%, and 99.32%. Test accuracy for VGG16 without AMs was 99.18%, whereas test accuracy for VGG16 with AMs improved by 0.62%. The proposed approaches also performed better than previous approaches examined in the related studies.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/sym15030582"
    },
    {
        "id": 22332,
        "title": "Machine and Deep Learning Based Detection of Attention Deficit Hyperactivity Disorder",
        "authors": "Gulay Cicek, Aydin Akan",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/asyu58738.2023.10296678"
    },
    {
        "id": 22333,
        "title": "Deep Reinforcement Learning Based Group Recommendation System with Multi-Head Attention Mechanism",
        "authors": "Saba Izadkhah, Banafsheh Reakbdar",
        "published": "2023-9-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/transai60598.2023.00038"
    },
    {
        "id": 22334,
        "title": "Attention-Based Mechanisms for Cognitive Reinforcement Learning",
        "authors": "Yue Gao, Di Li, Xiangjian Chen, Junwu Zhu",
        "published": "2023-6-21",
        "citations": 1,
        "abstract": "In this paper, we propose a cognitive reinforcement learning method based on an attention mechanism (CRL-CBAM) to address the problems of complex interactive communication, limited range, and time-varying communication topology in multi-intelligence collaborative work. The method not only combines the efficient decision-making capability of reinforcement learning, the representational capability of deep learning, and the self-learning capability of cognitive learning but also inserts a convolutional block attention module to increase the representational capability by using the attention mechanism to focus on important features and suppress unnecessary ones. The use of two modules, channel and spatial axis, to emphasize meaningful features in the two main dimensions can effectively aid the flow of information in the network. Results from simulation experiments show that the method has more rewards and is more efficient than other methods in formation control, which means a greater advantage when dealing with scenarios with a large number of agents. In group containment, the agents learn to sacrifice individual rewards to maximize group rewards. All tasks are successfully completed, even if the simulation scenario changes from the training scenario. The method can therefore be applied to new environments with effectiveness and robustness.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app13137361"
    },
    {
        "id": 22335,
        "title": "A Stock Prediction Model Based on CNN-BiLSTM and Multiple Attention Mechanisms",
        "authors": "Guojie Zhao, Pengwei Yuan",
        "published": "2023-7-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaml60083.2023.00049"
    },
    {
        "id": 22336,
        "title": "Deep Learning Segmentation Based Attention Mechanism Module for Navigation System",
        "authors": "Mainkordor Mawblei, Juwesh Binong",
        "published": "2023-3-16",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/i3cs58314.2023.10127365"
    },
    {
        "id": 22337,
        "title": "TRAFFIC VIOLATION AND DRIVER ATTENTION BASED SCORE CALCULATION USING DEEP LEARNING",
        "authors": "",
        "published": "2023-12-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.56726/irjmets46750"
    },
    {
        "id": 22338,
        "title": "Facial emotion-based students attention in online learning using deep learning",
        "authors": "Rajkumar Tekchandani, Parteek Kumar, Swadha Gupta",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1504/ijsem.2023.10060701"
    },
    {
        "id": 22339,
        "title": "Multi-Scale Learning with Attention-based UNet and Marginal Space Deep Ambiguity Transfer Learning for Lung Disease Prediction",
        "authors": "",
        "published": "2023-8-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.22266/ijies2023.0831.45"
    },
    {
        "id": 22340,
        "title": "Research on identification and classification of grassland forage based on deep learning and attention mechanisms",
        "authors": "Yilei Liu, Jiangping Liu, Xuanhe Zhao, Xin Pan, Weihong Yan",
        "published": "2023-7",
        "citations": 0,
        "abstract": "AbstractGrassland is an important resource for China's economic development and the main economic source of animal husbandry. The identification and classification of grassland forage is an important part of the improvement of forage varieties and the monitoring of germplasm resources, which can fundamentally solve the problems of poor forage quality and low reproduction rate. For the problem of low accuracy of forage identification and classification, the authors put forward a new 3DSECNN model to remove the preprocessing operation and directly study the images. The authors took forage hyperspectral image (HSI) images on the field and built dataset, used 3DSECNN to train the images to improve the classification effect. The outstanding contributions of this paper are: (1) The authors took high‐precision forage HSI images in the field, established a dedicated database of forage HSIs, and expanded the datasets; (2) the process of integrating preprocessing ideas into the network and replacing the traditional method of preprocessing the data and then extracting features; (3) proposing the 3DSECNN model, which adds SENet on the basis of the traditional 3DCNN, strengthens the correlation of the spatial dimension, selects the key features for the classification by calculating the channel weight, inhibits the unimportant information, and achieves the purpose of integrating the preprocessing ideas into the network. The experimental results show the overall accuracy (OA) of 3DSECNN is 94.36%, Precision, Recall, F1‐score, Kappa, and Time also showed good levels. The experimental results prove that the 3DSECNN strengthens the correlation between image channels, enhances the performance ability of features, and provides a new method for the identification and classification research of forage.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1049/ipr2.12808"
    },
    {
        "id": 22341,
        "title": "Deep Multi-Object Symbol Learning with Self-Attention Based Predictors",
        "authors": "Alper Ahmetoğlu, Erhan Öztop, Emre Uğur",
        "published": "2023-7-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/siu59756.2023.10223865"
    },
    {
        "id": 22342,
        "title": "Counting-based visual question answering with serial cascaded attention deep learning",
        "authors": "Tesfayee MeshuWelde, Lejian Liao",
        "published": "2023-12",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2023.109850"
    },
    {
        "id": 22343,
        "title": "Deep Learning Attention-Ranked Media Space Generation for Virtual Reality Equirectangular Scene Augmentation",
        "authors": "Joshua Bercich, Vera Chung, Xiaoming Chen",
        "published": "2023-9-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tensymp55890.2023.10223646"
    },
    {
        "id": 22344,
        "title": "Cross Model Attention based Deep Learning for Multi Modal Epilepsy Detection",
        "authors": "",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.22266/ijies2023.1031.07"
    },
    {
        "id": 22345,
        "title": "MoEAtt: A Deep Mixture of Experts Model using Attention-based Routing Gate",
        "authors": "Gal Blecher, Shai Fine",
        "published": "2023-12-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icmla58977.2023.00151"
    },
    {
        "id": 22346,
        "title": "Unmasking Depression via Attention-modulated Text Analysis using Deep Learning",
        "authors": "Prabhav Sanga, Jaskaran Singh, Prakhar Priyadarshi",
        "published": "2023-11-23",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccsai59793.2023.10421176"
    },
    {
        "id": 22347,
        "title": "A LSTM Deep Learning method with Attention Dense Mechanism for AQI prediction",
        "authors": "K. Kabilan, J. Jebathangam",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icscan58655.2023.10394883"
    },
    {
        "id": 22348,
        "title": "Deep Learning for Enterprise Sales Prediction: Haressing CNN-LSTM-Attention Model",
        "authors": "Yang Liu",
        "published": "2024-2-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eebda60612.2024.10485889"
    },
    {
        "id": 22349,
        "title": "ABC-KD: Attention-Based-Compression Knowledge Distillation for Deep Learning-Based Noise Suppression",
        "authors": "Yixin Wan, Yuan Zhou, Xiulian Peng, Kai-Wei Chang, Yan Lu",
        "published": "2023-8-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.21437/interspeech.2023-971"
    },
    {
        "id": 22350,
        "title": "Correction: Fati et al. Cyberbullying Detection on Twitter Using Deep Learning-Based Attention Mechanisms and Continuous Bag of Words Feature Extraction. Mathematics 2023, 11, 3567",
        "authors": "Suliman Mohamed Fati, Amgad Muneer, Ayed Alwadain, Abdullateef O. Balogun",
        "published": "2023-10-31",
        "citations": 0,
        "abstract": "In the original paper [...]",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/math11214494"
    },
    {
        "id": 22351,
        "title": "A New Spatio-Temporal Joint Attention-Based Deep Learning Model for Decoding Brain Cognition Function",
        "authors": "Yuhui Du, Yuliang Hou, Yu Zhang",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cac59555.2023.10451577"
    },
    {
        "id": 22352,
        "title": "CT-Based Super-Resolution Deep Learning Models with Attention Mechanisms for Predicting Spread Through Air Spaces of Solid or Part-Solid Lung Adenocarcinoma",
        "authors": "Shuxing Wang, Xiaowen Liu, Changsi Jiang, Wenyan Kang, Yudie Pan, Xue Tang, Yan Luo, Jingshan Gong",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.acra.2023.12.034"
    },
    {
        "id": 22353,
        "title": "Harnessing attention mechanisms in a comprehensive deep learning approach for induction motor fault diagnosis using raw electrical signals",
        "authors": "Thanh-Tung Vo, Meng-Kun Liu, Minh-Quang Tran",
        "published": "2024-3",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.engappai.2023.107643"
    },
    {
        "id": 22354,
        "title": "Incorporation of feature engineering and attention mechanisms into deep learning models to develop an early warning system for harmful algal blooms",
        "authors": "TaeHo Kim, Jihoon Shin, YoonKyung Cha",
        "published": "2023-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.jclepro.2023.137564"
    },
    {
        "id": 22355,
        "title": "Improving Plant Disease Recognition Through Gradient-Based Few-shot Learning with Attention Mechanisms",
        "authors": "Gültekin IŞIK",
        "published": "2023-9-1",
        "citations": 0,
        "abstract": "This study investigates the use of few-shot learning algorithms to improve classification performance in situations where traditional deep learning methods fail due to a lack of training data. Specifically, we propose a few-shot learning approach using the Almost No Inner Loop (ANIL) algorithm and attention modules to classify tomato diseases in the Plant Village dataset. The attended features obtained from the five separate attention modules are classified using a Multi Layer Perceptron (MLP) classifier, and the soft voting method is used to weigh the classification scores from each classifier. The results demonstrate that our proposed approach achieves state-of-the-art accuracy rates of 97.05% and 97.66% for 10-shot and 20-shot classification, respectively. Our approach demonstrates the potential for incorporating attention mechanisms in feature extraction processes and suggests new avenues for research in few-shot learning methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.21597/jist.1283491"
    },
    {
        "id": 22356,
        "title": "A novel deep learning graph attention network for Alzheimer’s disease image segmentation",
        "authors": "Md Easin Hasan, Amy Wagler",
        "published": "2024-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.health.2024.100310"
    },
    {
        "id": 22357,
        "title": "Deep residual learning with attention mechanism for breast cancer classification",
        "authors": "Chean Khim Toa, Mahmoud Elsayed, Kok Swee Sim",
        "published": "2023-8-31",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00500-023-09152-2"
    },
    {
        "id": 22358,
        "title": "An Enhanced Dueling Double Deep Q-Network With Convolutional Block Attention Module for Traffic Signal Optimization in Deep Reinforcement Learning",
        "authors": "Peng Wang, Wenlong Ni",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2024.3380454"
    },
    {
        "id": 22359,
        "title": "A novel attention-based feature learning and optimal deep learning approach for network intrusion detection",
        "authors": "K. Sakthi, P. Nirmal Kumar",
        "published": "2023-8-24",
        "citations": 2,
        "abstract": "Rapid technological advances and network progress has occurred in recent decades, as has the global growth of services via the Internet. Consequently, piracy has become more prevalent, and many modern systems have been infiltrated, making it vital to build information security tools to identify new threats. An intrusion detection system (IDS) is a critical information security technology that detects network fluctuations with the help of machine learning (ML) and deep learning (DL) approaches. However, conventional techniques could be more effective in dealing with advanced attacks. So, this paper proposes an efficient DL approach for network intrusion detection (NID) using an optimal weight-based deep neural network (OWDNN). The network traffic data was initially collected from three openly available datasets: NSL-KDD, CSE-CIC-IDS2018 and UNSW-NB15. Then preprocessing was carried out on the collected data based on missing values imputation, one-hot encoding, and normalization. After that, the data under-sampling process is performed using the butterfly-optimized k-means clustering (BOKMC) algorithm to balance the unbalanced dataset. The relevant features from the balanced dataset are selected using inception version 3 with multi-head attention (IV3MHA) mechanism to reduce the computation burden of the classifier. After that, the dimensionality of the selected feature is reduced based on principal component analysis (PCA). Finally, the classification is done using OWDNN, which classifies the network traffic as normal and anomalous. Experiments on NSL-KDD, CSE-CIC-IDS2018 and UNSW-NB15 datasets show that the OWDNN performs better than the other ID methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/jifs-231758"
    },
    {
        "id": 22360,
        "title": "A deep learning approach using attention mechanism and transfer learning for electromyographic hand gesture estimation",
        "authors": "Yanyu Wang, Pengfei Zhao, Zhen Zhang",
        "published": "2023-12",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.121055"
    },
    {
        "id": 22361,
        "title": "Deep Learning Based on Attention in Semantic Segmentation: An Introductory Survey",
        "authors": "",
        "published": "2023-3-30",
        "citations": 0,
        "abstract": "Semantic segmentation refers to labeling each pixel in the scene to its belonging object. It is a critical task for many computer vision applications that requires scene understanding because  It attempts to mimic human perceptual grouping. Despite the unremitting efforts in this field, it is still a challenge and preoccupies of researchers. Semantic segmentation performance improved using deep learning rather than traditional methods. Semantic segmentation based on deep learning models requires capturing local and global context information, where deep learning models usually can extract one of them but is challenging to integrate between them. Deep learning based on attention mechanisms can gather between the capturing of local and glopal information, so it is increasingly employed in semantic segmentation. This paper gives an introductory survey of the rising topic attention mechanisms in semantic segmentation. At first, it will discuss the concept of attention and its integration with semantic segmentation requirements. Then, it will review deep learning based on attention mechanisms in semantic segmentation.\n\nIndex Terms— attention concept, computer vision, deep learning, semantic segmentation.",
        "keywords": "",
        "link": "http://dx.doi.org/10.33103/uot.ijccce.23.1.9"
    },
    {
        "id": 22362,
        "title": "Retracted: A Deep Learning Approach for a Source Code Detection Model Using Self-Attention",
        "authors": " Complexity",
        "published": "2024-1-24",
        "citations": 0,
        "abstract": "",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2024/9761251"
    },
    {
        "id": 22363,
        "title": "Domain Adaptation based on Attention-Weighted Optimal Transport and Cluster Alignment",
        "authors": "Yanan Zhu, Yangyang Qi",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10165976"
    },
    {
        "id": 22364,
        "title": "A Deep Learning Seismic Processing Framework Based on Pre-Training: Giving the Dataset the Attention It Needs",
        "authors": "T. Alkhalifah, R. Harsuko",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3997/2214-4609.202332088"
    },
    {
        "id": 22365,
        "title": "Attention driven CWT-deep learning approach for discrimination of Radar PRI modulation",
        "authors": "Purabi Sharma, Kandarpa Kumar Sarma",
        "published": "2024-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.phycom.2023.102237"
    },
    {
        "id": 22366,
        "title": "Chinese review sentiment analysis based on deep learning and attention mechanism",
        "authors": "Wenjie Hu",
        "published": "2023-2-6",
        "citations": 0,
        "abstract": "With the development of the Internet and the continuous growth of the number of netizens, more and more people publish their attitudes and emotions on products, services, etc. on the Internet, accumulating a large number of comments containing personal opinions. The sentiment analysis of text reviews is of great significance to explore the emotional tendencies of users and help merchants adjust product positioning and marketing strategies in a timely manner. The deep learning framework adopts CNN and LSTM models respectively to introduce the attention mechanism for sentiment classification. The effects of CNN model and LSTM model on sentiment classification in Weibo comments were analyzed. From the experimental data, after the same number of iterations, the accuracy of the CNN model reaches 97.94%, and the accuracy of the LSTM model reaches 98.18%. The experimental results show that LSTM is better than CNN in the sentiment classification of Weibo comments.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/jceim.v10i1.5073"
    },
    {
        "id": 22367,
        "title": "Emotion Intensity Detection in Online Media: An Attention Mechanism Based Multimodal Deep Learning Approach",
        "authors": "",
        "published": "2024-4-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.17559/tv-20230628001154"
    },
    {
        "id": 22368,
        "title": "SPECT bone scan image classification by fusing multi-attention mechanism with deep residual networks",
        "authors": "Qianyu Feng, Yongchun Cao, Qiang Lin, Zhengxing Man, Yang He, ChengYang Liu",
        "published": "2023-5-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10165843"
    },
    {
        "id": 22369,
        "title": "Multi-granularity fusion resource allocation algorithm based on dual-attention deep reinforcement learning and lifelong learning architecture in heterogeneous IIoT",
        "authors": "Ying Wang, Fengjun Shang, Jianjun Lei",
        "published": "2023-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.inffus.2023.101871"
    },
    {
        "id": 22370,
        "title": "Accurate detection of coronavirus cases using deep learning with attention mechanism and genetic algorithm",
        "authors": "Ahmet Kara",
        "published": "2024-3-8",
        "citations": 0,
        "abstract": "AbstractThe novel coronavirus disease has caused severe threats to the daily life and health of people all over the world. Hence, early detection and timely treatment of this disease are significant to prevent the coronavirus's spread and ensure more effective patient care. This work adopted an integrated framework comprising deep learning and attention mechanism to provide a more effective and reliable diagnosis. This framework consists of two convolution neural network (CNN), a bidirectional LSTM, two fully-connected layers (FCL), and an attention mechanism. The main aim of the proposed framework is to reveal a promising approach based on deep learning for early and timely detection of coronavirus disease. For greater accuracy, the framework's hyperparameters are tuned by means of a genetic algorithm. The effectiveness of the proposed framework has been examined utilizing a public dataset including 18 different blood findings from Albert Einstein Israelita Hospital in Sao Paulo, Brazil. Additionally, within the experimental studies, the proposed framework is subjected to comparison with the state-of-the-art techniques, evaluated across various metrics. Based on the derived consequences, the proposed framework has yielded enhancements in accuracy, recall, precision, and F1-score, registering approximate improvements of 1.27%, 4.07%, 3.20%, and 2.88%, respectively, as measured against the second-best rates.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-024-18850-4"
    },
    {
        "id": 22371,
        "title": "Stocastic Multimodal Fusion Method for Classifying Emotions With Attention Mechanism Using Deep Learning",
        "authors": "R. Selvi, C. Vijayakumaran",
        "published": "2023-3-17",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icaccs57279.2023.10113124"
    },
    {
        "id": 22372,
        "title": "Attention-based Deep Learning Approaches in Brain Tumor Image Analysis: A Mini Review",
        "authors": "Mohammadreza Saraei, Sidong Liu",
        "published": "2023-10-29",
        "citations": 0,
        "abstract": "Introduction: Accurate diagnosis is crucial for brain tumors, given their low survival rates and high treatment costs. However, traditional methods relying on manual interpretation of medical images are time-consuming and prone to errors. Attention-based deep learning, utilizing deep neural networks to selectively focus on relevant features, offers a promising solution.Material and Methods: This paper presents an overview of recent advancements in attention-based deep learning for brain tumor image analysis. While the reviewed models have demonstrated respectable performance across different datasets, they have yet to achieve state-of-the-art results.Results: Advanced techniques, including super-resolution image reconstruction, multi-swin-transformer blocks, and spatial group-wise enhanced attention blocks, have shown improved segmentation network performance. Integration of graph attention, swin-transformer, and gradient awareness minimization with positional attention convolution blocks, self-attention blocks, and intermittent fully connected layers has considerably enhanced the efficiency of classification networks.Conclusion: While attention-based deep learning has shown improvements in performance, challenges persist. These challenges include the requirement for large datasets, resource limitations, accurate segmentation of irregularly shaped tumors, and high computational demands. Future studies should address these challenges to further enhance the efficiency of brain tumor diagnoses in real-world settings.",
        "keywords": "",
        "link": "http://dx.doi.org/10.30699/fhi.v12i0.493"
    },
    {
        "id": 22373,
        "title": "YOGA: Deep object detection in the wild with lightweight feature learning and multiscale attention",
        "authors": "Raja Sunkara, Tie Luo",
        "published": "2023-7",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.patcog.2023.109451"
    },
    {
        "id": 22374,
        "title": "Multi‐Scale Attention‐Enhanced Deep Learning Model for Ionogram Automatic Scaling",
        "authors": "Li Guo, Jiarong Xiong",
        "published": "2023-3",
        "citations": 0,
        "abstract": "AbstractTo increase the accuracy of ionogram automatic scaling, a deep learning model—multi‐scale attention‐enhanced UNet is proposed. Correspondingly, a multi‐scale attention‐enhanced (MSAE) sub‐network is developed which involves a spatial attention nearest up‐sampling module and several residual channel attention modules with multi‐scale skip connections. They contribute to multi‐scale feature fusion and augmentation of the learning ability for enhancing faint and elongated profile traces of ionograms. The MSAE sub‐network input consists of multi‐scale feature maps which could be optimally employed to make the network effectively utilize useful information from the encoders and decoders. Incidentally, a dual channel spatial attention block is embedded between the encoder and the decoder for deeper detail extraction. When the proposed model is applied to scale different electron density profiles of ionograms based on an open data set, the experimental results show the segmentation performance evaluation indexes: the precision and the recall rate can be improved by 6.9% and 26.1%, respectively, compared to automatic real‐time ionogram scaling with true‐height routine. Another set of indexes: the mean intersection over union and the F‐score are superior to that of other several contrasted deep learning models, which can be improved by 3% and 1.6%, respectively, compared to the original UNet model.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1029/2022rs007566"
    },
    {
        "id": 22375,
        "title": "Deep learning applied to EEG data with different montages using spatial attention",
        "authors": "Dung Truong, Muhammad Abdullah Khalid, Arnaud Delorme",
        "published": "2023-12-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/bibm58861.2023.10385525"
    },
    {
        "id": 22376,
        "title": "Image steganalysis algorithm based on deep learning and attention mechanism for computer communication",
        "authors": "Huan Li, Shi Dong",
        "published": "2024-1-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/1.jei.33.1.013015"
    },
    {
        "id": 22377,
        "title": "PT-MVSNet: Overlapping Attention Multi-view Stereo Network with Transformers",
        "authors": "Song Zhang, Lin Li, Jiangxuan Qiao",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10167367"
    },
    {
        "id": 22378,
        "title": "Deep Learning of Automatic Encoder Based on Attention for ADHD Classification of Brain MRI",
        "authors": "Nan Chen, Yun Jiao",
        "published": "2023-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icbea58866.2023.00010"
    },
    {
        "id": 22379,
        "title": "Dual-Attention Deep Reinforcement Learning for Multi-MAP 3D Trajectory Optimization in Dynamic 5G Networks",
        "authors": "Esteban Catté, Mohamed Sana, Mickael Maman",
        "published": "2023-5-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icc45041.2023.10278657"
    },
    {
        "id": 22380,
        "title": "Email spam detection using hierarchical attention hybrid deep learning method",
        "authors": "Sultan Zavrak, Seyhmus Yilmaz",
        "published": "2023-12",
        "citations": 8,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.eswa.2023.120977"
    },
    {
        "id": 22381,
        "title": "Attention Guided Deep Learning for CSI Compression and Feedback",
        "authors": "Wencai Shan, Chongwen Huang, Chen Zhu, Qianqian Yang, Zhaohui Yang",
        "published": "2023-10-20",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icct59356.2023.10419429"
    },
    {
        "id": 22382,
        "title": "Attention based morphological guided deep learning network for neuron segmentation in electron microscopy",
        "authors": "Maryam Imani, Amin Zehtabian",
        "published": "2024-3-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11227-024-06005-z"
    },
    {
        "id": 22383,
        "title": "Enhanced fingerprint pattern classification: Integrating attention modules with lightweight deep learning models",
        "authors": "Esther Mukoya, Richard Rimiru, Michael Kimwele",
        "published": "2024-4-15",
        "citations": 0,
        "abstract": "AbstractLarge fingerprint databases can make the automated search process tedious and time‐consuming. Fingerprint pattern classification is a significant step in the identification system's complexity in terms of time and speed. Although several fingerprint algorithms have been developed for classification tasks, further improvements in performance and efficiency are still required. Most of the fingerprint algorithms use deep learning techniques. However, some deep learning techniques can be resource‐intensive and computationally expensive, while others can disregard the spatial relationships between the features used in classifying fingerprint patterns. This study proposes using lightweight deep learning models (i.e., MobileNet and EfficientNet‐B0) integrated with attention modules to classify fingerprint patterns. The two lightweight models are modified, yielding MobileNet+ and EfficientNet‐B0+ models. The lightweight deep learning models can help achieve optimal performance and reduce computational complexity. The attention modules focus on distinctive features for classification. Our proposed approach integrates four attention modules for fingerprint pattern classification into two lightweight deep learning models, that is, MobileNet+ and EfficientNet‐B0+. To evaluate our approach, we use two publicly available fingerprint datasets, that is, the NIST special database 301 dataset and the LivDet dataset. The evaluation results show that the EfficientNet‐B0+ model achieves the highest classification accuracy of 97% with only 854,086 training parameters. As a conclusion, we consider the training parameters small enough for the EfficientNet‐B0+ model to be deployed on low‐resource devices.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/eng2.12897"
    },
    {
        "id": 22384,
        "title": "Deep Learning-Based Attention Mechanism for Automatic Drowsiness Detection Using EEG Signal",
        "authors": "Chiranjevulu Divvala, Madhusudhan Mishra",
        "published": "2024-3",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/lsens.2024.3363735"
    },
    {
        "id": 22385,
        "title": "Deep LSTM and LSTM-Attention Q-learning based reinforcement learning in oil and gas sector prediction",
        "authors": "David Opeoluwa Oyewola, Sulaiman Awwal Akinwunmi, Temidayo Oluwatosin Omotehinwa",
        "published": "2024-1",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2023.111290"
    },
    {
        "id": 22386,
        "title": "Offloading Mechanisms Based on Reinforcement Learning and Deep Learning Algorithms in the Fog Computing Environment",
        "authors": "Dezheen H. Abdulazeez, Shavan K. Askar",
        "published": "2023",
        "citations": 12,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3241881"
    },
    {
        "id": 22387,
        "title": "Diagnosis of attention deficit hyperactivity disorder: A deep learning approach",
        "authors": "Nizar Alsharif, Mosleh Hmoud Al-Adhaileh, Mohammed Al-Yaari",
        "published": "2024",
        "citations": 0,
        "abstract": "<abstract>\n\n<p>In recent years, there has been significant interest in the analysis and classification of brain dis-orders using electroencephalography (EEG). We presented machine learning and deep learning (DL) frameworks that integrate an EEG-based brain network with various DL models to diagnose attention deficit hyperactivity disorder (ADHD). By incorporating an objective biomarker into the diagnostic process, the accuracy and effectiveness of diagnosis could be enhanced. We used public EEG datasets from 61 ADHD youngsters and 60 normally developing children. The raw EEG data underwent preprocessing, including the application of filters in clinically relevant frequency bands and notch filters. From the preprocessed EEG segments, statistical features (e.g., standard deviation, kurtosis) and spectral features (e.g., entropy) were extracted. Principal component analysis (PCA) and chi-square with PCA were used as feature selection methods to obtain the most useful features and keep them. The machine learning models achieved the highest accuracy result of 94.86% by utilizing support vector machines (SVM) with PCA features. Furthermore, integrating models combining a convolutional neural network (CNN) with bidirectional long short-term memory (BiLSTM) networks, and gated recurrent unit-Transformer (GRU-Transformer block) with Chi-square and PCA features achieved accuracies of 94.50% and 95.59%, respectively. The suggested framework demonstrated a wide range of applicability in addressing the identification of ADHD. To evaluate the performance of the proposed models, comparisons were made with existing models, and the proposed system exhibited superior performance. We enhanced EEG-based analysis and categorization of ADHD by demonstrating the capabilities of advanced artificial intelligence models in enhancing diagnostic accuracy and efficacy.</p>\n\n       </abstract>",
        "keywords": "",
        "link": "http://dx.doi.org/10.3934/math.2024517"
    },
    {
        "id": 22388,
        "title": "Lightweight modified attention based deep learning model for cassava leaf diseases classification",
        "authors": "Anand Shanker Tewari, Priya Kumari",
        "published": "2023-12-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-17459-3"
    },
    {
        "id": 22389,
        "title": "Fusion of Deep Learning Models with Attention for Multi-Resident Activity Recognition in Ambient Assisted Living",
        "authors": "Hafiz Safdar Sultan, Labiba Gillani Fahad",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.2139/ssrn.4381248"
    },
    {
        "id": 22390,
        "title": "Cross-Image-Attention for Conditional Embeddings in Deep Metric Learning",
        "authors": "Dmytro Kotovenko, Pingchuan Ma, Timo Milbich, Björn Ommer",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvpr52729.2023.01065"
    },
    {
        "id": 22391,
        "title": "Energy Efficient VNF-FG Embedding via Attention-Based Deep Reinforcement Learning",
        "authors": "Omar Houidi, Oussama Soualah, Ines Houidi, Djamal Zeghlache",
        "published": "2023-10-30",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/cnsm59352.2023.10327825"
    },
    {
        "id": 22392,
        "title": "Radar Human Activity Recognition with an Attention-Based Deep Learning Network",
        "authors": "Sha Huan, Limei Wu, Man Zhang, Zhaoyue Wang, Chao Yang",
        "published": "2023-3-16",
        "citations": 6,
        "abstract": "Radar-based human activity recognition (HAR) provides a non-contact method for many scenarios, such as human–computer interaction, smart security, and advanced surveillance with privacy protection. Feeding radar-preprocessed micro-Doppler signals into a deep learning (DL) network is a promising approach for HAR. Conventional DL algorithms can achieve high performance in terms of accuracy, but the complex network structure causes difficulty for their real-time embedded application. In this study, an efficient network with an attention mechanism is proposed. This network decouples the Doppler and temporal features of radar preprocessed signals according to the feature representation of human activity in the time–frequency domain. The Doppler feature representation is obtained in sequence using the one-dimensional convolutional neural network (1D CNN) following the sliding window. Then, HAR is realized by inputting the Doppler features into the attention-mechanism-based long short-term memory (LSTM) as a time sequence. Moreover, the activity features are effectively enhanced using the averaged cancellation method, which improves the clutter suppression effect under the micro-motion conditions. Compared with the traditional moving target indicator (MTI), the recognition accuracy is improved by about 3.7%. Experiments based on two human activity datasets confirm the superiority of our method compared to traditional methods in terms of expressiveness and computational efficiency. Specifically, our method achieves an accuracy close to 96.9% on both datasets and has a more lightweight network structure compared to algorithms with similar recognition accuracy. The method proposed in this article has great potential for real-time embedded applications of HAR.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23063185"
    },
    {
        "id": 22393,
        "title": "A deep learning approach incorporating attention mechanism and transfer learning for lithium-ion battery lifespan prediction",
        "authors": "Wanjie Zhao, Wei Ding, Shujing Zhang, Zhen Zhang",
        "published": "2024-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.est.2023.109647"
    },
    {
        "id": 22394,
        "title": "Implicit and explicit attention mechanisms for zero-shot learning",
        "authors": "Faisal Alamri, Anjan Dutta",
        "published": "2023-5",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.neucom.2023.03.009"
    },
    {
        "id": 22395,
        "title": "Enhancing Deep Learning and Computer Image Analysis in Petrography through Artificial Self-Awareness Mechanisms",
        "authors": "Paolo Dell’Aversana",
        "published": "2024-2-28",
        "citations": 0,
        "abstract": "In this paper, we discuss the implementation of artificial self-awareness mechanisms and self-reflection abilities in deep neural networks. While the current limitations of research prevent achieving cognitive capabilities on par with natural biological entities, the incorporation of basic self-awareness and self-reflection mechanisms in deep learning architectures offers substantial advantages in tackling specific problems across various scientific fields, including geosciences. In the first section, we outline the foundational architecture of our deep learning approach termed Self-Aware Learning (SAL). The subsequent part of the paper highlights the practical benefits of this machine learning methodology through synthetic tests and applications addressed to automatic classification and image analysis of real petrological data sets. We show how Self-Aware Learning allows enhanced accuracy, reduced overfitting problems, and improved performances compared to other existing methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/min14030247"
    },
    {
        "id": 22396,
        "title": "Cyclic Code Word Embedding and Chi-Squared Test-Based Attention Mechanism for Deep Learning-Based Server Fault Detection*",
        "authors": "Yiyang Xiong, Shilei Dong",
        "published": "2023-6-19",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iwcmc58020.2023.10182514"
    },
    {
        "id": 22397,
        "title": "Hierarchical Multi-Agent Deep Reinforcement Learning with an Attention-based Graph Matching Approach for Multi-Domain VNF-FG Embedding",
        "authors": "Lotfi Slim, Fetia Bannour",
        "published": "2023-12-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/globecom54140.2023.10437970"
    },
    {
        "id": 22398,
        "title": "Multi-Agent attention-based deep reinforcement learning for demand response in grid-responsive buildings",
        "authors": "Jiahan Xie, Akshay Ajagekar, Fengqi You",
        "published": "2023-7",
        "citations": 11,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.apenergy.2023.121162"
    },
    {
        "id": 22399,
        "title": "Research on BiLSTM-GRU Water Quality Prediction Model Based on Attention Mechanism",
        "authors": "Jundong Zhang, Shilong Xue, Pan Geng",
        "published": "2023-5-12",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10166713"
    },
    {
        "id": 22400,
        "title": "Deep Learning-based Viewpoint Prediction Model and Influencing Attention Factors for Design Drawings",
        "authors": "Bai Liu",
        "published": "2023-2-24",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/nnice58320.2023.10105774"
    },
    {
        "id": 22401,
        "title": "Use of Attention Mechanism for Decoder in Deep Learning-based Image Super Resolution",
        "authors": "Hyeongyu Kim, Byungchan Choi, Haewoon Nam",
        "published": "2023-10-11",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ictc58733.2023.10393268"
    },
    {
        "id": 22402,
        "title": "A Self-attention based Deep Learning Model for Hurricane Nowcasting",
        "authors": "Shun Yao, Haonan Chen, V. Chandrasekar",
        "published": "2023-1-10",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/usnc-ursinrsm57470.2023.10043145"
    },
    {
        "id": 22403,
        "title": "Attention-Based Deep Learning Modelling for Intrusion Detection",
        "authors": "Ban AlOmar, Zouheir Trabelsi, Firas Saidi",
        "published": "2023-6-19",
        "citations": 0,
        "abstract": "Cyber-attacks are becoming increasingly sophisticated, posing more significant challenges to traditional intrusion detection methods. The inability to prevent intrusions could compromise the credibility of security services, thereby putting data confidentiality, integrity, and availability at risk. In response to this problem, research has been conducted to apply deep learning (DL) models to intrusion detection, leveraging the new era of AI and the proven efficiency of DL in many fields. This study proposes a new intrusion detection system (IDS) based on DL, utilizing attention-based long short-term memory (AT-LSTM) and attention-based bidirectional LSTM (AT-BiLSTM) models. The time-series nature of network traffic data, which changes continuously over time, makes LSTM and BiLSTM particularly effective in handling intrusion detection. These models can capture long-term dependencies in the sequence of events, learn the patterns of normal network behaviour, and detect deviations from this behaviour that may indicate an intrusion. Also, the attention mechanism in the proposed models lets them make predictions based on the most important parts of the network traffic data. This is important for finding intrusions because network traffic data can have many different features, not all of which are important for finding an attack. The attention mechanism lets the models learn which features are most important for making accurate predictions, which improves their performance and efficiency. The UNSW-NB15 benchmark dataset is used in the study to measure and compare the effectiveness and reliability of the proposed system. This dataset contains normal and attack traffic data with a significant class imbalance. To address this issue, the study employs the Synthetic Minority Over-sampling Technique (SMOTE) to balance the dataset, thus reducing the risk of overfitting to the majority class and improving the model's performance in detecting attacks. The performance evaluation results demonstrate that the proposed models achieved a detection rate of over 93%, indicating high precision in detecting intrusions. By harnessing the power of deep learning, these models can learn and adapt to new threats over time, thus ensuring data confidentiality, integrity, and availability in today's interconnected world.",
        "keywords": "",
        "link": "http://dx.doi.org/10.34190/eccws.22.1.1172"
    },
    {
        "id": 22404,
        "title": "The Source Code Comment Generation Based on Deep Reinforcement Learning and Hierarchical Attention",
        "authors": "Daoyang Ming, Weicheng Xiong",
        "published": "2023-11-21",
        "citations": 0,
        "abstract": " Code summarization provides the main aim described in natural language of the given function, it can benefit many tasks in software engineering. Due to the special grammar and syntax structure of programming languages and various shortcomings of different deep neural networks, the accuracy of existing code summarization approaches is not good enough. This work proposes to adopt the hierarchical attention mechanism to enable the code summarization framework to translate three representations of source code to the hidden spce and then it injects them into a deep reinforcement learning model to enhance the performance of code summarization. We conduct a few of experiments, and the results of which prove that the proposed approaches can obtain better accuracy compared with the baseline approaches.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54097/ajst.v8i1.13993"
    },
    {
        "id": 22405,
        "title": "Deep Learning-Assisted Iris Liveness Detection Mechanisms",
        "authors": "Zeenat Zahra, Arvind Selwal, Deepika Sharma",
        "published": "2023-6-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ecai58194.2023.10194066"
    },
    {
        "id": 22406,
        "title": "Attention deficit hyperactivity disorder detection using deep learning approach",
        "authors": "Md Abrar Hamim, F.M. Tanmoy, Orin Tasfia, Farzana Alam Juthi",
        "published": "2023-7-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icccnt56998.2023.10306955"
    },
    {
        "id": 22407,
        "title": "Camouflage object segmentation based on feature extraction and mixed attention",
        "authors": "ZeYao Zhang, Li Cui",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2679267"
    },
    {
        "id": 22408,
        "title": "Efficient Course Recommendation using Deep Transformer based Ensembled Attention Model",
        "authors": "A Madhavi, A Nagesh, A Govardhan",
        "published": "2023-12-20",
        "citations": 0,
        "abstract": "The exponential development of online learning resources has led to an information overload problem. Therefore, recommender systems play a crucial role in E-learning to provide learners with personalised course recommendations by automatically identifying their preferences. In addition, e-Learning platforms such as MOOCs and LMS have been criticised for their low course completion rates, and one of the primary reasons is that they do not provide personalised course recommendations for users with varying interests. Rapidly locating the courses that users are interested in on enormous e-Learning platforms can have a significant impact on the quality of learning and the dissemination of knowledge to the learner. This paper examines the most prevalent recommendation techniques utilised in E-learning.  We examined how to apply Deep Transformer based Ensembled Attention Model (DTEAM) on e-Learning system in order to achieve personalized course recommendations.  The proposed recommendation model uses BERT as its foundation integrated MLM and Transformers. Predicted course recommendations are more aligned with the interests of users. Our experimental results proved that traditional recommendation algorithms, such as collaborative filtering and item-based filtering are incapable of producing superior results. The consequence of the research can assist students in selecting courses according to their preferences and improve their learning caliber",
        "keywords": "",
        "link": "http://dx.doi.org/10.4108/eetel.4470"
    },
    {
        "id": 22409,
        "title": "Research on Human Body Features Extraction based on Attention Mechanism",
        "authors": "Yuheng Wu, Liangyu Wu, Hao Feng, Lei Kong",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10165806"
    },
    {
        "id": 22410,
        "title": "A Detailed Examination of Deep Learning Models for Detection of Attention Deficit Hyperactivity Disorder(ADHD)",
        "authors": "Zarina Begum, Kareemulla Shaik",
        "published": "2023-12-14",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icrtac59277.2023.10480856"
    },
    {
        "id": 22411,
        "title": "A gait recognition method based on deep learning and attention transformer",
        "authors": "Zhili Lu, Xiuqing Mao",
        "published": "2023-12-21",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.3012246"
    },
    {
        "id": 22412,
        "title": "Depression detection using cascaded attention based deep learning framework using speech data",
        "authors": "Sachi Gupta, Gaurav Agarwal, Shivani Agarwal, Dilkeshwar Pandey",
        "published": "2024-1-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-18076-w"
    },
    {
        "id": 22413,
        "title": "Combining attention mechanism and Feature Selection Module for Real-time semantic segmentation",
        "authors": "Jiakun Chen, Yan Wei, Yu Xie",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10167275"
    },
    {
        "id": 22414,
        "title": "Skin Cancer Classification with Channel Attention and SMOTE Sampling: A Deep Learning Approach",
        "authors": "Mohammad Mahbub, Sk. Md. Masudul Ahsan",
        "published": "2023-12-7",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/eict61409.2023.10427872"
    },
    {
        "id": 22415,
        "title": "Multimodal sentiment analysis based on multiple attention mechanisms",
        "authors": "Zixuan Jin, Changbo Xu, Shaozhong Cao, Yi Liu",
        "published": "2023-10-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3640912.3640957"
    },
    {
        "id": 22416,
        "title": "Scale-arbitrary Infrared Super-resolution Network based on Channel Attention Mechanisms",
        "authors": "Qi Shao, Xin Zheng, Shinan Lang, Yuchen Zheng",
        "published": "2023-8-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/prml59573.2023.10348211"
    },
    {
        "id": 22417,
        "title": "RNN-Attention Based Deep Learning for Solving Inverse Boundary Problems in Nonlinear Marshak Waves",
        "authors": "Di Zhao, Weiming Li, Wengu Chen, Peng Song null, Han Wang",
        "published": "2023-6",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.4208/jml.221209"
    },
    {
        "id": 22418,
        "title": "A Dual Attention Network for Multimodal Remote Sensing Image Matching",
        "authors": "Kaiyang Han, Fanzhi Cao, Tianxin Shi, Pu Wang",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10166096"
    },
    {
        "id": 22419,
        "title": "Online scheduling of coflows by attention-empowered scalable deep reinforcement learning",
        "authors": "Xin Wang, Hong Shen",
        "published": "2023-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.future.2023.04.020"
    },
    {
        "id": 22420,
        "title": "An evolutionary approach for depression detection from Twitter big data using a novel deep learning model with attention based feature learning mechanism",
        "authors": "Prabhakar K, Kavitha V",
        "published": "2024-4-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1080/00051144.2023.2296793"
    },
    {
        "id": 22421,
        "title": "WDA: Estimation of Travel Time for Taxi Using Wide and Deep Learning Together with Target Attention",
        "authors": "Yuxing Wang",
        "published": "2023-3-22",
        "citations": 0,
        "abstract": "There is an increasing interest in ways to use data and machine learning methods to optimize the operation of transportation system. In this paper, the author focuses on estimation of time arrival (ETA) for taxi. As taxi is one of the popular transportation vehicles in the urban area, predicting the time of arrival for taxi would help the customer to better estimate time required for the trip, especially in case of urgencies. The author develops a comprehensive neural network with both wide and deep components, and attention component for this predictive job. The author also evaluates the network with huge historic data and compare it with industry existing solutions. This network model is proven to have a better prediction accuracy under extreme traffic and weather condition with reasonable shorter training time.",
        "keywords": "",
        "link": "http://dx.doi.org/10.54254/2755-2721/2/20220670"
    },
    {
        "id": 22422,
        "title": "ARiADNE: A Reinforcement learning approach using Attention-based Deep Networks for Exploration",
        "authors": "Yuhong Cao, Tianxiang Hou, Yizhuo Wang, Xian Yi, Guillaume Sartoretti",
        "published": "2023-5-29",
        "citations": 5,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icra48891.2023.10160565"
    },
    {
        "id": 22423,
        "title": "High-Throughput Spike Detection in Greenhouse Cultivated Grain Crops with Attention Mechanisms-Based Deep Learning Models",
        "authors": "Sajid Ullah, Klára Panzarová, Martin Trtílek, Matej Lexa, Vojtěch Máčala, Kerstin Neumann, Thomas Altmann, Jan Hejátko, Markéta Pernisová, Evgeny Gladilin",
        "published": "2024-1",
        "citations": 0,
        "abstract": "Detection of spikes is the first important step toward image-based quantitative assessment of crop yield. However, spikes of grain plants occupy only a tiny fraction of the image area and often emerge in the middle of the mass of plant leaves that exhibit similar colors to spike regions. Consequently, accurate detection of grain spikes renders, in general, a non-trivial task even for advanced, state-of-the-art deep neural networks (DNNs). To improve pattern detection in spikes, we propose architectural changes to Faster-RCNN (FRCNN) by reducing feature extraction layers and introducing a global attention module. The performance of our extended FRCNN-A vs. conventional FRCNN was compared on images of different European wheat cultivars, including “difficult” bushy phenotypes from 2 different phenotyping facilities and optical setups. Our experimental results show that introduced architectural adaptations in FRCNN-A helped to improve spike detection accuracy in inner regions. The mean average precision (mAP) of FRCNN and FRCNN-A on inner spikes is 76.0% and 81.0%, respectively, while on the state-of-the-art detection DNNs, Swin Transformer mAP is 83.0%. As a lightweight network, FRCNN-A is faster than FRCNN and Swin Transformer on both baseline and augmented training datasets. On the FastGAN augmented dataset, FRCNN achieved a mAP of 84.24%, FRCNN-A attained a mAP of 85.0%, and the Swin Transformer achieved a mAP of 89.45%. The increase in mAP of DNNs on the augmented datasets is proportional to the amount of the IPK original and augmented images. Overall, this study indicates a superior performance of attention mechanisms-based deep learning models in detecting small and subtle features of grain spikes.",
        "keywords": "",
        "link": "http://dx.doi.org/10.34133/plantphenomics.0155"
    },
    {
        "id": 22424,
        "title": "An attention-enhanced neural network with distillation training for barcode detection",
        "authors": "Zijian Wang, Zhiyuan Su",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2678979"
    },
    {
        "id": 22425,
        "title": "Human attention detection system using deep learning and brain–computer interface",
        "authors": "S. Anju Latha Nair, Rajesh Kannan Megalingam",
        "published": "2024-3-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s00521-024-09628-8"
    },
    {
        "id": 22426,
        "title": "Attention aware fully convolutional deep learning model for retinal blood vessel segmentation",
        "authors": "C. Gobinath, M.P. Gopinath",
        "published": "2023-4-3",
        "citations": 0,
        "abstract": "Recent reports indicate a rise in retinal issues, and automatic artery vein categorization offers data that is particularly instructive for the medical evaluation of serious retinal disorders including glaucoma and diabetic retinopathy. This work presents a competent and precise deep-learning model designed for vessel segmentation in retinal fundus imaging. This article aims to segment the retinal images using an attention-based dense fully convolutional neural network (A-DFCNN) after removing uncertainty. The artery extraction layers encompass vessel-specific convolutional blocks to focus the tiny blood vessels and dense layers with skip connections for feature propagation. Segmentation is associated with artery extraction layers via individual loss function. Blood vessel maps produced from individual loss functions are authenticated for performance. The proposed technique attains improved outcomes in terms of Accuracy (0.9834), Sensitivity (0.8553), and Specificity (0.9835) from DRIVE, STARE, and CHASE-DB1 datasets. The result demonstrates that the proposed A-DFCNN is capable of segmenting minute vessel bifurcation breakdowns during the training and testing phases.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/jifs-224229"
    },
    {
        "id": 22427,
        "title": "Classification Of Chest X-ray Images Of Covid-19 By Deep Learning Based CNN Model and Attention Mechanism",
        "authors": "Amishi Agrawal",
        "published": "2023-5-5",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/incacct57535.2023.10141775"
    },
    {
        "id": 22428,
        "title": "Self-attention transformer unit-based deep learning framework for skin lesions classification in smart healthcare",
        "authors": "Khosro Rezaee, Hossein Ghayoumi Zadeh",
        "published": "2024-1-20",
        "citations": 1,
        "abstract": "AbstractRising mortality rates in recent years have elevated melanoma to the ranks of the world’s most lethal cancers. Dermoscopy images (DIs) have been used in smart healthcare applications to determine medical features using deep transfer learning (DTL). DI-related lesions are widespread, have local features, and are associated with uncertainty. There are three components to our bi-branch parallel model: (1) the Transformer module (TM), (2) the self-attention unit (SAU), and (3) a convolutional neural network (CNN). With CNN and TM able to extract local and global features, respectively, a novel model has been developed to fuse global and local features using cross-fusion to generate fine-grained features. Parallel systems between the branches are merged using a feature-fusion architecture, resulting in a pattern that identifies the characteristics of a variety of lesions. Moreover, this paper proposes an optimized and lightweight CNN architecture version (optResNet-18) that discriminates skin cancer lesions with high accuracy. To verify the proposed method, the procedure evaluated the accuracy for the ISIC-2019 and the PH2 datasets as 97.48 and 96.87%, respectively, a significant difference over traditional CNN networks (e.g., ResNet-50 and ResNet-101) and the TM. The proposed model outperforms state-of-the-art performance metrics such as AUC, F1-score, specificity, precision, and recall. The proposed method can also be used as a generalizable model to diagnose different lesions in DIs with smart healthcare applications by combining DTL and medical imaging. With the proposed e-Health platform, skin diseases can be detected in real-time, which is crucial to speedy and reliable diagnostics.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s42452-024-05655-1"
    },
    {
        "id": 22429,
        "title": "Effective lung nodule detection using deep CNN with dual attention mechanisms",
        "authors": "Zia UrRehman, Yan Qiang, Long Wang, Yiwei Shi, Qianqian Yang, Saeed Ullah Khattak, Rukhma Aftab, Juanjuan Zhao",
        "published": "2024-2-16",
        "citations": 0,
        "abstract": "AbstractNovel methods are required to enhance lung cancer detection, which has overtaken other cancer-related causes of death as the major cause of cancer-related mortality. Radiologists have long-standing methods for locating lung nodules in patients with lung cancer, such as computed tomography (CT) scans. Radiologists must manually review a significant amount of CT scan pictures, which makes the process time-consuming and prone to human error. Computer-aided diagnosis (CAD) systems have been created to help radiologists with their evaluations in order to overcome these difficulties. These systems make use of cutting-edge deep learning architectures. These CAD systems are designed to improve lung nodule diagnosis efficiency and accuracy. In this study, a bespoke convolutional neural network (CNN) with a dual attention mechanism was created, which was especially crafted to concentrate on the most important elements in images of lung nodules. The CNN model extracts informative features from the images, while the attention module incorporates both channel attention and spatial attention mechanisms to selectively highlight significant features. After the attention module, global average pooling is applied to summarize the spatial information. To evaluate the performance of the proposed model, extensive experiments were conducted using benchmark dataset of lung nodules. The results of these experiments demonstrated that our model surpasses recent models and achieves state-of-the-art accuracy in lung nodule detection and classification tasks.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1038/s41598-024-51833-x"
    },
    {
        "id": 22430,
        "title": "Source Acquisition Device Identification from Recorded Audio Based on Spatiotemporal Representation Learning with Multi-Attention Mechanisms",
        "authors": "Chunyan Zeng, Shixiong Feng, Dongliang Zhu, Zhifeng Wang",
        "published": "2023-4-6",
        "citations": 3,
        "abstract": "Source acquisition device identification from recorded audio aims to identify the source recording device by analyzing the intrinsic characteristics of audio, which is a challenging problem in audio forensics. In this paper, we propose a spatiotemporal representation learning framework with multi-attention mechanisms to tackle this problem. In the deep feature extraction stage of recording devices, a two-branch network based on residual dense temporal convolution networks (RD-TCNs) and convolutional neural networks (CNNs) is constructed. The spatial probability distribution features of audio signals are employed as inputs to the branch of the CNN for spatial representation learning, and the temporal spectral features of audio signals are fed into the branch of the RD-TCN network for temporal representation learning. This achieves simultaneous learning of long-term and short-term features to obtain an accurate representation of device-related information. In the spatiotemporal feature fusion stage, three attention mechanisms—temporal, spatial, and branch attention mechanisms—are designed to capture spatiotemporal weights and achieve effective deep feature fusion. The proposed framework achieves state-of-the-art performance on the benchmark CCNU_Mobile dataset, reaching an accuracy of 97.6% for the identification of 45 recording devices, with a significant reduction in training time compared to other models.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/e25040626"
    },
    {
        "id": 22431,
        "title": "Q-SAT: Value Factorization with Self-Attention for Deep Multi-Agent Reinforcement Learning",
        "authors": "Xunhan Hu, Jian Zhao, Youpeng Zhao, Wengang Zhou, Houqiang Li",
        "published": "2023-6-18",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ijcnn54540.2023.10191777"
    },
    {
        "id": 22432,
        "title": "Attention-based deep learning approach for CSI feedback under 5G TDL channel",
        "authors": "Hanli Peng",
        "published": "2024-2-1",
        "citations": 0,
        "abstract": "Abstract\nIn 5G communication systems, accurate channel state information (CSI) is indispensable for signal detection and regulation at the base station side. However, frequent CSI feedback from users leads to excessive system overhead. To tackle this challenge, this paper puts forward a novel deep learning framework - HCNet based on attention mechanism and autoencoder, aiming to efficiently compress and reconstruct the high-dimensional time-varying CSI matrices in an end-to-end approach. The proposed framework incorporates a self-attention module in the encoder to explicitly capture global dependencies within the CSI matrix. Meanwhile, the decoder adopts gated recurrent unit networks to fully exploit inter-feature correlations and redundancy. To evaluate the performance, simulations are conducted using datasets conforming to current 5G time-varying TDL channel models. Results demonstrate superior performance over existing deep learning based feedback networks. Specifically, the proposed framework can reduce the normalized mean square error of CSI reconstruction by 4 dB under various compression ratios which confirms the effectiveness of the attention-enhanced autoencoder structure for compressive CSI sensing and feedback in practical dynamic communication systems.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/1742-6596/2711/1/012001"
    },
    {
        "id": 22433,
        "title": "UGAN-GSAM-IT: Unsupervised Generative Adversarial Network with Generative Self-Attention Method for Image Translation",
        "authors": "Chonghao Hu, Yu Chen",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10167327"
    },
    {
        "id": 22434,
        "title": "MAGRes-UNet: Improved Medical Image Segmentation Through a Deep Learning Paradigm of Multi-Attention Gated Residual U-Net",
        "authors": "Tahir Hussain, Hayaru Shouno",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2024.3374108"
    },
    {
        "id": 22435,
        "title": "A novel unsupervised deep learning approach for vibration-based damage diagnosis using a multi-head self-attention LSTM autoencoder",
        "authors": "Shayan Ghazimoghadam, S.A.A. Hosseinzadeh",
        "published": "2024-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.measurement.2024.114410"
    },
    {
        "id": 22436,
        "title": "Attention-based deep learning framework to recognize diabetes disease from cellular retinal images",
        "authors": "Deep Kothadiya, Amjad Rehman, Sidra Abbas, Faten S. Alamri, Tanzila Saba",
        "published": "2023-12-1",
        "citations": 4,
        "abstract": " A medical disorder known as diabetic retinopathy (DR) affects people who suffer from diabetes. Many people are visually impaired due to DR. Primary cause of DR in patients is high blood sugar, and it affects blood vessels available in the retinal cell. The recent advancement in deep learning and computer vision methods, and their automation applications can recognize the presence of DR in retinal cells and vessel images. Authors have proposed an attention-based hybrid model to recognize diabetes in early stage to prevent harmful clauses. Proposed methodology uses DenseNet121 architecture for convolution learning and then, the feature vector will be enhanced with channel and spatial attention model. The proposed architecture also simulates binary and multiclass classification to recognize the infection and the spreading of disease. Binary classification recognizes DR images either positive or negative, while multiclass classification represents an infection on a scale of 0–4. Simulation of the proposed methodology has achieved 98.57% and 99.01% accuracy for multiclass and binary classification, respectively. Simulation of the study also explored the impact of data augmentation to make the proposed model robust and generalized. Attention-based deep learning model has achieved remarkable accuracy to detect diabetic infection from retinal cellular images. ",
        "keywords": "",
        "link": "http://dx.doi.org/10.1139/bcb-2023-0151"
    },
    {
        "id": 22437,
        "title": "Dual attention-based deep learning approach for building segmentation of remote sensing images",
        "authors": "Noopur Srivastava, Kamal Jain",
        "published": "2023-10-19",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2684330"
    },
    {
        "id": 22438,
        "title": "Deep Learning Recurrent Attention Optical Character Recognition Network with Data Augmentation for Cheque Data Extraction",
        "authors": "Hitesh Chaitanyaswami, Ashwin Dobariya",
        "published": "2023-6-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/ic2e357697.2023.10262478"
    },
    {
        "id": 22439,
        "title": "Automated Skin Cancer Detection using Deep Learning with Self-Attention Mechanism",
        "authors": "Himanshi Singh, K Suganya Devi, Shraddha Singh Gaur, Ramanuj Bhattacharjee",
        "published": "2023-4-28",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cises58720.2023.10183586"
    },
    {
        "id": 22440,
        "title": "Wavelet Attention Network for Few-shot learning",
        "authors": "Rui Feng, Hongbing Ji, Zhigang Zhu, Lei Wang",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10166227"
    },
    {
        "id": 22441,
        "title": "YOLOv4-tiny pedestrian detection method based on attention fusion mechanism",
        "authors": "Yanling Li, Lixia Du, Yue Hou",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2678861"
    },
    {
        "id": 22442,
        "title": "ConF: A Deep Learning Model Based on BiLSTM, CNN, and Cross Multi-Head Attention Mechanism for Noncoding RNA Family Prediction",
        "authors": "Shoryu Teragawa, Lei Wang",
        "published": "2023-11-13",
        "citations": 0,
        "abstract": "This paper presents ConF, a novel deep learning model designed for accurate and efficient prediction of noncoding RNA families. NcRNAs are essential functional RNA molecules involved in various cellular processes, including replication, transcription, and gene expression. Identifying ncRNA families is crucial for comprehensive RNA research, as ncRNAs within the same family often exhibit similar functionalities. Traditional experimental methods for identifying ncRNA families are time-consuming and labor-intensive. Computational approaches relying on annotated secondary structure data face limitations in handling complex structures like pseudoknots and have restricted applicability, resulting in suboptimal prediction performance. To overcome these challenges, ConF integrates mainstream techniques such as residual networks with dilated convolutions and cross multi-head attention mechanisms. By employing a combination of dual-layer convolutional networks and BiLSTM, ConF effectively captures intricate features embedded within RNA sequences. This feature extraction process leads to significantly improved prediction accuracy compared to existing methods. Experimental evaluations conducted using a single, publicly available dataset and applying ten-fold cross-validation demonstrate the superiority of ConF in terms of accuracy, sensitivity, and other performance metrics. Overall, ConF represents a promising solution for accurate and efficient ncRNA family prediction, addressing the limitations of traditional experimental and computational methods.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/biom13111643"
    },
    {
        "id": 22443,
        "title": "Revolutionizing COVID-19 Diagnosis with Swin Transformer: A Comparative Study on CT Image Attention Analysisand CNN Models performance",
        "authors": "Jianbo Yang",
        "published": "2023-5-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/cvidl58838.2023.10167142"
    },
    {
        "id": 22444,
        "title": "Abstract 3517: A deep learning-based virtual staining system with multimodal-attention for precision medicine",
        "authors": "Zixia Zhou, Yuming Jiang, Ruijiang Li, Lei Xing",
        "published": "2024-3-22",
        "citations": 0,
        "abstract": "Abstract\nPurpose: This study introduces a novel multimodal-attention-based virtual mIF staining (MAS) system designed for efficient, reliable virtual mIF staining from label-free fluorescence images. Our goal was to overcome the performance bottleneck and time-cost limitations associated with traditional mIF techniques and thereby enhance their clinical utility.\nMethod and Materials: Our approach involved developing a cutting-edge MAS model. This model is built upon a sophisticated end-to-end generative convolutional neural network (CNN) architecture. It ingeniously leverages autofluorescence and 4',6-diamidino-2-phenylindole (DAPI) slides as inputs to generate mIF images. To achieve this, we equipped the model with feature extractors enhanced by pretrained masked auto-encoders (MAEs) and a self-attention combination strategy. These components worked harmoniously to extract antigen-label-related features and precisely locate specific cells within the images.\nResults: In our comprehensive study, we engaged 94 gastric cancer patients, utilizing the MAS system for automated virtual mIF staining of seven biomarkers, namely CD3, CD20, FOXP3, PD1, CD8, CD163, and PDL1, in both cancerous and non-cancerous tissues. Importantly, the MAS-produced virtual mIF stains matched the quality of traditional manual stains. Furthermore, we validated the prognostic accuracy for gastric cancer using these virtual mIF images, demonstrating their ability to provide clinical information that is as reliable and valuable as that obtained from manually stained mIF images.\nConclusions: Our study identifies the MAS system as an important advancement in mIF staining, enhancing personalized medicine with its efficiency and quality. This tool holds significant potential to enable personalized medicine efficiently and cost-effectively, streamlining the process of diagnosing diseases, making prognoses, and developing treatment plans.\nQuantitative Comparison of Ablation Experiments for MAS system in predicting multiple biomarkers Biomarkers Index U-Net (Avg±Std) ReU-Net (Avg±Std) Att-ReU-Net (Avg±Std) MAS (Avg±Std) CD3 PSNR 27.053±4.10 27.419±4.15 28.073±4.00 28.546±4.40 CD3 SSIM 0.733±0.07 0.724±0.07 0.728±0.05 0.742±0.07 CD20 PSNR 28.835±4.66 29.244±4.76 28.672±4.52 29.243±4.99 CD20 SSIM 0.921±0.058 0.921±0.057 0.915±0.051 0.923±0.051 FOXP3 PSNR 31.769±3.29 31.838±3.10 31.098±3.20 31.862±3.11 FOXP3 SSIM 0.613±0.11 0.618±0.11 0.617±0.112 0.617±0.12 PD1 PSNR 27.908±4.47 27.950±4.43 30.283±4.37 31.717±4.17 PD1 SSIM 0.654±0.13 0.659±0.13 0.694±0.12 0.726±0.11\nCitation Format: Zixia Zhou, Yuming Jiang, Ruijiang Li, Lei Xing. A deep learning-based virtual staining system with multimodal-attention for precision medicine [abstract]. In: Proceedings of the American Association for Cancer Research Annual Meeting 2024; Part 1 (Regular Abstracts); 2024 Apr 5-10; San Diego, CA. Philadelphia (PA): AACR; Cancer Res 2024;84(6_Suppl):Abstract nr 3517.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1158/1538-7445.am2024-3517"
    },
    {
        "id": 22445,
        "title": "Learning Representative Features by Deep Attention Network for 3D Point Cloud Registration",
        "authors": "Xiaokai Xia, Zhiqiang Fan, Gang Xiao, Fangyue Chen, Yu Liu, Yiheng Hu",
        "published": "2023-4-20",
        "citations": 0,
        "abstract": "Three-dimensional point cloud registration, which aims to find the transformation that best aligns two point clouds, is a widely studied problem in computer vision with a wide spectrum of applications, such as underground mining. Many learning-based approaches have been developed and have demonstrated their effectiveness for point cloud registration. Particularly, attention-based models have achieved outstanding performance due to the extra contextual information captured by attention mechanisms. To avoid the high computation cost brought by attention mechanisms, an encoder–decoder framework is often employed to hierarchically extract the features where the attention module is only applied in the middle. This leads to the compromised effectiveness of the attention module. To tackle this issue, we propose a novel model with the attention layers embedded in both the encoder and decoder stages. In our model, the self-attentional layers are applied in the encoder to consider the relationship between points inside each point cloud, while the decoder utilizes cross-attentional layers to enrich features with contextual information. Extensive experiments conducted on public datasets prove that our model is able to achieve quality results on a registration task.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23084123"
    },
    {
        "id": 22446,
        "title": "A mixed CNN based on attention mechanism to predict seizures",
        "authors": "Nan Qi, Yan Piao, Baolin Tan",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2678864"
    },
    {
        "id": 22447,
        "title": "Innovative Use of Self-Attention-Based Ensemble Deep Learning for Suicide Risk Detection in Social Media Posts",
        "authors": "Hoan-Suk Choi, Jinhong Yang",
        "published": "2024-1-20",
        "citations": 0,
        "abstract": "Suicidal ideation constitutes a critical concern in mental health, adversely affecting individuals and society at large. The early detection of such ideation is vital for providing timely support to individuals and mitigating its societal impact. With social media serving as a platform for self-expression, it offers a rich source of data that can reveal early symptoms of mental health issues. This paper introduces an innovative ensemble learning method named LSTM-Attention-BiTCN, which fuses LSTM and BiTCN models with a self-attention mechanism to detect signs of suicidality in social media posts. Our LSTM-Attention-BiTCN model demonstrated superior performance in comparison to baseline models in the realm of classification and suicidal ideation detection, boasting an accuracy of 0.9405, a precision of 0.9385, a recall of 0.9424, and an F1-score of 0.9405. Our proposed model can aid healthcare professionals in recognizing suicidal tendencies among social media users accurately, thereby contributing to efforts to reduce suicide rates.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/app14020893"
    },
    {
        "id": 22448,
        "title": "Retracted: Music Emotion Classification Method Based on Deep Learning and Explicit Sparse Attention Network",
        "authors": "",
        "published": "2023-8-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1155/2023/9858032"
    },
    {
        "id": 22449,
        "title": "A vehicle classification method based on deep learning and multi-attention mechanism",
        "authors": "Kaiyan Zhang, Xinglong Feng",
        "published": "2023-6-8",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2681386"
    },
    {
        "id": 22450,
        "title": "Deep Attributed Graph Clustering with Graph Attention Network",
        "authors": "Bowen Zhu, Dong Huang, Jinrong Cui, Guang-Yu Zhang",
        "published": "2023-2-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3587716.3587776"
    },
    {
        "id": 22451,
        "title": "Self-attention based deep direct recurrent reinforcement learning with hybrid loss for trading signal generation",
        "authors": "Dongkyu Kwak, Sungyoon Choi, Woojin Chang",
        "published": "2023-4",
        "citations": 7,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ins.2022.12.042"
    },
    {
        "id": 22452,
        "title": "Early Detection of Alzheimer’s Disease: An Extensive Review of Advancements in Machine Learning Mechanisms Using an Ensemble and Deep Learning Technique",
        "authors": "Renjith Prabhavathi Neelakandan, Ramesh Kandasamy, Balasubramani Subbiyan, Mariya Anto Bennet",
        "published": "2023-12-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/engproc2023059010"
    },
    {
        "id": 22453,
        "title": "Identification of attention deficit hyperactivity disorder with deep learning model",
        "authors": "Ömer Kasim",
        "published": "2023-9",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s13246-023-01275-y"
    },
    {
        "id": 22454,
        "title": "Multi-Camera 3D Object Detection for Autonomous Driving Using Deep Learning and Self-Attention Mechanism",
        "authors": "Ananya Hazarika, Amit Vyas, Mehdi Rahmati, Yan Wang",
        "published": "2023",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3288112"
    },
    {
        "id": 22455,
        "title": "Building of Computationally Effective Deep Learning Models using Attention-Guided Knowledge Distillation",
        "authors": "V A Ashwath, Anish Sai Ayyagari, C R Deebakkarthi, R Arumuga Arun",
        "published": "2023-8-17",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icoac59537.2023.10249491"
    },
    {
        "id": 22456,
        "title": "Federated deep active learning for attention-based transaction classification",
        "authors": "Usman Ahmed, Jerry Chun-Wei Lin, Philippe Fournier-Viger",
        "published": "2023-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10489-022-04388-1"
    },
    {
        "id": 22457,
        "title": "Self-Attention Mechanism based Visual Detection for Transmission Line Pins",
        "authors": "Shijia Ding, Yangyang Wang, Tuoran Wang, Hongyu Wang",
        "published": "2023-7-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3613330.3613335"
    },
    {
        "id": 22458,
        "title": "Efficient Attention Fusion Feature Extraction Network for Image Super-Resolution",
        "authors": "Tuoran Wang, Na Cheng, Shijia Ding, Hongyu Wang",
        "published": "2023-7-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3613330.3613336"
    },
    {
        "id": 22459,
        "title": "Deep Residual Learning with Attention Mechanism for OFDM Channel Estimation",
        "authors": "Wei Gao, Wei Zhang, Libin Liu, Meihong Yang",
        "published": "2024",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/lwc.2022.3232378"
    },
    {
        "id": 22460,
        "title": "Attention-Based CNN-BiLSTM Deep Learning Approach for Network Intrusion Detection System in Software Defined Networks",
        "authors": "Rachid Ben Said, Iman Askerzade",
        "published": "2023-8-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/pci60110.2023.10325985"
    },
    {
        "id": 22461,
        "title": "DeepFPD: Browser Fingerprinting Detection via Deep Learning With Multimodal Learning and Attention",
        "authors": "Weizhong Qiang, Kunlun Ren, Yueming Wu, Deqing Zou, Hai Jin",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tr.2024.3355233"
    },
    {
        "id": 22462,
        "title": "Microseismic Event Recognition and Transfer Learning Based on Convolutional Neural Network and Attention Mechanisms",
        "authors": "Shu Jin, Shichao Zhang, Ya Gao, Benli Yu, Shenglai Zhen",
        "published": "2024-4-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11770-024-1058-y"
    },
    {
        "id": 22463,
        "title": "An Attention-Based Deep Learning Approach for Lithium-ion Battery Lifespan Prediction: Analysis and Experimental Validation",
        "authors": "Ahmed Darwish",
        "published": "2024-4-16",
        "citations": 0,
        "abstract": "The potential for lithium-ion batteries to become unstable can lead to operational malfunctions within the system and result in safety incidents. Therefore, accurately forecasting the remaining useful life (RUL) is beneficial in mitigating the likelihood of battery failure and prolonging its operational lifespan. Hence, precise estimation of RUL can help prevent numerous safety incidents and minimize resource wastage, presenting a significant and complex issue. This paper introduces a Deep Learning (DL) model that utilizes Long Short-Term Memory (LSTM) and attention mechanism to improve the accuracy of predicting the RUL of lithium-ion batteries. Initially, the battery capacity regeneration phenomenon is captured by applying four LSTM layers, followed by implementing an attention mechanism to align input and output sequences based on the content or semantics of the input sequence. Finally, the final prediction outcomes are generated via a Fully Connected (FC) layer. The efficacy of the proposed model is assessed through the utilization of the NASA dataset, and its performance is contrasted with various deep learning models to highlight its efficacy. Results from the experiments demonstrate that the suggested At-LSTM presents a robust option for forecasting the RUL of lithium-ion batteries, as it delivers superior results compared to all other models examined.",
        "keywords": "",
        "link": "http://dx.doi.org/10.61356/j.iswa.2024.2224"
    },
    {
        "id": 22464,
        "title": "Histopathologic brain age estimation via context‐aware attention‐based deep multiple instance learning",
        "authors": "Gabriel A. Marx",
        "published": "2023-6",
        "citations": 1,
        "abstract": "AbstractBackgroundWhile a large list of age‐related changes have been described in the human brain, the extent to which they represent the result of common pathological reactions versus signatures of underlying brain aging remains unclear. One approach to sorting out the relative importance of the myriad of changes is deep learning, which has emerged as a powerful tool for image analysis and computer vision. However, large digitized whole slide image datasets from human aging brains have not been previously available.MethodIn this study, we leveraged a large novel collection of uniformly processed digitized human post‐mortem brain tissue sections to create a histological brain age estimation model. We further investigated the effect of cognitive impairment and exogenous stress on the model. This was accomplished by developing a context‐aware attention‐based deep multiple instance learning model on 702 human brain tissues sections (age range 50‐110 yr) from the hippocampus stained with Luxol Fast Blue counterstained with hematoxylin and eosin (LH&E) on a brain age estimation task.ResultOur model estimated brain age within a mean absolute error of 6.2 years. Learned attention weights corresponded to neuroanatomical regions known to be vulnerable to age‐related change. We found that deviations from our estimated histopathologic brain age significantly correlated with the clinical marker of cognitive status (p = 0.042). In addition, we found evidence of significantly accelerated age (p = 1.12×10‐23) in a cohort of subjects with a neuropathological diagnosis of chronic traumatic encephalopathy (CTE), a neurodegenerative disease caused by mild yet repetitive traumatic brain injury, that displays features that overlap with aging.ConclusionThese data indicate that estimated histopathologic age can be used as a reliable pathologic correlate to identify factors that contribute to accelerated or decelerated brain aging.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1002/alz.067335"
    },
    {
        "id": 22465,
        "title": "Attention adaptive instance normalization style transfer for vascular segmentation using deep learning",
        "authors": "Supriti Mulay, Keerthi Ram, Mohanasankar Sivaprakasam",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s10489-023-05033-1"
    },
    {
        "id": 22466,
        "title": "Deep Scattering Transform with Attention Mechanisms Improves EMG-based Hand Gesture Recognition",
        "authors": "Ahmed A. Al Taee, Rami N. Khushaba, Tanveer Zia, Adel Al-Jumaily",
        "published": "2023-7-24",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/embc40787.2023.10340544"
    },
    {
        "id": 22467,
        "title": "Attention module-based fused deep cnn for learning disabilities identification using EEG signal",
        "authors": "Nitin Kisan Ahire, R. N. Awale, Abhay Wagh",
        "published": "2023-11-2",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-17277-7"
    },
    {
        "id": 22468,
        "title": "SeaBil: Self-attention-weighted ultrashort-term deep learning prediction of ship maneuvering motion",
        "authors": "Ning Wang, Xiangjun Kong, Boyu Ren, Lizhu Hao, Bing Han",
        "published": "2023-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.oceaneng.2023.115890"
    },
    {
        "id": 22469,
        "title": "Detection of Attention Deficit Hyperactivity Disorder by Using EEG Feature Maps and Deep Learning",
        "authors": "Burak Akbugday, Ozge Ada Bozbas, Ozlem Karabiber Cura, Sude Pehlivan, Aydin Akan",
        "published": "2023-9-4",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.23919/eusipco58844.2023.10289818"
    },
    {
        "id": 22470,
        "title": "Eye diseases detection using deep learning with BAM attention module",
        "authors": "Amna Zia, Rabbia Mahum, Nabeel Ahmad, Muhammad Awais, Ahmad M. Alshamrani",
        "published": "2023-12-27",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11042-023-17839-9"
    },
    {
        "id": 22471,
        "title": "Hybrid Deep Learning Classification Model for Attention-Deficit-Hyperactivity Disorder using functional Magnetic Resonance Imaging",
        "authors": "Usha Rupni K, Aruna Priya P",
        "published": "2023-2-9",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iciscois56541.2023.10100467"
    },
    {
        "id": 22472,
        "title": "Hybrid Deep Learning Model Integrating Attention Mechanism for the Accurate Prediction and Forecasting of the Cryptocurrency Market",
        "authors": "Godfrey Joseph Saqware, Ismail B",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s43069-024-00302-2"
    },
    {
        "id": 22473,
        "title": "DTITD: An Intelligent Insider Threat Detection Framework Based on Digital Twin and Self-Attention Based Deep Learning Models",
        "authors": "Zhi Qiang Wang, Abdulmotaleb El Saddik",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3324371"
    },
    {
        "id": 22474,
        "title": "Sentiment classification on online product reviews using dwarf mongoose optimization with attention based deep learning model",
        "authors": "D. Elangovan, V. Subedha",
        "published": "2023-11-17",
        "citations": 0,
        "abstract": "Opinion Mining and Sentiment Analysis acts as a pivotal role in facilitating businesses to actively operate on enhancing the business strategies and accomplish detailed insights of the consumer’s feedback regarding the products. In recent times, deep learning (DL)technique has been used for many sentiment analysis tasks and has attained effective outcomes. Huge quantity of product reviews is being posted by the customer on different e-commerce and social networking platforms which can assist the developers to improve the quality of the products. The study focuses on the design of Sentiment Classification on Online Product Reviews using Dwarf Mongoose Optimization with Attention based Deep Learning (DMO-ABDL) model. The proposed DMO-ABDL technique analyzes the product reviews for the identification of sentiments. To accomplish this, the DMO-ABDL technique performs different stages of preprocessing to transform the actual data into suitable format. Furthermore, the Glove technique is employed for word embedding process. Moreover, attention based long short-term memory (ALSTM) approach was exploited for sentiment classification and its hyperparameters can be optimally chosen by the DMO technique. A comprehensive set of experiments were performed in order to guarantee the enhanced sentiment classification performance of the DMO-ABDL algorithm. A brief comparative study highlighted the supremacy of the DMO-ABDL technique over other existing approaches under different measures.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3233/jifs-233611"
    },
    {
        "id": 22475,
        "title": "KolamNetV2: efficient attention-based deep learning network for tamil heritage art-kolam classification",
        "authors": "A. Sasithradevi,  Sabarinathan, S. Shoba, S. Mohamed Mansoor Roomi, P. Prakash",
        "published": "2024-2-19",
        "citations": 0,
        "abstract": "AbstractIn India, kolam, commonly referred to as rangoli, is a traditional style of art. It involves using rice flour, chalk, or coloured powders to create elaborate patterns and motifs on the ground. Kolam is a common daily ritual in many regions of India, especially in South India, where it is seen as a significant cultural tradition and a means to greet visitors. Unfortunately, as a result of people’s hectic lives nowadays, the habit of drawing kolam on a regular basis is dwindling. The art of making kolam patterns is in danger of disappearing as so many individuals no longer have the time or space to do it on a regular basis. Therefore, it is imperative that ancient art be conserved and digitally documented in order to enlighten our next generation about kolam and its classifications. Deep learning has become a powerful technique because of its ability to learn from raw image data without the aid of a feature engineering process. In this article, we attempted to understand the types of Kolam images using the proposed deep architecture called KolamNetV2. KolamNetV2 comprises EfficientNet and attention layers, ensuring high accuracy with minimal training data and parameters. We evaluated KolamNetV2 to reveal its ability to learn the various types in our challenging Kolam dataset. The experimental findings show that the proposed network achieves fine enhancement in performance metrics viz, precision-0.7954, recall-0.7846, F1score-0.7854 and accuracy-81%. We compared our results with state-of-the-art deep learning methodologies, proving the astounding capability.\nGraphical Abstract",
        "keywords": "",
        "link": "http://dx.doi.org/10.1186/s40494-024-01167-8"
    },
    {
        "id": 22476,
        "title": "Low-Cost Real-Time Automated Optical Inspection Using Deep Learning and Attention Map",
        "authors": "Yu Shih, Chien-Chih Kuo, Ching-Hung Lee",
        "published": "2023",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/iasc.2023.027659"
    },
    {
        "id": 22477,
        "title": "Intelligent Recommendation System Based on the Infusion Algorithms with Deep Learning, Attention Network and Clustering",
        "authors": "Wenjun Li",
        "published": "2023-5-13",
        "citations": 2,
        "abstract": "AbstractThe creation and use of big data have driven the intelligent development of e-commerce. The information generated in e-commerce provides a good means to analyze the behavior of users. How to use this information to give customer recommendations, improve the accuracy of recommendations and protect information security is a topic worth studying. For improving the accuracy of recommendations, analysis of users and tagging of resources are key. The current popular session recommendation algorithms face many problems, such as user interest drift which is difficult to be handled by these algorithms, thus affecting the recommendation accuracy. Based on these problems, this paper proposes a recommendation model based on deep learning, applies it to the clustering analysis of user tagging system, and designs a personalized recommendation algorithm for the tagging system. The model proposed in this paper can effectively analyze not only the interests exhibited by users in the current session, but also their potential long-term interests. By comparing the different performances of different datasets, the experimental results of this paper show that the proposed algorithmic model in this paper helps to dig the interests of different users, thus improving the quality of the recommendation system.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s44196-023-00264-z"
    },
    {
        "id": 22478,
        "title": "A Similarity-based Positional Attention aided Deep Learning Model for Copy-Move Forgery Detection",
        "authors": "Ayush Roy, Sk Mohiuddin, Ram Sarkar",
        "published": "2024",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tai.2024.3379941"
    },
    {
        "id": 22479,
        "title": "A Multi-Label Detection Deep Learning Model with Attention-Guided Image Enhancement for Retinal Images",
        "authors": "Zhenwei Li, Mengying Xu, Xiaoli Yang, Yanqi Han, Jiawen Wang",
        "published": "2023-3-22",
        "citations": 1,
        "abstract": "At present, multi-disease fundus image classification tasks still have the problems of small data volumes, uneven distributions, and low classification accuracy. In order to solve the problem of large data demand of deep learning models, a multi-disease fundus image classification ensemble model based on gradient-weighted class activation mapping (Grad-CAM) is proposed. The model uses VGG19 and ResNet50 as the classification networks. Grad-CAM is a data augmentation module used to obtain a network convolutional layer output activation map. Both the augmented and the original data are used as the input of the model to achieve the classification goal. The data augmentation module can guide the model to learn the feature differences of lesions in the fundus and enhance the robustness of the classification model. Model fine tuning and transfer learning are used to improve the accuracy of multiple classifiers. The proposed method is based on the RFMiD (Retinal Fundus Multi-Disease Image Dataset) dataset, and an ablation experiment was performed. Compared with other methods, the accuracy, precision, and recall of this model are 97%, 92%, and 81%, respectively. The resulting activation graph shows the areas of interest for model classification, making it easier to understand the classification network.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/mi14030705"
    },
    {
        "id": 22480,
        "title": "Triplet attention-based deep learning model for hierarchical image classification of household items for robotic applications",
        "authors": "Divya Arora Bhayana, Om Prakash Verma",
        "published": "2024-4-15",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s11760-024-03168-3"
    },
    {
        "id": 22481,
        "title": "Attention-Guided Deep Learning Framework For Movement Quality Assessment",
        "authors": "Aditya Kanade, Mansi Sharma, Manivannan Muniyandi",
        "published": "2023-6-4",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/icassp49357.2023.10095031"
    },
    {
        "id": 22482,
        "title": "Anomaly detection using deep learning based model with feature attention",
        "authors": "Rikin J. Nayak, Jitendra P. Chaudhari",
        "published": "2024-3-1",
        "citations": 0,
        "abstract": "<span lang=\"EN-US\">Anomaly detection is a difficult problem with numerous industrial applications, such as analyzing the quality of objects using images. Anomaly detection is the process of identifying outliers in a given dataset. Recently, machine learning approaches to computer vision problems have outperformed classical state-of-the-art approaches. Anomaly detection problems can be solved using supervised approaches. However, labelled datasets are hard to obtain. Thus, many researchers have taken an unsupervised approach to solving the problem of anomaly detection. In this study, we use an adversarial auto encoder model as a base model and create a custom model to detect anomalies in images and videos. The model was trained exclusively on normal data. The modified national institute of standards and technology database (MNIST) dataset achieved an area under curve (AUC) score of 0.872 for anomaly detection, while the University of California San Diego (UCSD) anomaly dataset (Video dataset) achieved an AUC score of 0.74 for Ped1 and 0.87 for Ped2. To calculate the anomaly score, the concept of attention weights is combined with the reconstruction loss, and the proposed method outperformed other similar methods designed for the same problem. However, the usefulness of the proposed model was demonstrated through the detection of anomalies, and the model is still being improved for use in real-world situations.</span>",
        "keywords": "",
        "link": "http://dx.doi.org/10.11591/ijai.v13.i1.pp383-390"
    },
    {
        "id": 22483,
        "title": "Deep Learning-Based Apple Detection with Attention Module and Improved Loss Function in YOLO",
        "authors": "Praveen Kumar Sekharamantry, Farid Melgani, Jonni Malacarne",
        "published": "2023-3-9",
        "citations": 17,
        "abstract": "Horticulture and agriculture are considered as the important pillars of any economy. Current technological advancements have led to the development of several new technologies which are useful in atomizing the agriculture process. Apple farming has a significant role in Italy’s agriculture domain where manual labor is widely employed for apple picking which can be replaced by automated robot mechanisms. However, these mechanisms are based on computer vision methods. These methods focus on detection, localization and tracking the apple fruits in given video frames. Later, appropriate actions can be taken to enhance the production and harvesting. Several techniques have been presented for apple detection, but complex background, noise and image blurriness are the major causes which can deteriorate the performance of the system. Thus, in this work, we present a deep learning-based scheme to detect apples which uses Yolov5 architecture in live apple farm images. We further improve the Yolov5 architecture by incorporating an adaptive pooling scheme and attribute augmentation model. This model detects the smaller objects and improves the feature quality to detect the apples in complex backgrounds. Moreover, a loss function is also incorporated to obtain the accurate bounding box which helps to maximize the detection accuracy. The comparative study shows that the proposed approach with the improved Yolov5 architecture achieves overall accuracy of 0.97, 0.99, and 0.98 in terms of precision, recall, and F1-score, respectively.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/rs15061516"
    },
    {
        "id": 22484,
        "title": "Nonintrusive Load Monitoring (NILM) Using a Deep Learning Model with a Transformer-Based Attention Mechanism and Temporal Pooling",
        "authors": "Mohammad Irani Azad, Roozbeh Rajabi, Abouzar Estebsari",
        "published": "2024-1-18",
        "citations": 0,
        "abstract": "Nonintrusive load monitoring (NILM) is an important technique for energy management and conservation. In this paper, a deep learning model based on an attention mechanism, temporal pooling, residual connections, and transformers is proposed. This article presents a novel approach for NILM to accurately discern energy consumption patterns of individual household appliances. The proposed method entails a sequence of layers, including encoders, transformers, attention, temporal pooling, and residual connections, offering a comprehensive solution for NILM while effectively capturing appliance-specific energy usage in a household. The proposed model was evaluated using UK-DALE, REDD, and REFIT datasets in both seen and unseen cases. It shows that the proposed model in this paper performs better than other methods stated in other papers in terms of F1-score and total error of the results (in terms of SAE). This model achieved an F1-score equal to 92.96 as well as a total SAE equal to −0.036, which shows its effectiveness in accurately diagnosing and estimating the energy consumption of individual home appliances. The findings of this research show that the proposed model can be a tool for energy management in residential and commercial buildings.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/electronics13020407"
    },
    {
        "id": 22485,
        "title": "Multi-Task Deep Learning with Task Attention for Post-Click Conversion Rate Prediction",
        "authors": "Hongxin Luo, Xiaobing Zhou, Haiyan Ding, Liqing Wang",
        "published": "2023",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.32604/iasc.2023.036622"
    },
    {
        "id": 22486,
        "title": "Attention-Based Multimodal Deep Learning on Vision-Language Data: Models, Datasets, Tasks, Evaluation Metrics and Applications",
        "authors": "Priyankar Bose, Pratip Rana, Preetam Ghosh",
        "published": "2023",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/access.2023.3299877"
    },
    {
        "id": 22487,
        "title": "Enhancing Vehicle Routing Solutions Through Attention-Based Deep Reinforcement Learning",
        "authors": "Jianlin Chen, Jianping Luo",
        "published": "2023-9-22",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/docs60977.2023.10294826"
    },
    {
        "id": 22488,
        "title": "Predicting thermoelectric transport properties from composition with attention-based deep learning",
        "authors": "Luis M Antunes, Keith T Butler, Ricardo Grau-Crespo",
        "published": "2023-3-1",
        "citations": 3,
        "abstract": "Abstract\nThermoelectric materials can be used to construct devices which recycle waste heat into electricity. However, the best known thermoelectrics are based on rare, expensive or even toxic elements, which limits their widespread adoption. To enable deployment on global scales, new classes of effective thermoelectrics are thus required. Ab initio models of transport properties can help in the design of new thermoelectrics, but they are still too computationally expensive to be solely relied upon for high-throughput screening in the vast chemical space of all possible candidates. Here, we use models constructed with modern machine learning techniques to scan very large areas of inorganic materials space for novel thermoelectrics, using composition as an input. We employ an attention-based deep learning model, trained on data derived from ab initio calculations, to predict a material’s Seebeck coefficient, electrical conductivity, and power factor over a range of temperatures and n- or p-type doping levels, with surprisingly good performance given the simplicity of the input, and with significantly lower computational cost. The results of applying the model to a space of known and hypothetical binary and ternary selenides reveal several materials that may represent promising thermoelectrics. Our study establishes a protocol for composition-based prediction of thermoelectric behaviour that can be easily enhanced as more accurate theoretical or experimental databases become available.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1088/2632-2153/acc4a9"
    },
    {
        "id": 22489,
        "title": "A Novel Deep Learning Network with Deformable Convolution and Attention Mechanisms for Complex Scenes Ship Detection in SAR Images",
        "authors": "Chen Peng, Zhou Hui, Ying Li, Liu Peng, Liu Bingxin",
        "published": "2023-5-16",
        "citations": 2,
        "abstract": "Synthetic aperture radar (SAR) can detect objects in various climate and weather conditions. Therefore, SAR images are widely used for maritime object detection in applications such as maritime transportation safety and fishery law enforcement. However, nearshore ship targets in SAR images are often affected by background clutter, resulting in a low detection rate, high false alarm rate, and high missed detection rate, especially for small-scale ship targets. To address this problem, in this paper, we propose a novel deep learning network with deformable convolution and attention mechanisms to improve the Feature Pyramid Network (FPN) model for nearshore ship target detection in SAR images with complex backgrounds. The proposed model uses a deformable convolutional neural network in the feature extraction network to adapt the convolution position to the target sampling point, enhancing the feature extraction ability of the target, and improving the detection rate of the ship target against the complex background. Moreover, this model uses a channel attention mechanism to capture the feature dependencies between different channel graphs in the feature extraction network and reduce the false detection rate. The designed experiments on a public SAR image ship dataset show that our model achieves 87.9% detection accuracy for complex scenes and 95.1% detection accuracy for small-scale ship targets. A quantitative comparison of the proposed model with several classical and recently developed deep learning models on the same SAR images dataset demonstrated the superior performance of the proposed method over other models.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/rs15102589"
    },
    {
        "id": 22490,
        "title": "Is attention all geosciences need? Advancing quantitative petrography with attention-based deep learning",
        "authors": "Ardiansyah Koeshidayatullah, Ivan Ferreira-Chacua, Weichang Li",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.cageo.2023.105466"
    },
    {
        "id": 22491,
        "title": "Zero-exemplar deep continual learning for crop disease recognition: a study of total variation attention regularization in vision transformers",
        "authors": "Boyuan Wang",
        "published": "2024-1-4",
        "citations": 0,
        "abstract": "With the increasing integration of AI technology in the food industry, deep learning has demonstrated its immense potential in the domain of plant disease image recognition. However, there remains a gap in research between models capable of continual learning of new diseases and addressing the inherent catastrophic forgetting issue in neural networks. This study aims to comprehensively evaluate various learning strategies based on advanced computer vision models for multi-disease continual learning tasks in food disease recognition. To cater to the benchmark dataset requirements, we collected the PlantDiseaseCL dataset, sourced from the internet, encompassing diverse crop diseases from apples, corn, and more. Utilizing the Vision Transformer (ViT) model, we established a plant disease image recognition classifier, which, in joint learning, outperformed several comparative CNN architectures in accuracy (0.9538), precision (0.9532), recall (0.9528), and F1 score (0.9560). To further harness the potential of ViT in food disease defect recognition, we introduced a mathematical paradigm for crop disease recognition continual learning. For the first time, we proposed a novel ViT-TV architecture in the multi-disease image recognition scenario, incorporating a Total Variation (TV) distance-based loss (TV-Loss) to quantify the disparity between current and previous attention distributions, fostering attention consistency and mitigating the catastrophic forgetting inherent in ViT without prior task samples. In the incremental learning of the PlantDiseaseCL dataset across 3-Steps and 5-Steps, our strategy achieved average accuracies of 0.7077 and 0.5661, respectively, surpassing all compared Zero-Exemplar Approaches like LUCIR, SI, MAS, and even outperforming exemplar-based strategies like EEIL and ICaRL. In conclusion, the ViT-TV approach offers robust support for the long-term intelligent development of the agricultural and food industry, especially showcasing significant applicability in continual learning for crop disease image recognition.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fpls.2023.1283055"
    },
    {
        "id": 22492,
        "title": "Detection of Attention Deficit Hyperactivity Disorder using Decision-level Fusion of Brain Connectivity Information Based on Deep Learning",
        "authors": "Ozlem Karabiber Cura, Fatma Gunseli Ciklacandir, Aydin Akan, Sibel Kocaaslan Atli",
        "published": "2023-11-10",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/tiptekno59875.2023.10359178"
    },
    {
        "id": 22493,
        "title": "Stacked hourglass deep learning networks based on attention mechanism in multi-person pose estimation",
        "authors": "jiazhi Di, ben wang, hua hu",
        "published": "2023-3-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2668319"
    },
    {
        "id": 22494,
        "title": "A Deep Learning Model Based on Multi-Head Attention for Long-Term Forecasting of Solar Activity",
        "authors": "Adriana Marcucci, Giovanna Jerse, Valentina Alberti, Mauro Messerotti",
        "published": "2023-6-29",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/engproc2023039016"
    },
    {
        "id": 22495,
        "title": "Tree trunk detection in urban scenes using a multiscale attention-based deep learning method",
        "authors": "Rao Li, GuoDong Sun, Sheng Wang, TianZhuzi Tan, Fu Xu",
        "published": "2023-11",
        "citations": 2,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ecoinf.2023.102215"
    },
    {
        "id": 22496,
        "title": "Ensemble CNN Attention-Based BiLSTM Deep Learning Architecture for Multivariate Cloud Workload Prediction",
        "authors": "Ananya Kaim, Surjit Singh, Yashwant Singh Patel",
        "published": "2023-1-4",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1145/3571306.3571433"
    },
    {
        "id": 22497,
        "title": "Classification of lily weeds based on dual attention mechanism in field condition",
        "authors": "Yongjun Ding, Jingjing Zhang, Yuqing Bai",
        "published": "2023-5-25",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1117/12.2679148"
    },
    {
        "id": 22498,
        "title": "Human Activity Recognition Using Attention-Mechanism-Based Deep Learning Feature Combination",
        "authors": "Morsheda Akter, Shafew Ansary, Md. Al-Masrur Khan, Dongwan Kim",
        "published": "2023-6-19",
        "citations": 2,
        "abstract": "Human activity recognition (HAR) performs a vital function in various fields, including healthcare, rehabilitation, elder care, and monitoring. Researchers are using mobile sensor data (i.e., accelerometer, gyroscope) by adapting various machine learning (ML) or deep learning (DL) networks. The advent of DL has enabled automatic high-level feature extraction, which has been effectively leveraged to optimize the performance of HAR systems. In addition, the application of deep-learning techniques has demonstrated success in sensor-based HAR across diverse domains. In this study, a novel methodology for HAR was introduced, which utilizes convolutional neural networks (CNNs). The proposed approach combines features from multiple convolutional stages to generate a more comprehensive feature representation, and an attention mechanism was incorporated to extract more refined features, further enhancing the accuracy of the model. The novelty of this study lies in the integration of feature combinations from multiple stages as well as in proposing a generalized model structure with CBAM modules. This leads to a more informative and effective feature extraction technique by feeding the model with more information in every block operation. This research used spectrograms of the raw signals instead of extracting hand-crafted features through intricate signal processing techniques. The developed model has been assessed on three datasets, including KU-HAR, UCI-HAR, and WISDM datasets. The experimental findings showed that the classification accuracies of the suggested technique on the KU-HAR, UCI-HAR, and WISDM datasets were 96.86%, 93.48%, and 93.89%, respectively. The other evaluation criteria also demonstrate that the proposed methodology is comprehensive and competent compared to previous works.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3390/s23125715"
    },
    {
        "id": 22499,
        "title": "Leveraging attention layer in improving deep learning models performance for sentiment analysis",
        "authors": "Monir Yahya Salmony, Arman Rasool Faridi, Faraz Masood",
        "published": "2023-10-28",
        "citations": 1,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1007/s41870-023-01570-7"
    },
    {
        "id": 22500,
        "title": "An attention‐based deep learning model for credibility assessment of online health information",
        "authors": "Swarup Padhy, Santosh Singh Rathore",
        "published": "2023-10",
        "citations": 1,
        "abstract": "AbstractWith the surge of searching and reading online health‐based articles, maintaining the quality and credibility of online health‐based articles has become crucial. The circulation of deceptive health information on numerous social media sites can mislead people and can potentially cause adverse effects on people's health. To address these problems, this work uses deep learning approaches to automate the assessment and scoring of online health‐related articles' credibility. The paper proposed an Attention‐based Recurrent Multichannel Convolutional Neural Network (ARMCNN) model. The proposed model incorporates a BiLSTM layer, a multichannel CNN layer, and an attention layer and predicts the credibility of online health information. To perform a reliable evaluation of the presented model, we utilize the health articles reviewed by the experts, compiled in a labeled dataset termed “Pubhealth,” which consists of thousands of health articles. The results are evaluated using five performance measures, accuracy, precision, recall, f1‐score, and area under the ROC curve (AUC). Furthermore, we extensively compared the proposed model with different deep learning and machine learning models such as Long short‐term memory (LSTM), Bidirectional LSTM, CNN (Convolutional neural network), and RNN‐CNN. The experimental results showed that the proposed model produced state‐of‐the‐art performance on the used dataset by achieving an accuracy of 0.88, precision of 0.92, recall of 0.87, f1‐score of 0.90, and AUC of 0.94. Further, the proposed model yielded better performance than other benchmarked techniques for the credibility assessment of online health articles.",
        "keywords": "",
        "link": "http://dx.doi.org/10.1111/coin.12596"
    },
    {
        "id": 22501,
        "title": "A spectrum contextual self-attention deep learning network for hyperspectral inversion of soil metals",
        "authors": "Tingyu Zhang, Quan Fu, Runqing Tian, Yang Zhang, Zenghui Sun",
        "published": "2023-8",
        "citations": 3,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.ecolind.2023.110351"
    },
    {
        "id": 22502,
        "title": "An Attention-Based Deep Learning Approach to Knee Injury Classification from MRI Images",
        "authors": "Kowshik Deb Nath, A. F. M. Minhazur Rahman, Md. Ali Hossain",
        "published": "2023-12-13",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1109/iccit60459.2023.10441340"
    },
    {
        "id": 22503,
        "title": "Spatio-temporal representation learning enhanced speech emotion recognition with multi-head attention mechanisms",
        "authors": "Zengzhao Chen, Mengting Lin, Zhifeng Wang, Qiuyu Zheng, Chuan Liu",
        "published": "2023-12",
        "citations": 0,
        "abstract": "No Abstract or Keywords available",
        "keywords": "",
        "link": "http://dx.doi.org/10.1016/j.knosys.2023.111077"
    },
    {
        "id": 22504,
        "title": "An attention-based deep learning network for lung nodule malignancy discrimination",
        "authors": "Gang Liu, Fei Liu, Jun Gu, Xu Mao, XiaoTing Xie, Jingyao Sang",
        "published": "2023-1-9",
        "citations": 1,
        "abstract": "IntroductionEffective classification of lung cancers plays a vital role in lung tumor diagnosis and subsequent treatments. However, classification of benign and malignant lung nodules remains inaccurate.MethodsThis study proposes a novel multimodal attention-based 3D convolutional neural network (CNN) which combines computed tomography (CT) imaging features and clinical information to classify benign and malignant nodules.ResultsAn average diagnostic sensitivity of 96.2% for malignant nodules and an average accuracy of 81.6% for classification of benign and malignant nodules were achieved in our algorithm, exceeding results achieved from traditional ResNet network (sensitivity of 89% and accuracy of 80%) and VGG network (sensitivity of 78% and accuracy of 73.1%).DiscussionThe proposed deep learning (DL) model could effectively distinguish benign and malignant nodules with higher precision.",
        "keywords": "",
        "link": "http://dx.doi.org/10.3389/fnins.2022.1106937"
    }
]